- en: T5
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: T5
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/t5](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/t5)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/t5](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/t5)
- en: '[![Models](../Images/e9c13937278bcba9e0fa513715110056.png)](https://huggingface.co/models?filter=t5)
    [![Spaces](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/docs-demos/t5-base)
    [![Paper page](../Images/34309e98f4862f5c97a4c0fb366f8607.png)](https://huggingface.co/papers/1910.10683)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[![æ¨¡å‹](../Images/e9c13937278bcba9e0fa513715110056.png)](https://huggingface.co/models?filter=t5)
    [![ç©ºé—´](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/docs-demos/t5-base)
    [![è®ºæ–‡é¡µé¢](../Images/34309e98f4862f5c97a4c0fb366f8607.png)](https://huggingface.co/papers/1910.10683)'
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: The T5 model was presented in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf) by [Colin
    Raffel](https://huggingface.co/craffel), Noam Shazeer, [Adam Roberts](https://huggingface.co/adarob),
    Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, [Peter J. Liu](https://huggingface.co/peterjliu).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ¨¡å‹åœ¨[æ¢ç´¢ç»Ÿä¸€æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢å™¨çš„è¿ç§»å­¦ä¹ æé™](https://arxiv.org/pdf/1910.10683.pdf)ä¸­ç”±[Colin Raffel](https://huggingface.co/craffel)ã€Noam
    Shazeerã€[Adam Roberts](https://huggingface.co/adarob)ã€Katherine Leeã€Sharan Narangã€Michael
    Matenaã€Yanqi Zhouã€Wei Liã€[Peter J. Liu](https://huggingface.co/peterjliu)æå‡ºã€‚
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*Transfer learning, where a model is first pre-trained on a data-rich task
    before being fine-tuned on a downstream task, has emerged as a powerful technique
    in natural language processing (NLP). The effectiveness of transfer learning has
    given rise to a diversity of approaches, methodology, and practice. In this paper,
    we explore the landscape of transfer learning techniques for NLP by introducing
    a unified framework that converts every language problem into a text-to-text format.
    Our systematic study compares pretraining objectives, architectures, unlabeled
    datasets, transfer approaches, and other factors on dozens of language understanding
    tasks. By combining the insights from our exploration with scale and our new â€œColossal
    Clean Crawled Corpusâ€, we achieve state-of-the-art results on many benchmarks
    covering summarization, question answering, text classification, and more. To
    facilitate future work on transfer learning for NLP, we release our dataset, pre-trained
    models, and code.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ç§»å­¦ä¹ ï¼Œå³æ¨¡å‹é¦–å…ˆåœ¨æ•°æ®ä¸°å¯Œçš„ä»»åŠ¡ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå·²æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­çš„ä¸€ç§å¼ºå¤§æŠ€æœ¯ã€‚è¿ç§»å­¦ä¹ çš„æœ‰æ•ˆæ€§å‚¬ç”Ÿäº†å¤šç§æ–¹æ³•ã€æ–¹æ³•è®ºå’Œå®è·µã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªå°†æ¯ä¸ªè¯­è¨€é—®é¢˜è½¬æ¢ä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬æ ¼å¼çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ¢ç´¢äº†NLPçš„è¿ç§»å­¦ä¹ æŠ€æœ¯é¢†åŸŸã€‚æˆ‘ä»¬çš„ç³»ç»Ÿç ”ç©¶æ¯”è¾ƒäº†æ•°åä¸ªè¯­è¨€ç†è§£ä»»åŠ¡ä¸Šçš„é¢„è®­ç»ƒç›®æ ‡ã€æ¶æ„ã€æ— æ ‡ç­¾æ•°æ®é›†ã€è¿ç§»æ–¹æ³•å’Œå…¶ä»–å› ç´ ã€‚é€šè¿‡å°†æˆ‘ä»¬çš„æ¢ç´¢è§è§£ä¸è§„æ¨¡å’Œæˆ‘ä»¬çš„æ–°â€œå·¨å¤§å¹²å‡€çˆ¬å–è¯­æ–™åº“â€ç›¸ç»“åˆï¼Œæˆ‘ä»¬åœ¨è®¸å¤šæ¶µç›–æ‘˜è¦ã€é—®ç­”ã€æ–‡æœ¬åˆ†ç±»ç­‰æ–¹é¢çš„åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ä¸ºäº†ä¿ƒè¿›æœªæ¥å…³äºNLPçš„è¿ç§»å­¦ä¹ çš„å·¥ä½œï¼Œæˆ‘ä»¬å‘å¸ƒäº†æˆ‘ä»¬çš„æ•°æ®é›†ã€é¢„è®­ç»ƒæ¨¡å‹å’Œä»£ç ã€‚*'
- en: All checkpoints can be found on the [hub](https://huggingface.co/models?search=t5).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ£€æŸ¥ç‚¹éƒ½å¯ä»¥åœ¨[hub](https://huggingface.co/models?search=t5)ä¸Šæ‰¾åˆ°ã€‚
- en: This model was contributed by [thomwolf](https://huggingface.co/thomwolf). The
    original code can be found [here](https://github.com/google-research/text-to-text-transfer-transformer).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç”±[thomwolf](https://huggingface.co/thomwolf)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/google-research/text-to-text-transfer-transformer)æ‰¾åˆ°ã€‚
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æç¤º
- en: 'T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised
    and supervised tasks and for which each task is converted into a text-to-text
    format. T5 works well on a variety of tasks out-of-the-box by prepending a different
    prefix to the input corresponding to each task, e.g., for translation: *translate
    English to German: â€¦*, for summarization: *summarize: â€¦*.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T5æ˜¯ä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œé¢„è®­ç»ƒäºæ— ç›‘ç£å’Œç›‘ç£ä»»åŠ¡çš„å¤šä»»åŠ¡æ··åˆä¸­ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½è½¬æ¢ä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬æ ¼å¼ã€‚é€šè¿‡ä¸ºæ¯ä¸ªä»»åŠ¡çš„è¾“å…¥æ·»åŠ ä¸åŒçš„å‰ç¼€ï¼Œä¾‹å¦‚ï¼Œå¯¹äºç¿»è¯‘ï¼š*å°†è‹±è¯­ç¿»è¯‘æˆå¾·è¯­ï¼šâ€¦*ï¼Œå¯¹äºæ‘˜è¦ï¼š*æ€»ç»“ï¼šâ€¦*ï¼ŒT5å¯ä»¥åœ¨å„ç§ä»»åŠ¡ä¸Šç›´æ¥ä½¿ç”¨ã€‚
- en: The pretraining includes both supervised and self-supervised training. Supervised
    training is conducted on downstream tasks provided by the GLUE and SuperGLUE benchmarks
    (converting them into text-to-text tasks as explained above).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„è®­ç»ƒåŒ…æ‹¬ç›‘ç£å’Œè‡ªç›‘ç£è®­ç»ƒã€‚ç›‘ç£è®­ç»ƒæ˜¯åœ¨GLUEå’ŒSuperGLUEåŸºå‡†æä¾›çš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œçš„ï¼ˆå°†å®ƒä»¬è½¬æ¢ä¸ºä¸Šé¢è§£é‡Šçš„æ–‡æœ¬åˆ°æ–‡æœ¬ä»»åŠ¡ï¼‰ã€‚
- en: Self-supervised training uses corrupted tokens, by randomly removing 15% of
    the tokens and replacing them with individual sentinel tokens (if several consecutive
    tokens are marked for removal, the whole group is replaced with a single sentinel
    token). The input of the encoder is the corrupted sentence, the input of the decoder
    is the original sentence and the target is then the dropped out tokens delimited
    by their sentinel tokens.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡ªç›‘ç£è®­ç»ƒä½¿ç”¨æŸåçš„æ ‡è®°ï¼Œéšæœºåˆ é™¤15%çš„æ ‡è®°å¹¶ç”¨å•ç‹¬çš„æ ‡è®°æ›¿æ¢å®ƒä»¬ï¼ˆå¦‚æœæœ‰å‡ ä¸ªè¿ç»­çš„æ ‡è®°è¢«æ ‡è®°ä¸ºåˆ é™¤ï¼Œåˆ™æ•´ä¸ªç»„å°†è¢«æ›¿æ¢ä¸ºå•ä¸ªæ ‡è®°ï¼‰ã€‚ç¼–ç å™¨çš„è¾“å…¥æ˜¯æŸåçš„å¥å­ï¼Œè§£ç å™¨çš„è¾“å…¥æ˜¯åŸå§‹å¥å­ï¼Œç›®æ ‡æ˜¯è¢«åˆ é™¤çš„æ ‡è®°ï¼Œç”±å®ƒä»¬çš„æ ‡è®°æ ‡è®°ã€‚
- en: T5 uses relative scalar embeddings. Encoder input padding can be done on the
    left and on the right.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T5ä½¿ç”¨ç›¸å¯¹æ ‡é‡åµŒå…¥ã€‚ç¼–ç å™¨è¾“å…¥çš„å¡«å……å¯ä»¥åœ¨å·¦ä¾§å’Œå³ä¾§è¿›è¡Œã€‚
- en: See the [training](#training), [inference](#inference) and [scripts](#scripts)
    sections below for all details regarding usage.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ä¸‹é¢çš„[è®­ç»ƒ](#training)ã€[æ¨ç†](#inference)å’Œ[è„šæœ¬](#scripts)éƒ¨åˆ†ï¼Œäº†è§£æœ‰å…³ä½¿ç”¨çš„æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ã€‚
- en: 'T5 comes in different sizes:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: T5æœ‰ä¸åŒçš„å°ºå¯¸ï¼š
- en: '[t5-small](https://huggingface.co/t5-small)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[t5-small](https://huggingface.co/t5-small)'
- en: '[t5-base](https://huggingface.co/t5-base)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[t5-base](https://huggingface.co/t5-base)'
- en: '[t5-large](https://huggingface.co/t5-large)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[t5-large](https://huggingface.co/t5-large)'
- en: '[t5-3b](https://huggingface.co/t5-3b)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[t5-3b](https://huggingface.co/t5-3b)'
- en: '[t5-11b](https://huggingface.co/t5-11b).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[t5-11b](https://huggingface.co/t5-11b)ã€‚'
- en: 'Based on the original T5 model, Google has released some follow-up works:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºåŸå§‹T5æ¨¡å‹ï¼ŒGoogleå‘å¸ƒäº†ä¸€äº›åç»­ä½œå“ï¼š
- en: '**T5v1.1**: T5v1.1 is an improved version of T5 with some architectural tweaks,
    and is pre-trained on C4 only without mixing in the supervised tasks. Refer to
    the documentation of T5v1.1 which can be found [here](t5v1.1).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**T5v1.1**ï¼šT5v1.1æ˜¯T5çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œè¿›è¡Œäº†ä¸€äº›æ¶æ„è°ƒæ•´ï¼Œä»…åœ¨C4ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œæ²¡æœ‰æ··åˆç›‘ç£ä»»åŠ¡ã€‚è¯·å‚é˜…T5v1.1çš„æ–‡æ¡£ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](t5v1.1)æ‰¾åˆ°ã€‚'
- en: '**mT5**: mT5 is a multilingual T5 model. It is pre-trained on the mC4 corpus,
    which includes 101 languages. Refer to the documentation of mT5 which can be found
    [here](mt5).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MT5ï¼šmT5æ˜¯ä¸€ä¸ªå¤šè¯­è¨€T5æ¨¡å‹ã€‚å®ƒåœ¨åŒ…æ‹¬101ç§è¯­è¨€çš„mC4è¯­æ–™åº“ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚è¯·å‚è€ƒå¯ä»¥åœ¨[è¿™é‡Œ](mt5)æ‰¾åˆ°çš„mT5çš„æ–‡æ¡£ã€‚
- en: '**byT5**: byT5 is a T5 model pre-trained on byte sequences rather than SentencePiece
    subword token sequences. Refer to the documentation of byT5 which can be found
    [here](byt5).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: byT5ï¼šbyT5æ˜¯ä¸€ä¸ªåœ¨å­—èŠ‚åºåˆ—è€Œä¸æ˜¯SentencePieceå­è¯æ ‡è®°åºåˆ—ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„T5æ¨¡å‹ã€‚è¯·å‚è€ƒå¯ä»¥åœ¨[è¿™é‡Œ](byt5)æ‰¾åˆ°çš„byT5çš„æ–‡æ¡£ã€‚
- en: '**UL2**: UL2 is a T5 like model pretrained on various denoising objectives'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UL2ï¼šUL2æ˜¯ä¸€ä¸ªç±»ä¼¼T5çš„æ¨¡å‹ï¼Œé¢„è®­ç»ƒäºå„ç§å»å™ªç›®æ ‡ã€‚
- en: '**Flan-T5**: Flan is a pretraining methods that is based on prompting. The
    Flan-T5 are T5 models trained on the Flan collection of datasets which include:
    `taskmaster2`, `djaym7/wiki_dialog`, `deepmind/code_contests`, `lambada`, `gsm8k`,
    `aqua_rat`, `esnli`, `quasc` and `qed`.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flan-T5ï¼šFlanæ˜¯ä¸€ç§åŸºäºæç¤ºçš„é¢„è®­ç»ƒæ–¹æ³•ã€‚Flan-T5æ˜¯åœ¨Flanæ•°æ®é›†ä¸Šè®­ç»ƒçš„T5æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š`taskmaster2`ã€`djaym7/wiki_dialog`ã€`deepmind/code_contests`ã€`lambada`ã€`gsm8k`ã€`aqua_rat`ã€`esnli`ã€`quasc`å’Œ`qed`ã€‚
- en: '**FLan-UL2** : the UL2 model finetuned using the â€œFlanâ€ prompt tuning and dataset
    collection.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FLan-UL2ï¼šä½¿ç”¨â€œFlanâ€æç¤ºè°ƒæ•´å’Œæ•°æ®é›†æ”¶é›†å¯¹UL2æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚
- en: '**UMT5**: UmT5 is a multilingual T5 model trained on an improved and refreshed
    mC4 multilingual corpus, 29 trillion characters across 107 language, using a new
    sampling method, UniMax. Refer to the documentation of mT5 which can be found
    [here](umt5).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UMT5ï¼šUmT5æ˜¯ä¸€ä¸ªå¤šè¯­è¨€T5æ¨¡å‹ï¼Œè®­ç»ƒäºä¸€ä¸ªæ”¹è¿›å’Œæ›´æ–°çš„mC4å¤šè¯­è¨€è¯­æ–™åº“ï¼Œè·¨107ç§è¯­è¨€ï¼Œä½¿ç”¨ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•UniMaxã€‚è¯·å‚è€ƒå¯ä»¥åœ¨[è¿™é‡Œ](umt5)æ‰¾åˆ°çš„mT5çš„æ–‡æ¡£ã€‚
- en: Training
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒ
- en: T5 is an encoder-decoder model and converts all NLP problems into a text-to-text
    format. It is trained using teacher forcing. This means that for training, we
    always need an input sequence and a corresponding target sequence. The input sequence
    is fed to the model using `input_ids`. The target sequence is shifted to the right,
    i.e., prepended by a start-sequence token and fed to the decoder using the `decoder_input_ids`.
    In teacher-forcing style, the target sequence is then appended by the EOS token
    and corresponds to the `labels`. The PAD token is hereby used as the start-sequence
    token. T5 can be trained / fine-tuned both in a supervised and unsupervised fashion.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ˜¯ä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œå°†æ‰€æœ‰NLPé—®é¢˜è½¬æ¢ä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬çš„æ ¼å¼ã€‚å®ƒä½¿ç”¨æ•™å¸ˆå¼ºåˆ¶è¿›è¡Œè®­ç»ƒã€‚è¿™æ„å‘³ç€åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬æ€»æ˜¯éœ€è¦ä¸€ä¸ªè¾“å…¥åºåˆ—å’Œä¸€ä¸ªç›¸åº”çš„ç›®æ ‡åºåˆ—ã€‚è¾“å…¥åºåˆ—é€šè¿‡`input_ids`é¦ˆé€åˆ°æ¨¡å‹ã€‚ç›®æ ‡åºåˆ—å‘å³ç§»åŠ¨ï¼Œå³åœ¨å‰é¢åŠ ä¸Šä¸€ä¸ªèµ·å§‹åºåˆ—æ ‡è®°ï¼Œå¹¶é€šè¿‡`decoder_input_ids`é¦ˆé€åˆ°è§£ç å™¨ã€‚åœ¨æ•™å¸ˆå¼ºåˆ¶é£æ ¼ä¸­ï¼Œç›®æ ‡åºåˆ—ç„¶åé™„åŠ EOSæ ‡è®°ï¼Œå¹¶å¯¹åº”äº`labels`ã€‚åœ¨è¿™é‡Œï¼ŒPADæ ‡è®°è¢«ç”¨ä½œèµ·å§‹åºåˆ—æ ‡è®°ã€‚T5å¯ä»¥ä»¥ç›‘ç£å’Œæ— ç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒ/å¾®è°ƒã€‚
- en: One can use [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (or the Tensorflow/Flax variant), which includes the language modeling head on
    top of the decoder.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)ï¼ˆæˆ–Tensorflow/Flaxå˜ä½“ï¼‰ï¼Œå®ƒåœ¨è§£ç å™¨é¡¶éƒ¨åŒ…å«äº†è¯­è¨€å»ºæ¨¡å¤´ã€‚
- en: Unsupervised denoising training
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ— ç›‘ç£å»å™ªè®­ç»ƒ
- en: In this setup, spans of the input sequence are masked by so-called sentinel
    tokens (*a.k.a* unique mask tokens) and the output sequence is formed as a concatenation
    of the same sentinel tokens and the *real* masked tokens. Each sentinel token
    represents a unique mask token for this sentence and should start with `<extra_id_0>`,
    `<extra_id_1>`, â€¦ up to `<extra_id_99>`. As a default, 100 sentinel tokens are
    available in [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§è®¾ç½®ä¸­ï¼Œè¾“å…¥åºåˆ—çš„ç‰‡æ®µè¢«æ‰€è°“çš„å“¨å…µæ ‡è®°ï¼ˆ*åˆå*å”¯ä¸€çš„æ©ç æ ‡è®°ï¼‰å±è”½ï¼Œè¾“å‡ºåºåˆ—ç”±ç›¸åŒçš„å“¨å…µæ ‡è®°å’Œ*çœŸå®*è¢«å±è”½çš„æ ‡è®°çš„ä¸²è”å½¢æˆã€‚æ¯ä¸ªå“¨å…µæ ‡è®°ä»£è¡¨è¿™ä¸ªå¥å­çš„ä¸€ä¸ªå”¯ä¸€çš„æ©ç æ ‡è®°ï¼Œåº”è¯¥ä»¥`<extra_id_0>`ã€`<extra_id_1>`ç­‰å½¢å¼å¼€å§‹ï¼Œä¸€ç›´åˆ°`<extra_id_99>`ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ[T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)ä¸­æœ‰100ä¸ªå“¨å…µæ ‡è®°å¯ç”¨ã€‚
- en: 'For instance, the sentence â€œThe cute dog walks in the parkâ€ with the masks
    put on â€œcute dogâ€ and â€œtheâ€ should be processed as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¥å­â€œThe cute dog walks in the parkâ€ä¸­çš„â€œcute dogâ€å’Œâ€œtheâ€è¢«å±è”½ååº”è¯¥è¢«å¤„ç†å¦‚ä¸‹ï¼š
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If youâ€™re interested in pre-training T5 on a new corpus, check out the [run_t5_mlm_flax.py](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling)
    script in the Examples directory.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£åœ¨æ–°è¯­æ–™åº“ä¸Šé¢„è®­ç»ƒT5ï¼Œè¯·æŸ¥çœ‹Examplesç›®å½•ä¸­çš„[run_t5_mlm_flax.py](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling)è„šæœ¬ã€‚
- en: Supervised training
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›‘ç£è®­ç»ƒ
- en: 'In this setup, the input sequence and output sequence are a standard sequence-to-sequence
    input-output mapping. Suppose that we want to fine-tune the model for translation
    for example, and we have a training example: the input sequence â€œThe house is
    wonderful.â€ and output sequence â€œDas Haus ist wunderbar.â€, then they should be
    prepared for the model as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§è®¾ç½®ä¸­ï¼Œè¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—æ˜¯æ ‡å‡†çš„åºåˆ—åˆ°åºåˆ—çš„è¾“å…¥è¾“å‡ºæ˜ å°„ã€‚å‡è®¾æˆ‘ä»¬æƒ³è¦ä¸ºç¿»è¯‘è°ƒæ•´æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªè®­ç»ƒç¤ºä¾‹ï¼šè¾“å…¥åºåˆ—â€œThe house is
    wonderful.â€å’Œè¾“å‡ºåºåˆ—â€œDas Haus ist wunderbar.â€ï¼Œé‚£ä¹ˆå®ƒä»¬åº”è¯¥è¢«å‡†å¤‡ä¸ºæ¨¡å‹å¦‚ä¸‹ï¼š
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, only 2 inputs are required for the model in order to compute
    a loss: `input_ids` (which are the `input_ids` of the encoded input sequence)
    and `labels` (which are the `input_ids` of the encoded target sequence). The model
    will automatically create the `decoder_input_ids` based on the `labels`, by shifting
    them one position to the right and prepending the `config.decoder_start_token_id`,
    which for T5 is equal to 0 (i.e. the id of the pad token). Also note the task
    prefix: we prepend the input sequence with â€˜translate English to German: â€™ before
    encoding it. This will help in improving the performance, as this task prefix
    was used during T5â€™s pre-training.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¦‚æ‚¨æ‰€è§ï¼Œä¸ºäº†è®¡ç®—æŸå¤±ï¼Œæ¨¡å‹åªéœ€è¦2ä¸ªè¾“å…¥ï¼š`input_ids`ï¼ˆç¼–ç è¾“å…¥åºåˆ—çš„`input_ids`ï¼‰å’Œ`labels`ï¼ˆç¼–ç ç›®æ ‡åºåˆ—çš„`input_ids`ï¼‰ã€‚æ¨¡å‹å°†æ ¹æ®`labels`è‡ªåŠ¨åˆ›å»º`decoder_input_ids`ï¼Œå°†å®ƒä»¬å‘å³ç§»åŠ¨ä¸€ä¸ªä½ç½®å¹¶åœ¨å‰é¢æ·»åŠ `config.decoder_start_token_id`ï¼Œå¯¹äºT5æ¥è¯´ç­‰äº0ï¼ˆå³å¡«å……æ ‡è®°çš„idï¼‰ã€‚è¿˜è¦æ³¨æ„ä»»åŠ¡å‰ç¼€ï¼šæˆ‘ä»¬åœ¨ç¼–ç ä¹‹å‰åœ¨è¾“å…¥åºåˆ—å‰é¢æ·»åŠ äº†â€˜translate
    English to German: â€™ã€‚è¿™å°†æœ‰åŠ©äºæé«˜æ€§èƒ½ï¼Œå› ä¸ºè¿™ä¸ªä»»åŠ¡å‰ç¼€åœ¨T5çš„é¢„è®­ç»ƒä¸­ä½¿ç”¨è¿‡ã€‚'
- en: However, the example above only shows a single training example. In practice,
    one trains deep learning models in batches. This entails that we must pad/truncate
    examples to the same length. For encoder-decoder models, one typically defines
    a `max_source_length` and `max_target_length`, which determine the maximum length
    of the input and output sequences respectively (otherwise they are truncated).
    These should be carefully set depending on the task.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸Šé¢çš„ç¤ºä¾‹åªæ˜¾ç¤ºäº†ä¸€ä¸ªè®­ç»ƒç¤ºä¾‹ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸æ‰¹é‡è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¿…é¡»å°†ç¤ºä¾‹å¡«å……/æˆªæ–­åˆ°ç›¸åŒçš„é•¿åº¦ã€‚å¯¹äºç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œé€šå¸¸å®šä¹‰`max_source_length`å’Œ`max_target_length`ï¼Œåˆ†åˆ«ç¡®å®šè¾“å…¥å’Œè¾“å‡ºåºåˆ—çš„æœ€å¤§é•¿åº¦ï¼ˆå¦åˆ™å°†è¢«æˆªæ–­ï¼‰ã€‚è¿™äº›åº”æ ¹æ®ä»»åŠ¡ä»”ç»†è®¾ç½®ã€‚
- en: In addition, we must make sure that padding token idâ€™s of the `labels` are not
    taken into account by the loss function. In PyTorch and Tensorflow, this can be
    done by replacing them with -100, which is the `ignore_index` of the `CrossEntropyLoss`.
    In Flax, one can use the `decoder_attention_mask` to ignore padded tokens from
    the loss (see the [Flax summarization script](https://github.com/huggingface/transformers/tree/main/examples/flax/summarization)
    for details). We also pass `attention_mask` as additional input to the model,
    which makes sure that padding tokens of the inputs are ignored. The code example
    below illustrates all of this.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿`labels`çš„å¡«å……æ ‡è®°IDä¸è¢«æŸå¤±å‡½æ•°è€ƒè™‘ã€‚åœ¨PyTorchå’ŒTensorflowä¸­ï¼Œå¯ä»¥é€šè¿‡ç”¨-100æ›¿æ¢å®ƒä»¬æ¥å®ç°ï¼Œ-100æ˜¯`CrossEntropyLoss`çš„`ignore_index`ã€‚åœ¨Flaxä¸­ï¼Œå¯ä»¥ä½¿ç”¨`decoder_attention_mask`æ¥å¿½ç•¥æŸå¤±ä¸­çš„å¡«å……æ ‡è®°ï¼ˆæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[Flaxæ‘˜è¦è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/flax/summarization)ï¼‰ã€‚æˆ‘ä»¬è¿˜å°†`attention_mask`ä½œä¸ºæ¨¡å‹çš„é™„åŠ è¾“å…¥ä¼ é€’ï¼Œä»¥ç¡®ä¿å¿½ç•¥è¾“å…¥çš„å¡«å……æ ‡è®°ã€‚ä¸‹é¢çš„ä»£ç ç¤ºä¾‹è¯´æ˜äº†æ‰€æœ‰è¿™äº›ã€‚
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Additional training tips:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: é¢å¤–çš„è®­ç»ƒæç¤ºï¼š
- en: T5 models need a slightly higher learning rate than the default one set in the
    `Trainer` when using the AdamW optimizer. Typically, 1e-4 and 3e-4 work well for
    most problems (classification, summarization, translation, question answering,
    question generation). Note that T5 was pre-trained using the AdaFactor optimizer.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ä½¿ç”¨AdamWä¼˜åŒ–å™¨æ—¶ï¼ŒT5æ¨¡å‹éœ€è¦æ¯”`Trainer`ä¸­è®¾ç½®çš„é»˜è®¤å­¦ä¹ ç‡ç•¥é«˜ã€‚é€šå¸¸ï¼Œå¯¹äºå¤§å¤šæ•°é—®é¢˜ï¼ˆåˆ†ç±»ã€æ‘˜è¦ã€ç¿»è¯‘ã€é—®ç­”ã€é—®é¢˜ç”Ÿæˆï¼‰ï¼Œ1e-4å’Œ3e-4æ•ˆæœå¾ˆå¥½ã€‚è¯·æ³¨æ„ï¼ŒT5æ˜¯ä½¿ç”¨AdaFactorä¼˜åŒ–å™¨è¿›è¡Œé¢„è®­ç»ƒçš„ã€‚
- en: According to [this forum post](https://discuss.huggingface.co/t/t5-finetuning-tips/684),
    task prefixes matter when (1) doing multi-task training (2) your task is similar
    or related to one of the supervised tasks used in T5â€™s pre-training mixture (see
    Appendix D of the [paper](https://arxiv.org/pdf/1910.10683.pdf) for the task prefixes
    used).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®[è¿™ç¯‡è®ºå›å¸–å­](https://discuss.huggingface.co/t/t5-finetuning-tips/684)ï¼Œä»»åŠ¡å‰ç¼€åœ¨ï¼ˆ1ï¼‰è¿›è¡Œå¤šä»»åŠ¡è®­ç»ƒæ—¶ï¼ˆ2ï¼‰æ‚¨çš„ä»»åŠ¡ä¸T5é¢„è®­ç»ƒæ··åˆä¸­ä½¿ç”¨çš„ç›‘ç£ä»»åŠ¡ä¹‹ä¸€ç±»ä¼¼æˆ–ç›¸å…³æ—¶å¾ˆé‡è¦ï¼ˆè¯·å‚é˜…[è®ºæ–‡](https://arxiv.org/pdf/1910.10683.pdf)çš„é™„å½•Dï¼Œäº†è§£ä½¿ç”¨çš„ä»»åŠ¡å‰ç¼€ï¼‰ã€‚
- en: If training on TPU, it is recommended to pad all examples of the dataset to
    the same length or make use of *pad_to_multiple_of* to have a small number of
    predefined bucket sizes to fit all examples in. Dynamically padding batches to
    the longest example is not recommended on TPU as it triggers a recompilation for
    every batch shape that is encountered during training thus significantly slowing
    down the training. only padding up to the longest example in a batch) leads to
    very slow training on TPU.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœåœ¨TPUä¸Šè®­ç»ƒï¼Œå»ºè®®å°†æ•°æ®é›†çš„æ‰€æœ‰ç¤ºä¾‹å¡«å……åˆ°ç›¸åŒçš„é•¿åº¦ï¼Œæˆ–è€…ä½¿ç”¨*pad_to_multiple_of*æ¥ä½¿ç”¨å°‘é‡é¢„å®šä¹‰çš„æ¡¶å¤§å°ä»¥é€‚åº”æ‰€æœ‰ç¤ºä¾‹ã€‚åœ¨TPUä¸ŠåŠ¨æ€å¡«å……æ‰¹æ¬¡åˆ°æœ€é•¿ç¤ºä¾‹ä¸å»ºè®®ï¼Œå› ä¸ºå®ƒä¼šåœ¨è®­ç»ƒæœŸé—´é‡åˆ°çš„æ¯ä¸ªæ‰¹æ¬¡å½¢çŠ¶è§¦å‘é‡æ–°ç¼–è¯‘ï¼Œä»è€Œæ˜¾è‘—å‡æ…¢è®­ç»ƒé€Ÿåº¦ã€‚åªå¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„ç¤ºä¾‹ä¼šå¯¼è‡´åœ¨TPUä¸Šè®­ç»ƒéå¸¸ç¼“æ…¢ã€‚
- en: Inference
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨ç†
- en: At inference time, it is recommended to use [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate).
    This method takes care of encoding the input and feeding the encoded hidden states
    via cross-attention layers to the decoder and auto-regressively generates the
    decoder output. Check out [this blog post](https://huggingface.co/blog/how-to-generate)
    to know all the details about generating text with Transformers. Thereâ€™s also
    [this blog post](https://huggingface.co/blog/encoder-decoder#encoder-decoder)
    which explains how generation works in general in encoder-decoder models.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¨ç†æ—¶ï¼Œå»ºè®®ä½¿ç”¨[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)ã€‚è¿™ç§æ–¹æ³•è´Ÿè´£å¯¹è¾“å…¥è¿›è¡Œç¼–ç ï¼Œå¹¶é€šè¿‡äº¤å‰æ³¨æ„åŠ›å±‚å°†ç¼–ç éšè—çŠ¶æ€é¦ˆé€åˆ°è§£ç å™¨ï¼Œè‡ªå›å½’åœ°ç”Ÿæˆè§£ç å™¨è¾“å‡ºã€‚æŸ¥çœ‹[è¿™ç¯‡åšæ–‡](https://huggingface.co/blog/how-to-generate)äº†è§£ä½¿ç”¨Transformersç”Ÿæˆæ–‡æœ¬çš„æ‰€æœ‰ç»†èŠ‚ã€‚è¿˜æœ‰[è¿™ç¯‡åšæ–‡](https://huggingface.co/blog/encoder-decoder#encoder-decoder)è§£é‡Šäº†ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ä¸­ç”Ÿæˆçš„å·¥ä½œåŸç†ã€‚
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that T5 uses the `pad_token_id` as the `decoder_start_token_id`, so when
    doing generation without using [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate),
    make sure you start it with the `pad_token_id`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼ŒT5ä½¿ç”¨`pad_token_id`ä½œä¸º`decoder_start_token_id`ï¼Œå› æ­¤åœ¨ç”Ÿæˆæ—¶å¦‚æœä¸ä½¿ç”¨[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)ï¼Œè¯·ç¡®ä¿ä»¥`pad_token_id`å¼€å¤´ã€‚
- en: 'The example above only shows a single example. You can also do batched inference,
    like so:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„ç¤ºä¾‹åªæ˜¾ç¤ºäº†ä¸€ä¸ªå•ç‹¬çš„ç¤ºä¾‹ã€‚æ‚¨ä¹Ÿå¯ä»¥è¿›è¡Œæ‰¹é‡æ¨ç†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Because T5 has been trained with the span-mask denoising objective, it can be
    used to predict the sentinel (masked-out) tokens during inference. The predicted
    tokens will then be placed between the sentinel tokens.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºT5å·²ç»ä½¿ç”¨äº†è·¨åº¦æ©ç å»å™ªç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç”¨äºé¢„æµ‹æ ‡è®°ï¼ˆè¢«æ©ç çš„ï¼‰æ ‡è®°ã€‚ç„¶åï¼Œé¢„æµ‹çš„æ ‡è®°å°†è¢«æ”¾ç½®åœ¨æ ‡è®°ä¹‹é—´ã€‚
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Performance
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ€§èƒ½
- en: If youâ€™d like a faster training and inference performance, install [NVIDIA APEX](https://github.com/NVIDIA/apex#quick-start)
    for NVIDIA GPUs, or [ROCm APEX](https://github.com/ROCmSoftwarePlatform/apex)
    for AMD GPUs and then the model will automatically use `apex.normalization.FusedRMSNorm`
    instead of `T5LayerNorm`. The former uses an optimized fused kernel which is several
    times faster than the latter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¸Œæœ›è·å¾—æ›´å¿«çš„è®­ç»ƒå’Œæ¨ç†æ€§èƒ½ï¼Œè¯·ä¸ºNVIDIA GPUå®‰è£…[NVIDIA APEX](https://github.com/NVIDIA/apex#quick-start)ï¼Œæˆ–ä¸ºAMD
    GPUå®‰è£…[ROCm APEX](https://github.com/ROCmSoftwarePlatform/apex)ï¼Œç„¶åæ¨¡å‹å°†è‡ªåŠ¨ä½¿ç”¨`apex.normalization.FusedRMSNorm`è€Œä¸æ˜¯`T5LayerNorm`ã€‚å‰è€…ä½¿ç”¨ä¼˜åŒ–çš„èåˆå†…æ ¸ï¼Œæ¯”åè€…å¿«å‡ å€ã€‚
- en: Resources
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started with T5\. If youâ€™re interested in submitting a resource to
    be included here, please feel free to open a Pull Request and weâ€™ll review it!
    The resource should ideally demonstrate something new instead of duplicating an
    existing resource.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå®˜æ–¹Hugging Faceå’Œç¤¾åŒºèµ„æºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰ï¼Œå¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨T5ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ªPull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥ç†æƒ³åœ°å±•ç¤ºä¸€äº›æ–°å†…å®¹ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: Text Classification
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ†ç±»
- en: A notebook for how to [finetune T5 for classification and multiple choice](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb).
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äºå¦‚ä½•[å¾®è°ƒT5è¿›è¡Œåˆ†ç±»å’Œå¤šé¡¹é€‰æ‹©](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb)çš„ç¬”è®°æœ¬ã€‚
- en: A notebook for how to [finetune T5 for sentiment span extraction](https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb).
    ğŸŒ
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äºå¦‚ä½•[å¾®è°ƒT5è¿›è¡Œæƒ…æ„Ÿè·¨åº¦æå–](https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb)çš„ç¬”è®°æœ¬ã€‚ğŸŒ
- en: Token Classification
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡è®°åˆ†ç±»
- en: A notebook for how to [finetune T5 for named entity recognition](https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing).
    ğŸŒ
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äºå¦‚ä½•[å¾®è°ƒT5è¿›è¡Œå‘½åå®ä½“è¯†åˆ«](https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing)çš„ç¬”è®°æœ¬ã€‚ğŸŒ
- en: Text Generation
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬ç”Ÿæˆ
- en: A notebook for [Finetuning CodeT5 for generating docstrings from Ruby code](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tune_CodeT5_for_generating_docstrings_from_Ruby_code.ipynb).
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äº[å¯¹Rubyä»£ç ç”Ÿæˆdocstringsè¿›è¡ŒFine-tuning CodeT5](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tune_CodeT5_for_generating_docstrings_from_Ruby_code.ipynb)çš„ç¬”è®°æœ¬ã€‚
- en: Summarization
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: A notebook to [Finetune T5-base-dutch to perform Dutch abstractive summarization
    on a TPU](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tuning_Dutch_T5_base_on_CNN_Daily_Mail_for_summarization_(on_TPU_using_HuggingFace_Accelerate).ipynb).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äº[åœ¨TPUä¸Šå¯¹T5-base-dutchè¿›è¡Œè·å…°è¯­æŠ½è±¡æ‘˜è¦çš„Fine-tuning](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tuning_Dutch_T5_base_on_CNN_Daily_Mail_for_summarization_(on_TPU_using_HuggingFace_Accelerate).ipynb)çš„ç¬”è®°æœ¬ã€‚
- en: A notebook for how to [finetune T5 for summarization in PyTorch and track experiments
    with WandB](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb#scrollTo=OKRpFvYhBauC).
    ğŸŒ
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äºå¦‚ä½•[åœ¨PyTorchä¸­å¾®è°ƒT5è¿›è¡Œæ‘˜è¦å¹¶ä½¿ç”¨WandBè·Ÿè¸ªå®éªŒ](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb#scrollTo=OKRpFvYhBauC)çš„ç¬”è®°æœ¬ã€‚ğŸŒ
- en: 'A blog post on [Distributed Training: Train BART/T5 for Summarization using
    ğŸ¤— Transformers and Amazon SageMaker](https://huggingface.co/blog/sagemaker-distributed-training-seq2seq).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç¯‡å…³äº[åˆ†å¸ƒå¼è®­ç»ƒï¼šä½¿ç”¨ğŸ¤— Transformerså’ŒAmazon SageMakerè®­ç»ƒBART/T5è¿›è¡Œæ‘˜è¦](https://huggingface.co/blog/sagemaker-distributed-training-seq2seq)çš„åšå®¢æ–‡ç« ã€‚
- en: '[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)æ”¯æŒã€‚'
- en: '[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)æ”¯æŒã€‚'
- en: '[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/flax/summarization).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/flax/summarization)æ”¯æŒã€‚'
- en: '[Summarization](https://huggingface.co/course/chapter7/5?fw=pt#summarization)
    chapter of the ğŸ¤— Hugging Face course.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ¤— Hugging Faceè¯¾ç¨‹çš„[æ‘˜è¦](https://huggingface.co/course/chapter7/5?fw=pt#summarization)ç« èŠ‚ã€‚
- en: '[Summarization task guide](../tasks/summarization)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ‘˜è¦ä»»åŠ¡æŒ‡å—](../tasks/summarization)'
- en: Fill-Mask
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¡«å……æ©ç 
- en: '[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#t5-like-span-masked-language-modeling)
    for training T5 with a span-masked language model objective. The script also shows
    how to train a T5 tokenizer. [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    is also supported by this [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/masked_language_modeling_flax.ipynb).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#t5-like-span-masked-language-modeling)æ”¯æŒï¼Œç”¨äºè®­ç»ƒå…·æœ‰è·¨åº¦æ©ç è¯­è¨€æ¨¡å‹ç›®æ ‡çš„T5ã€‚è¯¥è„šæœ¬è¿˜å±•ç¤ºäº†å¦‚ä½•è®­ç»ƒT5åˆ†è¯å™¨ã€‚[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)ä¹Ÿç”±è¿™ä¸ª[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/masked_language_modeling_flax.ipynb)æ”¯æŒã€‚'
- en: Translation
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç¿»è¯‘
- en: '[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/translation)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/translation)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)æ”¯æŒã€‚'
- en: '[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/translation)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb).'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/translation)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)æ”¯æŒã€‚'
- en: '[Translation task guide](../tasks/translation)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ç¿»è¯‘ä»»åŠ¡æŒ‡å—](../tasks/translation)'
- en: Question Answering
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: é—®ç­”
- en: A notebook on how to [finetune T5 for question answering with TensorFlow 2](https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb).
    ğŸŒ
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äºå¦‚ä½•ä½¿ç”¨TensorFlow 2å¯¹[T5è¿›è¡Œé—®é¢˜å›ç­”å¾®è°ƒçš„ç¬”è®°æœ¬](https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb)ã€‚ğŸŒ
- en: A notebook on how to [finetune T5 for question answering on a TPU](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil).
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…³äºå¦‚ä½•åœ¨TPUä¸Šå¯¹[T5è¿›è¡Œé—®é¢˜å›ç­”å¾®è°ƒçš„ç¬”è®°æœ¬](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil)ã€‚
- en: ğŸš€ **Deploy**
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸš€ **éƒ¨ç½²**
- en: A blog post on how to deploy [T5 11B for inference for less than $500](https://www.philschmid.de/deploy-t5-11b).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³äºå¦‚ä½•ä»¥ä½äº500ç¾å…ƒçš„ä»·æ ¼éƒ¨ç½²[T5 11Bè¿›è¡Œæ¨ç†çš„åšå®¢æ–‡ç« ](https://www.philschmid.de/deploy-t5-11b)ã€‚
- en: T5Config
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5Config
- en: '### `class transformers.T5Config`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/configuration_t5.py#L34)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/configuration_t5.py#L34)'
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_size` (`int`, *optional*, defaults to 32128) â€” Vocabulary size of the
    T5 model. Defines the number of different tokens that can be represented by the
    `inputs_ids` passed when calling [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    or [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model).'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 32128) â€” T5æ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨è°ƒç”¨[T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)æˆ–[TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ã€‚'
- en: '`d_model` (`int`, *optional*, defaults to 512) â€” Size of the encoder layers
    and the pooler layer.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *optional*, defaults to 512) â€” ç¼–ç å™¨å±‚å’Œæ± åŒ–å±‚çš„å¤§å°ã€‚'
- en: '`d_kv` (`int`, *optional*, defaults to 64) â€” Size of the key, query, value
    projections per attention head. The `inner_dim` of the projection layer will be
    defined as `num_heads * d_kv`.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_kv` (`int`, *optional*, defaults to 64) â€” æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„é”®ã€æŸ¥è¯¢ã€å€¼æŠ•å½±çš„å¤§å°ã€‚æŠ•å½±å±‚çš„`inner_dim`å°†è¢«å®šä¹‰ä¸º`num_heads
    * d_kv`ã€‚'
- en: '`d_ff` (`int`, *optional*, defaults to 2048) â€” Size of the intermediate feed
    forward layer in each `T5Block`.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_ff` (`int`, *optional*, defaults to 2048) â€” æ¯ä¸ª`T5Block`ä¸­é—´çš„å‰é¦ˆå±‚çš„å¤§å°ã€‚'
- en: '`num_layers` (`int`, *optional*, defaults to 6) â€” Number of hidden layers in
    the Transformer encoder.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers` (`int`, *optional*, defaults to 6) â€” Transformerç¼–ç å™¨ä¸­éšè—å±‚çš„æ•°é‡ã€‚'
- en: '`num_decoder_layers` (`int`, *optional*) â€” Number of hidden layers in the Transformer
    decoder. Will use the same value as `num_layers` if not set.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_decoder_layers` (`int`, *optional*) â€” Transformerè§£ç å™¨ä¸­éšè—å±‚çš„æ•°é‡ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†ä½¿ç”¨ä¸`num_layers`ç›¸åŒçš„å€¼ã€‚'
- en: '`num_heads` (`int`, *optional*, defaults to 8) â€” Number of attention heads
    for each attention layer in the Transformer encoder.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`int`, *optional*, defaults to 8) â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`relative_attention_num_buckets` (`int`, *optional*, defaults to 32) â€” The
    number of buckets to use for each attention layer.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relative_attention_num_buckets` (`int`, *optional*, defaults to 32) â€” æ¯ä¸ªæ³¨æ„åŠ›å±‚ä½¿ç”¨çš„æ¡¶æ•°é‡ã€‚'
- en: '`relative_attention_max_distance` (`int`, *optional*, defaults to 128) â€” The
    maximum distance of the longer sequences for the bucket separation.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relative_attention_max_distance` (`int`, *optional*, defaults to 128) â€” è¾ƒé•¿åºåˆ—çš„æœ€å¤§è·ç¦»ï¼Œç”¨äºæ¡¶åˆ†ç¦»ã€‚'
- en: '`dropout_rate` (`float`, *optional*, defaults to 0.1) â€” The ratio for all dropout
    layers.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout_rate` (`float`, *optional*, defaults to 0.1) â€” æ‰€æœ‰dropoutå±‚çš„æ¯”ç‡ã€‚'
- en: '`classifier_dropout` (`float`, *optional*, defaults to 0.0) â€” The dropout ratio
    for classifier.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classifier_dropout` (`float`, *optional*, defaults to 0.0) â€” åˆ†ç±»å™¨çš„dropoutæ¯”ç‡ã€‚'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-6) â€” The epsilon used
    by the layer normalization layers.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-6) â€” å±‚å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„epsilonã€‚'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1) â€” A factor for initializing
    all weight matrices (should be kept to 1, used internally for initialization testing).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor` (`float`, *optional*, defaults to 1) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„å› å­ï¼ˆåº”ä¿æŒä¸º1ï¼Œç”¨äºå†…éƒ¨åˆå§‹åŒ–æµ‹è¯•ï¼‰ã€‚'
- en: '`feed_forward_proj` (`string`, *optional*, defaults to `"relu"`) â€” Type of
    feed forward layer to be used. Should be one of `"relu"` or `"gated-gelu"`. T5v1.1
    uses the `"gated-gelu"` feed forward projection. Original T5 uses `"relu"`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feed_forward_proj` (`string`, *optional*, defaults to `"relu"`) â€” è¦ä½¿ç”¨çš„å‰é¦ˆå±‚ç±»å‹ã€‚åº”ä¸º`"relu"`æˆ–`"gated-gelu"`ä¹‹ä¸€ã€‚T5v1.1ä½¿ç”¨`"gated-gelu"`å‰é¦ˆæŠ•å½±ã€‚åŸå§‹T5ä½¿ç”¨`"relu"`ã€‚'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æœ€åçš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ï¼‰ã€‚'
- en: This is the configuration class to store the configuration of a [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    or a [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model).
    It is used to instantiate a T5 model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the T5 [t5-small](https://huggingface.co/t5-small)
    architecture.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”¨äºå­˜å‚¨[T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)æˆ–[TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)é…ç½®çš„é…ç½®ç±»ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–T5æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºT5
    [t5-small](https://huggingface.co/t5-small)æ¶æ„çš„é…ç½®ã€‚
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: T5Tokenizer
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5Tokenizer
- en: '### `class transformers.T5Tokenizer`'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5Tokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L63)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L63)'
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_file` (`str`) â€” [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a *.spm* extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file`ï¼ˆ`str`ï¼‰â€”åŒ…å«å®ä¾‹åŒ–åˆ†è¯å™¨æ‰€éœ€è¯æ±‡è¡¨çš„[SentencePiece](https://github.com/google/sentencepiece)æ–‡ä»¶ï¼ˆé€šå¸¸å…·æœ‰*.spm*æ‰©å±•åï¼‰ã€‚'
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) â€” The end of sequence
    token.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"</s>"`ï¼‰â€”åºåˆ—ç»“æŸæ ‡è®°ã€‚'
- en: When building a sequence using special tokens, this is not the token that is
    used for the end of sequence. The token used is the `sep_token`.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ„å»ºåºåˆ—æ—¶ä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼Œè¿™ä¸æ˜¯ç”¨äºåºåˆ—ç»“æŸçš„æ ‡è®°ã€‚ä½¿ç”¨çš„æ ‡è®°æ˜¯`sep_token`ã€‚
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) â€” The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"<unk>"`ï¼‰â€”æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­ä¸å­˜åœ¨çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸ºIDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) â€” The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"<pad>"`ï¼‰â€”ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚'
- en: '`extra_ids` (`int`, *optional*, defaults to 100) â€” Add a number of extra ids
    added to the vocabulary for use as sentinels. These tokens are accessible as â€œ<extra>id{%d}>â€
    where â€{%d}â€ is a number between 0 and extra_ids-1\. These tokens can be retrieved
    by calling get_sentinel_tokens method and token ids can be by calling get_sentinel_token_ids
    method additional_special_tokens (`List[str]`, *optional*): Additional special
    tokens used by the tokenizer.</extra>'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extra_ids`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º100ï¼‰â€”æ·»åŠ åˆ°è¯æ±‡è¡¨ä¸­ç”¨ä½œå“¨å…µçš„é¢å¤–IDæ•°é‡ã€‚è¿™äº›æ ‡è®°å¯é€šè¿‡è°ƒç”¨get_sentinel_tokensæ–¹æ³•è®¿é—®ä¸ºâ€œ<extra>id{%d}>â€ï¼Œå…¶ä¸­â€{%d}â€æ˜¯0åˆ°extra_ids-1ä¹‹é—´çš„æ•°å­—ã€‚è¿™äº›æ ‡è®°å¯ä»¥é€šè¿‡è°ƒç”¨get_sentinel_token_idsæ–¹æ³•æ£€ç´¢ï¼Œé¢å¤–çš„ç‰¹æ®Šæ ‡è®°ï¼ˆ`List[str]`ï¼Œ*å¯é€‰*ï¼‰ï¼šåˆ†è¯å™¨ä½¿ç”¨çš„å…¶ä»–ç‰¹æ®Šæ ‡è®°ã€‚</extra>'
- en: '`sp_model_kwargs` (`dict`, *optional*) â€” Will be passed to the `SentencePieceProcessor.__init__()`
    method. The [Python wrapper for SentencePiece](https://github.com/google/sentencepiece/tree/master/python)
    can be used, among other things, to set:'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model_kwargs`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€”å°†ä¼ é€’ç»™`SentencePieceProcessor.__init__()`æ–¹æ³•ã€‚[SentencePieceçš„PythonåŒ…è£…å™¨](https://github.com/google/sentencepiece/tree/master/python)å¯ç”¨äºè®¾ç½®ï¼š'
- en: '`enable_sampling`: Enable subword regularization.'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enable_sampling`ï¼šå¯ç”¨å­è¯æ­£åˆ™åŒ–ã€‚'
- en: '`nbest_size`: Sampling parameters for unigram. Invalid for BPE-Dropout.'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size`ï¼šunigramçš„é‡‡æ ·å‚æ•°ã€‚å¯¹äºBPE-Dropoutæ— æ•ˆã€‚'
- en: '`nbest_size = {0,1}`: No sampling is performed.'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size = {0,1}`ï¼šä¸æ‰§è¡Œé‡‡æ ·ã€‚'
- en: '`nbest_size > 1`: samples from the nbest_size results.'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size > 1`ï¼šä»nbest_sizeç»“æœä¸­é‡‡æ ·ã€‚'
- en: '`nbest_size < 0`: assuming that nbest_size is infinite and samples from the
    all hypothesis (lattice) using forward-filtering-and-backward-sampling algorithm.'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size < 0`ï¼šå‡è®¾nbest_sizeæ˜¯æ— é™çš„ï¼Œå¹¶ä½¿ç”¨å‰å‘è¿‡æ»¤å’Œåå‘é‡‡æ ·ç®—æ³•ä»æ‰€æœ‰å‡è®¾ï¼ˆæ ¼ï¼‰ä¸­é‡‡æ ·ã€‚'
- en: '`alpha`: Smoothing parameter for unigram sampling, and dropout probability
    of merge operations for BPE-dropout.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`ï¼šunigramé‡‡æ ·çš„å¹³æ»‘å‚æ•°ï¼Œä»¥åŠBPE-dropoutçš„åˆå¹¶æ“ä½œçš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`legacy` (`bool`, *optional*) â€” Whether or not the `legacy` behaviour of the
    tokenizer should be used. Legacy is before the merge of #24622 and #25224 which
    includes fixes to properly handle tokens that appear after special tokens. A simple
    example:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`legacy`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€”æ˜¯å¦åº”ä½¿ç”¨åˆ†è¯å™¨çš„`legacy`è¡Œä¸ºã€‚Legacyæ˜¯åœ¨#24622å’Œ#25224åˆå¹¶ä¹‹å‰ï¼ŒåŒ…æ‹¬ä¿®å¤æ­£ç¡®å¤„ç†å‡ºç°åœ¨ç‰¹æ®Šæ ‡è®°ä¹‹åçš„æ ‡è®°çš„å†…å®¹ã€‚ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š'
- en: '`legacy=True`:'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`legacy=True`ï¼š'
- en: Construct a T5 tokenizer. Based on [SentencePiece](https://github.com/google/sentencepiece).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªT5åˆ†è¯å™¨ã€‚åŸºäº[SentencePiece](https://github.com/google/sentencepiece)ã€‚
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤åˆ†è¯å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)ï¼Œå…¶ä¸­åŒ…å«å¤§å¤šæ•°ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒæ­¤è¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L333)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L333)'
- en: '[PRE8]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs to which the special tokens will
    be added.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`ï¼ˆ`List[int]`ï¼‰â€”è¦æ·»åŠ ç‰¹æ®Šæ ‡è®°çš„IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`ï¼ˆ`List[int]`ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨äºåºåˆ—å¯¹çš„å¯é€‰ç¬¬äºŒä¸ªIDåˆ—è¡¨ã€‚'
- en: Returns
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰é€‚å½“ç‰¹æ®Šæ ‡è®°çš„[input IDs](../glossary#input-ids)åˆ—è¡¨ã€‚
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A sequence has the following
    format:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿æ¥å’Œæ·»åŠ ç‰¹æ®Šæ ‡è®°ä»åºåˆ—æˆ–åºåˆ—å¯¹æ„å»ºç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹è¾“å…¥ã€‚åºåˆ—çš„æ ¼å¼å¦‚ä¸‹ï¼š
- en: 'single sequence: `X </s>`'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä¸ªåºåˆ—ï¼š`X </s>`
- en: 'pair of sequences: `A </s> B </s>`'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åºåˆ—å¯¹ï¼š`A </s> B </s>`
- en: '#### `get_special_tokens_mask`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L264)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L264)'
- en: '[PRE9]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`ï¼ˆ`List[int]`ï¼‰â€” IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`ï¼ˆ`List[int]`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ï¼Œç”¨äºåºåˆ—å¯¹ã€‚'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) â€” Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ ‡è®°åˆ—è¡¨æ˜¯å¦å·²ç»æ ¼å¼åŒ–ä¸ºæ¨¡å‹çš„ç‰¹æ®Šæ ‡è®°ã€‚'
- en: Returns
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼ŒèŒƒå›´ä¸º[0, 1]ï¼š1è¡¨ç¤ºç‰¹æ®Šæ ‡è®°ï¼Œ0è¡¨ç¤ºåºåˆ—æ ‡è®°ã€‚
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ²¡æœ‰æ·»åŠ ç‰¹æ®Šæ ‡è®°çš„æ ‡è®°åˆ—è¡¨ä¸­æ£€ç´¢åºåˆ—IDã€‚å½“ä½¿ç”¨åˆ†è¯å™¨çš„`prepare_for_model`æ–¹æ³•æ·»åŠ ç‰¹æ®Šæ ‡è®°æ—¶ï¼Œå°†è°ƒç”¨æ­¤æ–¹æ³•ã€‚
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L311)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L311)'
- en: '[PRE10]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`ï¼ˆ`List[int]`ï¼‰â€” IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`ï¼ˆ`List[int]`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ï¼Œç”¨äºåºåˆ—å¯¹ã€‚'
- en: Returns
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of zeros.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶åˆ—è¡¨ã€‚
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. T5 does not make use of token type ids, therefore a list of zeros is returned.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¼ é€’çš„ä¸¤ä¸ªåºåˆ—åˆ›å»ºä¸€ä¸ªç”¨äºåºåˆ—å¯¹åˆ†ç±»ä»»åŠ¡çš„æ©ç ã€‚T5ä¸ä½¿ç”¨æ ‡è®°ç±»å‹IDï¼Œå› æ­¤è¿”å›ä¸€ä¸ªé›¶åˆ—è¡¨ã€‚
- en: '#### `save_vocabulary`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L442)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5.py#L442)'
- en: '[PRE11]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: T5TokenizerFast
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5TokenizerFast
- en: '### `class transformers.T5TokenizerFast`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5TokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5_fast.py#L66)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5_fast.py#L66)'
- en: '[PRE12]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_file` (`str`) â€” [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a *.spm* extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file`ï¼ˆ`str`ï¼‰â€” åŒ…å«å®ä¾‹åŒ–åˆ†è¯å™¨æ‰€éœ€è¯æ±‡çš„[SentencePiece](https://github.com/google/sentencepiece)æ–‡ä»¶ï¼ˆé€šå¸¸å…·æœ‰*.spm*æ‰©å±•åï¼‰ã€‚'
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) â€” The end of sequence
    token.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"</s>"`ï¼‰â€” åºåˆ—ç»“æŸæ ‡è®°ã€‚'
- en: When building a sequence using special tokens, this is not the token that is
    used for the end of sequence. The token used is the `sep_token`.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨æ„å»ºä½¿ç”¨ç‰¹æ®Šæ ‡è®°çš„åºåˆ—æ—¶ï¼Œè¿™ä¸æ˜¯ç”¨äºåºåˆ—ç»“æŸçš„æ ‡è®°ã€‚ä½¿ç”¨çš„æ ‡è®°æ˜¯`sep_token`ã€‚
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) â€” The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"<unk>"`ï¼‰â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­æ²¡æœ‰çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸ºIDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) â€” The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"<pad>"`ï¼‰â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚'
- en: '`extra_ids` (`int`, *optional*, defaults to 100) â€” Add a number of extra ids
    added to the vocabulary for use as sentinels. These tokens are accessible as â€œ<extra>id{%d}>â€
    where â€{%d}â€ is a number between 0 and extra_ids-1\. These tokens can be retrieved
    by calling get_sentinel_tokens method and token ids can be by calling get_sentinel_token_ids
    method</extra>'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extra_ids`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º100ï¼‰â€” æ·»åŠ ä¸€äº›é¢å¤–çš„IDåˆ°è¯æ±‡è¡¨ä¸­ï¼Œç”¨ä½œå“¨å…µã€‚è¿™äº›æ ‡è®°å¯ä»¥ä½œä¸ºâ€œ<extra>id{%d}>â€è®¿é—®ï¼Œå…¶ä¸­â€{%d}â€æ˜¯0åˆ°extra_ids-1ä¹‹é—´çš„æ•°å­—ã€‚å¯ä»¥é€šè¿‡è°ƒç”¨get_sentinel_tokensæ–¹æ³•æ£€ç´¢è¿™äº›æ ‡è®°ï¼Œé€šè¿‡è°ƒç”¨get_sentinel_token_idsæ–¹æ³•è·å–æ ‡è®°ID</extra>'
- en: '`additional_special_tokens` (`List[str]`, *optional*) â€” Additional special
    tokens used by the tokenizer.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`additional_special_tokens`ï¼ˆ`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” åˆ†è¯å™¨ä½¿ç”¨çš„é¢å¤–ç‰¹æ®Šæ ‡è®°ã€‚'
- en: Construct a â€œfastâ€ T5 tokenizer (backed by HuggingFaceâ€™s *tokenizers* library).
    Based on [Unigram](https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=unigram#models).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªâ€œå¿«é€Ÿâ€T5åˆ†è¯å™¨ï¼ˆç”±HuggingFaceçš„*tokenizers*åº“æ”¯æŒï¼‰ã€‚åŸºäº[Unigram](https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=unigram#models)ã€‚
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ†è¯å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)ï¼Œå…¶ä¸­åŒ…å«å¤§éƒ¨åˆ†ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒè¿™ä¸ªè¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5_fast.py#L195)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5_fast.py#L195)'
- en: '[PRE13]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs to which the special tokens will
    be added.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`ï¼ˆ`List[int]`ï¼‰â€” å°†æ·»åŠ ç‰¹æ®Šæ ‡è®°çš„IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`ï¼ˆ`List[int]`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ï¼Œç”¨äºåºåˆ—å¯¹ã€‚'
- en: Returns
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰é€‚å½“ç‰¹æ®Šæ ‡è®°çš„[input IDs](../glossary#input-ids)åˆ—è¡¨ã€‚
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A sequence has the following
    format:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿æ¥å’Œæ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œä»åºåˆ—æˆ–åºåˆ—å¯¹æ„å»ºç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹è¾“å…¥ã€‚åºåˆ—çš„æ ¼å¼å¦‚ä¸‹ï¼š
- en: 'single sequence: `X </s>`'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä¸ªåºåˆ—ï¼š`X </s>`
- en: 'pair of sequences: `A </s> B </s>`'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åºåˆ—å¯¹ï¼š`A </s> B </s>`
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5_fast.py#L221)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/tokenization_t5_fast.py#L221)'
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`ï¼ˆ`List[int]`ï¼‰- IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`ï¼ˆ`List[int]`ï¼Œ*å¯é€‰*ï¼‰- åºåˆ—å¯¹çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ã€‚'
- en: Returns
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of zeros.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶çš„åˆ—è¡¨ã€‚
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. T5 does not make use of token type ids, therefore a list of zeros is returned.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¼ é€’çš„ä¸¤ä¸ªåºåˆ—åˆ›å»ºä¸€ä¸ªç”¨äºåºåˆ—å¯¹åˆ†ç±»ä»»åŠ¡çš„æ©ç ã€‚T5ä¸ä½¿ç”¨token type idsï¼Œå› æ­¤è¿”å›ä¸€ä¸ªé›¶çš„åˆ—è¡¨ã€‚
- en: PytorchHide Pytorch content
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorchå†…å®¹
- en: T5Model
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5Model
- en: '### `class transformers.T5Model`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1340)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1340)'
- en: '[PRE15]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)ï¼‰-
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare T5 Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„T5æ¨¡å‹è½¬æ¢å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ¨¡å‹æ˜¯ç”±Colin Raffelã€Noam Shazeerã€Adam Robertsã€Katherine Leeã€Sharan Narangã€Michael
    Matenaã€Yanqi Zhouã€Wei Liã€Peter J. Liuåœ¨[æ¢ç´¢ç»Ÿä¸€æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢å™¨çš„è¿ç§»å­¦ä¹ æé™](https://arxiv.org/abs/1910.10683)ä¸­æå‡ºçš„ã€‚å®ƒæ˜¯ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°æ–‡æœ¬å»å™ªç”Ÿæˆè®¾ç½®ä¸­é¢„è®­ç»ƒçš„ç¼–ç å™¨è§£ç å™¨è½¬æ¢å™¨ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚
- en: '#### `forward`'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1433)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1433)'
- en: '[PRE16]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary. T5 is a model with relative
    position embeddings so you should be able to pad the inputs on both the right
    and the left.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰- è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚T5æ˜¯ä¸€ä¸ªå…·æœ‰ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ¨¡å‹ï¼Œå› æ­¤æ‚¨åº”è¯¥èƒ½å¤Ÿåœ¨å³ä¾§å’Œå·¦ä¾§éƒ½å¡«å……è¾“å…¥ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æŸ¥çœ‹[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)è·å–è¯¦ç»†ä¿¡æ¯ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯input IDsï¼Ÿ](../glossary#input-ids)'
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: äº†è§£å¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`input_ids`ï¼Œè¯·æŸ¥çœ‹[T5 Training](./t5#training)ã€‚
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    é¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é€‰æ‹©çš„æ©ç å€¼åœ¨`[0, 1]`ä¸­ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæœªè¢«`masked`çš„æ ‡è®°ä¸º1ã€‚
- en: 0 for tokens that are `masked`.
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¢«`masked`çš„æ ‡è®°ä¸º0ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰-
    è¯æ±‡è¡¨ä¸­è§£ç å™¨è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è§£ç å™¨è¾“å…¥IDï¼Ÿ](../glossary#decoder-input-ids)'
- en: T5 uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: T5ä½¿ç”¨`pad_token_id`ä½œä¸º`decoder_input_ids`ç”Ÿæˆçš„èµ·å§‹æ ‡è®°ã€‚å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œå¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åä¸€ä¸ª`decoder_input_ids`ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¦äº†è§£æ›´å¤šå…³äºå¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`decoder_input_ids`çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[T5 Training](./t5#training)ã€‚
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” é»˜è®¤è¡Œä¸ºï¼šç”Ÿæˆä¸€ä¸ªå¼ é‡ï¼Œå¿½ç•¥`decoder_input_ids`ä¸­çš„å¡«å……æ ‡è®°ã€‚å› æœæ©ç ä¹Ÿå°†é»˜è®¤ä½¿ç”¨ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç¼–ç å™¨ä¸­è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©æ€§å±è”½å¤´éƒ¨çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” è§£ç å™¨ä¸­è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©æ€§å±è”½å¤´éƒ¨çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the cross-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” è§£ç å™¨ä¸­äº¤å‰æ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©æ€§å±è”½å¤´éƒ¨çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” å…ƒç»„åŒ…æ‹¬ï¼ˆ`last_hidden_state`ï¼Œå¯é€‰ï¼š*hidden_states*ï¼Œå¯é€‰ï¼š*attentions*ï¼‰`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size,
    sequence_length, hidden_size)`ï¼Œæ˜¯ç¼–ç å™¨æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” åŒ…å«æ³¨æ„åŠ›å—çš„é¢„è®¡ç®—é”®å’Œå€¼éšè—çŠ¶æ€ã€‚å¯ç”¨äºåŠ é€Ÿè§£ç ã€‚'
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åä¸€ä¸ª`decoder_input_ids`ï¼ˆé‚£äº›æ²¡æœ‰å°†å…¶è¿‡å»çš„é”®å€¼çŠ¶æ€æä¾›ç»™è¯¥æ¨¡å‹çš„ï¼‰çš„å½¢çŠ¶ä¸º`(batch_size,
    1)`ï¼Œè€Œä¸æ˜¯å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„æ‰€æœ‰`decoder_input_ids`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†å¾ˆæœ‰ç”¨ã€‚'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`decoder_input_ids`ã€‚å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œå¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åä¸€ä¸ª`decoder_inputs_embeds`ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`decoder_input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†å¾ˆæœ‰ç”¨ã€‚'
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœ`decoder_input_ids`å’Œ`decoder_inputs_embeds`éƒ½æœªè®¾ç½®ï¼Œåˆ™`decoder_inputs_embeds`å–`inputs_embeds`çš„å€¼ã€‚
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œå°†è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¹¶å¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¯å±‚ç¼–ç å™¨çš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åä½¿ç”¨ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    forward method, overrides the `__call__` special method.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '[T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œå‰å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE17]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: T5ForConditionalGeneration
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5ForConditionalGeneration
- en: '### `class transformers.T5ForConditionalGeneration`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5ForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1548)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1548)'
- en: '[PRE18]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)ï¼‰â€”
    åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: T5 Model with a `language modeling` head on top.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰`è¯­è¨€å»ºæ¨¡`å¤´éƒ¨çš„T5æ¨¡å‹ã€‚
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ¨¡å‹æ˜¯ç”±Colin Raffelï¼ŒNoam Shazeerï¼ŒAdam Robertsï¼ŒKatherine Leeï¼ŒSharan Narangï¼ŒMichael
    Matenaï¼ŒYanqi Zhouï¼ŒWei Liï¼ŒPeter J. Liuåœ¨[æ¢ç´¢ç»Ÿä¸€æ–‡æœ¬åˆ°æ–‡æœ¬å˜æ¢å™¨çš„è¿ç§»å­¦ä¹ æé™](https://arxiv.org/abs/1910.10683)ä¸­æå‡ºçš„ã€‚å®ƒæ˜¯ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°æ–‡æœ¬å»å™ªç”Ÿæˆè®¾ç½®ä¸­é¢„è®­ç»ƒçš„ç¼–ç å™¨è§£ç å™¨å˜æ¢å™¨ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼Œè°ƒæ•´è¾“å…¥åµŒå…¥å¤§å°ï¼Œä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1642)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1642)'
- en: '[PRE19]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary. T5 is a model with relative
    position embeddings so you should be able to pad the inputs on both the right
    and the left.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼‰â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚T5æ˜¯ä¸€ä¸ªå…·æœ‰ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ¨¡å‹ï¼Œå› æ­¤æ‚¨åº”è¯¥èƒ½å¤Ÿåœ¨å³ä¾§å’Œå·¦ä¾§éƒ½å¡«å……è¾“å…¥ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æŸ¥çœ‹[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ä»¥è·å–è¯¦ç»†ä¿¡æ¯ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)'
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: äº†è§£å¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`input_ids`ï¼Œè¯·æŸ¥çœ‹[T5è®­ç»ƒ](./t5#training)ã€‚
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*ï¼‰â€”
    é¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæœªè¢«`masked`çš„æ ‡è®°ä¸º1ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¢«`masked`çš„æ ‡è®°ä¸º0ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`ï¼Œ*å¯é€‰*ï¼‰â€”
    è¯æ±‡è¡¨ä¸­è§£ç å™¨è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è§£ç å™¨è¾“å…¥IDï¼Ÿ](../glossary#decoder-input-ids)'
- en: T5 uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: T5ä½¿ç”¨`pad_token_id`ä½œä¸º`decoder_input_ids`ç”Ÿæˆçš„èµ·å§‹æ ‡è®°ã€‚å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œåˆ™å¯èƒ½åªéœ€è¾“å…¥æœ€åçš„`decoder_input_ids`ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³å¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`decoder_input_ids`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[T5 Training](./t5#training)ã€‚
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`çš„`torch.BoolTensor`ï¼Œ*å¯é€‰*ï¼‰-
    é»˜è®¤è¡Œä¸ºï¼šç”Ÿæˆä¸€ä¸ªå¼ é‡ï¼Œå¿½ç•¥`decoder_input_ids`ä¸­çš„å¡«å……æ ‡è®°ã€‚å› æœæ©ç ä¹Ÿå°†é»˜è®¤ä½¿ç”¨ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºå°†ç¼–ç å™¨ä¸­è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºå°†è§£ç å™¨ä¸­è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the cross-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºå°†è§£ç å™¨ä¸­äº¤å‰æ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`ï¼ˆå…ƒç»„ï¼ˆå…ƒç»„ï¼ˆ`torch.FloatTensor`ï¼‰ï¼Œ*å¯é€‰*ï¼‰- å…ƒç»„ç”±ï¼ˆ`last_hidden_state`ï¼Œ*å¯é€‰*ï¼š*hidden_states*ï¼Œ*å¯é€‰*ï¼š*attentions*ï¼‰ç»„æˆï¼Œ`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size,
    sequence_length, hidden_size)`ï¼Œæ˜¯ç¼–ç å™¨æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`ï¼ˆé•¿åº¦ä¸º`config.n_layers`çš„å…ƒç»„ï¼ˆå…ƒç»„ï¼ˆ`torch.FloatTensor`ï¼‰ï¼‰ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å«4ä¸ªå½¢çŠ¶ä¸º`(batch_size,
    num_heads, sequence_length - 1, embed_size_per_head)`çš„å¼ é‡ï¼‰- åŒ…å«æ³¨æ„åŠ›å—çš„é¢„è®¡ç®—é”®å’Œå€¼éšè—çŠ¶æ€ã€‚å¯ç”¨äºåŠ é€Ÿè§£ç ã€‚'
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åçš„`decoder_input_ids`ï¼ˆè¿™äº›æœªå°†å…¶è¿‡å»é”®å€¼çŠ¶æ€æä¾›ç»™æ­¤æ¨¡å‹çš„IDï¼‰çš„å½¢çŠ¶ä¸º`(batch_size,
    1)`çš„å¼ é‡ï¼Œè€Œä¸æ˜¯æ‰€æœ‰å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`decoder_input_ids`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼‰-
    å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨å¸Œæœ›æ›´å¤šåœ°æ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, target_sequence_length,
    hidden_size)`ï¼Œ*å¯é€‰*ï¼‰- å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`decoder_input_ids`ã€‚å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œåˆ™å¯èƒ½åªéœ€è¾“å…¥æœ€åçš„`decoder_inputs_embeds`ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚å¦‚æœæ‚¨å¸Œæœ›æ›´å¤šåœ°æ§åˆ¶å¦‚ä½•å°†`decoder_input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚'
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœ`decoder_input_ids`å’Œ`decoder_inputs_embeds`éƒ½æœªè®¾ç½®ï¼Œåˆ™`decoder_inputs_embeds`å–`inputs_embeds`çš„å€¼ã€‚
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- å¦‚æœè®¾ç½®ä¸º`True`ï¼Œå°†è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¹¶å¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[-100, 0, ..., config.vocab_size - 1]`. All labels set to `-100` are ignored
    (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size,)`ï¼Œ*å¯é€‰*) â€” ç”¨äºè®¡ç®—åºåˆ—åˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[-100,
    0, ..., config.vocab_size - 1]`ä¸­ã€‚æ‰€æœ‰æ ‡ç­¾è®¾ç½®ä¸º`-100`éƒ½å°†è¢«å¿½ç•¥ï¼ˆæ©ç›–ï¼‰ï¼ŒæŸå¤±ä»…è®¡ç®—æ ‡ç­¾åœ¨`[0, ..., config.vocab_size]`ä¸­çš„æƒ…å†µã€‚'
- en: Returns
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…æ‹¬å„ç§å…ƒç´ ï¼Œå…·ä½“å–å†³äºé…ç½®ï¼ˆ[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)ï¼‰å’Œè¾“å…¥ã€‚'
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Language modeling loss.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰ â€” è¯­è¨€å»ºæ¨¡æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” è¯­è¨€å»ºæ¨¡å¤´çš„é¢„æµ‹åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰æ¯ä¸ªè¯æ±‡æ ‡è®°çš„åˆ†æ•°ï¼‰ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›ï¼‰
    â€” é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`çš„å¼ é‡å’Œ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆè§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥è¾“å‡ºçš„è¾“å‡º+æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¯å±‚è§£ç å™¨çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›SoftMaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›SoftMaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`ï¼Œ*å¯é€‰*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡ºï¼Œå¦‚æœæ¨¡å‹æœ‰ä¸€ä¸ªåµŒå…¥å±‚ï¼Œ+
    ä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)çš„å‰å‘æ–¹æ³•è¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE20]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: T5EncoderModel
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5EncoderModel
- en: '### `class transformers.T5EncoderModel`'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5EncoderModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1869)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1869)'
- en: '[PRE21]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)ï¼‰â€”
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare T5 Model transformer outputting encoderâ€™s raw hidden-states without
    any specific head on top.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„T5æ¨¡å‹å˜æ¢å™¨è¾“å‡ºç¼–ç å™¨çš„åŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨åœ¨é¡¶éƒ¨ã€‚
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ¨¡å‹ç”±Colin Raffelã€Noam Shazeerã€Adam Robertsã€Katherine Leeã€Sharan Narangã€Michael
    Matenaã€Yanqi Zhouã€Wei Liã€Peter J. Liuåœ¨[æ¢ç´¢ç»Ÿä¸€æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢çš„è¿ç§»å­¦ä¹ æé™](https://arxiv.org/abs/1910.10683)ä¸­æå‡ºã€‚å®ƒæ˜¯ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°æ–‡æœ¬å»å™ªç”Ÿæˆè®¾ç½®ä¸­é¢„è®­ç»ƒçš„ç¼–ç å™¨è§£ç å™¨å˜æ¢å™¨ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥äº†è§£æ‰€æœ‰ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1945)'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1945)'
- en: '[PRE22]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary. T5 is a model with relative
    position embeddings so you should be able to pad the inputs on both the right
    and the left.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰â€” è¾“å…¥åºåˆ—æ ‡è®°åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ã€‚T5æ˜¯ä¸€ä¸ªå…·æœ‰ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ¨¡å‹ï¼Œå› æ­¤æ‚¨åº”è¯¥èƒ½å¤Ÿåœ¨å³ä¾§å’Œå·¦ä¾§éƒ½å¡«å……è¾“å…¥ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚è§[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¦äº†è§£æœ‰å…³å¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`input_ids`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[T5 Training](./t5#training)ã€‚
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” é¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæœªè¢«`masked`çš„æ ‡è®°ä¸º1ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¢«`masked`çš„æ ‡è®°ä¸º0ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-365
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæœªè¢«`masked`çš„å¤´éƒ¨ä¸º1ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-366
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¢«`masked`çš„å¤´éƒ¨ä¸º0ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)ï¼‰å’Œè¾“å…¥ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è‡ªæ³¨æ„åŠ›å¤´ä¸­ä½¿ç”¨æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—åŠ æƒå¹³å‡å€¼ã€‚
- en: The [T5EncoderModel](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5EncoderModel)
    forward method, overrides the `__call__` special method.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '[T5EncoderModel](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5EncoderModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤ä¹‹åè°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE23]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: T5ForSequenceClassification
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T5ForSequenceClassification
- en: '### `class transformers.T5ForSequenceClassification`'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.T5ForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1988)'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L1988)'
- en: '[PRE24]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)ï¼‰-
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: T5 model with a sequence classification/head on top (a linear layer on top of
    the pooled output) e.g. for GLUE tasks.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ¨¡å‹åœ¨é¡¶éƒ¨å¸¦æœ‰åºåˆ—åˆ†ç±»/å¤´ï¼ˆæ±‡èšè¾“å‡ºçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºGLUEä»»åŠ¡ã€‚
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: T5æ¨¡å‹ç”±Colin Raffelã€Noam Shazeerã€Adam Robertsã€Katherine Leeã€Sharan Narangã€Michael
    Matenaã€Yanqi Zhouã€Wei Liã€Peter J. Liuåœ¨[æ¢ç´¢ç»Ÿä¸€æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢çš„è¿ç§»å­¦ä¹ æé™](https://arxiv.org/abs/1910.10683)ä¸­æå‡ºã€‚å®ƒæ˜¯ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°æ–‡æœ¬å»å™ªç”Ÿæˆè®¾ç½®ä¸­é¢„è®­ç»ƒçš„ç¼–ç å™¨è§£ç å™¨å˜å‹å™¨ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹è¿˜æ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥äº†è§£ä¸ä¸€èˆ¬ä½¿ç”¨å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L2009)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L2009)'
- en: '[PRE25]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary. T5 is a model with relative
    position embeddings so you should be able to pad the inputs on both the right
    and the left.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰- è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚T5æ˜¯ä¸€ä¸ªå¸¦æœ‰ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ¨¡å‹ï¼Œå› æ­¤æ‚¨åº”è¯¥èƒ½å¤Ÿåœ¨å³ä¾§å’Œå·¦ä¾§éƒ½å¡«å……è¾“å…¥ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç´¢å¼•å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å¾—ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)'
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¦äº†è§£æœ‰å…³å¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`input_ids`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[T5è®­ç»ƒ](./t5#training)ã€‚
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¸­ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 ç”¨äºæœªè¢«â€œæ©ç â€æ‰çš„æ ‡è®°ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 ç”¨äºè¢«â€œæ©ç â€æ‰çš„æ ‡è®°ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰-
    è¯æ±‡è¡¨ä¸­è§£ç å™¨è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç´¢å¼•å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å¾—ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è§£ç å™¨è¾“å…¥IDï¼Ÿ](../glossary#decoder-input-ids)'
- en: T5 uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: T5ä½¿ç”¨`pad_token_id`ä½œä¸º`decoder_input_ids`ç”Ÿæˆçš„èµ·å§‹æ ‡è®°ã€‚å¦‚æœä½¿ç”¨`past_key_values`ï¼Œåˆ™å¯é€‰æ‹©ä»…è¾“å…¥æœ€åçš„`decoder_input_ids`ï¼ˆè¯·å‚é˜…`past_key_values`ï¼‰ã€‚
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¦äº†è§£æœ‰å…³å¦‚ä½•ä¸ºé¢„è®­ç»ƒå‡†å¤‡`decoder_input_ids`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[T5è®­ç»ƒ](./t5#training)ã€‚
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`çš„`torch.BoolTensor`ï¼Œ*å¯é€‰*ï¼‰-
    é»˜è®¤è¡Œä¸ºï¼šç”Ÿæˆä¸€ä¸ªå¿½ç•¥`decoder_input_ids`ä¸­å¡«å……æ ‡è®°çš„å¼ é‡ã€‚å› æœæ©ç ä¹Ÿå°†é»˜è®¤ä½¿ç”¨ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the cross-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. If `config.num_labels > 1` a classification
    loss is computed (Cross-Entropy).'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `label`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) â€”
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: T5ForQuestionAnswering
  id: totrans-451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.T5ForQuestionAnswering`'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L2121)'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: T5 Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_t5.py#L2177)'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary. T5 is a model with relative
    position embeddings so you should be able to pad the inputs on both the right
    and the left.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-471
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: T5 uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-481
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-483
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-484
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the cross-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-486
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-487
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    â€” Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (*sequence_length*). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€”
    Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (*sequence_length*). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Total span extraction loss is the sum of a Cross-Entropy for the
    start and end positions.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Span-start scores (before SoftMax).'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Span-end scores (before SoftMax).'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlowHide TensorFlow content
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: TFT5Model
  id: totrans-522
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFT5Model`'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_tf_t5.py#L1177)'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare T5 Model transformer outputting raw hidden-stateswithout any specific
    head on top.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_tf_t5.py#L1209)'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`tf.Tensor` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on the right or the left.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-546
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `inputs` for pretraining take a look at [T5 Training](./t5#training).
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Provide for sequence to sequence training. T5 uses the `pad_token_id`
    as the starting token for `decoder_input_ids` generation. If `past_key_values`
    is used, optionally only the last `decoder_input_ids` have to be input (see `past_key_values`).'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-551
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-552
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-553
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-556
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-557
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-559
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-560
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(tf.FloatTensor)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(tf.Tensor))` of length `config.n_layers` with
    each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_inputs_embeds` (`tf.Tensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” If set to `True`, `past_key_values`
    key value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple. This argument can be used in eager mode, in graph mode
    the value will always be set to True.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    â€” Sequence of hidden-states at the output of the last layer of the decoder of
    the model.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`List[tf.Tensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” List of `tf.Tensor` of length `config.n_layers`,
    with each tensor of shape `(2, batch_size, num_heads, sequence_length, embed_size_per_head)`).'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-580
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-584
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-587
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-589
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    forward method, overrides the `__call__` special method.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: TFT5ForConditionalGeneration
  id: totrans-594
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFT5ForConditionalGeneration`'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_tf_t5.py#L1329)'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-597
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: T5 Model with a `language modeling` head on top.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_tf_t5.py#L1386)'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-614
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`tf.Tensor` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on the right or the left.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-617
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-618
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `inputs` for pretraining take a look at [T5 Training](./t5#training).
  id: totrans-619
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Provide for sequence to sequence training. T5 uses the `pad_token_id`
    as the starting token for `decoder_input_ids` generation. If `past_key_values`
    is used, optionally only the last `decoder_input_ids` have to be input (see `past_key_values`).'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-621
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-623
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-624
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-625
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-628
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-629
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules in
    the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-631
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-632
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(tf.FloatTensor)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(tf.Tensor))` of length `config.n_layers` with
    each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_inputs_embeds` (`tf.Tensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” If set to `True`, `past_key_values`
    key value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple. This argument can be used in eager mode, in graph mode
    the value will always be set to True.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Labels for computing the cross entropy classification loss. Indices should be
    in `[0, ..., config.vocab_size - 1]`.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(n,)`, *optional*, where n is the number of non-masked
    labels, returned when `labels` is provided) â€” Language modeling loss.'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`List[tf.Tensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” List of `tf.Tensor` of length `config.n_layers`,
    with each tensor of shape `(2, batch_size, num_heads, sequence_length, embed_size_per_head)`).'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-651
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-655
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-657
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-662
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-666
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: TFT5EncoderModel
  id: totrans-667
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFT5EncoderModel`'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_tf_t5.py#L1599)'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-670
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare T5 Model transformer outputting encoderâ€™s raw hidden-stateswithout
    any specific head on top.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
- en: The T5 model was proposed in [Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin
    Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
    Yanqi Zhou, Wei Li, Peter J. Liu. Itâ€™s an encoder decoder transformer pre-trained
    in a text-to-text denoising generative setting.
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_tf_t5.py#L1622)'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
- en: '`inputs` (`tf.Tensor` of shape `(batch_size, sequence_length)`) â€” Indices of
    input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on the right or the left.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `inputs` for pre-training take a look at [T5
    Training](./t5#training).
  id: totrans-691
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-693
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-694
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-698
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-699
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    â€” Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-709
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFT5EncoderModel](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5EncoderModel)
    forward method, overrides the `__call__` special method.
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-715
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: JAXHide JAX content
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
- en: FlaxT5Model
  id: totrans-717
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FlaxT5Model`'
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1367)'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-720
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '#### `__call__`'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L986)'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-723
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`jnp.ndarray` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on both the right and the left.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-726
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-727
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-728
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-730
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-731
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-732
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-735
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: T5 uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-736
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-737
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(jnp.ndarray)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-741
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Returns
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” Tuple of `tuple(jnp.ndarray)` of
    length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-747
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-749
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-751
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-753
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-756
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-758
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `FlaxT5PreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-762
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '#### `encode`'
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1072)'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-765
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`jnp.ndarray` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on both the right and the left.'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-768
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-769
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-771
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-772
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-773
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_flax_outputs.FlaxBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_flax_outputs.FlaxBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.t5.configuration_t5.T5Config'>`)
    and inputs.
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-782
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-784
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-786
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '#### `decode`'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1130)'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-789
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`)
    â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-792
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-793
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For training, `decoder_input_ids` should be provided.
  id: totrans-794
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(jnp.ndarray)`) â€” Tuple consists of (`last_hidden_state`,
    *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state` of
    shape `(batch_size, sequence_length, hidden_size)`, *optional*) is a sequence
    of hidden-states at the output of the last layer of the encoder. Used in the cross-attention
    of the decoder.'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-797
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-798
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-799
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to change padding behavior, you should modify to your needs. See
    diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more information
    on the default strategy.
  id: totrans-801
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`Dict[str, np.ndarray]`, *optional*, returned by `init_cache`
    or when passing previous `past_key_values`) â€” Dictionary of pre-computed hidden-states
    (key and values in the attention blocks) that can be used for fast auto-regressive
    decoding. Pre-computed key and value hidden-states are of shape *[batch_size,
    max_length]*.'
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions)
    or `tuple(torch.FloatTensor)`'
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.t5.configuration_t5.T5Config'>`)
    and inputs.
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-810
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” Tuple of `tuple(jnp.ndarray)` of
    length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and optionally if `config.is_encoder_decoder=True`
    2 additional tensors of shape `(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and optionally if `config.is_encoder_decoder=True` in the cross-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-812
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-814
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-816
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    and `config.add_cross_attention=True` is passed or when `config.output_attentions=True`)
    â€” Tuple of `jnp.ndarray` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-818
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-820
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: FlaxT5ForConditionalGeneration
  id: totrans-821
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FlaxT5ForConditionalGeneration`'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1605)'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-824
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '#### `__call__`'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L986)'
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-827
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`jnp.ndarray` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on both the right and the left.'
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-830
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-831
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-832
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-834
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-835
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-836
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-838
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-839
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: T5 uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-840
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `decoder_input_ids` for pretraining take a look
    at [T5 Training](./t5#training).
  id: totrans-841
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(jnp.ndarray)`, *optional*) â€” Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) â€” Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-845
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Returns
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config))
    and inputs.
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” Tuple of `tuple(jnp.ndarray)` of
    length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-851
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-853
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-855
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-857
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-860
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-862
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `FlaxT5PreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-866
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '#### `encode`'
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1072)'
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-869
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Parameters
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`jnp.ndarray` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on both the right and the left.'
  id: totrans-871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-872
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-873
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-875
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-876
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-877
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_flax_outputs.FlaxBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_flax_outputs.FlaxBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.t5.configuration_t5.T5Config'>`)
    and inputs.
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-886
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-888
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-890
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '#### `decode`'
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1608)'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-893
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Parameters
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`)
    â€” Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-896
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-897
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For training, `decoder_input_ids` should be provided.
  id: totrans-898
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(jnp.ndarray)`) â€” Tuple consists of (`last_hidden_state`,
    *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state` of
    shape `(batch_size, sequence_length, hidden_size)`, *optional*) is a sequence
    of hidden-states at the output of the last layer of the encoder. Used in the cross-attention
    of the decoder.'
  id: totrans-899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-901
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-902
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-903
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`jnp.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to change padding behavior, you should modify to your needs. See
    diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more information
    on the default strategy.
  id: totrans-905
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`Dict[str, np.ndarray]`, *optional*, returned by `init_cache`
    or when passing previous `past_key_values`) â€” Dictionary of pre-computed hidden-states
    (key and values in the attention blocks) that can be used for fast auto-regressive
    decoding. Pre-computed key and value hidden-states are of shape *[batch_size,
    max_length]*.'
  id: totrans-906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions)
    or `tuple(torch.FloatTensor)`'
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.t5.configuration_t5.T5Config'>`)
    and inputs.
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-915
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-917
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross attentions weights after the attention softmax, used to compute the weighted
    average in the cross-attention heads.
  id: totrans-919
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” Tuple of `jnp.ndarray` tuples of
    length `config.n_layers`, with each tuple containing the cached key, value states
    of the self-attention and the cross-attention layers if model is used in encoder-decoder
    setting. Only relevant if `config.is_decoder = True`.'
  id: totrans-920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-921
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-923
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: FlaxT5EncoderModel
  id: totrans-924
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FlaxT5EncoderModel`'
  id: totrans-925
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1454)'
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-927
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '#### `__call__`'
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/t5/modeling_flax_t5.py#L1457)'
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-930
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Parameters
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`jnp.ndarray` of shape `(batch_size, sequence_length)`) â€” Indices
    of input sequence tokens in the vocabulary. T5 is a model with relative position
    embeddings so you should be able to pad the inputs on both the right and the left.'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail.
  id: totrans-933
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To know more on how to prepare `input_ids` for pretraining take a look a [T5
    Training](./t5#training).
  id: totrans-934
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`jnp.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-936
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-937
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-938
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [FlaxT5EncoderModel](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5EncoderModel)
    forward method, overrides the `__call__` special method.
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
