# 结论

> 原文链接：[https://huggingface.co/learn/deep-rl-course/unit5/conclusion](https://huggingface.co/learn/deep-rl-course/unit5/conclusion)

恭喜你完成了这个单元！你刚刚训练了你的第一个ML-Agents并分享到了Hub🥳。

学习的最佳方式是**练习和尝试**。为什么不尝试另一个环境呢？[ML-Agents有18个不同的环境](https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md)。

例如：

+   [蠕虫](https://singularite.itch.io/worm)，在这里你教会一只蠕虫爬行。

+   [行走者](https://singularite.itch.io/walker)，在这里你教一个代理向目标行走。

查看文档以了解如何训练它们，并查看Hub上已经集成的MLAgents环境列表：[https://github.com/huggingface/ml-agents#getting-started](https://github.com/huggingface/ml-agents#getting-started)

![示例环境](../Images/77b4170bed8e669351f9f15ec1ef34c1.png)

在下一个单元中，我们将学习关于多代理的知识。你将训练你的第一个多代理来参加足球比赛和雪球大战，与其他同学的代理竞争。

![雪球大战](../Images/72372e440c960be9f642a47a648aae4d.png)

最后，我们很想知道**你对课程的看法以及我们如何改进**。如果你有反馈，请👉[填写此表格](https://forms.gle/BzKXWzLAGZESGNaE9)

### 继续学习，保持优秀🤗
