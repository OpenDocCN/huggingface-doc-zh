["```py\n>>> import torch\n>>> from transformers import XLMTokenizer, XLMWithLMHeadModel\n\n>>> tokenizer = XLMTokenizer.from_pretrained(\"xlm-clm-enfr-1024\")\n>>> model = XLMWithLMHeadModel.from_pretrained(\"xlm-clm-enfr-1024\")\n```", "```py\n>>> print(tokenizer.lang2id)\n{'en': 0, 'fr': 1}\n```", "```py\n>>> input_ids = torch.tensor([tokenizer.encode(\"Wikipedia was used to\")])  # batch size of 1\n```", "```py\n>>> language_id = tokenizer.lang2id[\"en\"]  # 0\n>>> langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])\n\n>>> # We reshape it to be of size (batch_size, sequence_length)\n>>> langs = langs.view(1, -1)  # is now of shape [1, sequence_length] (we have a batch size of 1)\n```", "```py\n>>> outputs = model(input_ids, langs=langs)\n```", "```py\n>>> from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n\n>>> en_text = \"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\"\n>>> chinese_text = \"\u4e0d\u8981\u63d2\u624b\u5deb\u5e2b\u7684\u4e8b\u52d9, \u56e0\u70ba\u4ed6\u5011\u662f\u5fae\u5999\u7684, \u5f88\u5feb\u5c31\u6703\u767c\u6012.\"\n\n>>> tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", src_lang=\"zh\")\n>>> model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n```", "```py\n>>> encoded_zh = tokenizer(chinese_text, return_tensors=\"pt\")\n```", "```py\n>>> generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n'Do not interfere with the matters of the witches, because they are delicate and will soon be angry.'\n```", "```py\n>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n>>> en_text = \"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\"\n>>> fi_text = \"\u00c4l\u00e4 sekaannu velhojen asioihin, sill\u00e4 ne ovat hienovaraisia ja nopeasti vihaisia.\"\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"fi_FI\")\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n```", "```py\n>>> encoded_en = tokenizer(en_text, return_tensors=\"pt\")\n```", "```py\n>>> generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\"Don't interfere with the wizard's affairs, because they are subtle, will soon get angry.\"\n```"]