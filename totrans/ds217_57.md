# æ‰¹å¤„ç†æ˜ å°„

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/datasets/about_map_batch](https://huggingface.co/docs/datasets/about_map_batch)

å°†[Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)çš„å®ç”¨æ€§ä¸æ‰¹å¤„ç†æ¨¡å¼ç»“åˆèµ·æ¥éå¸¸å¼ºå¤§ã€‚å®ƒå…è®¸æ‚¨åŠ å¿«å¤„ç†é€Ÿåº¦ï¼Œå¹¶è‡ªç”±æ§åˆ¶ç”Ÿæˆçš„æ•°æ®é›†çš„å¤§å°ã€‚

## éœ€è¦é€Ÿåº¦

æ‰¹å¤„ç†æ˜ å°„çš„ä¸»è¦ç›®æ ‡æ˜¯åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œä½¿ç”¨æ•°æ®æ‰¹æ¬¡è€Œä¸æ˜¯å•ä¸ªç¤ºä¾‹æ›´å¿«ã€‚è‡ªç„¶åœ°ï¼Œæ‰¹å¤„ç†æ˜ å°„é€‚ç”¨äºæ ‡è®°åŒ–ã€‚ä¾‹å¦‚ï¼ŒğŸ¤— [Tokenizers](https://huggingface.co/docs/tokenizers/python/latest/)åº“åœ¨æ‰¹å¤„ç†ä¸­çš„å·¥ä½œé€Ÿåº¦æ›´å¿«ï¼Œå› ä¸ºå®ƒå¹¶è¡Œå¤„ç†æ‰¹æ¬¡ä¸­æ‰€æœ‰ç¤ºä¾‹çš„æ ‡è®°åŒ–ã€‚

## è¾“å…¥å¤§å° != è¾“å‡ºå¤§å°

æ§åˆ¶ç”Ÿæˆæ•°æ®é›†å¤§å°çš„èƒ½åŠ›å¯ä»¥ç”¨äºè®¸å¤šæœ‰è¶£çš„ç”¨ä¾‹ã€‚åœ¨[map](#map)éƒ¨åˆ†ä¸­ï¼Œæœ‰ä½¿ç”¨æ‰¹å¤„ç†æ˜ å°„çš„ç¤ºä¾‹ï¼š

+   å°†é•¿å¥å­æ‹†åˆ†ä¸ºè¾ƒçŸ­çš„å—ã€‚

+   ç”¨é¢å¤–çš„æ ‡è®°å¢å¼ºæ•°æ®é›†ã€‚

äº†è§£è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„å¾ˆæœ‰å¸®åŠ©ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥æƒ³å‡ºè‡ªå·±ä½¿ç”¨æ‰¹å¤„ç†æ˜ å°„çš„æ–¹æ³•ã€‚æ­¤æ—¶ï¼Œæ‚¨å¯èƒ½æƒ³çŸ¥é“å¦‚ä½•æ§åˆ¶ç”Ÿæˆæ•°æ®é›†çš„å¤§å°ã€‚ç­”æ¡ˆæ˜¯ï¼š**æ˜ å°„å‡½æ•°ä¸å¿…è¿”å›ç›¸åŒå¤§å°çš„è¾“å‡ºæ‰¹æ¬¡**ã€‚

æ¢å¥è¯è¯´ï¼Œæ‚¨çš„æ˜ å°„å‡½æ•°è¾“å…¥å¯ä»¥æ˜¯å¤§å°ä¸º`N`çš„æ‰¹æ¬¡ï¼Œå¹¶è¿”å›å¤§å°ä¸º`M`çš„æ‰¹æ¬¡ã€‚è¾“å‡º`M`å¯ä»¥å¤§äºæˆ–å°äº`N`ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥è¿æ¥ç¤ºä¾‹ï¼Œå°†å…¶åˆ†å‰²ï¼Œå¹¶ç”šè‡³æ·»åŠ æ›´å¤šç¤ºä¾‹ï¼

ä½†æ˜¯ï¼Œè¯·è®°ä½ï¼Œè¾“å‡ºå­—å…¸ä¸­çš„æ‰€æœ‰å€¼å¿…é¡»åŒ…å«ä¸è¾“å‡ºå­—å…¸ä¸­çš„å…¶ä»–å­—æ®µ**ç›¸åŒæ•°é‡çš„å…ƒç´ **ã€‚å¦åˆ™ï¼Œæ— æ³•å®šä¹‰æ˜ å°„å‡½æ•°è¿”å›çš„è¾“å‡ºä¸­çš„ç¤ºä¾‹æ•°é‡ã€‚æ˜ å°„å‡½æ•°å¤„ç†çš„è¿ç»­æ‰¹æ¬¡ä¹‹é—´çš„æ•°é‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ä½†æ˜¯å¯¹äºå•ä¸ªæ‰¹æ¬¡ï¼Œè¾“å‡ºå­—å…¸çš„æ‰€æœ‰å€¼åº”å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼ˆå³å…ƒç´ æ•°é‡ï¼‰ã€‚

ä¾‹å¦‚ï¼Œä»å…·æœ‰1åˆ—å’Œ3è¡Œçš„æ•°æ®é›†ä¸­ï¼Œå¦‚æœæ‚¨ä½¿ç”¨`map`è¿”å›å…·æœ‰ä¸¤å€è¡Œæ•°çš„æ–°åˆ—ï¼Œåˆ™ä¼šå‡ºç°é”™è¯¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å°†å¾—åˆ°ä¸€åˆ—æœ‰3è¡Œï¼Œå¦ä¸€åˆ—æœ‰6è¡Œã€‚å¦‚æ‚¨æ‰€è§ï¼Œè¡¨å°†æ— æ•ˆï¼š

```py
>>> from datasets import Dataset
>>> dataset = Dataset.from_dict({"a": [0, 1, 2]})
>>> dataset.map(lambda batch: {"b": batch["a"] * 2}, batched=True)  # new column with 6 elements: [0, 1, 2, 0, 1, 2]
'ArrowInvalid: Column 1 named b expected length 3 but got length 6'
```

ä¸ºä½¿å…¶æœ‰æ•ˆï¼Œæ‚¨å¿…é¡»åˆ é™¤å…¶ä¸­ä¸€ä¸ªåˆ—ï¼š

```py
>>> from datasets import Dataset
>>> dataset = Dataset.from_dict({"a": [0, 1, 2]})
>>> dataset_with_duplicates = dataset.map(lambda batch: {"b": batch["a"] * 2}, remove_columns=["a"], batched=True)
>>> len(dataset_with_duplicates)
6
```
