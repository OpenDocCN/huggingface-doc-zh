# 加载不同的 Stable Diffusion 格式

> 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/other-formats](https://huggingface.co/docs/diffusers/using-diffusers/other-formats)

稳定的扩散模型以不同的格式提供，具体取决于它们所训练和保存的框架，以及您从哪里下载它们。将这些格式转换为 🤗 Diffusers 以便在库中使用所有支持的功能，例如[使用不同的调度器](schedulers)进行推断，[构建自定义流水线](write_own_pipeline)，以及各种用于[优化推断速度](../optimization/opt_overview)的技术和方法。

我们强烈建议使用 `.safetensors` 格式，因为它比传统的可被利用来在您的机器上执行任何代码的 pickled 文件更安全（在[加载 safetensors](using_safetensors)指南中了解更多）。

本指南将向您展示如何将其他 Stable Diffusion 格式转换为与 🤗 Diffusers 兼容。

## PyTorch .ckpt

检查点 - 或 `.ckpt` - 格式通常用于存储和保存模型。`.ckpt` 文件包含整个模型，通常大小为几个GB。虽然您可以直接使用 [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file) 方法加载和使用 `.ckpt` 文件，但通常最好将 `.ckpt` 文件转换为 🤗 Diffusers，以便两种格式都可用。

有两种选项可以转换 `.ckpt` 文件：使用 Space 转换检查点或使用脚本转换 `.ckpt` 文件。

### 使用 Space 进行转换

转换 `.ckpt` 文件的最简单和最便捷的方法是使用 [SD to Diffusers](https://huggingface.co/spaces/diffusers/sd-to-diffusers) Space。您可以按照 Space 上的说明转换 `.ckpt` 文件。

这种方法适用于基本模型，但可能在更定制的模型上遇到困难。如果返回空的拉取请求或错误，则会知道空间失败。在这种情况下，您可以尝试使用脚本转换 `.ckpt` 文件。

### 使用脚本进行转换

🤗 Diffusers 提供了一个[转换脚本](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py)用于转换 `.ckpt` 文件。这种方法比上面的 Space 更可靠。

在开始之前，请确保您有一个本地克隆的 🤗 Diffusers 以运行脚本，并登录到您的 Hugging Face 帐户，以便您可以打开拉取请求并将转换的模型推送到 Hub。

```py
huggingface-cli login
```

使用脚本：

1.  克隆包含您要转换的 `.ckpt` 文件的存储库。例如，让我们转换这个 [TemporalNet](https://huggingface.co/CiaraRowles/TemporalNet) `.ckpt` 文件：

```py
git lfs install
git clone https://huggingface.co/CiaraRowles/TemporalNet
```

1.  在您从中转换检查点的存储库上打开一个拉取请求：

```py
cd TemporalNet && git fetch origin refs/pr/13:pr/13
git checkout pr/13
```

1.  转换脚本中有几个输入参数需要配置，但最重要的是：

    +   `checkpoint_path`：要转换的 `.ckpt` 文件的路径。

    +   `original_config_file`：定义原始架构配置的 YAML 文件。如果找不到此文件，请尝试在找到 `.ckpt` 文件的 GitHub 存储库中搜索 YAML 文件。

    +   `dump_path`：转换模型的路径。

        例如，您可以从 [ControlNet](https://github.com/lllyasviel/ControlNet/tree/main/models) 存储库中获取 `cldm_v15.yaml` 文件，因为 TemporalNet 模型是 Stable Diffusion v1.5 和 ControlNet 模型。

1.  现在您可以运行脚本来转换 `.ckpt` 文件：

```py
python ../diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path temporalnetv3.ckpt --original_config_file cldm_v15.yaml --dump_path ./ --controlnet
```

1.  转换完成后，上传您转换的模型并测试生成的[拉取请求](https://huggingface.co/CiaraRowles/TemporalNet/discussions/13)!

```py
git push origin pr/13:refs/pr/13
```

## Keras .pb 或 .h5

🧪 这是一个实验性功能。目前 Convert KerasCV Space 仅支持 Stable Diffusion v1 检查点。

[KerasCV](https://keras.io/keras_cv/)支持[稳定扩散](https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/stable_diffusion) v1和v2的训练。然而，它对于实验稳定扩散模型进行推理和部署的支持有限，而🤗 Diffusers具有更完整的功能集，例如不同的[噪声调度器](https://huggingface.co/docs/diffusers/using-diffusers/schedulers)、[闪光注意力](https://huggingface.co/docs/diffusers/optimization/xformers)和[其他优化技术](https://huggingface.co/docs/diffusers/optimization/fp16)。

[Convert KerasCV](https://huggingface.co/spaces/sayakpaul/convert-kerascv-sd-diffusers)空间将`.pb`或`.h5`文件转换为PyTorch，然后将它们包装在[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)中，以便进行推理。转换后的检查点存储在Hugging Face Hub上的存储库中。

在此示例中，让我们转换[`sayakpaul/textual-inversion-kerasio`](https://huggingface.co/sayakpaul/textual-inversion-kerasio/tree/main)检查点，该检查点是使用文本反转训练的。它使用特殊令牌`<my-funny-cat>`来个性化带有猫的图像。

转换KerasCV空间允许您输入以下内容：

+   您的Hugging Face令牌。

+   从中下载UNet和文本编码器权重的路径。根据模型的训练方式，您不一定需要提供UNet和文本编码器的路径。例如，文本反转只需要文本编码器的嵌入，而文本到图像模型只需要UNet权重。

+   占位符令牌仅适用于文本反转模型。

+   `output_repo_prefix`是存储转换模型的存储库的名称。

单击**提交**按钮自动转换KerasCV检查点！一旦检查点成功转换，您将看到一个链接，指向包含转换后检查点的新存储库。跟随链接到新存储库，您将看到Convert KerasCV空间生成了一个模型卡，带有一个推理小部件，以尝试转换后的模型。

如果您更喜欢使用代码进行推理，请单击模型卡的右上角的**在Diffusers中使用**按钮以复制并粘贴代码片段：

```py
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "sayakpaul/textual-inversion-cat-kerascv_sd_diffusers_pipeline", use_safetensors=True
)
```

然后，您可以生成一张图片：

```py
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "sayakpaul/textual-inversion-cat-kerascv_sd_diffusers_pipeline", use_safetensors=True
)
pipeline.to("cuda")

placeholder_token = "<my-funny-cat-token>"
prompt = f"two {placeholder_token} getting married, photorealistic, high quality"
image = pipeline(prompt, num_inference_steps=50).images[0]
```

## A1111 LoRA文件

[Automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui)（A1111）是一个流行的稳定扩散网络界面，支持像[Civitai](https://civitai.com/)这样的模型共享平台。使用低秩适应（LoRA）技术训练的模型特别受欢迎，因为它们训练速度快，文件大小比完全微调的模型小得多。🤗 Diffusers支持使用[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)加载A1111 LoRA检查点：

```py
from diffusers import StableDiffusionXLPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "Lykon/dreamshaper-xl-1-0", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
```

从Civitai下载一个LoRA检查点；此示例使用[Blueprintify SD XL 1.0](https://civitai.com/models/150986/blueprintify-sd-xl-10)检查点，但随时可以尝试任何LoRA检查点！

```py
# uncomment to download the safetensor weights
#!wget https://civitai.com/api/download/models/168776 -O blueprintify.safetensors
```

使用[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)方法将LoRA检查点加载到管道中：

```py
pipeline.load_lora_weights(".", weight_name="blueprintify.safetensors")
```

现在您可以使用管道生成图像：

```py
prompt = "bl3uprint, a highly detailed blueprint of the empire state building, explaining how to build all parts, many txt, blueprint grid backdrop"
negative_prompt = "lowres, cropped, worst quality, low quality, normal quality, artifacts, signature, watermark, username, blurry, more than one bridge, bad architecture"

image = pipeline(
    prompt=prompt,
    negative_prompt=negative_prompt,
    generator=torch.manual_seed(0),
).images[0]
image
```

![](../Images/cee84d318d0e1d6c11ae7b5a6f49a8ca.png)
