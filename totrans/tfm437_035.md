# 零样本图像分类

> 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/tasks/zero_shot_image_classification](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/zero_shot_image_classification)

零样本图像分类是一个任务，涉及使用未明确训练包含来自这些特定类别的标记示例的数据的模型将图像分类为不同的类别。

传统上，图像分类需要在特定一组带标签的图像上训练模型，该模型学习将某些图像特征“映射”到标签。当需要将这样的模型用于引入新标签集的分类任务时，需要进行微调以“重新校准”模型。

相比之下，零样本或开放词汇图像分类模型通常是多模态模型，已经在大量图像和相关描述的数据集上进行了训练。这些模型学习了对齐的视觉-语言表示，可用于许多下游任务，包括零样本图像分类。

这是一种更灵活的图像分类方法，允许模型推广到新的和未见过的类别，而无需额外的训练数据，并且使用户能够使用目标对象的自由形式文本描述查询图像。

在本指南中，您将学习如何：

+   创建一个零样本图像分类管道

+   手动运行零样本图像分类推理

在开始之前，请确保已安装所有必要的库：

```py
pip install -q transformers
```

## 零样本图像分类管道

尝试使用支持零样本图像分类的模型进行推理的最简单方法是使用相应的[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。从[Hugging Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads)实例化一个管道：

```py
>>> from transformers import pipeline

>>> checkpoint = "openai/clip-vit-large-patch14"
>>> detector = pipeline(model=checkpoint, task="zero-shot-image-classification")
```

接下来，选择一个您想要分类的图像。

```py
>>> from PIL import Image
>>> import requests

>>> url = "https://unsplash.com/photos/g8oS8-82DxI/download?ixid=MnwxMjA3fDB8MXx0b3BpY3x8SnBnNktpZGwtSGt8fHx8fDJ8fDE2NzgxMDYwODc&force=true&w=640"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image
```

![猫头鹰的照片](../Images/ceeab937a1338358216d31c99c500d27.png)

将图像和候选对象标签传递给管道。在这里，我们直接传递图像；其他合适的选项包括图像的本地路径或图像url。候选标签可以像这个例子中那样简单，也可以更具描述性。

```py
>>> predictions = detector(image, candidate_labels=["fox", "bear", "seagull", "owl"])
>>> predictions
[{'score': 0.9996670484542847, 'label': 'owl'},
 {'score': 0.000199399160919711, 'label': 'seagull'},
 {'score': 7.392891711788252e-05, 'label': 'fox'},
 {'score': 5.96074532950297e-05, 'label': 'bear'}]
```

## 手动进行零样本图像分类

现在您已经看到如何使用零样本图像分类管道，让我们看看如何手动运行零样本图像分类。

首先从[Hugging Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads)加载模型和相关处理器。在这里，我们将使用与之前相同的检查点：

```py
>>> from transformers import AutoProcessor, AutoModelForZeroShotImageClassification

>>> model = AutoModelForZeroShotImageClassification.from_pretrained(checkpoint)
>>> processor = AutoProcessor.from_pretrained(checkpoint)
```

让我们换一张不同的图片。

```py
>>> from PIL import Image
>>> import requests

>>> url = "https://unsplash.com/photos/xBRQfR2bqNI/download?ixid=MnwxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNjc4Mzg4ODEx&force=true&w=640"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image
```

![汽车的照片](../Images/32d5d4f7954f70dbb6de697af5252857.png)

使用处理器为模型准备输入。处理器结合了一个图像处理器，通过调整大小和归一化来为模型准备图像，以及一个标记器，负责处理文本输入。

```py
>>> candidate_labels = ["tree", "car", "bike", "cat"]
>>> inputs = processor(images=image, text=candidate_labels, return_tensors="pt", padding=True)
```

通过模型传递输入，并对结果进行后处理：

```py
>>> import torch

>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> logits = outputs.logits_per_image[0]
>>> probs = logits.softmax(dim=-1).numpy()
>>> scores = probs.tolist()

>>> result = [
...     {"score": score, "label": candidate_label}
...     for score, candidate_label in sorted(zip(probs, candidate_labels), key=lambda x: -x[0])
... ]

>>> result
[{'score': 0.998572, 'label': 'car'},
 {'score': 0.0010570387, 'label': 'bike'},
 {'score': 0.0003393686, 'label': 'tree'},
 {'score': 3.1572064e-05, 'label': 'cat'}]
```
