- en: K-Diffusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Diffusion
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/k_diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/k_diffusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/k_diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/k_diffusion)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[k-diffusion](https://github.com/crowsonkb/k-diffusion) is a popular library
    created by [Katherine Crowson](https://github.com/crowsonkb/). We provide `StableDiffusionKDiffusionPipeline`
    and `StableDiffusionXLKDiffusionPipeline` that allow you to run Stable DIffusion
    with samplers from k-diffusion.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-diffusion](https://github.com/crowsonkb/k-diffusion)æ˜¯ç”±[Katherine Crowson](https://github.com/crowsonkb/)åˆ›å»ºçš„æµè¡Œåº“ã€‚æˆ‘ä»¬æä¾›`StableDiffusionKDiffusionPipeline`å’Œ`StableDiffusionXLKDiffusionPipeline`ï¼Œå…è®¸æ‚¨ä½¿ç”¨k-diffusionçš„é‡‡æ ·å™¨è¿è¡ŒStable
    DIffusionã€‚'
- en: Note that most the samplers from k-diffusion are implemented in Diffusers and
    we recommend using existing schedulers. You can find a mapping between k-diffusion
    samplers and schedulers in Diffusers [here](https://huggingface.co/docs/diffusers/api/schedulers/overview)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå¤§å¤šæ•°k-diffusionçš„é‡‡æ ·å™¨éƒ½åœ¨Diffusersä¸­å®ç°ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ç°æœ‰çš„è°ƒåº¦ç¨‹åºã€‚æ‚¨å¯ä»¥åœ¨Diffusersä¸­æ‰¾åˆ°k-diffusioné‡‡æ ·å™¨å’Œè°ƒåº¦ç¨‹åºä¹‹é—´çš„æ˜ å°„[here](https://huggingface.co/docs/diffusers/api/schedulers/overview)
- en: StableDiffusionKDiffusionPipeline
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionKDiffusionPipeline
- en: '### `class diffusers.StableDiffusionKDiffusionPipeline`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionKDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py#L50)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py#L50)'
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç ï¼Œä»¥åŠä»æ½œåœ¨è¡¨ç¤ºä¸­è§£ç å›¾åƒã€‚'
- en: '`text_encoder` (`CLIPTextModel`) â€” Frozen text-encoder. Stable Diffusion uses
    the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`CLIPTextModel`) â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚ Stable Diffusionä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå…·ä½“æ¥è¯´æ˜¯[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)å˜ä½“ã€‚'
- en: '`tokenizer` (`CLIPTokenizer`) â€” Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`CLIPTokenizer`) â€” ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„åˆ†è¯å™¨ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” æœ‰æ¡ä»¶çš„U-Netæ¶æ„ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” ç”¨äºä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨è¡¨ç¤ºçš„è°ƒåº¦ç¨‹åºã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” Classification module that
    estimates whether generated images could be considered offensive or harmful. Please,
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for details.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” ç”¨äºä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è§†ä¸ºå…·æœ‰å†’çŠ¯æ€§æˆ–æœ‰å®³æ€§çš„åˆ†ç±»æ¨¡å—ã€‚è¯·å‚è€ƒ[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)è·å–è¯¦ç»†ä¿¡æ¯ã€‚'
- en: '`feature_extractor` (`CLIPImageProcessor`) â€” Model that extracts features from
    generated images to be used as inputs for the `safety_checker`.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` (`CLIPImageProcessor`) â€” ä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾çš„æ¨¡å‹ï¼Œç”¨ä½œ`safety_checker`çš„è¾“å…¥ã€‚'
- en: Pipeline for text-to-image generation using Stable Diffusion.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Stable Diffusionè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æµç¨‹ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æµç¨‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æµç¨‹è¿˜ç»§æ‰¿ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    ç”¨äºåŠ è½½æ–‡æœ¬åè½¬åµŒå…¥'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    ç”¨äºåŠ è½½LoRAæƒé‡'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    ç”¨äºä¿å­˜LoRAæƒé‡'
- en: This is an experimental pipeline and is likely to change in the future.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„æµç¨‹ï¼Œæœªæ¥å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚
- en: '#### `encode_prompt`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py#L181)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py#L181)'
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded device â€”
    (`torch.device`): torch device'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- è¦ç¼–ç çš„æç¤ºè®¾å¤‡-ï¼ˆ`torch.device`ï¼‰ï¼štorchè®¾å¤‡'
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`ï¼ˆ`int`ï¼‰- æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡'
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance`ï¼ˆ`bool`ï¼‰- æ˜¯å¦ä½¿ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- ä¸ç”¨æ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚å¦‚æœä¸ä½¿ç”¨æŒ‡å¯¼ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰- é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰- é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆnegative_prompt_embedsã€‚'
- en: '`lora_scale` (`float`, *optional*) â€” A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼‰- å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰LoRAå±‚çš„LoRAæ¯”ä¾‹ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰- åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦ä»CLIPä¸­è·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º1è¡¨ç¤ºå°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
- en: StableDiffusionXLKDiffusionPipeline
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionXLKDiffusionPipeline
- en: '### `class diffusers.StableDiffusionXLKDiffusionPipeline`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionXLKDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L92)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L92)'
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)ï¼‰-
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`text_encoder` (`CLIPTextModel`) â€” Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ`CLIPTextModel`ï¼‰- å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚ Stable Diffusion XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)å˜ä½“ã€‚'
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) â€” Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_2`ï¼ˆ`CLIPTextModelWithProjection`ï¼‰- ç¬¬äºŒä¸ªå†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚ Stable Diffusion
    XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection)çš„æ–‡æœ¬å’Œæ± éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)å˜ä½“ã€‚'
- en: '`tokenizer` (`CLIPTokenizer`) â€” Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ`CLIPTokenizer`ï¼‰- ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„åˆ†è¯å™¨ã€‚'
- en: '`tokenizer_2` (`CLIPTokenizer`) â€” Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_2`ï¼ˆ`CLIPTokenizer`ï¼‰- ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„ç¬¬äºŒä¸ªåˆ†è¯å™¨ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)ï¼‰-
    æœ‰æ¡ä»¶çš„U-Netæ¶æ„ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œå˜é‡ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`ï¼ˆ[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)ï¼‰-
    ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œå˜é‡çš„è°ƒåº¦ç¨‹åºã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) â€”
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_zeros_for_empty_prompt`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"True"`ï¼‰- æ˜¯å¦å¼ºåˆ¶è´Ÿæç¤ºåµŒå…¥å§‹ç»ˆè®¾ç½®ä¸º0ã€‚è¿˜è¯·å‚é˜…`stabilityai/stable-diffusion-xl-base-1-0`çš„é…ç½®ã€‚'
- en: Pipeline for text-to-image generation using Stable Diffusion XL and k-diffusion.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Stable Diffusion XLå’Œk-diffusionè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æµæ°´çº¿ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡é“è¿˜ç»§æ‰¿ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥çš„[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶çš„[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºåŠ è½½LoRAæƒé‡çš„[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_lora_weights()`ç”¨äºä¿å­˜LoRAæƒé‡'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½IPé€‚é…å™¨
- en: '#### `disable_freeu`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L609)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L609)'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå·²å¯ç”¨ï¼Œåˆ™ç¦ç”¨FreeUæœºåˆ¶ã€‚
- en: '#### `disable_vae_slicing`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L208)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L208)'
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ‡ç‰‡VAEè§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_slicing`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚
- en: '#### `disable_vae_tiling`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L225)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L225)'
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨å¹³é“ºVAEè§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_tiling`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚
- en: '#### `enable_freeu`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L586)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L586)'
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1` (`float`) â€” é˜¶æ®µ1çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚'
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2` (`float`) â€” é˜¶æ®µ2çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚'
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1` (`float`) â€” é˜¶æ®µ1çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚'
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2` (`float`) â€” é˜¶æ®µ2çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨FreeUæœºåˆ¶ï¼Œå¦‚[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)ä¸­æ‰€è¿°ã€‚
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬åº”ç”¨çš„é˜¶æ®µã€‚
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚Stable Diffusion
    v1ã€v2å’ŒStable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚
- en: '#### `enable_vae_slicing`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L200)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L200)'
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ‡ç‰‡VAEè§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç‰‡æ®µï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç ã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜å¹¶å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°éå¸¸æœ‰ç”¨ã€‚
- en: '#### `enable_vae_tiling`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L216)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L216)'
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨å¹³é“ºVAEè§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç“¦ç‰‡ï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚
- en: '#### `encode_prompt`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L233)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L233)'
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦ç¼–ç çš„æç¤º'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device â€” (`torch.device`): torch device'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­éƒ½ä½¿ç”¨`prompt`è®¾å¤‡
    â€” (`torch.device`): torchè®¾å¤‡'
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`ï¼ˆ`int`ï¼‰â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡'
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance`ï¼ˆ`bool`ï¼‰â€” æ˜¯å¦ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸ç”¨æ¥å¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨å¼•å¯¼æ—¶è¢«å¿½ç•¥ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™è¢«å¿½ç•¥ï¼‰ã€‚'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„ä¸ç”¨æ¥å¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­éƒ½ä½¿ç”¨`negative_prompt`'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆè´Ÿé¢æç¤ºåµŒå…¥ã€‚'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„è´Ÿæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„è´Ÿé¢æç¤ºåµŒå…¥ã€‚'
- en: '`lora_scale` (`float`, *optional*) â€” A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼‰â€” å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰LoRAå±‚çš„loraæ¯”ä¾‹ï¼Œå¦‚æœåŠ è½½äº†LoRAå±‚ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€” åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦ä»CLIPä¸­è·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º1æ„å‘³ç€å°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
- en: '#### `fuse_qkv_projections`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `fuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L614)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L614)'
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” åœ¨UNetä¸Šåº”ç”¨èåˆã€‚'
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” åœ¨VAEä¸Šåº”ç”¨èåˆã€‚'
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨èåˆçš„QKVæŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆå³æŸ¥è¯¢ã€é”®ã€å€¼ï¼‰éƒ½è¢«èåˆã€‚å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚
- en: This API is ğŸ§ª experimental.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚
- en: '#### `unfuse_qkv_projections`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unfuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L645)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L645)'
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” åœ¨UNetä¸Šåº”ç”¨èåˆã€‚'
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” åœ¨VAEä¸Šåº”ç”¨èåˆã€‚'
- en: Disable QKV projection fusion if enabled.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¯ç”¨ï¼Œç¦ç”¨QKVæŠ•å½±èåˆã€‚
- en: This API is ğŸ§ª experimental.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚
