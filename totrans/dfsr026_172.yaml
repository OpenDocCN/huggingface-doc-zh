- en: K-Diffusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/k_diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/k_diffusion)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: '[k-diffusion](https://github.com/crowsonkb/k-diffusion) is a popular library
    created by [Katherine Crowson](https://github.com/crowsonkb/). We provide `StableDiffusionKDiffusionPipeline`
    and `StableDiffusionXLKDiffusionPipeline` that allow you to run Stable DIffusion
    with samplers from k-diffusion.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that most the samplers from k-diffusion are implemented in Diffusers and
    we recommend using existing schedulers. You can find a mapping between k-diffusion
    samplers and schedulers in Diffusers [here](https://huggingface.co/docs/diffusers/api/schedulers/overview)
  prefs: []
  type: TYPE_NORMAL
- en: StableDiffusionKDiffusionPipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.StableDiffusionKDiffusionPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py#L50)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder` (`CLIPTextModel`) — Frozen text-encoder. Stable Diffusion uses
    the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please,
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`feature_extractor` (`CLIPImageProcessor`) — Model that extracts features from
    generated images to be used as inputs for the `safety_checker`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text-to-image generation using Stable Diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline also inherits the following loading methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is an experimental pipeline and is likely to change in the future.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py#L181)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  prefs: []
  type: TYPE_NORMAL
- en: StableDiffusionXLKDiffusionPipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.StableDiffusionXLKDiffusionPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L92)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder` (`CLIPTextModel`) — Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) — Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer_2` (`CLIPTokenizer`) — Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) —
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text-to-image generation using Stable Diffusion XL and k-diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline also inherits the following loading methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_lora_weights()` for saving LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `disable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L609)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Disables the FreeU mechanism if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L208)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L225)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L586)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L200)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L216)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L233)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device — (`torch.device`): torch device'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) — A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `fuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L614)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) — To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) — To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  prefs: []
  type: TYPE_NORMAL
- en: This API is 🧪 experimental.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `unfuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_xl_k_diffusion.py#L645)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) — To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) — To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable QKV projection fusion if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: This API is 🧪 experimental.
  prefs: []
  type: TYPE_NORMAL
