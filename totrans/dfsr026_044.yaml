- en: Distilled Stable Diffusion inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd](https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion inference can be a computationally intensive process because
    it must iteratively denoise the latents to generate an image. To reduce the computational
    burden, you can use a *distilled* version of the Stable Diffusion model from [Nota
    AI](https://huggingface.co/nota-ai). The distilled version of their Stable Diffusion
    model eliminates some of the residual and attention blocks from the UNet, reducing
    the model size by 51% and improving latency on CPU/GPU by 43%.
  prefs: []
  type: TYPE_NORMAL
- en: Read this [blog post](https://huggingface.co/blog/sd_distillation) to learn
    more about how knowledge distillation training works to produce a faster, smaller,
    and cheaper generative model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s load the distilled Stable Diffusion model and compare it against the
    original Stable Diffusion model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Given a prompt, get the inference time for the original model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Time the distilled model inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f82acf1004076b7b492a9df026e46793.png)'
  prefs: []
  type: TYPE_IMG
- en: original Stable Diffusion (45781.5 ms)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdcbeffef0420159642acccb6336a302.png)'
  prefs: []
  type: TYPE_IMG
- en: distilled Stable Diffusion (29884.2 ms)
  prefs: []
  type: TYPE_NORMAL
- en: Tiny AutoEncoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To speed inference up even more, use a tiny distilled version of the [Stable
    Diffusion VAE](https://huggingface.co/sayakpaul/taesdxl-diffusers) to denoise
    the latents into images. Replace the VAE in the distilled Stable Diffusion model
    with the tiny VAE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Time the distilled model and distilled VAE inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3eae18d18492330797db5d70b23824f7.png)'
  prefs: []
  type: TYPE_IMG
- en: distilled Stable Diffusion + Tiny AutoEncoder (27165.7 ms)
  prefs: []
  type: TYPE_NORMAL
