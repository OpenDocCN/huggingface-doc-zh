# åŠ è½½LoRAè¿›è¡Œæ¨ç†

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference)

æœ‰è®¸å¤šé€‚é…å™¨ï¼ˆå…¶ä¸­LoRAæ˜¯æœ€å¸¸è§çš„ç±»å‹ï¼‰ä»¥ä¸åŒçš„é£æ ¼è¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°ä¸åŒçš„æ•ˆæœã€‚æ‚¨ç”šè‡³å¯ä»¥ç»„åˆå¤šä¸ªé€‚é…å™¨æ¥åˆ›å»ºæ–°çš„ç‹¬ç‰¹å›¾åƒã€‚é€šè¿‡ğŸ¤— [PEFT](https://huggingface.co/docs/peft/index)åœ¨ğŸ¤— Diffusersä¸­çš„é›†æˆï¼Œéå¸¸å®¹æ˜“åŠ è½½å’Œç®¡ç†é€‚é…å™¨è¿›è¡Œæ¨ç†ã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ä¸åŒçš„é€‚é…å™¨ä¸[Stable Diffusion XL (SDXL)](../api/pipelines/stable_diffusion/stable_diffusion_xl)ä¸€èµ·è¿›è¡Œæ¨ç†ã€‚

åœ¨æ•´ä¸ªæŒ‡å—ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨LoRAä½œä¸ºä¸»è¦é€‚é…å™¨æŠ€æœ¯ï¼Œå› æ­¤æˆ‘ä»¬å°†LoRAå’Œé€‚é…å™¨æœ¯è¯­äº’æ¢ä½¿ç”¨ã€‚æ‚¨åº”è¯¥å¯¹LoRAæœ‰ä¸€å®šäº†è§£ï¼Œå¦‚æœæ²¡æœ‰ï¼Œæ¬¢è¿æŸ¥çœ‹[LoRAæŒ‡å—](https://huggingface.co/docs/peft/conceptual_guides/lora)ã€‚

è®©æˆ‘ä»¬é¦–å…ˆå®‰è£…æ‰€æœ‰æ‰€éœ€çš„åº“ã€‚

```py
!pip install -q transformers accelerate
!pip install peft
!pip install diffusers
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªå¸¦æœ‰SDXLæ£€æŸ¥ç‚¹çš„ç®¡é“ï¼š

```py
from diffusers import DiffusionPipeline
import torch

pipe_id = "stabilityai/stable-diffusion-xl-base-1.0"
pipe = DiffusionPipeline.from_pretrained(pipe_id, torch_dtype=torch.float16).to("cuda")
```

æ¥ä¸‹æ¥ï¼Œä½¿ç”¨[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)æ–¹æ³•åŠ è½½ä¸€ä¸ªLoRAæ£€æŸ¥ç‚¹ã€‚

é€šè¿‡ğŸ¤— PEFTé›†æˆï¼Œæ‚¨å¯ä»¥ä¸ºæ£€æŸ¥ç‚¹åˆ†é…ç‰¹å®šçš„`adapter_name`ï¼Œè¿™æ ·æ‚¨å¯ä»¥è½»æ¾åœ¨ä¸åŒçš„LoRAæ£€æŸ¥ç‚¹ä¹‹é—´åˆ‡æ¢ã€‚è®©æˆ‘ä»¬å°†æ­¤é€‚é…å™¨å‘½åä¸º`"toy"`ã€‚

```py
pipe.load_lora_weights("CiroN2022/toy-face", weight_name="toy_face_sdxl.safetensors", adapter_name="toy")
```

ç„¶åæ‰§è¡Œæ¨ç†ï¼š

```py
prompt = "toy_face of a hacker with a hoodie"

lora_scale= 0.9
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": lora_scale}, generator=torch.manual_seed(0)
).images[0]
image
```

![ç©å…·è„¸](../Images/5113690135aa0bd78ddd1d3e7c53479d.png)

ä½¿ç”¨`adapter_name`å‚æ•°ï¼Œéå¸¸å®¹æ˜“ä¸ºæ¨ç†ä½¿ç”¨å¦ä¸€ä¸ªé€‚é…å™¨ï¼åŠ è½½å·²ç»å¾®è°ƒä»¥ç”Ÿæˆåƒç´ è‰ºæœ¯å›¾åƒçš„[nerijs/pixel-art-xl](https://huggingface.co/nerijs/pixel-art-xl)é€‚é…å™¨ï¼Œå¹¶å°†å…¶å‘½åä¸º`"pixel"`ã€‚

ç®¡é“ä¼šè‡ªåŠ¨å°†ç¬¬ä¸€ä¸ªåŠ è½½çš„é€‚é…å™¨ï¼ˆ`"toy"`ï¼‰è®¾ç½®ä¸ºæ´»åŠ¨é€‚é…å™¨ã€‚ä½†æ˜¯æ‚¨å¯ä»¥ä½¿ç”¨ä¸‹é¢æ˜¾ç¤ºçš„[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)æ–¹æ³•æ¿€æ´»`"pixel"`é€‚é…å™¨ï¼š

```py
pipe.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipe.set_adapters("pixel")
```

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨ç¬¬äºŒä¸ªé€‚é…å™¨ç”Ÿæˆä¸€å¹…å›¾åƒå¹¶æ£€æŸ¥ç»“æœï¼š

```py
prompt = "a hacker with a hoodie, pixel art"
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": lora_scale}, generator=torch.manual_seed(0)
).images[0]
image
```

![åƒç´ è‰ºæœ¯](../Images/d01ebc0347358d4583b5ade26b841a6f.png)

## ç»„åˆå¤šä¸ªé€‚é…å™¨

æ‚¨è¿˜å¯ä»¥æ‰§è¡Œå¤šé€‚é…å™¨æ¨ç†ï¼Œå…¶ä¸­æ‚¨å°†ç»„åˆä¸åŒçš„é€‚é…å™¨æ£€æŸ¥ç‚¹è¿›è¡Œæ¨ç†ã€‚

å†æ¬¡ä½¿ç”¨[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)æ–¹æ³•æ¿€æ´»ä¸¤ä¸ªLoRAæ£€æŸ¥ç‚¹ï¼Œå¹¶æŒ‡å®šæ£€æŸ¥ç‚¹åº”å¦‚ä½•ç»„åˆçš„æƒé‡ã€‚

```py
pipe.set_adapters(["pixel", "toy"], adapter_weights=[0.5, 1.0])
```

ç°åœ¨æˆ‘ä»¬å·²ç»è®¾ç½®äº†è¿™ä¸¤ä¸ªé€‚é…å™¨ï¼Œè®©æˆ‘ä»¬ä»ç»„åˆé€‚é…å™¨ç”Ÿæˆä¸€å¹…å›¾åƒï¼

æ‰©æ•£ç¤¾åŒºä¸­çš„LoRAæ£€æŸ¥ç‚¹å‡ ä¹æ€»æ˜¯ä½¿ç”¨[DreamBooth](https://huggingface.co/docs/diffusers/main/en/training/dreambooth)è·å¾—çš„ã€‚ DreamBoothè®­ç»ƒé€šå¸¸ä¾èµ–äºè¾“å…¥æ–‡æœ¬æç¤ºä¸­çš„â€œè§¦å‘â€è¯ï¼Œä»¥ä¾¿ç”Ÿæˆç»“æœçœ‹èµ·æ¥ç¬¦åˆé¢„æœŸã€‚å½“æ‚¨ç»„åˆå¤šä¸ªLoRAæ£€æŸ¥ç‚¹æ—¶ï¼Œé‡è¦çš„æ˜¯ç¡®ä¿ç›¸åº”LoRAæ£€æŸ¥ç‚¹çš„è§¦å‘è¯å­˜åœ¨äºè¾“å…¥æ–‡æœ¬æç¤ºä¸­ã€‚

è§¦å‘è¯[CiroN2022/toy-face](https://hf.co/CiroN2022/toy-face)å’Œ[nerijs/pixel-art-xl](https://hf.co/nerijs/pixel-art-xl)å¯ä»¥åœ¨å®ƒä»¬çš„å­˜å‚¨åº“ä¸­æ‰¾åˆ°ã€‚

```py
# Notice how the prompt is constructed.
prompt = "toy_face of a hacker with a hoodie, pixel art"
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": 1.0}, generator=torch.manual_seed(0)
).images[0]
image
```

![ç©å…·è„¸åƒç´ è‰ºæœ¯](../Images/99de7c335e766f24d86d686716cfbe1c.png)

ä»¤äººå°è±¡æ·±åˆ»ï¼æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ··åˆä¸¤ä¸ªé€‚é…å™¨ç‰¹å¾çš„å›¾åƒã€‚

å¦‚æœè¦å›åˆ°ä»…ä½¿ç”¨ä¸€ä¸ªé€‚é…å™¨ï¼Œè¯·ä½¿ç”¨[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)æ–¹æ³•æ¿€æ´»`"toy"`é€‚é…å™¨ï¼š

```py
# First, set the adapter.
pipe.set_adapters("toy")

# Then, run inference.
prompt = "toy_face of a hacker with a hoodie"
lora_scale= 0.9
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": lora_scale}, generator=torch.manual_seed(0)
).images[0]
image
```

![ç©å…·è„¸å†æ¬¡](../Images/c176e32c69a0df1e6ed4b22f5a94350b.png)

å¦‚æœè¦åˆ‡æ¢åˆ°ä»…ä½¿ç”¨åŸºæœ¬æ¨¡å‹ï¼Œè¯·ä½¿ç”¨[disable_lora()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.disable_lora)æ–¹æ³•ç¦ç”¨æ‰€æœ‰LoRAã€‚

```py
pipe.disable_lora()

prompt = "toy_face of a hacker with a hoodie"
lora_scale= 0.9
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]
image
```

![no-lora](../Images/13732666737056b846ce11880fe30289.png)

## ç›‘è§†æ´»åŠ¨é€‚é…å™¨

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å·²ç»è¿æ¥äº†å¤šä¸ªé€‚é…å™¨ï¼Œå¦‚æœæ‚¨å¯¹å·²è¿æ¥åˆ°ç®¡é“ç»„ä»¶çš„é€‚é…å™¨æ„Ÿåˆ°æœ‰äº›è¿·èŒ«ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[get_active_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_active_adapters)æ–¹æ³•è½»æ¾æ£€æŸ¥æ´»åŠ¨é€‚é…å™¨çš„åˆ—è¡¨ï¼š

```py
active_adapters = pipe.get_active_adapters()
active_adapters
["toy", "pixel"]
```

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨[get_list_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_list_adapters)è·å–æ¯ä¸ªç®¡é“ç»„ä»¶çš„æ´»åŠ¨é€‚é…å™¨ï¼š

```py
list_adapters_component_wise = pipe.get_list_adapters()
list_adapters_component_wise
{"text_encoder": ["toy", "pixel"], "unet": ["toy", "pixel"], "text_encoder_2": ["toy", "pixel"]}
```

## å°†é€‚é…å™¨èåˆåˆ°æ¨¡å‹ä¸­

æ‚¨å¯ä»¥ä½¿ç”¨PEFTè½»æ¾åœ°å°†å¤šä¸ªé€‚é…å™¨ç›´æ¥èåˆ/è§£é™¤èåˆåˆ°æ¨¡å‹æƒé‡ä¸­ï¼ˆUNetå’Œæ–‡æœ¬ç¼–ç å™¨å‡å¯ï¼‰ï¼Œä½¿ç”¨[fuse_lora()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.fuse_lora)æ–¹æ³•ï¼Œè¿™å¯ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦å¹¶é™ä½VRAMä½¿ç”¨ç‡ã€‚

```py
pipe.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipe.load_lora_weights("CiroN2022/toy-face", weight_name="toy_face_sdxl.safetensors", adapter_name="toy")

pipe.set_adapters(["pixel", "toy"], adapter_weights=[0.5, 1.0])
# Fuses the LoRAs into the Unet
pipe.fuse_lora()

prompt = "toy_face of a hacker with a hoodie, pixel art"
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]

# Gets the Unet back to the original state
pipe.unfuse_lora()
```

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨`adapter_names`æ¥èåˆä¸€äº›é€‚é…å™¨ï¼Œä»¥åŠ å¿«ç”Ÿæˆé€Ÿåº¦ï¼š

```py
pipe.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipe.load_lora_weights("CiroN2022/toy-face", weight_name="toy_face_sdxl.safetensors", adapter_name="toy")

pipe.set_adapters(["pixel"], adapter_weights=[0.5, 1.0])
# Fuses the LoRAs into the Unet
pipe.fuse_lora(adapter_names=["pixel"])

prompt = "a hacker with a hoodie, pixel art"
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]

# Gets the Unet back to the original state
pipe.unfuse_lora()

# Fuse all adapters
pipe.fuse_lora(adapter_names=["pixel", "toy"])

prompt = "toy_face of a hacker with a hoodie, pixel art"
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]
```

## åœ¨èåˆé€‚é…å™¨åä¿å­˜ç®¡é“

åœ¨åŠ è½½é€‚é…å™¨åæ­£ç¡®ä¿å­˜ç®¡é“ä¹‹å‰ï¼Œåº”è¯¥åƒè¿™æ ·åºåˆ—åŒ–ï¼š

```py
pipe.fuse_lora(lora_scale=1.0)
pipe.unload_lora_weights()
pipe.save_pretrained("path-to-pipeline")
```
