# 加载LoRA进行推理

> 原文链接：[https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference)

有许多适配器（其中LoRA是最常见的类型）以不同的风格进行训练，以实现不同的效果。您甚至可以组合多个适配器来创建新的独特图像。通过🤗 [PEFT](https://huggingface.co/docs/peft/index)在🤗 Diffusers中的集成，非常容易加载和管理适配器进行推理。在本指南中，您将学习如何使用不同的适配器与[Stable Diffusion XL (SDXL)](../api/pipelines/stable_diffusion/stable_diffusion_xl)一起进行推理。

在整个指南中，您将使用LoRA作为主要适配器技术，因此我们将LoRA和适配器术语互换使用。您应该对LoRA有一定了解，如果没有，欢迎查看[LoRA指南](https://huggingface.co/docs/peft/conceptual_guides/lora)。

让我们首先安装所有所需的库。

```py
!pip install -q transformers accelerate
!pip install peft
!pip install diffusers
```

现在，让我们加载一个带有SDXL检查点的管道：

```py
from diffusers import DiffusionPipeline
import torch

pipe_id = "stabilityai/stable-diffusion-xl-base-1.0"
pipe = DiffusionPipeline.from_pretrained(pipe_id, torch_dtype=torch.float16).to("cuda")
```

接下来，使用[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)方法加载一个LoRA检查点。

通过🤗 PEFT集成，您可以为检查点分配特定的`adapter_name`，这样您可以轻松在不同的LoRA检查点之间切换。让我们将此适配器命名为`"toy"`。

```py
pipe.load_lora_weights("CiroN2022/toy-face", weight_name="toy_face_sdxl.safetensors", adapter_name="toy")
```

然后执行推理：

```py
prompt = "toy_face of a hacker with a hoodie"

lora_scale= 0.9
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": lora_scale}, generator=torch.manual_seed(0)
).images[0]
image
```

![玩具脸](../Images/5113690135aa0bd78ddd1d3e7c53479d.png)

使用`adapter_name`参数，非常容易为推理使用另一个适配器！加载已经微调以生成像素艺术图像的[nerijs/pixel-art-xl](https://huggingface.co/nerijs/pixel-art-xl)适配器，并将其命名为`"pixel"`。

管道会自动将第一个加载的适配器（`"toy"`）设置为活动适配器。但是您可以使用下面显示的[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法激活`"pixel"`适配器：

```py
pipe.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipe.set_adapters("pixel")
```

现在让我们使用第二个适配器生成一幅图像并检查结果：

```py
prompt = "a hacker with a hoodie, pixel art"
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": lora_scale}, generator=torch.manual_seed(0)
).images[0]
image
```

![像素艺术](../Images/d01ebc0347358d4583b5ade26b841a6f.png)

## 组合多个适配器

您还可以执行多适配器推理，其中您将组合不同的适配器检查点进行推理。

再次使用[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法激活两个LoRA检查点，并指定检查点应如何组合的权重。

```py
pipe.set_adapters(["pixel", "toy"], adapter_weights=[0.5, 1.0])
```

现在我们已经设置了这两个适配器，让我们从组合适配器生成一幅图像！

扩散社区中的LoRA检查点几乎总是使用[DreamBooth](https://huggingface.co/docs/diffusers/main/en/training/dreambooth)获得的。 DreamBooth训练通常依赖于输入文本提示中的“触发”词，以便生成结果看起来符合预期。当您组合多个LoRA检查点时，重要的是确保相应LoRA检查点的触发词存在于输入文本提示中。

触发词[CiroN2022/toy-face](https://hf.co/CiroN2022/toy-face)和[nerijs/pixel-art-xl](https://hf.co/nerijs/pixel-art-xl)可以在它们的存储库中找到。

```py
# Notice how the prompt is constructed.
prompt = "toy_face of a hacker with a hoodie, pixel art"
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": 1.0}, generator=torch.manual_seed(0)
).images[0]
image
```

![玩具脸像素艺术](../Images/99de7c335e766f24d86d686716cfbe1c.png)

令人印象深刻！正如您所看到的，模型能够生成混合两个适配器特征的图像。

如果要回到仅使用一个适配器，请使用[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法激活`"toy"`适配器：

```py
# First, set the adapter.
pipe.set_adapters("toy")

# Then, run inference.
prompt = "toy_face of a hacker with a hoodie"
lora_scale= 0.9
image = pipe(
    prompt, num_inference_steps=30, cross_attention_kwargs={"scale": lora_scale}, generator=torch.manual_seed(0)
).images[0]
image
```

![玩具脸再次](../Images/c176e32c69a0df1e6ed4b22f5a94350b.png)

如果要切换到仅使用基本模型，请使用[disable_lora()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.disable_lora)方法禁用所有LoRA。

```py
pipe.disable_lora()

prompt = "toy_face of a hacker with a hoodie"
lora_scale= 0.9
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]
image
```

![no-lora](../Images/13732666737056b846ce11880fe30289.png)

## 监视活动适配器

在本教程中，您已经连接了多个适配器，如果您对已连接到管道组件的适配器感到有些迷茫，您可以使用[get_active_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_active_adapters)方法轻松检查活动适配器的列表：

```py
active_adapters = pipe.get_active_adapters()
active_adapters
["toy", "pixel"]
```

您还可以使用[get_list_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_list_adapters)获取每个管道组件的活动适配器：

```py
list_adapters_component_wise = pipe.get_list_adapters()
list_adapters_component_wise
{"text_encoder": ["toy", "pixel"], "unet": ["toy", "pixel"], "text_encoder_2": ["toy", "pixel"]}
```

## 将适配器融合到模型中

您可以使用PEFT轻松地将多个适配器直接融合/解除融合到模型权重中（UNet和文本编码器均可），使用[fuse_lora()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.fuse_lora)方法，这可以加快推理速度并降低VRAM使用率。

```py
pipe.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipe.load_lora_weights("CiroN2022/toy-face", weight_name="toy_face_sdxl.safetensors", adapter_name="toy")

pipe.set_adapters(["pixel", "toy"], adapter_weights=[0.5, 1.0])
# Fuses the LoRAs into the Unet
pipe.fuse_lora()

prompt = "toy_face of a hacker with a hoodie, pixel art"
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]

# Gets the Unet back to the original state
pipe.unfuse_lora()
```

您还可以使用`adapter_names`来融合一些适配器，以加快生成速度：

```py
pipe.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipe.load_lora_weights("CiroN2022/toy-face", weight_name="toy_face_sdxl.safetensors", adapter_name="toy")

pipe.set_adapters(["pixel"], adapter_weights=[0.5, 1.0])
# Fuses the LoRAs into the Unet
pipe.fuse_lora(adapter_names=["pixel"])

prompt = "a hacker with a hoodie, pixel art"
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]

# Gets the Unet back to the original state
pipe.unfuse_lora()

# Fuse all adapters
pipe.fuse_lora(adapter_names=["pixel", "toy"])

prompt = "toy_face of a hacker with a hoodie, pixel art"
image = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]
```

## 在融合适配器后保存管道

在加载适配器后正确保存管道之前，应该像这样序列化：

```py
pipe.fuse_lora(lora_scale=1.0)
pipe.unload_lora_weights()
pipe.save_pretrained("path-to-pipeline")
```
