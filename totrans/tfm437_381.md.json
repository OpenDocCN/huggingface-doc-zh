["```py\n( vocab_size = 100 action_weight = 5 reward_weight = 1 value_weight = 1 block_size = 249 action_dim = 6 observation_dim = 17 transition_dim = 25 n_layer = 4 n_head = 4 n_embd = 128 embd_pdrop = 0.1 attn_pdrop = 0.1 resid_pdrop = 0.1 learning_rate = 0.0006 max_position_embeddings = 512 initializer_range = 0.02 layer_norm_eps = 1e-12 kaiming_initializer_range = 1 use_cache = True pad_token_id = 1 bos_token_id = 50256 eos_token_id = 50256 **kwargs )\n```", "```py\n>>> from transformers import TrajectoryTransformerConfig, TrajectoryTransformerModel\n\n>>> # Initializing a TrajectoryTransformer CarlCochet/trajectory-transformer-halfcheetah-medium-v2 style configuration\n>>> configuration = TrajectoryTransformerConfig()\n\n>>> # Initializing a model (with random weights) from the CarlCochet/trajectory-transformer-halfcheetah-medium-v2 style configuration\n>>> model = TrajectoryTransformerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config )\n```", "```py\n( trajectories: Optional = None past_key_values: Optional = None targets: Optional = None attention_mask: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.deprecated.trajectory_transformer.modeling_trajectory_transformer.TrajectoryTransformerOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import TrajectoryTransformerModel\n>>> import torch\n\n>>> model = TrajectoryTransformerModel.from_pretrained(\n...     \"CarlCochet/trajectory-transformer-halfcheetah-medium-v2\"\n... )\n>>> model.to(device)\n>>> model.eval()\n\n>>> observations_dim, action_dim, batch_size = 17, 6, 256\n>>> seq_length = observations_dim + action_dim + 1\n\n>>> trajectories = torch.LongTensor([np.random.permutation(self.seq_length) for _ in range(batch_size)]).to(\n...     device\n... )\n>>> targets = torch.LongTensor([np.random.permutation(self.seq_length) for _ in range(batch_size)]).to(device)\n\n>>> outputs = model(\n...     trajectories,\n...     targets=targets,\n...     use_cache=True,\n...     output_attentions=True,\n...     output_hidden_states=True,\n...     return_dict=True,\n... )\n```"]