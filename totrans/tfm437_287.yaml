- en: Swin Transformer V2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swin Transformer V2
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/swinv2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/swinv2)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/swinv2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/swinv2)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The Swin Transformer V2 model was proposed in [Swin Transformer V2: Scaling
    Up Capacity and Resolution](https://arxiv.org/abs/2111.09883) by Ze Liu, Han Hu,
    Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang,
    Li Dong, Furu Wei, Baining Guo.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'Swin Transformer V2模型是由刘泽、胡涵、林宇彤、姚竹亮、谢振达、魏一轩、宁佳、曹越、张铮、董力、魏富儒、郭百宁在[《Swin Transformer
    V2: 扩展容量和分辨率》](https://arxiv.org/abs/2111.09883)中提出的。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要如下：
- en: '*Large-scale NLP models have been shown to significantly improve the performance
    on language tasks with no signs of saturation. They also demonstrate amazing few-shot
    capabilities like that of human beings. This paper aims to explore large-scale
    models in computer vision. We tackle three major issues in training and application
    of large vision models, including training instability, resolution gaps between
    pre-training and fine-tuning, and hunger on labelled data. Three main techniques
    are proposed: 1) a residual-post-norm method combined with cosine attention to
    improve training stability; 2) A log-spaced continuous position bias method to
    effectively transfer models pre-trained using low-resolution images to downstream
    tasks with high-resolution inputs; 3) A self-supervised pre-training method, SimMIM,
    to reduce the needs of vast labeled images. Through these techniques, this paper
    successfully trained a 3 billion-parameter Swin Transformer V2 model, which is
    the largest dense vision model to date, and makes it capable of training with
    images of up to 1,536×1,536 resolution. It set new performance records on 4 representative
    vision tasks, including ImageNet-V2 image classification, COCO object detection,
    ADE20K semantic segmentation, and Kinetics-400 video action classification. Also
    note our training is much more efficient than that in Google’s billion-level visual
    models, which consumes 40 times less labelled data and 40 times less training
    time.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*已经证明大规模的NLP模型在语言任务上显著提高了性能，没有饱和的迹象。它们还展示了惊人的少样本能力，就像人类一样。本文旨在探索计算机视觉中的大规模模型。我们解决了大视觉模型训练和应用中的三个主要问题，包括训练不稳定性、预训练和微调之间的分辨率差距，以及对标记数据的需求。提出了三种主要技术：1）结合余弦注意力的残差后归一化方法，以提高训练稳定性；2）一种对数间隔连续位置偏置方法，有效地将使用低分辨率图像预训练的模型转移到具有高分辨率输入的下游任务；3）一种自监督预训练方法，SimMIM，以减少对大量标记图像的需求。通过这些技术，本文成功训练了一个30亿参数的Swin
    Transformer V2模型，这是迄今为止最大的密集视觉模型，并使其能够训练具有高达1,536×1,536分辨率的图像。它在4个代表性的视觉任务上创造了新的性能记录，包括ImageNet-V2图像分类、COCO目标检测、ADE20K语义分割和Kinetics-400视频动作分类。还请注意，我们的训练比谷歌的十亿级视觉模型更高效，消耗的标记数据少40倍，训练时间少40倍。*'
- en: This model was contributed by [nandwalritik](https://huggingface.co/nandwalritik).
    The original code can be found [here](https://github.com/microsoft/Swin-Transformer).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[nandwalritik](https://huggingface.co/nandwalritik)贡献。原始代码可以在[这里](https://github.com/microsoft/Swin-Transformer)找到。
- en: Resources
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with Swin Transformer v2.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 官方Hugging Face和社区（由🌎表示）资源列表，帮助您开始使用Swin Transformer v2。
- en: Image Classification
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类
- en: '[Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)由这个[示例脚本](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)和[笔记本](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)支持。'
- en: 'See also: [Image classification task guide](../tasks/image_classification)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：[图像分类任务指南](../tasks/image_classification)
- en: 'Besides that:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外：
- en: '[Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)由这个[示例脚本](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)支持。'
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we’ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在这里，请随时提交Pull Request，我们将进行审核！资源应该展示出一些新的东西，而不是重复现有资源。
- en: Swinv2Config
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swinv2Config
- en: '### `class transformers.Swinv2Config`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Swinv2Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/configuration_swinv2.py#L31)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/configuration_swinv2.py#L31)'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_size` (`int`, *optional*, defaults to 224) — The size (resolution) of
    each image.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size`（`int`，*可选*，默认为224）— 每个图像的大小（分辨率）。'
- en: '`patch_size` (`int`, *optional*, defaults to 4) — The size (resolution) of
    each patch.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size`（`int`，*可选*，默认为4）— 每个补丁的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels`（`int`，*可选*，默认为3）— 输入通道的数量。'
- en: '`embed_dim` (`int`, *optional*, defaults to 96) — Dimensionality of patch embedding.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embed_dim`（`int`，*可选*，默认为96）— 补丁嵌入的维度。'
- en: '`depths` (`list(int)`, *optional*, defaults to `[2, 2, 6, 2]`) — Depth of each
    layer in the Transformer encoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depths`（`list(int)`，*可选*，默认为`[2, 2, 6, 2]`）— Transformer编码器中每个层的深度。'
- en: '`num_heads` (`list(int)`, *optional*, defaults to `[3, 6, 12, 24]`) — Number
    of attention heads in each layer of the Transformer encoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`list(int)`，*可选*，默认为 `[3, 6, 12, 24]`) — Transformer 编码器每层中的注意力头数。'
- en: '`window_size` (`int`, *optional*, defaults to 7) — Size of windows.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`window_size` (`int`，*可选*，默认为 7) — 窗口的大小。'
- en: '`pretrained_window_sizes` (`list(int)`, *optional*, defaults to `[0, 0, 0,
    0]`) — Size of windows during pretraining.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_window_sizes` (`list(int)`，*可选*，默认为 `[0, 0, 0, 0]`) — 预训练期间窗口的大小。'
- en: '`mlp_ratio` (`float`, *optional*, defaults to 4.0) — Ratio of MLP hidden dimensionality
    to embedding dimensionality.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlp_ratio` (`float`，*可选*，默认为 4.0) — MLP 隐藏维度与嵌入维度的比率。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether or not a learnable
    bias should be added to the queries, keys and values.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`，*可选*，默认为 `True`) — 是否应向查询、键和值添加可学习偏置。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — The dropout
    probability for all fully connected layers in the embeddings and encoder.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`，*可选*，默认为 0.0) — 嵌入和编码器中所有全连接层的丢弃概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — The
    dropout ratio for the attention probabilities.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`，*可选*，默认为 0.0) — 注意力概率的丢弃比率。'
- en: '`drop_path_rate` (`float`, *optional*, defaults to 0.1) — Stochastic depth
    rate.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop_path_rate` (`float`，*可选*，默认为 0.1) — 随机深度率。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder. If string,
    `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` 或 `function`，*可选*，默认为 `"gelu"`) — 编码器中的非线性激活函数（函数或字符串）。如果是字符串，支持
    `"gelu"`、`"relu"`、`"selu"` 和 `"gelu_new"`。'
- en: '`use_absolute_embeddings` (`bool`, *optional*, defaults to `False`) — Whether
    or not to add absolute position embeddings to the patch embeddings.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_absolute_embeddings` (`bool`，*可选*，默认为 `False`) — 是否要将绝对位置嵌入添加到补丁嵌入中。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`，*可选*，默认为 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`，*可选*，默认为 1e-05) — 层归一化层使用的 epsilon。'
- en: '`encoder_stride` (`int`, *optional*, defaults to 32) — Factor to increase the
    spatial resolution by in the decoder head for masked image modeling.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_stride` (`int`，*可选*，默认为 32) — 在解码器头部用于遮蔽图像建模时增加空间分辨率的因子。'
- en: '`out_features` (`List[str]`, *optional*) — If used as backbone, list of features
    to output. Can be any of `"stem"`, `"stage1"`, `"stage2"`, etc. (depending on
    how many stages the model has). If unset and `out_indices` is set, will default
    to the corresponding stages. If unset and `out_indices` is unset, will default
    to the last stage.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_features` (`List[str]`，*可选*) — 如果用作骨干网络，要输出的特征列表。可以是 `"stem"`、`"stage1"`、`"stage2"`
    等（取决于模型有多少阶段）。如果未设置且设置了 `out_indices`，将默认为相应的阶段。如果未设置且未设置 `out_indices`，将默认为最后一个阶段。'
- en: '`out_indices` (`List[int]`, *optional*) — If used as backbone, list of indices
    of features to output. Can be any of 0, 1, 2, etc. (depending on how many stages
    the model has). If unset and `out_features` is set, will default to the corresponding
    stages. If unset and `out_features` is unset, will default to the last stage.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_indices` (`List[int]`，*可选*) — 如果用作骨干网络，要输出的特征的索引列表。可以是 0、1、2 等（取决于模型有多少阶段）。如果未设置且设置了
    `out_features`，将默认为相应的阶段。如果未设置且未设置 `out_features`，将默认为最后一个阶段。'
- en: This is the configuration class to store the configuration of a [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model).
    It is used to instantiate a Swin Transformer v2 model according to the specified
    arguments, defining the model architecture. Instantiating a configuration with
    the defaults will yield a similar configuration to that of the Swin Transformer
    v2 [microsoft/swinv2-tiny-patch4-window8-256](https://huggingface.co/microsoft/swinv2-tiny-patch4-window8-256)
    architecture.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储 [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    的配置。根据指定的参数实例化 Swin Transformer v2 模型，定义模型架构。使用默认值实例化配置将产生类似于 Swin Transformer
    v2 [microsoft/swinv2-tiny-patch4-window8-256](https://huggingface.co/microsoft/swinv2-tiny-patch4-window8-256)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读来自
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Swinv2Model
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swinv2Model
- en: '### `class transformers.Swinv2Model`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Swinv2Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L992)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L992)'
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: The bare Swinv2 Model transformer outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的 Swinv2 模型变压器输出原始隐藏状态，没有特定的头部。此模型是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1024)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1024)'
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅[ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*optional*)
    — 用于使自注意力模块中选择的头部失效的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被`masked`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`,
    *optional*) — Boolean masked positions. Indicates which patches are masked (1)
    and which aren’t (0).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos` (`torch.BoolTensor`，形状为`(batch_size, num_patches)`，*optional*)
    — 布尔掩码位置。指示哪些补丁被掩盖（1）哪些没有（0）。'
- en: Returns
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.swinv2.modeling_swinv2.Swinv2ModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.swinv2.modeling_swinv2.Swinv2ModelOutput` 或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.swinv2.modeling_swinv2.Swinv2ModelOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    and inputs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.swinv2.modeling_swinv2.Swinv2ModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包括根据配置（[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)）和输入而异的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层输出的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`,
    *optional*, returned when `add_pooling_layer=True` is passed) — Average pooling
    of the last layer hidden-state.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor`，形状为`(batch_size, hidden_size)`，*optional*，当传递`add_pooling_layer=True`时返回)
    — 最后一层隐藏状态的平均池化。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each stage) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each stage) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个阶段一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, hidden_size, height, width)`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, hidden_size, height, width)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs reshaped to include the spatial dimensions.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及初始嵌入输出，重塑以包括空间维度。
- en: The [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    forward method, overrides the `__call__` special method.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用 `Module` 实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Swinv2ForMaskedImageModeling
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swinv2ForMaskedImageModeling
- en: '### `class transformers.Swinv2ForMaskedImageModeling`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Swinv2ForMaskedImageModeling`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1094)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1094)'
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: Swinv2 Model with a decoder on top for masked image modeling, as proposed in
    [SimMIM](https://arxiv.org/abs/2111.09886).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Swinv2 模型在顶部带有解码器，用于掩码图像建模，如 [SimMIM](https://arxiv.org/abs/2111.09886) 中提出的。
- en: Note that we provide a script to pre-train this model on custom data in our
    [examples directory](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在我们的 [示例目录](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)
    中提供了一个脚本，用于在自定义数据上预训练此模型。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    的子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1125)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1125)'
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height,
    width)`) — 像素值。可以使用 [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    获取像素值。有关详细信息，请参阅 [ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块中选择的头部失效的掩码。掩码值选在 `[0, 1]`：'
- en: 1 indicates the head is `not masked`,
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `掩码`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`)
    — Boolean masked positions. Indicates which patches are masked (1) and which aren’t
    (0).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos` (`torch.BoolTensor`，形状为 `(batch_size, num_patches)`) — 布尔掩码位置。指示哪些补丁被掩盖（1）哪些没有（0）。'
- en: Returns
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.swinv2.modeling_swinv2.Swinv2MaskedImageModelingOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.swinv2.modeling_swinv2.Swinv2MaskedImageModelingOutput`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.swinv2.modeling_swinv2.Swinv2MaskedImageModelingOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    and inputs.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `transformers.models.swinv2.modeling_swinv2.Swinv2MaskedImageModelingOutput`
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含根据配置（[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `bool_masked_pos`
    is provided) — Masked image modeling (MLM) loss.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为 `(1,)`，*可选*，当提供 `bool_masked_pos` 时返回) — 掩码图像建模（MLM）损失。'
- en: '`reconstruction` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Reconstructed pixel values.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reconstruction` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height,
    width)`) — 重构的像素值。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each stage) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each stage) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, hidden_size, height, width)`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs reshaped to include the spatial dimensions.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)
    forward method, overrides the `__call__` special method.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Swinv2ForImageClassification
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.Swinv2ForImageClassification`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1212)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swinv2 Model transformer with an image classification head on top (a linear
    layer on top of the final hidden state of the [CLS] token) e.g. for ImageNet.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/swinv2/modeling_swinv2.py#L1235)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选的*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the image classification/regression loss. Indices should be in `[0,
    ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is
    computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size,)`, *可选的*) — 用于计算图像分类/回归损失的标签。索引应在`[0,
    ..., config.num_labels - 1]`范围内。如果`config.num_labels == 1`，则计算回归损失（均方损失），如果`config.num_labels
    > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.swinv2.modeling_swinv2.Swinv2ImageClassifierOutput` or
    `tuple(torch.FloatTensor)`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.swinv2.modeling_swinv2.Swinv2ImageClassifierOutput` 或
    `tuple(torch.FloatTensor)`'
- en: A `transformers.models.swinv2.modeling_swinv2.Swinv2ImageClassifierOutput` or
    a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config))
    and inputs.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.swinv2.modeling_swinv2.Swinv2ImageClassifierOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或者当`config.return_dict=False`时）包含根据配置（[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`, *可选的*, 当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each stage) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或者当`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态加上初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each stage) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_attentions=True`或者当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个阶段一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, hidden_size, height, width)`.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或者当`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, hidden_size, height, width)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs reshaped to include the spatial dimensions.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态，加上重新调整形状以包括空间维度的初始嵌入输出。
- en: The [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在之后调用`Module`实例，而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
