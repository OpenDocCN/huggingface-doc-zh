["```py\nimport torch\nfrom PIL import Image\nimport requests\nfrom transformers import SamModel, SamProcessor\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\nprocessor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n\nimg_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")\ninput_points = [[[450, 600]]]  # 2D location of a window in the image\n\ninputs = processor(raw_image, input_points=input_points, return_tensors=\"pt\").to(device)\nwith torch.no_grad():\n    outputs = model(**inputs)\n\nmasks = processor.image_processor.post_process_masks(\n    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n)\nscores = outputs.iou_scores\n```", "```py\nimport torch\nfrom PIL import Image\nimport requests\nfrom transformers import SamModel, SamProcessor\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\nprocessor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n\nimg_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")\nmask_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\nsegmentation_map = Image.open(requests.get(mask_url, stream=True).raw).convert(\"RGB\")\ninput_points = [[[450, 600]]]  # 2D location of a window in the image\n\ninputs = processor(raw_image, input_points=input_points, segmentation_maps=mask, return_tensors=\"pt\").to(device)\nwith torch.no_grad():\n    outputs = model(**inputs)\n\nmasks = processor.image_processor.post_process_masks(\n    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n)\nscores = outputs.iou_scores\n```", "```py\n>>> from transformers import (\n...     SamVisionConfig,\n...     SamPromptEncoderConfig,\n...     SamMaskDecoderConfig,\n...     SamModel,\n... )\n\n>>> # Initializing a SamConfig with `\"facebook/sam-vit-huge\"` style configuration\n>>> configuration = SamConfig()\n\n>>> # Initializing a SamModel (with random weights) from the `\"facebook/sam-vit-huge\"` style configuration\n>>> model = SamModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n\n>>> # We can also initialize a SamConfig from a SamVisionConfig, SamPromptEncoderConfig, and SamMaskDecoderConfig\n\n>>> # Initializing SAM vision, SAM Q-Former and language model configurations\n>>> vision_config = SamVisionConfig()\n>>> prompt_encoder_config = SamPromptEncoderConfig()\n>>> mask_decoder_config = SamMaskDecoderConfig()\n\n>>> config = SamConfig(vision_config, prompt_encoder_config, mask_decoder_config)\n```"]