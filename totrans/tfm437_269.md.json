["```py\n( image_size = 224 patch_size = 4 num_channels = 3 embed_dim = 96 use_conv_embed = False hidden_sizes = [192, 384, 768, 768] depths = [2, 2, 6, 2] focal_levels = [2, 2, 2, 2] focal_windows = [3, 3, 3, 3] hidden_act = 'gelu' mlp_ratio = 4.0 hidden_dropout_prob = 0.0 drop_path_rate = 0.1 use_layerscale = False layerscale_value = 0.0001 use_post_layernorm = False use_post_layernorm_in_modulation = False normalize_modulator = False initializer_range = 0.02 layer_norm_eps = 1e-05 encoder_stride = 32 out_features = None out_indices = None **kwargs )\n```", "```py\n>>> from transformers import FocalNetConfig, FocalNetModel\n\n>>> # Initializing a FocalNet microsoft/focalnet-tiny style configuration\n>>> configuration = FocalNetConfig()\n\n>>> # Initializing a model (with random weights) from the microsoft/focalnet-tiny style configuration\n>>> model = FocalNetModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config add_pooling_layer = True use_mask_token = False )\n```", "```py\n( pixel_values: Optional = None bool_masked_pos: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.focalnet.modeling_focalnet.FocalNetModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, FocalNetModel\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"microsoft/focalnet-tiny\")\n>>> model = FocalNetModel.from_pretrained(\"microsoft/focalnet-tiny\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 49, 768]\n```", "```py\n( config )\n```", "```py\n( pixel_values: Optional = None bool_masked_pos: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.focalnet.modeling_focalnet.FocalNetMaskedImageModelingOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, FocalNetConfig, FocalNetForMaskedImageModeling\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"microsoft/focalnet-base-simmim-window6-192\")\n>>> config = FocalNetConfig()\n>>> model = FocalNetForMaskedImageModeling(config)\n\n>>> num_patches = (model.config.image_size // model.config.patch_size) ** 2\n>>> pixel_values = image_processor(images=image, return_tensors=\"pt\").pixel_values\n>>> # create random boolean mask of shape (batch_size, num_patches)\n>>> bool_masked_pos = torch.randint(low=0, high=2, size=(1, num_patches)).bool()\n\n>>> outputs = model(pixel_values, bool_masked_pos=bool_masked_pos)\n>>> loss, reconstructed_pixel_values = outputs.loss, outputs.logits\n>>> list(reconstructed_pixel_values.shape)\n[1, 3, 192, 192]\n```", "```py\n( config )\n```", "```py\n( pixel_values: Optional = None labels: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.focalnet.modeling_focalnet.FocalNetImageClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, FocalNetForImageClassification\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"microsoft/focalnet-tiny\")\n>>> model = FocalNetForImageClassification.from_pretrained(\"microsoft/focalnet-tiny\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = logits.argmax(-1).item()\n>>> print(model.config.id2label[predicted_label])\ntabby, tabby cat\n```"]