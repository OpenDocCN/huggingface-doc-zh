- en: Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/optimum-neuron/package_reference/modeling](https://huggingface.co/docs/optimum-neuron/package_reference/modeling)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/optimum.neuron/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/entry/start.abfe5599.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/scheduler.9039eef2.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/singletons.9144bb03.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/paths.e169ac99.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/entry/app.df8ec0a0.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/index.cdcc3d35.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/nodes/0.a52c6f40.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/nodes/17.048217f3.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/Tip.6f74db41.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/Docstring.fff63cfc.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/Heading.96ce3702.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/CodeBlock.e3ac94d9.js">
  prefs: []
  type: TYPE_NORMAL
- en: Generic model classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NeuronBaseModel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `NeuronBaseModel` class is available for instantiating a base Neuron model
    without a specific head. It is used as the base class for all tasks but text generation.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronBaseModel`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_base.py#L55)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Base class running compiled and optimized models on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: It implements generic methods for interacting with the Hugging Face Hub as well
    as compiling vanilla transformers models to neuron-optimized TorchScript module
    and export it using `optimum.exporters.neuron` toolchain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Class attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: model_type (`str`, *optional*, defaults to `"neuron_model"`) — The name of the
    model type to use when registering the NeuronBaseModel classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: auto_model_class (`Type`, *optional*, defaults to `AutoModel`) — The `AutoModel`
    class to be represented by the current NeuronBaseModel class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Common attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: model (`torch.jit._script.ScriptModule`) — The loaded `ScriptModule` compiled
    for neuron devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: config ([PretrainedConfig](https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: model_save_dir (`Path`) — The directory where a neuron compiled model is saved.
    By default, if the loaded model is local, the directory where the original model
    will be used. Otherwise, the cache directory will be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `get_input_static_shapes`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_base.py#L451)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Gets a dictionary of inputs with their valid static shapes.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `load_model`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_base.py#L98)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`path` (`Union[str, Path]`) — Path of the compiled model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loads a TorchScript module compiled by neuron(x)-cc compiler. It will be first
    loaded onto CPU and then moved to one or multiple [NeuronCore](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/neuroncores-arch.html).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `remove_padding`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_base.py#L548)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`outputs` (`List[torch.Tensor]`) — List of torch tensors which are inference
    output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dims` (`List[int]`) — List of dimensions in which we slice a tensor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`indices` (`List[int]`) — List of indices in which we slice a tensor along
    an axis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`padding_side` (`Literal["right", "left"]`, defaults to “right”) — The side
    on which the padding has been applied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removes padding from output tensors.
  prefs: []
  type: TYPE_NORMAL
- en: NeuronDecoderModel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `NeuronDecoderModel` class is the base class for text generation models.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronDecoderModel`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_decoder.py#L76)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Base class to convert and run pre-trained transformers decoder models on Neuron
    devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'It implements the methods to convert a pre-trained transformers decoder model
    into a Neuron transformer model by:'
  prefs: []
  type: TYPE_NORMAL
- en: transferring the checkpoint weights of the original into an optimized neuron
    graph,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: compiling the resulting graph using the Neuron compiler.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Common attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: model (`torch.nn.Module`) — The decoder model with a graph optimized for neuron
    devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: config ([PretrainedConfig](https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration of the original model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: generation_config ([GenerationConfig](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationConfig))
    — The generation configuration used by default when calling `generate()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural Language Processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following Neuron model classes are available for natural language processing
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: NeuronModelForFeatureExtraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForFeatureExtraction`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L122)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model with a BaseModelOutput for feature-extraction tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Feature Extraction model on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L135)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Mask to avoid performing attention on padding token indices.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Segment token indices to indicate first and second portions
    of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForFeatureExtraction](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForFeatureExtraction)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of feature extraction: *(Following model is compiled with neuronx compiler
    and can only be run on INF2\. Replace “neuronx” with “neuron” if you are using
    INF1.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForSentenceTransformers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForSentenceTransformers`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L195)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model for Sentence Transformers.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Sentence Transformers model on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L208)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Mask to avoid performing attention on padding token indices.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Segment token indices to indicate first and second portions
    of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForSentenceTransformers](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForSentenceTransformers)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of TEXT Sentence Transformers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForMaskedLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForMaskedLM`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L266)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model with a MaskedLMOutput for masked language modeling tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Masked language model for on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L279)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Mask to avoid performing attention on padding token indices.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Segment token indices to indicate first and second portions
    of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForMaskedLM](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForMaskedLM)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of fill mask: *(Following model is compiled with neuronx compiler and
    can only be run on INF2\. Replace “neuronx” with “neuron” if you are using INF1.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForSequenceClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForSequenceClassification`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L404)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model with a sequence classification/regression head on top (a linear
    layer on top of the pooled output) e.g. for GLUE tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Sequence Classification model on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L418)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Mask to avoid performing attention on padding token indices.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Segment token indices to indicate first and second portions
    of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForSequenceClassification](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForSequenceClassification)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of single-label classification: *(Following model is compiled with
    neuronx compiler and can only be run on INF2.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForQuestionAnswering`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L336)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model with a QuestionAnsweringModelOutput for extractive question-answering
    tasks like SQuAD.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Question Answering model on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L349)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Mask to avoid performing attention on padding token indices.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Segment token indices to indicate first and second portions
    of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForQuestionAnswering](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of question answering: *(Following model is compiled with neuronx compiler
    and can only be run on INF2.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForTokenClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForTokenClassification`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L472)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Token Classification model on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L486)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Mask to avoid performing attention on padding token indices.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, sequence_length)`,
    defaults to `None`) — Segment token indices to indicate first and second portions
    of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForTokenClassification](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForTokenClassification)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of token classification: *(Following model is compiled with neuronx
    compiler and can only be run on INF2.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForMultipleChoice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForMultipleChoice`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L553)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the `optimum.neuron.modeling.NeuronBaseModel.from_pretrained`
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`torch.jit._script.ScriptModule`) — [torch.jit._script.ScriptModule](https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html)
    is the TorchScript module with embedded NEFF(Neuron Executable File Format) compiled
    by neuron(x) compiler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron Model with a multiple choice classification head on top (a linear layer
    on top of the pooled output and a softmax) e.g. for RocStories/SWAG tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronBaseModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: Multiple choice model on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L567)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, num_choices, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary. Indices can be obtained
    using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
    See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode)
    and [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Union[torch.Tensor, None]` of shape `(batch_size, num_choices,
    sequence_length)`, defaults to `None`) — Mask to avoid performing attention on
    padding token indices. Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Union[torch.Tensor, None]` of shape `(batch_size, num_choices,
    sequence_length)`, defaults to `None`) — Segment token indices to indicate first
    and second portions of the inputs. Indices are selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `sentence A`,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `sentence B`. [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForMultipleChoice](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForMultipleChoice)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of mutliple choice: *(Following model is compiled with neuronx compiler
    and can only be run on INF2.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: NeuronModelForCausalLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronModelForCausalLM`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L640)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`model` (`torch.nn.Module`) — [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)
    is the neuron decoder graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config` (`transformers.PretrainedConfig`) — [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
    is the Model configuration class with all the parameters of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_path` (`Path`) — The directory where the compiled artifacts for the
    model are stored. It can be a temporary directory if the model has never been
    saved locally before.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generation_config` (`transformers.GenerationConfig`) — [GenerationConfig](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig)
    holds the configuration for the model generation task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neuron model with a causal language modeling head for inference on Neuron devices.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from `~neuron.modeling.NeuronDecoderModel`. Check the superclass
    documentation for the generic methods the library implements for all its model
    (such as downloading or saving)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `can_generate`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L717)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Returns True to validate the check made in `GenerationMixin.generate()`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L667)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor`) — Indices of decoder input sequence tokens
    in the vocabulary of shape `(batch_size, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cache_ids` (`torch.LongTensor`) — The indices at which the cached key and
    value for the current inputs need to be stored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_ids` (`torch.LongTensor`) — The indices of the first tokens to be processed,
    deduced form the attention masks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [NeuronModelForCausalLM](/docs/optimum.neuron/main/en/package_reference/modeling#optimum.neuron.NeuronModelForCausalLM)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of text generation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '#### `generate`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L721)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.Tensor` of shape `(batch_size, sequence_length)`) — The
    sequence used as a prompt for the generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generation_config` (`~transformers.generation.GenerationConfig`, *optional*)
    — The generation configuration to be used as base parametrization for the generation
    call. `**kwargs` passed to generate matching the attributes of `generation_config`
    will override them. If `generation_config` is not provided, default will be used,
    which had the following loading priority: 1) from the `generation_config.json`
    model file, if it exists; 2) from the model configuration. Please note that unspecified
    parameters will inherit `GenerationConfig`’s default values, whose documentation
    should be checked to parameterize generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stopping_criteria` (`Optional[transformers.generation.StoppingCriteriaList],
    defaults to` None`) — Custom stopping criteria that complement the default stopping
    criteria built from arguments and a generation config.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.Tensor`'
  prefs: []
  type: TYPE_NORMAL
- en: A `torch.FloatTensor`.
  prefs: []
  type: TYPE_NORMAL
- en: A streamlined generate() method overriding the transformers.GenerationMixin.generate()
    method.
  prefs: []
  type: TYPE_NORMAL
- en: This method uses the same logits processors/warpers and stopping criterias as
    the transformers library `generate()` method but restricts the generation to greedy
    search and sampling.
  prefs: []
  type: TYPE_NORMAL
- en: It does not support transformers `generate()` advanced options.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to [https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationMixin.generate](https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    for details on generation configuration.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `generate_tokens`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling.py#L802)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    The sequence used as a prompt for the generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selector` (`TokenSelector`) — The object implementing the generation logic
    based on transformers processors and stopping criterias.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`) — The actual input batch size. Used to avoid generating
    tokens for padded inputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. model_kwargs
    — Additional model specific kwargs will be forwarded to the `forward` function
    of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.LongTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: A `torch.LongTensor` containing the generated tokens.
  prefs: []
  type: TYPE_NORMAL
- en: Generate tokens using sampling or greedy search.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NeuronStableDiffusionPipelineBase
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.modeling_diffusion.NeuronStableDiffusionPipelineBase`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L81)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '#### `load_model`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L243)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`data_parallel_mode` (`Optional[str]`) — Mode to decide what components to
    load into both NeuronCores of a Neuron device. Can be “none”(no data parallel),
    “unet”(only load unet into both cores of each device), “all”(load the whole pipeline
    into both cores).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_path` (`Union[str, Path]`) — Path of the compiled text encoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet_path` (`Union[str, Path]`) — Path of the compiled U-NET.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae_decoder_path` (`Optional[Union[str, Path]]`, defaults to `None`) — Path
    of the compiled VAE decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae_encoder_path` (`Optional[Union[str, Path]]`, defaults to `None`) — Path
    of the compiled VAE encoder. It is optional, only used for tasks taking images
    as input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_2_path` (`Optional[Union[str, Path]]`, defaults to `None`) —
    Path of the compiled second frozen text encoder. SDXL only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dynamic_batch_size` (`bool`, defaults to `False`) — Whether enable dynamic
    batch size for neuron compiled model. If `True`, the input batch size can be a
    multiple of the batch size during the compilation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loads Stable Diffusion TorchScript modules compiled by neuron(x)-cc compiler.
    It will be first loaded onto CPU and then moved to one or multiple [NeuronCore](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/neuroncores-arch.html).
  prefs: []
  type: TYPE_NORMAL
- en: NeuronStableDiffusionPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronStableDiffusionPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L798)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_stable_diffusion.py#L33)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 7.5) — A higher guidance scale value
    encourages the model to generate images closely linked to the text `prompt` at
    the expense of lower image quality. Guidance scale is enabled when `guidance_scale
    > 1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) —
    The prompt or prompts to guide what to not include in image generation. If not
    defined, you need to pass `negative_prompt_embeds` instead. Ignored when not using
    guidance (`guidance_scale < 1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt. If it is different from the batch size used for the compiltaion, it
    will be overriden by the static batch size of neuron (except for dynamic batching).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, defaults to 0.0) — Corresponds to parameter eta (η) from the
    [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the `diffusers.schedulers.DDIMScheduler`,
    and is ignored in other schedulers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    noisy latents sampled from a Gaussian distribution, to be used as inputs for image
    generation. Can be used to tweak the same generation with different prompts. If
    not provided, a latents tensor is generated by sampling using the supplied random
    `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs (prompt weighting). If
    not provided, text embeddings are generated from the `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated negative text embeddings. Can be used to easily tweak text inputs
    (prompt weighting). If not provided, `negative_prompt_embeds` are generated from
    the `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`Optional[str]`, defaults to `"pil"`) — The output format of
    the generated image. Choose between `PIL.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback` (`Optional[Callable]`, defaults to `None`) — A function that calls
    every `callback_steps` steps during inference. The function is called with the
    following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_steps` (`int`, defaults to 1) — The frequency at which the `callback`
    function is called. If not specified, the callback is called at every step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, defaults to `None`) — A kwargs dictionary
    that if specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_rescale` (`float`, defaults to 0.0) — Guidance rescale factor from
    [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If `return_dict` is `True`, `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  prefs: []
  type: TYPE_NORMAL
- en: The call function to the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: NeuronStableDiffusionImg2ImgPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronStableDiffusionImg2ImgPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L802)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_stable_diffusion_img2img.py#L83)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`Optional["PipelineImageInput"]`, defaults to `None`) — `Image`, numpy
    array or tensor representing an image batch to be used as the starting point.
    For both numpy array and pytorch tensor, the expected value range is between `[0,
    1]` If it’s a tensor or a list or tensors, the expected shape should be `(B, C,
    H, W)` or `(C, H, W)`. If it is a numpy array or a list of arrays, the expected
    shape should be `(B, H, W, C)` or `(H, W, C)` It can also accept image latents
    as `image`, but if passing latents directly it is not encoded again.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, defaults to 0.8) — Indicates extent to transform the reference
    `image`. Must be between 0 and 1\. `image` is used as a starting point and more
    noise is added the higher the `strength`. The number of denoising steps depends
    on the amount of noise initially added. When `strength` is 1, added noise is maximum
    and the denoising process runs for the full number of iterations specified in
    `num_inference_steps`. A value of 1 essentially ignores `image`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference. This parameter is modulated by `strength`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 7.5) — A higher guidance scale value
    encourages the model to generate images closely linked to the text `prompt` at
    the expense of lower image quality. Guidance scale is enabled when `guidance_scale
    > 1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`Optional[Union[str, List[str]`, defaults to `None`) — The
    prompt or prompts to guide what to not include in image generation. If not defined,
    you need to pass `negative_prompt_embeds` instead. Ignored when not using guidance
    (`guidance_scale < 1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt. If it is different from the batch size used for the compiltaion, it
    will be overriden by the static batch size of neuron (except for dynamic batching).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, defaults to 0.0) — Corresponds to parameter eta (η) from the
    [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the `diffusers.schedulers.DDIMScheduler`,
    and is ignored in other schedulers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs (prompt weighting). If
    not provided, text embeddings are generated from the `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated negative text embeddings. Can be used to easily tweak text inputs
    (prompt weighting). If not provided, `negative_prompt_embeds` are generated from
    the `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`Optional[str]`, defaults to `"pil"`) — The output format of
    the generated image. Choose between `PIL.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback` (`Optional[Callable]`, defaults to `None`) — A function that calls
    every `callback_steps` steps during inference. The function is called with the
    following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_steps` (`int`, defaults to 1) — The frequency at which the `callback`
    function is called. If not specified, the callback is called at every step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, defaults to `None`) — A kwargs dictionary
    that if specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If `return_dict` is `True`, `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  prefs: []
  type: TYPE_NORMAL
- en: The call function to the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: NeuronStableDiffusionInpaintPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronStableDiffusionInpaintPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L808)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_stable_diffusion_inpaint.py#L48)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`Optional["PipelineImageInput"]`, defaults to `None`) — `Image`, numpy
    array or tensor representing an image batch to be inpainted (which parts of the
    image to be masked out with `mask_image` and repainted according to `prompt`).
    For both numpy array and pytorch tensor, the expected value range is between `[0,
    1]` If it’s a tensor or a list or tensors, the expected shape should be `(B, C,
    H, W)` or `(C, H, W)`. If it is a numpy array or a list of arrays, the expected
    shape should be `(B, H, W, C)` or `(H, W, C)` It can also accept image latents
    as `image`, but if passing latents directly it is not encoded again.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_image` (`Optional["PipelineImageInput"]`, defaults to `None`) — `Image`,
    numpy array or tensor representing an image batch to mask `image`. White pixels
    in the mask are repainted while black pixels are preserved. If `mask_image` is
    a PIL image, it is converted to a single channel (luminance) before use. If it’s
    a numpy array or pytorch tensor, it should contain one color channel (L) instead
    of 3, so the expected shape for pytorch tensor would be `(B, 1, H, W)`, `(B, H,
    W)`, `(1, H, W)`, `(H, W)`. And for numpy array would be for `(B, H, W, 1)`, `(B,
    H, W)`, `(H, W, 1)`, or `(H, W)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, defaults to 1.0) — Indicates extent to transform the reference
    `image`. Must be between 0 and 1\. `image` is used as a starting point and more
    noise is added the higher the `strength`. The number of denoising steps depends
    on the amount of noise initially added. When `strength` is 1, added noise is maximum
    and the denoising process runs for the full number of iterations specified in
    `num_inference_steps`. A value of 1 essentially ignores `image`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference. This parameter is modulated by `strength`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 7.5) — A higher guidance scale value
    encourages the model to generate images closely linked to the text `prompt` at
    the expense of lower image quality. Guidance scale is enabled when `guidance_scale
    > 1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`Optional[Union[str, List[str]`, defaults to `None`) — The
    prompt or prompts to guide what to not include in image generation. If not defined,
    you need to pass `negative_prompt_embeds` instead. Ignored when not using guidance
    (`guidance_scale < 1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt. If it is different from the batch size used for the compiltaion, it
    will be overriden by the static batch size of neuron (except for dynamic batching).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, defaults to 0.0) — Corresponds to parameter eta (η) from the
    [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the `diffusers.schedulers.DDIMScheduler`,
    and is ignored in other schedulers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    noisy latents sampled from a Gaussian distribution, to be used as inputs for image
    generation. Can be used to tweak the same generation with different prompts. If
    not provided, a latents tensor is generated by sampling using the supplied random
    `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs (prompt weighting). If
    not provided, text embeddings are generated from the `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated negative text embeddings. Can be used to easily tweak text inputs
    (prompt weighting). If not provided, `negative_prompt_embeds` are generated from
    the `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`Optional[str]`, defaults to `"pil"`) — The output format of
    the generated image. Choose between `PIL.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback` (`Optional[Callable]`, defaults to `None`) — A function that calls
    every `callback_steps` steps during inference. The function is called with the
    following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_steps` (`int`, defaults to 1) — The frequency at which the `callback`
    function is called. If not specified, the callback is called at every step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, defaults to `None`) — A kwargs dictionary
    that if specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, defaults to `None`) — Number of layers to be skipped from
    CLIP while computing the prompt embeddings. A value of 1 means that the output
    of the pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If `return_dict` is `True`, `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  prefs: []
  type: TYPE_NORMAL
- en: The call function to the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: NeuronLatentConsistencyModelPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronLatentConsistencyModelPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L814)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_latent_consistency_text2img.py#L67)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_inference_steps` (`Optional[int]`, defaults to `None`) — The original
    number of inference steps use to generate a linearly-spaced timestep schedule,
    from which we will draw `num_inference_steps` evenly spaced timesteps from as
    our final timestep schedule, following the Skipping-Step method in the paper (see
    Section 4.3). If not set this will default to the scheduler’s `original_inference_steps`
    attribute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 8.5) — A higher guidance scale value
    encourages the model to generate images closely linked to the text `prompt` at
    the expense of lower image quality. Guidance scale is enabled when `guidance_scale
    > 1`. Note that the original latent consistency models paper uses a different
    CFG formulation where the guidance scales are decreased by 1 (so in the paper
    formulation CFG is enabled when `guidance_scale > 0`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    noisy latents sampled from a Gaussian distribution, to be used as inputs for image
    generation. Can be used to tweak the same generation with different prompts. If
    not provided, a latents tensor is generated by sampling using the supplied random
    `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs (prompt weighting). If
    not provided, text embeddings are generated from the `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, defaults to `"pil"`) — The output format of the generated
    image. Choose between `PIL.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `~pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`Optional[Dict[str, Any]]`, defaults to `None`) —
    A kwargs dictionary that if specified is passed along to the `AttentionProcessor`
    as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`Optional[int]`, defaults to `None`) — Number of layers to be
    skipped from CLIP while computing the prompt embeddings. A value of 1 means that
    the output of the pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Optional[Callable]`, defaults to `None`) — A function
    that calls at the end of each denoising steps during the inference. The function
    is called with the following arguments: `callback_on_step_end(self: DiffusionPipeline,
    step: int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include
    a list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List[str]`, defaults to `["latents"]`)
    — The list of tensor inputs for the `callback_on_step_end` function. The tensors
    specified in the list will be passed as `callback_kwargs` argument. You will only
    be able to include variables listed in the `._callback_tensor_inputs` attribute
    of your pipeine class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If `return_dict` is `True`, `diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  prefs: []
  type: TYPE_NORMAL
- en: The call function to the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: NeuronStableDiffusionXLPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronStableDiffusionXLPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L873)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_stable_diffusion_xl.py#L38)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.
    instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to be sent to the `tokenizer_2` and `text_encoder_2`. If not defined,
    `prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`Optional[float]`, defaults to `None`) — When specified, determines
    the fraction (between 0.0 and 1.0) of the total denoising process to be completed
    before it is intentionally prematurely terminated. As a result, the returned sample
    will still retain a substantial amount of noise as determined by the discrete
    timesteps selected by the scheduler. The denoising_end parameter should ideally
    be utilized when this pipeline forms a part of a “Mixture of Denoisers” multi-pipeline
    setup, as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 5.0) — Guidance scale as defined in
    [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598). `guidance_scale`
    is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) —
    The prompt or prompts not to guide the image generation. If not defined, one has
    to pass `negative_prompt_embeds` instead. Ignored when not using guidance (i.e.,
    ignored if `guidance_scale` is less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`Optional[Union[str, List[str]]]`, defaults to `None`)
    — The prompt or prompts not to guide the image generation to be sent to `tokenizer_2`
    and `text_encoder_2`. If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt. If it is different from the batch size used for the compiltaion, it
    will be overriden by the static batch size of neuron (except for dynamic batching).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, defaults to 0.0) — Corresponds to parameter eta (η) in the
    DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to `schedulers.DDIMScheduler`, will be ignored for others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    noisy latents, sampled from a Gaussian distribution, to be used as inputs for
    image generation. Can be used to tweak the same generation with different prompts.
    If not provided, a latents tensor will ge generated by sampling using the supplied
    random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated negative text embeddings. Can be used to easily tweak text inputs,
    *e.g.* prompt weighting. If not provided, negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated pooled text embeddings. Can be used to easily tweak text inputs,
    *e.g.* prompt weighting. If not provided, pooled text embeddings will be generated
    from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to
    `None`) — Pre-generated negative pooled text embeddings. Can be used to easily
    tweak text inputs, *e.g.* prompt weighting. If not provided, pooled negative_prompt_embeds
    will be generated from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`Optional[str]`, defaults to `"pil"`) — The output format of
    the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `diffusers.pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback` (`Optional[Callable]`, defaults to `None`) — A function that will
    be called every `callback_steps` steps during inference. The function will be
    called with the following arguments: `callback(step: int, timestep: int, latents:
    torch.FloatTensor)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_steps` (`int`, defaults to 1) — The frequency at which the `callback`
    function will be called. If not specified, the callback will be called at every
    step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, defaults to `None`) — A kwargs dictionary
    that if specified is passed along to the `AttentionProcessor` as defined under
    `self.processor` in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) — Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `φ` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Optional[Tuple[int, int]]`, defaults to (1024, 1024)) — If
    `original_size` is not the same as `target_size` the image will appear to be down-
    or upsampled. `original_size` defaults to `(width, height)` if not specified.
    Part of SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, defaults to (0, 0)) — `crops_coords_top_left`
    can be used to generate an image that appears to be “cropped” from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`,defaults to (1024, 1024)) — For most cases, `target_size`
    should be set to the desired height and width of the generated image. If not specified
    it will default to `(width, height)`. Part of SDXL’s micro-conditioning as explained
    in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, defaults to (1024, 1024)) — To negatively
    condition the generation process based on a specific image resolution. Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, defaults to (0, 0)) — To negatively
    condition the generation process based on a specific crop coordinates. Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, defaults to (1024, 1024)) — To negatively
    condition the generation process based on a target image resolution. It should
    be as same as the `target_size` for most cases. Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`Optional[int]`, defaults to `None`) — Number of layers to be
    skipped from CLIP while computing the prompt embeddings. A value of 1 means that
    the output of the pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` or
    `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` if
    `return_dict` is True, otherwise a `tuple`. When returning a tuple, the first
    element is a list with the generated images.'
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: NeuronStableDiffusionXLImg2ImgPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronStableDiffusionXLImg2ImgPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L877)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_stable_diffusion_xl_img2img.py#L109)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.
    instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to be sent to the `tokenizer_2` and `text_encoder_2`. If not defined,
    `prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`Optional["PipelineImageInput"]`, defaults to `None`) — The image(s)
    to modify with the pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, defaults to 0.3) — Conceptually, indicates how much to
    transform the reference `image`. Must be between 0 and 1\. `image` will be used
    as a starting point, adding more noise to it the larger the `strength`. The number
    of denoising steps depends on the amount of noise initially added. When `strength`
    is 1, added noise will be maximum and the denoising process will run for the full
    number of iterations specified in `num_inference_steps`. A value of 1, therefore,
    essentially ignores `image`. Note that in the case of `denoising_start` being
    declared as an integer, the value of `strength` will be ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_start` (`Optional[float]`, defaults to `None`) — When specified,
    indicates the fraction (between 0.0 and 1.0) of the total denoising process to
    be bypassed before it is initiated. Consequently, the initial part of the denoising
    process is skipped and it is assumed that the passed `image` is a partly denoised
    image. Note that when this is specified, strength will be ignored. The `denoising_start`
    parameter is particularly beneficial when this pipeline is integrated into a “Mixture
    of Denoisers” multi-pipeline setup, as detailed in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`Optional[float]`, defaults to `None`) — When specified, determines
    the fraction (between 0.0 and 1.0) of the total denoising process to be completed
    before it is intentionally prematurely terminated. As a result, the returned sample
    will still retain a substantial amount of noise (ca. final 20% of timesteps still
    needed) and should be denoised by a successor pipeline that has `denoising_start`
    set to 0.8 so that it only denoises the final 20% of the scheduler. The denoising_end
    parameter should ideally be utilized when this pipeline forms a part of a “Mixture
    of Denoisers” multi-pipeline setup, as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 7.5) — Guidance scale as defined in
    [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598). `guidance_scale`
    is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) —
    The prompt or prompts not to guide the image generation. If not defined, one has
    to pass `negative_prompt_embeds` instead. Ignored when not using guidance (i.e.,
    ignored if `guidance_scale` is less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`Optional[Union[str, List[str]]]`, defaults to `None`)
    — The prompt or prompts not to guide the image generation to be sent to `tokenizer_2`
    and `text_encoder_2`. If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt. If it is different from the batch size used for the compiltaion, it
    will be overriden by the static batch size of neuron (except for dynamic batching).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, defaults to 0.0) — Corresponds to parameter eta (η) in the
    DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to `schedulers.DDIMScheduler`, will be ignored for others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    noisy latents, sampled from a Gaussian distribution, to be used as inputs for
    image generation. Can be used to tweak the same generation with different prompts.
    If not provided, a latents tensor will ge generated by sampling using the supplied
    random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated negative text embeddings. Can be used to easily tweak text inputs,
    *e.g.* prompt weighting. If not provided, negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated pooled text embeddings. Can be used to easily tweak text inputs,
    *e.g.* prompt weighting. If not provided, pooled text embeddings will be generated
    from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to
    `None`) — Pre-generated negative pooled text embeddings. Can be used to easily
    tweak text inputs, *e.g.* prompt weighting. If not provided, pooled negative_prompt_embeds
    will be generated from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`Optional[str]`, defaults to `"pil"`) — The output format of
    the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback` (`Optional[Callable]`, defaults to `None`) — A function that will
    be called every `callback_steps` steps during inference. The function will be
    called with the following arguments: `callback(step: int, timestep: int, latents:
    torch.FloatTensor)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_stcallback_steps` (`int`, defaults to 1) — The frequency at which
    the `callback` function will be called. If not specified, the callback will be
    called at every step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`Optional[Dict[str, Any]]`, defaults to `None`) —
    A kwargs dictionary that if specified is passed along to the `AttentionProcessor`
    as defined under `self.processor` in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_rescale` (`float`, defaults to 0.0) — Guidance rescale factor proposed
    by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `φ` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Optional[Tuple[int, int]]`, defaults to (1024, 1024)) — If
    `original_size` is not the same as `target_size` the image will appear to be down-
    or upsampled. `original_size` defaults to `(width, height)` if not specified.
    Part of SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, defaults to (0, 0)) — `crops_coords_top_left`
    can be used to generate an image that appears to be “cropped” from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`,defaults to (1024, 1024)) — For most cases, `target_size`
    should be set to the desired height and width of the generated image. If not specified
    it will default to `(width, height)`. Part of SDXL’s micro-conditioning as explained
    in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, defaults to (1024, 1024)) — To negatively
    condition the generation process based on a specific image resolution. Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, defaults to (0, 0)) — To negatively
    condition the generation process based on a specific crop coordinates. Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, defaults to (1024, 1024)) — To negatively
    condition the generation process based on a target image resolution. It should
    be as same as the `target_size` for most cases. Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aesthetic_score` (`float`, defaults to 6.0) — Used to simulate an aesthetic
    score of the generated image by influencing the positive text condition. Part
    of SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_aesthetic_score` (`float`, defaults to 2.5) — Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`Optional[int]`, defaults to `None`) — Number of layers to be
    skipped from CLIP while computing the prompt embeddings. A value of 1 means that
    the output of the pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple. When returning a tuple, the first element is a list
    with the generated images.'
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: NeuronStableDiffusionXLInpaintPipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class optimum.neuron.NeuronStableDiffusionXLInpaintPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/modeling_diffusion.py#L883)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/optimum-neuron/blob/main/optimum/neuron/pipelines/diffusers/pipeline_stable_diffusion_xl_inpaint.py#L80)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.
    instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`Optional[Union[str, List[str]]]`, defaults to `None`) — The prompt
    or prompts to be sent to the `tokenizer_2` and `text_encoder_2`. If not defined,
    `prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`Optional["PipelineImageInput"]`, defaults to `None`) — `Image`, or
    tensor representing an image batch which will be inpainted, *i.e.* parts of the
    image will be masked out with `mask_image` and repainted according to `prompt`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_image` (`Optional["PipelineImageInput"]`, defaults to `None`) — `Image`,
    or tensor representing an image batch, to mask `image`. White pixels in the mask
    will be repainted, while black pixels will be preserved. If `mask_image` is a
    PIL image, it will be converted to a single channel (luminance) before use. If
    it’s a tensor, it should contain one color channel (L) instead of 3, so the expected
    shape would be `(B, H, W, 1)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`padding_mask_crop` (`Optional[int]`, defaults to `None`) — The size of margin
    in the crop to be applied to the image and masking. If `None`, no crop is applied
    to image and mask_image. If `padding_mask_crop` is not `None`, it will first find
    a rectangular region with the same aspect ration of the image and contains all
    masked area, and then expand that area based on `padding_mask_crop`. The image
    and mask_image will then be cropped based on the expanded area before resizing
    to the original image size for inpainting. This is useful when the masked area
    is small while the image is large and contain information inreleant for inpainging,
    such as background.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, defaults to 0.9999) — Conceptually, indicates how much
    to transform the masked portion of the reference `image`. Must be between 0 and
    1\. `image` will be used as a starting point, adding more noise to it the larger
    the `strength`. The number of denoising steps depends on the amount of noise initially
    added. When `strength` is 1, added noise will be maximum and the denoising process
    will run for the full number of iterations specified in `num_inference_steps`.
    A value of 1, therefore, essentially ignores the masked portion of the reference
    `image`. Note that in the case of `denoising_start` being declared as an integer,
    the value of `strength` will be ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, defaults to 50) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`Optional[List[int]]`, defaults to `None`) — Custom timesteps
    to use for the denoising process with schedulers which support a `timesteps` argument
    in their `set_timesteps` method. If not defined, the default behavior when `num_inference_steps`
    is passed will be used. Must be in descending order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_start` (`Optional[float]`, defaults to `None`) — When specified,
    indicates the fraction (between 0.0 and 1.0) of the total denoising process to
    be bypassed before it is initiated. Consequently, the initial part of the denoising
    process is skipped and it is assumed that the passed `image` is a partly denoised
    image. Note that when this is specified, strength will be ignored. The `denoising_start`
    parameter is particularly beneficial when this pipeline is integrated into a “Mixture
    of Denoisers” multi-pipeline setup, as detailed in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`Optional[float]`, defaults to `None`) — When specified, determines
    the fraction (between 0.0 and 1.0) of the total denoising process to be completed
    before it is intentionally prematurely terminated. As a result, the returned sample
    will still retain a substantial amount of noise (ca. final 20% of timesteps still
    needed) and should be denoised by a successor pipeline that has `denoising_start`
    set to 0.8 so that it only denoises the final 20% of the scheduler. The denoising_end
    parameter should ideally be utilized when this pipeline forms a part of a “Mixture
    of Denoisers” multi-pipeline setup, as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, defaults to 7.5) — Guidance scale as defined in
    [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598). `guidance_scale`
    is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`Optional[Union[str, List[str]]]`, defaults to `None`) —
    The prompt or prompts not to guide the image generation. If not defined, one has
    to pass `negative_prompt_embeds` instead. Ignored when not using guidance (i.e.,
    ignored if `guidance_scale` is less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`Optional[Union[str, List[str]]]`, defaults to `None`)
    — The prompt or prompts not to guide the image generation to be sent to `tokenizer_2`
    and `text_encoder_2`. If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated negative text embeddings. Can be used to easily tweak text inputs,
    *e.g.* prompt weighting. If not provided, negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to `None`)
    — Pre-generated pooled text embeddings. Can be used to easily tweak text inputs,
    *e.g.* prompt weighting. If not provided, pooled text embeddings will be generated
    from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`Optional[torch.FloatTensor]`, defaults to
    `None`) — Pre-generated negative pooled text embeddings. Can be used to easily
    tweak text inputs, *e.g.* prompt weighting. If not provided, pooled negative_prompt_embeds
    will be generated from `negative_prompt` input argument. ip_adapter_image — (`Optional[PipelineImageInput]`,
    defaults to `None`): Optional image input to work with IP Adapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, defaults to 1) — The number of images to generate
    per prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, defaults to 0.0) — Corresponds to parameter eta (η) in the
    DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to `schedulers.DDIMScheduler`, will be ignored for others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`Optional[Union[torch.Generator, List[torch.Generator]]]`, defaults
    to `None`) — One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`Optional[torch.FloatTensor]`, defaults to `None`) — Pre-generated
    noisy latents, sampled from a Gaussian distribution, to be used as inputs for
    image generation. Can be used to tweak the same generation with different prompts.
    If not provided, a latents tensor will ge generated by sampling using the supplied
    random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`Optional[str]`, defaults to `"pil"`) — The output format of
    the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, defaults to `True`) — Whether or not to return a `~pipelines.stable_diffusion.StableDiffusionPipelineOutput`
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`Optional[Dict[str, Any]]`, defaults to `None`) —
    A kwargs dictionary that if specified is passed along to the `AttentionProcessor`
    as defined under `self.processor` in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Tuple[int]`, defaults to (1024, 1024)) — If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXL’s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, defaults to (0, 0)) — `crops_coords_top_left`
    can be used to generate an image that appears to be “cropped” from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`, defaults to (1024, 1024)) — For most cases, `target_size`
    should be set to the desired height and width of the generated image. If not specified
    it will default to `(height, width)`. Part of SDXL’s micro-conditioning as explained
    in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, defaults to (1024, 1024)) — To negatively
    condition the generation process based on a specific image resolution. Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, defaults to (0, 0)) — To negatively
    condition the generation process based on a specific crop coordinates. Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, defaults to (1024, 1024)) — To negatively
    condition the generation process based on a target image resolution. It should
    be as same as the `target_size` for most cases. Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aesthetic_score` (`float`, defaults to 6.0) — Used to simulate an aesthetic
    score of the generated image by influencing the positive text condition. Part
    of SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_aesthetic_score` (`float`, defaults to 2.5) — Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`Optional[int]`, defaults to `None`) — Number of layers to be
    skipped from CLIP while computing the prompt embeddings. A value of 1 means that
    the output of the pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Optional[Callable[[int, int, Dict], None]]`, defaults
    to `None`) — A function that calls at the end of each denoising steps during the
    inference. The function is called with the following arguments: `callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs`
    will include a list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List[str]`, defaults to [“latents”])
    — The list of tensor inputs for the `callback_on_step_end` function. The tensors
    specified in the list will be passed as `callback_kwargs` argument. You will only
    be able to include variables listed in the `._callback_tensor_inputs` attribute
    of your pipeline class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: '`diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple.` tuple. When returning a tuple, the first element
    is a list with the generated images.'
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
