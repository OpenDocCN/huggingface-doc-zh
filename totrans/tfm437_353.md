# LayoutLMv3

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv3](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv3)

## æ¦‚è¿°

LayoutLMv3æ¨¡å‹ç”±Yupan Huangã€Tengchao Lvã€Lei Cuiã€Yutong Luã€Furu Weiåœ¨[LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387)ä¸­æå‡ºã€‚LayoutLMv3é€šè¿‡ä½¿ç”¨è¡¥ä¸åµŒå…¥ï¼ˆå¦‚[ViT](vit)ä¸­çš„æ–¹å¼ï¼‰ç®€åŒ–äº†[LayoutLMv2](layoutlmv2)ï¼Œå¹¶åœ¨3ä¸ªç›®æ ‡ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†é¢„è®­ç»ƒï¼šæ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMLMï¼‰ã€æ©ç å›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰å’Œå•è¯-è¡¥ä¸å¯¹é½ï¼ˆWPAï¼‰ã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*è‡ªç›‘ç£é¢„è®­ç»ƒæŠ€æœ¯åœ¨æ–‡æ¡£AIé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚å¤§å¤šæ•°å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡ç›®æ ‡æ¥å­¦ä¹ æ–‡æœ¬æ¨¡æ€ä¸Šçš„åŒå‘è¡¨ç¤ºï¼Œä½†å®ƒä»¬åœ¨å›¾åƒæ¨¡æ€çš„é¢„è®­ç»ƒç›®æ ‡ä¸Šæœ‰æ‰€ä¸åŒã€‚è¿™ç§å·®å¼‚å¢åŠ äº†å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ çš„éš¾åº¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†LayoutLMv3ï¼Œç”¨äºä¸ºæ–‡æ¡£AIé¢„è®­ç»ƒå¤šæ¨¡æ€Transformersï¼Œç»Ÿä¸€æ–‡æœ¬å’Œå›¾åƒæ©ç ã€‚æ­¤å¤–ï¼ŒLayoutLMv3è¿˜ä½¿ç”¨äº†å•è¯-è¡¥ä¸å¯¹é½ç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒï¼Œé€šè¿‡é¢„æµ‹æ–‡æœ¬å•è¯çš„ç›¸åº”å›¾åƒè¡¥ä¸æ˜¯å¦è¢«æ©ç æ¥å­¦ä¹ è·¨æ¨¡æ€å¯¹é½ã€‚ç®€å•çš„ç»Ÿä¸€æ¶æ„å’Œè®­ç»ƒç›®æ ‡ä½¿LayoutLMv3æˆä¸ºæ–‡æœ¬ä¸­å¿ƒå’Œå›¾åƒä¸­å¿ƒæ–‡æ¡£AIä»»åŠ¡çš„é€šç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLayoutLMv3ä¸ä»…åœ¨æ–‡æœ¬ä¸­å¿ƒä»»åŠ¡ï¼ˆå¦‚è¡¨å•ç†è§£ã€æ”¶æ®ç†è§£å’Œæ–‡æ¡£è§†è§‰é—®ç­”ï¼‰ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€Œä¸”åœ¨å›¾åƒä¸­å¿ƒä»»åŠ¡ï¼ˆå¦‚æ–‡æ¡£å›¾åƒåˆ†ç±»å’Œæ–‡æ¡£å¸ƒå±€åˆ†æï¼‰ä¸­ä¹Ÿå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚*

![drawing](../Images/af2a6f9e13d097092393e586cc161f9d.png) LayoutLMv3æ¶æ„ã€‚æ‘˜è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2204.08387)ã€‚

è¯¥æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚è¯¥æ¨¡å‹çš„TensorFlowç‰ˆæœ¬ç”±[chriskoo](https://huggingface.co/chriskoo)ã€[tokec](https://huggingface.co/tokec)å’Œ[lre](https://huggingface.co/lre)æ·»åŠ ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/microsoft/unilm/tree/master/layoutlmv3)æ‰¾åˆ°ã€‚

## ä½¿ç”¨æç¤º

+   åœ¨æ•°æ®å¤„ç†æ–¹é¢ï¼ŒLayoutLMv3ä¸å…¶å‰èº«[LayoutLMv2](layoutlmv2)ç›¸åŒï¼Œåªæ˜¯ï¼š

    +   å›¾åƒéœ€è¦è°ƒæ•´å¤§å°å¹¶ä½¿ç”¨å¸¸è§„RGBæ ¼å¼çš„é€šé“è¿›è¡Œå½’ä¸€åŒ–ã€‚å¦ä¸€æ–¹é¢ï¼ŒLayoutLMv2åœ¨å†…éƒ¨å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ï¼Œå¹¶æœŸæœ›é€šé“ä»¥BGRæ ¼å¼æä¾›ã€‚

    +   æ–‡æœ¬ä½¿ç”¨å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰è¿›è¡Œæ ‡è®°åŒ–ï¼Œè€Œä¸æ˜¯WordPieceã€‚ç”±äºæ•°æ®é¢„å¤„ç†ä¸­çš„è¿™äº›å·®å¼‚ï¼Œå¯ä»¥ä½¿ç”¨[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)ï¼Œå®ƒå†…éƒ¨ç»“åˆäº†[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)ï¼ˆç”¨äºå›¾åƒæ¨¡æ€ï¼‰å’Œ[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)/[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)ï¼ˆç”¨äºæ–‡æœ¬æ¨¡æ€ï¼‰æ¥ä¸ºæ¨¡å‹å‡†å¤‡æ‰€æœ‰æ•°æ®ã€‚

+   å…³äº[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬å‚è€ƒå…¶å‰èº«çš„[ä½¿ç”¨æŒ‡å—](layoutlmv2#usage-layoutlmv2processor)ã€‚

## èµ„æº

Hugging Faceå®˜æ–¹å’Œç¤¾åŒºï¼ˆğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨LayoutLMv3ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ªPull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æ ¸ï¼èµ„æºåº”è¯¥æœ€å¥½å±•ç¤ºä¸€äº›æ–°ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚

LayoutLMv3å‡ ä¹ä¸LayoutLMv2ç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬è¿˜åŒ…å«äº†æ‚¨å¯ä»¥ä¸ºLayoutLMv3ä»»åŠ¡è°ƒæ•´çš„LayoutLMv2èµ„æºã€‚åœ¨å‡†å¤‡æ¨¡å‹æ•°æ®æ—¶ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)ï¼

+   LayoutLMv3çš„æ¼”ç¤ºç¬”è®°æœ¬å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/LayoutLMv3)æ‰¾åˆ°ã€‚

+   æ¼”ç¤ºè„šæœ¬å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3)æ‰¾åˆ°ã€‚

æ–‡æœ¬åˆ†ç±»

+   è¿™ä¸ª[ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/RVL-CDIP/Fine_tuning_LayoutLMv2ForSequenceClassification_on_RVL_CDIP.ipynb)æ”¯æŒ[LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)ã€‚

+   [æ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/sequence_classification)

æ ‡è®°åˆ†ç±»

+   è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv3/Fine_tune_LayoutLMv3_on_FUNSD_(HuggingFace_Trainer).ipynb)æ”¯æŒ[LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)ã€‚

+   ä¸€ä¸ªå…³äºå¦‚ä½•ä½¿ç”¨[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)è¿›è¡Œæ¨æ–­çš„[ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Inference_with_LayoutLMv2ForTokenClassification.ipynb)ï¼Œä»¥åŠä¸€ä¸ªå…³äºå¦‚ä½•åœ¨æ²¡æœ‰æ ‡ç­¾çš„æƒ…å†µä¸‹ä½¿ç”¨[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)è¿›è¡Œæ¨æ–­çš„[ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/True_inference_with_LayoutLMv2ForTokenClassification_%2B_Gradio_demo.ipynb)ã€‚

+   ä¸€ä¸ªå…³äºå¦‚ä½•ä½¿ç”¨ğŸ¤— Trainerå¯¹[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)è¿›è¡Œå¾®è°ƒçš„[ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Fine_tuning_LayoutLMv2ForTokenClassification_on_FUNSD_using_HuggingFace_Trainer.ipynb)ã€‚

+   [æ ‡è®°åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/token_classification)

é—®ç­”

+   è¿™ä¸ª[ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/DocVQA/Fine_tuning_LayoutLMv2ForQuestionAnswering_on_DocVQA.ipynb)æ”¯æŒ[LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)ã€‚

+   [é—®ç­”ä»»åŠ¡æŒ‡å—](../tasks/question_answering)

**æ–‡æ¡£é—®ç­”**

+   [æ–‡æ¡£é—®ç­”ä»»åŠ¡æŒ‡å—](../tasks/document_question_answering)

## LayoutLMv3Config

### `class transformers.LayoutLMv3Config`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/configuration_layoutlmv3.py#L40)

```py
( vocab_size = 50265 hidden_size = 768 num_hidden_layers = 12 num_attention_heads = 12 intermediate_size = 3072 hidden_act = 'gelu' hidden_dropout_prob = 0.1 attention_probs_dropout_prob = 0.1 max_position_embeddings = 512 type_vocab_size = 2 initializer_range = 0.02 layer_norm_eps = 1e-05 pad_token_id = 1 bos_token_id = 0 eos_token_id = 2 max_2d_position_embeddings = 1024 coordinate_size = 128 shape_size = 128 has_relative_attention_bias = True rel_pos_bins = 32 max_rel_pos = 128 rel_2d_pos_bins = 64 max_rel_2d_pos = 256 has_spatial_attention_bias = True text_embed = True visual_embed = True input_size = 224 num_channels = 3 patch_size = 16 classifier_dropout = None **kwargs )
```

å‚æ•°

+   `vocab_size` (`int`, *optional*, é»˜è®¤ä¸º50265) â€” LayoutLMv3æ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨è°ƒç”¨[LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ã€‚

+   `hidden_size` (`int`, *optional*, é»˜è®¤ä¸º768) â€” ç¼–ç å™¨å±‚å’Œæ± åŒ–å±‚çš„ç»´åº¦ã€‚

+   `num_hidden_layers` (`int`, *optional*, é»˜è®¤ä¸º12) â€” Transformerç¼–ç å™¨ä¸­éšè—å±‚çš„æ•°é‡ã€‚

+   `num_attention_heads` (`int`, *optional*, é»˜è®¤ä¸º 12) â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `intermediate_size` (`int`, *optional*, é»˜è®¤ä¸º 3072) â€” Transformerç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆå³å‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `hidden_act` (`str` æˆ– `function`, *optional*, é»˜è®¤ä¸º `"gelu"`) â€” ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ `"gelu"`, `"relu"`, `"selu"` å’Œ `"gelu_new"`ã€‚

+   `hidden_dropout_prob` (`float`, *optional*, é»˜è®¤ä¸º 0.1) â€” åµŒå…¥ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„dropoutæ¦‚ç‡ã€‚

+   `attention_probs_dropout_prob` (`float`, *optional*, é»˜è®¤ä¸º 0.1) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„dropoutæ¯”ç‡ã€‚

+   `max_position_embeddings` (`int`, *optional*, é»˜è®¤ä¸º 512) â€” è¯¥æ¨¡å‹å¯èƒ½ä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚é€šå¸¸è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ512æˆ–1024æˆ–2048ï¼‰ã€‚

+   `type_vocab_size` (`int`, *optional*, é»˜è®¤ä¸º 2) â€” åœ¨è°ƒç”¨ [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model) æ—¶ä¼ é€’çš„ `token_type_ids` çš„è¯æ±‡è¡¨å¤§å°ã€‚

+   `initializer_range` (`float`, *optional*, é»˜è®¤ä¸º 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `layer_norm_eps` (`float`, *optional*, é»˜è®¤ä¸º 1e-5) â€” å±‚å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„epsilonã€‚

+   `max_2d_position_embeddings` (`int`, *optional*, é»˜è®¤ä¸º 1024) â€” 2Dä½ç½®åµŒå…¥å¯èƒ½ä½¿ç”¨çš„æœ€å¤§å€¼ã€‚é€šå¸¸è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ1024ï¼‰ã€‚

+   `coordinate_size` (`int`, *optional*, é»˜è®¤ä¸º `128`) â€” åæ ‡åµŒå…¥çš„ç»´åº¦ã€‚

+   `shape_size` (`int`, *optional*, é»˜è®¤ä¸º `128`) â€” å®½åº¦å’Œé«˜åº¦åµŒå…¥çš„ç»´åº¦ã€‚

+   `has_relative_attention_bias` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦åœ¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ä½¿ç”¨ç›¸å¯¹æ³¨æ„åŠ›åç½®ã€‚

+   `rel_pos_bins` (`int`, *optional*, é»˜è®¤ä¸º 32) â€” åœ¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ä½¿ç”¨çš„ç›¸å¯¹ä½ç½®æ¡¶çš„æ•°é‡ã€‚

+   `max_rel_pos` (`int`, *optional*, é»˜è®¤ä¸º 128) â€” åœ¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ä½¿ç”¨çš„æœ€å¤§ç›¸å¯¹ä½ç½®æ•°ã€‚

+   `max_rel_2d_pos` (`int`, *optional*, é»˜è®¤ä¸º 256) â€” è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„æœ€å¤§2Dç›¸å¯¹ä½ç½®æ•°ã€‚

+   `rel_2d_pos_bins` (`int`, *optional*, é»˜è®¤ä¸º 64) â€” è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„2Dç›¸å¯¹ä½ç½®æ¡¶çš„æ•°é‡ã€‚

+   `has_spatial_attention_bias` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦åœ¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ä½¿ç”¨ç©ºé—´æ³¨æ„åç½®ã€‚

+   `visual_embed` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æ·»åŠ è¡¥ä¸åµŒå…¥ã€‚

+   `input_size` (`int`, *optional*, é»˜è®¤ä¸º `224`) â€” å›¾åƒçš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚

+   `num_channels` (`int`, *optional*, é»˜è®¤ä¸º `3`) â€” å›¾åƒçš„é€šé“æ•°ã€‚

+   `patch_size` (`int`, *optional*, é»˜è®¤ä¸º `16`) â€” è¡¥ä¸çš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚

+   `classifier_dropout` (`float`, *optional*) â€” åˆ†ç±»å¤´çš„dropoutæ¯”ç‡ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model) çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ª LayoutLMv3 æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº LayoutLMv3 [microsoft/layoutlmv3-base](https://huggingface.co/microsoft/layoutlmv3-base) æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯» [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig) çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import LayoutLMv3Config, LayoutLMv3Model

>>> # Initializing a LayoutLMv3 microsoft/layoutlmv3-base style configuration
>>> configuration = LayoutLMv3Config()

>>> # Initializing a model (with random weights) from the microsoft/layoutlmv3-base style configuration
>>> model = LayoutLMv3Model(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## LayoutLMv3FeatureExtractor

### `class transformers.LayoutLMv3FeatureExtractor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py#L28)

```py
( *args **kwargs )
```

#### `__call__`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)

```py
( images **kwargs )
```

é¢„å¤„ç†ä¸€å¼ å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒã€‚

## LayoutLMv3ImageProcessor

### `class transformers.LayoutLMv3ImageProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/image_processing_layoutlmv3.py#L95)

```py
( do_resize: bool = True size: Dict = None resample: Resampling = <Resampling.BILINEAR: 2> do_rescale: bool = True rescale_value: float = 0.00392156862745098 do_normalize: bool = True image_mean: Union = None image_std: Union = None apply_ocr: bool = True ocr_lang: Optional = None tesseract_config: Optional = '' **kwargs )
```

å‚æ•°

+   `do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†å›¾åƒçš„ (é«˜åº¦ï¼Œå®½åº¦) å°ºå¯¸è°ƒæ•´ä¸º `(size["height"], size["width"])`ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `do_resize` è¦†ç›–ã€‚

+   `size` (`Dict[str, int]` *optional*, é»˜è®¤ä¸º `{"height" -- 224, "width": 224}`): è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `size` è¦†ç›–ã€‚

+   `resample` (`PILImageResampling`, *optional*, é»˜è®¤ä¸º `PILImageResampling.BILINEAR`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œè¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `resample` è¦†ç›–ã€‚

+   `do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æŒ‰æŒ‡å®šçš„ `rescale_value` é‡æ–°ç¼©æ”¾å›¾åƒçš„åƒç´ å€¼ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `do_rescale` è¦†ç›–ã€‚

+   `rescale_factor` (`float`, *optional*, é»˜è®¤ä¸º 1 / 255) â€” å›¾åƒçš„åƒç´ å€¼è¢«é‡æ–°ç¼©æ”¾çš„å€¼ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `rescale_factor` è¦†ç›–ã€‚

+   `do_normalize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œè§„èŒƒåŒ–ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_normalize` å‚æ•°è¦†ç›–ã€‚

+   `image_mean` (`Iterable[float]` æˆ– `float`, *optional*, é»˜è®¤ä¸º `IMAGENET_STANDARD_MEAN`) â€” å¦‚æœè§„èŒƒåŒ–å›¾åƒè¦ä½¿ç”¨çš„å‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_mean` å‚æ•°è¦†ç›–ã€‚

+   `image_std` (`Iterable[float]` æˆ– `float`, *optional*, é»˜è®¤ä¸º `IMAGENET_STANDARD_STD`) â€” å¦‚æœè§„èŒƒåŒ–å›¾åƒè¦ä½¿ç”¨çš„æ ‡å‡†å·®ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_std` å‚æ•°è¦†ç›–ã€‚

+   `apply_ocr` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦åº”ç”¨ Tesseract OCR å¼•æ“ä»¥è·å–å•è¯ + è§„èŒƒåŒ–è¾¹ç•Œæ¡†ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `apply_ocr` å‚æ•°è¦†ç›–ã€‚

+   `ocr_lang` (`str`, *optional*) â€” Tesseract OCR å¼•æ“è¦ä½¿ç”¨çš„è¯­è¨€ï¼Œç”±å…¶ ISO ä»£ç æŒ‡å®šã€‚é»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨è‹±è¯­ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `ocr_lang` å‚æ•°è¦†ç›–ã€‚

+   `tesseract_config` (`str`, *optional*) â€” è½¬å‘åˆ°è°ƒç”¨ Tesseract æ—¶ `config` å‚æ•°çš„ä»»ä½•é¢å¤–è‡ªå®šä¹‰é…ç½®æ ‡å¿—ã€‚ä¾‹å¦‚ï¼šâ€˜â€”psm 6â€™ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `tesseract_config` å‚æ•°è¦†ç›–ã€‚

æ„å»ºä¸€ä¸ª LayoutLMv3 å›¾åƒå¤„ç†å™¨ã€‚

#### `preprocess`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/image_processing_layoutlmv3.py#L216)

```py
( images: Union do_resize: bool = None size: Dict = None resample = None do_rescale: bool = None rescale_factor: float = None do_normalize: bool = None image_mean: Union = None image_std: Union = None apply_ocr: bool = None ocr_lang: Optional = None tesseract_config: Optional = None return_tensors: Union = None data_format: ChannelDimension = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )
```

å‚æ•°

+   `images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒã€‚æœŸæœ›å•ä¸ªæˆ–æ‰¹é‡å›¾åƒï¼Œåƒç´ å€¼èŒƒå›´ä¸º 0 åˆ° 255ã€‚å¦‚æœä¼ å…¥åƒç´ å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´çš„å›¾åƒï¼Œè¯·è®¾ç½® `do_rescale=False`ã€‚

+   `do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_resize`) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `self.size`) â€” åº”ç”¨ `resize` åè¾“å‡ºå›¾åƒçš„æœŸæœ›å¤§å°ã€‚

+   `resample` (`int`, *optional*, defaults to `self.resample`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™è¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚è¿™å¯ä»¥æ˜¯ `PILImageResampling` æ»¤æ³¢å™¨ä¹‹ä¸€ã€‚ä»…åœ¨ `do_resize` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚

+   `do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) â€” æ˜¯å¦å°†å›¾åƒåƒç´ å€¼é‡æ–°ç¼©æ”¾åˆ° [0, 1] ä¹‹é—´ã€‚

+   `rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) â€” åº”ç”¨äºå›¾åƒåƒç´ å€¼çš„é‡æ–°ç¼©æ”¾å› å­ã€‚ä»…åœ¨ `do_rescale` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚

+   `do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚

+   `image_mean` (`float` or `Iterable[float]`, *optional*, defaults to `self.image_mean`) â€” ç”¨äºå½’ä¸€åŒ–çš„å‡å€¼ã€‚ä»…åœ¨ `do_normalize` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚

+   `image_std` (`float` or `Iterable[float]`, *optional*, defaults to `self.image_std`) â€” ç”¨äºå½’ä¸€åŒ–çš„æ ‡å‡†å·®å€¼ã€‚ä»…åœ¨ `do_normalize` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚

+   `apply_ocr` (`bool`, *optional*, defaults to `self.apply_ocr`) â€” æ˜¯å¦åº”ç”¨ Tesseract OCR å¼•æ“ä»¥è·å–å•è¯ + è§„èŒƒåŒ–è¾¹ç•Œæ¡†ã€‚

+   `ocr_lang` (`str`, *optional*, defaults to `self.ocr_lang`) â€” Tesseract OCR å¼•æ“ä½¿ç”¨çš„è¯­è¨€ï¼Œç”±å…¶ ISO ä»£ç æŒ‡å®šã€‚é»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨è‹±è¯­ã€‚

+   `tesseract_config` (`str`, *optional*, defaults to `self.tesseract_config`) â€” è½¬å‘åˆ°è°ƒç”¨ Tesseract æ—¶ `config` å‚æ•°çš„ä»»ä½•é¢å¤–è‡ªå®šä¹‰é…ç½®æ ‡å¿—ã€‚

+   `return_tensors` (`str` or `TensorType`, *optional*) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   æœªè®¾ç½®ï¼šè¿”å› `np.ndarray` çš„åˆ—è¡¨ã€‚

    +   `TensorType.TENSORFLOW` æˆ– `'tf'`ï¼šè¿”å›ç±»å‹ä¸º `tf.Tensor` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.PYTORCH` æˆ– `'pt'`ï¼šè¿”å›ç±»å‹ä¸º `torch.Tensor` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.NUMPY` æˆ– `'np'`ï¼šè¿”å›ç±»å‹ä¸º `np.ndarray` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.JAX` æˆ– `'jax'`ï¼šè¿”å›ç±»å‹ä¸º `jax.numpy.ndarray` çš„æ‰¹æ¬¡ã€‚

+   `data_format` (`ChannelDimension` æˆ– `str`, *optional*, defaults to `ChannelDimension.FIRST`) â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `ChannelDimension.FIRST`ï¼šå›¾åƒä»¥ (é€šé“æ•°, é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

    +   `ChannelDimension.LAST`ï¼šå›¾åƒä»¥ (é«˜åº¦, å®½åº¦, é€šé“æ•°) æ ¼å¼ã€‚

+   `input_data_format` (`ChannelDimension` æˆ– `str`, *optional*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`ï¼šå›¾åƒä»¥ (é€šé“æ•°, é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`ï¼šå›¾åƒä»¥ (é«˜åº¦, å®½åº¦, é€šé“æ•°) æ ¼å¼ã€‚

    +   `"none"` æˆ– `ChannelDimension.NONE`ï¼šå›¾åƒä»¥ (é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

é¢„å¤„ç†å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚

## LayoutLMv3Tokenizer

### `class transformers.LayoutLMv3Tokenizer`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L200)

```py
( vocab_file merges_file errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = True cls_token_box = [0, 0, 0, 0] sep_token_box = [0, 0, 0, 0] pad_token_box = [0, 0, 0, 0] pad_token_label = -100 only_label_first_subword = True **kwargs )
```

å‚æ•°

+   `vocab_file` (`str`) â€” è¯æ±‡æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `merges_file` (`str`) â€” åˆå¹¶æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `errors` (`str`, *optional*, defaults to `"replace"`) â€” è§£ç å­—èŠ‚ä¸º UTF-8 æ—¶è¦éµå¾ªçš„èŒƒä¾‹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)ã€‚

+   `bos_token` (`str`, *optional*, defaults to `"<s>"`) â€” åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨çš„åºåˆ—å¼€å¤´æ ‡è®°ã€‚å¯ç”¨ä½œåºåˆ—åˆ†ç±»å™¨æ ‡è®°ã€‚

    æ„å»ºåºåˆ—æ—¶ä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼Œè¿™ä¸æ˜¯åºåˆ—å¼€å¤´ä½¿ç”¨çš„æ ‡è®°ã€‚ä½¿ç”¨çš„æ ‡è®°æ˜¯ `cls_token`ã€‚

+   `eos_token` (`str`, *optional*, defaults to `"</s>"`) â€” åºåˆ—ç»“æŸæ ‡è®°ã€‚

    æ„å»ºåºåˆ—æ—¶ä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼Œè¿™ä¸æ˜¯åºåˆ—æœ«å°¾ä½¿ç”¨çš„æ ‡è®°ã€‚ä½¿ç”¨çš„æ ‡è®°æ˜¯ `sep_token`ã€‚

+   `sep_token` (`str`, *optional*, é»˜è®¤ä¸º `"</s>"`) â€” åˆ†éš”ç¬¦æ ‡è®°ï¼Œåœ¨æ„å»ºæ¥è‡ªå¤šä¸ªåºåˆ—çš„åºåˆ—æ—¶ä½¿ç”¨ï¼Œä¾‹å¦‚ç”¨äºåºåˆ—åˆ†ç±»çš„ä¸¤ä¸ªåºåˆ—æˆ–ç”¨äºé—®é¢˜å›ç­”çš„æ–‡æœ¬å’Œé—®é¢˜ã€‚å®ƒè¿˜ç”¨ä½œä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ„å»ºçš„åºåˆ—çš„æœ€åä¸€ä¸ªæ ‡è®°ã€‚

+   `cls_token` (`str`, *optional*, é»˜è®¤ä¸º `"<s>"`) â€” åˆ†ç±»å™¨æ ‡è®°ï¼Œç”¨äºè¿›è¡Œåºåˆ—åˆ†ç±»ï¼ˆå¯¹æ•´ä¸ªåºåˆ—è¿›è¡Œåˆ†ç±»ï¼Œè€Œä¸æ˜¯æ¯ä¸ªæ ‡è®°è¿›è¡Œåˆ†ç±»ï¼‰ã€‚å®ƒæ˜¯ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ„å»ºçš„åºåˆ—çš„ç¬¬ä¸€ä¸ªæ ‡è®°ã€‚

+   `unk_token` (`str`, *optional*, é»˜è®¤ä¸º `"<unk>"`) â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­æ²¡æœ‰çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸ºIDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚

+   `pad_token` (`str`, *optional*, é»˜è®¤ä¸º `"<pad>"`) â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚

+   `mask_token` (`str`, *optional*, é»˜è®¤ä¸º `"<mask>"`) â€” ç”¨äºå±è”½å€¼çš„æ ‡è®°ã€‚è¿™æ˜¯åœ¨ä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡è®­ç»ƒæ­¤æ¨¡å‹æ—¶ä½¿ç”¨çš„æ ‡è®°ã€‚è¿™æ˜¯æ¨¡å‹å°†å°è¯•é¢„æµ‹çš„æ ‡è®°ã€‚

+   `add_prefix_space` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦åœ¨è¾“å…¥ä¸­æ·»åŠ åˆå§‹ç©ºæ ¼ã€‚è¿™å…è®¸å°†å‰å¯¼å•è¯è§†ä¸ºä»»ä½•å…¶ä»–å•è¯ã€‚ï¼ˆRoBERTaåˆ†è¯å™¨é€šè¿‡å‰é¢çš„ç©ºæ ¼æ£€æµ‹å•è¯çš„å¼€å¤´ï¼‰ã€‚

+   `cls_token_box` (`List[int]`, *optional*, é»˜è®¤ä¸º `[0, 0, 0, 0]`) â€” ç”¨äºç‰¹æ®Š[CLS]æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚

+   `sep_token_box` (`List[int]`, *optional*, é»˜è®¤ä¸º `[0, 0, 0, 0]`) â€” ç”¨äºç‰¹æ®Š[SEP]æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚

+   `pad_token_box` (`List[int]`, *optional*, é»˜è®¤ä¸º `[0, 0, 0, 0]`) â€” ç”¨äºç‰¹æ®Š[PAD]æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚

+   `pad_token_label` (`int`, *optional*, é»˜è®¤ä¸º -100) â€” ç”¨äºå¡«å……æ ‡è®°çš„æ ‡ç­¾ã€‚é»˜è®¤ä¸º-100ï¼Œè¿™æ˜¯PyTorchçš„CrossEntropyLossçš„`ignore_index`ã€‚

+   `only_label_first_subword` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä»…æ ‡è®°ç¬¬ä¸€ä¸ªå­è¯ï¼Œå¦‚æœæä¾›äº†å•è¯æ ‡ç­¾ã€‚

æ„å»ºä¸€ä¸ªLayoutLMv3åˆ†è¯å™¨ã€‚åŸºäº`RoBERTatokenizer`ï¼ˆå­—èŠ‚å¯¹ç¼–ç æˆ–BPEï¼‰ã€‚[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer) å¯ç”¨äºå°†å•è¯ã€å•è¯çº§è¾¹ç•Œæ¡†å’Œå¯é€‰å•è¯æ ‡ç­¾è½¬æ¢ä¸ºæ ‡è®°çº§`input_ids`ã€`attention_mask`ã€`token_type_ids`ã€`bbox`å’Œå¯é€‰`labels`ï¼ˆç”¨äºæ ‡è®°åˆ†ç±»ï¼‰ã€‚

æ­¤åˆ†è¯å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)ï¼Œå…¶ä¸­åŒ…å«å¤§å¤šæ•°ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒæ­¤è¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚

[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer) è¿è¡Œç«¯åˆ°ç«¯çš„åˆ†è¯ï¼šæ ‡ç‚¹ç¬¦å·æ‹†åˆ†å’Œè¯å—ã€‚å®ƒè¿˜å°†å•è¯çº§è¾¹ç•Œæ¡†è½¬æ¢ä¸ºæ ‡è®°çº§è¾¹ç•Œæ¡†ã€‚

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L550)

```py
( text: Union text_pair: Union = None boxes: Union = None word_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )
```

å‚æ•°

+   `text` (`str`, `List[str]`, `List[List[str]]`) â€” è¦ç¼–ç çš„åºåˆ—æˆ–æ‰¹æ¬¡åºåˆ—ã€‚æ¯ä¸ªåºåˆ—å¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆå•ä¸ªç¤ºä¾‹çš„å•è¯æˆ–ä¸€æ‰¹ç¤ºä¾‹çš„é—®é¢˜ï¼‰æˆ–ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨çš„åˆ—è¡¨ï¼ˆä¸€æ‰¹å•è¯ï¼‰ã€‚

+   `text_pair` (`List[str]`, `List[List[str]]`) â€” è¦ç¼–ç çš„åºåˆ—æˆ–æ‰¹æ¬¡åºåˆ—ã€‚æ¯ä¸ªåºåˆ—åº”è¯¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆé¢„åˆ†è¯çš„å­—ç¬¦ä¸²ï¼‰ã€‚

+   `boxes` (`List[List[int]]`, `List[List[List[int]]]`) â€” å•è¯çº§è¾¹ç•Œæ¡†ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”æ ‡å‡†åŒ–ä¸º0-1000çš„æ¯”ä¾‹ã€‚

+   `word_labels` (`List[int]`, `List[List[int]]`, *optional*) â€” å•è¯çº§æ•´æ•°æ ‡ç­¾ï¼ˆç”¨äºè¯¸å¦‚FUNSDã€CORDä¹‹ç±»çš„æ ‡è®°åˆ†ç±»ä»»åŠ¡ï¼‰ã€‚

+   `add_special_tokens` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦å¯¹åºåˆ—è¿›è¡Œç¼–ç ï¼Œä½¿ç”¨ç›¸å¯¹äºå…¶æ¨¡å‹çš„ç‰¹æ®Šæ ‡è®°ã€‚

+   `padding` (`bool`, `str` æˆ– [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy), *optional*, defaults to `False`) â€” æ¿€æ´»å¹¶æ§åˆ¶å¡«å……ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True` æˆ– `'longest'`: å¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„åºåˆ—ï¼ˆå¦‚æœåªæä¾›äº†å•ä¸ªåºåˆ—ï¼Œåˆ™ä¸å¡«å……ï¼‰ã€‚

    +   `'max_length'`: å¡«å……åˆ°æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼ˆä½¿ç”¨å‚æ•° `max_length`ï¼‰æˆ–æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚

    +   `False` æˆ– `'do_not_pad'`ï¼ˆé»˜è®¤ï¼‰ï¼šæ— å¡«å……ï¼ˆå³ï¼Œå¯ä»¥è¾“å‡ºå…·æœ‰ä¸åŒé•¿åº¦åºåˆ—çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `truncation` (`bool`, `str` æˆ– [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy), *optional*, defaults to `False`) â€” æ¿€æ´»å¹¶æ§åˆ¶æˆªæ–­ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True` æˆ– `'longest_first'`: æˆªæ–­åˆ°æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼ˆä½¿ç”¨å‚æ•° `max_length`ï¼‰æˆ–æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™é€æ ‡è®°æˆªæ–­ï¼Œä»æœ€é•¿åºåˆ—ä¸­åˆ é™¤ä¸€ä¸ªæ ‡è®°ã€‚

    +   `'only_first'`: æˆªæ–­åˆ°æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼ˆä½¿ç”¨å‚æ•° `max_length`ï¼‰æˆ–æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™ä»…æˆªæ–­ç¬¬ä¸€ä¸ªåºåˆ—ã€‚

    +   `'only_second'`: æˆªæ–­åˆ°æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼ˆä½¿ç”¨å‚æ•° `max_length`ï¼‰æˆ–æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™ä»…æˆªæ–­ç¬¬äºŒä¸ªåºåˆ—ã€‚

    +   `False` æˆ– `'do_not_truncate'`ï¼ˆé»˜è®¤ï¼‰ï¼šæ— æˆªæ–­ï¼ˆå³ï¼Œå¯ä»¥è¾“å‡ºå…·æœ‰å¤§äºæ¨¡å‹æœ€å¤§å¯æ¥å—è¾“å…¥å¤§å°çš„åºåˆ—é•¿åº¦çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `max_length` (`int`, *optional*) â€” æ§åˆ¶æˆªæ–­/å¡«å……å‚æ•°ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚

    å¦‚æœæœªè®¾ç½®æˆ–è®¾ç½®ä¸º `None`ï¼Œåˆ™å°†ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹æœ€å¤§é•¿åº¦ï¼ˆå¦‚æœæˆªæ–­/å¡«å……å‚æ•°éœ€è¦æœ€å¤§é•¿åº¦ï¼‰ã€‚å¦‚æœæ¨¡å‹æ²¡æœ‰ç‰¹å®šçš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚ XLNetï¼‰ï¼Œåˆ™å°†ç¦ç”¨æˆªæ–­/å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚

+   `stride` (`int`, *optional*, defaults to 0) â€” å¦‚æœè®¾ç½®ä¸ºä¸€ä¸ªæ•°å­—ï¼Œå¹¶ä¸”ä¸ `max_length` ä¸€èµ·ä½¿ç”¨ï¼Œå½“ `return_overflowing_tokens=True` æ—¶è¿”å›çš„æº¢å‡ºæ ‡è®°å°†åŒ…å«æˆªæ–­åºåˆ—æœ«å°¾çš„ä¸€äº›æ ‡è®°ï¼Œä»¥æä¾›æˆªæ–­å’Œæº¢å‡ºåºåˆ—ä¹‹é—´çš„ä¸€äº›é‡å ã€‚è¯¥å‚æ•°çš„å€¼å®šä¹‰äº†é‡å æ ‡è®°çš„æ•°é‡ã€‚

+   `pad_to_multiple_of` (`int`, *optional*) â€” å¦‚æœè®¾ç½®ï¼Œå°†å¡«å……åºåˆ—åˆ°æä¾›çš„å€¼çš„å€æ•°ã€‚è¿™å¯¹äºåœ¨å…·æœ‰è®¡ç®—èƒ½åŠ› `>= 7.5`ï¼ˆVoltaï¼‰çš„ NVIDIA ç¡¬ä»¶ä¸Šå¯ç”¨ Tensor Cores ç‰¹åˆ«æœ‰ç”¨ã€‚

+   `return_tensors` (`str` æˆ– [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType), *optional*) â€” å¦‚æœè®¾ç½®ï¼Œå°†è¿”å›å¼ é‡è€Œä¸æ˜¯ Python æ•´æ•°åˆ—è¡¨ã€‚å¯æ¥å—çš„å€¼ä¸ºï¼š

    +   `'tf'`: è¿”å› TensorFlow `tf.constant` å¯¹è±¡ã€‚

    +   `'pt'`: è¿”å› PyTorch `torch.Tensor` å¯¹è±¡ã€‚

    +   `'np'`: è¿”å› Numpy `np.ndarray` å¯¹è±¡ã€‚

+   `add_special_tokens` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦å¯¹åºåˆ—è¿›è¡Œç¼–ç ï¼Œä½¿ç”¨ç›¸å¯¹äºå…¶æ¨¡å‹çš„ç‰¹æ®Šæ ‡è®°ã€‚

+   `padding` (`bool`, `str` æˆ– [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy), *optional*, defaults to `False`) â€” æ¿€æ´»å¹¶æ§åˆ¶å¡«å……ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True` æˆ– `'longest'`: å¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„åºåˆ—ï¼ˆå¦‚æœåªæä¾›äº†å•ä¸ªåºåˆ—ï¼Œåˆ™ä¸å¡«å……ï¼‰ã€‚

    +   `'max_length'`: å¡«å……åˆ°æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œè¯¥é•¿åº¦ç”±å‚æ•° `max_length` æŒ‡å®šï¼Œæˆ–è€…å¡«å……åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼Œå¦‚æœæœªæä¾›è¯¥å‚æ•°ã€‚

    +   `False` æˆ– `'do_not_pad'`ï¼ˆé»˜è®¤ï¼‰ï¼šä¸å¡«å……ï¼ˆå³ï¼Œå¯ä»¥è¾“å‡ºå…·æœ‰ä¸åŒé•¿åº¦åºåˆ—çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `truncation` (`bool`, `str` æˆ– [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy), *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ¿€æ´»å’Œæ§åˆ¶æˆªæ–­ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True` æˆ– `'longest_first'`: æˆªæ–­åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æˆªæ–­åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼Œå¦‚æœæœªæä¾›è¯¥å‚æ•°ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹åºåˆ—å¯¹ï¼‰ï¼Œåˆ™å°†é€ä¸ªæ ‡è®°æˆªæ–­ï¼Œä»è¾ƒé•¿åºåˆ—ä¸­åˆ é™¤ä¸€ä¸ªæ ‡è®°ã€‚

    +   `'only_first'`: æˆªæ–­åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æˆªæ–­åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼Œå¦‚æœæœªæä¾›è¯¥å‚æ•°ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹åºåˆ—å¯¹ï¼‰ï¼Œåˆ™ä»…æˆªæ–­ç¬¬ä¸€ä¸ªåºåˆ—ã€‚

    +   `'only_second'`: æˆªæ–­åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æˆªæ–­åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ï¼Œå¦‚æœæœªæä¾›è¯¥å‚æ•°ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹åºåˆ—å¯¹ï¼‰ï¼Œåˆ™ä»…æˆªæ–­ç¬¬äºŒä¸ªåºåˆ—ã€‚ 

    +   `False` æˆ– `'do_not_truncate'`ï¼ˆé»˜è®¤ï¼‰ï¼šä¸æˆªæ–­ï¼ˆå³ï¼Œå¯ä»¥è¾“å‡ºå…·æœ‰å¤§äºæ¨¡å‹æœ€å¤§å¯æ¥å—è¾“å…¥å¤§å°çš„åºåˆ—é•¿åº¦çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `max_length` (`int`, *å¯é€‰*) â€” æ§åˆ¶æˆªæ–­/å¡«å……å‚æ•°ä¹‹ä¸€ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚å¦‚æœæœªè®¾ç½®æˆ–è®¾ç½®ä¸º `None`ï¼Œåˆ™å°†ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹æœ€å¤§é•¿åº¦ï¼Œå¦‚æœæˆªæ–­/å¡«å……å‚æ•°éœ€è¦æœ€å¤§é•¿åº¦ã€‚å¦‚æœæ¨¡å‹æ²¡æœ‰ç‰¹å®šçš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚ XLNetï¼‰ï¼Œåˆ™å°†ç¦ç”¨æˆªæ–­/å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚

+   `stride` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” å¦‚æœä¸ `max_length` ä¸€èµ·è®¾ç½®ä¸ºä¸€ä¸ªæ•°å­—ï¼Œåˆ™å½“ `return_overflowing_tokens=True` æ—¶è¿”å›çš„æº¢å‡ºæ ‡è®°å°†åŒ…å«ä»æˆªæ–­åºåˆ—æœ«å°¾è¿”å›çš„ä¸€äº›æ ‡è®°ï¼Œä»¥æä¾›æˆªæ–­å’Œæº¢å‡ºåºåˆ—ä¹‹é—´çš„ä¸€äº›é‡å ã€‚è¯¥å‚æ•°çš„å€¼å®šä¹‰äº†é‡å æ ‡è®°çš„æ•°é‡ã€‚

+   `pad_to_multiple_of` (`int`, *å¯é€‰*) â€” å¦‚æœè®¾ç½®ï¼Œå°†å¡«å……åºåˆ—åˆ°æä¾›çš„å€¼çš„å€æ•°ã€‚è¿™å¯¹äºåœ¨å…·æœ‰è®¡ç®—èƒ½åŠ› `>= 7.5`ï¼ˆVoltaï¼‰çš„ NVIDIA ç¡¬ä»¶ä¸Šå¯ç”¨ Tensor Cores ç‰¹åˆ«æœ‰ç”¨ã€‚

+   `return_tensors` (`str` æˆ– [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType), *å¯é€‰*) â€” å¦‚æœè®¾ç½®ï¼Œå°†è¿”å›å¼ é‡è€Œä¸æ˜¯ Python æ•´æ•°åˆ—è¡¨ã€‚å¯æ¥å—çš„å€¼ä¸ºï¼š

    +   `'tf'`: è¿”å› TensorFlow `tf.constant` å¯¹è±¡ã€‚

    +   `'pt'`: è¿”å› PyTorch `torch.Tensor` å¯¹è±¡ã€‚

    +   `'np'`: è¿”å› Numpy `np.ndarray` å¯¹è±¡ã€‚

ç”¨äºå¯¹ä¸€ä¸ªæˆ–å¤šä¸ªåºåˆ—æˆ–ä¸€ä¸ªæˆ–å¤šä¸ªåºåˆ—å¯¹è¿›è¡Œæ ‡è®°åŒ–å’Œä¸ºæ¨¡å‹å‡†å¤‡çš„ä¸»è¦æ–¹æ³•ï¼Œå…¶ä¸­åŒ…æ‹¬å•è¯çº§åˆ«çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†å’Œå¯é€‰æ ‡ç­¾ã€‚

#### `save_vocabulary`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L431)

```py
( save_directory: str filename_prefix: Optional = None )
```

## LayoutLMv3TokenizerFast

### `class transformers.LayoutLMv3TokenizerFast`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py#L65)

```py
( vocab_file = None merges_file = None tokenizer_file = None errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = True trim_offsets = True cls_token_box = [0, 0, 0, 0] sep_token_box = [0, 0, 0, 0] pad_token_box = [0, 0, 0, 0] pad_token_label = -100 only_label_first_subword = True **kwargs )
```

å‚æ•°

+   `vocab_file` (`str`) â€” è¯æ±‡è¡¨æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `merges_file` (`str`) â€” åˆå¹¶æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `errors` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"replace"`) â€” è§£ç å­—èŠ‚ä¸º UTF-8 æ—¶è¦éµå¾ªçš„èŒƒä¾‹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)ã€‚

+   `bos_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"<s>"`) â€” åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨çš„åºåˆ—å¼€å§‹æ ‡è®°ã€‚å¯ä»¥ç”¨ä½œåºåˆ—åˆ†ç±»å™¨æ ‡è®°ã€‚

    æ„å»ºåºåˆ—æ—¶ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ—¶ï¼Œè¿™ä¸æ˜¯ç”¨äºåºåˆ—å¼€å¤´çš„æ ‡è®°ã€‚ä½¿ç”¨çš„æ ‡è®°æ˜¯`cls_token`ã€‚

+   `eos_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"</s>"`) â€” åºåˆ—ç»“æŸæ ‡è®°ã€‚

    æ„å»ºåºåˆ—æ—¶ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ—¶ï¼Œè¿™ä¸æ˜¯ç”¨äºåºåˆ—ç»“å°¾çš„æ ‡è®°ã€‚ä½¿ç”¨çš„æ ‡è®°æ˜¯`sep_token`ã€‚

+   `sep_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"</s>"`) â€” åˆ†éš”ç¬¦æ ‡è®°ï¼Œç”¨äºä»å¤šä¸ªåºåˆ—æ„å»ºåºåˆ—ï¼Œä¾‹å¦‚ç”¨äºåºåˆ—åˆ†ç±»çš„ä¸¤ä¸ªåºåˆ—æˆ–ç”¨äºæ–‡æœ¬å’Œé—®é¢˜çš„é—®é¢˜å›ç­”ã€‚å®ƒä¹Ÿç”¨ä½œä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ„å»ºçš„åºåˆ—çš„æœ€åä¸€ä¸ªæ ‡è®°ã€‚

+   `cls_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"<s>"`) â€” åœ¨è¿›è¡Œåºåˆ—åˆ†ç±»ï¼ˆæ•´ä¸ªåºåˆ—è€Œä¸æ˜¯æ¯ä¸ªæ ‡è®°çš„åˆ†ç±»ï¼‰æ—¶ä½¿ç”¨çš„åˆ†ç±»å™¨æ ‡è®°ã€‚å½“ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ„å»ºåºåˆ—æ—¶ï¼Œå®ƒæ˜¯åºåˆ—çš„ç¬¬ä¸€ä¸ªæ ‡è®°ã€‚

+   `unk_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"<unk>"`) â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­æ²¡æœ‰çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸ºIDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚

+   `pad_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"<pad>"`) â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚

+   `mask_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"<mask>"`) â€” ç”¨äºå±è”½å€¼çš„æ ‡è®°ã€‚è¿™æ˜¯åœ¨ä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡è®­ç»ƒæ­¤æ¨¡å‹æ—¶ä½¿ç”¨çš„æ ‡è®°ã€‚è¿™æ˜¯æ¨¡å‹å°†å°è¯•é¢„æµ‹çš„æ ‡è®°ã€‚

+   `add_prefix_space` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨è¾“å…¥ä¸­æ·»åŠ åˆå§‹ç©ºæ ¼ã€‚è¿™å…è®¸å°†å‰å¯¼å•è¯è§†ä¸ºä»»ä½•å…¶ä»–å•è¯ã€‚ï¼ˆRoBERTaæ ‡è®°å™¨é€šè¿‡å‰é¢çš„ç©ºæ ¼æ£€æµ‹å•è¯çš„å¼€å¤´ï¼‰ã€‚

+   `trim_offsets` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” åå¤„ç†æ­¥éª¤æ˜¯å¦åº”ä¿®å‰ªåç§»é‡ä»¥é¿å…åŒ…å«ç©ºæ ¼ã€‚

+   `cls_token_box` (`List[int]`, *å¯é€‰*, é»˜è®¤ä¸º `[0, 0, 0, 0]`) â€” ç”¨äºç‰¹æ®Š[CLS]æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚

+   `sep_token_box` (`List[int]`, *å¯é€‰*, é»˜è®¤ä¸º `[0, 0, 0, 0]`) â€” ç”¨äºç‰¹æ®Š[SEP]æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚

+   `pad_token_box` (`List[int]`, *å¯é€‰*, é»˜è®¤ä¸º `[0, 0, 0, 0]`) â€” ç”¨äºç‰¹æ®Š[PAD]æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚

+   `pad_token_label` (`int`, *å¯é€‰*, é»˜è®¤ä¸º -100) â€” ç”¨äºå¡«å……æ ‡è®°çš„æ ‡ç­¾ã€‚é»˜è®¤ä¸º-100ï¼Œè¿™æ˜¯PyTorchçš„CrossEntropyLossçš„`ignore_index`ã€‚

+   `only_label_first_subword` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä»…æ ‡è®°ç¬¬ä¸€ä¸ªå­è¯ï¼Œå¦‚æœæä¾›äº†å•è¯æ ‡ç­¾ã€‚

æ„å»ºâ€œå¿«é€Ÿâ€LayoutLMv3æ ‡è®°å™¨ï¼ˆç”±HuggingFaceçš„*tokenizers*åº“æ”¯æŒï¼‰ã€‚åŸºäºBPEã€‚

æ­¤æ ‡è®°å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)ï¼Œå…¶ä¸­åŒ…å«å¤§å¤šæ•°ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒæ­¤è¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py#L224)

```py
( text: Union text_pair: Union = None boxes: Union = None word_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )
```

å‚æ•°

+   `text` (`str`, `List[str]`, `List[List[str]]`) â€” è¦ç¼–ç çš„åºåˆ—æˆ–åºåˆ—æ‰¹æ¬¡ã€‚æ¯ä¸ªåºåˆ—å¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆå•ä¸ªç¤ºä¾‹çš„å•è¯æˆ–ä¸€æ‰¹ç¤ºä¾‹çš„é—®é¢˜ï¼‰æˆ–ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨çš„åˆ—è¡¨ï¼ˆå•è¯æ‰¹æ¬¡ï¼‰ã€‚

+   `text_pair` (`List[str]`, `List[List[str]]`) â€” è¦ç¼–ç çš„åºåˆ—æˆ–åºåˆ—æ‰¹æ¬¡ã€‚æ¯ä¸ªåºåˆ—åº”è¯¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆé¢„å…ˆæ ‡è®°åŒ–çš„å­—ç¬¦ä¸²ï¼‰ã€‚

+   `boxes` (`List[List[int]]`, `List[List[List[int]]]`) â€” å•è¯çº§åˆ«çš„è¾¹ç•Œæ¡†ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥è¢«å½’ä¸€åŒ–ä¸º0-1000çš„æ¯”ä¾‹ã€‚

+   `word_labels`ï¼ˆ`List[int]`ã€`List[List[int]]`ï¼Œ*å¯é€‰*ï¼‰ â€” å•è¯çº§æ•´æ•°æ ‡ç­¾ï¼ˆç”¨äºè¯¸å¦‚ FUNSDã€CORD ç­‰æ ‡è®°åˆ†ç±»ä»»åŠ¡ï¼‰ã€‚

+   `add_special_tokens`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`ï¼‰ â€” æ˜¯å¦ä½¿ç”¨ç›¸å¯¹äºå…¶æ¨¡å‹çš„ç‰¹æ®Šæ ‡è®°å¯¹åºåˆ—è¿›è¡Œç¼–ç ã€‚

+   `padding`ï¼ˆ`bool`ã€`str` æˆ– [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`ï¼‰ â€” æ¿€æ´»å’Œæ§åˆ¶å¡«å……ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True` æˆ– `'longest'`ï¼šå¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„åºåˆ—ï¼ˆå¦‚æœåªæä¾›äº†å•ä¸ªåºåˆ—ï¼Œåˆ™ä¸è¿›è¡Œå¡«å……ï¼‰ã€‚

    +   `'max_length'`ï¼šå¡«å……åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…å¡«å……åˆ°æ¨¡å‹å¯æ¥å—çš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚

    +   `False` æˆ– `'do_not_pad'`ï¼ˆé»˜è®¤ï¼‰ï¼šä¸è¿›è¡Œå¡«å……ï¼ˆå³å¯ä»¥è¾“å‡ºé•¿åº¦ä¸åŒçš„æ‰¹æ¬¡ï¼‰ã€‚

+   `truncation`ï¼ˆ`bool`ã€`str` æˆ– [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`ï¼‰ â€” æ¿€æ´»å’Œæ§åˆ¶æˆªæ–­ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True` æˆ– `'longest_first'`ï¼šæˆªæ–­åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æˆªæ–­åˆ°æ¨¡å‹å¯æ¥å—çš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™å°†é€ä¸ªæ ‡è®°è¿›è¡Œæˆªæ–­ï¼Œä»ä¸€å¯¹åºåˆ—ä¸­æœ€é•¿çš„åºåˆ—ä¸­åˆ é™¤ä¸€ä¸ªæ ‡è®°ã€‚

    +   `'only_first'`ï¼šæˆªæ–­åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æˆªæ–­åˆ°æ¨¡å‹å¯æ¥å—çš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™åªä¼šæˆªæ–­ç¬¬ä¸€ä¸ªåºåˆ—ã€‚

    +   `'only_second'`ï¼šæˆªæ–­åˆ°ç”±å‚æ•° `max_length` æŒ‡å®šçš„æœ€å¤§é•¿åº¦ï¼Œæˆ–è€…æˆªæ–­åˆ°æ¨¡å‹å¯æ¥å—çš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼‰ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™åªä¼šæˆªæ–­ç¬¬äºŒä¸ªåºåˆ—ã€‚

    +   `False` æˆ– `'do_not_truncate'`ï¼ˆé»˜è®¤ï¼‰ï¼šä¸è¿›è¡Œæˆªæ–­ï¼ˆå³å¯ä»¥è¾“å‡ºé•¿åº¦å¤§äºæ¨¡å‹æœ€å¤§å¯æ¥å—è¾“å…¥å¤§å°çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `max_length`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰ â€” æ§åˆ¶æˆªæ–­/å¡«å……å‚æ•°ä¹‹ä¸€ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚

    å¦‚æœæœªè®¾ç½®æˆ–è®¾ç½®ä¸º `None`ï¼Œåˆ™å°†ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹æœ€å¤§é•¿åº¦ï¼ˆå¦‚æœæˆªæ–­/å¡«å……å‚æ•°éœ€è¦æœ€å¤§é•¿åº¦ï¼‰ã€‚å¦‚æœæ¨¡å‹æ²¡æœ‰ç‰¹å®šçš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚ XLNetï¼‰ï¼Œåˆ™å°†ç¦ç”¨æˆªæ–­/å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚

+   `stride`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰ â€” å¦‚æœè®¾ç½®ä¸ºä¸€ä¸ªæ•°å­—ï¼Œå¹¶ä¸”ä¸ `max_length` ä¸€èµ·ä½¿ç”¨ï¼Œå½“ `return_overflowing_tokens=True` æ—¶è¿”å›çš„æº¢å‡ºæ ‡è®°å°†åŒ…å«æˆªæ–­åºåˆ—æœ«å°¾çš„ä¸€äº›æ ‡è®°ï¼Œä»¥æä¾›æˆªæ–­å’Œæº¢å‡ºåºåˆ—ä¹‹é—´çš„ä¸€äº›é‡å ã€‚è¯¥å‚æ•°çš„å€¼å®šä¹‰äº†é‡å æ ‡è®°çš„æ•°é‡ã€‚

+   `pad_to_multiple_of`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰ â€” å¦‚æœè®¾ç½®ï¼Œå°†å¡«å……åºåˆ—åˆ°æä¾›çš„å€¼çš„å€æ•°ã€‚è¿™å¯¹äºåœ¨å…·æœ‰è®¡ç®—èƒ½åŠ› `>= 7.5`ï¼ˆVoltaï¼‰çš„ NVIDIA ç¡¬ä»¶ä¸Šå¯ç”¨ Tensor Cores ç‰¹åˆ«æœ‰ç”¨ã€‚

+   `return_tensors`ï¼ˆ`str` æˆ– [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)ï¼Œ*å¯é€‰*ï¼‰ â€” å¦‚æœè®¾ç½®ï¼Œå°†è¿”å›å¼ é‡è€Œä¸æ˜¯ Python æ•´æ•°åˆ—è¡¨ã€‚å¯æ¥å—çš„å€¼ä¸ºï¼š

    +   `'tf'`ï¼šè¿”å› TensorFlow `tf.constant` å¯¹è±¡ã€‚

    +   `'pt'`ï¼šè¿”å› PyTorch `torch.Tensor` å¯¹è±¡ã€‚

    +   `'np'`ï¼šè¿”å› Numpy `np.ndarray` å¯¹è±¡ã€‚

+   `add_special_tokens`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`ï¼‰ â€” æ˜¯å¦ä½¿ç”¨ç›¸å¯¹äºå…¶æ¨¡å‹çš„ç‰¹æ®Šæ ‡è®°å¯¹åºåˆ—è¿›è¡Œç¼–ç ã€‚

+   `padding`ï¼ˆ`bool`ã€`str` æˆ– [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`ï¼‰ â€” æ¿€æ´»å’Œæ§åˆ¶å¡«å……ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True`æˆ–`'longest'`: å¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„åºåˆ—ï¼ˆå¦‚æœåªæä¾›å•ä¸ªåºåˆ—ï¼Œåˆ™ä¸å¡«å……ï¼‰ã€‚

    +   `'max_length'`: ä½¿ç”¨å‚æ•°`max_length`æŒ‡å®šçš„æœ€å¤§é•¿åº¦å¡«å……ï¼Œæˆ–è€…å¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼Œåˆ™å¡«å……åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ã€‚

    +   `False`æˆ–`'do_not_pad'`ï¼ˆé»˜è®¤ï¼‰ï¼šä¸å¡«å……ï¼ˆå³å¯ä»¥è¾“å‡ºå…·æœ‰ä¸åŒé•¿åº¦åºåˆ—çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `truncation`ï¼ˆ`bool`ï¼Œ`str`æˆ–[TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ - æ¿€æ´»å’Œæ§åˆ¶æˆªæ–­ã€‚æ¥å—ä»¥ä¸‹å€¼ï¼š

    +   `True`æˆ–`'longest_first'`: ä½¿ç”¨å‚æ•°`max_length`æŒ‡å®šçš„æœ€å¤§é•¿åº¦æˆªæ–­ï¼Œæˆ–è€…å¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼Œåˆ™æˆªæ–­åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™å°†é€æ ‡è®°æˆªæ–­ï¼Œä»ä¸€å¯¹åºåˆ—ä¸­æœ€é•¿çš„åºåˆ—ä¸­åˆ é™¤ä¸€ä¸ªæ ‡è®°ã€‚

    +   `'only_first'`: ä½¿ç”¨å‚æ•°`max_length`æŒ‡å®šçš„æœ€å¤§é•¿åº¦æˆªæ–­ï¼Œæˆ–è€…å¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼Œåˆ™æˆªæ–­åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™åªä¼šæˆªæ–­ç¬¬ä¸€ä¸ªåºåˆ—ã€‚

    +   `'only_second'`: ä½¿ç”¨å‚æ•°`max_length`æŒ‡å®šçš„æœ€å¤§é•¿åº¦æˆªæ–­ï¼Œæˆ–è€…å¦‚æœæœªæä¾›è¯¥å‚æ•°ï¼Œåˆ™æˆªæ–­åˆ°æ¨¡å‹çš„æœ€å¤§å¯æ¥å—è¾“å…¥é•¿åº¦ã€‚å¦‚æœæä¾›äº†ä¸€å¯¹åºåˆ—ï¼ˆæˆ–ä¸€æ‰¹å¯¹åºåˆ—ï¼‰ï¼Œåˆ™åªä¼šæˆªæ–­ç¬¬äºŒä¸ªåºåˆ—ã€‚

    +   `False`æˆ–`'do_not_truncate'`ï¼ˆé»˜è®¤ï¼‰ï¼šä¸æˆªæ–­ï¼ˆå³å¯ä»¥è¾“å‡ºé•¿åº¦å¤§äºæ¨¡å‹æœ€å¤§å¯æ¥å—è¾“å…¥å¤§å°çš„æ‰¹æ¬¡ï¼‰ã€‚

+   `max_length`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰ - æ§åˆ¶æˆªæ–­/å¡«å……å‚æ•°ä¹‹ä¸€ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚å¦‚æœæœªè®¾ç½®æˆ–è®¾ç½®ä¸º`None`ï¼Œåˆ™å°†ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹æœ€å¤§é•¿åº¦ï¼ˆå¦‚æœæˆªæ–­/å¡«å……å‚æ•°éœ€è¦æœ€å¤§é•¿åº¦ï¼‰ã€‚å¦‚æœæ¨¡å‹æ²¡æœ‰ç‰¹å®šçš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆå¦‚XLNetï¼‰ï¼Œåˆ™å°†ç¦ç”¨æˆªæ–­/å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚

+   `stride`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0ï¼‰ - å¦‚æœä¸`max_length`ä¸€èµ·è®¾ç½®ä¸ºä¸€ä¸ªæ•°å­—ï¼Œåˆ™å½“`return_overflowing_tokens=True`æ—¶è¿”å›çš„æº¢å‡ºæ ‡è®°å°†åŒ…å«æˆªæ–­åºåˆ—æœ«å°¾çš„ä¸€äº›æ ‡è®°ï¼Œä»¥æä¾›æˆªæ–­å’Œæº¢å‡ºåºåˆ—ä¹‹é—´çš„ä¸€äº›é‡å ã€‚è¯¥å‚æ•°çš„å€¼å®šä¹‰äº†é‡å æ ‡è®°çš„æ•°é‡ã€‚

+   `pad_to_multiple_of`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰ - å¦‚æœè®¾ç½®ï¼Œå°†åºåˆ—å¡«å……åˆ°æä¾›çš„å€¼çš„å€æ•°ã€‚è¿™å¯¹äºå¯ç”¨å…·æœ‰è®¡ç®—èƒ½åŠ›`>= 7.5`ï¼ˆVoltaï¼‰çš„NVIDIAç¡¬ä»¶ä¸Šçš„Tensor Coresç‰¹åˆ«æœ‰ç”¨ã€‚

+   `return_tensors`ï¼ˆ`str`æˆ–[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)ï¼Œ*å¯é€‰*ï¼‰ - å¦‚æœè®¾ç½®ï¼Œå°†è¿”å›å¼ é‡è€Œä¸æ˜¯Pythonæ•´æ•°åˆ—è¡¨ã€‚å¯æ¥å—çš„å€¼ä¸ºï¼š

    +   `'tf'`: è¿”å›TensorFlow `tf.constant`å¯¹è±¡ã€‚

    +   `'pt'`: è¿”å›PyTorch `torch.Tensor`å¯¹è±¡ã€‚

    +   `'np'`: è¿”å›Numpy `np.ndarray`å¯¹è±¡ã€‚

ç”¨äºæ ‡è®°å’Œå‡†å¤‡ä¸€ä¸ªæˆ–å¤šä¸ªåºåˆ—æˆ–ä¸€ä¸ªæˆ–å¤šä¸ªåºåˆ—å¯¹çš„ä¸»è¦æ–¹æ³•ï¼Œå…·æœ‰å•è¯çº§åˆ«çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†å’Œå¯é€‰æ ‡ç­¾ã€‚

## LayoutLMv3Processor

### `class transformers.LayoutLMv3Processor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/processing_layoutlmv3.py#L27)

```py
( image_processor = None tokenizer = None **kwargs )
```

å‚æ•°

+   `image_processor`ï¼ˆ`LayoutLMv3ImageProcessor`ï¼Œ*å¯é€‰*ï¼‰ - [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)çš„ä¸€ä¸ªå®ä¾‹ã€‚å›¾åƒå¤„ç†å™¨æ˜¯å¿…éœ€çš„è¾“å…¥ã€‚

+   `tokenizer`ï¼ˆ`LayoutLMv3Tokenizer`æˆ–`LayoutLMv3TokenizerFast`ï¼Œ*å¯é€‰*ï¼‰- [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)æˆ–[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)çš„å®ä¾‹ã€‚æ ‡è®°å™¨æ˜¯å¿…éœ€çš„è¾“å…¥ã€‚

æ„å»ºä¸€ä¸ªLayoutLMv3å¤„ç†å™¨ï¼Œå°†LayoutLMv3å›¾åƒå¤„ç†å™¨å’ŒLayoutLMv3æ ‡è®°å™¨ç»„åˆæˆä¸€ä¸ªå•ä¸€å¤„ç†å™¨ã€‚

[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)æä¾›äº†å‡†å¤‡æ•°æ®ç»™æ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰åŠŸèƒ½ã€‚

å®ƒé¦–å…ˆä½¿ç”¨[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)æ¥è°ƒæ•´å’Œè§„èŒƒæ–‡æ¡£å›¾åƒï¼Œå¹¶å¯é€‰æ‹©åº”ç”¨OCRä»¥è·å–å•è¯å’Œè§„èŒƒåŒ–çš„è¾¹ç•Œæ¡†ã€‚ç„¶åå°†å®ƒä»¬æä¾›ç»™[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)æˆ–[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)ï¼Œå°†å•è¯å’Œè¾¹ç•Œæ¡†è½¬æ¢ä¸ºæ ‡è®°çº§`input_ids`ã€`attention_mask`ã€`token_type_ids`ã€`bbox`ã€‚å¯é€‰åœ°ï¼Œå¯ä»¥æä¾›æ•´æ•°`word_labels`ï¼Œè¿™äº›æ ‡ç­¾è¢«è½¬æ¢ä¸ºç”¨äºæ ‡è®°åˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚FUNSDã€CORDï¼‰çš„æ ‡è®°çº§`labels`ã€‚ 

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/processing_layoutlmv3.py#L69)

```py
( images text: Union = None text_pair: Union = None boxes: Union = None word_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True return_tensors: Union = None **kwargs )
```

æ­¤æ–¹æ³•é¦–å…ˆå°†`images`å‚æ•°è½¬å‘åˆ°[**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚å¦‚æœ[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)åˆå§‹åŒ–æ—¶å°†`apply_ocr`è®¾ç½®ä¸º`True`ï¼Œåˆ™å°†è·å¾—çš„å•è¯å’Œè¾¹ç•Œæ¡†è¿åŒå…¶ä»–å‚æ•°ä¼ é€’ç»™[**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer.__call__)å¹¶è¿”å›è¾“å‡ºï¼Œä»¥åŠè°ƒæ•´å¤§å°å’Œè§„èŒƒåŒ–çš„`pixel_values`ã€‚å¦‚æœ[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)åˆå§‹åŒ–æ—¶å°†`apply_ocr`è®¾ç½®ä¸º`False`ï¼Œåˆ™å°†ç”¨æˆ·æŒ‡å®šçš„å•è¯ï¼ˆ`text`/``text_pair`ï¼‰å’Œ`boxes`è¿åŒå…¶ä»–å‚æ•°ä¼ é€’ç»™[**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer.__call__)å¹¶è¿”å›è¾“å‡ºï¼Œä»¥åŠè°ƒæ•´å¤§å°å’Œè§„èŒƒåŒ–çš„`pixel_values`ã€‚

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒä¸Šè¿°ä¸¤ç§æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚

Pytorchéšè— Pytorchå†…å®¹

## LayoutLMv3Model

### `class transformers.LayoutLMv3Model`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L734)

```py
( config )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰- æ¨¡å‹çš„æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸çš„LayoutLMv3æ¨¡å‹å˜æ¢å™¨è¾“å‡ºæ²¡æœ‰ç‰¹å®šå¤´éƒ¨çš„åŸå§‹éšè—çŠ¶æ€ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L827)

```py
( input_ids: Optional = None bbox: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `input_ids` (`torch.LongTensor` of shape `(batch_size, token_sequence_length)`) â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    [ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)

+   `bbox` (`torch.LongTensor` of shape `(batch_size, token_sequence_length, 4)`, *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯ä¸€ä¸ªè§„èŒƒåŒ–ç‰ˆæœ¬ï¼Œæ ¼å¼ä¸º(x0, y0, x1, y1)ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

+   `pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`) â€” æ–‡æ¡£å›¾åƒçš„æ‰¹å¤„ç†ã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º`(num_channels, config.patch_size, config.patch_size)`çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°(=`patch_sequence_length`)ç­‰äº`((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask` (`torch.FloatTensor` of shape `(batch_size, token_sequence_length)`, *optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   1è¡¨ç¤ºæœªè¢«å±è”½çš„æ ‡è®°ï¼Œ

    +   0è¡¨ç¤ºè¢«å±è”½çš„æ ‡è®°ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids` (`torch.LongTensor` of shape `(batch_size, token_sequence_length)`, *optional*) â€” æŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†çš„æ®µæ ‡è®°ç´¢å¼•ã€‚ç´¢å¼•é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   0å¯¹åº”äº*å¥å­A*æ ‡è®°ï¼Œ

    +   1å¯¹åº”äº*å¥å­B*æ ‡è®°ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids` (`torch.LongTensor` of shape `(batch_size, token_sequence_length)`, *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)

+   `head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, token_sequence_length, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)æˆ–`tuple(torch.FloatTensor)`

ä¸€ä¸ª[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…æ‹¬æ ¹æ®é…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚

+   `last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼‰â€” æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚çš„è¾“å‡ºï¼Œåˆ™ä¸ºåµŒå…¥å±‚çš„è¾“å‡º+æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºéšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–å½“`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚

    åœ¨æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, AutoModel
>>> from datasets import load_dataset

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = AutoModel.from_pretrained("microsoft/layoutlmv3-base")

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> words = example["tokens"]
>>> boxes = example["bboxes"]

>>> encoding = processor(image, words, boxes=boxes, return_tensors="pt")

>>> outputs = model(**encoding)
>>> last_hidden_states = outputs.last_hidden_state
```

## LayoutLMv3ForSequenceClassification

### `class transformers.LayoutLMv3ForSequenceClassification`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1259)

```py
( config )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

LayoutLMv3æ¨¡å‹åœ¨é¡¶éƒ¨å…·æœ‰åºåˆ—åˆ†ç±»å¤´éƒ¨ï¼ˆåœ¨[CLS]æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºæ–‡æ¡£å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œå¦‚[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)æ•°æ®é›†ã€‚

è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1277)

```py
( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None bbox: Optional = None pixel_values: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.SequenceClassifierOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚

    å¯ä»¥ä½¿ç”¨ [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer) è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode) å’Œ [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    [ä»€ä¹ˆæ˜¯è¾“å…¥ IDï¼Ÿ](../glossary#input-ids)

+   `bbox` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length, 4)`ï¼Œ*optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰å®šèŒƒå›´ä¸º `[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯ (x0, y0, x1, y1) æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­ (x0, y0) å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1) è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

+   `pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, num_channels, height, width)`) â€” æ–‡æ¡£å›¾åƒçš„æ‰¹å¤„ç†ã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º `(num_channels, config.patch_size, config.patch_size)` çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº `((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`ï¼Œ*optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰å®šåœ¨ `[0, 1]` ä¹‹é—´ï¼š

    +   1 ä»£è¡¨æœªè¢« `masked` çš„æ ‡è®°ï¼Œ

    +   0 ä»£è¡¨è¢« `masked` çš„æ ‡è®°ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`ï¼Œ*optional*) â€” æ®µæ ‡è®°ç´¢å¼•ï¼ŒæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•é€‰å®šåœ¨ `[0, 1]` ä¹‹é—´ï¼š

    +   0 å¯¹åº”äº *å¥å­ A* æ ‡è®°ï¼Œ

    +   1 å¯¹åº”äº *å¥å­ B* æ ‡è®°ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹ IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`ï¼Œ*optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰å®šèŒƒå›´ä¸º `[0, config.max_position_embeddings - 1]`ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½® IDï¼Ÿ](../glossary#position-ids)

+   `head_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(num_heads,)` æˆ– `(num_layers, num_heads)`ï¼Œ*optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰å®šåœ¨ `[0, 1]` ä¹‹é—´ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªè¢« `masked`ï¼Œ

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢« `masked`ã€‚

+   `inputs_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length, hidden_size)`ï¼Œ*optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’ `input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶æƒï¼Œä»¥ä¾¿å°† *input_ids* ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„ `attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„ `hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput) æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput) æˆ– `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ– `config.return_dict=False`ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥ä¸åŒå…ƒç´ ã€‚

+   `loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰- åˆ†ç±»ï¼ˆå¦‚æœconfig.num_labels==1åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰- åˆ†ç±»ï¼ˆå¦‚æœconfig.num_labels==1åˆ™ä¸ºå›å½’ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚

    æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚

    æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ æ’­çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, AutoModelForSequenceClassification
>>> from datasets import load_dataset
>>> import torch

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = AutoModelForSequenceClassification.from_pretrained("microsoft/layoutlmv3-base")

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> words = example["tokens"]
>>> boxes = example["bboxes"]

>>> encoding = processor(image, words, boxes=boxes, return_tensors="pt")
>>> sequence_label = torch.tensor([1])

>>> outputs = model(**encoding, labels=sequence_label)
>>> loss = outputs.loss
>>> logits = outputs.logits
```

## LayoutLMv3ForTokenClassification

### `class transformers.LayoutLMv3ForTokenClassification`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1016)

```py
( config )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰- å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

LayoutLMv3æ¨¡å‹ï¼Œé¡¶éƒ¨å¸¦æœ‰ä¸€ä¸ªæ ‡è®°åˆ†ç±»å¤´ï¼ˆæœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºåºåˆ—æ ‡è®°ï¼ˆä¿¡æ¯æå–ï¼‰ä»»åŠ¡çš„[FUNSD](https://guillaumejaume.github.io/FUNSD/)ã€[SROIE](https://rrc.cvc.uab.es/?ch=13)ã€[CORD](https://github.com/clovaai/cord)å’Œ[Kleister-NDA](https://github.com/applicaai/kleister-nda)ã€‚

æ­¤æ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯ã€‚

#### `å‰å‘ä¼ æ’­`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1039)

```py
( input_ids: Optional = None bbox: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None pixel_values: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.TokenClassifierOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰- è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æŸ¥çœ‹[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)è·å–è¯¦ç»†ä¿¡æ¯ã€‚

    [ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)

+   `bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚åœ¨èŒƒå›´ `[0, config.max_2d_position_embeddings-1]` ä¸­é€‰æ‹©ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯ (x0, y0, x1, y1) æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­ (x0, y0) å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œè€Œ (x1, y1) è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

+   `pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`) â€” æ–‡æ¡£å›¾åƒçš„æ‰¹å¤„ç†ã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º `(num_channels, config.patch_size, config.patch_size)` çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº `((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   å¯¹äºæœªè¢« `masked` çš„æ ‡è®°ä¸º 1ï¼Œ

    +   å¯¹äºè¢« `masked` çš„æ ‡è®°ä¸º 0ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” æ®µæ ‡è®°ç´¢å¼•ï¼ŒæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   0 å¯¹åº”äº *å¥å­ A* æ ‡è®°ï¼Œ

    +   1 å¯¹åº”äº *å¥å­ B* æ ‡è®°ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹ IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´ `[0, config.max_position_embeddings - 1]` ä¸­é€‰æ‹©ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½® IDï¼Ÿ](../glossary#position-ids)

+   `head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªè¢« `masked`ï¼Œ

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢« `masked`ã€‚

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’ `input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶æƒæ¥å°† *input_ids* ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè¿™å°†éå¸¸æœ‰ç”¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„ `attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„ `hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šå…ƒç»„ã€‚

+   `labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” ç”¨äºè®¡ç®—æ ‡è®°åˆ†ç±»æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨ `[0, ..., config.num_labels - 1]` ä¸­ã€‚

è¿”å›

[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput) æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª [transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput) æˆ–ä¸€ä¸ª `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå…·ä½“å–å†³äºé…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥ã€‚

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, å½“æä¾› `labels` æ—¶è¿”å›) â€” åˆ†ç±»æŸå¤±ã€‚

+   `logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`) â€” åˆ†ç±»å¾—åˆ†ï¼ˆSoftMax ä¹‹å‰ï¼‰ã€‚

+   `hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰çš„*, å½“ä¼ é€’`output_hidden_states=True`æˆ–è€…å½“`config.output_hidden_states=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡ºï¼Œå¦‚æœæ¨¡å‹æœ‰ä¸€ä¸ªåµŒå…¥å±‚ï¼Œ+ ä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰çš„*, å½“ä¼ é€’`output_attentions=True`æˆ–è€…å½“`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚

    åœ¨æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, AutoModelForTokenClassification
>>> from datasets import load_dataset

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = AutoModelForTokenClassification.from_pretrained("microsoft/layoutlmv3-base", num_labels=7)

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> words = example["tokens"]
>>> boxes = example["bboxes"]
>>> word_labels = example["ner_tags"]

>>> encoding = processor(image, words, boxes=boxes, word_labels=word_labels, return_tensors="pt")

>>> outputs = model(**encoding)
>>> loss = outputs.loss
>>> logits = outputs.logits
```

## LayoutLMv3ForQuestionAnswering

### `class transformers.LayoutLMv3ForQuestionAnswering`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1129)

```py
( config )
```

å‚æ•°

+   `config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)) â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

LayoutLMv3æ¨¡å‹ï¼Œé¡¶éƒ¨å¸¦æœ‰ä¸€ä¸ªç”¨äºæå–é—®ç­”ä»»åŠ¡çš„è·¨åº¦åˆ†ç±»å¤´ï¼Œä¾‹å¦‚[DocVQA](https://rrc.cvc.uab.es/?ch=17)ï¼ˆåœ¨éšè—çŠ¶æ€è¾“å‡ºçš„æ–‡æœ¬éƒ¨åˆ†é¡¶éƒ¨çš„çº¿æ€§å±‚ï¼Œç”¨äºè®¡ç®—`span start logits`å’Œ`span end logits`ï¼‰ã€‚

è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1147)

```py
( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None start_positions: Optional = None end_positions: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None bbox: Optional = None pixel_values: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.QuestionAnsweringModelOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `input_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`) â€” è¾“å…¥åºåˆ—æ ‡è®°åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚è¯¦æƒ…è¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ

+   `bbox` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`ï¼Œ*å¯é€‰çš„*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

+   `pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`) â€” æ–‡æ¡£å›¾åƒçš„æ‰¹å¤„ç†ã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º `(num_channels, config.patch_size, config.patch_size)` çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº `((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   1 è¡¨ç¤ºæœªè¢«å±è”½çš„æ ‡è®°ï¼Œ

    +   0 è¡¨ç¤ºè¢«å±è”½çš„æ ‡è®°ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” æ®µè½æ ‡è®°ç´¢å¼•ï¼Œç”¨äºæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   0 å¯¹åº”äº *å¥å­ A* æ ‡è®°ï¼Œ

    +   1 å¯¹åº”äº *å¥å­ B* æ ‡è®°ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´ `[0, config.max_position_embeddings - 1]` ä¸­é€‰æ‹©ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)

+   `head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’ `input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°† *input_ids* ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„ `attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„ `hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” ç”¨äºè®¡ç®—æ ‡è®°èŒƒå›´å¼€å§‹ä½ç½®çš„æ ‡ç­¾ï¼ˆç´¢å¼•ï¼‰ã€‚ä½ç½®è¢«å¤¹ç´§åˆ°åºåˆ—çš„é•¿åº¦ (`sequence_length`)ã€‚è¶…å‡ºåºåˆ—èŒƒå›´çš„ä½ç½®ä¸ä¼šç”¨äºè®¡ç®—æŸå¤±ã€‚

+   `end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” ç”¨äºè®¡ç®—æ ‡è®°èŒƒå›´ç»“æŸä½ç½®çš„æ ‡ç­¾ï¼ˆç´¢å¼•ï¼‰ã€‚ä½ç½®è¢«å¤¹ç´§åˆ°åºåˆ—çš„é•¿åº¦ (`sequence_length`)ã€‚è¶…å‡ºåºåˆ—èŒƒå›´çš„ä½ç½®ä¸ä¼šç”¨äºè®¡ç®—æŸå¤±ã€‚

è¿”å›

[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput) æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput) æˆ–ä¸€ä¸ª `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, å½“æä¾› `labels` æ—¶è¿”å›) â€” æ€»è·¨åº¦æå–æŸå¤±æ˜¯å¼€å§‹å’Œç»“æŸä½ç½®çš„äº¤å‰ç†µä¹‹å’Œã€‚

+   `start_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.FloatTensor`ï¼‰-è·¨åº¦å¼€å§‹åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `end_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.FloatTensor`ï¼‰-è·¨åº¦ç»“æŸåˆ†æ•°ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚çš„è¾“å‡º+æ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºå¤„çš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚

    åœ¨æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

å°½ç®¡å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œå‰å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…åˆ™é»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering
>>> from datasets import load_dataset
>>> import torch

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = AutoModelForQuestionAnswering.from_pretrained("microsoft/layoutlmv3-base")

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> question = "what's his name?"
>>> words = example["tokens"]
>>> boxes = example["bboxes"]

>>> encoding = processor(image, question, words, boxes=boxes, return_tensors="pt")
>>> start_positions = torch.tensor([1])
>>> end_positions = torch.tensor([3])

>>> outputs = model(**encoding, start_positions=start_positions, end_positions=end_positions)
>>> loss = outputs.loss
>>> start_scores = outputs.start_logits
>>> end_scores = outputs.end_logits
```

TensorFlowéšè—TensorFlowå†…å®¹

## TFLayoutLMv3Model

### `class transformers.TFLayoutLMv3Model`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1257)

```py
( config *inputs **kwargs )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Configï¼‰ï¼‰-æ¨¡å‹é…ç½®ç±»ï¼Œå…·æœ‰æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸çš„LayoutLMv3æ¨¡å‹å˜å‹å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºå…¶æ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

è¯¥æ¨¡å‹è¿˜æ˜¯ä¸€ä¸ª[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„TF 2.0 Kerasæ¨¡å‹ï¼Œå¹¶å‚è€ƒTF 2.0æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

TensorFlowæ¨¡å‹å’Œ`transformers`ä¸­çš„å±‚æ¥å—ä¸¤ç§æ ¼å¼çš„è¾“å…¥ï¼š

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºå…³é”®å­—å‚æ•°ï¼ˆå¦‚PyTorchæ¨¡å‹ï¼‰ï¼Œ

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºåˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸æ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­ã€‚

æ”¯æŒç¬¬äºŒç§æ ¼å¼çš„åŸå› æ˜¯Kerasæ–¹æ³•åœ¨å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å’Œå±‚æ—¶æ›´å–œæ¬¢è¿™ç§æ ¼å¼ã€‚ç”±äºè¿™ç§æ”¯æŒï¼Œå½“ä½¿ç”¨`model.fit()`ç­‰æ–¹æ³•æ—¶ï¼Œåº”è¯¥â€œåªéœ€å·¥ä½œâ€-åªéœ€ä¼ é€’æ‚¨çš„è¾“å…¥å’Œæ ‡ç­¾ä»¥ä»»ä½•`model.fit()`æ”¯æŒçš„æ ¼å¼ï¼ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³åœ¨Kerasæ–¹æ³•ä¹‹å¤–ä½¿ç”¨ç¬¬äºŒç§æ ¼å¼ï¼Œä¾‹å¦‚åœ¨ä½¿ç”¨Keras`Functional`APIåˆ›å»ºè‡ªå·±çš„å±‚æˆ–æ¨¡å‹æ—¶ï¼Œæœ‰ä¸‰ç§å¯èƒ½æ€§å¯ç”¨äºæ”¶é›†ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­çš„æ‰€æœ‰è¾“å…¥å¼ é‡ï¼š

+   åªæœ‰`input_ids`çš„å•ä¸ªå¼ é‡ï¼Œæ²¡æœ‰å…¶ä»–å†…å®¹ï¼š`model(input_ids)`

+   ä¸€ä¸ªå…·æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å¼ é‡çš„å˜é•¿åˆ—è¡¨ï¼ŒæŒ‰ç…§æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„é¡ºåºï¼š`model([input_ids, attention_mask])`æˆ–`model([input_ids, attention_mask, token_type_ids])`

+   ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„è¾“å…¥åç§°ç›¸å…³è”çš„ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å¼ é‡ï¼š`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

è¯·æ³¨æ„ï¼Œå½“ä½¿ç”¨[å­ç±»åŒ–](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)åˆ›å»ºæ¨¡å‹å’Œå±‚æ—¶ï¼Œæ‚¨æ— éœ€æ‹…å¿ƒè¿™äº›é—®é¢˜ï¼Œå› ä¸ºæ‚¨å¯ä»¥åƒå¯¹å¾…å…¶ä»–Pythonå‡½æ•°ä¸€æ ·ä¼ é€’è¾“å…¥ï¼

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1269)

```py
( input_ids: tf.Tensor | None = None bbox: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None pixel_values: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFBaseModelOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼‰- è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    [ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)

+   `bbox`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰- æ–‡æ¡£å›¾åƒçš„æ‰¹å¤„ç†ã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º`(num_channels, config.patch_size, config.patch_size)`çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº`((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   å¯¹äºæœªè¢«æ©ç çš„æ ‡è®°ï¼Œä¸º1ï¼Œ

    +   å¯¹äºè¢«æ©ç çš„æ ‡è®°ä¸º0ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- æŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†çš„æ®µæ ‡è®°ç´¢å¼•ã€‚ç´¢å¼•é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   0å¯¹åº”äº*å¥å­A*æ ‡è®°ï¼Œ

    +   1å¯¹åº”äº*å¥å­B*æ ‡è®°ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç ã€‚

+   `inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè¿™å¾ˆæœ‰ç”¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µã€‚

+   `output_attentions`ï¼ˆ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

[transformers.modeling_tf_outputs.TFBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput)æˆ–`tuple(tf.Tensor)`

[transformers.modeling_tf_outputs.TFBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥ã€‚

+   `last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼‰â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—è¾“å‡ºã€‚

+   `hidden_states`ï¼ˆ*å¯é€‰çš„*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºéšè—çŠ¶æ€ä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions` (`tuple(tf.Tensor)`, *å¯é€‰çš„*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–å½“`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚

    åœ¨è‡ªæ³¨æ„åŠ›å¤´ä¸­ç”¨äºè®¡ç®—åŠ æƒå¹³å‡å€¼çš„æ³¨æ„åŠ›æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åã€‚

[TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, TFAutoModel
>>> from datasets import load_dataset

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = TFAutoModel.from_pretrained("microsoft/layoutlmv3-base")

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> words = example["tokens"]
>>> boxes = example["bboxes"]

>>> encoding = processor(image, words, boxes=boxes, return_tensors="tf")

>>> outputs = model(**encoding)
>>> last_hidden_states = outputs.last_hidden_state
```

## TFLayoutLMv3ForSequenceClassification

### `class transformers.TFLayoutLMv3ForSequenceClassification`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1391)

```py
( config: LayoutLMv3Config **kwargs )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

LayoutLMv3æ¨¡å‹åœ¨é¡¶éƒ¨å¸¦æœ‰åºåˆ—åˆ†ç±»å¤´ï¼ˆåœ¨[CLS]æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºæ–‡æ¡£å›¾åƒåˆ†ç±»ä»»åŠ¡çš„[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)æ•°æ®é›†ã€‚

æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ª[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„TF 2.0 Kerasæ¨¡å‹ï¼Œå¹¶å‚è€ƒTF 2.0æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯ã€‚

`transformers`ä¸­çš„TensorFlowæ¨¡å‹å’Œå±‚æ¥å—ä¸¤ç§æ ¼å¼çš„è¾“å…¥ï¼š

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºå…³é”®å­—å‚æ•°ï¼ˆç±»ä¼¼äºPyTorchæ¨¡å‹ï¼‰ï¼Œæˆ–

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºåˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸æ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­ã€‚

æ”¯æŒç¬¬äºŒç§æ ¼å¼çš„åŸå› æ˜¯Kerasæ–¹æ³•åœ¨å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å’Œå±‚æ—¶æ›´å–œæ¬¢è¿™ç§æ ¼å¼ã€‚ç”±äºæœ‰æ­¤æ”¯æŒï¼Œå½“ä½¿ç”¨`model.fit()`ç­‰æ–¹æ³•æ—¶ï¼Œåº”è¯¥å¯ä»¥â€œæ­£å¸¸å·¥ä½œâ€ - åªéœ€ä»¥`model.fit()`æ”¯æŒçš„ä»»ä½•æ ¼å¼ä¼ é€’è¾“å…¥å’Œæ ‡ç­¾å³å¯ï¼ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³åœ¨Kerasæ–¹æ³•ä¹‹å¤–ä½¿ç”¨ç¬¬äºŒç§æ ¼å¼ï¼Œä¾‹å¦‚åœ¨ä½¿ç”¨Keras`Functional`APIåˆ›å»ºè‡ªå·±çš„å±‚æˆ–æ¨¡å‹æ—¶ï¼Œæœ‰ä¸‰ç§å¯èƒ½æ€§å¯ç”¨äºæ”¶é›†æ‰€æœ‰è¾“å…¥å¼ é‡æ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­ï¼š

+   ä¸€ä¸ªä»…åŒ…å«`input_ids`çš„å•ä¸ªå¼ é‡ï¼Œæ²¡æœ‰å…¶ä»–å†…å®¹ï¼š`model(input_ids)`

+   ä¸€ä¸ªé•¿åº¦å¯å˜çš„åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«æŒ‰ç…§æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„é¡ºåºçš„ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å¼ é‡ï¼š`model([input_ids, attention_mask])`æˆ–`model([input_ids, attention_mask, token_type_ids])`

+   ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªä¸æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„è¾“å…¥åç§°ç›¸å…³è”çš„è¾“å…¥å¼ é‡ï¼š`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

è¯·æ³¨æ„ï¼Œåœ¨ä½¿ç”¨[å­ç±»åŒ–](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)åˆ›å»ºæ¨¡å‹å’Œå±‚æ—¶ï¼Œæ‚¨æ— éœ€æ‹…å¿ƒè¿™äº›ï¼Œå› ä¸ºæ‚¨å¯ä»¥åƒå¯¹å¾…ä»»ä½•å…¶ä»–Pythonå‡½æ•°ä¸€æ ·ä¼ é€’è¾“å…¥ï¼

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1409)

```py
( input_ids: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None bbox: tf.Tensor | None = None pixel_values: tf.Tensor | None = None training: Optional[bool] = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSequenceClassifierOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼‰- è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    [ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)

+   `bbox`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰- æ‰¹é‡æ–‡æ¡£å›¾åƒã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º`(num_channels, config.patch_size, config.patch_size)`çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº`((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é€‰æ‹©çš„æ©ç å€¼åœ¨`[0, 1]`ä¸­ï¼š

    +   1è¡¨ç¤ºæœªè¢«â€œmaskedâ€çš„æ ‡è®°ï¼Œ

    +   å¯¹äºè¢«`masked`çš„æ ‡è®°ã€‚

    è¯·æ³¨æ„`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids`ï¼ˆ`Numpyæ•°ç»„`æˆ–å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ®µæ ‡è®°ç´¢å¼•ï¼ŒæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   0å¯¹åº”äº*å¥å­A*æ ‡è®°ï¼Œ

    +   1å¯¹åº”äº*å¥å­B*æ ‡è®°ã€‚

    è¯·æ³¨æ„`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids`ï¼ˆ`Numpyæ•°ç»„`æˆ–å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚

    è¯·æ³¨æ„`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`ï¼Œè¯·å‚é˜…`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚é€‰æ‹©çš„æ©ç å€¼åœ¨`[0, 1]`ä¸­ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«â€œmaskedâ€ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚

+   `inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨å¸Œæœ›æ›´å¤šåœ°æ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)æˆ–`tuple(tf.Tensor)`

[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…æ‹¬æ ¹æ®é…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚

+   `loss`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, )`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼Œåœ¨æä¾›`labels`æ—¶è¿”å›ï¼‰â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œåœ¨ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚

    åœ¨æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)çš„å‰å‘æ–¹æ³•è¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

å°½ç®¡éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰å‰å‘ä¼ é€’çš„æ­¥éª¤ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è°ƒç”¨æ­¤å‡½æ•°ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, TFAutoModelForSequenceClassification
>>> from datasets import load_dataset
>>> import tensorflow as tf

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = TFAutoModelForSequenceClassification.from_pretrained("microsoft/layoutlmv3-base")

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> words = example["tokens"]
>>> boxes = example["bboxes"]

>>> encoding = processor(image, words, boxes=boxes, return_tensors="tf")
>>> sequence_label = tf.convert_to_tensor([1])

>>> outputs = model(**encoding, labels=sequence_label)
>>> loss = outputs.loss
>>> logits = outputs.logits
```

## TFLayoutLMv3ForTokenClassification

### `class transformers.TFLayoutLMv3ForTokenClassification`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1505)

```py
( config: LayoutLMv3Config **kwargs )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Configï¼‰ï¼‰- å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

LayoutLMv3æ¨¡å‹åœ¨é¡¶éƒ¨å¸¦æœ‰ä¸€ä¸ªæ ‡è®°åˆ†ç±»å¤´ï¼ˆåœ¨æœ€ç»ˆéšè—çŠ¶æ€çš„é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºåºåˆ—æ ‡è®°ï¼ˆä¿¡æ¯æå–ï¼‰ä»»åŠ¡çš„[FUNSD](https://guillaumejaume.github.io/FUNSD/)ã€[SROIE](https://rrc.cvc.uab.es/?ch=13)ã€[CORD](https://github.com/clovaai/cord)å’Œ[Kleister-NDA](https://github.com/applicaai/kleister-nda)ã€‚

æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹è¿˜æ˜¯[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„TF 2.0 Kerasæ¨¡å‹ï¼Œå¹¶å‚è€ƒTF 2.0æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯ã€‚

`transformers`ä¸­çš„TensorFlowæ¨¡å‹å’Œå±‚æ¥å—ä¸¤ç§æ ¼å¼çš„è¾“å…¥ï¼š

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºå…³é”®å­—å‚æ•°ï¼ˆç±»ä¼¼äºPyTorchæ¨¡å‹ï¼‰ï¼Œæˆ–

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºåˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸æ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­ã€‚

ç¬¬äºŒç§æ ¼å¼å¾—åˆ°æ”¯æŒçš„åŸå› æ˜¯ï¼Œå½“å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å’Œå±‚æ—¶ï¼ŒKerasæ–¹æ³•æ›´å–œæ¬¢è¿™ç§æ ¼å¼ã€‚ç”±äºè¿™ç§æ”¯æŒï¼Œå½“ä½¿ç”¨è¯¸å¦‚`model.fit()`ä¹‹ç±»çš„æ–¹æ³•æ—¶ï¼Œå¯¹æ‚¨æ¥è¯´åº”è¯¥â€œåªéœ€å·¥ä½œâ€ - åªéœ€ä»¥`model.fit()`æ”¯æŒçš„ä»»ä½•æ ¼å¼ä¼ é€’æ‚¨çš„è¾“å…¥å’Œæ ‡ç­¾ï¼ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³åœ¨Kerasæ–¹æ³•ä¹‹å¤–ä½¿ç”¨ç¬¬äºŒç§æ ¼å¼ï¼Œæ¯”å¦‚åœ¨ä½¿ç”¨Keras`Functional` APIåˆ›å»ºè‡ªå·±çš„å±‚æˆ–æ¨¡å‹æ—¶ï¼Œæœ‰ä¸‰ç§å¯èƒ½æ€§å¯ä»¥ç”¨æ¥æ”¶é›†æ‰€æœ‰è¾“å…¥å¼ é‡åœ¨ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­ï¼š

+   åªåŒ…å«`input_ids`çš„å•ä¸ªå¼ é‡ï¼Œæ²¡æœ‰å…¶ä»–å†…å®¹ï¼š`model(input_ids)`

+   æŒ‰ç…§æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„é¡ºåºï¼Œé•¿åº¦å¯å˜çš„åˆ—è¡¨ï¼ŒåŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å¼ é‡ï¼š`model([input_ids, attention_mask])`æˆ–`model([input_ids, attention_mask, token_type_ids])`

+   ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„è¾“å…¥åç§°ç›¸å…³è”çš„ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å¼ é‡ï¼š`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

è¯·æ³¨æ„ï¼Œå½“ä½¿ç”¨[å­ç±»åŒ–](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)åˆ›å»ºæ¨¡å‹å’Œå±‚æ—¶ï¼Œæ‚¨æ— éœ€æ‹…å¿ƒè¿™äº›é—®é¢˜ï¼Œå› ä¸ºæ‚¨å¯ä»¥åƒå¯¹å¾…ä»»ä½•å…¶ä»–Pythonå‡½æ•°ä¸€æ ·ä¼ é€’è¾“å…¥ï¼

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1534)

```py
( input_ids: tf.Tensor | None = None bbox: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None pixel_values: tf.Tensor | None = None training: Optional[bool] = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFTokenClassifierOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼‰â€” è¾“å…¥åºåˆ—ä»¤ç‰Œåœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ã€‚

    æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]ä»¤ç‰Œã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ

+   `bbox`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ¯ä¸ªè¾“å…¥åºåˆ—ä»¤ç‰Œçš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

    æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]ä»¤ç‰Œã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰â€” æ–‡æ¡£å›¾åƒçš„æ‰¹å¤„ç†ã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º`(num_channels, config.patch_size, config.patch_size)`çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº`((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¿å…åœ¨å¡«å……ä»¤ç‰Œç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…çš„æ©ç å€¼ï¼š

    +   1è¡¨ç¤ºæœªè¢«`æ©ç `çš„ä»¤ç‰Œã€‚

    +   0è¡¨ç¤ºè¢«`æ©ç `çš„ä»¤ç‰Œã€‚

    æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]ä»¤ç‰Œã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ

+   `token_type_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ®µä»¤ç‰Œç´¢å¼•ï¼Œç”¨äºæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   0å¯¹åº”äº*å¥å­A*ä»¤ç‰Œï¼Œ

    +   1å¯¹åº”äº*å¥å­B*ä»¤ç‰Œã€‚

    æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]ä»¤ç‰Œã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

    ä»€ä¹ˆæ˜¯ä»¤ç‰Œç±»å‹IDï¼Ÿ

+   `position_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ¯ä¸ªè¾“å…¥åºåˆ—ä»¤ç‰Œåœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚

    æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]ä»¤ç‰Œã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

    ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…çš„æ©ç å€¼ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`æ©ç `ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨è¢«`æ©ç `ã€‚

+   `inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè¿™å°†å¾ˆæœ‰ç”¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µã€‚

+   `output_attentions` (`bool`ï¼Œ*å¯é€‰*ï¼‰ â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`ï¼Œ*å¯é€‰*ï¼‰ â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`ï¼Œ*å¯é€‰*ï¼‰ â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels` (`tf.Tensor` of shape `(batch_size, sequence_length)`ï¼Œ*å¯é€‰*ï¼‰ â€” ç”¨äºè®¡ç®—æ ‡è®°åˆ†ç±»æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0, ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚

è¿”å›

[transformers.modeling_tf_outputs.TFTokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput)æˆ–`tuple(tf.Tensor)`

ä¸€ä¸ª[transformers.modeling_tf_outputs.TFTokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚

+   `loss` (`tf.Tensor` of shape `(n,)`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼Œå…¶ä¸­næ˜¯æœªå±è”½æ ‡ç­¾çš„æ•°é‡ï¼‰ â€” åˆ†ç±»æŸå¤±ã€‚

+   `logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.num_labels)`) â€” åˆ†ç±»å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `hidden_states` (`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„éšè—çŠ¶æ€ä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions` (`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚

    æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, TFAutoModelForTokenClassification
>>> from datasets import load_dataset

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = TFAutoModelForTokenClassification.from_pretrained("microsoft/layoutlmv3-base", num_labels=7)

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> words = example["tokens"]
>>> boxes = example["bboxes"]
>>> word_labels = example["ner_tags"]

>>> encoding = processor(image, words, boxes=boxes, word_labels=word_labels, return_tensors="tf")

>>> outputs = model(**encoding)
>>> loss = outputs.loss
>>> logits = outputs.logits
```

## TFLayoutLMv3ForQuestionAnswering

### `class transformers.TFLayoutLMv3ForQuestionAnswering`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1643)

```py
( config: LayoutLMv3Config **kwargs )
```

å‚æ•°

+   `config`ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰ â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

LayoutLMv3æ¨¡å‹ï¼Œé¡¶éƒ¨å¸¦æœ‰ç”¨äºæå–é—®ç­”ä»»åŠ¡çš„è·¨åº¦åˆ†ç±»å¤´ï¼Œä¾‹å¦‚[DocVQA](https://rrc.cvc.uab.es/?ch=17)ï¼ˆåœ¨éšè—çŠ¶æ€è¾“å‡ºçš„æ–‡æœ¬éƒ¨åˆ†é¡¶éƒ¨çš„çº¿æ€§å±‚ï¼Œç”¨äºè®¡ç®—`span start logits`å’Œ`span end logits`ï¼‰ã€‚

æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºå…¶æ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹è¿˜æ˜¯ä¸€ä¸ª[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„TF 2.0 Kerasæ¨¡å‹ï¼Œå¹¶å‚è€ƒTF 2.0æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

`transformers`ä¸­çš„TensorFlowæ¨¡å‹å’Œå±‚æ¥å—ä¸¤ç§æ ¼å¼çš„è¾“å…¥ï¼š

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºå…³é”®å­—å‚æ•°ï¼ˆç±»ä¼¼äºPyTorchæ¨¡å‹ï¼‰ï¼Œæˆ–è€…

+   å°†æ‰€æœ‰è¾“å…¥ä½œä¸ºåˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸çš„ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ã€‚

æ”¯æŒç¬¬äºŒç§æ ¼å¼çš„åŸå› æ˜¯ï¼ŒKerasæ–¹æ³•åœ¨å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å’Œå±‚æ—¶æ›´å–œæ¬¢è¿™ç§æ ¼å¼ã€‚ç”±äºè¿™ç§æ”¯æŒï¼Œå½“ä½¿ç”¨`model.fit()`ç­‰æ–¹æ³•æ—¶ï¼Œåº”è¯¥å¯ä»¥â€œæ­£å¸¸å·¥ä½œâ€ - åªéœ€ä»¥`model.fit()`æ”¯æŒçš„ä»»ä½•æ ¼å¼ä¼ é€’è¾“å…¥å’Œæ ‡ç­¾å³å¯ï¼ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³åœ¨Kerasæ–¹æ³•ä¹‹å¤–ä½¿ç”¨ç¬¬äºŒç§æ ¼å¼ï¼Œä¾‹å¦‚åœ¨ä½¿ç”¨Keras`Functional` APIåˆ›å»ºè‡ªå·±çš„å±‚æˆ–æ¨¡å‹æ—¶ï¼Œæœ‰ä¸‰ç§å¯èƒ½æ€§å¯ç”¨äºåœ¨ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°ä¸­æ”¶é›†æ‰€æœ‰è¾“å…¥å¼ é‡ï¼š

+   ä¸€ä¸ªä»…åŒ…å«`input_ids`çš„å•ä¸ªå¼ é‡ï¼Œæ²¡æœ‰å…¶ä»–å†…å®¹ï¼š`model(input_ids)`

+   ä¸€ä¸ªé•¿åº¦å¯å˜çš„åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‰ç…§æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šé¡ºåºçš„è¾“å…¥å¼ é‡ï¼š`model([input_ids, attention_mask])`æˆ–`model([input_ids, attention_mask, token_type_ids])`

+   ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªä¸æ–‡æ¡£å­—ç¬¦ä¸²ä¸­ç»™å®šçš„è¾“å…¥åç§°ç›¸å…³è”çš„è¾“å…¥å¼ é‡ï¼š`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

è¯·æ³¨æ„ï¼Œå½“ä½¿ç”¨[å­ç±»åŒ–](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)åˆ›å»ºæ¨¡å‹å’Œå±‚æ—¶ï¼Œæ‚¨æ— éœ€æ‹…å¿ƒä»»ä½•è¿™äº›ï¼Œå› ä¸ºæ‚¨å¯ä»¥åƒå¯¹å¾…ä»»ä½•å…¶ä»–Pythonå‡½æ•°ä¸€æ ·ä¼ é€’è¾“å…¥ï¼

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1663)

```py
( input_ids: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None start_positions: tf.Tensor | None = None end_positions: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None bbox: tf.Tensor | None = None pixel_values: tf.Tensor | None = None return_dict: Optional[bool] = None training: bool = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpyæ•°ç»„`æˆ–`tf.Tensor`ï¼‰ - è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

    å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚

    [ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)

+   `bbox`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`çš„`Numpyæ•°ç»„`æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰ - æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚åœ¨èŒƒå›´`[0, config.max_2d_position_embeddings-1]`ä¸­é€‰æ‹©ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æŸ¥çœ‹`pixel_values`ä»¥è·å–`patch_sequence_length`ã€‚

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰ - æ‰¹é‡æ–‡æ¡£å›¾åƒã€‚æ¯ä¸ªå›¾åƒè¢«åˆ†æˆå½¢çŠ¶ä¸º`(num_channels, config.patch_size, config.patch_size)`çš„è¡¥ä¸ï¼Œå¹¶ä¸”è¡¥ä¸çš„æ€»æ•°ï¼ˆ=`patch_sequence_length`ï¼‰ç­‰äº`((height / config.patch_size) * (width / config.patch_size))`ã€‚

+   `attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   1è¡¨ç¤ºæ ‡è®°æœªè¢«é®è”½ï¼Œ

    +   0è¡¨ç¤ºæ ‡è®°è¢«é®è”½ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›è’™ç‰ˆï¼Ÿ](../glossary#attention-mask)

+   `token_type_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ®µæ ‡è®°ç´¢å¼•ï¼Œç”¨äºæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   0å¯¹åº”äºä¸€ä¸ª*å¥å­A*çš„æ ‡è®°ï¼Œ

    +   1å¯¹åº”äºä¸€ä¸ª*å¥å­B*çš„æ ‡è®°ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)

+   `position_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`Numpy`æ•°ç»„æˆ–`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚

    è¯·æ³¨æ„ï¼Œ`sequence_length = token_sequence_length + patch_sequence_length + 1`ï¼Œå…¶ä¸­`1`ä»£è¡¨[CLS]æ ‡è®°ã€‚æœ‰å…³`patch_sequence_length`çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§`pixel_values`ã€‚

    [ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨æ— æ•ˆçš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®è”½ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨è¢«é®è”½ã€‚

+   `inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶æƒï¼Œä»¥ä¾¿å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šå…ƒç»„ã€‚

+   `start_positions`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—æ ‡è®°åˆ†ç±»æŸå¤±çš„æ ‡è®°ï¼ˆç´¢å¼•ï¼‰çš„æ ‡ç­¾çš„èµ·å§‹ä½ç½®ã€‚ä½ç½®è¢«å¤¹ç´§åˆ°åºåˆ—çš„é•¿åº¦ï¼ˆ`sequence_length`ï¼‰ã€‚è¶…å‡ºåºåˆ—èŒƒå›´çš„ä½ç½®ä¸ä¼šç”¨äºè®¡ç®—æŸå¤±ã€‚

+   `end_positions`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—æ ‡è®°åˆ†ç±»æŸå¤±çš„æ ‡è®°ï¼ˆç´¢å¼•ï¼‰çš„æ ‡ç­¾ã€‚ä½ç½®è¢«å¤¹ç´§åˆ°åºåˆ—çš„é•¿åº¦ï¼ˆ`sequence_length`ï¼‰ã€‚è¶…å‡ºåºåˆ—èŒƒå›´çš„ä½ç½®ä¸ä¼šç”¨äºè®¡ç®—æŸå¤±ã€‚

è¿”å›

[transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput)æˆ–`tuple(tf.Tensor)`

ä¸€ä¸ª[transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚

+   `loss` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, )`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾› `start_positions` å’Œ `end_positions` æ—¶è¿”å›ï¼‰ â€” æ€»è·¨åº¦æå–æŸå¤±æ˜¯èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®çš„äº¤å‰ç†µä¹‹å’Œã€‚

+   `start_logits` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`) â€” è·¨åº¦èµ·å§‹å¾—åˆ†ï¼ˆSoftMax ä¹‹å‰ï¼‰ã€‚

+   `end_logits` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`) â€” è·¨åº¦ç»“æŸå¾—åˆ†ï¼ˆSoftMax ä¹‹å‰ï¼‰ã€‚

+   `hidden_states` (`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’ `output_hidden_states=True` æˆ–å½“ `config.output_hidden_states=True` æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º `(batch_size, sequence_length, hidden_size)` çš„ `tf.Tensor` å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºçš„éšè—çŠ¶æ€ã€‚

+   `attentions` (`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’ `output_attentions=True` æˆ–å½“ `config.output_attentions=True` æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º `(batch_size, num_heads, sequence_length, sequence_length)` çš„ `tf.Tensor` å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚

    æ³¨æ„åŠ›æƒé‡åœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering) çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº† `__call__` ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨ `Module` å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…åˆ™é»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, TFAutoModelForQuestionAnswering
>>> from datasets import load_dataset
>>> import tensorflow as tf

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
>>> model = TFAutoModelForQuestionAnswering.from_pretrained("microsoft/layoutlmv3-base")

>>> dataset = load_dataset("nielsr/funsd-layoutlmv3", split="train")
>>> example = dataset[0]
>>> image = example["image"]
>>> question = "what's his name?"
>>> words = example["tokens"]
>>> boxes = example["bboxes"]

>>> encoding = processor(image, question, words, boxes=boxes, return_tensors="tf")
>>> start_positions = tf.convert_to_tensor([1])
>>> end_positions = tf.convert_to_tensor([3])

>>> outputs = model(**encoding, start_positions=start_positions, end_positions=end_positions)
>>> loss = outputs.loss
>>> start_scores = outputs.start_logits
>>> end_scores = outputs.end_logits
```
