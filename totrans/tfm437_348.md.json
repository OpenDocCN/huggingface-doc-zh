["```py\n( vocab_size = 32000 additional_vocab_size = 0 hidden_size = 4096 intermediate_size = 11008 num_hidden_layers = 32 num_attention_heads = 32 dropout = 0.0 hidden_act = 'silu' initializer_range = 0.02 alpha_initializer = 'zeros' alphas_initializer_range = 0.0 alpha_type = 'float' rms_norm_eps = 1e-06 use_cache = True pad_token_id = 0 bos_token_id = 1 eos_token_id = 2 tie_word_embeddings = False cross_layer_interval = 1 qk_layer_norms = False freeze_text_layers = True freeze_text_module_exceptions = [] freeze_lm_head = False freeze_vision_layers = True freeze_vision_module_exceptions = [] use_resampler = False vision_config = None perceiver_config = None **kwargs )\n```", "```py\n>>> from transformers import IdeficsModel, IdeficsConfig\n\n>>> # Initializing a Idefics idefics-9b style configuration\n>>> configuration = IdeficsConfig()\n\n>>> # Initializing a model from the idefics-9b style configuration\n>>> model = IdeficsModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config: IdeficsConfig )\n```", "```py\n( input_ids: LongTensor = None attention_mask: Optional = None position_ids: Optional = None past_key_values: Optional = None inputs_embeds: Optional = None pixel_values: Optional = None image_encoder_embeddings: Optional = None perceiver_embeddings: Optional = None image_attention_mask: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None interpolate_pos_encoding: Optional = False return_dict: Optional = None )\n```", "```py\n( config vision_model = None )\n```", "```py\n( input_ids: LongTensor = None attention_mask: Optional = None position_ids: Optional = None past_key_values: Optional = None inputs_embeds: Optional = None pixel_values: Optional = None image_encoder_embeddings: Optional = None perceiver_embeddings: Optional = None image_attention_mask: Optional = None labels: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None interpolate_pos_encoding: Optional = False return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.idefics.modeling_idefics.IdeficsCausalLMOutputWithPast or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoTokenizer, IdeficsForVisionText2Text\n\n>>> model = IdeficsForVisionText2Text.from_pretrained(\"HuggingFaceM4/idefics-9b\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceM4/idefics-9b\")\n\n>>> prompt = \"Hey, are you consciours? Can you talk to me?\"\n>>> inputs = tokenizer(prompt, return_tensors=\"pt\")\n\n>>> # Generate\n>>> generate_ids = model.generate(inputs.input_ids, max_length=30)\n>>> tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\"Hey, are you consciours? Can you talk to me?\\nI'm not consciours, but I can talk to you.\"\n```", "```py\n( image_size: int = 224 image_mean: Union = None image_std: Union = None image_num_channels: Optional = 3 **kwargs )\n```", "```py\n( images: Union image_num_channels: Optional = 3 image_size: Optional = None image_mean: Union = None image_std: Union = None transform: Callable = None **kwargs )\n```", "```py\n( image_processor tokenizer = None image_size = 224 add_end_of_utterance_token = None **kwargs )\n```", "```py\n( prompts: Union padding: Union = False truncation: Union = None max_length: Optional = None transform: Callable = None add_eos_token = False add_end_of_utterance_token = None debug = False return_tensors: Union = <TensorType.PYTORCH: 'pt'> ) \u2192 export const metadata = 'undefined';a dict with entries\n```", "```py\ncheckpoint = \"HuggingFaceM4/idefics-9b\"\nprocessor = AutoProcessor.from_pretrained(checkpoint)\nurl = \"https://hips.hearstapps.com/hmg-prod/images/cute-photos-of-cats-in-grass-1593184777.jpg\"\nimg = processor.image_processor.fetch_images([url])[0]\n\nprompts = [\n    \"User:\",\n    img,\n    \"Describe this image.\nt: An image of two kittens in grass.\n\n    \"User:\",\n    \"https://hips.hearstapps.com/hmg-prod/images/dog-puns-1581708208.jpg\",\n    \"Describe this image.\nt:\",\n]\n\ninputs = processor(prompts, return_tensors=\"pt\")\ngenerated_ids = model.generate(**inputs, max_length=100)\ngenerated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n```", "```py\n<s>User:<fake_token_around_image><image><fake_token_around_image>Describe this image.\nAssistant: An image of two kittens in grass.\nUser:<fake_token_around_image><image><fake_token_around_image>Describe this image.\nAssistant:'\n```", "```py\nimage_transform = transforms.Compose(\n    [\n        transforms.RandomResizedCrop(\n            (w, h), scale=(0.9, 1.0), interpolation=transforms.InterpolationMode.BICUBIC\n        ),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=self.image_mean, std=self.image_std),\n    ]\n)\ninputs = processor(prompts, transform=image_transform, return_tensors=\"pt\")\n```"]