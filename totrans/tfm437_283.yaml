- en: ResNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/resnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/resnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ResNet model was proposed in [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
    by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun. Our implementation follows
    the small changes made by [Nvidia](https://catalog.ngc.nvidia.com/orgs/nvidia/resources/resnet_50_v1_5_for_pytorch),
    we apply the `stride=2` for downsampling in bottleneck‚Äôs `3x3` conv and not in
    the first `1x1`. This is generally known as ‚ÄúResNet v1.5‚Äù.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: ResNet introduced residual connections, they allow to train networks with an
    unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition,
    one important milestone in deep computer vision.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '*Deeper neural networks are more difficult to train. We present a residual
    learning framework to ease the training of networks that are substantially deeper
    than those used previously. We explicitly reformulate the layers as learning residual
    functions with reference to the layer inputs, instead of learning unreferenced
    functions. We provide comprehensive empirical evidence showing that these residual
    networks are easier to optimize, and can gain accuracy from considerably increased
    depth. On the ImageNet dataset we evaluate residual nets with a depth of up to
    152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble
    of these residual nets achieves 3.57% error on the ImageNet test set. This result
    won the 1st place on the ILSVRC 2015 classification task. We also present analysis
    on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central
    importance for many visual recognition tasks. Solely due to our extremely deep
    representations, we obtain a 28% relative improvement on the COCO object detection
    dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO
    2015 competitions, where we also won the 1st places on the tasks of ImageNet detection,
    ImageNet localization, COCO detection, and COCO segmentation.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The figure below illustrates the architecture of ResNet. Taken from the [original
    paper](https://arxiv.org/abs/1512.03385).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ccad54651391b48289acb1dad8b77f1.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
- en: This model was contributed by [Francesco](https://huggingface.co/Francesco).
    The TensorFlow version of this model was added by [amyeroberts](https://huggingface.co/amyeroberts).
    The original code can be found [here](https://github.com/KaimingHe/deep-residual-networks).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A list of official Hugging Face and community (indicated by üåé) resources to
    help you get started with ResNet.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Image Classification
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'See also: [Image classification task guide](../tasks/image_classification)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you‚Äôre interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we‚Äôll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: ResNetConfig
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.ResNetConfig`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/configuration_resnet.py#L35)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '`num_channels` (`int`, *optional*, defaults to 3) ‚Äî The number of input channels.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embedding_size` (`int`, *optional*, defaults to 64) ‚Äî Dimensionality (hidden
    size) for the embedding layer.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_sizes` (`List[int]`, *optional*, defaults to `[256, 512, 1024, 2048]`)
    ‚Äî Dimensionality (hidden size) at each stage.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`depths` (`List[int]`, *optional*, defaults to `[3, 4, 6, 3]`) ‚Äî Depth (number
    of layers) for each stage.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`layer_type` (`str`, *optional*, defaults to `"bottleneck"`) ‚Äî The layer to
    use, it can be either `"basic"` (used for smaller models, like resnet-18 or resnet-34)
    or `"bottleneck"` (used for larger models like resnet-50 and above).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_act` (`str`, *optional*, defaults to `"relu"`) ‚Äî The non-linear activation
    function in each block. If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"`
    are supported.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`downsample_in_first_stage` (`bool`, *optional*, defaults to `False`) ‚Äî If
    `True`, the first stage will downsample the inputs using a `stride` of 2.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`downsample_in_bottleneck` (`bool`, *optional*, defaults to `False`) ‚Äî If `True`,
    the first conv 1x1 in ResNetBottleNeckLayer will downsample the inputs using a
    `stride` of 2.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`out_features` (`List[str]`, *optional*) ‚Äî If used as backbone, list of features
    to output. Can be any of `"stem"`, `"stage1"`, `"stage2"`, etc. (depending on
    how many stages the model has). If unset and `out_indices` is set, will default
    to the corresponding stages. If unset and `out_indices` is unset, will default
    to the last stage. Must be in the same order as defined in the `stage_names` attribute.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`out_indices` (`List[int]`, *optional*) ‚Äî If used as backbone, list of indices
    of features to output. Can be any of 0, 1, 2, etc. (depending on how many stages
    the model has). If unset and `out_features` is set, will default to the corresponding
    stages. If unset and `out_features` is unset, will default to the last stage.
    Must be in the same order as defined in the `stage_names` attribute.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the configuration class to store the configuration of a [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel).
    It is used to instantiate an ResNet model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the ResNet [microsoft/resnet-50](https://huggingface.co/microsoft/resnet-50)
    architecture.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: PytorchHide Pytorch content
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: ResNetModel
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.ResNetModel`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L311)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare ResNet model outputting raw features without any specific head on top.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L325)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) ‚Äî Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) ‚Äî Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) ‚Äî Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    `tuple(torch.FloatTensor)`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) ‚Äî Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    ‚Äî Last layer hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) ‚Äî Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ResNetForImageClassification
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.ResNetForImageClassification`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L361)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L381)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) ‚Äî Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) ‚Äî Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) ‚Äî Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) ‚Äî Labels
    for computing the image classification/regression loss. Indices should be in `[0,
    ..., config.num_labels - 1]`. If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or `tuple(torch.FloatTensor)`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) ‚Äî Classification (or regression if config.num_labels==1) loss.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) ‚Äî
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) ‚Äî Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each stage) of shape `(batch_size, num_channels, height,
    width)`. Hidden-states (also called feature maps) of the model at the output of
    each stage.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: TensorFlowHide TensorFlow content
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: TFResNetModel
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFResNetModel`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L472)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare ResNet model outputting raw features without any specific head on top.
    This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L481)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    ‚Äî Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) ‚Äî Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) ‚Äî Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or `tuple(tf.Tensor)`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, num_channels, height,
    width)`) ‚Äî Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooler_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) ‚Äî Last layer
    hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) ‚Äî Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each layer) of shape `(batch_size, num_channels, height, width)`.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: TFResNetForImageClassification
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFResNetForImageClassification`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L519)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L544)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    ‚Äî Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) ‚Äî Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) ‚Äî Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`tf.Tensor` of shape `(batch_size,)`, *optional*) ‚Äî Labels for computing
    the image classification/regression loss. Indices should be in `[0, ..., config.num_labels
    - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.modeling_tf_outputs.TFImageClassifierOutputWithNoAttention` or
    `tuple(tf.Tensor)`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.modeling_tf_outputs.TFImageClassifierOutputWithNoAttention`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(1,)`, *optional*, returned when `labels` is
    provided) ‚Äî Classification (or regression if config.num_labels==1) loss.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) ‚Äî Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) ‚Äî Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the model at the output of each stage.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: JAXHide JAX content
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: FlaxResNetModel
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FlaxResNetModel`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L576)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) ‚Äî
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The bare ResNet model outputting raw features without any specific head on top.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Returns
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPoolingAndNoAttention`
    or `tuple(torch.FloatTensor)`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPoolingAndNoAttention`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`)
    and inputs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, num_channels, height,
    width)`) ‚Äî Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooler_output` (`jnp.ndarray` of shape `(batch_size, hidden_size)`) ‚Äî Last
    layer hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) ‚Äî Tuple of `jnp.ndarray`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`. Hidden-states of the model at the output of each layer plus the optional
    initial embedding outputs.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `FlaxResNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: FlaxResNetForImageClassification
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FlaxResNetForImageClassification`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L660)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) ‚Äî
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ÊúÄÂêéÔºåËøô‰∏™Ê®°ÂûãÊîØÊåÅÂÜÖÂú®ÁöÑ JAX ÁâπÊÄßÔºåÊØîÂ¶ÇÔºö
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Âç≥Êó∂ÁºñËØëÔºàJITÔºâ](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ëá™Âä®ÂæÆÂàÜ](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ÂêëÈáèÂåñ](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Âπ∂Ë°åÂåñ](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[<Êù•Ê∫ê>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
- en: '[PRE18]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Returns
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ËøîÂõû
- en: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or `tuple(torch.FloatTensor)`'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    Êàñ `tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`)
    and inputs.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ‰∏Ä‰∏™ `transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    Êàñ‰∏Ä‰∏™ `torch.FloatTensor` ÂÖÉÁªÑÔºàÂ¶ÇÊûú‰º†ÈÄí‰∫Ü `return_dict=False` ÊàñÂΩì `config.return_dict=False`
    Êó∂ÔºâÂåÖÂê´Ê†πÊçÆÈÖçÁΩÆÔºà`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`ÔºâÂíåËæìÂÖ•ÁöÑ‰∏çÂêåÂÖÉÁ¥†„ÄÇ
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, config.num_labels)`) ‚Äî Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ÔºàÂΩ¢Áä∂‰∏∫ `(batch_size, config.num_labels)` ÁöÑ `jnp.ndarray`Ôºâ ‚Äî ÂàÜÁ±ªÔºàÂ¶ÇÊûú `config.num_labels==1`
    Âàô‰∏∫ÂõûÂΩíÔºâÂæóÂàÜÔºàSoftMax ‰πãÂâçÔºâ„ÄÇ'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`Ôºà`tuple(jnp.ndarray)`Ôºå*ÂèØÈÄâ*ÔºåÂΩì‰º†ÈÄí‰∫Ü `output_hidden_states=True`
    ÊàñÂΩì'
- en: '`config.output_hidden_states=True):` Tuple of `jnp.ndarray` (one for the output
    of the embeddings, if the model has an embedding layer, + one for the output of
    each stage) of shape `(batch_size, num_channels, height, width)`. Hidden-states
    (also called feature maps) of the model at the output of each stage.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_hidden_states=True):` ÂΩ¢Áä∂‰∏∫ `(batch_size, num_channels, height,
    width)` ÁöÑ `jnp.ndarray` ÂÖÉÁªÑÔºàÂ¶ÇÊûúÊ®°ÂûãÊúâÂµåÂÖ•Â±ÇÔºåÂàô‰∏∫ÂµåÂÖ•ÁöÑËæìÂá∫ + ÊØè‰∏™Èò∂ÊÆµÁöÑËæìÂá∫Ôºâ„ÄÇÊ®°ÂûãÂú®ÊØè‰∏™Èò∂ÊÆµËæìÂá∫ÁöÑÈöêËóèÁä∂ÊÄÅÔºà‰πüÁß∞‰∏∫ÁâπÂæÅÂõæÔºâ„ÄÇ'
- en: The `FlaxResNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxResNetPreTrainedModel` ÁöÑÂâçÂêëÊñπÊ≥ïÔºåË¶ÜÁõñ‰∫Ü `__call__` ÁâπÊÆäÊñπÊ≥ï„ÄÇ'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ËôΩÁÑ∂ÂâçÂêë‰º†ÈÄíÁöÑÊ≠•È™§ÈúÄË¶ÅÂú®Ëøô‰∏™ÂáΩÊï∞ÂÜÖÂÆö‰πâÔºå‰ΩÜÂ∫îËØ•Âú®‰πãÂêéË∞ÉÁî® `Module` ÂÆû‰æãËÄå‰∏çÊòØËøô‰∏™ÂáΩÊï∞ÔºåÂõ†‰∏∫ÂâçËÄÖ‰ºöÂ§ÑÁêÜËøêË°åÂâçÂêéÁöÑÂ§ÑÁêÜÊ≠•È™§ÔºåËÄåÂêéËÄÖ‰ºöÈªòÈªòÂú∞ÂøΩÁï•ÂÆÉ‰ª¨„ÄÇ
- en: 'Example:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Á§∫‰æãÔºö
- en: '[PRE19]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
