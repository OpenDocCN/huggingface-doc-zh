# 关于指标的一切

> 原文链接：[https://huggingface.co/docs/datasets/about_metrics](https://huggingface.co/docs/datasets/about_metrics)

在🤗数据集中，指标已被弃用。要了解如何使用指标，请查看库🤗[Evaluate](https://huggingface.co/docs/evaluate/index)！除了指标，您还可以找到更多用于评估模型和数据集的工具。

🤗数据集提供了广泛的自然语言处理指标。您可以加载与基准数据集（如GLUE或SQuAD）和复杂指标（如BLEURT或BERTScore）相关联的指标，只需一个命令：[load_metric()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_metric)。一旦加载了指标，就可以轻松计算和评估模型的性能。

## ELI5：load_metric

加载数据集和加载指标有许多相似之处。这是一个有意设计的选择，因为我们希望创造一个简单和统一的体验。当您调用[load_metric()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_metric)时，将从GitHub下载并导入指标加载脚本（如果之前尚未下载）。它包含有关指标的信息，例如引用、主页和描述。

指标加载脚本将实例化并返回一个[Metric](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric)对象。这将存储您需要计算指标值的预测和参考值。[Metric](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric)对象存储为Apache Arrow表。因此，预测和参考值直接存储在具有内存映射的磁盘上。这使得🤗数据集能够对指标进行延迟计算，并且更容易在分布式环境中收集所有预测值。

## 分布式评估

在分布式环境中计算指标可能会很棘手。指标评估是在不同数据集子集上的单独Python进程或节点中执行的。通常，当指标得分是可加的（`f(AuB) = f(A) + f(B)`）时，您可以使用分布式reduce操作来收集每个数据集子集的得分。但是当指标是不可加的（`f(AuB) ≠ f(A) + f(B)`）时，情况就不那么简单了。例如，您不能将每个数据子集的[F1](https://huggingface.co/metrics/f1)得分之和作为您的**最终指标**。

克服这个问题的常见方法是回退到单进程评估。指标在单个GPU上进行评估，这变得低效。

🤗数据集通过仅在第一个节点上计算最终指标来解决这个问题。预测和参考值分别为每个节点计算并提供给指标。这些暂时存储在Apache Arrow表中，避免了GPU或CPU内存的混乱。当您准备好[指标计算（Metric.compute()）](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric.compute)最终指标时，第一个节点能够访问所有其他节点上存储的预测和参考值。一旦收集到所有预测和参考值，[指标计算（Metric.compute()）](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric.compute)将执行最终指标评估。

这种解决方案允许🤗数据集执行分布式预测，这对于分布式环境中的评估速度至关重要。同时，您还可以使用复杂的非可加指标，而不会浪费宝贵的GPU或CPU内存。
