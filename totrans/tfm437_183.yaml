- en: HerBERT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/herbert](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/herbert)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The HerBERT model was proposed in [KLEJ: Comprehensive Benchmark for Polish
    Language Understanding](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)
    by Piotr Rybak, Robert Mroczkowski, Janusz Tracz, and Ireneusz Gawlik. It is a
    BERT-based Language Model trained on Polish Corpora using only MLM objective with
    dynamic masking of whole words.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '*In recent years, a series of Transformer-based models unlocked major improvements
    in general natural language understanding (NLU) tasks. Such a fast pace of research
    would not be possible without general NLU benchmarks, which allow for a fair comparison
    of the proposed methods. However, such benchmarks are available only for a handful
    of languages. To alleviate this issue, we introduce a comprehensive multi-task
    benchmark for the Polish language understanding, accompanied by an online leaderboard.
    It consists of a diverse set of tasks, adopted from existing datasets for named
    entity recognition, question-answering, textual entailment, and others. We also
    introduce a new sentiment analysis task for the e-commerce domain, named Allegro
    Reviews (AR). To ensure a common evaluation scheme and promote models that generalize
    to different NLU tasks, the benchmark includes datasets from varying domains and
    applications. Additionally, we release HerBERT, a Transformer-based model trained
    specifically for the Polish language, which has the best average performance and
    obtains the best results for three out of nine tasks. Finally, we provide an extensive
    evaluation, including several standard baselines and recently proposed, multilingual
    Transformer-based models.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: This model was contributed by [rmroczkowski](https://huggingface.co/rmroczkowski).
    The original code can be found [here](https://github.com/allegro/HerBERT).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Usage example
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Herbert implementation is the same as `BERT` except for the tokenization method.
    Refer to [BERT documentation](bert) for API reference and examples.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: HerbertTokenizer
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.HerbertTokenizer`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L289)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Construct a BPE tokenizer for HerBERT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'Peculiarities:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'uses BERT’s pre-tokenizer: BaseTokenizer splits tokens on spaces, and also
    on punctuation. Each occurrence of a punctuation character will be treated separately.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such pretokenized input is BPE subtokenized
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This tokenizer inherits from [XLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMTokenizer)
    which contains most of the methods. Users should refer to the superclass for more
    information regarding methods.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L526)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. An XLM sequence has the following
    format:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'single sequence: `<s> X </s>`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'pair of sequences: `<s> A </s> B </s>`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `convert_tokens_to_string`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L520)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Converts a sequence of tokens (string) in a single string.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L583)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. An XLM sequence
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'pair mask has the following format:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_special_tokens_mask`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L554)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: HerbertTokenizerFast
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.HerbertTokenizerFast`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L40)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merges_file` (`str`) — Path to the merges file.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Construct a “Fast” BPE tokenizer for HerBERT (backed by HuggingFace’s *tokenizers*
    library).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Peculiarities:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'uses BERT’s pre-tokenizer: BertPreTokenizer splits tokens on spaces, and also
    on punctuation. Each occurrence of a punctuation character will be treated separately.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the methods. Users should refer to the superclass for more
    information regarding methods.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L89)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. An HerBERT, like BERT sequence
    has the following format:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'single sequence: `<s> X </s>`'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'pair of sequences: `<s> A </s> B </s>`'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L143)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. HerBERT, like
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'BERT sequence pair mask has the following format:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `get_special_tokens_mask`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L116)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的令牌列表中检索序列标识。在使用分词器的`prepare_for_model`方法添加特殊标记时调用此方法。
