- en: Philosophy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/diffusers/conceptual/philosophy](https://huggingface.co/docs/diffusers/conceptual/philosophy)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/117.c6d9a246.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: üß® Diffusers provides **state-of-the-art** pretrained diffusion models across
    multiple modalities. Its purpose is to serve as a **modular toolbox** for both
    inference and training.
  prefs: []
  type: TYPE_NORMAL
- en: We aim at building a library that stands the test of time and therefore take
    API design very seriously.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, Diffusers is built to be a natural extension of PyTorch. Therefore,
    most of our design choices are based on [PyTorch‚Äôs Design Principles](https://pytorch.org/docs/stable/community/design.html#pytorch-design-philosophy).
    Let‚Äôs go over the most important ones:'
  prefs: []
  type: TYPE_NORMAL
- en: Usability over Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While Diffusers has many built-in performance-enhancing features (see [Memory
    and Speed](https://huggingface.co/docs/diffusers/optimization/fp16)), models are
    always loaded with the highest precision and lowest optimization. Therefore, by
    default diffusion pipelines are always instantiated on CPU with float32 precision
    if not otherwise defined by the user. This ensures usability across different
    platforms and accelerators and means that no complex installations are required
    to run the library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffusers aims to be a **light-weight** package and therefore has very few required
    dependencies, but many soft dependencies that can improve performance (such as
    `accelerate`, `safetensors`, `onnx`, etc‚Ä¶). We strive to keep the library as lightweight
    as possible so that it can be added without much concern as a dependency on other
    packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffusers prefers simple, self-explainable code over condensed, magic code.
    This means that short-hand code syntaxes such as lambda functions, and advanced
    PyTorch operators are often not desired.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple over easy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As PyTorch states, **explicit is better than implicit** and **simple is better
    than complex**. This design philosophy is reflected in multiple parts of the library:'
  prefs: []
  type: TYPE_NORMAL
- en: We follow PyTorch‚Äôs API with methods like [`DiffusionPipeline.to`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.to)
    to let the user handle device management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raising concise error messages is preferred to silently correct erroneous input.
    Diffusers aims at teaching the user, rather than making the library as easy to
    use as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complex model vs. scheduler logic is exposed instead of magically handled inside.
    Schedulers/Samplers are separated from diffusion models with minimal dependencies
    on each other. This forces the user to write the unrolled denoising loop. However,
    the separation allows for easier debugging and gives the user more control over
    adapting the denoising process or switching out diffusion models or schedulers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Separately trained components of the diffusion pipeline, *e.g.* the text encoder,
    the unet, and the variational autoencoder, each have their own model class. This
    forces the user to handle the interaction between the different model components,
    and the serialization format separates the model components into different files.
    However, this allows for easier debugging and customization. DreamBooth or Textual
    Inversion training is very simple thanks to Diffusers‚Äô ability to separate single
    components of the diffusion pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tweakable, contributor-friendly over abstraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For large parts of the library, Diffusers adopts an important design principle
    of the [Transformers library](https://github.com/huggingface/transformers), which
    is to prefer copy-pasted code over hasty abstractions. This design principle is
    very opinionated and stands in stark contrast to popular design principles such
    as [Don‚Äôt repeat yourself (DRY)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself).
    In short, just like Transformers does for modeling files, Diffusers prefers to
    keep an extremely low level of abstraction and very self-contained code for pipelines
    and schedulers. Functions, long code blocks, and even classes can be copied across
    multiple files which at first can look like a bad, sloppy design choice that makes
    the library unmaintainable. **However**, this design has proven to be extremely
    successful for Transformers and makes a lot of sense for community-driven, open-source
    machine learning libraries because:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning is an extremely fast-moving field in which paradigms, model
    architectures, and algorithms are changing rapidly, which therefore makes it very
    difficult to define long-lasting code abstractions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine Learning practitioners like to be able to quickly tweak existing code
    for ideation and research and therefore prefer self-contained code over one that
    contains many abstractions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open-source libraries rely on community contributions and therefore must build
    a library that is easy to contribute to. The more abstract the code, the more
    dependencies, the harder to read, and the harder to contribute to. Contributors
    simply stop contributing to very abstract libraries out of fear of breaking vital
    functionality. If contributing to a library cannot break other fundamental code,
    not only is it more inviting for potential new contributors, but it is also easier
    to review and contribute to multiple parts in parallel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At Hugging Face, we call this design the **single-file policy** which means
    that almost all of the code of a certain class should be written in a single,
    self-contained file. To read more about the philosophy, you can have a look at
    [this blog post](https://huggingface.co/blog/transformers-design-philosophy).
  prefs: []
  type: TYPE_NORMAL
- en: In Diffusers, we follow this philosophy for both pipelines and schedulers, but
    only partly for diffusion models. The reason we don‚Äôt follow this design fully
    for diffusion models is because almost all diffusion pipelines, such as [DDPM](https://huggingface.co/docs/diffusers/api/pipelines/ddpm),
    [Stable Diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview#stable-diffusion-pipelines),
    [unCLIP (DALL¬∑E 2)](https://huggingface.co/docs/diffusers/api/pipelines/unclip)
    and [Imagen](https://imagen.research.google/) all rely on the same diffusion model,
    the [UNet](https://huggingface.co/docs/diffusers/api/models/unet2d-cond).
  prefs: []
  type: TYPE_NORMAL
- en: Great, now you should have generally understood why üß® Diffusers is designed
    the way it is ü§ó. We try to apply these design principles consistently across the
    library. Nevertheless, there are some minor exceptions to the philosophy or some
    unlucky design choices. If you have feedback regarding the design, we would ‚ù§Ô∏è
    to hear it [directly on GitHub](https://github.com/huggingface/diffusers/issues/new?assignees=&labels=&template=feedback.md&title=).
  prefs: []
  type: TYPE_NORMAL
- en: Design Philosophy in Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let‚Äôs look a bit into the nitty-gritty details of the design philosophy.
    Diffusers essentially consists of three major classes: [pipelines](https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines),
    [models](https://github.com/huggingface/diffusers/tree/main/src/diffusers/models),
    and [schedulers](https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers).
    Let‚Äôs walk through more in-detail design decisions for each class.'
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pipelines are designed to be easy to use (therefore do not follow [*Simple over
    easy*](#simple-over-easy) 100%), are not feature complete, and should loosely
    be seen as examples of how to use [models](#models) and [schedulers](#schedulers)
    for inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following design principles are followed:'
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines follow the single-file policy. All pipelines can be found in individual
    directories under src/diffusers/pipelines. One pipeline folder corresponds to
    one diffusion paper/project/release. Multiple pipeline files can be gathered in
    one pipeline folder, as it‚Äôs done for [`src/diffusers/pipelines/stable-diffusion`](https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/stable_diffusion).
    If pipelines share similar functionality, one can make use of the [#Copied from
    mechanism](https://github.com/huggingface/diffusers/blob/125d783076e5bd9785beb05367a2d2566843a271/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py#L251).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines all inherit from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every pipeline consists of different model and scheduler components, that are
    documented in the [`model_index.json` file](https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json),
    are accessible under the same name as attributes of the pipeline and can be shared
    between pipelines with [`DiffusionPipeline.components`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.components)
    function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every pipeline should be loadable via the [`DiffusionPipeline.from_pretrained`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained)
    function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines should be used **only** for inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines should be very readable, self-explanatory, and easy to tweak.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines should be designed to build on top of each other and be easy to integrate
    into higher-level APIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines are **not** intended to be feature-complete user interfaces. For future
    complete user interfaces one should rather have a look at [InvokeAI](https://github.com/invoke-ai/InvokeAI),
    [Diffuzers](https://github.com/abhishekkrthakur/diffuzers), and [lama-cleaner](https://github.com/Sanster/lama-cleaner).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every pipeline should have one and only one way to run it via a `__call__` method.
    The naming of the `__call__` arguments should be shared across all pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipelines should be named after the task they are intended to solve.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In almost all cases, novel diffusion pipelines shall be implemented in a new
    pipeline folder/file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Models are designed as configurable toolboxes that are natural extensions of
    [PyTorch‚Äôs Module class](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).
    They only partly follow the **single-file policy**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following design principles are followed:'
  prefs: []
  type: TYPE_NORMAL
- en: Models correspond to **a type of model architecture**. *E.g.* the [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)
    class is used for all UNet variations that expect 2D image inputs and are conditioned
    on some context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All models can be found in [`src/diffusers/models`](https://github.com/huggingface/diffusers/tree/main/src/diffusers/models)
    and every model architecture shall be defined in its file, e.g. [`unet_2d_condition.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unet_2d_condition.py),
    [`transformer_2d.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/transformer_2d.py),
    etc‚Ä¶
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Models **do not** follow the single-file policy and should make use of smaller
    model building blocks, such as [`attention.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention.py),
    [`resnet.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/resnet.py),
    [`embeddings.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/embeddings.py),
    etc‚Ä¶ **Note**: This is in stark contrast to Transformers‚Äô modeling files and shows
    that models do not really follow the single-file policy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models intend to expose complexity, just like PyTorch‚Äôs `Module` class, and
    give clear error messages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models all inherit from `ModelMixin` and `ConfigMixin`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models can be optimized for performance when it doesn‚Äôt demand major code changes,
    keeps backward compatibility, and gives significant memory or compute gain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models should by default have the highest precision and lowest performance setting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To integrate new model checkpoints whose general architecture can be classified
    as an architecture that already exists in Diffusers, the existing model architecture
    shall be adapted to make it work with the new checkpoint. One should only create
    a new file if the model architecture is fundamentally different.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models should be designed to be easily extendable to future changes. This can
    be achieved by limiting public function arguments, configuration arguments, and
    ‚Äúforeseeing‚Äù future changes, *e.g.* it is usually better to add `string` ‚Äú‚Ä¶type‚Äù
    arguments that can easily be extended to new future types instead of boolean `is_..._type`
    arguments. Only the minimum amount of changes shall be made to existing architectures
    to make a new model checkpoint work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model design is a difficult trade-off between keeping code readable and
    concise and supporting many model checkpoints. For most parts of the modeling
    code, classes shall be adapted for new model checkpoints, while there are some
    exceptions where it is preferred to add new classes to make sure the code is kept
    concise and readable long-term, such as [UNet blocks](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unet_2d_blocks.py)
    and [Attention processors](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedulers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Schedulers are responsible to guide the denoising process for inference as well
    as to define a noise schedule for training. They are designed as individual classes
    with loadable configuration files and strongly follow the **single-file policy**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following design principles are followed:'
  prefs: []
  type: TYPE_NORMAL
- en: All schedulers are found in [`src/diffusers/schedulers`](https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedulers are **not** allowed to import from large utils files and shall be
    kept very self-contained.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One scheduler Python file corresponds to one scheduler algorithm (as might be
    defined in a paper).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If schedulers share similar functionalities, we can make use of the `#Copied
    from` mechanism.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedulers all inherit from `SchedulerMixin` and `ConfigMixin`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedulers can be easily swapped out with the [`ConfigMixin.from_config`](https://huggingface.co/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config)
    method as explained in detail [here](../using-diffusers/schedulers.md).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every scheduler has to have a `set_num_inference_steps`, and a `step` function.
    `set_num_inference_steps(...)` has to be called before every denoising process,
    *i.e.* before `step(...)` is called.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every scheduler exposes the timesteps to be ‚Äúlooped over‚Äù via a `timesteps`
    attribute, which is an array of timesteps the model will be called upon.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `step(...)` function takes a predicted model output and the ‚Äúcurrent‚Äù sample
    (x_t) and returns the ‚Äúprevious‚Äù, slightly more denoised sample (x_t-1).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the complexity of diffusion schedulers, the `step` function does not expose
    all the complexity and can be a bit of a ‚Äúblack box‚Äù.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In almost all cases, novel schedulers shall be implemented in a new scheduling
    file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
