["```py\nfrom huggingface_hub import InferenceClient\n\nclient = InferenceClient(\"http://127.0.0.1:8080\")\nfor token in client.text_generation(\"How do you make cheese?\", max_new_tokens=12, stream=True):\n    print(token)\n\n# To\n# make\n# cheese\n#,\n# you\n# need\n# to\n# start\n# with\n# milk\n#.\n```", "```py\nfor details in client.text_generation(\"How do you make cheese?\", max_new_tokens=12, details=True, stream=True):\n    print(details)\n\n#TextGenerationStreamResponse(token=Token(id=193, text='\\n', logprob=-0.007358551, special=False), generated_text=None, details=None)\n#TextGenerationStreamResponse(token=Token(id=2044, text='To', logprob=-1.1357422, special=False), generated_text=None, details=None)\n#TextGenerationStreamResponse(token=Token(id=717, text=' make', logprob=-0.009841919, special=False), generated_text=None, details=None)\n#...\n#TextGenerationStreamResponse(token=Token(id=25, text='.', logprob=-1.3408203, special=False), generated_text='\\nTo make cheese, you need to start with milk.', details=StreamDetails(finish_reason=<FinishReason.Length: 'length'>, generated_tokens=12, seed=None))\n```", "```py\nfrom huggingface_hub import AsyncInferenceClient\n\nclient = AsyncInferenceClient(\"http://127.0.0.1:8080\")\nasync for token in await client.text_generation(\"How do you make cheese?\", stream=True):\n    print(token)\n\n# To\n# make\n# cheese\n#,\n# you\n# need\n# to\n# start\n# with\n# milk\n#.\n```", "```py\ncurl -N 127.0.0.1:8080/generate_stream \\\n    -X POST \\\n    -d '{\"inputs\":\"What is Deep Learning?\",\"parameters\":{\"max_new_tokens\":20}}' \\\n    -H 'Content-Type: application/json'\n```", "```py\nimport { HfInferenceEndpoint } from '@huggingface/inference'\n\nconst hf = new HfInferenceEndpoint('https://YOUR_ENDPOINT.endpoints.huggingface.cloud', 'hf_YOUR_TOKEN')\n\n// prompt\nconst prompt = 'What can you do in Nuremberg, Germany? Give me 3 Tips'\n\nconst stream = hf.textGenerationStream({ inputs: prompt })\nfor await (const r of stream) { \n  // yield the generated token\n  process.stdout.write(r.token.text)\n}\n```"]