# 自定义工具和提示

> 原文：[`huggingface.co/docs/transformers/v4.37.2/en/custom_tools`](https://huggingface.co/docs/transformers/v4.37.2/en/custom_tools)

如果您不了解 transformers 上下文中的工具和代理是什么，我们建议您先阅读 Transformers Agents 页面。

Transformers Agents 是一个实验性 API，随时可能发生变化。代理返回的结果可能会有所不同，因为 API 或底层模型可能会发生变化。

创建和使用自定义工具和提示对于赋予代理能力并使其执行新任务至关重要。在本指南中，我们将看一下：

+   如何自定义提示

+   如何使用自定义工具

+   如何创建自定义工具

## 自定义提示

如 Transformers Agents 中所解释的，代理可以在 run()和 chat()模式下运行。`run` 和 `chat` 模式都基于相同的逻辑。驱动代理的语言模型是基于一个长提示进行条件化，并通过生成下一个标记来完成提示，直到达到停止标记。两种模式之间唯一的区别是，在 `chat` 模式期间，提示会扩展为先前用户输入和模型生成。这使得代理可以访问过去的交互，似乎给代理一定的记忆。

### 提示的结构

让我们更仔细地看一下提示的结构，以了解如何最好地定制它。提示大体上分为四个部分。

+   1.  介绍：代理应该如何行为，工具概念的解释。

+   1.  所有工具的描述。这由一个 `<<all_tools>>` 标记定义，它在运行时动态替换为用户定义/选择的工具。

+   1.  一组任务及其解决方案的示例

+   1.  当前示例和解决方案请求。

为了更好地理解每个部分，让我们看一下 `run` 提示的缩短版本可能是什么样子：

```py
I will ask you to perform a task, your job is to come up with a series of simple commands in Python that will perform the task.
[...]
You can print intermediate results if it makes sense to do so.

Tools:
- document_qa: This is a tool that answers a question about a document (pdf). It takes an input named `document` which should be the document containing the information, as well as a `question` that is the question about the document. It returns a text that contains the answer to the question.
- image_captioner: This is a tool that generates a description of an image. It takes an input named `image` which should be the image to the caption and returns a text that contains the description in English.
[...]

Task: "Answer the question in the variable `question` about the image stored in the variable `image`. The question is in French."

I will use the following tools: `translator` to translate the question into English and then `image_qa` to answer the question on the input image.

Answer:
```py

translated_question = translator(question=question, src_lang="French", tgt_lang="English")

print(f"翻译后的问题是 {translated_question}。")

answer = image_qa(image=image, question=translated_question)

print(f"答案是 {answer}")

```py

Task: "Identify the oldest person in the `document` and create an image showcasing the result as a banner."

I will use the following tools: `document_qa` to find the oldest person in the document, then `image_generator` to generate an image according to the answer.

Answer:
```py

answer = document_qa(document, question="最年长的人是谁？")

print(f"答案是 {answer}。")

image = image_generator("显示 " + answer + " 的横幅")

```py

[...]

Task: "Draw me a picture of rivers and lakes"

I will use the following
```

介绍（“工具：”之前的文本）精确解释了模型应该如何行为以及它应该做什么。这部分很可能不需要定制，因为代理应该始终以相同的方式行为。

第二部分（“工具”下面的项目符号）在调用 `run` 或 `chat` 时动态添加。`agent.toolbox` 中有多少工具，就有多少项目符号，每个项目符号包括工具的名称和描述：

```py
- <tool.name>: <tool.description>
```

让我们通过加载 document_qa 工具并打印出名称和描述来快速验证这一点。

```py
from transformers import load_tool

document_qa = load_tool("document-question-answering")
print(f"- {document_qa.name}: {document_qa.description}")
```

这给出了：

```py
- document_qa: This is a tool that answers a question about a document (pdf). It takes an input named `document` which should be the document containing the information, as well as a `question` that is the question about the document. It returns a text that contains the answer to the question.
```

我们可以看到工具名称简短而准确。描述包括两部分，第一部分解释工具的功能，第二部分说明预期的输入参数和返回值。

一个好的工具名称和工具描述对于代理正确使用它非常重要。请注意，代理对于工具的唯一信息是其名称和描述，因此应确保两者都写得准确，并与工具箱中现有工具的风格匹配。特别要确保描述中提到所有预期的参数名称，以代码样式列出，以及预期的类型和它们的描述。

检查精心策划的 Transformers 工具的命名和描述，以更好地了解工具应该具有的名称和描述。您可以通过 `Agent.toolbox` 属性查看所有工具。

第三部分包括一组精心策划的示例，向代理展示它应该为何种用户请求生成什么样的代码。赋予代理力量的大型语言模型非常擅长识别提示中的模式，并使用新数据重复该模式。因此，非常重要的是示例以最大化代理生成正确可执行代码的可能性的方式编写。

让我们看一个例子：

```py
Task: "Identify the oldest person in the `document` and create an image showcasing the result as a banner."

I will use the following tools: `document_qa` to find the oldest person in the document, then `image_generator` to generate an image according to the answer.

Answer:
```py

answer = document_qa(document, question="What is the oldest person?")

print(f"答案是 {answer}。")

image = image_generator("显示" + answer + "的横幅")

```py

```

模型被提示重复的模式有三部分：任务陈述，代理解释其打算做什么，最后是生成的代码。提示中的每个示例都具有这个确切的模式，从而确保代理在生成新标记时会重现完全相同的模式。 

提示示例由 Transformers 团队精心策划，并在一组[问题陈述](https://github.com/huggingface/transformers/blob/main/src/transformers/tools/evaluate_agent.py)上进行严格评估，以确保代理的提示尽可能好地解决代理的真实用例。

提示的最后部分对应于：

```py
Task: "Draw me a picture of rivers and lakes"

I will use the following
```

是代理被要求完成的最终未完成示例。未完成的示例是根据实际用户输入动态创建的。对于上面的示例，用户运行了：

```py
agent.run("Draw me a picture of rivers and lakes")
```

用户输入 - *即*任务：“给我画一幅河流和湖泊的图片”被转换为提示模板：“任务：<task> \n\n 我将使用以下内容”。这句话构成了代理所依赖的提示的最后几行，因此强烈影响代理完成示例的方式与之前的示例完全相同。

不要深入细节，聊天模板具有相同的提示结构，示例具有稍微不同的风格，*例如*：

```py
[...]

=====

Human: Answer the question in the variable `question` about the image stored in the variable `image`.

Assistant: I will use the tool `image_qa` to answer the question on the input image.

```py

answer = image_qa(text=question, image=image)

打印(f"答案是 {answer}")

```py

Human: I tried this code, it worked but didn't give me a good result. The question is in French

Assistant: In this case, the question needs to be translated first. I will use the tool `translator` to do this.

```py

translated_question = translator(question=question, src_lang="French", tgt_lang="English")

打印(f"翻译后的问题是 {translated_question}。")

answer = image_qa(text=translated_question, image=image)

打印(f"答案是 {answer}")

```py

=====

[...]
```

与`run`提示的示例相反，每个`chat`提示示例都有一个或多个*人类*和*助手*之间的交流。每个交流的结构与`run`提示的示例类似。用户的输入附加在*人类:*后面，代理被提示首先生成需要完成的内容，然后再生成代码。一个交流可以基于先前的交流，因此允许用户参考先前的交流，就像用户上面的输入“我尝试**这**段代码”引用了代理先前生成的代码一样。

运行`.chat`后，用户的输入或*任务*被转换为一个未完成的示例，形式如下：

```py
Human: <user-input>\n\nAssistant:
```

代理完成。与`run`命令相反，`chat`命令会将已完成的示例附加到提示中，从而为下一个`chat`轮提供更多上下文。

现在我们知道了提示的结构，让我们看看如何自定义它！

### 编写良好的用户输入

虽然大型语言模型在理解用户意图方面变得越来越好，但尽可能准确地帮助代理选择正确的任务会极大地有所帮助。什么是尽可能准确？

代理在其提示中看到一系列工具名称及其描述。添加的工具越多，代理选择正确工具的难度就越大，选择正确的工具运行的顺序也变得更加困难。让我们看一个常见的失败案例，这里我们只返回分析代码。

```py
from transformers import HfAgent

agent = HfAgent("https://api-inference.huggingface.co/models/bigcode/starcoder")

agent.run("Show me a tree", return_code=True)
```

给出：

```py
==Explanation from the agent==
I will use the following tool: `image_segmenter` to create a segmentation mask for the image.

==Code generated by the agent==
mask = image_segmenter(image, prompt="tree")
```

这可能不是我们想要的。相反，更有可能的是我们希望生成一棵树的图像。为了更多地引导代理程序使用特定工具，因此使用工具名称和描述中存在的重要关键词可能非常有帮助。让我们看一看。

```py
agent.toolbox["image_generator"].description
```

```py
'This is a tool that creates an image according to a prompt, which is a text description. It takes an input named `prompt` which contains the image description and outputs an image.
```

名称和描述使用了关键词“图像”、“提示”、“创建”和“生成”。在这里使用这些词可能会更有效。让我们稍微完善一下我们的提示。

```py
agent.run("Create an image of a tree", return_code=True)
```

给出：

```py
==Explanation from the agent==
I will use the following tool `image_generator` to generate an image of a tree.

==Code generated by the agent==
image = image_generator(prompt="tree")
```

好多了！这看起来更像我们想要的。简而言之，当您注意到代理程序在正确将您的任务映射到正确的工具时遇到困难时，请尝试查找工具名称和描述的最相关关键词，并尝试用它来完善您的任务请求。

### 自定义工具描述

正如我们之前所看到的，代理程序可以访问每个工具的名称和描述。基本工具应该具有非常精确的名称和描述，但是，您可能会发现，为了您的特定用例，更改工具的描述或名称可能会有所帮助。当您添加了多个非常相似的工具或者只想将代理程序用于特定领域时，这可能变得尤为重要，例如图像生成和转换。

一个常见问题是，当代理程序在图像生成任务中经常混淆图像生成和图像转换/修改时，*例如*

```py
agent.run("Make an image of a house and a car", return_code=True)
```

返回

```py
==Explanation from the agent== 
I will use the following tools `image_generator` to generate an image of a house and `image_transformer` to transform the image of a car into the image of a house.

==Code generated by the agent==
house_image = image_generator(prompt="A house")
car_image = image_generator(prompt="A car")
house_car_image = image_transformer(image=car_image, prompt="A house")
```

这可能不是我们想要的。看起来代理程序很难理解`image_generator`和`image_transformer`之间的区别，并经常同时使用这两者。

我们可以通过更改`image_transformer`的工具名称和描述来帮助代理程序。我们可以将其称为`modifier`，以使其与“图像”和“提示”有些脱离关系：

```py
agent.toolbox["modifier"] = agent.toolbox.pop("image_transformer")
agent.toolbox["modifier"].description = agent.toolbox["modifier"].description.replace(
    "transforms an image according to a prompt", "modifies an image"
)
```

现在，“修改”是一个强烈的提示，可以使用新的图像处理器来帮助完成上述提示。让我们再次运行它。

```py
agent.run("Make an image of a house and a car", return_code=True)
```

现在我们得到了：

```py
==Explanation from the agent==
I will use the following tools: `image_generator` to generate an image of a house, then `image_generator` to generate an image of a car.

==Code generated by the agent==
house_image = image_generator(prompt="A house")
car_image = image_generator(prompt="A car")
```

这绝对更接近我们的想法！但是，我们希望在同一张图片中同时有房子和汽车。将任务更多地转向单张图片生成应该会有所帮助：

```py
agent.run("Create image: 'A house and car'", return_code=True)
```

```py
==Explanation from the agent==
I will use the following tool: `image_generator` to generate an image.

==Code generated by the agent==
image = image_generator(prompt="A house and car")
```

对于许多用例，代理程序仍然很脆弱，特别是在生成多个对象的图像等稍微复杂的用例中。代理程序本身和基础提示将在未来几个月进一步改进，以确保代理程序对各种用户输入更加稳健。

### 自定义整个提示

为了给用户最大的灵活性，整个提示模板如上所述可以被用户覆盖。在这种情况下，请确保您的自定义提示包括一个介绍部分、一个工具部分、一个示例部分和一个未完成示例部分。如果您想覆盖`run`提示模板，可以按照以下步骤操作：

```py
template = """ [...] """

agent = HfAgent(your_endpoint, run_prompt_template=template)
```

请确保在`template`中的某处定义`<<all_tools>>`字符串和`<<prompt>>`，以便代理程序可以了解可用的工具，并正确插入用户的提示。

同样，用户可以覆盖`chat`提示模板。请注意，`chat`模式始终使用以下格式进行交流：

```py
Human: <<task>>

Assistant:
```

因此，重要的是自定义`chat`提示模板的示例也要使用这种格式。您可以在实例化时覆盖`chat`模板，如下所示。

```py
template = """ [...] """

agent = HfAgent(url_endpoint=your_endpoint, chat_prompt_template=template)
```

请确保在`template`中的某处定义`<<all_tools>>`字符串，以便代理程序可以了解可用的工具。

在这两种情况下，如果您想使用社区中某人托管的模板，可以传递一个存储库 ID 而不是提示模板。默认提示位于[此存储库](https://huggingface.co/datasets/huggingface-tools/default-prompts)中作为示例。

要在 Hub 上上传您的自定义提示并与社区共享，请确保：

+   使用数据集存储库

+   将`run`命令的提示模板放在名为`run_prompt_template.txt`的文件中

+   将`chat`命令的提示模板放在名为`chat_prompt_template.txt`的文件中

## 使用自定义工具

在本节中，我们将利用两个现有的特定于图像生成的自定义工具：

+   我们用[diffusers/controlnet-canny-tool](https://huggingface.co/spaces/diffusers/controlnet-canny-tool)替换[huggingface-tools/image-transformation](https://huggingface.co/spaces/huggingface-tools/image-transformation)，以允许进行更多图像修改。

+   我们向默认工具箱添加一个新的图像升频工具：[diffusers/latent-upscaler-tool](https://huggingface.co/spaces/diffusers/latent-upscaler-tool)替换现有的图像转换工具。

我们将通过方便的 load_tool()函数加载自定义工具：

```py
from transformers import load_tool

controlnet_transformer = load_tool("diffusers/controlnet-canny-tool")
upscaler = load_tool("diffusers/latent-upscaler-tool")
```

在向代理添加自定义工具时，工具的描述和名称会自动包含在代理的提示中。因此，自定义工具必须有一个写得很好的描述和名称，以便代理了解如何使用它们。让我们看一下`controlnet_transformer`的描述和名称：

```py
print(f"Description: '{controlnet_transformer.description}'")
print(f"Name: '{controlnet_transformer.name}'")
```

给出

```py
Description: 'This is a tool that transforms an image with ControlNet according to a prompt. 
It takes two inputs: `image`, which should be the image to transform, and `prompt`, which should be the prompt to use to change it. It returns the modified image.'
Name: 'image_transformer'
```

名称和描述准确，并符合精心策划的工具集的风格。接下来，让我们用`controlnet_transformer`和`upscaler`实例化一个代理：

```py
tools = [controlnet_transformer, upscaler]
agent = HfAgent("https://api-inference.huggingface.co/models/bigcode/starcoder", additional_tools=tools)
```

此命令应该给您以下信息：

```py
image_transformer has been replaced by <transformers_modules.diffusers.controlnet-canny-tool.bd76182c7777eba9612fc03c0
8718a60c0aa6312.image_transformation.ControlNetTransformationTool object at 0x7f1d3bfa3a00> as provided in `additional_tools`
```

精心策划的工具集已经有一个`image_transformer`工具，现在用我们的自定义工具替换。

覆盖现有工具可以是有益的，如果我们想要为与现有工具完全相同的任务使用自定义工具，因为代理擅长使用特定任务。请注意，自定义工具在这种情况下应遵循与被覆盖工具完全相同的 API，或者您应该调整提示模板以确保使用该工具的所有示例都已更新。

升频工具被命名为`image_upscaler`，该工具尚未出现在默认工具箱中，因此只需将其添加到工具列表中。您可以随时查看代理当前可用的工具箱，通过`agent.toolbox`属性：

```py
print("\n".join([f"- {a}" for a in agent.toolbox.keys()]))
```

```py
- document_qa
- image_captioner
- image_qa
- image_segmenter
- transcriber
- summarizer
- text_classifier
- text_qa
- text_reader
- translator
- image_transformer
- text_downloader
- image_generator
- video_generator
- image_upscaler
```

请注意，`image_upscaler`现在是代理工具箱的一部分。

现在让我们尝试一下新工具！我们将重复使用我们在 Transformers Agents Quickstart 中生成的图像。

```py
from diffusers.utils import load_image

image = load_image(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rivers_and_lakes.png"
)
```

![](img/eabd440c942fd7c70ec75212a9603e8a.png)

让我们将图像转换为美丽的冬季风景：

```py
image = agent.run("Transform the image: 'A frozen lake and snowy forest'", image=image)
```

```py
==Explanation from the agent==
I will use the following tool: `image_transformer` to transform the image.

==Code generated by the agent==
image = image_transformer(image, prompt="A frozen lake and snowy forest")
```

![](img/67c48ebec156a5115cefc1b4d4e6751c.png)

新的图像处理工具基于 ControlNet，可以对图像进行非常强烈的修改。默认情况下，图像处理工具返回大小为 512x512 像素的图像。让我们看看是否可以将其升频。

```py
image = agent.run("Upscale the image", image)
```

```py
==Explanation from the agent==
I will use the following tool: `image_upscaler` to upscale the image.

==Code generated by the agent==
upscaled_image = image_upscaler(image)
```

![](img/1e4809693bd6c47f57ad6cc02d12f4b9.png)

代理根据升频工具的描述和名称自动将我们的提示“将图像升频”映射到刚刚添加的升频工具，并能够正确运行它。

接下来，让我们看看如何创建一个新的自定义工具。

### 添加新工具

在本节中，我们将展示如何创建一个可以添加到代理的新工具。

#### 创建一个新工具

我们首先将通过创建一个工具来开始。我们将添加一个不太有用但有趣的任务，即获取 Hugging Face Hub 上针对给定任务下载量最高的模型。

我们可以使用以下代码来实现：

```py
from huggingface_hub import list_models

task = "text-classification"

model = next(iter(list_models(filter=task, sort="downloads", direction=-1)))
print(model.id)
```

对于任务`text-classification`，返回`'facebook/bart-large-mnli'`，对于`translation`，返回`'t5-base'。

我们如何将其转换为代理可以利用的工具？所有工具都依赖于保存主要属性的超类`Tool`。我们将创建一个继承自它的类：

```py
from transformers import Tool

class HFModelDownloadsTool(Tool):
    pass
```

这个类有一些需求：

+   一个 `name` 属性，对应于工具本身的名称。为了与具有表现性名称的其他工具保持一致，我们将其命名为 `model_download_counter`。

+   一个 `description` 属性，将用于填充代理的提示。

+   `inputs` 和 `outputs` 属性。定义这些属性将帮助 Python 解释器做出明智的选择，并允许在将工具推送到 Hub 时生成一个 gradio-demo。它们都是预期值的列表，可以是 `text`、`image` 或 `audio`。

+   包含推理代码的 `__call__` 方法。这就是我们上面玩耍的代码！

现在我们的类是这样的：

```py
from transformers import Tool
from huggingface_hub import list_models

class HFModelDownloadsTool(Tool):
    name = "model_download_counter"
    description = (
        "This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. "
        "It takes the name of the category (such as text-classification, depth-estimation, etc), and "
        "returns the name of the checkpoint."
    )

    inputs = ["text"]
    outputs = ["text"]

    def __call__(self, task: str):
        model = next(iter(list_models(filter=task, sort="downloads", direction=-1)))
        return model.id
```

现在我们有了我们的工具。将其保存在一个文件中，并从您的主脚本中导入它。让我们将这个文件命名为 `model_downloads.py`，这样生成的导入代码看起来像这样：

```py
from model_downloads import HFModelDownloadsTool

tool = HFModelDownloadsTool()
```

为了让其他人从中受益，并为了更简单的初始化，我们建议将其推送到 Hub 在您的命名空间下。要这样做，只需在 `tool` 变量上调用 `push_to_hub`：

```py
tool.push_to_hub("hf-model-downloads")
```

现在您的代码已经在 Hub 上了！让我们看看最后一步，即让代理使用它。

#### 让代理使用工具

现在我们有了我们的工具，它存放在 Hub 上，可以这样实例化（将用户名更改为您的工具）：

```py
from transformers import load_tool

tool = load_tool("lysandre/hf-model-downloads")
```

为了在代理中使用它，只需将其传递给代理初始化方法的 `additional_tools` 参数：

```py
from transformers import HfAgent

agent = HfAgent("https://api-inference.huggingface.co/models/bigcode/starcoder", additional_tools=[tool])

agent.run(
    "Can you read out loud the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?"
)
```

输出如下：

```py
==Code generated by the agent==
model = model_download_counter(task="text-to-video")
print(f"The model with the most downloads is {model}.")
audio_model = text_reader(model)

==Result==
The model with the most downloads is damo-vilab/text-to-video-ms-1.7b.
```

并生成以下音频。

| **音频** |
| --- |

|

<https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/damo.wav>

|

根据 LLM 的不同，有些可能非常脆弱，需要非常精确的提示才能很好地工作。拥有工具的明确定义的名称和描述对于代理能够利用它至关重要。

### 替换现有工具

通过将新项目分配给代理的工具箱，可以简单地替换现有工具。以下是如何操作的方法：

```py
from transformers import HfAgent, load_tool

agent = HfAgent("https://api-inference.huggingface.co/models/bigcode/starcoder")
agent.toolbox["image-transformation"] = load_tool("diffusers/controlnet-canny-tool")
```

替换工具时要小心！这也会调整代理的提示。如果您有一个更适合任务的更好提示，这可能是好事，但也可能导致您的工具被选中的次数远远超过其他工具，或者选择其他工具而不是您定义的工具。

## 利用 gradio-tools

[gradio-tools](https://github.com/freddyaboulton/gradio-tools) 是一个强大的库，允许使用 Hugging Face Spaces 作为工具。它支持许多现有的 Spaces，以及可以使用它设计自定义 Spaces。

我们通过使用 `Tool.from_gradio` 方法为 `gradio_tools` 提供支持。例如，我们想利用 `gradio-tools` 工具包中提供的 `StableDiffusionPromptGeneratorTool` 工具来改进我们的提示并生成更好的图像。

我们首先从 `gradio_tools` 导入工具并实例化它：

```py
from gradio_tools import StableDiffusionPromptGeneratorTool

gradio_tool = StableDiffusionPromptGeneratorTool()
```

我们将该实例传递给 `Tool.from_gradio` 方法：

```py
from transformers import Tool

tool = Tool.from_gradio(gradio_tool)
```

现在我们可以像处理通常的自定义工具一样管理它。我们利用它来改进我们的提示 `一只穿着太空服的兔子`：

```py
from transformers import HfAgent

agent = HfAgent("https://api-inference.huggingface.co/models/bigcode/starcoder", additional_tools=[tool])

agent.run("Generate an image of the `prompt` after improving it.", prompt="A rabbit wearing a space suit")
```

模型充分利用了该工具：

```py
==Explanation from the agent==
I will use the following  tools: `StableDiffusionPromptGenerator` to improve the prompt, then `image_generator` to generate an image according to the improved prompt.

==Code generated by the agent==
improved_prompt = StableDiffusionPromptGenerator(prompt)
print(f"The improved prompt is {improved_prompt}.")
image = image_generator(improved_prompt)
```

最后生成图像之前：

![](img/562727afc88cc5866a6269fc324460aa.png)

gradio-tools 需要*文本*输入和输出，即使在处理不同的模态时也是如此。这个实现可以处理图像和音频对象。目前这两者是不兼容的，但随着我们努力改进支持，它们将迅速变得兼容。

## 未来与 Langchain 的兼容性

我们喜欢 Langchain，并认为它拥有一个非常引人注目的工具套件。为了处理这些工具，Langchain 需要*文本*输入和输出，即使在处理不同的模态时也是如此。这通常是对象的序列化版本（即保存到磁盘）。

这种差异意味着 transformers-agents 和 langchain 之间不能处理多模态。我们希望在未来版本中解决这个限制，并欢迎热衷于 langchain 的用户帮助我们实现这种兼容性。

我们希望能得到更好的支持。如果您愿意帮助，请[提出问题](https://github.com/huggingface/transformers/issues/new)，并分享您的想法。
