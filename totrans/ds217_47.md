# 使用CLI共享数据集

> 原始文本：[https://huggingface.co/docs/datasets/share](https://huggingface.co/docs/datasets/share)

在Hugging Face，我们的使命是使优秀的机器学习民主化，我们相信开源的价值。这就是为什么我们设计了🤗数据集，以便任何人都可以与更广泛的ML社区共享数据集。目前在Hugging Face Hub上有超过100种语言的数千个数据集，Hugging Face团队始终欢迎新的贡献！

数据集存储库提供功能，例如：

+   免费数据集托管

+   数据集版本控制

+   提交历史和差异

+   用于发现的元数据

+   用于文档、许可、限制等的数据集卡片

+   [数据集查看器](../hub/datasets-viewer)

本指南将向您展示如何共享一个数据集文件夹或存储库，任何人都可以轻松访问。

## 添加一个数据集

您可以通过Hugging Face Hub上的数据集存储库与社区共享您的数据集。如果您想控制谁可以访问数据集，它也可以是一个私有数据集。

在数据集存储库中，您可以托管所有数据文件，并[配置您的数据集](./repository_structure#define-your-splits-in-yaml)以定义哪个文件属于哪个拆分。支持以下格式：CSV、TSV、JSON、JSON行、文本、Parquet、Arrow、SQLite、WebDataset。还支持许多种压缩文件类型：GZ、BZ2、LZ4、LZMA或ZSTD。例如，您的数据集可以由`.json.gz`文件组成。

另一方面，如果您的数据集不是支持的格式，或者您想要更多控制数据集的加载方式，您可以编写自己的数据集脚本。请注意，使用加载脚本定义的数据集可能无法使用一些功能，例如数据集查看器。用户还必须传递`trust_remote_code=True`来加载数据集。如果可能的话，通常建议数据集不要依赖加载脚本，以便从Hub的所有功能中受益。

从Hub加载数据集时，所有支持格式的文件都会被加载，遵循[存储库结构](./repository_structure)。但是，如果有数据集脚本，它将被下载并执行以下载和准备数据集。

有关如何从Hub加载数据集的更多信息，请查看[从Hub加载数据集](./load_hub)教程。

### 创建存储库

如果您还没有在[hf.co](https://huggingface.co/join)上创建帐户，共享社区数据集将需要您创建一个。您可以直接从Hugging Face Hub上的帐户创建一个[新数据集存储库](https://huggingface.co/login?next=%2Fnew-dataset)，但本指南将向您展示如何从终端上传数据集。

1.  确保您在安装Datasets的虚拟环境中，并运行以下命令：

```py
huggingface-cli login
```

1.  使用您的Hugging Face Hub凭据登录，并创建一个新的数据集存储库：

```py
huggingface-cli repo create my-cool-dataset --type dataset
```

添加`-organization`标志以在特定组织下创建存储库：

```py
huggingface-cli repo create my-cool-dataset --type dataset --organization your-org-name
```

## 准备您的文件

检查您的目录，确保您要上传的文件只有：

+   数据集的数据文件

+   数据集卡片`README.md`

+   （可选）`your_dataset_name.py`是您的数据集加载脚本（如果您的数据文件已经是支持的格式csv/jsonl/json/parquet/txt，则可选）。要创建数据集脚本，请参阅[数据集脚本](dataset_script)页面。请注意，使用加载脚本定义的数据集可能无法使用一些功能，例如数据集查看器。用户还必须传递`trust_remote_code=True`来加载数据集。如果可能的话，通常建议数据集不要依赖加载脚本，以便从Hub的所有功能中受益。

## 上传huggingface-cli

使用`huggingface-cli upload`命令直接上传文件到Hub。在内部，它使用了在[上传指南](../huggingface_hub/guides/upload)中描述的相同的`upload_file`和`upload_folder`辅助函数。在下面的示例中，我们将介绍最常见的用例。要查看所有可用选项的完整列表，您可以运行：

```py
>>> huggingface-cli upload --help
```

有关`huggingface-cli`的更一般信息，您可以查看[CLI指南](../huggingface_hub/guides/cli)。

### 上传整个文件夹

此命令的默认用法是：

```py
# Usage:  huggingface-cli upload [dataset_repo_id] --repo-type=dataset [local_path] [path_in_repo]
```

要在存储库的根目录上传当前目录，请使用：

```py
>>> huggingface-cli upload my-cool-dataset --repo-type=dataset . .
https://huggingface.co/datasets/Wauplin/my-cool-dataset/tree/main/
```

如果存储库尚不存在，将自动创建它。

您还可以上传特定文件夹：

```py
>>> huggingface-cli upload my-cool-dataset --repo-type=dataset ./data .
https://huggingface.co/datasetsWauplin/my-cool-dataset/tree/main/
```

最后，您可以将文件夹上传到存储库的特定目的地：

```py
>>> huggingface-cli upload my-cool-dataset --repo-type=dataset ./path/to/curated/data /data/train
https://huggingface.co/datasetsWauplin/my-cool-dataset/tree/main/data/train
```

### 上传单个文件

您还可以通过将`local_path`设置为指向计算机上的文件来上传单个文件。如果是这种情况，`path_in_repo`是可选的，将默认为您本地文件的名称：

```py
>>> huggingface-cli upload Wauplin/my-cool-dataset --repo-type=dataset ./files/train.csv
https://huggingface.co/datasetsWauplin/my-cool-dataset/blob/main/train.csv
```

如果要将单个文件上传到特定目录，请相应地设置`path_in_repo`：

```py
>>> huggingface-cli upload Wauplin/my-cool-dataset --repo-type=dataset ./files/train.csv /data/train.csv
https://huggingface.co/datasetsWauplin/my-cool-dataset/blob/main/data/train.csv
```

### 上传多个文件

要一次从文件夹上传多个文件，而不上传整个文件夹，请使用`--include`和`--exclude`模式。也可以与`--delete`选项结合使用，以在上传新文件的同时删除存储库中的文件。在下面的示例中，我们通过删除远程文件并上传所有CSV文件来同步本地Space：

```py
# Sync local Space with Hub (upload new CSV files, delete removed files)
>>> huggingface-cli upload Wauplin/my-cool-dataset --repo-type=dataset --include="/data/*.csv" --delete="*" --commit-message="Sync local dataset with Hub"
...
```

### 上传到组织

要将内容上传到组织拥有的存储库而不是个人存储库，必须在`repo_id`中明确指定：

```py
>>> huggingface-cli upload MyCoolOrganization/my-cool-dataset --repo-type=dataset . .
https://huggingface.co/datasetsMyCoolOrganization/my-cool-dataset/tree/main/
```

### 上传到特定的修订版本

默认情况下，文件将上传到`main`分支。如果要将文件上传到另一个分支或引用，请使用`--revision`选项：

```py
# Upload files to a PR
>>> huggingface-cli upload bigcode/the-stack --repo-type dataset -revision refs/pr/104 . .
...
```

**注意：**如果`revision`不存在且未设置`--create-pr`，将自动从`main`分支创建一个分支。

### 上传并创建PR

如果您没有推送到存储库的权限，您必须打开一个PR并让作者知道您想要进行的更改。这可以通过设置`--create-pr`选项来完成：

```py
# Create a PR and upload the files to it
>>> huggingface-cli upload bigcode/the-stack --repo-type dataset --revision refs/pr/104 --create-pr . .
https://huggingface.co/datasets/bigcode/the-stack/blob/refs%2Fpr%2F104/
```

### 定期间隔上传

在某些情况下，您可能希望定期向存储库推送更新。例如，如果您的数据集随着时间的推移而增长，并且希望每10分钟上传一次数据文件夹，则可以使用`--every`选项：

```py
# Upload new logs every 10 minutes
huggingface-cli upload my-cool-dynamic-dataset data/ --every=10
```

### 指定提交消息

使用`--commit-message`和`--commit-description`设置自定义消息和描述以替代默认消息

```py
>>> huggingface-cli upload Wauplin/my-cool-dataset ./data . --repo-type dataset --commit-message="Version 2" --commit-description="Train size: 4321\. Check Dataset Viewer for more details."
...
https://huggingface.co/datasetsWauplin/my-cool-dataset/tree/main
```

### 指定令牌

要上传文件，您必须使用令牌。默认情况下，将使用本地保存的令牌（使用`huggingface-cli login`）。如果要明确进行身份验证，请使用`--token`选项：

```py
>>> huggingface-cli upload Wauplin/my-cool-dataset ./data . --token=hf_****
...
https://huggingface.co/datasetsWauplin/my-cool-data/tree/main
```

### 安静模式

默认情况下，`huggingface-cli upload`命令将是冗长的。它将打印诸如警告消息、有关上传文件的信息和进度条等详细信息。如果要将所有这些信息静音，请使用`--quiet`选项。只会打印最后一行（即上传文件的URL）。如果您希望将输出传递给脚本中的另一个命令，则这可能会很有用。

```py
>>> huggingface-cli upload Wauplin/my-cool-dataset ./data . --quiet
https://huggingface.co/datasets/Wauplin/my-cool-dataset/tree/main
```

## 享受！

恭喜，您的数据集现在已经上传到Hugging Face Hub，任何人都可以在一行代码中加载它！🥳

```py
dataset = load_dataset("Wauplin/my-cool-dataset")
```

如果您的数据集受支持，还应该有一个[数据集查看器](../hub/datasets-viewer)供所有人探索数据集内容。

最后，请不要忘记丰富数据集卡片以记录您的数据集并使其可发现！查看[创建数据集卡片](dataset_card)指南以了解更多。
