["```py\n( )\n```", "```py\n( *args **kwargs )\n```", "```py\n( ) \u2192 export const metadata = 'undefined';torch.device\n```", "```py\n( *args **kwargs ) \u2192 export const metadata = 'undefined';DiffusionPipeline\n```", "```py\n( )\n```", "```py\n>>> from diffusers import (\n...     StableDiffusionPipeline,\n...     StableDiffusionImg2ImgPipeline,\n...     StableDiffusionInpaintPipeline,\n... )\n\n>>> text2img = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n>>> img2img = StableDiffusionImg2ImgPipeline(**text2img.components)\n>>> inpaint = StableDiffusionInpaintPipeline(**text2img.components)\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( pretrained_model_name **kwargs ) \u2192 export const metadata = 'undefined';os.PathLike\n```", "```py\n( slice_size: Union = 'auto' )\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionPipeline\n\n>>> pipe = StableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\",\n...     torch_dtype=torch.float16,\n...     use_safetensors=True,\n... )\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> pipe.enable_attention_slicing()\n>>> image = pipe(prompt).images[0]\n```", "```py\n( gpu_id: Optional = None device: Union = 'cuda' )\n```", "```py\n( gpu_id: Optional = None device: Union = 'cuda' )\n```", "```py\n( attention_op: Optional = None )\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n( pretrained_model_name_or_path: Union **kwargs )\n```", "```py\nSome weights of UNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:\n- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 9, 3, 3]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n```", "```py\n>>> from diffusers import DiffusionPipeline\n\n>>> # Download pipeline from huggingface.co and cache.\n>>> pipeline = DiffusionPipeline.from_pretrained(\"CompVis/ldm-text2im-large-256\")\n\n>>> # Download pipeline that requires an authorization token\n>>> # For more information on access tokens, please refer to this section\n>>> # of the documentation](https://huggingface.co/docs/hub/security-tokens)\n>>> pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n\n>>> # Use a different scheduler\n>>> from diffusers import LMSDiscreteScheduler\n\n>>> scheduler = LMSDiscreteScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.scheduler = scheduler\n```", "```py\n( )\n```", "```py\n( images )\n```", "```py\n( save_directory: Union safe_serialization: bool = True variant: Optional = None push_to_hub: bool = False **kwargs )\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path: Union **kwargs )\n```", "```py\nSome weights of FlaxUNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:\n```", "```py\n>>> from diffusers import FlaxDiffusionPipeline\n\n>>> # Download pipeline from huggingface.co and cache.\n>>> # Requires to be logged in to Hugging Face hub,\n>>> # see more in [the documentation](https://huggingface.co/docs/hub/security-tokens)\n>>> pipeline, params = FlaxDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\",\n...     revision=\"bf16\",\n...     dtype=jnp.bfloat16,\n... )\n\n>>> # Download pipeline, but use a different scheduler\n>>> from diffusers import FlaxDPMSolverMultistepScheduler\n\n>>> model_id = \"runwayml/stable-diffusion-v1-5\"\n>>> dpmpp, dpmpp_state = FlaxDPMSolverMultistepScheduler.from_pretrained(\n...     model_id,\n...     subfolder=\"scheduler\",\n... )\n\n>>> dpm_pipe, dpm_params = FlaxStableDiffusionPipeline.from_pretrained(\n...     model_id, revision=\"bf16\", dtype=jnp.bfloat16, scheduler=dpmpp\n... )\n>>> dpm_params[\"scheduler\"] = dpmpp_state\n```", "```py\n( images )\n```", "```py\n( save_directory: Union params: Union push_to_hub: bool = False **kwargs )\n```", "```py\n( )\n```", "```py\n( repo_id: str commit_message: Optional = None private: Optional = None token: Optional = None create_pr: bool = False safe_serialization: bool = True variant: Optional = None )\n```", "```py\nfrom diffusers import UNet2DConditionModel\n\nunet = UNet2DConditionModel.from_pretrained(\"stabilityai/stable-diffusion-2\", subfolder=\"unet\")\n\n# Push the `unet` to your namespace with the name \"my-finetuned-unet\".\nunet.push_to_hub(\"my-finetuned-unet\")\n\n# Push the `unet` to an organization with the name \"my-finetuned-unet\".\nunet.push_to_hub(\"your-org/my-finetuned-unet\")\n```"]