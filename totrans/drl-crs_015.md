# è®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†ğŸ¤–

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/learn/deep-rl-course/unit1/hands-on`](https://huggingface.co/learn/deep-rl-course/unit1/hands-on)

![æé—®](http://hf.co/join/discord) ![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit1/unit1.ipynb)

ç°åœ¨ä½ å·²ç»å­¦ä¹ äº†å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œä½ å¯ä»¥å¼€å§‹è®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªä»£ç†ï¼Œå¹¶é€šè¿‡ Hub ä¸ç¤¾åŒºåˆ†äº«ğŸ”¥ï¼šä¸€ä¸ªæœˆçƒç€é™†å™¨ä»£ç†ï¼Œå°†å­¦ä¼šæ­£ç¡®ç€é™†åœ¨æœˆçƒä¸ŠğŸŒ•

![æœˆçƒç€é™†å™¨](img/2cd989d7bf01c3c770ed0607b8bfdd59.png)

æœ€åï¼Œä½ å°†**ä¸Šä¼ è¿™ä¸ªè®­ç»ƒå¥½çš„ä»£ç†åˆ° Hugging Face Hub ğŸ¤—ï¼Œè¿™æ˜¯ä¸€ä¸ªå…è´¹ã€å¼€æ”¾çš„å¹³å°ï¼Œäººä»¬å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«æœºå™¨å­¦ä¹ æ¨¡å‹ã€æ•°æ®é›†å’Œæ¼”ç¤ºã€‚**

æ„Ÿè°¢æˆ‘ä»¬çš„[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ï¼Œä½ å°†èƒ½å¤Ÿä¸å…¶ä»–åŒå­¦æ¯”è¾ƒä½ çš„ç»“æœï¼Œå¹¶äº¤æµæœ€ä½³å®è·µï¼Œä»¥æé«˜ä½ çš„ä»£ç†åˆ†æ•°ã€‚è°å°†èµ¢å¾— Unit 1 çš„æŒ‘æˆ˜ğŸ†ï¼Ÿ

ä¸ºäº†éªŒè¯è¿™ä¸ª[è®¤è¯æµç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)çš„å®è·µæ€§ï¼Œä½ éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hubï¼Œå¹¶**è·å¾—>=200 çš„ç»“æœ**ã€‚

è¦æ‰¾åˆ°ä½ çš„ç»“æœï¼Œå»[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)æ‰¾åˆ°ä½ çš„æ¨¡å‹ï¼Œ**ç»“æœ=å¹³å‡å¥–åŠ±-å¥–åŠ±çš„æ ‡å‡†å·®**

**å¦‚æœæ‰¾ä¸åˆ°ä½ çš„æ¨¡å‹ï¼Œè¯·è½¬åˆ°é¡µé¢åº•éƒ¨å¹¶ç‚¹å‡»åˆ·æ–°æŒ‰é’®ã€‚**

æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰[`huggingface.co/deep-rl-course/en/unit0/introduction#certification-process`](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)

ä½ å¯ä»¥åœ¨è¿™é‡Œæ£€æŸ¥ä½ çš„è¿›åº¦ğŸ‘‰[`huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course`](https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course)

è®©æˆ‘ä»¬å¼€å§‹å§ï¼ğŸš€

**è¦å¼€å§‹å®è·µï¼Œè¯·ç‚¹å‡»â€œåœ¨ Colab ä¸­æ‰“å¼€â€æŒ‰é’®**ğŸ‘‡ï¼š

![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit1/unit1.ipynb)

æˆ‘ä»¬å¼ºçƒˆå»ºè®®å­¦ç”Ÿä½¿ç”¨ Google Colab è¿›è¡Œå®è·µç»ƒä¹ ï¼Œè€Œä¸æ˜¯åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œã€‚

é€šè¿‡ä½¿ç”¨ Google Colabï¼Œ**ä½ å¯ä»¥ä¸“æ³¨äºå­¦ä¹ å’Œå®éªŒï¼Œè€Œä¸å¿…æ‹…å¿ƒè®¾ç½®ç¯å¢ƒçš„æŠ€æœ¯ç»†èŠ‚**ã€‚

# Unit 1ï¼šè®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†ğŸ¤–

![Unit 1 ç¼©ç•¥å›¾](img/269d50061313727de39330c553eb4733.png)

åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œä½ å°†è®­ç»ƒä½ çš„**ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†**ï¼Œä¸€ä¸ªæœˆçƒç€é™†å™¨ä»£ç†ï¼Œå°†å­¦ä¼š**åœ¨æœˆçƒä¸Šæ­£ç¡®ç€é™†ğŸŒ•**ã€‚ä½¿ç”¨[Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)è¿™ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ï¼Œä¸ç¤¾åŒºåˆ†äº«ï¼Œå¹¶å°è¯•ä¸åŒçš„é…ç½®

### ç¯å¢ƒğŸ®

+   [LunarLander-v2](https://gymnasium.farama.org/environments/box2d/lunar_lander/)

### ä½¿ç”¨çš„åº“ğŸ“š

+   [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)

æˆ‘ä»¬ä¸æ–­åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœä½ åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­å‘ç°äº†ä¸€äº›é—®é¢˜**ï¼Œè¯·åœ¨ Github Repo ä¸Š[æå‡ºé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)ã€‚

## æœ¬ç¬”è®°æœ¬çš„ç›®æ ‡ğŸ†

åœ¨ç¬”è®°æœ¬çš„ç»“å°¾ï¼Œä½ å°†ï¼š

+   èƒ½å¤Ÿä½¿ç”¨**Gymnasium**ï¼Œè¿™æ˜¯ä¸€ä¸ªç¯å¢ƒåº“ã€‚

+   èƒ½å¤Ÿä½¿ç”¨**Stable-Baselines3**ï¼Œè¿™æ˜¯ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ã€‚

+   èƒ½å¤Ÿ**å°†è®­ç»ƒå¥½çš„ä»£ç†æ¨é€åˆ° Hub**ï¼Œå¹¶é™„ä¸Šä¸€ä¸ªæ¼‚äº®çš„è§†é¢‘å›æ”¾å’Œä¸€ä¸ªè¯„ä¼°åˆ†æ•°ğŸ”¥ã€‚

## è¿™ä¸ªç¬”è®°æœ¬æ¥è‡ªæ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹

![æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹æ’å›¾](img/1ffbb6aa2076af9a6f9eb9b4e21ecf34.png)

åœ¨è¿™é—¨å…è´¹è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†ï¼š

+   ğŸ“– ç†è®ºå’Œå®è·µä¸Šå­¦ä¹ æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚

+   ğŸ§‘â€ğŸ’» å­¦ä¹ ä½¿ç”¨è‘—åçš„æ·±åº¦ RL åº“ï¼Œå¦‚ Stable Baselines3ã€RL Baselines3 Zooã€CleanRL å’Œ Sample Factory 2.0ã€‚

+   ğŸ¤– åœ¨ç‹¬ç‰¹ç¯å¢ƒä¸­**è®­ç»ƒä»£ç†**

+   ğŸ“ é€šè¿‡å®Œæˆ 80%çš„ä½œä¸š**è·å¾—å®Œæˆè¯ä¹¦**ã€‚

ä»¥åŠæ›´å¤šï¼

æŸ¥çœ‹ğŸ“šè¯¾ç¨‹å¤§çº²ğŸ‘‰[`simoninithomas.github.io/deep-rl-course`](https://simoninithomas.github.io/deep-rl-course)

ä¸è¦å¿˜è®°**[æ³¨å†Œè¯¾ç¨‹](http://eepurl.com/ic5ZUD)**ï¼ˆæˆ‘ä»¬æ­£åœ¨æ”¶é›†æ‚¨çš„ç”µå­é‚®ä»¶ä»¥ä¾¿**åœ¨æ¯ä¸ªå•å…ƒå‘å¸ƒæ—¶å‘æ‚¨å‘é€é“¾æ¥å¹¶æä¾›æœ‰å…³æŒ‘æˆ˜å’Œæ›´æ–°çš„ä¿¡æ¯ï¼‰**ã€‚

ä¿æŒè”ç³»å¹¶æé—®çš„æœ€ä½³æ–¹å¼æ˜¯**åŠ å…¥æˆ‘ä»¬çš„ discord æœåŠ¡å™¨**ä¸ç¤¾åŒºå’Œæˆ‘ä»¬äº¤æµğŸ‘‰ğŸ»[`discord.gg/ydHrjt3WP5`](https://discord.gg/ydHrjt3WP5)

## å…ˆå†³æ¡ä»¶ğŸ—ï¸

åœ¨æ·±å…¥ç¬”è®°æœ¬ä¹‹å‰ï¼Œæ‚¨éœ€è¦ï¼š

ğŸ”²ğŸ“ é€šè¿‡[é˜…è¯»ç¬¬ 0 å•å…ƒ](https://huggingface.co/deep-rl-course/unit0/introduction) **è·å–æœ‰å…³è¯¾ç¨‹çš„æ‰€æœ‰ä¿¡æ¯å¹¶å¸®åŠ©æ‚¨å…¥é—¨**ğŸ¤—

ğŸ”²ğŸ“š é€šè¿‡[é˜…è¯»ç¬¬ 1 å•å…ƒ](https://huggingface.co/deep-rl-course/unit1/introduction) **äº†è§£å¼ºåŒ–å­¦ä¹ åŸºç¡€**ï¼ˆMCã€TDã€å¥–åŠ±å‡è®¾...ï¼‰ã€‚

## æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å°ç»“ğŸ“š

![RL è¿‡ç¨‹](img/79d6e90ecca40e7412a5ae37c07bf478.png)

è®©æˆ‘ä»¬ç®€è¦å›é¡¾ä¸€ä¸‹æˆ‘ä»¬åœ¨ç¬¬ä¸€ä¸ªå•å…ƒå­¦åˆ°çš„å†…å®¹ï¼š

+   å¼ºåŒ–å­¦ä¹ æ˜¯ä¸€ç§**ä»è¡ŒåŠ¨ä¸­å­¦ä¹ çš„è®¡ç®—æ–¹æ³•**ã€‚æˆ‘ä»¬æ„å»ºä¸€ä¸ªä»£ç†ï¼Œé€šè¿‡**é€šè¿‡è¯•é”™ä¸ç¯å¢ƒäº’åŠ¨**å¹¶æ¥æ”¶å¥–åŠ±ï¼ˆè´Ÿé¢æˆ–æ­£é¢ï¼‰ä½œä¸ºåé¦ˆæ¥å­¦ä¹ ã€‚

+   ä»»ä½• RL ä»£ç†çš„ç›®æ ‡æ˜¯**æœ€å¤§åŒ–å…¶é¢„æœŸç´¯ç§¯å¥–åŠ±**ï¼ˆä¹Ÿç§°ä¸ºé¢„æœŸå›æŠ¥ï¼‰ï¼Œå› ä¸º RL åŸºäº*å¥–åŠ±å‡è®¾*ï¼Œå³æ‰€æœ‰ç›®æ ‡éƒ½å¯ä»¥æè¿°ä¸ºæœ€å¤§åŒ–é¢„æœŸç´¯ç§¯å¥–åŠ±ã€‚

+   RL è¿‡ç¨‹æ˜¯ä¸€ä¸ª**è¾“å‡ºçŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±å’Œä¸‹ä¸€ä¸ªçŠ¶æ€åºåˆ—çš„å¾ªç¯**ã€‚

+   ä¸ºäº†è®¡ç®—é¢„æœŸç´¯ç§¯å¥–åŠ±ï¼ˆé¢„æœŸå›æŠ¥ï¼‰ï¼Œ**æˆ‘ä»¬æŠ˜æ‰£å¥–åŠ±**ï¼šè¶Šæ—©è·å¾—çš„å¥–åŠ±ï¼ˆåœ¨æ¸¸æˆå¼€å§‹æ—¶ï¼‰æ›´æœ‰å¯èƒ½å‘ç”Ÿï¼Œå› ä¸ºå®ƒä»¬æ¯”é•¿æœŸæœªæ¥å¥–åŠ±æ›´å¯é¢„æµ‹ã€‚

+   è¦è§£å†³ RL é—®é¢˜ï¼Œæ‚¨å¸Œæœ›**æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜ç­–ç•¥**ï¼›ç­–ç•¥æ˜¯æ‚¨çš„ AI çš„â€œå¤§è„‘â€ï¼Œå°†å‘Šè¯‰æˆ‘ä»¬åœ¨ç»™å®šçŠ¶æ€ä¸‹åº”è¯¥é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ã€‚æœ€ä½³ç­–ç•¥æ˜¯ä½¿æ‚¨çš„è¡ŒåŠ¨æœ€å¤§åŒ–é¢„æœŸå›æŠ¥çš„ç­–ç•¥ã€‚

æœ‰**ä¸¤ç§**æ–¹æ³•å¯ä»¥æ‰¾åˆ°æ‚¨çš„æœ€ä¼˜ç­–ç•¥ï¼š

+   é€šè¿‡**ç›´æ¥è®­ç»ƒæ‚¨çš„ç­–ç•¥**ï¼šåŸºäºç­–ç•¥çš„æ–¹æ³•ã€‚

+   é€šè¿‡**è®­ç»ƒä¸€ä¸ªå€¼å‡½æ•°**å‘Šè¯‰æˆ‘ä»¬ä»£ç†åœ¨æ¯ä¸ªçŠ¶æ€å°†è·å¾—çš„é¢„æœŸå›æŠ¥ï¼Œå¹¶ä½¿ç”¨æ­¤å‡½æ•°å®šä¹‰æˆ‘ä»¬çš„ç­–ç•¥ï¼šåŸºäºä»·å€¼çš„æ–¹æ³•ã€‚

+   æœ€åï¼Œæˆ‘ä»¬è°ˆåˆ°äº†æ·±åº¦ RLï¼Œå› ä¸º**æˆ‘ä»¬å¼•å…¥äº†æ·±åº¦ç¥ç»ç½‘ç»œæ¥ä¼°è®¡è¦é‡‡å–çš„è¡ŒåŠ¨ï¼ˆåŸºäºç­–ç•¥ï¼‰æˆ–ä¼°è®¡çŠ¶æ€çš„ä»·å€¼ï¼ˆåŸºäºä»·å€¼ï¼‰ï¼Œå› æ­¤å¾—åâ€œæ·±åº¦â€ã€‚**

# è®©æˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†å¹¶å°†å…¶ä¸Šä¼ åˆ° HubğŸš€

## è·å¾—è¯ä¹¦ğŸ“

ä¸ºäº†éªŒè¯è¿™ä¸€ç‚¹ï¼Œè¿›è¡Œ[è®¤è¯æµç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)ï¼Œæ‚¨éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hub å¹¶**è·å¾—>=200 çš„ç»“æœ**ã€‚

è¦æ‰¾åˆ°æ‚¨çš„ç»“æœï¼Œè¯·è½¬åˆ°[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)å¹¶æ‰¾åˆ°æ‚¨çš„æ¨¡å‹ï¼Œ**ç»“æœ=å¹³å‡å¥–åŠ±-å¥–åŠ±çš„æ ‡å‡†å·®**

æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰[`huggingface.co/deep-rl-course/en/unit0/introduction#certification-process`](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)

## è®¾ç½® GPUğŸ’ª

+   ä¸ºäº†**åŠ é€Ÿä»£ç†çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ GPU**ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œè½¬åˆ°`è¿è¡Œæ—¶ > æ›´æ”¹è¿è¡Œæ—¶ç±»å‹`

![GPU æ­¥éª¤ 1](img/5378127c314cdd92729aa31b7e11ca44.png)

+   ç¡¬ä»¶åŠ é€Ÿå™¨ > GPU

![GPU æ­¥éª¤ 2](img/e0fec252447f98378386ccca8e57a80a.png)

## å®‰è£…ä¾èµ–å¹¶åˆ›å»ºè™šæ‹Ÿå±å¹•ğŸ”½

ç¬¬ä¸€æ­¥æ˜¯å®‰è£…ä¾èµ–é¡¹ï¼Œæˆ‘ä»¬å°†å®‰è£…å¤šä¸ªã€‚

+   `gymnasium[box2d]`ï¼šåŒ…å« LunarLander-v2 ç¯å¢ƒğŸŒ›

+   `stable-baselines3[extra]`ï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ã€‚

+   `huggingface_sb3`ï¼šç”¨äº Stable-baselines3 åŠ è½½å’Œä¸Šä¼ æ¨¡å‹çš„é¢å¤–ä»£ç æ¥è‡ª Hugging Face ğŸ¤— Hubã€‚

ä¸ºäº†ç®€åŒ–äº‹æƒ…ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªè„šæœ¬æ¥å®‰è£…æ‰€æœ‰è¿™äº›ä¾èµ–é¡¹ã€‚

```py
apt install swig cmake
```

```py
pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt
```

åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªé‡æ’­è§†é¢‘ã€‚ä¸ºæ­¤ï¼Œåœ¨ colab ä¸­ï¼Œ**æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ¥æ¸²æŸ“ç¯å¢ƒ**ï¼ˆä»è€Œè®°å½•å¸§ï¼‰ã€‚

å› æ­¤ï¼Œæ¥ä¸‹æ¥çš„å•å…ƒæ ¼å°†å®‰è£…è™šæ‹Ÿå±å¹•åº“å¹¶åˆ›å»ºå’Œè¿è¡Œè™šæ‹Ÿå±å¹•ğŸ–¥

```py
sudo apt-get update
apt install python-opengl
apt install ffmpeg
apt install xvfb
pip3 install pyvirtualdisplay
```

ä¸ºäº†ç¡®ä¿æ–°å®‰è£…çš„åº“è¢«ä½¿ç”¨ï¼Œ**æœ‰æ—¶éœ€è¦é‡æ–°å¯åŠ¨ç¬”è®°æœ¬è¿è¡Œæ—¶**ã€‚ä¸‹ä¸€ä¸ªå•å…ƒæ ¼å°†å¼ºåˆ¶**è¿è¡Œæ—¶å´©æºƒï¼Œå› æ­¤æ‚¨éœ€è¦é‡æ–°è¿æ¥å¹¶ä»è¿™é‡Œå¼€å§‹è¿è¡Œä»£ç **ã€‚é€šè¿‡è¿™ä¸ªæŠ€å·§ï¼Œ**æˆ‘ä»¬å°†èƒ½å¤Ÿè¿è¡Œæˆ‘ä»¬çš„è™šæ‹Ÿå±å¹•**ã€‚

```py
import os

os.kill(os.getpid(), 9)
```

```py
# Virtual display
from pyvirtualdisplay import Display

virtual_display = Display(visible=0, size=(1400, 900))
virtual_display.start()
```

## å¯¼å…¥åŒ…ğŸ“¦

æˆ‘ä»¬å¯¼å…¥çš„å¦ä¸€ä¸ªåº“æ˜¯ huggingface_hub **ä»¥ä¾¿èƒ½å¤Ÿä» hub ä¸Šä¼ å’Œä¸‹è½½è®­ç»ƒå¥½çš„æ¨¡å‹**ã€‚

Hugging Face Hub ğŸ¤— ä½œä¸ºä¸€ä¸ªä¸­å¿ƒåœ°æ–¹ï¼Œä»»ä½•äººéƒ½å¯ä»¥åˆ†äº«å’Œæ¢ç´¢æ¨¡å‹å’Œæ•°æ®é›†ã€‚å®ƒå…·æœ‰ç‰ˆæœ¬æ§åˆ¶ã€æŒ‡æ ‡ã€å¯è§†åŒ–å’Œå…¶ä»–åŠŸèƒ½ï¼Œè®©æ‚¨å¯ä»¥è½»æ¾ä¸ä»–äººåˆä½œã€‚

æ‚¨å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°æ‰€æœ‰å¯ç”¨çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ğŸ‘‰[`huggingface.co/models?pipeline_tag=reinforcement-learning&sort=downloads`](https://huggingface.co/models?pipeline_tag=reinforcement-learning&sort=downloads)

```py
import gymnasium

from huggingface_sb3 import load_from_hub, package_to_hub
from huggingface_hub import (
    notebook_login,
)  # To log to our Hugging Face account to be able to upload models to the Hub.

from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.monitor import Monitor
```

## äº†è§£ Gymnasium åŠå…¶å·¥ä½œåŸç†ğŸ¤–

ğŸ‹ åŒ…å«æˆ‘ä»¬ç¯å¢ƒçš„åº“ç§°ä¸º Gymnasiumã€‚**åœ¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ‚¨å°†ç»å¸¸ä½¿ç”¨ Gymnasiumã€‚**

Gymnasium æ˜¯ç”± Farama Foundation ç»´æŠ¤çš„ Gym åº“çš„**æ–°ç‰ˆæœ¬**ï¼ˆhttps://farama.org/ï¼‰ã€‚

Gymnasium åº“æä¾›ä¸¤ä¸ªä¸œè¥¿ï¼š

+   ä¸€ä¸ªå…è®¸æ‚¨**åˆ›å»º RL ç¯å¢ƒ**çš„æ¥å£ã€‚

+   ä¸€ç»„ç¯å¢ƒï¼ˆgym-controlã€atariã€box2D...ï¼‰ã€‚

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼Œä½†é¦–å…ˆè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ RL å¾ªç¯ã€‚

![RL è¿‡ç¨‹

åœ¨æ¯ä¸€æ­¥ï¼š

+   æˆ‘ä»¬çš„ä»£ç†ä»**ç¯å¢ƒ**æ¥æ”¶ä¸€ä¸ª**çŠ¶æ€ï¼ˆS0ï¼‰**â€”â€”æˆ‘ä»¬æ¥æ”¶åˆ°æ¸¸æˆçš„ç¬¬ä¸€å¸§ï¼ˆç¯å¢ƒï¼‰ã€‚

+   åŸºäºé‚£ä¸ª**çŠ¶æ€ï¼ˆS0ï¼‰**ï¼Œä»£ç†é‡‡å–ä¸€ä¸ª**åŠ¨ä½œï¼ˆA0ï¼‰**â€”â€”æˆ‘ä»¬çš„ä»£ç†å°†å‘å³ç§»åŠ¨ã€‚

+   ç¯å¢ƒè½¬æ¢åˆ°ä¸€ä¸ª**æ–°çš„çŠ¶æ€ï¼ˆS1ï¼‰**â€”â€”æ–°çš„å¸§ã€‚

+   ç¯å¢ƒç»™ä»£ç†ä¸€äº›**å¥–åŠ±ï¼ˆR1ï¼‰**â€”â€”æˆ‘ä»¬è¿˜æ²¡æœ‰æ­»äº¡*(æ­£å¥–åŠ± +1)*ã€‚

ä½¿ç”¨ Gymnasiumï¼š

1ï¸âƒ£ æˆ‘ä»¬ä½¿ç”¨ `gymnasium.make()` åˆ›å»ºæˆ‘ä»¬çš„ç¯å¢ƒ

2ï¸âƒ£ æˆ‘ä»¬ä½¿ç”¨ `observation = env.reset()` å°†ç¯å¢ƒé‡ç½®ä¸ºåˆå§‹çŠ¶æ€

åœ¨æ¯ä¸€æ­¥ï¼š

3ï¸âƒ£ ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è·å–ä¸€ä¸ªåŠ¨ä½œï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­æˆ‘ä»¬æ‰§è¡Œä¸€ä¸ªéšæœºåŠ¨ä½œï¼‰

4ï¸âƒ£ ä½¿ç”¨ `env.step(action)`ï¼Œæˆ‘ä»¬åœ¨ç¯å¢ƒä¸­æ‰§è¡Œæ­¤åŠ¨ä½œå¹¶è·å–

+   `observation`ï¼šæ–°çŠ¶æ€ï¼ˆst+1ï¼‰

+   `reward`ï¼šæ‰§è¡ŒåŠ¨ä½œåæˆ‘ä»¬è·å¾—çš„å¥–åŠ±

+   `terminated`ï¼šæŒ‡ç¤ºå‰§é›†æ˜¯å¦ç»ˆæ­¢ï¼ˆä»£ç†åˆ°è¾¾ç»ˆæ­¢çŠ¶æ€ï¼‰

+   `truncated`ï¼šåœ¨è¿™ä¸ªæ–°ç‰ˆæœ¬ä¸­å¼•å…¥ï¼Œå®ƒæŒ‡ç¤ºä¸€ä¸ªæ—¶é—´é™åˆ¶æˆ–è€…å¦‚æœä»£ç†è¶…å‡ºç¯å¢ƒçš„è¾¹ç•Œã€‚

+   `info`ï¼šæä¾›é¢å¤–ä¿¡æ¯çš„å­—å…¸ï¼ˆå–å†³äºç¯å¢ƒï¼‰ã€‚

æœ‰å…³æ›´å¤šè§£é‡Šï¼Œè¯·æŸ¥çœ‹æ­¤é“¾æ¥ğŸ‘‰[`gymnasium.farama.org/api/env/#gymnasium.Env.step`](https://gymnasium.farama.org/api/env/#gymnasium.Env.step)

å¦‚æœå‰§é›†ç»ˆæ­¢ï¼š

+   æˆ‘ä»¬ä½¿ç”¨ `observation = env.reset()` å°†ç¯å¢ƒé‡ç½®ä¸ºåˆå§‹çŠ¶æ€

**è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼** ç¡®ä¿é˜…è¯»ä»£ç 

```py
import gymnasium as gym

# First, we create our environment called LunarLander-v2
env = gym.make("LunarLander-v2")

# Then we reset this environment
observation, info = env.reset()

for _ in range(20):
    # Take a random action
    action = env.action_space.sample()
    print("Action taken:", action)

    # Do this action in the environment and get
    # next_state, reward, terminated, truncated and info
    observation, reward, terminated, truncated, info = env.step(action)

    # If the game is terminated (in our case we land, crashed) or truncated (timeout)
    if terminated or truncated:
        # Reset the environment
        print("Environment is reset")
        observation, info = env.reset()

env.close()
```

## åˆ›å»º LunarLander ç¯å¢ƒğŸŒ›å¹¶äº†è§£å…¶å·¥ä½œåŸç†

### ç¯å¢ƒğŸ®

åœ¨è¿™ä¸ªç¬¬ä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†è®­ç»ƒæˆ‘ä»¬çš„ä»£ç†ï¼Œä¸€ä¸ª[æœˆçƒç€é™†å™¨](https://gymnasium.farama.org/environments/box2d/lunar_lander/)ï¼Œ**æ­£ç¡®ç€é™†åœ¨æœˆçƒä¸Š**ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œä»£ç†éœ€è¦å­¦ä¼š**è°ƒæ•´å…¶é€Ÿåº¦å’Œä½ç½®ï¼ˆæ°´å¹³ã€å‚ç›´å’Œè§’åº¦ï¼‰ä»¥æ­£ç¡®ç€é™†**ã€‚

* * *

ğŸ’¡ å½“æ‚¨å¼€å§‹ä½¿ç”¨ä¸€ä¸ªç¯å¢ƒæ—¶ï¼Œä¸€ä¸ªå¥½ä¹ æƒ¯æ˜¯æ£€æŸ¥å…¶æ–‡æ¡£

ğŸ‘‰ [`gymnasium.farama.org/environments/box2d/lunar_lander/`](https://gymnasium.farama.org/environments/box2d/lunar_lander/)

* * *

è®©æˆ‘ä»¬çœ‹çœ‹ç¯å¢ƒæ˜¯ä»€ä¹ˆæ ·å­çš„ï¼š

```py
# We create our environment with gym.make("<name_of_the_environment>")
env = gym.make("LunarLander-v2")
env.reset()
print("_____OBSERVATION SPACE_____ \n")
print("Observation Space Shape", env.observation_space.shape)
print("Sample observation", env.observation_space.sample())  # Get a random observation
```

æˆ‘ä»¬çœ‹åˆ°`è§‚å¯Ÿç©ºé—´å½¢çŠ¶ï¼ˆ8ï¼Œï¼‰`ï¼Œè§‚å¯Ÿæ˜¯ä¸€ä¸ªå¤§å°ä¸º 8 çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå€¼åŒ…å«æœ‰å…³ç€é™†å™¨çš„ä¸åŒä¿¡æ¯ï¼š

+   æ°´å¹³ç€é™†å«åæ ‡ï¼ˆxï¼‰

+   å‚ç›´ç€é™†å«åæ ‡ï¼ˆyï¼‰

+   æ°´å¹³é€Ÿåº¦ï¼ˆxï¼‰

+   å‚ç›´é€Ÿåº¦ï¼ˆyï¼‰

+   è§’åº¦

+   è§’é€Ÿåº¦

+   å¦‚æœå·¦è…¿æ¥è§¦ç‚¹æ¥è§¦åˆ°åœ°é¢ï¼ˆå¸ƒå°”å€¼ï¼‰

+   å¦‚æœå³è…¿æ¥è§¦ç‚¹æ¥è§¦åˆ°åœ°é¢ï¼ˆå¸ƒå°”å€¼ï¼‰

```py
print("\n _____ACTION SPACE_____ \n")
print("Action Space Shape", env.action_space.n)
print("Action Space Sample", env.action_space.sample())  # Take a random action
```

åŠ¨ä½œç©ºé—´ï¼ˆä»£ç†å¯ä»¥é‡‡å–çš„å¯èƒ½åŠ¨ä½œé›†ï¼‰æ˜¯ç¦»æ•£çš„ï¼Œæœ‰ 4 ä¸ªå¯ç”¨åŠ¨ä½œğŸ®ï¼š

+   åŠ¨ä½œ 0ï¼šä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼Œ

+   åŠ¨ä½œ 1ï¼šå¯åŠ¨å·¦å®šå‘å¼•æ“ï¼Œ

+   åŠ¨ä½œ 2ï¼šå¯åŠ¨ä¸»å¼•æ“ï¼Œ

+   åŠ¨ä½œ 3ï¼šå¯åŠ¨å³å®šå‘å¼•æ“ã€‚

å¥–åŠ±å‡½æ•°ï¼ˆåœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ç»™å‡ºå¥–åŠ±çš„å‡½æ•°ï¼‰ğŸ’°ï¼š

æ¯ä¸€æ­¥ä¹‹åéƒ½ä¼šè·å¾—å¥–åŠ±ã€‚ä¸€é›†çš„æ€»å¥–åŠ±æ˜¯**è¯¥é›†ä¸­æ‰€æœ‰æ­¥éª¤çš„å¥–åŠ±ä¹‹å’Œ**ã€‚

æ¯ä¸€æ­¥çš„å¥–åŠ±ï¼š

+   å½“ç€é™†å™¨æ¥è¿‘/è¿œç¦»ç€é™†å«æ—¶ï¼Œå¢åŠ /å‡å°‘ã€‚

+   å½“ç€é™†å™¨ç§»åŠ¨å¾—æ›´æ…¢/æ›´å¿«æ—¶ï¼Œå¢åŠ /å‡å°‘ã€‚

+   å½“ç€é™†å™¨å€¾æ–œæ—¶ï¼ˆéæ°´å¹³è§’åº¦ï¼‰ï¼Œå‡å°‘ã€‚

+   æ¯ä¸ªæ¥è§¦åœ°é¢çš„è…¿å¢åŠ  10 åˆ†ã€‚

+   å½“ä¾§å‘å¼•æ“å¯åŠ¨æ—¶ï¼Œæ¯å¸§å‡å°‘ 0.03 ç‚¹ã€‚

+   å½“ä¸»å¼•æ“å¯åŠ¨æ—¶ï¼Œæ¯å¸§å‡å°‘ 0.3 ç‚¹ã€‚

æ¯ä¸€é›†ä¼šå› å æ¯æˆ–å®‰å…¨ç€é™†è€Œè·å¾—é¢å¤–çš„-100 æˆ–+100 åˆ†å¥–åŠ±ã€‚

ä¸€é›†è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œå¦‚æœå¾—åˆ†è‡³å°‘ä¸º 200 åˆ†ã€‚

#### çŸ¢é‡åŒ–ç¯å¢ƒ

+   æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªçŸ¢é‡åŒ–ç¯å¢ƒï¼ˆä¸€ç§å°†å¤šä¸ªç‹¬ç«‹ç¯å¢ƒå †å åˆ°å•ä¸ªç¯å¢ƒä¸­çš„æ–¹æ³•ï¼‰åŒ…å« 16 ä¸ªç¯å¢ƒï¼Œè¿™æ ·ï¼Œ**æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†æœ‰æ›´å¤šä¸åŒçš„ä½“éªŒ**ã€‚

```py
# Create the environment
env = make_vec_env("LunarLander-v2", n_envs=16)
```

## åˆ›å»ºæ¨¡å‹ğŸ¤–

+   æˆ‘ä»¬å·²ç»ç ”ç©¶äº†æˆ‘ä»¬çš„ç¯å¢ƒå¹¶ç†è§£äº†é—®é¢˜ï¼š**é€šè¿‡æ§åˆ¶å·¦ã€å³å’Œä¸»å®šå‘å¼•æ“ï¼Œèƒ½å¤Ÿå°†æœˆçƒç€é™†å™¨æ­£ç¡®ç€é™†åˆ°ç€é™†å«ä¸Š**ã€‚ç°åœ¨è®©æˆ‘ä»¬æ„å»ºæˆ‘ä»¬å°†ç”¨æ¥è§£å†³è¿™ä¸ªé—®é¢˜çš„ç®—æ³• ğŸš€ã€‚

+   ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ï¼Œ[ç¨³å®šåŸºçº¿ 3ï¼ˆSB3ï¼‰](https://stable-baselines3.readthedocs.io/en/master/)ã€‚

+   SB3 æ˜¯ PyTorch ä¸­**å¯é çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å®ç°é›†åˆ**ã€‚

* * *

ğŸ’¡ å½“ä½¿ç”¨æ–°åº“æ—¶ï¼Œä¸€ä¸ªå¥½ä¹ æƒ¯æ˜¯é¦–å…ˆæ·±å…¥ç ”ç©¶æ–‡æ¡£ï¼š[`stable-baselines3.readthedocs.io/en/master/`](https://stable-baselines3.readthedocs.io/en/master/)ï¼Œç„¶åå°è¯•ä¸€äº›æ•™ç¨‹ã€‚

* * *

![ç¨³å®šåŸºçº¿ 3](img/12dda719af36ee58d0b11fadfe3279ba.png)

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ SB3 **PPO**ã€‚[PPOï¼ˆå³ Proximal Policy Optimizationï¼‰æ˜¯ä¸€ç§æœ€å…ˆè¿›çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ‚¨å°†åœ¨æœ¬è¯¾ç¨‹ä¸­å­¦ä¹ åˆ°](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#example%5D)ã€‚

PPO æ˜¯ä»¥ä¸‹å†…å®¹çš„ç»„åˆï¼š

+   *åŸºäºä»·å€¼çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•*ï¼šå­¦ä¹ ä¸€ä¸ªåŠ¨ä½œ-ä»·å€¼å‡½æ•°ï¼Œè¯¥å‡½æ•°å°†å‘Šè¯‰æˆ‘ä»¬**åœ¨ç»™å®šçŠ¶æ€å’ŒåŠ¨ä½œçš„æƒ…å†µä¸‹é‡‡å–çš„æœ€æœ‰ä»·å€¼çš„åŠ¨ä½œ**ã€‚

+   *åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•*ï¼šå­¦ä¹ ä¸€ä¸ªå°†**ä¸ºæˆ‘ä»¬æä¾›åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒ**çš„ç­–ç•¥ã€‚

ç¨³å®šåŸºçº¿ 3 å¾ˆå®¹æ˜“è®¾ç½®ï¼š

1ï¸âƒ£ æ‚¨**åˆ›å»ºæ‚¨çš„ç¯å¢ƒ**ï¼ˆåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­å·²ç»å®Œæˆï¼‰

2ï¸âƒ£ æ‚¨å®šä¹‰æ‚¨æƒ³è¦ä½¿ç”¨çš„**æ¨¡å‹å¹¶å®ä¾‹åŒ–æ­¤æ¨¡å‹** `model = PPO("MlpPolicy")`

3ï¸âƒ£ æ‚¨**è®­ç»ƒä»£ç†**ä½¿ç”¨ `model.learn` å¹¶å®šä¹‰è®­ç»ƒæ­¥æ•°

```py
# Create environment
env = gym.make('LunarLander-v2')

# Instantiate the agent
model = PPO('MlpPolicy', env, verbose=1)
# Train the agent
model.learn(total_timesteps=int(2e5))
```

```py
# TODO: Define a PPO MlpPolicy architecture
# We use MultiLayerPerceptron (MLPPolicy) because the input is a vector,
# if we had frames as input we would use CnnPolicy
model =
```

#### è§£å†³æ–¹æ¡ˆ

```py
# SOLUTION
# We added some parameters to accelerate the training
model = PPO(
    policy="MlpPolicy",
    env=env,
    n_steps=1024,
    batch_size=64,
    n_epochs=4,
    gamma=0.999,
    gae_lambda=0.98,
    ent_coef=0.01,
    verbose=1,
)
```

## è®­ç»ƒ PPO ä»£ç† ğŸƒ

+   è®©æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„ä»£ç†è®­ç»ƒ 1,000,000 ä¸ªæ—¶é—´æ­¥ï¼Œä¸è¦å¿˜è®°åœ¨ Colab ä¸Šä½¿ç”¨ GPUã€‚è¿™å°†å¤§çº¦éœ€è¦~20 åˆ†é’Ÿï¼Œä½†å¦‚æœæ‚¨åªæƒ³å°è¯•ä¸€ä¸‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ›´å°‘çš„æ—¶é—´æ­¥æ•°ã€‚

+   åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼‘æ¯ä¸€ä¸‹ï¼Œæ‚¨å€¼å¾—æ‹¥æœ‰ ğŸ¤—

```py
# TODO: Train it for 1,000,000 timesteps

# TODO: Specify file name for model and save the model to file
model_name = "ppo-LunarLander-v2"
```

#### è§£å†³æ–¹æ¡ˆ

```py
# SOLUTION
# Train it for 1,000,000 timesteps
model.learn(total_timesteps=1000000)
# Save the model
model_name = "ppo-LunarLander-v2"
model.save(model_name)
```

## è¯„ä¼°ä»£ç† ğŸ“ˆ

+   è®°å¾—å°†ç¯å¢ƒåŒ…è£…åœ¨[ç›‘è§†å™¨](https://stable-baselines3.readthedocs.io/en/master/common/monitor.html)ä¸­ã€‚

+   ç°åœ¨æˆ‘ä»¬çš„æœˆçƒç€é™†å™¨ä»£ç†å·²ç»è®­ç»ƒå¥½äº† ğŸš€ï¼Œæˆ‘ä»¬éœ€è¦**æ£€æŸ¥å…¶æ€§èƒ½**ã€‚

+   Stable-Baselines3 æä¾›äº†ä¸€ä¸ªæ–¹æ³•æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼š`evaluate_policy`ã€‚

+   è¦å¡«å†™è¯¥éƒ¨åˆ†ï¼Œæ‚¨éœ€è¦[æŸ¥çœ‹æ–‡æ¡£](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#basic-usage-training-saving-loading)

+   åœ¨ä¸‹ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°**å¦‚ä½•è‡ªåŠ¨è¯„ä¼°å’Œåˆ†äº«æ‚¨çš„ä»£ç†ä»¥å‚åŠ æ’è¡Œæ¦œæ¯”èµ›ï¼Œä½†ç°åœ¨è®©æˆ‘ä»¬è‡ªå·±æ¥åš**

ğŸ’¡ å½“æ‚¨è¯„ä¼°æ‚¨çš„ä»£ç†æ—¶ï¼Œæ‚¨ä¸åº”è¯¥ä½¿ç”¨è®­ç»ƒç¯å¢ƒï¼Œè€Œæ˜¯åˆ›å»ºä¸€ä¸ªè¯„ä¼°ç¯å¢ƒã€‚

```py
# TODO: Evaluate the agent
# Create a new environment for evaluation
eval_env =

# Evaluate the model with 10 evaluation episodes and deterministic=True
mean_reward, std_reward = 

# Print the results
```

#### è§£å†³æ–¹æ¡ˆ

```py
# @title
eval_env = Monitor(gym.make("LunarLander-v2"))
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")
```

+   åœ¨æˆ‘çš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒ 1 ç™¾ä¸‡æ­¥åï¼Œæˆ‘å¾—åˆ°çš„å¹³å‡å¥–åŠ±æ˜¯`200.20 +/- 20.80`ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„æœˆçƒç€é™†å™¨ä»£ç†å·²ç»å‡†å¤‡å¥½åœ¨æœˆçƒä¸Šç€é™† ğŸŒ›ğŸ¥³ã€‚

## åœ¨ Hub ä¸Šå‘å¸ƒæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ ğŸ”¥

ç°åœ¨æˆ‘ä»¬çœ‹åˆ°åœ¨è®­ç»ƒåå–å¾—äº†è‰¯å¥½çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œä»£ç å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹å‘å¸ƒåˆ° hub ğŸ¤—ã€‚

ğŸ“š åº“çš„æ–‡æ¡£ ğŸ‘‰ [`github.com/huggingface/huggingface_sb3/tree/main#hugging-faceâ€”x-stable-baselines3-v20`](https://github.com/huggingface/huggingface_sb3/tree/main#hugging-face--x-stable-baselines3-v20)

è¿™æ˜¯ä¸€ä¸ªæ¨¡å‹å¡çš„ç¤ºä¾‹ï¼ˆå¸¦æœ‰å¤ªç©ºä¾µç•¥è€…ï¼‰ï¼š

é€šè¿‡ä½¿ç”¨`package_to_hub` **æ‚¨å¯ä»¥è¯„ä¼°ã€è®°å½•å›æ”¾ã€ç”Ÿæˆä»£ç†çš„æ¨¡å‹å¡å¹¶å°†å…¶æ¨é€åˆ° hub**ã€‚

è¿™æ ·ï¼š

+   æ‚¨å¯ä»¥**å±•ç¤ºæˆ‘ä»¬çš„å·¥ä½œ** ğŸ”¥

+   æ‚¨å¯ä»¥**å¯è§†åŒ–æ‚¨çš„ä»£ç†è¿›è¡Œæ¸¸æˆ** ğŸ‘€

+   æ‚¨å¯ä»¥**ä¸ç¤¾åŒºåˆ†äº«å…¶ä»–äººå¯ä»¥ä½¿ç”¨çš„ä»£ç†** ğŸ’¾

+   æ‚¨å¯ä»¥**è®¿é—®æ’è¡Œæ¦œ ğŸ† æŸ¥çœ‹æ‚¨çš„ä»£ç†ç›¸å¯¹äºåŒå­¦è¡¨ç°å¦‚ä½•** ğŸ‘‰ [`huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard`](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)

ä¸ºäº†èƒ½å¤Ÿä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ï¼Œè¿˜æœ‰ä¸‰ä¸ªæ­¥éª¤è¦éµå¾ªï¼š

1ï¸âƒ£ (å¦‚æœè¿˜æ²¡æœ‰) åœ¨ Hugging Face ä¸Šåˆ›å»ºä¸€ä¸ªå¸æˆ· â¡ [`huggingface.co/join`](https://huggingface.co/join)

2ï¸âƒ£ ç™»å½•ï¼Œç„¶åï¼Œæ‚¨éœ€è¦ä» Hugging Face ç½‘ç«™å­˜å‚¨æ‚¨çš„èº«ä»½éªŒè¯ä»¤ç‰Œã€‚

+   åˆ›å»ºä¸€ä¸ªæ–°çš„ä»¤ç‰Œ([`huggingface.co/settings/tokens`](https://huggingface.co/settings/tokens)) **å…·æœ‰å†™å…¥æƒé™**

![åˆ›å»º HF ä»¤ç‰Œ](img/d21a97c736edaab9119d2d1c1da9deac.png)

+   å¤åˆ¶ä»¤ç‰Œ

+   è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å¹¶ç²˜è´´ä»¤ç‰Œ

```py
notebook_login()
!git config --global credential.helper store
```

å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨ Google Colab æˆ– Jupyter Notebookï¼Œæ‚¨éœ€è¦ä½¿ç”¨è¿™ä¸ªå‘½ä»¤ï¼š`huggingface-cli login`

3ï¸âƒ£ ç°åœ¨æˆ‘ä»¬å‡†å¤‡ä½¿ç”¨`package_to_hub()`å‡½æ•°å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„ä»£ç†æ¨é€åˆ°ğŸ¤— Hub ğŸ”¥

è®©æˆ‘ä»¬å¡«å†™`package_to_hub`å‡½æ•°ï¼š

+   `model`ï¼šæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚

+   `model_name`ï¼šæˆ‘ä»¬åœ¨`model_save`ä¸­å®šä¹‰çš„è®­ç»ƒæ¨¡å‹çš„åç§°

+   `model_architecture`ï¼šæˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹æ¶æ„ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­æ˜¯ PPO

+   `env_id`ï¼šç¯å¢ƒçš„åç§°ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­æ˜¯`LunarLander-v2`

+   `eval_env`ï¼šåœ¨ eval_env ä¸­å®šä¹‰çš„è¯„ä¼°ç¯å¢ƒ

+   `repo_id`ï¼šå°†è¦åˆ›å»º/æ›´æ–°çš„ Hugging Face Hub å­˜å‚¨åº“çš„åç§°`(repo_id = {username}/{repo_name})`

ğŸ’¡ **ä¸€ä¸ªå¥½çš„åç§°æ˜¯`{username}/{model_architecture}-{env_id}`**

+   `commit_message`ï¼šæäº¤çš„æ¶ˆæ¯

```py
import gymnasium as gym
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env

from huggingface_sb3 import package_to_hub

## TODO: Define a repo_id
## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
repo_id = 

# TODO: Define the name of the environment
env_id = 

# Create the evaluation env and set the render_mode="rgb_array"
eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode="rgb_array")])

# TODO: Define the model architecture we used
model_architecture = ""

## TODO: Define the commit message
commit_message = ""

# method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hub
package_to_hub(model=model, # Our trained model
               model_name=model_name, # The name of our trained model 
               model_architecture=model_architecture, # The model architecture we used: in our case PPO
               env_id=env_id, # Name of the environment
               eval_env=eval_env, # Evaluation Environment
               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
               commit_message=commit_message)
```

#### è§£å†³æ–¹æ¡ˆ

```py
import gymnasium as gym

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env

from huggingface_sb3 import package_to_hub

# PLACE the variables you've just defined two cells above
# Define the name of the environment
env_id = "LunarLander-v2"

# TODO: Define the model architecture we used
model_architecture = "PPO"

## Define a repo_id
## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
## CHANGE WITH YOUR REPO ID
repo_id = "ThomasSimonini/ppo-LunarLander-v2"  # Change with your repo id, you can't push with mine ğŸ˜„

## Define the commit message
commit_message = "Upload PPO LunarLander-v2 trained agent"

# Create the evaluation env and set the render_mode="rgb_array"
eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode="rgb_array"))])

# PLACE the package_to_hub function you've just filled here
package_to_hub(
    model=model,  # Our trained model
    model_name=model_name,  # The name of our trained model
    model_architecture=model_architecture,  # The model architecture we used: in our case PPO
    env_id=env_id,  # Name of the environment
    eval_env=eval_env,  # Evaluation Environment
    repo_id=repo_id,  # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
    commit_message=commit_message,
)
```

æ­å–œ ğŸ¥³ æ‚¨åˆšåˆšè®­ç»ƒå¹¶ä¸Šä¼ äº†æ‚¨çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚ä¸Šé¢çš„è„šæœ¬åº”è¯¥æ˜¾ç¤ºäº†ä¸€ä¸ªæŒ‡å‘æ¨¡å‹å­˜å‚¨åº“çš„é“¾æ¥ï¼Œä¾‹å¦‚[`huggingface.co/osanseviero/test_sb3`](https://huggingface.co/osanseviero/test_sb3)ã€‚å½“æ‚¨è®¿é—®æ­¤é“¾æ¥æ—¶ï¼Œæ‚¨å¯ä»¥ï¼š

+   åœ¨å³ä¾§æŸ¥çœ‹ä»£ç†çš„è§†é¢‘é¢„è§ˆã€‚

+   ç‚¹å‡»â€œæ–‡ä»¶å’Œç‰ˆæœ¬â€ä»¥æŸ¥çœ‹å­˜å‚¨åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚

+   ç‚¹å‡»â€œåœ¨ stable-baselines3 ä¸­ä½¿ç”¨â€ä»¥è·å–æ˜¾ç¤ºå¦‚ä½•åŠ è½½æ¨¡å‹çš„ä»£ç ç‰‡æ®µã€‚

+   ä¸€ä¸ªæ¨¡å‹å¡ç‰‡ï¼ˆ`README.md`æ–‡ä»¶ï¼‰ï¼Œå…¶ä¸­æè¿°äº†æ¨¡å‹

åœ¨å¹•åï¼ŒHub ä½¿ç”¨åŸºäº git çš„å­˜å‚¨åº“ï¼ˆå¦‚æœä½ ä¸çŸ¥é“ git æ˜¯ä»€ä¹ˆï¼Œä¸ç”¨æ‹…å¿ƒï¼‰ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥åœ¨å®éªŒå’Œæ”¹è¿›ä»£ç†æ—¶æ›´æ–°æ¨¡å‹çš„æ–°ç‰ˆæœ¬ã€‚

ä½¿ç”¨æ’è¡Œæ¦œæ¯”è¾ƒä½ çš„ LunarLander-v2 çš„ç»“æœä¸ä½ çš„åŒå­¦ğŸ†ğŸ‘‰[`huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard`](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)

## ä» Hub åŠ è½½ä¿å­˜çš„ LunarLander æ¨¡å‹ğŸ¤—

æ„Ÿè°¢[ironbar](https://github.com/ironbar)çš„è´¡çŒ®ã€‚

ä» Hub åŠ è½½ä¿å­˜çš„æ¨¡å‹éå¸¸å®¹æ˜“ã€‚

ä½ å¯ä»¥å»[`huggingface.co/models?library=stable-baselines3`](https://huggingface.co/models?library=stable-baselines3)æŸ¥çœ‹æ‰€æœ‰ Stable-baselines3 ä¿å­˜æ¨¡å‹çš„åˆ—è¡¨ã€‚

1.  é€‰æ‹©ä¸€ä¸ªå¹¶å¤åˆ¶å…¶ repo_id

![Copy-id](img/f3fbf7e375946adf2b0df2b8be31be10.png)

1.  ç„¶åæˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ load_from_hubï¼š

+   repo_id

+   æ–‡ä»¶åï¼šå­˜å‚¨åº“ä¸­ä¿å­˜çš„æ¨¡å‹åŠå…¶æ‰©å±•åï¼ˆ*.zipï¼‰

å› ä¸ºæˆ‘ä» Hub ä¸‹è½½çš„æ¨¡å‹æ˜¯ä½¿ç”¨ Gymï¼ˆGymnasium çš„å‰èº«ï¼‰è®­ç»ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å®‰è£… shimmyï¼Œè¿™æ˜¯ä¸€ä¸ª API è½¬æ¢å·¥å…·ï¼Œå°†å¸®åŠ©æˆ‘ä»¬æ­£ç¡®è¿è¡Œç¯å¢ƒã€‚

Shimmy æ–‡æ¡£ï¼š[`github.com/Farama-Foundation/Shimmy`](https://github.com/Farama-Foundation/Shimmy)

```py
!pip install shimmy
```

```py
from huggingface_sb3 import load_from_hub

repo_id = "Classroom-workshop/assignment2-omar"  # The repo_id
filename = "ppo-LunarLander-v2.zip"  # The model filename.zip

# When the model was trained on Python 3.8 the pickle protocol is 5
# But Python 3.6, 3.7 use protocol 4
# In order to get compatibility we need to:
# 1\. Install pickle5 (we done it at the beginning of the colab)
# 2\. Create a custom empty object we pass as parameter to PPO.load()
custom_objects = {
    "learning_rate": 0.0,
    "lr_schedule": lambda _: 0.0,
    "clip_range": lambda _: 0.0,
}

checkpoint = load_from_hub(repo_id, filename)
model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)
```

è®©æˆ‘ä»¬è¯„ä¼°è¿™ä¸ªä»£ç†ï¼š

```py
# @title
eval_env = Monitor(gym.make("LunarLander-v2"))
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")
```

## ä¸€äº›é¢å¤–çš„æŒ‘æˆ˜ğŸ†

å­¦ä¹ çš„æœ€ä½³æ–¹å¼**æ˜¯è‡ªå·±å°è¯•**ï¼æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå½“å‰çš„ä»£ç†è¡¨ç°ä¸ä½³ã€‚ä½œä¸ºç¬¬ä¸€ä¸ªå»ºè®®ï¼Œä½ å¯ä»¥è®­ç»ƒæ›´å¤šæ­¥éª¤ã€‚é€šè¿‡ 100 ä¸‡æ­¥ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€äº›å¾ˆå¥½çš„ç»“æœï¼

åœ¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ä¸­ï¼Œä½ ä¼šæ‰¾åˆ°ä½ çš„ä»£ç†ã€‚ä½ èƒ½è¾¾åˆ°æ¦œé¦–å—ï¼Ÿ

ä»¥ä¸‹æ˜¯ä¸€äº›å®ç°çš„æƒ³æ³•ï¼š

+   è®­ç»ƒæ›´å¤šæ­¥éª¤

+   å°è¯•ä¸åŒçš„`PPO`è¶…å‚æ•°ã€‚ä½ å¯ä»¥åœ¨[`stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters`](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters)çœ‹åˆ°å®ƒä»¬ã€‚

+   æŸ¥çœ‹[Stable-Baselines3 æ–‡æ¡£](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)ï¼Œå°è¯•å¦ä¸€ä¸ªæ¨¡å‹ï¼Œå¦‚ DQNã€‚

+   **å°†ä½ çš„æ–°è®­ç»ƒæ¨¡å‹æ¨é€åˆ° Hub** ğŸ”¥

**ä½¿ç”¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ä¸ä½ çš„åŒå­¦æ¯”è¾ƒä½ çš„ LunarLander-v2 çš„ç»“æœ** ğŸ†

å¯¹ä½ æ¥è¯´ï¼Œç™»æœˆå¤ªæ— èŠäº†å—ï¼Ÿå°è¯•**æ”¹å˜ç¯å¢ƒ**ï¼Œä¸ºä»€ä¹ˆä¸ä½¿ç”¨ MountainCar-v0ï¼ŒCartPole-v1 æˆ– CarRacing-v0ï¼ŸæŸ¥çœ‹å®ƒä»¬çš„å·¥ä½œæ–¹å¼[ä½¿ç”¨ gym æ–‡æ¡£](https://www.gymlibrary.dev/)å¹¶äº«å—ä¹è¶£ğŸ‰ã€‚

* * *

æ­å–œä½ å®Œæˆäº†è¿™ä¸€ç« ï¼è¿™æ˜¯æœ€å¤§çš„ä¸€ç« ï¼Œ**åŒ…å«äº†å¾ˆå¤šä¿¡æ¯ã€‚**

å¦‚æœä½ ä»ç„¶æ„Ÿåˆ°å›°æƒ‘ï¼Œè¿™äº›å…ƒç´ å¯¹æˆ‘å’Œæ‰€æœ‰å­¦ä¹  RL çš„äººæ¥è¯´éƒ½æ˜¯æ­£å¸¸çš„ï¼

åœ¨ç»§ç»­ä¹‹å‰èŠ±æ—¶é—´çœŸæ­£**æŒæ¡ææ–™å¹¶å°è¯•é¢å¤–çš„æŒ‘æˆ˜**ã€‚æŒæ¡è¿™äº›å…ƒç´ å¹¶å»ºç«‹åšå®çš„åŸºç¡€æ˜¯å¾ˆé‡è¦çš„ã€‚

åœ¨è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ›´æ·±å…¥åœ°æ¢è®¨è¿™äº›æ¦‚å¿µï¼Œä½†**æœ€å¥½ç°åœ¨å°±å¯¹å®ƒä»¬æœ‰ä¸€ä¸ªè‰¯å¥½çš„ç†è§£ï¼Œç„¶åå†æ·±å…¥ä¸‹ä¸€ç« èŠ‚ã€‚**

ä¸‹æ¬¡ï¼Œåœ¨å¥–åŠ±å•å…ƒ 1 ä¸­ï¼Œä½ å°†è®­ç»ƒ Huggy the Dog å»æ¥æ£å­ã€‚

![Huggy](img/3fff0107ad50440533e843a81416a46f.png)

## ç»§ç»­å­¦ä¹ ï¼Œä¿æŒæ£’æ£’çš„ğŸ¤—
