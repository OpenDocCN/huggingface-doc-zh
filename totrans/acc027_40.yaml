- en: The Command Line
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‘½ä»¤è¡Œ
- en: 'Original text: [https://huggingface.co/docs/accelerate/package_reference/cli](https://huggingface.co/docs/accelerate/package_reference/cli)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/accelerate/package_reference/cli](https://huggingface.co/docs/accelerate/package_reference/cli)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Below is a list of all the available commands ğŸ¤— Accelerate with their parameters
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æ‰€æœ‰å¯ç”¨å‘½ä»¤ğŸ¤—åŠ é€ŸåŠå…¶å‚æ•°çš„åˆ—è¡¨
- en: accelerate config
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ é€Ÿé…ç½®
- en: '**Command**:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‘½ä»¤**:'
- en: '`accelerate config` or `accelerate-config`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate config` æˆ– `accelerate-config`'
- en: Launches a series of prompts to create and save a `default_config.yml` configuration
    file for your training system. Should always be ran first on your machine.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¯åŠ¨ä¸€ç³»åˆ—æç¤ºï¼Œåˆ›å»ºå¹¶ä¿å­˜ä¸€ä¸ª`default_config.yml`é…ç½®æ–‡ä»¶ï¼Œç”¨äºæ‚¨çš„è®­ç»ƒç³»ç»Ÿã€‚åº”å§‹ç»ˆé¦–å…ˆåœ¨æ‚¨çš„æœºå™¨ä¸Šè¿è¡Œã€‚
- en: '**Usage**:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**:'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Optional Arguments**:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**:'
- en: '`--config_file CONFIG_FILE` (`str`) â€” The path to use to store the config file.
    Will default to a file named default_config.yaml in the cache location, which
    is the content of the environment `HF_HOME` suffixed with â€˜accelerateâ€™, or if
    you donâ€™t have such an environment variable, your cache directory (`~/.cache`
    or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file CONFIG_FILE` (`str`) â€” ç”¨äºå­˜å‚¨é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸ºç¼“å­˜ä½ç½®ä¸­åä¸ºdefault_config.yamlçš„æ–‡ä»¶ï¼Œè¯¥ä½ç½®æ˜¯ç¯å¢ƒå˜é‡`HF_HOME`çš„å†…å®¹åç¼€ä¸ºâ€˜accelerateâ€™ï¼Œæˆ–è€…å¦‚æœæ‚¨æ²¡æœ‰è¿™æ ·çš„ç¯å¢ƒå˜é‡ï¼Œåˆ™ä¸ºæ‚¨çš„ç¼“å­˜ç›®å½•(`~/.cache`æˆ–`XDG_CACHE_HOME`çš„å†…å®¹)åç¼€ä¸º`huggingface`ã€‚'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º'
- en: accelerate config default
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ é€Ÿé…ç½®é»˜è®¤
- en: '**Command**:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‘½ä»¤**:'
- en: '`accelerate config default` or `accelerate-config default`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate config default` æˆ– `accelerate-config default`'
- en: Create a default config file for Accelerate with only a few flags set.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºåŠ é€Ÿåˆ›å»ºä¸€ä¸ªé»˜è®¤é…ç½®æ–‡ä»¶ï¼Œåªè®¾ç½®äº†å‡ ä¸ªæ ‡å¿—ã€‚
- en: '**Usage**:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**:'
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Optional Arguments**:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**:'
- en: '`--config_file CONFIG_FILE` (`str`) â€” The path to use to store the config file.
    Will default to a file named default_config.yaml in the cache location, which
    is the content of the environment `HF_HOME` suffixed with â€˜accelerateâ€™, or if
    you donâ€™t have such an environment variable, your cache directory (`~/.cache`
    or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file CONFIG_FILE` (`str`) â€” ç”¨äºå­˜å‚¨é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸ºç¼“å­˜ä½ç½®ä¸­åä¸ºdefault_config.yamlçš„æ–‡ä»¶ï¼Œè¯¥ä½ç½®æ˜¯ç¯å¢ƒå˜é‡`HF_HOME`çš„å†…å®¹åç¼€ä¸ºâ€˜accelerateâ€™ï¼Œæˆ–è€…å¦‚æœæ‚¨æ²¡æœ‰è¿™æ ·çš„ç¯å¢ƒå˜é‡ï¼Œåˆ™ä¸ºæ‚¨çš„ç¼“å­˜ç›®å½•(`~/.cache`æˆ–`XDG_CACHE_HOME`çš„å†…å®¹)åç¼€ä¸º`huggingface`ã€‚'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º'
- en: '`--mixed_precision {no,fp16,bf16}` (`str`) â€” Whether or not to use mixed precision
    training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only
    supported on Nvidia Ampere GPUs and PyTorch 1.10 or later.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--mixed_precision {no,fp16,bf16}` (`str`) â€” æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒã€‚é€‰æ‹©åœ¨FP16å’ŒBF16ï¼ˆbfloat16ï¼‰è®­ç»ƒä¹‹é—´ã€‚BF16è®­ç»ƒä»…å—Nvidia
    Ampere GPUå’ŒPyTorch 1.10æˆ–æ›´é«˜ç‰ˆæœ¬æ”¯æŒã€‚'
- en: accelerate config update
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ é€Ÿé…ç½®æ›´æ–°
- en: '**Command**:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‘½ä»¤**:'
- en: '`accelerate config update` or `accelerate-config update`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate config update` æˆ– `accelerate-config update`'
- en: Update an existing config file with the latest defaults while maintaining the
    old configuration.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æœ€æ–°é»˜è®¤å€¼æ›´æ–°ç°æœ‰é…ç½®æ–‡ä»¶ï¼ŒåŒæ—¶ä¿ç•™æ—§é…ç½®ã€‚
- en: '**Usage**:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**:'
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Optional Arguments**:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**:'
- en: '`--config_file CONFIG_FILE` (`str`) â€” The path to the config file to update.
    Will default to a file named default_config.yaml in the cache location, which
    is the content of the environment `HF_HOME` suffixed with â€˜accelerateâ€™, or if
    you donâ€™t have such an environment variable, your cache directory (`~/.cache`
    or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file CONFIG_FILE` (`str`) â€” è¦æ›´æ–°çš„é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸ºç¼“å­˜ä½ç½®ä¸­åä¸ºdefault_config.yamlçš„æ–‡ä»¶ï¼Œè¯¥ä½ç½®æ˜¯ç¯å¢ƒå˜é‡`HF_HOME`çš„å†…å®¹åç¼€ä¸ºâ€˜accelerateâ€™ï¼Œæˆ–è€…å¦‚æœæ‚¨æ²¡æœ‰è¿™æ ·çš„ç¯å¢ƒå˜é‡ï¼Œåˆ™ä¸ºæ‚¨çš„ç¼“å­˜ç›®å½•(`~/.cache`æˆ–`XDG_CACHE_HOME`çš„å†…å®¹)åç¼€ä¸º`huggingface`ã€‚'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º'
- en: accelerate env
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ é€Ÿç¯å¢ƒ
- en: '**Command**:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‘½ä»¤**:'
- en: '`accelerate env` or `accelerate-env` or `python -m accelerate.commands.env`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate env` æˆ– `accelerate-env` æˆ– `python -m accelerate.commands.env`'
- en: Lists the contents of the passed ğŸ¤— Accelerate configuration file. Should always
    be used when opening an issue on the [GitHub repository](https://github.com/huggingface/accelerate).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—å‡ºä¼ é€’çš„ğŸ¤—åŠ é€Ÿé…ç½®æ–‡ä»¶çš„å†…å®¹ã€‚åœ¨æ‰“å¼€[GitHubå­˜å‚¨åº“](https://github.com/huggingface/accelerate)ä¸Šçš„é—®é¢˜æ—¶åº”å§‹ç»ˆä½¿ç”¨ã€‚
- en: '**Usage**:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**:'
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Optional Arguments**:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**:'
- en: '`--config_file CONFIG_FILE` (`str`) â€” The path to use to store the config file.
    Will default to a file named default_config.yaml in the cache location, which
    is the content of the environment `HF_HOME` suffixed with â€˜accelerateâ€™, or if
    you donâ€™t have such an environment variable, your cache directory (`~/.cache`
    or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file CONFIG_FILE` (`str`) â€” ç”¨äºå­˜å‚¨é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸ºç¼“å­˜ä½ç½®ä¸­åä¸ºdefault_config.yamlçš„æ–‡ä»¶ï¼Œè¯¥ä½ç½®æ˜¯ç¯å¢ƒå˜é‡`HF_HOME`çš„å†…å®¹åç¼€ä¸ºâ€˜accelerateâ€™ï¼Œæˆ–è€…å¦‚æœæ‚¨æ²¡æœ‰è¿™æ ·çš„ç¯å¢ƒå˜é‡ï¼Œåˆ™ä¸ºæ‚¨çš„ç¼“å­˜ç›®å½•(`~/.cache`æˆ–`XDG_CACHE_HOME`çš„å†…å®¹)åç¼€ä¸º`huggingface`ã€‚'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º'
- en: accelerate launch
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ é€Ÿå¯åŠ¨
- en: '**Command**:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‘½ä»¤**:'
- en: '`accelerate launch` or `accelerate-launch` or `python -m accelerate.commands.launch`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate launch` æˆ– `accelerate-launch` æˆ– `python -m accelerate.commands.launch`'
- en: Launches a specified script on a distributed system with the right parameters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸Šå¯åŠ¨æŒ‡å®šçš„è„šæœ¬ï¼Œä½¿ç”¨æ­£ç¡®çš„å‚æ•°ã€‚
- en: '**Usage**:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**:'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Positional Arguments**:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½ç½®å‚æ•°**:'
- en: '`{training_script}` â€” The full path to the script to be launched in parallel'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{training_script}` â€” è¦å¹¶è¡Œå¯åŠ¨çš„è„šæœ¬çš„å®Œæ•´è·¯å¾„'
- en: '`--{training_script-argument-1}` â€” Arguments of the training script'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--{training_script-argument-1}` â€” è®­ç»ƒè„šæœ¬çš„å‚æ•°'
- en: '**Optional Arguments**:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**:'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º'
- en: '`--config_file CONFIG_FILE` (`str`)â€” The config file to use for the default
    values in the launching script.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file CONFIG_FILE` (`str`)â€” ç”¨äºå¯åŠ¨è„šæœ¬ä¸­é»˜è®¤å€¼çš„é…ç½®æ–‡ä»¶ã€‚'
- en: '`-m`, `--module` (`bool`) â€” Change each process to interpret the launch script
    as a Python module, executing with the same behavior as â€˜python -mâ€™.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-m`, `--module` (`bool`) â€” å°†æ¯ä¸ªè¿›ç¨‹æ›´æ”¹ä¸ºå°†å¯åŠ¨è„šæœ¬è§£é‡Šä¸ºPythonæ¨¡å—ï¼Œä»¥ä¸â€˜python -mâ€™ç›¸åŒçš„è¡Œä¸ºæ‰§è¡Œã€‚'
- en: '`--no_python` (`bool`) â€” Skip prepending the training script with â€˜pythonâ€™
    - just execute it directly. Useful when the script is not a Python script.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--no_python` (`bool`) â€” è·³è¿‡åœ¨è®­ç»ƒè„šæœ¬å‰æ·»åŠ â€œpythonâ€ - ç›´æ¥æ‰§è¡Œå®ƒã€‚å½“è„šæœ¬ä¸æ˜¯Pythonè„šæœ¬æ—¶å¾ˆæœ‰ç”¨ã€‚'
- en: '`--debug` (`bool`) â€” Whether to print out the torch.distributed stack trace
    when something fails.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--debug` (`bool`) â€” å½“æŸäº›å†…å®¹å¤±è´¥æ—¶æ˜¯å¦æ‰“å°å‡ºtorch.distributedå †æ ˆè·Ÿè¸ªã€‚'
- en: '`-q`, `--quiet` (`bool`) â€” Silence subprocess errors from the launch stack
    trace to only show the relevant tracebacks. (Only applicable to DeepSpeed and
    single-process configurations).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-q`, `--quiet` (`bool`) â€” ä»å¯åŠ¨å †æ ˆè·Ÿè¸ªä¸­æ¶ˆé™¤å­è¿›ç¨‹é”™è¯¯ï¼Œä»…æ˜¾ç¤ºç›¸å…³çš„è·Ÿè¸ªã€‚ ï¼ˆä»…é€‚ç”¨äºDeepSpeedå’Œå•è¿›ç¨‹é…ç½®ï¼‰ã€‚'
- en: The rest of these arguments are configured through `accelerate config` and are
    read in from the specified `--config_file` (or default configuration) for their
    values. They can also be passed in manually.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä½™è¿™äº›å‚æ•°é€šè¿‡æŒ‡å®šçš„`--config_file`ï¼ˆæˆ–é»˜è®¤é…ç½®ï¼‰è¿›è¡Œé…ç½®ï¼Œå…¶å€¼ä»ä¸­è¯»å–ã€‚ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¼ é€’ã€‚
- en: '**Hardware Selection Arguments**:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç¡¬ä»¶é€‰æ‹©å‚æ•°**ï¼š'
- en: '`--cpu` (`bool`) â€” Whether or not to force the training on the CPU.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--cpu` (`bool`) â€” æ˜¯å¦å¼ºåˆ¶åœ¨CPUä¸Šè¿›è¡Œè®­ç»ƒã€‚'
- en: '`--multi_gpu` (`bool`) â€” Whether or not this should launch a distributed GPU
    training.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--multi_gpu` (`bool`) â€” æ˜¯å¦åº”å¯åŠ¨åˆ†å¸ƒå¼GPUè®­ç»ƒã€‚'
- en: '`--tpu` (`bool`) â€” Whether or not this should launch a TPU training.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--tpu` (`bool`) â€” æ˜¯å¦åº”å¯åŠ¨TPUè®­ç»ƒã€‚'
- en: '`--ipex` (`bool`) â€” Whether or not this should launch an Intel Pytorch Extension
    (IPEX) training.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--ipex` (`bool`) â€” æ˜¯å¦åº”å¯åŠ¨Intel Pytorch Extensionï¼ˆIPEXï¼‰è®­ç»ƒã€‚'
- en: '**Resource Selection Arguments**:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æºé€‰æ‹©å‚æ•°**ï¼š'
- en: The following arguments are useful for fine-tuning how available hardware should
    be used
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°å¯¹äºè°ƒæ•´å¯ç”¨ç¡¬ä»¶çš„ä½¿ç”¨æ–¹å¼å¾ˆæœ‰ç”¨
- en: '`--mixed_precision {no,fp16,bf16}` (`str`) â€” Whether or not to use mixed precision
    training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only
    supported on Nvidia Ampere GPUs and PyTorch 1.10 or later.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--mixed_precision {no,fp16,bf16}` (`str`) â€” æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒã€‚é€‰æ‹©åœ¨FP16å’ŒBF16ï¼ˆbfloat16ï¼‰è®­ç»ƒä¹‹é—´ã€‚BF16è®­ç»ƒä»…åœ¨Nvidia
    Ampere GPUå’ŒPyTorch 1.10æˆ–æ›´é«˜ç‰ˆæœ¬ä¸Šå—æ”¯æŒã€‚'
- en: '`--num_processes NUM_PROCESSES` (`int`) â€” The total number of processes to
    be launched in parallel.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_processes NUM_PROCESSES` (`int`) â€” è¦å¹¶è¡Œå¯åŠ¨çš„è¿›ç¨‹æ€»æ•°ã€‚'
- en: '`--num_machines NUM_MACHINES` (`int`) â€” The total number of machines used in
    this training.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_machines NUM_MACHINES` (`int`) â€” åœ¨æ­¤è®­ç»ƒä¸­ä½¿ç”¨çš„æœºå™¨æ€»æ•°ã€‚'
- en: '`--num_cpu_threads_per_process NUM_CPU_THREADS_PER_PROCESS` (`int`) â€” The number
    of CPU threads per process. Can be tuned for optimal performance.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_cpu_threads_per_process NUM_CPU_THREADS_PER_PROCESS` (`int`) â€” æ¯ä¸ªè¿›ç¨‹çš„CPUçº¿ç¨‹æ•°ã€‚å¯ä»¥è°ƒæ•´ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚'
- en: '**Training Paradigm Arguments**:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒèŒƒå¼å‚æ•°**ï¼š'
- en: The following arguments are useful for selecting which training paradigm to
    use.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°å¯¹äºé€‰æ‹©è¦ä½¿ç”¨çš„è®­ç»ƒèŒƒå¼å¾ˆæœ‰ç”¨ã€‚
- en: '`--use_deepspeed` (`bool`) â€” Whether or not to use DeepSpeed for training.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--use_deepspeed` (`bool`) â€” æ˜¯å¦ä½¿ç”¨DeepSpeedè¿›è¡Œè®­ç»ƒã€‚'
- en: '`--use_fsdp` (`bool`) â€” Whether or not to use FullyShardedDataParallel for
    training.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--use_fsdp` (`bool`) â€” æ˜¯å¦ä½¿ç”¨FullyShardedDataParallelè¿›è¡Œè®­ç»ƒã€‚'
- en: '`--use_megatron_lm` (`bool`) â€” Whether or not to use Megatron-LM for training.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--use_megatron_lm` (`bool`) â€” æ˜¯å¦ä½¿ç”¨Megatron-LMè¿›è¡Œè®­ç»ƒã€‚'
- en: '`--use_xpu` (`bool`) â€” Whether to use IPEX plugin to speed up training on XPU
    specifically.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--use_xpu` (`bool`) â€” æ˜¯å¦ä½¿ç”¨IPEXæ’ä»¶æ¥åŠ é€ŸXPUä¸Šçš„è®­ç»ƒã€‚'
- en: '**Distributed GPU Arguments**:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**åˆ†å¸ƒå¼GPUå‚æ•°**ï¼š'
- en: 'The following arguments are only useful when `multi_gpu` is passed or multi-gpu
    training is configured through `accelerate config`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä»…åœ¨ä¼ é€’`multi_gpu`æˆ–é€šè¿‡`accelerate config`é…ç½®å¤šGPUè®­ç»ƒæ—¶æœ‰ç”¨ï¼š
- en: '`--gpu_ids` (`str`) â€” What GPUs (by id) should be used for training on this
    machine as a comma-seperated list'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--gpu_ids` (`str`) â€” åº”è¯¥åœ¨æ­¤æœºå™¨ä¸Šç”¨äºè®­ç»ƒçš„GPUï¼ˆæŒ‰idï¼‰ä½œä¸ºé€—å·åˆ†éš”çš„åˆ—è¡¨'
- en: '`--same_network` (`bool`) â€” Whether all machines used for multinode training
    exist on the same local network.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--same_network` (`bool`) â€” ç”¨äºå¤šèŠ‚ç‚¹è®­ç»ƒçš„æ‰€æœ‰æœºå™¨æ˜¯å¦å­˜åœ¨äºåŒä¸€æœ¬åœ°ç½‘ç»œä¸Šã€‚'
- en: '`--machine_rank MACHINE_RANK` (`int`) â€” The rank of the machine on which this
    script is launched.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--machine_rank MACHINE_RANK` (`int`) â€” å¯åŠ¨æ­¤è„šæœ¬çš„æœºå™¨çš„ç­‰çº§ã€‚'
- en: '`--main_process_ip MAIN_PROCESS_IP` (`str`) â€” The IP address of the machine
    of rank 0.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--main_process_ip MAIN_PROCESS_IP` (`str`) â€” æ’å0çš„æœºå™¨çš„IPåœ°å€ã€‚'
- en: '`--main_process_port MAIN_PROCESS_PORT` (`int`) â€” The port to use to communicate
    with the machine of rank 0.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--main_process_port MAIN_PROCESS_PORT` (`int`) â€” ç”¨äºä¸æ’å0çš„æœºå™¨é€šä¿¡çš„ç«¯å£ã€‚'
- en: '`--rdzv_backend` (`str`) â€” The rendezvous method to use, such as â€œstaticâ€ or
    â€œc10dâ€'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rdzv_backend` (`str`) â€” è¦ä½¿ç”¨çš„ä¼šé¢æ–¹æ³•ï¼Œä¾‹å¦‚â€œstaticâ€æˆ–â€œc10dâ€'
- en: '`--rdzv_conf` (`str`) â€” Additional rendezvous configuration (<key1>=<value1>,<key2>=<value2>,â€¦).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rdzv_conf` (`str`) â€” é™„åŠ çš„ä¼šé¢é…ç½®ï¼ˆ<key1>=<value1>,<key2>=<value2>,â€¦ï¼‰ã€‚'
- en: '`--max_restarts` (`int`) â€” Maximum number of worker group restarts before failing.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--max_restarts` (`int`) â€” åœ¨å¤±è´¥ä¹‹å‰çš„æœ€å¤§å·¥ä½œç»„é‡å¯æ¬¡æ•°ã€‚'
- en: '`--monitor_interval` (`float`) â€” Interval, in seconds, to monitor the state
    of workers.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--monitor_interval` (`float`) â€” ç›‘è§†å·¥ä½œè€…çŠ¶æ€çš„é—´éš”ï¼Œä»¥ç§’ä¸ºå•ä½ã€‚'
- en: '**TPU Arguments**:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**TPUå‚æ•°**ï¼š'
- en: 'The following arguments are only useful when `tpu` is passed or TPU training
    is configured through `accelerate config`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä»…åœ¨ä¼ é€’`tpu`æˆ–é€šè¿‡`accelerate config`é…ç½®TPUè®­ç»ƒæ—¶æœ‰ç”¨ï¼š
- en: '`--main_training_function MAIN_TRAINING_FUNCTION` (`str`) â€” The name of the
    main function to be executed in your script.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--main_training_function MAIN_TRAINING_FUNCTION` (`str`) â€” è¦åœ¨è„šæœ¬ä¸­æ‰§è¡Œçš„ä¸»å‡½æ•°çš„åç§°ã€‚'
- en: '`--downcast_bf16` (`bool`) â€” Whether when using bf16 precision on TPUs if both
    float and double tensors are cast to bfloat16 or if double tensors remain as float32.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--downcast_bf16` (`bool`) â€” åœ¨TPUä¸Šä½¿ç”¨bf16ç²¾åº¦æ—¶ï¼Œæ˜¯å¦å°†æµ®ç‚¹å’ŒåŒç²¾åº¦å¼ é‡éƒ½è½¬æ¢ä¸ºbfloat16ï¼Œè¿˜æ˜¯å°†åŒç²¾åº¦å¼ é‡ä¿ç•™ä¸ºfloat32ã€‚'
- en: '**DeepSpeed Arguments**:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**DeepSpeedå‚æ•°**ï¼š'
- en: 'The following arguments are only useful when `use_deepspeed` is passed or `deepspeed`
    is configured through `accelerate config`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä»…åœ¨ä¼ é€’`use_deepspeed`æˆ–é€šè¿‡`accelerate config`é…ç½®`deepspeed`æ—¶æœ‰ç”¨ï¼š
- en: '`--deepspeed_config_file` (`str`) â€” DeepSpeed config file.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--deepspeed_config_file` (`str`) â€” DeepSpeedé…ç½®æ–‡ä»¶ã€‚'
- en: '`--zero_stage` (`int`) â€” DeepSpeedâ€™s ZeRO optimization stage.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--zero_stage` (`int`) â€” DeepSpeedçš„ZeROä¼˜åŒ–é˜¶æ®µã€‚'
- en: '`--offload_optimizer_device` (`str`) â€” Decides where (none|cpu|nvme) to offload
    optimizer states.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--offload_optimizer_device` (`str`) â€” å†³å®šåœ¨å“ªé‡Œï¼ˆnone|cpu|nvmeï¼‰å¸è½½ä¼˜åŒ–å™¨çŠ¶æ€ã€‚'
- en: '`--offload_param_device` (`str`) â€” Decides where (none|cpu|nvme) to offload
    parameters.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--offload_param_device` (`str`) â€” å†³å®šåœ¨å“ªé‡Œï¼ˆnone|cpu|nvmeï¼‰å¸è½½å‚æ•°ã€‚'
- en: '`--gradient_accumulation_steps` (`int`) â€” No of gradient_accumulation_steps
    used in your training script.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--gradient_accumulation_steps` (`int`) â€” åœ¨è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨çš„æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€‚'
- en: '`--gradient_clipping` (`float`) â€” Gradient clipping value used in your training
    script.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--gradient_clipping` (`float`) â€” åœ¨è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨çš„æ¢¯åº¦è£å‰ªå€¼ã€‚'
- en: '`--zero3_init_flag` (`str`) â€” Decides Whether (true|false) to enable `deepspeed.zero.Init`
    for constructing massive models. Only applicable with DeepSpeed ZeRO Stage-3.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--zero3_init_flag` (`str`) â€” å†³å®šæ˜¯å¦å¯ç”¨`deepspeed.zero.Init`æ¥æ„å»ºå¤§å‹æ¨¡å‹ã€‚ä»…é€‚ç”¨äºDeepSpeed
    ZeRO Stage-3ã€‚'
- en: '`--zero3_save_16bit_model` (`str`) â€” Decides Whether (true|false) to save 16-bit
    model weights when using ZeRO Stage-3\. Only applicable with DeepSpeed ZeRO Stage-3.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--zero3_save_16bit_model` (`str`) â€” å†³å®šåœ¨ä½¿ç”¨ZeRO Stage-3æ—¶æ˜¯å¦ä¿å­˜16ä½æ¨¡å‹æƒé‡ã€‚ä»…é€‚ç”¨äºDeepSpeed
    ZeRO Stage-3ã€‚'
- en: '`--deepspeed_hostfile` (`str`) â€” DeepSpeed hostfile for configuring multi-node
    compute resources.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--deepspeed_hostfile` (`str`) â€” ç”¨äºé…ç½®å¤šèŠ‚ç‚¹è®¡ç®—èµ„æºçš„DeepSpeedä¸»æœºæ–‡ä»¶ã€‚'
- en: '`--deepspeed_exclusion_filter` (`str`) â€” DeepSpeed exclusion filter string
    when using mutli-node setup.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--deepspeed_exclusion_filter` (`str`) â€” åœ¨ä½¿ç”¨å¤šèŠ‚ç‚¹è®¾ç½®æ—¶çš„DeepSpeedæ’é™¤è¿‡æ»¤å™¨å­—ç¬¦ä¸²ã€‚'
- en: '`--deepspeed_inclusion_filter` (`str`) â€” DeepSpeed inclusion filter string
    when using mutli-node setup.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--deepspeed_inclusion_filter` (`str`) â€” åœ¨ä½¿ç”¨å¤šèŠ‚ç‚¹è®¾ç½®æ—¶çš„DeepSpeedåŒ…å«è¿‡æ»¤å™¨å­—ç¬¦ä¸²ã€‚'
- en: '`--deepspeed_multinode_launcher` (`str`) â€” DeepSpeed multi-node launcher to
    use.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--deepspeed_multinode_launcher` (`str`) â€” è¦ä½¿ç”¨çš„DeepSpeedå¤šèŠ‚ç‚¹å¯åŠ¨å™¨ã€‚'
- en: '**Fully Sharded Data Parallelism Arguments**:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fully Sharded Data Parallelism å‚æ•°**ï¼š'
- en: 'The following arguments are only useful when `use_fsdp` is passed or Fully
    Sharded Data Parallelism is configured through `accelerate config`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä»…åœ¨ä¼ é€’`use_fsdp`æˆ–é€šè¿‡`accelerate config`é…ç½®å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œæ—¶æœ‰ç”¨ï¼š
- en: '`--fsdp_offload_params` (`str`) â€” Decides Whether (true|false) to offload parameters
    and gradients to CPU.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_offload_params` (`str`) â€” å†³å®šæ˜¯å¦å°†å‚æ•°å’Œæ¢¯åº¦å¸è½½åˆ°CPUï¼ˆtrue|falseï¼‰ã€‚'
- en: '`--fsdp_min_num_params` (`int`) â€” FSDPâ€™s minimum number of parameters for Default
    Auto Wrapping.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_min_num_params` (`int`) â€” FSDP çš„é»˜è®¤è‡ªåŠ¨åŒ…è£…çš„æœ€å°å‚æ•°æ•°é‡ã€‚'
- en: '`--fsdp_sharding_strategy` (`int`) â€” FSDPâ€™s Sharding Strategy.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_sharding_strategy` (`int`) â€” FSDP çš„åˆ†ç‰‡ç­–ç•¥ã€‚'
- en: '`--fsdp_auto_wrap_policy` (`str`) â€” FSDPâ€™s auto wrap policy.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_auto_wrap_policy` (`str`) â€” FSDP çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ã€‚'
- en: '`--fsdp_transformer_layer_cls_to_wrap` (`str`) â€” Transformer layer class name
    (case-sensitive) to wrap, e.g, `BertLayer`, `GPTJBlock`, `T5Block` â€¦'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_transformer_layer_cls_to_wrap` (`str`) â€” è¦åŒ…è£…çš„Transformerå±‚ç±»åï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ï¼Œ`BertLayer`ï¼Œ`GPTJBlock`ï¼Œ`T5Block`
    â€¦'
- en: '`--fsdp_backward_prefetch_policy` (`str`) â€” FSDPâ€™s backward prefetch policy.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_backward_prefetch_policy` (`str`) â€” FSDP çš„å‘åé¢„å–ç­–ç•¥ã€‚'
- en: '`--fsdp_state_dict_type` (`str`) â€” FSDPâ€™s state dict type.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fsdp_state_dict_type` (`str`) â€” FSDP çš„çŠ¶æ€å­—å…¸ç±»å‹ã€‚'
- en: '**Megatron-LM Arguments**:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**Megatron-LM å‚æ•°**ï¼š'
- en: 'The following arguments are only useful when `use_megatron_lm` is passed or
    Megatron-LM is configured through `accelerate config`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä»…åœ¨ä¼ é€’`use_megatron_lm`æˆ–é€šè¿‡`accelerate config`é…ç½®Megatron-LMæ—¶æœ‰ç”¨ï¼š
- en: '`--megatron_lm_tp_degree` (â€œ) â€” Megatron-LMâ€™s Tensor Parallelism (TP) degree.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_tp_degree` (â€œ) â€” Megatron-LM çš„å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰åº¦ã€‚'
- en: '`--megatron_lm_pp_degree` (â€œ) â€” Megatron-LMâ€™s Pipeline Parallelism (PP) degree.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_pp_degree` (â€œ) â€” Megatron-LM çš„ç®¡é“å¹¶è¡Œï¼ˆPPï¼‰åº¦ã€‚'
- en: '`--megatron_lm_num_micro_batches` (â€œ) â€” Megatron-LMâ€™s number of micro batches
    when PP degree > 1.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_num_micro_batches` (â€œ) â€” å½“PP degree > 1æ—¶ï¼ŒMegatron-LM çš„å¾®æ‰¹æ¬¡æ•°ã€‚'
- en: '`--megatron_lm_sequence_parallelism` (â€œ) â€” Decides Whether (true|false) to
    enable Sequence Parallelism when TP degree > 1.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_sequence_parallelism` (â€œ) â€” å†³å®šåœ¨TP degree > 1æ—¶æ˜¯å¦å¯ç”¨åºåˆ—å¹¶è¡Œã€‚'
- en: '`--megatron_lm_recompute_activations` (â€œ) â€” Decides Whether (true|false) to
    enable Selective Activation Recomputation.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_recompute_activations` (â€œ) â€” å†³å®šæ˜¯å¦å¯ç”¨é€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—ã€‚'
- en: '`--megatron_lm_use_distributed_optimizer` (â€œ) â€” Decides Whether (true|false)
    to use distributed optimizer which shards optimizer state and gradients across
    Data Parallel (DP) ranks.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_use_distributed_optimizer` (â€œ) â€” å†³å®šæ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¼ä¼˜åŒ–å™¨ï¼Œå°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦åˆ†ç‰‡åˆ°æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ç­‰çº§ã€‚'
- en: '`--megatron_lm_gradient_clipping` (â€œ) â€” Megatron-LMâ€™s gradient clipping value
    based on global L2 Norm (0 to disable).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--megatron_lm_gradient_clipping` (â€œ) â€” åŸºäºå…¨å±€L2èŒƒæ•°çš„Megatron-LMæ¢¯åº¦è£å‰ªå€¼ï¼ˆ0ä¸ºç¦ç”¨ï¼‰ã€‚'
- en: '**AWS SageMaker Arguments**:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**AWS SageMaker å‚æ•°**ï¼š'
- en: The following arguments are only useful when training in SageMaker
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä»…åœ¨SageMakerä¸­è®­ç»ƒæ—¶æœ‰ç”¨
- en: '`--aws_access_key_id AWS_ACCESS_KEY_ID` (`str`) â€” The AWS_ACCESS_KEY_ID used
    to launch the Amazon SageMaker training job'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--aws_access_key_id AWS_ACCESS_KEY_ID` (`str`) â€” ç”¨äºå¯åŠ¨Amazon SageMakerè®­ç»ƒä½œä¸šçš„AWS_ACCESS_KEY_ID'
- en: '`--aws_secret_access_key AWS_SECRET_ACCESS_KEY` (`str`) â€” The AWS_SECRET_ACCESS_KEY
    used to launch the Amazon SageMaker training job'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--aws_secret_access_key AWS_SECRET_ACCESS_KEY` (`str`) â€” ç”¨äºå¯åŠ¨Amazon SageMakerè®­ç»ƒä½œä¸šçš„AWS_SECRET_ACCESS_KEY'
- en: accelerate estimate-memory
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: accelerate estimate-memory
- en: '**Command**:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‘½ä»¤**ï¼š'
- en: '`accelerate estimate-memory` or `accelerate-estimate-memory` or `python -m
    accelerate.commands.estimate`'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate estimate-memory` æˆ– `accelerate-estimate-memory` æˆ– `python -m accelerate.commands.estimate`'
- en: Estimates the total vRAM a particular model hosted on the Hub needs to be loaded
    in with an estimate for training. Requires that `huggingface_hub` be installed.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡åœ¨Hubä¸Šæ‰˜ç®¡çš„ç‰¹å®šæ¨¡å‹éœ€è¦åŠ è½½çš„æ€»vRAMï¼Œä»¥åŠç”¨äºè®­ç»ƒçš„ä¼°è®¡ã€‚éœ€è¦å®‰è£…`huggingface_hub`ã€‚
- en: When performing inference, typically add â‰¤20% to the result as overall allocation
    [as referenced here](https://blog.eleuther.ai/transformer-math/). We will have
    more extensive estimations in the future that will automatically be included in
    the calculation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œé€šå¸¸å°†ç»“æœæ•´ä½“åˆ†é…å¢åŠ â‰¤20% [å‚è€ƒæ­¤å¤„](https://blog.eleuther.ai/transformer-math/)ã€‚æˆ‘ä»¬å°†æ¥ä¼šæœ‰æ›´å¹¿æ³›çš„ä¼°è®¡ï¼Œå°†è‡ªåŠ¨åŒ…å«åœ¨è®¡ç®—ä¸­ã€‚
- en: '**Usage**:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**ï¼š'
- en: '[PRE5]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Required Arguments**:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¿…éœ€å‚æ•°**ï¼š'
- en: '`MODEL_NAME` (`str`)â€” The model name on the Hugging Face Hub'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL_NAME` (`str`)â€” Hugging Face Hubä¸Šçš„æ¨¡å‹åç§°'
- en: '**Optional Arguments**:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**ï¼š'
- en: '`--library_name {timm,transformers}` (`str`) â€” The library the model has an
    integration with, such as `transformers`, needed only if this information is not
    stored on the Hub'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--library_name {timm,transformers}` (`str`) â€” æ¨¡å‹ä¸ä¹‹é›†æˆçš„åº“ï¼Œä¾‹å¦‚ `transformers`ï¼Œä»…åœ¨Hubä¸Šæœªå­˜å‚¨æ­¤ä¿¡æ¯æ—¶éœ€è¦ã€‚'
- en: '`--dtypes {float32,float16,int8,int4}` (`[{float32,float16,int8,int4} ...]`)
    â€” The dtypes to use for the model, must be one (or many) of `float32`, `float16`,
    `int8`, and `int4`'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--dtypes {float32,float16,int8,int4}` (`[{float32,float16,int8,int4} ...]`)
    â€” ç”¨äºæ¨¡å‹çš„æ•°æ®ç±»å‹ï¼Œå¿…é¡»æ˜¯`float32`ã€`float16`ã€`int8`å’Œ`int4`ä¸­çš„ä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰'
- en: '`--trust_remote_code` (`bool`) â€” Whether or not to allow for custom models
    defined on the Hub in their own modeling files. This option should only be passed
    for repositories you trust and in which you have read the code, as it will execute
    code present on the Hub on your local machine.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--trust_remote_code` (`bool`) â€” æ˜¯å¦å…è®¸åœ¨Hubä¸Šå®šä¹‰è‡ªå®šä¹‰æ¨¡å‹çš„ä»£ç åœ¨å…¶è‡ªå·±çš„å»ºæ¨¡æ–‡ä»¶ä¸­ã€‚æ­¤é€‰é¡¹ä»…åº”ä¼ é€’ç»™æ‚¨ä¿¡ä»»çš„å­˜å‚¨åº“ï¼Œå¹¶ä¸”æ‚¨å·²é˜…è¯»äº†ä»£ç ï¼Œå› ä¸ºå®ƒå°†åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰§è¡ŒHubä¸Šå­˜åœ¨çš„ä»£ç ã€‚'
- en: accelerate tpu-config
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: accelerate tpu-config
- en: '`accelerate tpu-config`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate tpu-config`'
- en: '**Usage**:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**ï¼š'
- en: '[PRE6]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Optional Arguments**:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**ï¼š'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©æ¶ˆæ¯å¹¶é€€å‡º'
- en: '**Config Arguments**:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**é…ç½®å‚æ•°**ï¼š'
- en: Arguments that can be configured through `accelerate config`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥é€šè¿‡`accelerate config`é…ç½®çš„å‚æ•°ã€‚
- en: '`--config_file` (`str`) â€” Path to the config file to use for accelerate.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file` (`str`) â€” ç”¨äºaccelerateçš„é…ç½®æ–‡ä»¶è·¯å¾„ã€‚'
- en: '`--tpu_name` (`str`) â€” The name of the TPU to use. If not specified, will use
    the TPU specified in the config file.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--tpu_name` (`str`) â€” è¦ä½¿ç”¨çš„TPUçš„åç§°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„TPUã€‚'
- en: '`--tpu_zone` (`str`) â€” The zone of the TPU to use. If not specified, will use
    the zone specified in the config file.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--tpu_zone` (`str`) â€” è¦ä½¿ç”¨çš„TPUçš„åŒºåŸŸã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„åŒºåŸŸã€‚'
- en: '**TPU Arguments**:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**TPUå‚æ•°**ï¼š'
- en: Arguments for options ran inside the TPU.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨TPUå†…éƒ¨è¿è¡Œçš„é€‰é¡¹çš„å‚æ•°ã€‚
- en: '`--command_file` (`str`) â€” The path to the file containing the commands to
    run on the pod on startup.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--command_file` (`str`) â€” åŒ…å«åœ¨å¯åŠ¨æ—¶åœ¨podä¸Šè¿è¡Œçš„å‘½ä»¤çš„æ–‡ä»¶è·¯å¾„ã€‚'
- en: '`--command` (`str`) â€” A command to run on the pod. Can be passed multiple times.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--command` (`str`) â€” åœ¨podä¸Šè¿è¡Œçš„å‘½ä»¤ã€‚å¯ä»¥å¤šæ¬¡ä¼ é€’ã€‚'
- en: '`--install_accelerate` (`bool`) â€” Whether to install accelerate on the pod.
    Defaults to False.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--install_accelerate` (`bool`) â€” æ˜¯å¦åœ¨podä¸Šå®‰è£…accelerateã€‚é»˜è®¤ä¸ºFalseã€‚'
- en: '`--accelerate_version` (`str`) â€” The version of accelerate to install on the
    pod. If not specified, will use the latest pypi version. Specify â€˜devâ€™ to install
    from GitHub.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--accelerate_version` (`str`) â€” å®‰è£…åœ¨podä¸Šçš„accelerateç‰ˆæœ¬ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨æœ€æ–°çš„pypiç‰ˆæœ¬ã€‚æŒ‡å®šâ€˜devâ€™ä»¥ä»GitHubå®‰è£…ã€‚'
- en: '`--debug` (`bool`) â€” If set, will print the command that would be run instead
    of running it.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--debug` (`bool`) â€” å¦‚æœè®¾ç½®ï¼Œå°†æ‰“å°å°†è¦è¿è¡Œçš„å‘½ä»¤è€Œä¸æ˜¯è¿è¡Œå®ƒã€‚'
- en: accelerate test
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: accelerate test
- en: '`accelerate test` or `accelerate-test`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerate test`æˆ–`accelerate-test`'
- en: Runs `accelerate/test_utils/test_script.py` to verify that ğŸ¤— Accelerate has
    been properly configured on your system and runs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œ`accelerate/test_utils/test_script.py`æ¥éªŒè¯ğŸ¤— Accelerateæ˜¯å¦å·²åœ¨æ‚¨çš„ç³»ç»Ÿä¸Šæ­£ç¡®é…ç½®å¹¶è¿è¡Œã€‚
- en: '**Usage**:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æ³•**ï¼š'
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Optional Arguments**:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯é€‰å‚æ•°**ï¼š'
- en: '`--config_file CONFIG_FILE` (`str`) â€” The path to use to store the config file.
    Will default to a file named default_config.yaml in the cache location, which
    is the content of the environment `HF_HOME` suffixed with â€˜accelerateâ€™, or if
    you donâ€™t have such an environment variable, your cache directory (`~/.cache`
    or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--config_file CONFIG_FILE` (`str`) â€” ç”¨äºå­˜å‚¨é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸ºç¼“å­˜ä½ç½®ä¸­åä¸ºdefault_config.yamlçš„æ–‡ä»¶ï¼Œè¯¥ä½ç½®æ˜¯ç¯å¢ƒå˜é‡`HF_HOME`çš„å†…å®¹åç¼€ä¸ºâ€˜accelerateâ€™ï¼Œæˆ–è€…å¦‚æœæ‚¨æ²¡æœ‰è¿™æ ·çš„ç¯å¢ƒå˜é‡ï¼Œåˆ™æ˜¯æ‚¨çš„ç¼“å­˜ç›®å½•ï¼ˆ`~/.cache`æˆ–`XDG_CACHE_HOME`çš„å†…å®¹ï¼‰åç¼€ä¸º`huggingface`ã€‚'
- en: '`-h`, `--help` (`bool`) â€” Show a help message and exit'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-h`, `--help` (`bool`) â€” æ˜¾ç¤ºå¸®åŠ©æ¶ˆæ¯å¹¶é€€å‡º'
