["```py\npip install huggingface_hub --upgrade\n```", "```py\nfrom huggingface_hub import login\n\nlogin()\n```", "```py\npip install -q diffusers accelerate transformers\n```", "```py\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import pt_to_pil, make_image_grid\nimport torch\n\n# stage 1\nstage_1 = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\nstage_1.enable_model_cpu_offload()\n\n# stage 2\nstage_2 = DiffusionPipeline.from_pretrained(\n    \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n)\nstage_2.enable_model_cpu_offload()\n\n# stage 3\nsafety_modules = {\n    \"feature_extractor\": stage_1.feature_extractor,\n    \"safety_checker\": stage_1.safety_checker,\n    \"watermarker\": stage_1.watermarker,\n}\nstage_3 = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-x4-upscaler\", **safety_modules, torch_dtype=torch.float16\n)\nstage_3.enable_model_cpu_offload()\n\nprompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says \"very deep learning\"'\ngenerator = torch.manual_seed(1)\n\n# text embeds\nprompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)\n\n# stage 1\nstage_1_output = stage_1(\n    prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, generator=generator, output_type=\"pt\"\n).images\n#pt_to_pil(stage_1_output)[0].save(\"./if_stage_I.png\")\n\n# stage 2\nstage_2_output = stage_2(\n    image=stage_1_output,\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    generator=generator,\n    output_type=\"pt\",\n).images\n#pt_to_pil(stage_2_output)[0].save(\"./if_stage_II.png\")\n\n# stage 3\nstage_3_output = stage_3(prompt=prompt, image=stage_2_output, noise_level=100, generator=generator).images\n#stage_3_output[0].save(\"./if_stage_III.png\")\nmake_image_grid([pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0], stage_3_output[0]], rows=1, rows=3)\n```", "```py\nfrom diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline\nfrom diffusers.utils import pt_to_pil, load_image, make_image_grid\nimport torch\n\n# download image\nurl = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\noriginal_image = load_image(url)\noriginal_image = original_image.resize((768, 512))\n\n# stage 1\nstage_1 = IFImg2ImgPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\nstage_1.enable_model_cpu_offload()\n\n# stage 2\nstage_2 = IFImg2ImgSuperResolutionPipeline.from_pretrained(\n    \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n)\nstage_2.enable_model_cpu_offload()\n\n# stage 3\nsafety_modules = {\n    \"feature_extractor\": stage_1.feature_extractor,\n    \"safety_checker\": stage_1.safety_checker,\n    \"watermarker\": stage_1.watermarker,\n}\nstage_3 = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-x4-upscaler\", **safety_modules, torch_dtype=torch.float16\n)\nstage_3.enable_model_cpu_offload()\n\nprompt = \"A fantasy landscape in style minecraft\"\ngenerator = torch.manual_seed(1)\n\n# text embeds\nprompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)\n\n# stage 1\nstage_1_output = stage_1(\n    image=original_image,\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    generator=generator,\n    output_type=\"pt\",\n).images\n#pt_to_pil(stage_1_output)[0].save(\"./if_stage_I.png\")\n\n# stage 2\nstage_2_output = stage_2(\n    image=stage_1_output,\n    original_image=original_image,\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    generator=generator,\n    output_type=\"pt\",\n).images\n#pt_to_pil(stage_2_output)[0].save(\"./if_stage_II.png\")\n\n# stage 3\nstage_3_output = stage_3(prompt=prompt, image=stage_2_output, generator=generator, noise_level=100).images\n#stage_3_output[0].save(\"./if_stage_III.png\")\nmake_image_grid([original_image, pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0], stage_3_output[0]], rows=1, rows=4)\n```", "```py\nfrom diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline\nfrom diffusers.utils import pt_to_pil, load_image, make_image_grid\nimport torch\n\n# download image\nurl = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png\"\noriginal_image = load_image(url)\n\n# download mask\nurl = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png\"\nmask_image = load_image(url)\n\n# stage 1\nstage_1 = IFInpaintingPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\nstage_1.enable_model_cpu_offload()\n\n# stage 2\nstage_2 = IFInpaintingSuperResolutionPipeline.from_pretrained(\n    \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n)\nstage_2.enable_model_cpu_offload()\n\n# stage 3\nsafety_modules = {\n    \"feature_extractor\": stage_1.feature_extractor,\n    \"safety_checker\": stage_1.safety_checker,\n    \"watermarker\": stage_1.watermarker,\n}\nstage_3 = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-x4-upscaler\", **safety_modules, torch_dtype=torch.float16\n)\nstage_3.enable_model_cpu_offload()\n\nprompt = \"blue sunglasses\"\ngenerator = torch.manual_seed(1)\n\n# text embeds\nprompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)\n\n# stage 1\nstage_1_output = stage_1(\n    image=original_image,\n    mask_image=mask_image,\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    generator=generator,\n    output_type=\"pt\",\n).images\n#pt_to_pil(stage_1_output)[0].save(\"./if_stage_I.png\")\n\n# stage 2\nstage_2_output = stage_2(\n    image=stage_1_output,\n    original_image=original_image,\n    mask_image=mask_image,\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    generator=generator,\n    output_type=\"pt\",\n).images\n#pt_to_pil(stage_1_output)[0].save(\"./if_stage_II.png\")\n\n# stage 3\nstage_3_output = stage_3(prompt=prompt, image=stage_2_output, generator=generator, noise_level=100).images\n#stage_3_output[0].save(\"./if_stage_III.png\")\nmake_image_grid([original_image, mask_image, pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0], stage_3_output[0]], rows=1, rows=5)\n```", "```py\nfrom diffusers import IFPipeline, IFSuperResolutionPipeline\n\npipe_1 = IFPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\")\npipe_2 = IFSuperResolutionPipeline.from_pretrained(\"DeepFloyd/IF-II-L-v1.0\")\n\nfrom diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline\n\npipe_1 = IFImg2ImgPipeline(**pipe_1.components)\npipe_2 = IFImg2ImgSuperResolutionPipeline(**pipe_2.components)\n\nfrom diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline\n\npipe_1 = IFInpaintingPipeline(**pipe_1.components)\npipe_2 = IFInpaintingSuperResolutionPipeline(**pipe_2.components)\n```", "```py\npipe = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\npipe.to(\"cuda\")\n```", "```py\npipe(\"<prompt>\", num_inference_steps=30)\n```", "```py\nfrom diffusers.pipelines.deepfloyd_if import fast27_timesteps\n\npipe(\"<prompt>\", timesteps=fast27_timesteps)\n```", "```py\npipe = IFImg2ImgPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\npipe.to(\"cuda\")\n\nimage = pipe(image=image, prompt=\"<prompt>\", strength=0.3).images\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\npipe = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\npipe.to(\"cuda\")\n\npipe.text_encoder = torch.compile(pipe.text_encoder, mode=\"reduce-overhead\", fullgraph=True)\npipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)\n```", "```py\npipe = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\npipe.enable_model_cpu_offload()\n```", "```py\npipe = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\npipe.enable_sequential_cpu_offload()\n```", "```py\nfrom transformers import T5EncoderModel\n\ntext_encoder = T5EncoderModel.from_pretrained(\n    \"DeepFloyd/IF-I-XL-v1.0\", subfolder=\"text_encoder\", device_map=\"auto\", load_in_8bit=True, variant=\"8bit\"\n)\n\nfrom diffusers import DiffusionPipeline\n\npipe = DiffusionPipeline.from_pretrained(\n    \"DeepFloyd/IF-I-XL-v1.0\",\n    text_encoder=text_encoder,  # pass the previously instantiated 8bit text encoder\n    unet=None,\n    device_map=\"auto\",\n)\n\nprompt_embeds, negative_embeds = pipe.encode_prompt(\"<prompt>\")\n```", "```py\nfrom diffusers import IFPipeline, IFSuperResolutionPipeline\nimport torch\nimport gc\nfrom transformers import T5EncoderModel\nfrom diffusers.utils import pt_to_pil, make_image_grid\n\ntext_encoder = T5EncoderModel.from_pretrained(\n    \"DeepFloyd/IF-I-XL-v1.0\", subfolder=\"text_encoder\", device_map=\"auto\", load_in_8bit=True, variant=\"8bit\"\n)\n\n# text to image\npipe = DiffusionPipeline.from_pretrained(\n    \"DeepFloyd/IF-I-XL-v1.0\",\n    text_encoder=text_encoder,  # pass the previously instantiated 8bit text encoder\n    unet=None,\n    device_map=\"auto\",\n)\n\nprompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says \"very deep learning\"'\nprompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n\n# Remove the pipeline so we can re-load the pipeline with the unet\ndel text_encoder\ndel pipe\ngc.collect()\ntorch.cuda.empty_cache()\n\npipe = IFPipeline.from_pretrained(\n    \"DeepFloyd/IF-I-XL-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16, device_map=\"auto\"\n)\n\ngenerator = torch.Generator().manual_seed(0)\nstage_1_output = pipe(\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    output_type=\"pt\",\n    generator=generator,\n).images\n\n#pt_to_pil(stage_1_output)[0].save(\"./if_stage_I.png\")\n\n# Remove the pipeline so we can load the super-resolution pipeline\ndel pipe\ngc.collect()\ntorch.cuda.empty_cache()\n\n# First super resolution\n\npipe = IFSuperResolutionPipeline.from_pretrained(\n    \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16, device_map=\"auto\"\n)\n\ngenerator = torch.Generator().manual_seed(0)\nstage_2_output = pipe(\n    image=stage_1_output,\n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    output_type=\"pt\",\n    generator=generator,\n).images\n\n#pt_to_pil(stage_2_output)[0].save(\"./if_stage_II.png\")\nmake_image_grid([pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0]], rows=1, rows=2)\n```", "```py\n>>> from diffusers import IFPipeline, IFSuperResolutionPipeline, DiffusionPipeline\n>>> from diffusers.utils import pt_to_pil\n>>> import torch\n\n>>> pipe = IFPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says \"very deep learning\"'\n>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n\n>>> image = pipe(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, output_type=\"pt\").images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> super_res_1_pipe = IFSuperResolutionPipeline.from_pretrained(\n...     \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> super_res_1_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_1_pipe(\n...     image=image, prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, output_type=\"pt\"\n... ).images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> safety_modules = {\n...     \"feature_extractor\": pipe.feature_extractor,\n...     \"safety_checker\": pipe.safety_checker,\n...     \"watermarker\": pipe.watermarker,\n... }\n>>> super_res_2_pipe = DiffusionPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-x4-upscaler\", **safety_modules, torch_dtype=torch.float16\n... )\n>>> super_res_2_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_2_pipe(\n...     prompt=prompt,\n...     image=image,\n... ).images\n>>> image[0].save(\"./if_stage_II.png\")\n```", "```py\n>>> from diffusers import IFPipeline, IFSuperResolutionPipeline, DiffusionPipeline\n>>> from diffusers.utils import pt_to_pil\n>>> import torch\n\n>>> pipe = IFPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says \"very deep learning\"'\n>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n\n>>> image = pipe(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, output_type=\"pt\").images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> super_res_1_pipe = IFSuperResolutionPipeline.from_pretrained(\n...     \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> super_res_1_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_1_pipe(\n...     image=image, prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds\n... ).images\n>>> image[0].save(\"./if_stage_II.png\")\n```", "```py\n>>> from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline\n>>> from diffusers.utils import pt_to_pil\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from io import BytesIO\n\n>>> url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n>>> response = requests.get(url)\n>>> original_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> original_image = original_image.resize((768, 512))\n\n>>> pipe = IFImg2ImgPipeline.from_pretrained(\n...     \"DeepFloyd/IF-I-XL-v1.0\",\n...     variant=\"fp16\",\n...     torch_dtype=torch.float16,\n... )\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"A fantasy landscape in style minecraft\"\n>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n\n>>> image = pipe(\n...     image=original_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n...     output_type=\"pt\",\n... ).images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> super_res_1_pipe = IFImg2ImgSuperResolutionPipeline.from_pretrained(\n...     \"DeepFloyd/IF-II-L-v1.0\",\n...     text_encoder=None,\n...     variant=\"fp16\",\n...     torch_dtype=torch.float16,\n... )\n>>> super_res_1_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_1_pipe(\n...     image=image,\n...     original_image=original_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n... ).images\n>>> image[0].save(\"./if_stage_II.png\")\n```", "```py\n>>> from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline\n>>> from diffusers.utils import pt_to_pil\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from io import BytesIO\n\n>>> url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n>>> response = requests.get(url)\n>>> original_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> original_image = original_image.resize((768, 512))\n\n>>> pipe = IFImg2ImgPipeline.from_pretrained(\n...     \"DeepFloyd/IF-I-XL-v1.0\",\n...     variant=\"fp16\",\n...     torch_dtype=torch.float16,\n... )\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"A fantasy landscape in style minecraft\"\n>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n\n>>> image = pipe(\n...     image=original_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n...     output_type=\"pt\",\n... ).images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> super_res_1_pipe = IFImg2ImgSuperResolutionPipeline.from_pretrained(\n...     \"DeepFloyd/IF-II-L-v1.0\",\n...     text_encoder=None,\n...     variant=\"fp16\",\n...     torch_dtype=torch.float16,\n... )\n>>> super_res_1_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_1_pipe(\n...     image=image,\n...     original_image=original_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n... ).images\n>>> image[0].save(\"./if_stage_II.png\")\n```", "```py\n>>> from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline\n>>> from diffusers.utils import pt_to_pil\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from io import BytesIO\n\n>>> url = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png\"\n>>> response = requests.get(url)\n>>> original_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> original_image = original_image\n\n>>> url = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png\"\n>>> response = requests.get(url)\n>>> mask_image = Image.open(BytesIO(response.content))\n>>> mask_image = mask_image\n\n>>> pipe = IFInpaintingPipeline.from_pretrained(\n...     \"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"blue sunglasses\"\n>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n\n>>> image = pipe(\n...     image=original_image,\n...     mask_image=mask_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n...     output_type=\"pt\",\n... ).images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> super_res_1_pipe = IFInpaintingSuperResolutionPipeline.from_pretrained(\n...     \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> super_res_1_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_1_pipe(\n...     image=image,\n...     mask_image=mask_image,\n...     original_image=original_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n... ).images\n>>> image[0].save(\"./if_stage_II.png\")\n```", "```py\n>>> from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline\n>>> from diffusers.utils import pt_to_pil\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from io import BytesIO\n\n>>> url = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png\"\n>>> response = requests.get(url)\n>>> original_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> original_image = original_image\n\n>>> url = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png\"\n>>> response = requests.get(url)\n>>> mask_image = Image.open(BytesIO(response.content))\n>>> mask_image = mask_image\n\n>>> pipe = IFInpaintingPipeline.from_pretrained(\n...     \"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"blue sunglasses\"\n\n>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)\n>>> image = pipe(\n...     image=original_image,\n...     mask_image=mask_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n...     output_type=\"pt\",\n... ).images\n\n>>> # save intermediate image\n>>> pil_image = pt_to_pil(image)\n>>> pil_image[0].save(\"./if_stage_I.png\")\n\n>>> super_res_1_pipe = IFInpaintingSuperResolutionPipeline.from_pretrained(\n...     \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> super_res_1_pipe.enable_model_cpu_offload()\n\n>>> image = super_res_1_pipe(\n...     image=image,\n...     mask_image=mask_image,\n...     original_image=original_image,\n...     prompt_embeds=prompt_embeds,\n...     negative_prompt_embeds=negative_embeds,\n... ).images\n>>> image[0].save(\"./if_stage_II.png\")\n```"]