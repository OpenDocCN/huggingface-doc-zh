["```py\nAdafactor(model.parameters(), scale_parameter=False, relative_step=False, warmup_init=False, lr=1e-3)\n```", "```py\nAdafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n```", "```py\nfrom transformers.optimization import Adafactor, AdafactorSchedule\n\noptimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\nlr_scheduler = AdafactorSchedule(optimizer)\ntrainer = Trainer(..., optimizers=(optimizer, lr_scheduler))\n```", "```py\n# replace AdamW with Adafactor\noptimizer = Adafactor(\n    model.parameters(),\n    lr=1e-3,\n    eps=(1e-30, 1e-3),\n    clip_threshold=1.0,\n    decay_rate=-0.8,\n    beta1=None,\n    weight_decay=0.0,\n    relative_step=False,\n    scale_parameter=False,\n    warmup_init=False,\n)\n```"]