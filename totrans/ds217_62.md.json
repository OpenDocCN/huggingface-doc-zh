["```py\n( with_community_datasets = True with_details = False )\n```", "```py\n>>> from datasets import list_datasets\n>>> list_datasets()\n['acronym_identification',\n 'ade_corpus_v2',\n 'adversarial_qa',\n 'aeslc',\n 'afrikaans_ner_corpus',\n 'ag_news',\n ...\n]\n```", "```py\n( path: str name: Optional = None data_dir: Optional = None data_files: Union = None split: Union = None cache_dir: Optional = None features: Optional = None download_config: Optional = None download_mode: Union = None verification_mode: Union = None ignore_verifications = 'deprecated' keep_in_memory: Optional = None save_infos: bool = False revision: Union = None token: Union = None use_auth_token = 'deprecated' task = 'deprecated' streaming: bool = False num_proc: Optional = None storage_options: Optional = None trust_remote_code: bool = None **config_kwargs ) \u2192 export const metadata = 'undefined';Dataset or DatasetDict\n```", "```py\n>>> from datasets import load_dataset\n>>> ds = load_dataset('rotten_tomatoes', split='train')\n\n# Map data files to splits\n>>> data_files = {'train': 'train.csv', 'test': 'test.csv'}\n>>> ds = load_dataset('namespace/your_dataset_name', data_files=data_files)\n```", "```py\n# Load a CSV file\n>>> from datasets import load_dataset\n>>> ds = load_dataset('csv', data_files='path/to/local/my_dataset.csv')\n\n# Load a JSON file\n>>> from datasets import load_dataset\n>>> ds = load_dataset('json', data_files='path/to/local/my_dataset.json')\n\n# Load from a local loading script\n>>> from datasets import load_dataset\n>>> ds = load_dataset('path/to/local/loading_script/loading_script.py', split='train')\n```", "```py\n>>> from datasets import load_dataset\n>>> ds = load_dataset('rotten_tomatoes', split='train', streaming=True)\n```", "```py\n>>> from datasets import load_dataset\n>>> ds = load_dataset('imagefolder', data_dir='/path/to/images', split='train')\n```", "```py\n( dataset_path: str fs = 'deprecated' keep_in_memory: Optional = None storage_options: Optional = None ) \u2192 export const metadata = 'undefined';Dataset or DatasetDict\n```", "```py\n>>> from datasets import load_from_disk\n>>> ds = load_from_disk('path/to/dataset/directory')\n```", "```py\n( path: str name: Optional = None data_dir: Optional = None data_files: Union = None cache_dir: Optional = None features: Optional = None download_config: Optional = None download_mode: Union = None revision: Union = None token: Union = None use_auth_token = 'deprecated' storage_options: Optional = None trust_remote_code: Optional = None _require_default_config_name = True **config_kwargs )\n```", "```py\n>>> from datasets import load_dataset_builder\n>>> ds_builder = load_dataset_builder('rotten_tomatoes')\n>>> ds_builder.info.features\n{'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None),\n 'text': Value(dtype='string', id=None)}\n```", "```py\n( path: str revision: Union = None download_config: Optional = None download_mode: Union = None dynamic_modules_path: Optional = None data_files: Union = None **download_kwargs )\n```", "```py\n>>> from datasets import get_dataset_config_names\n>>> get_dataset_config_names(\"glue\")\n['cola',\n 'sst2',\n 'mrpc',\n 'qqp',\n 'stsb',\n 'mnli',\n 'mnli_mismatched',\n 'mnli_matched',\n 'qnli',\n 'rte',\n 'wnli',\n 'ax']\n```", "```py\n( path: str data_files: Union = None download_config: Optional = None download_mode: Union = None revision: Union = None token: Union = None use_auth_token = 'deprecated' **config_kwargs )\n```", "```py\n>>> from datasets import get_dataset_infos\n>>> get_dataset_infos('rotten_tomatoes')\n{'default': DatasetInfo(description=\"Movie Review Dataset.\n is a dataset of containing 5,331 positive and 5,331 negative processed\nences from Rotten Tomatoes movie reviews...), ...}\n```", "```py\n( path: str config_name: Optional = None data_files: Union = None download_config: Optional = None download_mode: Union = None revision: Union = None token: Union = None use_auth_token = 'deprecated' **config_kwargs )\n```", "```py\n>>> from datasets import get_dataset_split_names\n>>> get_dataset_split_names('rotten_tomatoes')\n['train', 'validation', 'test']\n```", "```py\n( path: str local_path: str download_config: Optional = None **download_kwargs )\n```", "```py\n( with_community_metrics = True with_details = False )\n```", "```py\n>>> from datasets import list_metrics\n>>> list_metrics()\n['accuracy',\n 'bertscore',\n 'bleu',\n 'bleurt',\n 'cer',\n 'chrf',\n ...\n]\n```", "```py\n( path: str config_name: Optional = None process_id: int = 0 num_process: int = 1 cache_dir: Optional = None experiment_id: Optional = None keep_in_memory: bool = False download_config: Optional = None download_mode: Union = None revision: Union = None trust_remote_code: Optional = None **metric_init_kwargs )\n```", "```py\n>>> from datasets import load_metric\n>>> accuracy = load_metric('accuracy')\n>>> accuracy.compute(references=[1, 0], predictions=[1, 1])\n{'accuracy': 0.5}\n```", "```py\n( path: str local_path: str download_config: Optional = None **download_kwargs )\n```", "```py\nload_dataset(\"csv\", data_dir=\"path/to/data/dir\", sep=\"\\t\")\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None encoding: str = 'utf-8' errors: dataclasses.InitVar[typing.Optional[str]] = 'deprecated' encoding_errors: Optional = None chunksize: int = 10485760 keep_linebreaks: bool = False sample_by: str = 'line' )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None sep: str = ',' delimiter: Optional = None header: Union = 'infer' names: Optional = None column_names: Optional = None index_col: Union = None usecols: Union = None prefix: Optional = None mangle_dupe_cols: bool = True engine: Optional = None converters: Dict = None true_values: Optional = None false_values: Optional = None skipinitialspace: bool = False skiprows: Union = None nrows: Optional = None na_values: Union = None keep_default_na: bool = True na_filter: bool = True verbose: bool = False skip_blank_lines: bool = True thousands: Optional = None decimal: str = '.' lineterminator: Optional = None quotechar: str = '\"' quoting: int = 0 escapechar: Optional = None comment: Optional = None encoding: Optional = None dialect: Optional = None error_bad_lines: bool = True warn_bad_lines: bool = True skipfooter: int = 0 doublequote: bool = True memory_map: bool = False float_precision: Optional = None chunksize: int = 10000 features: Optional = None encoding_errors: Optional = 'strict' on_bad_lines: Literal = 'error' date_format: Optional = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None encoding: str = 'utf-8' encoding_errors: Optional = None field: Optional = None use_threads: bool = True block_size: Optional = None chunksize: int = 10485760 newlines_in_values: Optional = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None batch_size: int = 10000 columns: Optional = None features: Optional = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None sql: Union = None con: Union = None index_col: Union = None coerce_float: bool = True params: Union = None parse_dates: Union = None columns: Optional = None chunksize: Optional = 10000 features: Optional = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None drop_labels: bool = None drop_metadata: bool = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None drop_labels: bool = None drop_metadata: bool = None )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```", "```py\n( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )\n```"]