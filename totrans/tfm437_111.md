# 回调函数

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/callback](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/callback)

回调函数是可以自定义PyTorch [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)训练循环行为的对象（此功能尚未在TensorFlow中实现），可以检查训练循环状态（用于进度报告、在TensorBoard或其他ML平台上记录…）并做出决策（如提前停止）。

回调函数是“只读”代码片段，除了它们返回的[TrainerControl](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerControl)对象外，它们不能更改训练循环中的任何内容。对于需要更改训练循环的自定义内容，您应该子类化[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)并覆盖您需要的方法（请参阅[trainer](trainer)以获取示例）。

默认情况下，`TrainingArguments.report_to`设置为`"all"`，因此[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)将使用以下回调函数。

+   [DefaultFlowCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.DefaultFlowCallback)处理日志记录、保存和评估的默认行为。

+   使用[PrinterCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.PrinterCallback)或[ProgressCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.ProgressCallback)显示进度并打印日志（如果通过[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)停用tqdm，则使用第一个，否则使用第二个）。

+   如果tensorboard可访问（通过PyTorch >= 1.4或tensorboardX），则使用[TensorBoardCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.TensorBoardCallback)。

+   如果安装了[wandb](https://www.wandb.com/)，则使用[WandbCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.WandbCallback)。

+   如果安装了[comet_ml](https://www.comet.ml/site/)，则使用[CometCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.CometCallback)。

+   如果安装了[mlflow](https://www.mlflow.org/)，则使用[MLflowCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.MLflowCallback)。

+   如果安装了[neptune](https://neptune.ai/)，则使用[NeptuneCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.NeptuneCallback)。

+   如果安装了[azureml-sdk](https://pypi.org/project/azureml-sdk/)，则使用[AzureMLCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.AzureMLCallback)。

+   如果安装了[codecarbon](https://pypi.org/project/codecarbon/)，则使用[CodeCarbonCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.CodeCarbonCallback)。

+   如果安装了[clearml](https://github.com/allegroai/clearml)，则使用[ClearMLCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.ClearMLCallback)。

+   如果安装了[dagshub](https://dagshub.com/)，则使用[DagsHubCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.DagsHubCallback)。

+   如果安装了[flyte](https://flyte.org/)，则使用[FlyteCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.FlyteCallback)。

+   如果安装了[dvclive](https://dvc.org/doc/dvclive)，则使用[DVCLiveCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.integrations.DVCLiveCallback)。

如果安装了某个软件包，但您不希望使用相应的集成，可以将`TrainingArguments.report_to`更改为您想要使用的集成列表（例如`["azure_ml", "wandb"]`）。

实现回调的主要类是[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。它获取用于实例化[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)的[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)，可以通过[TrainerState](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerState)访问该Trainer的内部状态，并可以通过[TrainerControl](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerControl)对训练循环采取一些操作。

## 可用的回调

以下是库中可用的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)列表：

### `class transformers.integrations.CometCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L833)

```py
( )
```

一个将日志发送到[Comet ML](https://www.comet.ml/site/)的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

#### `setup`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L844)

```py
( args state model )
```

设置可选的Comet.ml集成。

环境：

+   `COMET_MODE` (`str`, *可选*，默认为`ONLINE`): 是否创建在线、离线实验或禁用Comet日志记录。可以是`OFFLINE`、`ONLINE`或`DISABLED`。

+   `COMET_PROJECT_NAME` (`str`, *可选*): 用于实验的Comet项目名称。

+   `COMET_OFFLINE_DIRECTORY` (`str`, *可选*): 在`COMET_MODE`为`OFFLINE`时用于保存离线实验的文件夹。

+   `COMET_LOG_ASSETS` (`str`, *可选*，默认为`TRUE`): 是否将训练资产（tf事件日志、检查点等）记录到Comet。可以是`TRUE`或`FALSE`。

有关环境中可配置项目的详细信息，请参阅[此处](https://www.comet.ml/docs/python-sdk/advanced/#comet-configuration-variables)。

### `class transformers.DefaultFlowCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L432)

```py
( )
```

处理训练循环的默认流程，包括日志、评估和检查点的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

### `class transformers.PrinterCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L532)

```py
( )
```

一个简单的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)，只打印日志。

### `class transformers.ProgressCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L482)

```py
( )
```

一个显示训练或评估进度的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

### `class transformers.EarlyStoppingCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L543)

```py
( early_stopping_patience: int = 1 early_stopping_threshold: Optional = 0.0 )
```

参数

+   `early_stopping_patience` (`int`) — 与`metric_for_best_model`一起使用，当指定的指标在`early_stopping_patience`次评估调用中恶化时停止训练。

+   `early_stopping_threshold(float,` *可选*) — 与TrainingArguments的`metric_for_best_model`和`early_stopping_patience`一起使用，表示指定指标必须改善多少才能满足提前停止条件。

一个处理提前停止的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

此回调取决于[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)参数*load_best_model_at_end*功能，以在[TrainerState](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerState)中设置best_metric。请注意，如果[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)参数*save_steps*与*eval_steps*不同，则直到下一个保存步骤才会发生早停。

### `class transformers.integrations.TensorBoardCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L579)

```py
( tb_writer = None )
```

参数

+   `tb_writer`（`SummaryWriter`，*可选*）—要使用的写入器。如果未设置，将实例化一个。

一个[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)，将日志发送到[TensorBoard](https://www.tensorflow.org/tensorboard)。

### `class transformers.integrations.WandbCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L665)

```py
( )
```

一个[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)，将指标、媒体、模型检查点记录到[Weights and Biases](https://www.wandb.com/)。

#### `setup`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L690)

```py
( args state model **kwargs )
```

设置可选的Weights & Biases（*wandb*）集成。

如果需要，可以子类化并重写此方法以自定义设置。在[这里](https://docs.wandb.ai/guides/integrations/huggingface)找到更多信息。您还可以重写以下环境变量：

环境：

+   `WANDB_LOG_MODEL`（`str`，*可选*，默认为`"false"`）：是否在训练期间记录模型和检查点。可以是`"end"`，`"checkpoint"`或`"false"`。如果设置为`"end"`，模型将在训练结束时上传。如果设置为`"checkpoint"`，将在每次`args.save_steps`保存时上传检查点。如果设置为`"false"`，模型将不会上传。与`load_best_model_at_end()`一起使用以上传最佳模型。

    在5.0中已弃用

    在🤗 Transformers的第5版中，将废弃将`WANDB_LOG_MODEL`设置为`bool`。

+   `WANDB_WATCH`（`str`，*可选*，默认为`"false"`）：可以是`"gradients"`，`"all"`，`"parameters"`或`"false"`。设置为`"all"`以记录梯度和参数。

+   `WANDB_PROJECT`（`str`，*可选*，默认为`"huggingface"`）：将其设置为自定义字符串以将结果存储在不同的项目中。

+   `WANDB_DISABLED`（`bool`，*可选*，默认为`False`）：是否完全禁用wandb。设置`WANDB_DISABLED=true`以禁用。

### `class transformers.integrations.MLflowCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L933)

```py
( )
```

一个[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)，将日志发送到[MLflow](https://www.mlflow.org/)。可以通过设置环境变量`DISABLE_MLFLOW_INTEGRATION = TRUE`来禁用。

#### `setup`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L952)

```py
( args state model )
```

设置可选的MLflow集成。

环境：

+   `HF_MLFLOW_LOG_ARTIFACTS`（`str`，*可选*）：是否使用MLflow的`.log_artifact()`功能来记录工件。只有在将日志记录到远程服务器（例如s3或GCS）时才有意义。如果设置为`True`或*1*，将在每次在[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)的`output_dir`中保存时将每个保存的检查点复制到本地或远程工件存储。在没有远程存储的情况下使用它将只是将文件复制到您的工件位置。

+   `MLFLOW_EXPERIMENT_NAME` (`str`, *可选*, 默认为`None`)：是否使用MLflow实验名称来启动运行。默认为`None`，将指向MLflow中的`Default`实验。否则，它是要激活的实验的区分大小写名称。如果不存在具有此名称的实验，则将创建一个具有此名称的新实验。

+   `MLFLOW_TAGS` (`str`, *可选*)：要添加到MLflow运行中的标签的键/值对的字符串转储。示例：`os.environ['MLFLOW_TAGS']='{"release.candidate": "RC1", "release.version": "2.2.0"}'`。

+   `MLFLOW_NESTED_RUN` (`str`, *可选*)：是否使用MLflow嵌套运行。如果设置为`True`或*1*，将在当前运行内创建一个嵌套运行。

+   `MLFLOW_RUN_ID` (`str`, *可选*)：允许重新附加到现有运行，这在从检查点恢复训练时可能很有用。当设置了`MLFLOW_RUN_ID`环境变量时，`start_run`尝试恢复具有指定运行ID的运行，其他参数将被忽略。

+   `MLFLOW_FLATTEN_PARAMS` (`str`, *可选*, 默认为`False`)：是否在记录之前展平参数字典。

### `class transformers.integrations.AzureMLCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L910)

```py
( azureml_run = None )
```

一个[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)，将日志发送到[AzureML](https://pypi.org/project/azureml-sdk/)。

### `class transformers.integrations.CodeCarbonCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1399)

```py
( )
```

一个[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)，用于跟踪训练的CO2排放量。

### `class transformers.integrations.NeptuneCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1128)

```py
( api_token: Optional = None project: Optional = None name: Optional = None base_namespace: str = 'finetuning' run = None log_parameters: bool = True log_checkpoints: Optional = None **neptune_run_kwargs )
```

参数

+   `api_token` (`str`, *可选*) — 在注册时获得的Neptune API令牌。如果已将令牌保存到`NEPTUNE_API_TOKEN`环境变量中，可以省略此参数（强烈建议）。在[文档](https://docs.neptune.ai/setup/installation)中查看完整的设置说明。

+   `project` (`str`, *可选*) — Neptune项目的名称，格式为“workspace-name/project-name”。您可以在Neptune中的项目设置 -> 属性中找到并复制名称。如果为None（默认），则使用`NEPTUNE_PROJECT`环境变量的值。

+   `name` (`str`, *可选*) — 运行的自定义名称。

+   `base_namespace` (`str`, 可选, 默认为“finetuning”) — 在Neptune运行中，将包含回调记录的所有元数据的根命名空间。

+   `log_parameters` (`bool`, *可选*, 默认为`True`) — 如果为True，则记录Trainer提供的所有参数和模型参数。

+   `log_checkpoints` (`str`, *可选*) — 如果为“same”，则在Trainer保存检查点时上传检查点。如果为“last”，则仅上传最近保存的检查点。如果为“best”，则上传最佳检查点（在Trainer保存的检查点中选择）。如果为`None`，则不上传检查点。

+   `run` (`Run`, *可选*) — 如果要继续记录到现有运行中，请传递一个Neptune运行对象。在[文档](https://docs.neptune.ai/logging/to_existing_object)中了解更多关于恢复运行的信息。

+   *`*neptune_run_kwargs` (*可选*) — 传递给[`neptune.init_run()`](https://docs.neptune.ai/api/neptune#init_run)函数的其他关键字参数，当创建新运行时。

将日志发送到[Neptune](https://app.neptune.ai)的TrainerCallback。

有关说明和示例，请参阅Neptune文档中的[Transformers集成指南](https://docs.neptune.ai/integrations/transformers)。

### `class transformers.integrations.ClearMLCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1428)

```py
( )
```

一个将日志发送到[ClearML](https://clear.ml/)的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

环境：

+   `CLEARML_PROJECT` (`str`, *可选*, 默认为 `HuggingFace Transformers`): ClearML项目名称。

+   `CLEARML_TASK` (`str`, *可选*, 默认为 `Trainer`): ClearML任务名称。

+   `CLEARML_LOG_MODEL` (`bool`, *可选*, 默认为 `False`): 是否在训练期间将模型记录为工件。

### `class transformers.integrations.DagsHubCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1068)

```py
( )
```

一个将日志记录到[DagsHub](https://dagshub.com/)的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。扩展`MLflowCallback`

### `setup`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1082)

```py
( *args **kwargs )
```

设置DagsHub的日志记录集成。

环境：

+   `HF_DAGSHUB_LOG_ARTIFACTS` (`str`, *可选*): 是否保存实验的数据和模型工件。默认为`False`。

### `class transformers.integrations.FlyteCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1549)

```py
( save_log_history: bool = True sync_checkpoints: bool = True )
```

参数

+   `save_log_history` (`bool`, *可选*, 默认为 `True`) — 当设置为True时，训练日志将保存为Flyte Deck。

+   `sync_checkpoints` (`bool`, *可选*, 默认为 `True`) — 当设置为True时，检查点将与Flyte同步，并可用于在中断的情况下恢复训练。

一个将日志发送到[Flyte](https://flyte.org/)的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。注意：此回调仅在Flyte任务内起作用。

示例：

```py
# Note: This example skips over some setup steps for brevity.
from flytekit import current_context, task

@task
def train_hf_transformer():
    cp = current_context().checkpoint
    trainer = Trainer(..., callbacks=[FlyteCallback()])
    output = trainer.train(resume_from_checkpoint=cp.restore())
```

### `class transformers.integrations.DVCLiveCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1612)

```py
( live: Optional = None log_model: Union = None **kwargs )
```

参数

+   `live` (`dvclive.Live`, *可选*, 默认为 `None`) — 可选的Live实例。如果为None，则将使用**kwargs创建一个新实例。

+   `log_model` (Union[Literal[`"all"`], bool], *可选*, 默认为 `None`) — 是否使用`dvclive.Live.log_artifact()`来记录[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)创建的检查点。如果设置为`True`，则在训练结束时记录最终检查点。如果设置为`"all"`，则在每个检查点处记录整个[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)的`output_dir`。

一个将日志发送到[DVCLive](https://www.dvc.org/doc/dvclive)的[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

在`setup`中使用下面的环境变量来配置集成。要在这些环境变量之外自定义此回调，请参阅[此处](https://dvc.org/doc/dvclive/ml-frameworks/huggingface)。

#### `setup`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/integration_utils.py#L1648)

```py
( args state model )
```

设置可选的DVCLive集成。要在环境变量之外自定义此回调，请参阅[此处](https://dvc.org/doc/dvclive/ml-frameworks/huggingface)。

环境：

+   `HF_DVCLIVE_LOG_MODEL` (`str`, *可选*): 是否使用`dvclive.Live.log_artifact()`来记录[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)创建的检查点。如果设置为`True`或*1*，则在训练结束时记录最终检查点。如果设置为`all`，则在每个检查点处记录整个[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)的`output_dir`。

## TrainerCallback

### `class transformers.TrainerCallback`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L175)

```py
( )
```

参数

+   `args` ([TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)) — 用于实例化[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)的训练参数。

+   `state` ([TrainerState](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerState)) — [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)的当前状态。

+   `control` ([TrainerControl](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerControl)) — 返回给[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)并可用于做出一些决策的对象。

+   `model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)或`torch.nn.Module`) — 正在训练的模型。

+   `tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)) — 用于编码数据的分词器。

+   `optimizer` (`torch.optim.Optimizer`) — 用于训练步骤的优化器。

+   `lr_scheduler` (`torch.optim.lr_scheduler.LambdaLR`) — 用于设置学习率的调度器。

+   `train_dataloader` (`torch.utils.data.DataLoader`, *optional*) — 用于训练的当前数据加载器。

+   `eval_dataloader` (`torch.utils.data.DataLoader`, *optional*) — 用于训练的当前数据加载器。

+   `metrics` (`Dict[str, float]`) — 上次评估阶段计算的指标。

    这些只能在事件`on_evaluate`中访问。

+   `logs` (`Dict[str, float]`) — 要记录的值。

    这些只能在事件`on_log`中访问。

一个用于在某些事件中检查训练循环状态并做出一些决策的对象类。在每个事件中，以下参数都是可用的：

`control`对象是唯一可以被回调函数更改的对象，如果更改了`control`的事件应该返回修改后的版本。

参数`args`、`state`和`control`对于所有事件都是位置参数，其他参数都被分组在`kwargs`中。您可以在事件的签名中解包您需要的参数。例如，查看简单的[PrinterCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.PrinterCallback)的代码。

示例：

```py
class PrinterCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        _ = logs.pop("total_flos", None)
        if state.is_local_process_zero:
            print(logs)
```

#### `on_epoch_begin`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L244)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在一个epoch开始时调用的事件。

#### `on_epoch_end`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L250)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在一个epoch结束时调用的事件。

#### `on_evaluate`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L276)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在评估阶段后调用的事件。

#### `on_init_end`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L226)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)初始化结束时调用的事件。

#### `on_log`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L294)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在记录最后日志后调用的事件。

#### `on_predict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L282)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl metrics **kwargs )
```

在成功预测后调用的事件。

#### `on_prediction_step`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L300)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在预测步骤后调用的事件。

#### `on_save`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L288)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在保存检查点后调用的事件。

#### `on_step_begin`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L256)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在训练步骤开始时调用的事件。如果使用梯度累积，一个训练步骤可能需要多个输入。

#### `on_step_end`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L269)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在训练步骤结束时调用的事件。如果使用梯度累积，一个训练步骤可能需要多个输入。

#### `on_substep_end`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L263)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在梯度累积期间子步骤结束时调用的事件。

#### `on_train_begin`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L232)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在训练开始时调用的事件。

`on_train_end`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L238)

```py
( args: TrainingArguments state: TrainerState control: TrainerControl **kwargs )
```

在训练结束时调用的事件。

这是一个如何在PyTorch [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 中注册自定义回调的示例：

```py
class MyCallback(TrainerCallback):
    "A callback that prints a message at the beginning of training"

    def on_train_begin(self, args, state, control, **kwargs):
        print("Starting training")

trainer = Trainer(
    model,
    args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    callbacks=[MyCallback],  # We can either pass the callback class this way or an instance of it (MyCallback())
)
```

另一种注册回调的方法是调用`trainer.add_callback()`如下：

```py
trainer = Trainer(...)
trainer.add_callback(MyCallback)
# Alternatively, we can pass an instance of the callback class
trainer.add_callback(MyCallback())
```

## TrainerState

### `class transformers.TrainerState`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L34)

```py
( epoch: Optional = None global_step: int = 0 max_steps: int = 0 logging_steps: int = 500 eval_steps: int = 500 save_steps: int = 500 train_batch_size: int = None num_train_epochs: int = 0 num_input_tokens_seen: int = 0 total_flos: float = 0 log_history: List = None best_metric: Optional = None best_model_checkpoint: Optional = None is_local_process_zero: bool = True is_world_process_zero: bool = True is_hyper_param_search: bool = False trial_name: str = None trial_params: Dict = None )
```

参数

+   `epoch` (`float`, *可选*) — 仅在训练期间设置，表示训练所处的时代（小数部分表示当前时代完成的百分比）。

+   `global_step` (`int`, *可选*, 默认为0) — 在训练过程中，表示已完成的更新步骤数量。

+   `max_steps` (`int`, *可选*, 默认为0) — 当前训练要执行的更新步骤数量。

+   `logging_steps` (`int`, *可选*, 默认为500) — 每X个更新步骤记录一次日志

+   `eval_steps` (`int`, *可选*) — 每X步运行一次评估。

+   `save_steps` (`int`, *可选*, 默认为500) — 每X个更新步骤保存一次检查点。

+   `train_batch_size` (`int`, *可选*) — 训练数据加载器的批量大小。仅在使用`auto_find_batch_size`时需要。

+   `num_input_tokens_seen` (`int`, *可选*, 默认为0) — 训练期间看到的标记数量（输入标记数量，而不是预测标记数量）。

+   `total_flos` (`float`, *可选*, 默认为0) — 自训练开始以来模型执行的浮点操作总数（存储为浮点数以避免溢出）。

+   `log_history` (`List[Dict[str, float]]`, *可选*) — 自训练开始以来完成的日志列表。

+   `best_metric` (`float`, *可选*) — 跟踪最佳模型时，迄今为止遇到的最佳指标的值。

+   `best_model_checkpoint` (`str`, *可选*) — 跟踪最佳模型时，迄今为止遇到的最佳模型的检查点名称的值。

+   `is_local_process_zero` (`bool`, *可选*, 默认为`True`) — 是否这个进程是本地（例如，在多台机器上以分布式方式训练时，是一台机器上的主进程）。

+   `is_world_process_zero` (`bool`, *可选*, 默认为`True`) — 是否这个进程是全局主进程（在多台机器上以分布式方式训练时，只有一个进程会是`True`）。

+   `is_hyper_param_search` (`bool`, *可选*, 默认为`False`) — 是否正在使用Trainer.hyperparameter_search进行超参数搜索。这将影响数据在TensorBoard中记录的方式。

一个包含将在检查点时保存的[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)内部状态的类，并传递给[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)。

在这个类中，一个步骤被理解为一个更新步骤。当使用梯度累积时，一个更新步骤可能需要多次前向和后向传递：如果使用`gradient_accumulation_steps=n`，则一个更新步骤需要通过*n*批次。

#### `load_from_json`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L117)

```py
( json_path: str )
```

从`json_path`的内容创建一个实例。

#### `save_to_json`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L111)

```py
( json_path: str )
```

将此实例的内容以JSON格式保存在`json_path`中。

## TrainerControl

### `class transformers.TrainerControl`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_callback.py#L125)

```py
( should_training_stop: bool = False should_epoch_stop: bool = False should_save: bool = False should_evaluate: bool = False should_log: bool = False )
```

参数

+   `should_training_stop`（`bool`，*可选*，默认为`False`）—是否应中断训练。

    如果为`True`，则此变量不会被设置回`False`。训练将直接停止。

+   `should_epoch_stop`（`bool`，*可选*，默认为`False`）—当前轮是否应中断。

    如果为`True`，则此变量将在下一轮开始时设置回`False`。

+   `should_save`（`bool`，*可选*，默认为`False`）—模型是否应在此步骤保存。

    如果为`True`，则此变量将在下一步开始时设置回`False`。

+   `should_evaluate`（`bool`，*可选*，默认为`False`）—模型是否应在此步骤进行评估。

    如果为`True`，则此变量将在下一步开始时设置回`False`。

+   `should_log`（`bool`，*可选*，默认为`False`）—是否应在此步骤报告日志。

    如果为`True`，则此变量将在下一步开始时设置回`False`。

处理[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)控制流的类。此类由[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)使用，以在训练循环中激活一些开关。
