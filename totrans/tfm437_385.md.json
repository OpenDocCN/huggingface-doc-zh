["```py\n\nfrom transformers import PatchTSMixerConfig, PatchTSMixerForPrediction\nfrom transformers import Trainer, TrainingArguments,\n\nconfig = PatchTSMixerConfig(context_length = 512, prediction_length = 96)\nmodel = PatchTSMixerForPrediction(config)\ntrainer = Trainer(model=model, args=training_args, \n            train_dataset=train_dataset,\n            eval_dataset=valid_dataset)\ntrainer.train()\nresults = trainer.evaluate(test_dataset)\n```", "```py\n( context_length: int = 32 patch_len: int = 8 num_input_channels: int = 1 patch_stride: int = 8 num_parallel_samples: int = 100 d_model: int = 8 expansion_factor: int = 2 num_layers: int = 3 dropout: float = 0.2 mode: str = 'common_channel' gated_attn: bool = True norm_mlp: str = 'LayerNorm' self_attn: bool = False self_attn_heads: int = 1 use_positional_encoding: bool = False positional_encoding_type: str = 'sincos' scaling: Union = 'std' loss: str = 'mse' init_std: float = 0.02 post_init: bool = False norm_eps: float = 1e-05 mask_type: str = 'random' random_mask_ratio: float = 0.5 num_forecast_mask_patches: Union = [2] mask_value: int = 0 masked_loss: bool = True channel_consistent_masking: bool = True unmasked_channel_indices: Optional = None head_dropout: float = 0.2 distribution_output: str = 'student_t' prediction_length: int = 16 prediction_channel_indices: list = None num_targets: int = 3 output_range: list = None head_aggregation: str = 'max_pool' **kwargs )\n```", "```py\n>>> from transformers import PatchTSMixerConfig, PatchTSMixerModel\n\n>>> # Initializing a default PatchTSMixer configuration\n>>> configuration = PatchTSMixerConfig()\n\n>>> # Randomly initializing a model (with random weights) from the configuration\n>>> model = PatchTSMixerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config: PatchTSMixerConfig mask_input: bool = False )\n```", "```py\n( past_values: Tensor observed_mask: Optional = None output_hidden_states: Optional = False return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerModelOutput or tuple(torch.FloatTensor)\n```", "```py\n( config: PatchTSMixerConfig )\n```", "```py\n( past_values: Tensor observed_mask: Optional = None future_values: Optional = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPredictionOutput or tuple(torch.FloatTensor)\n```", "```py\n( config: PatchTSMixerConfig )\n```", "```py\n( past_values: Tensor future_values: Tensor = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForTimeSeriesClassificationOutput or tuple(torch.FloatTensor)\n```", "```py\n( config: PatchTSMixerConfig )\n```", "```py\n( past_values: Tensor observed_mask: Optional = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPreTrainingOutput or tuple(torch.FloatTensor)\n```", "```py\n( config: PatchTSMixerConfig )\n```", "```py\n( past_values: Tensor future_values: Tensor = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForRegressionOutput or tuple(torch.FloatTensor)\n```"]