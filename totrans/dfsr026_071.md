# ä½¿ç”¨DDPOè¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/training/ddpo](https://huggingface.co/docs/diffusers/training/ddpo)

æ‚¨å¯ä»¥é€šè¿‡ğŸ¤— TRLåº“å’ŒğŸ¤— Diffusersåœ¨å¥–åŠ±å‡½æ•°ä¸Šå¾®è°ƒç¨³å®šæ‰©æ•£ã€‚è¿™æ˜¯é€šè¿‡Blackç­‰äººåœ¨ã€Šä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‹ä¸­ä»‹ç»çš„Denoising Diffusion Policy Optimizationï¼ˆDDPOï¼‰ç®—æ³•å®Œæˆçš„ï¼Œè¯¥ç®—æ³•åœ¨ğŸ¤— TRLä¸­å®ç°ï¼Œå¹¶ä¸”åœ¨[Training Diffusion Models with Reinforcement Learning](https://arxiv.org/abs/2305.13301)ä¸­æœ‰ä»‹ç»ã€‚

è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[DDPOTrainer](https://huggingface.co/docs/trl/v0.7.10/en/trainer#trl.DDPOTrainer)çš„APIå‚è€ƒå’Œ[é€šè¿‡TRLä½¿ç”¨DDPOå¾®è°ƒç¨³å®šæ‰©æ•£æ¨¡å‹](https://huggingface.co/blog/trl-ddpo)åšå®¢æ–‡ç« ã€‚
