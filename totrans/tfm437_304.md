# Bark

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/bark`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bark)

## æ¦‚è¿°

Bark æ˜¯ç”± Suno AI æå‡ºçš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ï¼Œä½äº[suno-ai/bark](https://github.com/suno-ai/bark)ã€‚

Bark ç”± 4 ä¸ªä¸»è¦æ¨¡å‹ç»„æˆï¼š

+   BarkSemanticModelï¼ˆä¹Ÿç§°ä¸ºâ€œæ–‡æœ¬â€æ¨¡å‹ï¼‰ï¼šä¸€ä¸ªå› æœè‡ªå›å½’ Transformer æ¨¡å‹ï¼Œå…¶è¾“å…¥ä¸ºæ ‡è®°åŒ–æ–‡æœ¬ï¼Œå¹¶é¢„æµ‹æ•æ‰æ–‡æœ¬å«ä¹‰çš„è¯­ä¹‰æ–‡æœ¬æ ‡è®°ã€‚

+   BarkCoarseModelï¼ˆä¹Ÿç§°ä¸ºâ€œç²—å£°å­¦â€æ¨¡å‹ï¼‰ï¼šä¸€ä¸ªå› æœè‡ªå›å½’ Transformerï¼Œå…¶è¾“å…¥ä¸º BarkSemanticModel æ¨¡å‹çš„ç»“æœã€‚å®ƒæ—¨åœ¨é¢„æµ‹ EnCodec æ‰€éœ€çš„å‰ä¸¤ä¸ªéŸ³é¢‘ç æœ¬ã€‚

+   BarkFineModelï¼ˆâ€œç²¾ç»†å£°å­¦â€æ¨¡å‹ï¼‰ï¼Œè¿™æ¬¡æ˜¯ä¸€ä¸ªéå› æœè‡ªç¼–ç å™¨ Transformerï¼Œå®ƒæ ¹æ®å…ˆå‰ç æœ¬åµŒå…¥çš„æ€»å’Œè¿­ä»£é¢„æµ‹æœ€åçš„ç æœ¬ã€‚

+   ä» EncodecModel ä¸­é¢„æµ‹äº†æ‰€æœ‰ç æœ¬é€šé“åï¼ŒBark ä½¿ç”¨å®ƒæ¥è§£ç è¾“å‡ºéŸ³é¢‘æ•°ç»„ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå‰ä¸‰ä¸ªæ¨¡å—ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯ä»¥æ”¯æŒæ¡ä»¶è¯´è¯è€…åµŒå…¥ï¼Œä»¥æ ¹æ®ç‰¹å®šé¢„å®šä¹‰çš„å£°éŸ³æ¥è°ƒæ•´è¾“å‡ºå£°éŸ³ã€‚

æ­¤æ¨¡å‹ç”±[Yoach Lacombe (ylacombe)](https://huggingface.co/ylacombe)å’Œ[Sanchit Gandhi (sanchit-gandhi)](https://github.com/sanchit-gandhi)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/suno-ai/bark)æ‰¾åˆ°ã€‚

### ä¼˜åŒ– Bark

Bark å¯ä»¥é€šè¿‡æ·»åŠ å‡ è¡Œé¢å¤–çš„ä»£ç è¿›è¡Œä¼˜åŒ–ï¼Œ**æ˜¾è‘—å‡å°‘å…¶å†…å­˜å ç”¨**å¹¶**åŠ é€Ÿæ¨ç†**ã€‚

#### ä½¿ç”¨åŠç²¾åº¦

é€šè¿‡å°†æ¨¡å‹åŠ è½½ä¸ºåŠç²¾åº¦ï¼Œå¯ä»¥å°†æ¨ç†åŠ é€Ÿå¹¶å‡å°‘å†…å­˜å ç”¨é‡ 50%ã€‚

```py
from transformers import BarkModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16).to(device)
```

#### ä½¿ç”¨ CPU å¸è½½

å¦‚ä¸Šæ‰€è¿°ï¼ŒBark ç”± 4 ä¸ªå­æ¨¡å‹ç»„æˆï¼Œåœ¨éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­æŒ‰é¡ºåºè°ƒç”¨ã€‚æ¢å¥è¯è¯´ï¼Œå½“ä¸€ä¸ªå­æ¨¡å‹åœ¨ä½¿ç”¨æ—¶ï¼Œå…¶ä»–å­æ¨¡å‹å¤„äºç©ºé—²çŠ¶æ€ã€‚

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨ CUDA è®¾å¤‡ï¼Œè¦è·å¾— 80%çš„å†…å­˜å ç”¨å‡å°‘ï¼Œä¸€ä¸ªç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯åœ¨å­æ¨¡å‹ç©ºé—²æ—¶å°†å…¶ä» GPU å¸è½½åˆ° CPUã€‚è¿™ä¸ªæ“ä½œç§°ä¸º*CPU å¸è½½*ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä¸€è¡Œä»£ç æ¥å®ç°ï¼š

```py
model.enable_cpu_offload()
```

è¯·æ³¨æ„ï¼Œåœ¨ä½¿ç”¨æ­¤åŠŸèƒ½ä¹‹å‰ï¼Œå¿…é¡»å®‰è£…ğŸ¤— Accelerateã€‚[è¿™é‡Œæ˜¯å¦‚ä½•å®‰è£…å®ƒçš„æ–¹æ³•ã€‚](https://huggingface.co/docs/accelerate/basic_tutorials/install)

#### ä½¿ç”¨ Better Transformer

Better Transformer æ˜¯ä¸€ä¸ªğŸ¤— Optimum åŠŸèƒ½ï¼Œå¯ä»¥åœ¨åå°æ‰§è¡Œå†…æ ¸èåˆã€‚æ‚¨å¯ä»¥è·å¾— 20%è‡³ 30%çš„é€Ÿåº¦æå‡ï¼Œè€Œæ€§èƒ½ä¸ä¼šé™ä½ã€‚åªéœ€ä¸€è¡Œä»£ç å³å¯å°†æ¨¡å‹å¯¼å‡ºåˆ°ğŸ¤— Better Transformerï¼š

```py
model =  model.to_bettertransformer()
```

è¯·æ³¨æ„ï¼Œåœ¨ä½¿ç”¨æ­¤åŠŸèƒ½ä¹‹å‰ï¼Œå¿…é¡»å®‰è£…ğŸ¤— Optimumã€‚[è¿™é‡Œæ˜¯å¦‚ä½•å®‰è£…å®ƒçš„æ–¹æ³•ã€‚](https://huggingface.co/docs/optimum/installation)

#### ä½¿ç”¨ Flash Attention 2

Flash Attention 2 æ˜¯å‰ä¸€ä¸ªä¼˜åŒ–çš„æ›´å¿«ã€ä¼˜åŒ–ç‰ˆæœ¬ã€‚

##### å®‰è£…

é¦–å…ˆï¼Œæ£€æŸ¥æ‚¨çš„ç¡¬ä»¶æ˜¯å¦ä¸ Flash Attention 2 å…¼å®¹ã€‚æœ€æ–°çš„å…¼å®¹ç¡¬ä»¶åˆ—è¡¨å¯ä»¥åœ¨[å®˜æ–¹æ–‡æ¡£](https://github.com/Dao-AILab/flash-attention#installation-and-features)ä¸­æ‰¾åˆ°ã€‚å¦‚æœæ‚¨çš„ç¡¬ä»¶ä¸ Flash Attention 2 ä¸å…¼å®¹ï¼Œæ‚¨ä»ç„¶å¯ä»¥é€šè¿‡ä¸Šé¢æåˆ°çš„ Better Transformer æ”¯æŒä»æ³¨æ„åŠ›å†…æ ¸ä¼˜åŒ–ä¸­å—ç›Šã€‚

æ¥ä¸‹æ¥ï¼Œ[å®‰è£…](https://github.com/Dao-AILab/flash-attention#installation-and-features)æœ€æ–°ç‰ˆæœ¬çš„ Flash Attention 2ï¼š

```py
pip install -U flash-attn --no-build-isolation
```

##### ç”¨æ³•

è¦ä½¿ç”¨ Flash Attention 2 åŠ è½½æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨[`.from_pretrained`](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)ä¸­ä¼ é€’`attn_implementation="flash_attention_2"`æ ‡å¿—æ¥å®ç°ã€‚æˆ‘ä»¬è¿˜å°†ä»¥åŠç²¾åº¦ï¼ˆä¾‹å¦‚`torch.float16`ï¼‰åŠ è½½æ¨¡å‹ï¼Œå› ä¸ºè¿™å‡ ä¹ä¸ä¼šå¯¹éŸ³é¢‘è´¨é‡é€ æˆé™çº§ï¼Œä½†å†…å­˜ä½¿ç”¨é‡æ˜æ˜¾é™ä½ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«ï¼š

```py
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16, attn_implementation="flash_attention_2").to(device)
```

##### æ€§èƒ½æ¯”è¾ƒ

ä»¥ä¸‹å›¾è¡¨æ˜¾ç¤ºäº†åŸç”Ÿæ³¨æ„åŠ›å®ç°ï¼ˆæ— ä¼˜åŒ–ï¼‰ä¸ Better Transformer å’Œ Flash Attention 2 ä¹‹é—´çš„å»¶è¿Ÿã€‚åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åœ¨ 40GB A100 GPU ä¸Šä½¿ç”¨ PyTorch 2.1 ç”Ÿæˆ 400 ä¸ªè¯­ä¹‰æ ‡è®°ã€‚Flash Attention 2 ä¹Ÿæ¯” Better Transformer æ›´å¿«ï¼Œå¹¶ä¸”éšç€æ‰¹é‡å¤§å°çš„å¢åŠ ï¼Œå…¶æ€§èƒ½ç”šè‡³æ›´å¥½ï¼š

![](img/62ff1093eff6a3b02e14aad370aaa0c2.png)

ä¸¾ä¸ªä¾‹å­ï¼Œåœ¨ NVIDIA A100 ä¸Šï¼Œå½“ä½¿ç”¨æ‰¹é‡å¤§å°ä¸º 16 ç”Ÿæˆ 400 ä¸ªè¯­ä¹‰æ ‡è®°æ—¶ï¼Œæ‚¨å¯ä»¥è·å¾— 17 å€çš„[ååé‡](https://huggingface.co/blog/optimizing-bark#throughput)ï¼Œå¹¶ä¸”ä»ç„¶æ¯”ä½¿ç”¨åŸç”Ÿæ¨¡å‹å®ç°é€å¥ç”Ÿæˆå¥å­å¿« 2 ç§’ã€‚æ¢å¥è¯è¯´ï¼Œæ‰€æœ‰æ ·æœ¬å°†ç”Ÿæˆé€Ÿåº¦æé«˜ 17 å€ã€‚

åœ¨æ‰¹é‡å¤§å°ä¸º 8 æ—¶ï¼Œåœ¨ NVIDIA A100 ä¸Šï¼ŒFlash Attention 2 ä¹Ÿæ¯” Better Transformer å¿« 10%ï¼Œåœ¨æ‰¹é‡å¤§å°ä¸º 16 æ—¶ï¼Œå¿« 25%ã€‚

#### ç»“åˆä¼˜åŒ–æŠ€æœ¯

æ‚¨å¯ä»¥ç»“åˆä¼˜åŒ–æŠ€æœ¯ï¼ŒåŒæ—¶ä½¿ç”¨ CPU å¸è½½ã€åŠç²¾åº¦å’Œ Flash Attention 2ï¼ˆæˆ–ğŸ¤— Better Transformerï¼‰ã€‚

```py
from transformers import BarkModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

# load in fp16 and use Flash Attention 2
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16, attn_implementation="flash_attention_2").to(device)

# enable CPU offload
model.enable_cpu_offload()
```

åœ¨æ¨ç†ä¼˜åŒ–æŠ€æœ¯ä¸Šäº†è§£æ›´å¤šä¿¡æ¯[è¿™é‡Œ](https://huggingface.co/docs/transformers/perf_infer_gpu_one)ã€‚

### ä½¿ç”¨æç¤º

Suno æä¾›äº†å¤šç§è¯­è¨€çš„å£°éŸ³é¢„è®¾åº“[è¿™é‡Œ](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)ã€‚è¿™äº›é¢„è®¾ä¹Ÿä¸Šä¼ åˆ°äº† hub [è¿™é‡Œ](https://huggingface.co/suno/bark-small/tree/main/speaker_embeddings) æˆ– [è¿™é‡Œ](https://huggingface.co/suno/bark/tree/main/speaker_embeddings)ã€‚

```py
>>> from transformers import AutoProcessor, BarkModel

>>> processor = AutoProcessor.from_pretrained("suno/bark")
>>> model = BarkModel.from_pretrained("suno/bark")

>>> voice_preset = "v2/en_speaker_6"

>>> inputs = processor("Hello, my dog is cute", voice_preset=voice_preset)

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

Bark å¯ä»¥ç”Ÿæˆé«˜åº¦é€¼çœŸçš„**å¤šè¯­è¨€**è¯­éŸ³ä»¥åŠå…¶ä»–éŸ³é¢‘ - åŒ…æ‹¬éŸ³ä¹ã€èƒŒæ™¯å™ªéŸ³å’Œç®€å•çš„éŸ³æ•ˆã€‚

```py
>>> # Multilingual speech - simplified Chinese
>>> inputs = processor("æƒŠäººçš„ï¼æˆ‘ä¼šè¯´ä¸­æ–‡")

>>> # Multilingual speech - French - let's use a voice_preset as well
>>> inputs = processor("Incroyable! Je peux gÃ©nÃ©rer du son.", voice_preset="fr_speaker_5")

>>> # Bark can also generate music. You can help it out by adding music notes around your lyrics.
>>> inputs = processor("â™ª Hello, my dog is cute â™ª")

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

è¯¥æ¨¡å‹è¿˜å¯ä»¥äº§ç”Ÿåƒç¬‘ã€å¹æ¯å’Œå“­æ³£ç­‰**éè¯­è¨€äº¤æµ**ã€‚

```py
>>> # Adding non-speech cues to the input text
>>> inputs = processor("Hello uh ... [clears throat], my dog is cute [laughter]")

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

è¦ä¿å­˜éŸ³é¢‘ï¼Œåªéœ€ä»æ¨¡å‹é…ç½®ä¸­è·å–é‡‡æ ·ç‡å’Œä¸€äº› scipy å®ç”¨ç¨‹åºï¼š

```py
>>> from scipy.io.wavfile import write as write_wav

>>> # save audio to disk, but first take the sample rate from the model config
>>> sample_rate = model.generation_config.sample_rate
>>> write_wav("bark_generation.wav", sample_rate, audio_array)
```

## BarkConfig

### `class transformers.BarkConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L219)

```py
( semantic_config: Dict = None coarse_acoustics_config: Dict = None fine_acoustics_config: Dict = None codec_config: Dict = None initializer_range = 0.02 **kwargs )
```

å‚æ•°

+   `semantic_config` (BarkSemanticConfig, *optional*) â€” åº•å±‚è¯­ä¹‰å­æ¨¡å‹çš„é…ç½®ã€‚

+   `coarse_acoustics_config` (BarkCoarseConfig, *optional*) â€” åº•å±‚ç²—ç³™å£°å­¦å­æ¨¡å‹çš„é…ç½®ã€‚

+   `fine_acoustics_config` (BarkFineConfig, *optional*) â€” åº•å±‚ç²¾ç»†å£°å­¦å­æ¨¡å‹çš„é…ç½®ã€‚

+   `codec_config` (AutoConfig, *optional*) â€” åº•å±‚ç¼–è§£ç å™¨å­æ¨¡å‹çš„é…ç½®ã€‚

    ç¤ºä¾‹ â€”

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ BarkModel çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å­æ¨¡å‹é…ç½®å®ä¾‹åŒ– Bark æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚

ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿä¸ Bark [suno/bark](https://huggingface.co/suno/bark)æ¶æ„ç±»ä¼¼çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª PretrainedConfigï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯» PretrainedConfig çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

#### `from_sub_model_configs`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L309)

```py
( semantic_config: BarkSemanticConfig coarse_acoustics_config: BarkCoarseConfig fine_acoustics_config: BarkFineConfig codec_config: PretrainedConfig **kwargs ) â†’ export const metadata = 'undefined';BarkConfig
```

è¿”å›

BarkConfig

é…ç½®å¯¹è±¡çš„å®ä¾‹

ä» bark å­æ¨¡å‹é…ç½®å®ä¾‹åŒ–ä¸€ä¸ª BarkConfigï¼ˆæˆ–æ´¾ç”Ÿç±»ï¼‰ã€‚

## BarkProcessor

### `class transformers.BarkProcessor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L34)

```py
( tokenizer speaker_embeddings = None )
```

å‚æ•°

+   `tokenizer` (PreTrainedTokenizer) â€” PreTrainedTokenizer çš„å®ä¾‹ã€‚

+   `speaker_embeddings` (`Dict[Dict[str]]`, *å¯é€‰*) â€” å¯é€‰çš„åµŒå¥—è¯´è¯è€…åµŒå…¥å­—å…¸ã€‚ç¬¬ä¸€çº§åŒ…å«å£°éŸ³é¢„è®¾åç§°ï¼ˆä¾‹å¦‚`"en_speaker_4"`ï¼‰ã€‚ç¬¬äºŒçº§åŒ…å«`"semantic_prompt"`ã€`"coarse_prompt"`å’Œ`"fine_prompt"`åµŒå…¥ã€‚å€¼å¯¹åº”äºç›¸åº”`np.ndarray`çš„è·¯å¾„ã€‚è¯·å‚é˜…[æ­¤å¤„](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)è·å–`voice_preset_names`åˆ—è¡¨ã€‚

æ„å»ºä¸€ä¸ª Bark å¤„ç†å™¨ï¼Œå°†æ–‡æœ¬æ ‡è®°å™¨å’Œå¯é€‰çš„ Bark å£°éŸ³é¢„è®¾åŒ…è£…æˆä¸€ä¸ªå¤„ç†å™¨ã€‚

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L219)

```py
( text = None voice_preset = None return_tensors = 'pt' max_length = 256 add_special_tokens = False return_attention_mask = True return_token_type_ids = False **kwargs ) â†’ export const metadata = 'undefined';Tuple(BatchEncoding, BatchFeature)
```

å‚æ•°

+   `text` (`str`, `List[str]`, `List[List[str]]`) â€” è¦ç¼–ç çš„åºåˆ—æˆ–åºåˆ—æ‰¹æ¬¡ã€‚æ¯ä¸ªåºåˆ—å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆé¢„åˆ†è¯å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæä¾›çš„åºåˆ—æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆé¢„åˆ†è¯ï¼‰ï¼Œå¿…é¡»è®¾ç½®`is_split_into_words=True`ï¼ˆä»¥æ¶ˆé™¤ä¸åºåˆ—æ‰¹æ¬¡çš„æ­§ä¹‰ï¼‰ã€‚

+   `voice_preset` (`str`, `Dict[np.ndarray]`) â€” å£°éŸ³é¢„è®¾ï¼Œå³è¯´è¯è€…åµŒå…¥ã€‚å®ƒå¯ä»¥æ˜¯æœ‰æ•ˆçš„ voice_preset åç§°ï¼Œä¾‹å¦‚`"en_speaker_1"`ï¼Œæˆ–ç›´æ¥æ˜¯`Bark`çš„æ¯ä¸ªå­æ¨¡å‹çš„`np.ndarray`åµŒå…¥çš„å­—å…¸ã€‚æˆ–è€…å®ƒå¯ä»¥æ˜¯æœ¬åœ°`.npz`å•ä¸ªå£°éŸ³é¢„è®¾çš„æœ‰æ•ˆæ–‡ä»¶åã€‚

+   `return_tensors` (`str`æˆ– TensorType, *å¯é€‰*) â€” å¦‚æœè®¾ç½®ï¼Œå°†è¿”å›ç‰¹å®šæ¡†æ¶çš„å¼ é‡ã€‚å¯æ¥å—çš„å€¼ä¸ºï¼š

    +   `'pt'`: è¿”å› PyTorch `torch.Tensor`å¯¹è±¡ã€‚

    +   `'np'`: è¿”å› NumPy `np.ndarray`å¯¹è±¡ã€‚

è¿”å›

å…ƒç»„(BatchEncoding, BatchFeature)

ä¸€ä¸ªå…ƒç»„ï¼Œç”±ä¸€ä¸ª BatchEncoding ç»„æˆï¼Œå³`tokenizer`çš„è¾“å‡ºï¼Œä»¥åŠä¸€ä¸ª BatchFeatureï¼Œå³å…·æœ‰æ­£ç¡®å¼ é‡ç±»å‹çš„å£°éŸ³é¢„è®¾ã€‚

å‡†å¤‡æ¨¡å‹ä¸€ä¸ªæˆ–å¤šä¸ªåºåˆ—çš„ä¸»è¦æ–¹æ³•ã€‚æ­¤æ–¹æ³•å°†`text`å’Œ`kwargs`å‚æ•°è½¬å‘ç»™ AutoTokenizer çš„`__call__()`ä»¥å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ã€‚è¯¥æ–¹æ³•è¿˜æä¾›äº†ä¸€ä¸ªå£°éŸ³é¢„è®¾ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ•°ç»„å­—å…¸ï¼Œç”¨äºæ¡ä»¶åŒ–`Bark`çš„è¾“å‡ºã€‚å¦‚æœ`voice_preset`æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶åï¼Œåˆ™`kwargs`å‚æ•°å°†è¢«è½¬å‘ç»™ tokenizer å’Œ`cached_file`æ–¹æ³•ã€‚

#### `from_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L64)

```py
( pretrained_processor_name_or_path speaker_embeddings_dict_path = 'speaker_embeddings_path.json' **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str` æˆ– `os.PathLike`) â€” è¿™å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒçš„ BarkProcessor çš„*æ¨¡å‹ ID*ï¼Œæ‰˜ç®¡åœ¨ huggingface.co ä¸Šçš„æ¨¡å‹å­˜å‚¨åº“ä¸­ã€‚æœ‰æ•ˆçš„æ¨¡å‹ ID å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚ `bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚ `dbmdz/bert-base-german-cased`ã€‚

    +   æŒ‡å‘åŒ…å«ä½¿ç”¨ save_pretrained() æ–¹æ³•ä¿å­˜çš„å¤„ç†å™¨çš„*ç›®å½•*è·¯å¾„ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

+   `speaker_embeddings_dict_path` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"speaker_embeddings_path.json"`) â€” åŒ…å«ä½äº `pretrained_model_name_or_path` ä¸­çš„è¯´è¯è€…åµŒå…¥å­—å…¸çš„ `.json` æ–‡ä»¶çš„åç§°ã€‚å¦‚æœä¸º `None`ï¼Œåˆ™ä¸åŠ è½½è¯´è¯è€…åµŒå…¥ã€‚**kwargs â€” ä¼ é€’ç»™ `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å®ä¾‹åŒ–ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸å…³è”çš„ Bark å¤„ç†å™¨ã€‚

#### `save_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L118)

```py
( save_directory speaker_embeddings_dict_path = 'speaker_embeddings_path.json' speaker_embeddings_directory = 'speaker_embeddings' push_to_hub: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str` æˆ– `os.PathLike`) â€” å°†åˆ†è¯å™¨æ–‡ä»¶å’Œè¯´è¯è€…åµŒå…¥ä¿å­˜åœ¨å…¶ä¸­çš„ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºç›®å½•ï¼‰ã€‚

+   `speaker_embeddings_dict_path` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"speaker_embeddings_path.json"`) â€” åŒ…å«è¯´è¯è€…åµŒå…¥åµŒå¥—è·¯å¾„å­—å…¸çš„ `.json` æ–‡ä»¶çš„åç§°ï¼Œå¦‚æœå­˜åœ¨ï¼Œå°†ä½äº `pretrained_model_name_or_path/speaker_embeddings_directory` ä¸­ã€‚

+   `speaker_embeddings_directory` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"speaker_embeddings/"`) â€” è¯´è¯è€…åµŒå…¥æ•°ç»„å°†ä¿å­˜åœ¨å…¶ä¸­çš„æ–‡ä»¶å¤¹çš„åç§°ã€‚

+   `push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°ï¼‰ã€‚kwargs â€” ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†æ­¤å¤„ç†å™¨çš„å±æ€§ï¼ˆåˆ†è¯å™¨ç­‰ï¼‰ä¿å­˜åœ¨æŒ‡å®šç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained() æ–¹æ³•é‡æ–°åŠ è½½ã€‚

## BarkModel

### `class transformers.BarkModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1629)

```py
( config )
```

å‚æ•°

+   `config` (BarkConfig) â€” æ¨¡å‹é…ç½®ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained() æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

å®Œæ•´çš„ Bark æ¨¡å‹ï¼Œä¸€ä¸ªç”± 4 ä¸ªå­æ¨¡å‹ç»„æˆçš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ï¼š

+   BarkSemanticModelï¼ˆä¹Ÿç§°ä¸ºâ€˜æ–‡æœ¬â€™æ¨¡å‹ï¼‰ï¼šä¸€ä¸ªå› æœè‡ªå›å½’å˜æ¢å™¨æ¨¡å‹ï¼Œä»¥æ ‡è®°åŒ–æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶é¢„æµ‹æ•æ‰æ–‡æœ¬å«ä¹‰çš„è¯­ä¹‰æ–‡æœ¬æ ‡è®°ã€‚

+   BarkCoarseModelï¼ˆä¹Ÿç§°ä¸ºâ€˜ç²—å£°å­¦â€™æ¨¡å‹ï¼‰ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå› æœè‡ªå›å½’å˜æ¢å™¨ï¼Œå®ƒæ¥å—ä¸Šä¸€ä¸ªæ¨¡å‹çš„ç»“æœä½œä¸ºè¾“å…¥ã€‚å®ƒæ—¨åœ¨å›å½’å‡ºç¼–ç æ‰€éœ€çš„å‰ä¸¤ä¸ªéŸ³é¢‘ç ä¹¦ã€‚

+   BarkFineModelï¼ˆ'fine acoustics'æ¨¡å‹ï¼‰ï¼Œè¿™æ¬¡æ˜¯ä¸€ä¸ªéå› æœè‡ªåŠ¨ç¼–ç å™¨å˜å‹å™¨ï¼Œå®ƒåŸºäºå‰ä¸€ä¸ªç æœ¬åµŒå…¥çš„æ€»å’Œæ¥è¿­ä»£é¢„æµ‹æœ€åçš„ç æœ¬ã€‚

+   ä» EncodecModel ä¸­é¢„æµ‹å‡ºæ‰€æœ‰ç æœ¬é€šé“åï¼ŒBark ä½¿ç”¨å®ƒæ¥è§£ç è¾“å‡ºéŸ³é¢‘æ•°ç»„ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå‰ä¸‰ä¸ªæ¨¡å—ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯ä»¥æ”¯æŒæ¡ä»¶è¯´è¯è€…åµŒå…¥ï¼Œæ ¹æ®ç‰¹å®šé¢„å®šä¹‰çš„å£°éŸ³æ¥è°ƒæ•´è¾“å‡ºå£°éŸ³ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª PreTrainedModelã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

è¯¥æ¨¡å‹è¿˜æ˜¯ä¸€ä¸ª PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥äº†è§£æ‰€æœ‰ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„äº‹é¡¹ã€‚

#### `generate`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1737)

```py
( input_ids: Optional = None history_prompt: Optional = None return_output_lengths: Optional = None **kwargs ) â†’ export const metadata = 'undefined';By default
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸ºï¼ˆbatch_sizeï¼Œseq_lenï¼‰çš„`Optional[torch.Tensor]`ï¼Œ*å¯é€‰*ï¼‰â€” è¾“å…¥ idã€‚å°†è¢«æˆªæ–­è‡³ 256 ä¸ªæ ‡è®°ã€‚è¯·æ³¨æ„ï¼Œè¾“å‡ºéŸ³é¢‘çš„é•¿åº¦å°†ä¸æ‰¹æ¬¡ä¸­æœ€é•¿çš„ç”Ÿæˆé•¿åº¦ä¸€æ ·ã€‚

+   `history_prompt`ï¼ˆ`Optional[Dict[str,torch.Tensor]]`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰çš„`Bark`è¯´è¯è€…æç¤ºã€‚è¯·æ³¨æ„ï¼Œç›®å‰ï¼Œè¯¥æ¨¡å‹æ¯æ‰¹æ¬¡åªæ¥å—ä¸€ä¸ªè¯´è¯è€…æç¤ºã€‚

+   `kwargs`ï¼ˆ*å¯é€‰*ï¼‰â€” å‰©ä½™çš„å…³é”®å­—å‚æ•°å­—å…¸ã€‚å…³é”®å­—å‚æ•°æœ‰ä¸¤ç§ç±»å‹ï¼š

    +   å¦‚æœæ²¡æœ‰å‰ç¼€ï¼Œå®ƒä»¬å°†ä½œä¸ºæ¯ä¸ªå­æ¨¡å‹çš„`generate`æ–¹æ³•çš„`**kwargs`è¾“å…¥ã€‚

    +   ä½¿ç”¨*semantic_*ã€*coarse_*ã€*fine_*å‰ç¼€ï¼Œå®ƒä»¬å°†ä½œä¸ºè¯­ä¹‰ã€ç²—ç³™å’Œç»†è‡´çš„`generate`æ–¹æ³•çš„è¾“å…¥ã€‚å®ƒä¼˜å…ˆäºæ²¡æœ‰å‰ç¼€çš„å…³é”®å­—ã€‚

    è¿™æ„å‘³ç€æ‚¨å¯ä»¥ä¸ºæ‰€æœ‰å­æ¨¡å‹æŒ‡å®šä¸€ä¸ªç”Ÿæˆç­–ç•¥ï¼Œé™¤äº†ä¸€ä¸ªã€‚

+   `return_output_lengths`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ³¢å½¢é•¿åº¦ã€‚åœ¨æ‰¹å¤„ç†æ—¶å¾ˆæœ‰ç”¨ã€‚

è¿”å›

é»˜è®¤æƒ…å†µä¸‹

+   `audio_waveform`ï¼ˆå½¢çŠ¶ä¸ºï¼ˆbatch_sizeï¼Œseq_lenï¼‰çš„`torch.Tensor`ï¼‰ï¼šç”Ÿæˆçš„éŸ³é¢‘æ³¢å½¢ã€‚å½“`return_output_lengths=True`æ—¶ï¼šè¿”å›ä¸€ä¸ªç”±ä»¥ä¸‹å…ƒç»„ç»„æˆï¼š

+   `audio_waveform`ï¼ˆå½¢çŠ¶ä¸ºï¼ˆbatch_sizeï¼Œseq_lenï¼‰çš„`torch.Tensor`ï¼‰ï¼šç”Ÿæˆçš„éŸ³é¢‘æ³¢å½¢ã€‚

+   `output_lengths`ï¼ˆå½¢çŠ¶ä¸ºï¼ˆbatch_sizeï¼‰çš„`torch.Tensor`ï¼‰ï¼šæ‰¹æ¬¡ä¸­æ¯ä¸ªæ³¢å½¢çš„é•¿åº¦

ä»è¾“å…¥æç¤ºå’Œä¸€ä¸ªé¢å¤–çš„å¯é€‰`Bark`è¯´è¯è€…æç¤ºç”ŸæˆéŸ³é¢‘ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoProcessor, BarkModel

>>> processor = AutoProcessor.from_pretrained("suno/bark-small")
>>> model = BarkModel.from_pretrained("suno/bark-small")

>>> # To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`
>>> voice_preset = "v2/en_speaker_6"

>>> inputs = processor("Hello, my dog is cute, I need him in my life", voice_preset=voice_preset)

>>> audio_array = model.generate(**inputs, semantic_max_new_tokens=100)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

#### `enable_cpu_offload`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1680)

```py
( gpu_id: Optional = 0 )
```

å‚æ•°

+   `gpu_id`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰â€” å­æ¨¡å‹å°†åŠ è½½å’Œå¸è½½çš„ GPU idã€‚

ä½¿ç”¨åŠ é€Ÿå™¨å°†æ‰€æœ‰å­æ¨¡å‹å¸è½½åˆ° CPUï¼Œå‡å°‘å†…å­˜ä½¿ç”¨é‡ï¼Œå¯¹æ€§èƒ½å½±å“è¾ƒå°ã€‚è¯¥æ–¹æ³•åœ¨ä½¿ç”¨æ—¶ä¸€æ¬¡å°†ä¸€ä¸ªå®Œæ•´çš„å­æ¨¡å‹ç§»åŠ¨åˆ° GPUï¼Œå¹¶ä¸”å­æ¨¡å‹åœ¨ GPU ä¸­ä¿æŒï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªå­æ¨¡å‹è¿è¡Œã€‚

## BarkSemanticModel

### `class transformers.BarkSemanticModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L913)

```py
( config )
```

å‚æ•°

+   `config`ï¼ˆBarkSemanticConfigï¼‰â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

Bark è¯­ä¹‰ï¼ˆæˆ–æ–‡æœ¬ï¼‰æ¨¡å‹ã€‚å®ƒä¸ç²—æ¨¡å‹å…±äº«ç›¸åŒçš„æ¶æ„ã€‚è¿™æ˜¯ä¸€ä¸ªç±»ä¼¼äº GPT-2 çš„è‡ªå›å½’æ¨¡å‹ï¼Œé¡¶éƒ¨å¸¦æœ‰è¯­è¨€å»ºæ¨¡å¤´ã€‚æ­¤æ¨¡å‹ç»§æ‰¿è‡ª PreTrainedModelã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºå…¶æ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹ä¹Ÿæ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)

```py
( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )
```

å‚æ•°

+   `input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰- è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœæä¾›å¡«å……ï¼Œåˆ™å°†è¢«å¿½ç•¥ã€‚å¯ä»¥ä½¿ç”¨ AutoTokenizer è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… PreTrainedTokenizer.encode()å’Œ PreTrainedTokenizer.`call`()ã€‚ä»€ä¹ˆæ˜¯è¾“å…¥ IDï¼Ÿ

+   `past_key_values`ï¼ˆ`tuple(tuple(torch.FloatTensor))`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’äº†`use_cache`æˆ–`config.use_cache=True`æ—¶è¿”å›ï¼‰- é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰ 2 ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, embed_size_per_head)`çš„å¼ é‡ã€‚

    åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ã€‚

    å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åçš„`decoder_input_ids`ï¼ˆé‚£äº›æ²¡æœ‰å°†å…¶è¿‡å»çš„é”®å€¼çŠ¶æ€æä¾›ç»™æ­¤æ¨¡å‹çš„æ ‡è®°ï¼‰ï¼Œå½¢çŠ¶ä¸º`(batch_size, 1)`ï¼Œè€Œä¸æ˜¯å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„æ‰€æœ‰`input_ids`ã€‚

+   `attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   å¯¹äºâ€œæœªå±è”½â€çš„æ ‡è®°ï¼Œä¸º 1ï¼Œ

    +   å¯¹äºâ€œå±è”½â€çš„æ ‡è®°ï¼Œä¸º 0ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ

+   `position_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰- æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚

    ä»€ä¹ˆæ˜¯ä½ç½® IDï¼Ÿ

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(encoder_layers, encoder_attention_heads)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºå°†ç¼–ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªâ€œå±è”½â€ã€‚

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢«â€œå±è”½â€ã€‚

+   `input_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, input_sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰- å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚åœ¨è¿™é‡Œï¼Œç”±äº`Bark`çš„ç‰¹æ®Šæ€§ï¼Œå¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œå°†å¿½ç•¥`input_embeds`ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨`input_ids`ã€‚å¦‚æœæœªä½¿ç”¨`past_key_values`ä¸”`use_cache`è®¾ç½®ä¸º`True`ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨`input_embeds`è€Œä¸æ˜¯`input_ids`ã€‚

+   `use_cache`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- å¦‚æœè®¾ç½®ä¸º`True`ï¼Œå°†è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¹¶å¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª ModelOutput è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚

BarkCausalModel çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹è€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

## BarkCoarseModel

### `class transformers.BarkCoarseModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1022)

```py
( config )
```

å‚æ•°

+   `config` (BarkCoarseConfig) â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

Bark ç²—ç³™å£°å­¦æ¨¡å‹ã€‚å®ƒä¸è¯­ä¹‰ï¼ˆæˆ–æ–‡æœ¬ï¼‰æ¨¡å‹å…±äº«ç›¸åŒçš„æ¶æ„ã€‚è¿™æ˜¯ä¸€ä¸ªç±»ä¼¼äº GPT-2 çš„è‡ªå›å½’æ¨¡å‹ï¼Œé¡¶éƒ¨å¸¦æœ‰è¯­è¨€å»ºæ¨¡å¤´ã€‚æ­¤æ¨¡å‹ç»§æ‰¿è‡ª PreTrainedModelã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹ä¹Ÿæ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)

```py
( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )
```

å‚æ•°

+   `input_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`) â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚å¯ä»¥ä½¿ç”¨ AutoTokenizer è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… PreTrainedTokenizer.encode()å’Œ PreTrainedTokenizer.`call`()ã€‚ä»€ä¹ˆæ˜¯è¾“å…¥ IDï¼Ÿ

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, å½“ä¼ é€’`use_cache`å‚æ•°æˆ–è€…`config.use_cache=True`æ—¶è¿”å›) â€” é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰ 2 ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, embed_size_per_head)`çš„å¼ é‡ã€‚

    åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆæŸ¥çœ‹`past_key_values`è¾“å…¥ï¼‰ã€‚

    å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åä¸€ä¸ªå½¢çŠ¶ä¸º`(batch_size, 1)`çš„`decoder_input_ids`ï¼ˆé‚£äº›æ²¡æœ‰å°†å®ƒä»¬çš„è¿‡å»é”®å€¼çŠ¶æ€æä¾›ç»™æ­¤æ¨¡å‹çš„ï¼‰è€Œä¸æ˜¯æ‰€æœ‰å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`input_ids`ã€‚

+   `attention_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   å¯¹äºæœªè¢«`masked`çš„æ ‡è®°ä¸º 1ï¼Œ

    +   å¯¹äºè¢«`masked`çš„æ ‡è®°ä¸º 0ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ

+   `position_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚

    ä»€ä¹ˆæ˜¯ä½ç½® IDï¼Ÿ

+   `head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(encoder_layers, encoder_attention_heads)`ï¼Œ*å¯é€‰*) â€” ç”¨äºä½¿ç¼–ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¸­ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æ˜¯`æœªå±è”½`ã€‚

    +   0 è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚

+   `input_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, input_sequence_length, hidden_size)`ï¼Œ*å¯é€‰*) â€” å¯é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚åœ¨è¿™é‡Œï¼Œç”±äº`Bark`çš„ç‰¹æ®Šæ€§ï¼Œå¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œåˆ™å°†å¿½ç•¥`input_embeds`ï¼Œå¿…é¡»ä½¿ç”¨`input_ids`ã€‚å¦‚æœæœªä½¿ç”¨`past_key_values`å¹¶ä¸”`use_cache`è®¾ç½®ä¸º`True`ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨`input_embeds`è€Œä¸æ˜¯`input_ids`ã€‚

+   `use_cache` (`bool`ï¼Œ*å¯é€‰*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚

+   `output_attentions` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›çš„å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª ModelOutput è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚

BarkCausalModel çš„å‰å‘æ–¹æ³•è¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰é…æ–¹ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è°ƒç”¨æ­¤å‡½æ•°ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œå‰å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

## BarkFineModel

### `class transformers.BarkFineModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1243)

```py
( config )
```

å‚æ•°

+   `config` (BarkFineConfig) â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

Bark fine acoustics model. It is a non-causal GPT-like model with `config.n_codes_total` embedding layers and language modeling heads, one for each codebook. This model inherits from PreTrainedModel. Check the superclass documentation for the generic methods the library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads etc.)

æ­¤æ¨¡å‹ä¹Ÿæ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1381)

```py
( codebook_idx: int input_ids: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )
```

å‚æ•°

+   `codebook_idx` (`int`) â€” å°†è¢«é¢„æµ‹çš„ç ä¹¦çš„ç´¢å¼•ã€‚

+   `input_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, number_of_codebooks)`ï¼‰ â€” è¾“å…¥åºåˆ—æ ‡è®°åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚æœ€åˆï¼Œå‰ä¸¤ä¸ªç ä¹¦çš„ç´¢å¼•æ˜¯ä»`coarse`å­æ¨¡å‹ä¸­è·å–çš„ã€‚å…¶ä½™çš„é€šè¿‡é€’å½’é¢„æµ‹å‰é¢é¢„æµ‹çš„é€šé“æ¥é¢„æµ‹ã€‚æ¨¡å‹å¯¹é•¿åº¦ä¸º 1024 çš„çª—å£è¿›è¡Œé¢„æµ‹ã€‚

+   `attention_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” é¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…ï¼š

    +   1 è¡¨ç¤º`æœªè¢« mask`çš„æ ‡è®°ï¼Œ

    +   0 è¡¨ç¤º`masked`çš„æ ‡è®°ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ

+   `position_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚ 

    ä»€ä¹ˆæ˜¯ä½ç½® IDï¼Ÿ

+   `head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(encoder_layers, encoder_attention_heads)`ï¼Œ*å¯é€‰*) â€” åœ¨ç¼–ç å™¨ä¸­å°†æ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨`æœªè¢« mask`ï¼Œ

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚

+   `labels` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” å°šæœªå®ç°ã€‚

+   `input_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, input_sequence_length, hidden_size)`ï¼Œ*å¯é€‰*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœä½¿ç”¨`past_key_values`ï¼Œåˆ™åªéœ€è¾“å…¥æœ€åçš„`input_embeds`ï¼ˆè¯·å‚è§`past_key_values`ï¼‰ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å› ModelOutput è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

BarkFineModel çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°ä¸­å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

## BarkCausalModel

### `class transformers.BarkCausalModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L658)

```py
( config )
```

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)

```py
( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )
```

å‚æ•°

+   `input_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`) â€” è¾“å…¥åºåˆ—æ ‡è®°åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚å¯ä»¥ä½¿ç”¨ AutoTokenizer è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ PreTrainedTokenizer.encode()å’Œ PreTrainedTokenizer.`call`()ã€‚ä»€ä¹ˆæ˜¯è¾“å…¥ IDï¼Ÿ

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’äº†`use_cache`æˆ–`config.use_cache=True`æ—¶è¿”å›) â€” é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰ä¸¤ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, embed_size_per_head)`çš„å¼ é‡ã€‚

    åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚

    å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åä¸€ä¸ªå½¢çŠ¶ä¸º`(batch_size, 1)`çš„`decoder_input_ids`ï¼ˆé‚£äº›æ²¡æœ‰å°†å…¶è¿‡å»çš„é”®å€¼çŠ¶æ€ä¼ é€’ç»™è¯¥æ¨¡å‹çš„ï¼‰è€Œä¸æ˜¯å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„æ‰€æœ‰`input_ids`ã€‚

+   `attention_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   1 è¡¨ç¤ºæ ‡è®°æœªè¢«â€œmaskedâ€ã€‚

    +   å¯¹äºè¢«`masked`çš„æ ‡è®°ä¸º 0ã€‚

    æ³¨æ„åŠ›æ©ç æ˜¯ä»€ä¹ˆï¼Ÿ

+   `position_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚

    ä½ç½® ID æ˜¯ä»€ä¹ˆï¼Ÿ

+   `head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(encoder_layers, encoder_attention_heads)`ï¼Œ*å¯é€‰*) â€” ç”¨äºä½¿ç¼–ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«â€œmaskedâ€ã€‚

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚

+   `input_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, input_sequence_length, hidden_size)`ï¼Œ*å¯é€‰*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚åœ¨è¿™é‡Œï¼Œç”±äº`Bark`çš„ç‰¹æ®Šæ€§ï¼Œå¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œå°†å¿½ç•¥`input_embeds`ï¼Œå¿…é¡»ä½¿ç”¨`input_ids`ã€‚å¦‚æœæœªä½¿ç”¨`past_key_values`ä¸”`use_cache`è®¾ç½®ä¸º`True`ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨`input_embeds`è€Œä¸æ˜¯`input_ids`ã€‚

+   `use_cache` (`bool`, *å¯é€‰*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œå°†è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¹¶å¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚

+   `output_attentions` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª ModelOutput è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šå…ƒç»„ã€‚

BarkCausalModel çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

å°½ç®¡å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹è€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

## BarkCoarseConfig

### `class transformers.BarkCoarseConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L164)

```py
( block_size = 1024 input_vocab_size = 10048 output_vocab_size = 10048 num_layers = 12 num_heads = 12 hidden_size = 768 dropout = 0.0 bias = True initializer_range = 0.02 use_cache = True **kwargs )
```

å‚æ•°

+   `block_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1024) â€” è¯¥æ¨¡å‹å¯èƒ½ä¼šä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚é€šå¸¸å°†å…¶è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ512ã€1024 æˆ– 2048ï¼‰ã€‚

+   `input_vocab_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 10_048) â€” Bark å­æ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨è°ƒç”¨ BarkCoarseModel æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ã€‚é»˜è®¤ä¸º 10_048ï¼Œä½†åº”è°¨æ…è€ƒè™‘æ‰€é€‰å­æ¨¡å‹ã€‚

+   `output_vocab_size` (`int`, *optional*, é»˜è®¤ä¸º 10_048) â€” Bark å­æ¨¡å‹çš„è¾“å‡ºè¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨å‘å‰ä¼ é€’ BarkCoarseModel æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ï¼š`output_ids`ã€‚é»˜è®¤ä¸º 10_048ï¼Œä½†åº”æ ¹æ®æ‰€é€‰å­æ¨¡å‹æ…é‡è€ƒè™‘ã€‚

+   `num_layers` (`int`, *optional*, é»˜è®¤ä¸º 12) â€” ç»™å®šå­æ¨¡å‹ä¸­éšè—å±‚çš„æ•°é‡ã€‚

+   `num_heads` (`int`, *optional*, é»˜è®¤ä¸º 12) â€” Transformer æ¶æ„ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `hidden_size` (`int`, *optional*, é»˜è®¤ä¸º 768) â€” æ¶æ„ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `dropout` (`float`, *optional*, é»˜è®¤ä¸º 0.0) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚

+   `bias` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦åœ¨çº¿æ€§å±‚å’Œå±‚å½’ä¸€åŒ–å±‚ä¸­ä½¿ç”¨åç½®ã€‚

+   `initializer_range` (`float`, *optional*, é»˜è®¤ä¸º 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `use_cache` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æœ€åçš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ï¼‰ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ BarkCoarseModel çš„é…ç½®ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿä¸ Bark [suno/bark](https://huggingface.co/suno/bark)æ¶æ„ç±»ä¼¼çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª PretrainedConfigï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯» PretrainedConfig çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import BarkCoarseConfig, BarkCoarseModel

>>> # Initializing a Bark sub-module style configuration
>>> configuration = BarkCoarseConfig()

>>> # Initializing a model (with random weights) from the suno/bark style configuration
>>> model = BarkCoarseModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## BarkFineConfig

### `class transformers.BarkFineConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L186)

```py
( tie_word_embeddings = True n_codes_total = 8 n_codes_given = 1 **kwargs )
```

å‚æ•°

+   `block_size` (`int`, *optional*, é»˜è®¤ä¸º 1024) â€” æ­¤æ¨¡å‹å¯èƒ½ä¼šä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚é€šå¸¸å°†å…¶è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ512 æˆ– 1024 æˆ– 2048ï¼‰ã€‚

+   `input_vocab_size` (`int`, *optional*, é»˜è®¤ä¸º 10_048) â€” Bark å­æ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨è°ƒç”¨ BarkFineModel æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ï¼š`inputs_ids`ã€‚é»˜è®¤ä¸º 10_048ï¼Œä½†åº”æ ¹æ®æ‰€é€‰å­æ¨¡å‹æ…é‡è€ƒè™‘ã€‚

+   `output_vocab_size` (`int`, *optional*, é»˜è®¤ä¸º 10_048) â€” Bark å­æ¨¡å‹çš„è¾“å‡ºè¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨å‘å‰ä¼ é€’ BarkFineModel æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ï¼š`output_ids`ã€‚é»˜è®¤ä¸º 10_048ï¼Œä½†åº”æ ¹æ®æ‰€é€‰å­æ¨¡å‹æ…é‡è€ƒè™‘ã€‚

+   `num_layers` (`int`, *optional*, é»˜è®¤ä¸º 12) â€” ç»™å®šå­æ¨¡å‹ä¸­éšè—å±‚çš„æ•°é‡ã€‚

+   `num_heads` (`int`, *optional*, é»˜è®¤ä¸º 12) â€” Transformer æ¶æ„ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `hidden_size` (`int`, *optional*, é»˜è®¤ä¸º 768) â€” æ¶æ„ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `dropout` (`float`, *optional*, é»˜è®¤ä¸º 0.0) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚

+   `bias` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦åœ¨çº¿æ€§å±‚å’Œå±‚å½’ä¸€åŒ–å±‚ä¸­ä½¿ç”¨åç½®ã€‚

+   `initializer_range` (`float`, *optional*, defaults to 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `use_cache` (`bool`, *optional*, defaults to `True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æœ€åçš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ï¼‰ã€‚

+   `n_codes_total` (`int`, *optional*, defaults to 8) â€” é¢„æµ‹çš„éŸ³é¢‘ç ä¹¦æ€»æ•°ã€‚ç”¨äºç»†å£°å­¦å­æ¨¡å‹ã€‚

+   `n_codes_given` (`int`, *optional*, defaults to 1) â€” ç²—å£°å­¦å­æ¨¡å‹ä¸­é¢„æµ‹çš„éŸ³é¢‘ç ä¹¦æ•°é‡ã€‚ç”¨äºå£°å­¦å­æ¨¡å‹ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ BarkFineModel çš„é…ç½®ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº Bark [suno/bark](https://huggingface.co/suno/bark)æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª PretrainedConfigï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯» PretrainedConfig çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import BarkFineConfig, BarkFineModel

>>> # Initializing a Bark sub-module style configuration
>>> configuration = BarkFineConfig()

>>> # Initializing a model (with random weights) from the suno/bark style configuration
>>> model = BarkFineModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## BarkSemanticConfig

### `class transformers.BarkSemanticConfig`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L142)

```py
( block_size = 1024 input_vocab_size = 10048 output_vocab_size = 10048 num_layers = 12 num_heads = 12 hidden_size = 768 dropout = 0.0 bias = True initializer_range = 0.02 use_cache = True **kwargs )
```

å‚æ•°

+   `block_size` (`int`, *optional*, defaults to 1024) â€” è¯¥æ¨¡å‹å¯èƒ½ä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚é€šå¸¸è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ512 æˆ– 1024 æˆ– 2048ï¼‰ã€‚

+   `input_vocab_size` (`int`, *optional*, defaults to 10_048) â€” Bark å­æ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨è°ƒç”¨ BarkSemanticModel æ—¶ä¼ é€’çš„`inputs_ids`å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ã€‚é»˜è®¤ä¸º 10_048ï¼Œä½†åº”æ ¹æ®æ‰€é€‰å­æ¨¡å‹æ…é‡è€ƒè™‘ã€‚

+   `output_vocab_size` (`int`, *optional*, defaults to 10_048) â€” Bark å­æ¨¡å‹çš„è¾“å‡ºè¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨ä¼ é€’ BarkSemanticModel æ—¶`output_ids`å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ã€‚é»˜è®¤ä¸º 10_048ï¼Œä½†åº”æ ¹æ®æ‰€é€‰å­æ¨¡å‹æ…é‡è€ƒè™‘ã€‚

+   `num_layers` (`int`, *optional*, defaults to 12) â€” ç»™å®šå­æ¨¡å‹ä¸­çš„éšè—å±‚æ•°é‡ã€‚

+   `num_heads` (`int`, *optional*, defaults to 12) â€” Transformer æ¶æ„ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `hidden_size` (`int`, *optional*, defaults to 768) â€” æ¶æ„ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `dropout` (`float`, *optional*, defaults to 0.0) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¤±æ¦‚ç‡ã€‚

+   `bias` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦åœ¨çº¿æ€§å±‚å’Œå±‚å½’ä¸€åŒ–å±‚ä¸­ä½¿ç”¨åç½®ã€‚

+   `initializer_range` (`float`, *optional*, defaults to 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `use_cache` (`bool`, *optional*, defaults to `True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æœ€åçš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ï¼‰ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ BarkSemanticModel çš„é…ç½®ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº Bark [suno/bark](https://huggingface.co/suno/bark)æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª PretrainedConfigï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯» PretrainedConfig çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import BarkSemanticConfig, BarkSemanticModel

>>> # Initializing a Bark sub-module style configuration
>>> configuration = BarkSemanticConfig()

>>> # Initializing a model (with random weights) from the suno/bark style configuration
>>> model = BarkSemanticModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```
