["```py\n>>> from transformers import CTRLConfig, CTRLModel\n\n>>> # Initializing a CTRL configuration\n>>> configuration = CTRLConfig()\n\n>>> # Initializing a model (with random weights) from the configuration\n>>> model = CTRLModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoTokenizer, CTRLModel\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = CTRLModel.from_pretrained(\"Salesforce/ctrl\")\n\n>>> # CTRL was trained with control codes as the first token\n>>> inputs = tokenizer(\"Opinion My dog is cute\", return_tensors=\"pt\")\n>>> assert inputs[\"input_ids\"][0, 0].item() in tokenizer.control_codes.values()\n\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 5, 1280]\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, CTRLLMHeadModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = CTRLLMHeadModel.from_pretrained(\"Salesforce/ctrl\")\n\n>>> # CTRL was trained with control codes as the first token\n>>> inputs = tokenizer(\"Wikipedia The llama is\", return_tensors=\"pt\")\n>>> assert inputs[\"input_ids\"][0, 0].item() in tokenizer.control_codes.values()\n\n>>> sequence_ids = model.generate(inputs[\"input_ids\"])\n>>> sequences = tokenizer.batch_decode(sequence_ids)\n>>> sequences\n['Wikipedia The llama is a member of the family Bovidae. It is native to the Andes of Peru,']\n\n>>> outputs = model(**inputs, labels=inputs[\"input_ids\"])\n>>> round(outputs.loss.item(), 2)\n9.21\n\n>>> list(outputs.logits.shape)\n[1, 5, 246534]\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, CTRLForSequenceClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = CTRLForSequenceClassification.from_pretrained(\"Salesforce/ctrl\")\n\n>>> # CTRL was trained with control codes as the first token\n>>> inputs = tokenizer(\"Opinion My dog is cute\", return_tensors=\"pt\")\n>>> assert inputs[\"input_ids\"][0, 0].item() in tokenizer.control_codes.values()\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> predicted_class_id = logits.argmax().item()\n>>> model.config.id2label[predicted_class_id]\n'LABEL_0'\n```", "```py\n>>> import torch\n\n>>> torch.manual_seed(42)\n>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n>>> num_labels = len(model.config.id2label)\n>>> model = CTRLForSequenceClassification.from_pretrained(\"Salesforce/ctrl\", num_labels=num_labels)\n\n>>> labels = torch.tensor(1)\n>>> loss = model(**inputs, labels=labels).loss\n>>> round(loss.item(), 2)\n0.35\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, CTRLForSequenceClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = CTRLForSequenceClassification.from_pretrained(\n...     \"Salesforce/ctrl\", problem_type=\"multi_label_classification\"\n... )\n\n>>> # CTRL was trained with control codes as the first token\n>>> inputs = tokenizer(\"Opinion My dog is cute\", return_tensors=\"pt\")\n>>> assert inputs[\"input_ids\"][0, 0].item() in tokenizer.control_codes.values()\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> predicted_class_id = logits.argmax().item()\n>>> model.config.id2label[predicted_class_id]\n'LABEL_0'\n```", "```py\n>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n>>> num_labels = len(model.config.id2label)\n>>> model = CTRLForSequenceClassification.from_pretrained(\"Salesforce/ctrl\", num_labels=num_labels)\n\n>>> num_labels = len(model.config.id2label)\n>>> labels = torch.nn.functional.one_hot(torch.tensor([predicted_class_id]), num_classes=num_labels).to(\n...     torch.float\n... )\n>>> loss = model(**inputs, labels=labels).loss\n>>> loss.backward()\n```", "```py\n>>> from transformers import AutoTokenizer, TFCTRLModel\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = TFCTRLModel.from_pretrained(\"Salesforce/ctrl\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n>>> outputs = model(inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, TFCTRLLMHeadModel\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = TFCTRLLMHeadModel.from_pretrained(\"Salesforce/ctrl\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n>>> outputs = model(inputs)\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoTokenizer, TFCTRLForSequenceClassification\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/ctrl\")\n>>> model = TFCTRLForSequenceClassification.from_pretrained(\"Salesforce/ctrl\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n\n>>> logits = model(**inputs).logits\n\n>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n```", "```py\n>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n>>> num_labels = len(model.config.id2label)\n>>> model = TFCTRLForSequenceClassification.from_pretrained(\"Salesforce/ctrl\", num_labels=num_labels)\n\n>>> labels = tf.constant(1)\n>>> loss = model(**inputs, labels=labels).loss\n```"]