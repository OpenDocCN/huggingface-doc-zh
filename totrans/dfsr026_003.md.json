["```py\n# uncomment to install the necessary libraries in Colab\n#!pip install --upgrade diffusers accelerate transformers\n```", "```py\n>>> from diffusers import DiffusionPipeline\n\n>>> pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", use_safetensors=True)\n```", "```py\n>>> pipeline\nStableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.21.4\",\n  ...,\n  \"scheduler\": [\n    \"diffusers\",\n    \"PNDMScheduler\"\n  ],\n  ...,\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n```", "```py\n>>> pipeline.to(\"cuda\")\n```", "```py\n>>> image = pipeline(\"An image of a squirrel in Picasso style\").images[0]\n>>> image\n```", "```py\n>>> image.save(\"image_of_squirrel_painting.png\")\n```", "```py\n!git lfs install\n!git clone https://huggingface.co/runwayml/stable-diffusion-v1-5\n```", "```py\n>>> pipeline = DiffusionPipeline.from_pretrained(\"./stable-diffusion-v1-5\", use_safetensors=True)\n```", "```py\n>>> from diffusers import EulerDiscreteScheduler\n\n>>> pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", use_safetensors=True)\n>>> pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)\n```", "```py\n>>> from diffusers import UNet2DModel\n\n>>> repo_id = \"google/ddpm-cat-256\"\n>>> model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)\n```", "```py\n>>> model.config\n```", "```py\n>>> import torch\n\n>>> torch.manual_seed(0)\n\n>>> noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)\n>>> noisy_sample.shape\ntorch.Size([1, 3, 256, 256])\n```", "```py\n>>> with torch.no_grad():\n...     noisy_residual = model(sample=noisy_sample, timestep=2).sample\n```", "```py\n>>> from diffusers import DDPMScheduler\n\n>>> scheduler = DDPMScheduler.from_pretrained(repo_id)\n>>> scheduler\nDDPMScheduler {\n  \"_class_name\": \"DDPMScheduler\",\n  \"_diffusers_version\": \"0.21.4\",\n  \"beta_end\": 0.02,\n  \"beta_schedule\": \"linear\",\n  \"beta_start\": 0.0001,\n  \"clip_sample\": true,\n  \"clip_sample_range\": 1.0,\n  \"dynamic_thresholding_ratio\": 0.995,\n  \"num_train_timesteps\": 1000,\n  \"prediction_type\": \"epsilon\",\n  \"sample_max_value\": 1.0,\n  \"steps_offset\": 0,\n  \"thresholding\": false,\n  \"timestep_spacing\": \"leading\",\n  \"trained_betas\": null,\n  \"variance_type\": \"fixed_small\"\n}\n```", "```py\n>>> less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample\n>>> less_noisy_sample.shape\ntorch.Size([1, 3, 256, 256])\n```", "```py\n>>> import PIL.Image\n>>> import numpy as np\n\n>>> def display_sample(sample, i):\n...     image_processed = sample.cpu().permute(0, 2, 3, 1)\n...     image_processed = (image_processed + 1.0) * 127.5\n...     image_processed = image_processed.numpy().astype(np.uint8)\n\n...     image_pil = PIL.Image.fromarray(image_processed[0])\n...     display(f\"Image at step {i}\")\n...     display(image_pil)\n```", "```py\n>>> model.to(\"cuda\")\n>>> noisy_sample = noisy_sample.to(\"cuda\")\n```", "```py\n>>> import tqdm\n\n>>> sample = noisy_sample\n\n>>> for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n...     # 1\\. predict noise residual\n...     with torch.no_grad():\n...         residual = model(sample, t).sample\n\n...     # 2\\. compute less noisy image and set x_t -> x_t-1\n...     sample = scheduler.step(residual, t, sample).prev_sample\n\n...     # 3\\. optionally look at image\n...     if (i + 1) % 50 == 0:\n...         display_sample(sample, i + 1)\n```"]