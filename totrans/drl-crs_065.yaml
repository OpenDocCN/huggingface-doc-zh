- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/learn/deep-rl-course/unit4/quiz](https://huggingface.co/learn/deep-rl-course/unit4/quiz)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/53.7d70e247.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Question.f95a37ca.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: The best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)
    **is to test yourself.** This will help you to find **where you need to reinforce
    your knowledge**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Q1: What are the advantages of policy-gradient over value-based methods? (Check
    all that apply)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Q2: What is the Policy Gradient Theorem?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <details data-svelte-h="svelte-nhcd05"><summary>Solution</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '*The Policy Gradient Theorem* is a formula that will help us to reformulate
    the objective function into a differentiable function that does not involve the
    differentiation of the state distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Policy Gradient](../Images/5a9b6c1a3ee9cf5b0e888fb819446af5.png)</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Q3: What‚Äôs the difference between policy-based methods and policy-gradient
    methods? (Check all that apply)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Q4: Why do we use gradient ascent instead of gradient descent to optimize J(Œ∏)?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Congrats on finishing this Quiz ü•≥, if you missed some elements, take time to
    read the chapter again to reinforce (üòè) your knowledge.
  prefs: []
  type: TYPE_NORMAL
