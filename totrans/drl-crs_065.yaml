- en: Quiz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit4/quiz](https://huggingface.co/learn/deep-rl-course/unit4/quiz)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/learn/deep-rl-course/unit4/quiz](https://huggingface.co/learn/deep-rl-course/unit4/quiz)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)
    **is to test yourself.** This will help you to find **where you need to reinforce
    your knowledge**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 学习和[避免能力错觉](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)的最佳方法**是测试自己**。这将帮助您找到**需要加强知识的地方**。
- en: 'Q1: What are the advantages of policy-gradient over value-based methods? (Check
    all that apply)'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q1: 政策梯度相对于基于价值的方法的优势是什么？（选择所有适用的选项）'
- en: 'Q2: What is the Policy Gradient Theorem?'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q2: 什么是政策梯度定理？'
- en: <details data-svelte-h="svelte-nhcd05"><summary>Solution</summary>
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-nhcd05"><summary>解决方案</summary>
- en: '*The Policy Gradient Theorem* is a formula that will help us to reformulate
    the objective function into a differentiable function that does not involve the
    differentiation of the state distribution.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*政策梯度定理*是一个公式，将帮助我们将目标函数重新表述为一个不涉及状态分布微分的可微函数。'
- en: '![Policy Gradient](../Images/5a9b6c1a3ee9cf5b0e888fb819446af5.png)</details>'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![政策梯度](../Images/5a9b6c1a3ee9cf5b0e888fb819446af5.png)</details>'
- en: 'Q3: What’s the difference between policy-based methods and policy-gradient
    methods? (Check all that apply)'
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q3: 政策基础方法和政策梯度方法之间有什么区别？（选择所有适用的选项）'
- en: 'Q4: Why do we use gradient ascent instead of gradient descent to optimize J(θ)?'
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q4: 为什么我们使用梯度上升而不是梯度下降来优化 J(θ)？'
- en: Congrats on finishing this Quiz 🥳, if you missed some elements, take time to
    read the chapter again to reinforce (😏) your knowledge.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您完成了这个测验🥳，如果您错过了一些元素，请花时间再次阅读章节以加强（😏）您的知识。
