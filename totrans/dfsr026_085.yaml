- en: ONNX Runtime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/diffusers/optimization/onnx](https://huggingface.co/docs/diffusers/optimization/onnx)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/126.561631d4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'ðŸ¤— [Optimum](https://github.com/huggingface/optimum) provides a Stable Diffusion
    pipeline compatible with ONNX Runtime. Youâ€™ll need to install ðŸ¤— Optimum with the
    following command for ONNX Runtime support:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This guide will show you how to use the Stable Diffusion and Stable Diffusion
    XL (SDXL) pipelines with ONNX Runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To load and run inference, use the [ORTStableDiffusionPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionPipeline).
    If you want to load a PyTorch model and convert it to the ONNX format on-the-fly,
    set `export=True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Generating multiple prompts in a batch seems to take too much memory. While
    we look into it, you may need to iterate instead of batching.
  prefs: []
  type: TYPE_NORMAL
- en: 'To export the pipeline in the ONNX format offline and use it later for inference,
    use the [`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then to perform inference (you donâ€™t have to specify `export=True` again):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/fef3f7dc8a705f8b94622883fd936702.png)'
  prefs: []
  type: TYPE_IMG
- en: You can find more examples in ðŸ¤— Optimum [documentation](https://huggingface.co/docs/optimum/),
    and Stable Diffusion is supported for text-to-image, image-to-image, and inpainting.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion XL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To load and run inference with SDXL, use the [ORTStableDiffusionXLPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionXLPipeline):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To export the pipeline in the ONNX format and use it later for inference, use
    the [`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: SDXL in the ONNX format is supported for text-to-image and image-to-image.
  prefs: []
  type: TYPE_NORMAL
