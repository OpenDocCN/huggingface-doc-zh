["```py\nfrom diffusers import AutoPipelineForText2Image\nimport torch\n\npipeline = AutoPipelineForText2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n).to(\"cuda\")\nprompt = \"peasant and dragon combat, wood cutting style, viking era, bevel with rune\"\n\nimage = pipeline(prompt, num_inference_steps=25).images[0]\nimage\n```", "```py\nfrom diffusers import AutoPipelineForImage2Image\nimport torch\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n).to(\"cuda\")\nprompt = \"a portrait of a dog wearing a pearl earring\"\n\nurl = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/1665_Girl_with_a_Pearl_Earring.jpg/800px-1665_Girl_with_a_Pearl_Earring.jpg\"\n\nresponse = requests.get(url)\nimage = Image.open(BytesIO(response.content)).convert(\"RGB\")\nimage.thumbnail((768, 768))\n\nimage = pipeline(prompt, image, num_inference_steps=200, strength=0.75, guidance_scale=10.5).images[0]\nimage\n```", "```py\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image\nimport torch\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True\n).to(\"cuda\")\n\nimg_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\nmask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\ninit_image = load_image(img_url).convert(\"RGB\")\nmask_image = load_image(mask_url).convert(\"RGB\")\n\nprompt = \"A majestic tiger sitting on a bench\"\nimage = pipeline(prompt, image=init_image, mask_image=mask_image, num_inference_steps=50, strength=0.80).images[0]\nimage\n```", "```py\nfrom diffusers import AutoPipelineForImage2Image\nimport torch\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"openai/shap-e-img2img\", torch_dtype=torch.float16, use_safetensors=True\n)\n\"ValueError: AutoPipeline can't find a pipeline linked to ShapEImg2ImgPipeline for None\"\n```", "```py\nfrom diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\nimport torch\n\npipeline_text2img = AutoPipelineForText2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n)\nprint(type(pipeline_text2img))\n\"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>\"\n```", "```py\npipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)\nprint(type(pipeline_img2img))\n\"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'>\"\n```", "```py\nfrom diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\nimport torch\n\npipeline_text2img = AutoPipelineForText2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n    requires_safety_checker=False,\n).to(\"cuda\")\n\npipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)\nprint(pipeline_img2img.config.requires_safety_checker)\n\"False\"\n```", "```py\npipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img, requires_safety_checker=True, strength=0.3)\nprint(pipeline_img2img.config.requires_safety_checker)\n\"True\"\n```"]