["```py\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npip install .\n```", "```py\ncd examples/text_to_image\npip install -r requirements.txt\n```", "```py\naccelerate config\n```", "```py\naccelerate config default\n```", "```py\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config()\n```", "```py\naccelerate launch train_text_to_image_lora.py \\\n  --num_train_epochs=150 \\\n```", "```py\nlora_attn_procs = {}\nfor name in unet.attn_processors.keys():\n    cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n    if name.startswith(\"mid_block\"):\n        hidden_size = unet.config.block_out_channels[-1]\n    elif name.startswith(\"up_blocks\"):\n        block_id = int(name[len(\"up_blocks.\")])\n        hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n    elif name.startswith(\"down_blocks\"):\n        block_id = int(name[len(\"down_blocks.\")])\n        hidden_size = unet.config.block_out_channels[block_id]\n\n    lora_attn_procs[name] = LoRAAttnProcessor(\n        hidden_size=hidden_size,\n        cross_attention_dim=cross_attention_dim,\n        rank=args.rank,\n    )\n\nunet.set_attn_processor(lora_attn_procs)\nlora_layers = AttnProcsLayers(unet.attn_processors)\n```", "```py\noptimizer = optimizer_cls(\n    lora_layers.parameters(),\n    lr=args.learning_rate,\n    betas=(args.adam_beta1, args.adam_beta2),\n    weight_decay=args.adam_weight_decay,\n    eps=args.adam_epsilon,\n)\n```", "```py\nexport MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\nexport OUTPUT_DIR=\"/sddata/finetune/lora/pokemon\"\nexport HUB_MODEL_ID=\"pokemon-lora\"\nexport DATASET_NAME=\"lambdalabs/pokemon-blip-captions\"\n\naccelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\n  --dataset_name=$DATASET_NAME \\\n  --dataloader_num_workers=8 \\\n  --resolution=512 \\\n  --center_crop \\\n  --random_flip \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=4 \\\n  --max_train_steps=15000 \\\n  --learning_rate=1e-04 \\\n  --max_grad_norm=1 \\\n  --lr_scheduler=\"cosine\" \\\n  --lr_warmup_steps=0 \\\n  --output_dir=${OUTPUT_DIR} \\\n  --push_to_hub \\\n  --hub_model_id=${HUB_MODEL_ID} \\\n  --report_to=wandb \\\n  --checkpointing_steps=500 \\\n  --validation_prompt=\"A pokemon with blue eyes.\" \\\n  --seed=1337\n```", "```py\nfrom diffusers import AutoPipelineForText2Image\nimport torch\n\npipeline = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\npipeline.load_lora_weights(\"path/to/lora/model\", weight_name=\"pytorch_lora_weights.safetensors\")\nimage = pipeline(\"A pokemon with blue eyes\").images[0]\n```"]