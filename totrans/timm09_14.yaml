- en: Learning Rate Schedulers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/timm/reference/schedulers](https://huggingface.co/docs/timm/reference/schedulers)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/timm/v0.9.12/en/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/entry/start.c775fc75.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/scheduler.85c25b89.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/singletons.602dd09e.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/paths.2e0ff118.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/entry/app.8203bc6a.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/index.c9837788.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/nodes/0.d2b01217.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/nodes/74.31107412.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/Docstring.288498f9.js">
    <link rel="modulepreload" href="/docs/timm/v0.9.12/en/_app/immutable/chunks/Heading.3097d2ed.js">
  prefs: []
  type: TYPE_NORMAL
- en: This page contains the API reference documentation for learning rate schedulers
    included in `timm`.
  prefs: []
  type: TYPE_NORMAL
- en: Schedulers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Factory functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '#### `timm.scheduler.create_scheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/scheduler_factory.py#L48)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#### `timm.scheduler.create_scheduler_v2`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/scheduler_factory.py#L60)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Scheduler Classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class timm.scheduler.CosineLRScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/cosine_lr.py#L18)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Cosine decay with restarts. This is described in the paper [https://arxiv.org/abs/1608.03983](https://arxiv.org/abs/1608.03983).
  prefs: []
  type: TYPE_NORMAL
- en: Inspiration from [https://github.com/allenai/allennlp/blob/master/allennlp/training/learning_rate_schedulers/cosine.py](https://github.com/allenai/allennlp/blob/master/allennlp/training/learning_rate_schedulers/cosine.py)
  prefs: []
  type: TYPE_NORMAL
- en: 'k-decay option based on `k-decay: A New Method For Learning Rate Schedule`
    - [https://arxiv.org/abs/2004.05909](https://arxiv.org/abs/2004.05909)'
  prefs: []
  type: TYPE_NORMAL
- en: '### `class timm.scheduler.MultiStepLRScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/multistep_lr.py#L10)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '### `class timm.scheduler.PlateauLRScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/plateau_lr.py#L12)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Decay the LR by a factor every time the validation loss plateaus.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class timm.scheduler.PolyLRScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/poly_lr.py#L18)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Polynomial LR Scheduler w/ warmup, noise, and k-decay
  prefs: []
  type: TYPE_NORMAL
- en: 'k-decay option based on `k-decay: A New Method For Learning Rate Schedule`
    - [https://arxiv.org/abs/2004.05909](https://arxiv.org/abs/2004.05909)'
  prefs: []
  type: TYPE_NORMAL
- en: '### `class timm.scheduler.StepLRScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/step_lr.py#L13)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '### `class timm.scheduler.TanhLRScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/pytorch-image-models/blob/v0.9.12/timm/scheduler/tanh_lr.py#L18)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Hyberbolic-Tangent decay with restarts. This is described in the paper [https://arxiv.org/abs/1806.01593](https://arxiv.org/abs/1806.01593)
  prefs: []
  type: TYPE_NORMAL
