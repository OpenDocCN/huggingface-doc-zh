- en: The Pyramid environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/learn/deep-rl-course/unit5/pyramids](https://huggingface.co/learn/deep-rl-course/unit5/pyramids)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/61.01e78d18.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: The goal in this environment is to train our agent to **get the gold brick on
    the top of the Pyramid. To do that, it needs to press a button to spawn a Pyramid,
    navigate to the Pyramid, knock it over, and move to the gold brick at the top**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Pyramids Environment](../Images/536b5b0e927d0d0306e93f4da0268c54.png)'
  prefs: []
  type: TYPE_IMG
- en: The reward function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The reward function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Pyramids Environment](../Images/7a2f490841f116e65eb1238e49c15daf.png)'
  prefs: []
  type: TYPE_IMG
- en: In terms of code, it looks like this
  prefs: []
  type: TYPE_NORMAL
- en: '![Pyramids Reward](../Images/2258bc079947e123a7416e90ca844dbd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To train this new agent that seeks that button and then the Pyramid to destroy,
    we’ll use a combination of two types of rewards:'
  prefs: []
  type: TYPE_NORMAL
- en: The *extrinsic one* given by the environment (illustration above).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But also an *intrinsic* one called **curiosity**. This second will **push our
    agent to be curious, or in other terms, to better explore its environment**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to know more about curiosity, the next section (optional) will explain
    the basics.
  prefs: []
  type: TYPE_NORMAL
- en: The observation space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In terms of observation, we **use 148 raycasts that can each detect objects**
    (switch, bricks, golden brick, and walls.)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/435ad65088b791923ae9504245a941d0.png)'
  prefs: []
  type: TYPE_IMG
- en: We also use a **boolean variable indicating the switch state** (did we turn
    on or off the switch to spawn the Pyramid) and a vector that **contains the agent’s
    speed**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Pyramids obs code](../Images/5882250ca2a7076510ae5ff13d9e2ee7.png)'
  prefs: []
  type: TYPE_IMG
- en: The action space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The action space is **discrete** with four possible actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Pyramids Environment](../Images/e9de67071147567254395b50b513ee1e.png)'
  prefs: []
  type: TYPE_IMG
