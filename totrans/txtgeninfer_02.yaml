- en: Text Generation Inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/text-generation-inference/index](https://huggingface.co/docs/text-generation-inference/index)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/text-generation-inference/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/entry/start.96d64f85.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/scheduler.9680c161.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/singletons.5632daf5.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/index.9d57cde4.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/paths.5eca520f.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/entry/app.48a2a24c.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/index.38d74ee1.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/nodes/0.c01ff294.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/nodes/14.da4a7b1a.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/Heading.74c51a96.js">
  prefs: []
  type: TYPE_NORMAL
- en: Text Generation Inference (TGI) is a toolkit for deploying and serving Large
    Language Models (LLMs). TGI enables high-performance text generation for the most
    popular open-source LLMs, including Llama, Falcon, StarCoder, BLOOM, GPT-NeoX,
    and T5.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text Generation Inference](../Images/d35ba6d3307e9474f5d05c1c873c7b52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Text Generation Inference implements many optimizations and features, such
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple launcher to serve most popular LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production ready (distributed tracing with Open Telemetry, Prometheus metrics)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tensor Parallelism for faster inference on multiple GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Token streaming using Server-Sent Events (SSE)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous batching of incoming requests for increased total throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimized transformers code for inference using [Flash Attention](https://github.com/HazyResearch/flash-attention)
    and [Paged Attention](https://github.com/vllm-project/vllm) on the most popular
    architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantization with [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
    and [GPT-Q](https://arxiv.org/abs/2210.17323)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Safetensors](https://github.com/huggingface/safetensors) weight loading'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Watermarking with [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logits warper (temperature scaling, top-p, top-k, repetition penalty)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stop sequences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log probabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Custom Prompt Generation: Easily generate text by providing custom prompts
    to guide the model’s output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fine-tuning Support: Utilize fine-tuned models for specific tasks to achieve
    higher accuracy and performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Text Generation Inference is used in production by multiple projects, such
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Hugging Chat](https://github.com/huggingface/chat-ui), an open-source interface
    for open-access models, such as Open Assistant and Llama'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAssistant](https://open-assistant.io/), an open-source community effort
    to train LLMs in the open'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[nat.dev](http://nat.dev/), a playground to explore and compare LLMs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
