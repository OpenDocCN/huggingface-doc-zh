["```py\n>>> import datasets\n>>> from transformers import ClvpProcessor, ClvpModelForConditionalGeneration\n\n>>> # Define the Text and Load the Audio (We are taking an audio example from HuggingFace Hub using `datasets` library).\n>>> text = \"This is an example text.\"\n\n>>> ds = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.cast_column(\"audio\", datasets.Audio(sampling_rate=22050))\n>>> sample = ds[0][\"audio\"]\n\n>>> # Define processor and model.\n>>> processor = ClvpProcessor.from_pretrained(\"susnato/clvp_dev\")\n>>> model = ClvpModelForConditionalGeneration.from_pretrained(\"susnato/clvp_dev\")\n\n>>> # Generate processor output and model output.\n>>> processor_output = processor(raw_speech=sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], text=text, return_tensors=\"pt\")\n>>> generated_output = model.generate(**processor_output)\n```", "```py\n>>> from transformers import ClvpConfig, ClvpModelForConditionalGeneration\n\n>>> # Initializing a ClvpConfig with susnato/clvp_dev style configuration\n>>> configuration = ClvpConfig()\n\n>>> # Initializing a ClvpModelForConditionalGeneration (with random weights) from the susnato/clvp_dev style configuration\n>>> model = ClvpModelForConditionalGeneration(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n\n>>> # We can also initialize a CLVPConfig from a CLVPTextConfig, CLVPSpeechConfig and a CLVPAutoRegressiveConfig\n>>> from transformers import ClvpEncoderConfig, ClvpDecoderConfig\n\n>>> # Initializing a CLVP text, CLVP speech and CLVP decoder configuration\n>>> config_text = ClvpEncoderConfig()\n>>> config_speech = ClvpEncoderConfig()\n>>> decoder_config = ClvpDecoderConfig()\n\n>>> config = ClvpConfig.from_sub_model_configs(config_text, config_speech, decoder_config)\n```", "```py\n>>> from transformers import ClvpEncoderConfig, ClvpEncoder\n\n>>> # Initializing a ClvpEncoderConfig with susnato/clvp_dev style configuration\n>>> encoder_configuration = ClvpEncoderConfig()\n\n>>> # Initializing a ClvpEncoder (with random weights) from the susnato/clvp_dev style configuration\n>>> model = ClvpEncoder(encoder_configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import ClvpDecoderConfig, ClvpDecoder\n\n>>> # Initializing a ClvpDecoderConfig with susnato/clvp_dev style configuration\n>>> decoder_configuration = ClvpDecoderConfig()\n\n>>> # Initializing a ClvpDecoder (with random weights) from the susnato/clvp_dev style configuration\n>>> model = ClvpDecoder(decoder_configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import ClvpTokenizer\n\n>>> tokenizer = ClvpTokenizer.from_pretrained(\"susnato/clvp_dev\")\n>>> tokenizer(\"Hello world\")[\"input_ids\"]\n[62, 84, 28, 2, 179, 79]\n\n>>> tokenizer(\" Hello world\")[\"input_ids\"]\n[2, 62, 84, 28, 2, 179, 79]\n```", "```py\n>>> import datasets\n>>> from transformers import ClvpProcessor, ClvpModelForConditionalGeneration\n\n>>> # Define the Text and Load the Audio (We are taking an audio example from HuggingFace Hub using `datasets` library)\n>>> text = \"This is an example text.\"\n\n>>> ds = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.cast_column(\"audio\", datasets.Audio(sampling_rate=22050))\n>>> _, audio, sr = ds.sort(\"id\").select(range(1))[:1][\"audio\"][0].values()\n\n>>> # Define processor and model\n>>> processor = ClvpProcessor.from_pretrained(\"susnato/clvp_dev\")\n>>> model = ClvpModelForConditionalGeneration.from_pretrained(\"susnato/clvp_dev\")\n\n>>> # processor outputs and model outputs\n>>> processor_output = processor(raw_speech=audio, sampling_rate=sr, text=text, return_tensors=\"pt\")\n>>> outputs = model(\n...     input_ids=processor_output[\"input_ids\"],\n...     input_features=processor_output[\"input_features\"],\n...     return_dict=True,\n... )\n```", "```py\n>>> from transformers import ClvpProcessor, ClvpModelForConditionalGeneration\n\n>>> # Define the Text\n>>> text = \"This is an example text.\"\n\n>>> # Define processor and model\n>>> processor = ClvpProcessor.from_pretrained(\"susnato/clvp_dev\")\n>>> model = ClvpModelForConditionalGeneration.from_pretrained(\"susnato/clvp_dev\")\n\n>>> # Generate processor output and text embeds\n>>> processor_output = processor(text=text, return_tensors=\"pt\")\n>>> text_embeds = model.get_text_features(input_ids=processor_output[\"input_ids\"])\n```", "```py\n>>> import datasets\n>>> from transformers import ClvpProcessor, ClvpModelForConditionalGeneration\n\n>>> # Define the Text and Load the Audio (We are taking an audio example from HuggingFace Hub using `datasets` library)\n>>> text = \"This is an example text.\"\n>>> ds = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.cast_column(\"audio\", datasets.Audio(sampling_rate=22050))\n>>> _, audio, sr = ds.sort(\"id\").select(range(1))[:1][\"audio\"][0].values()\n\n>>> # Define processor and model\n>>> processor = ClvpProcessor.from_pretrained(\"susnato/clvp_dev\")\n>>> model = ClvpModelForConditionalGeneration.from_pretrained(\"susnato/clvp_dev\")\n\n>>> # Generate processor output and model output\n>>> processor_output = processor(raw_speech=audio, sampling_rate=sr, text=text, return_tensors=\"pt\")\n>>> speech_embeds = model.get_speech_features(\n...     input_ids=processor_output[\"input_ids\"], input_features=processor_output[\"input_features\"]\n... )\n```"]