# 评估器

> [https://huggingface.co/docs/evaluate/package_reference/evaluator_classes](https://huggingface.co/docs/evaluate/package_reference/evaluator_classes)

用于自动评估的评估器类。

## 评估器类

使用评估器的主要入口点：

#### `evaluate.evaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/__init__.py#L108)

```py
( task: str = None ) → Evaluator
```

参数

+   `task` (`str`) — 定义将返回哪个评估器的任务。当前接受的任务有：

    +   `"image-classification"`：将返回一个[ImageClassificationEvaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.ImageClassificationEvaluator)。

    +   `"question-answering"`：将返回一个[QuestionAnsweringEvaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.QuestionAnsweringEvaluator)。

    +   `"text-classification"`（别名为`"sentiment-analysis"`可用）：将返回一个[TextClassificationEvaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.TextClassificationEvaluator)。

    +   `"token-classification"`：将返回一个[TokenClassificationEvaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.TokenClassificationEvaluator)。

返回

[Evaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.Evaluator)

适用于该任务的评估器。

实用工厂方法，用于构建一个[Evaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.Evaluator)。评估器封装了一个任务和一个默认的度量名称。它们利用`transformers`中的`pipeline`功能来简化对给定任务的多种模型、数据集和度量的评估。

示例：

```py
>>> from evaluate import evaluator
>>> # Sentiment analysis evaluator
>>> evaluator("sentiment-analysis")
```

所有评估器类的基类：

### `class evaluate.Evaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L102)

```py
( task: str default_metric_name: str = None )
```

评估器类是所有评估器继承的类。请参考此类以获取不同评估器共享的方法。实现评估器操作的基类。

#### `check_required_columns`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L295)

```py
( data: typing.Union[str, datasets.arrow_dataset.Dataset] columns_names: typing.Dict[str, str] )
```

参数

+   `data` (`str`或`Dataset`) — 指定我们将在其上运行评估的数据集。

+   `columns_names` (`List[str]`) —

+   要在数据集中检查的列名列表。键是传递给compute()方法的参数，—

+   当值是要检查的列名时。—

确保数据集中存在用于评估的所需列。

#### `compute_metric`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L457)

```py
( metric: EvaluationModule metric_inputs: typing.Dict strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 random_state: typing.Optional[int] = None )
```

计算并返回度量。

#### `get_dataset_split`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L312)

```py
( data subset = None split = None ) → split
```

参数

+   `data` (`str`) — 数据集名称

+   `subset` (`str`) — 具有多个配置的数据集的配置名称（例如'glue/cola'）

+   `split` (`str`，默认为None）— 要使用的拆分

返回

`split`

包含要使用的拆分的`str`

如果未给出None，则推断要使用的拆分。

#### `load_data`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L329)

```py
( data: typing.Union[str, datasets.arrow_dataset.Dataset] subset: str = None split: str = None ) → data (Dataset)
```

参数

+   `data`（`Dataset`或`str`，默认为None）— 指定我们将在其上运行评估的数据集。如果它是

+   `type` `str`，我们将其视为数据集名称，并加载它。否则，我们假设它表示一个预加载的数据集。—

+   `subset` (`str`，默认为None）— 指定要传递给`load_dataset`中的`name`的数据集子集。用于具有多个配置的数据集（例如glue/sst2）。

+   `split` (`str`，默认为None）— 用户定义的数据集拆分名称（例如train，validation，test）。支持切片拆分（test[:n]）。如果未定义且数据为`str`类型，则将通过`choose_split()`自动选择最佳拆分。

返回

数据（`Dataset`）

将用于评估的加载的数据集。

使用给定的子集和拆分加载数据集。

#### `predictions_processor`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L211)

```py
( *args **kwargs )
```

`Evaluator`类的核心方法，用于处理与度量兼容的管道输出。

#### `prepare_data`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L356)

```py
( data: Dataset input_column: str label_column: str *args **kwargs ) → dict
```

参数

+   `data` (`Dataset`) — 指定我们将在其上运行评估的数据集。

+   `input_column` (`str`，默认为`"text"`) — 数据集中包含文本特征的列的名称，由`data`指定。

+   `label_column` (`str`，默认为`"label"`) — 数据集中包含标签的列的名称，由`data`指定。

返回

`dict`

度量输入。`list`：管道输入。

准备数据。

#### `prepare_metric`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L427)

```py
( metric: typing.Union[str, evaluate.module.EvaluationModule] )
```

参数

+   `metric` (`str`或`EvaluationModule`，默认为`None`) — 指定我们在评估器中使用的度量。如果是`str`类型，则将其视为度量名称，并加载它。否则，我们假设它表示预加载的度量。

准备度量。

#### `prepare_pipeline`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L375)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] tokenizer: typing.Union[ForwardRef('PreTrainedTokenizerBase'), ForwardRef('FeatureExtractionMixin')] = None feature_extractor: typing.Union[ForwardRef('PreTrainedTokenizerBase'), ForwardRef('FeatureExtractionMixin')] = None device: int = None )
```

参数

+   `model_or_pipeline` (`str`或`Pipeline`或`Callable`或`PreTrainedModel`或`TFPreTrainedModel`，—

+   `defaults`为`None`) — 如果未指定参数，则我们为任务初始化默认管道。如果参数是`str`类型或是模型实例，则我们使用它来初始化具有给定模型的新`Pipeline`。否则，我们假设参数指定了一个预初始化的管道。

+   `preprocessor` (`PreTrainedTokenizerBase`或`FeatureExtractionMixin`，*可选*，默认为`None`) — 如果`model_or_pipeline`表示我们构建管道的模型，则可以使用该参数来覆盖默认的预处理器。如果`model_or_pipeline`为`None`或预初始化的管道，则忽略此参数。

准备管道。

## 任务特定的评估器

### 图像分类评估器

### `class evaluate.ImageClassificationEvaluator`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/image_classification.py#L45)

```py
( task = 'image-classification' default_metric_name = None )
```

图像分类评估器。此图像分类评估器目前可以从[evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator)中使用默认任务名称`image-classification`加载。此类中的方法假定数据格式与`ImageClassificationPipeline`兼容。

#### `compute`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/image_classification.py#L64)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None feature_extractor: typing.Union[str, ForwardRef('FeatureExtractionMixin'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'image' label_column: str = 'label' label_mapping: typing.Union[typing.Dict[str, numbers.Number], NoneType] = None )
```

参数

+   `model_or_pipeline` (`str`或`Pipeline`或`Callable`或`PreTrainedModel`或`TFPreTrainedModel`，默认为`None`) — 如果未指定参数，则我们为任务初始化默认管道（在本例中为`text-classification`或其别名 - `sentiment-analysis`）。如果参数是`str`类型或是模型实例，则我们使用它来初始化具有给定模型的新`Pipeline`。否则，我们假设参数指定了一个预初始化的管道。

+   `data` (`str`或`Dataset`，默认为`None`) — 指定我们将在其上运行评估的数据集。如果是`str`类型，则将其视为数据集名称，并加载它。否则，我们假设它表示预加载的数据集。

+   `subset` (`str`，默认为`None`) — 定义要加载的数据集子集。如果传递`None`，则加载默认子集。

+   `split` (`str`，默认为`None`) — 定义要加载的数据集拆分。如果传递`None`，则根据`choose_split`函数推断。

+   `metric` (`str`或`EvaluationModule`，默认为`None`) — 指定我们在评估器中使用的度量。如果是`str`类型，则将其视为度量名称，并加载它。否则，我们假设它表示预加载的度量。

+   tokenizer（`str`或`PreTrainedTokenizer`，*可选*，默认为`None`）—如果`model_or_pipeline`表示我们构建pipeline的模型，则可以使用此参数来覆盖默认的分词器。如果`model_or_pipeline`为`None`或预初始化的pipeline，则我们忽略此参数。

+   strategy（`Literal["simple", "bootstrap"]`，默认为“simple”）—指定评估策略。可能的值为：

    +   “简单” - 我们评估指标并返回分数。

    +   `bootstrap` - 除了计算指标分数外，我们还使用`scipy`的`bootstrap`方法为返回的每个指标键计算置信区间[https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   confidence_level（`float`，默认为`0.95`）—如果选择了`bootstrap`策略，则传递给`bootstrap`的`confidence_level`值。

+   n_resamples（`int`，默认为`9999`）—如果选择了`bootstrap`策略，则传递给`bootstrap`的`n_resamples`值。

+   device（`int`，默认为`None`）—用于CPU/GPU支持的设备序号。将其设置为-1将利用CPU，正整数将在关联的CUDA设备ID上运行模型。如果提供了`None`，它将被推断，并且如果可用，则使用CUDA:0，否则使用CPU。

+   random_state（`int`，*可选*，默认为`None`）—如果选择了`bootstrap`策略，则传递给`bootstrap`的`random_state`值。用于调试。

计算给定pipeline和数据集组合的指标。

示例：

```py
>>> from evaluate import evaluator
>>> from datasets import load_dataset
>>> task_evaluator = evaluator("image-classification")
>>> data = load_dataset("beans", split="test[:40]")
>>> results = task_evaluator.compute(
>>>     model_or_pipeline="nateraw/vit-base-beans",
>>>     data=data,
>>>     label_column="labels",
>>>     metric="accuracy",
>>>     label_mapping={'angular_leaf_spot': 0, 'bean_rust': 1, 'healthy': 2},
>>>     strategy="bootstrap"
>>> )
```

### QuestionAnsweringEvaluator

### `class evaluate.QuestionAnsweringEvaluator`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/question_answering.py#L74)

```py
( task = 'question-answering' default_metric_name = None )
```

问答评估器。此评估器处理[**提取式**问答](https://huggingface.co/docs/transformers/task_summary#extractive-question-answering)，其中问题的答案从上下文中提取出来。

此问答评估器目前可以从[evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator)中使用默认任务名称`question-answering`加载。

此类中的方法假定数据格式与[`QuestionAnsweringPipeline`](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline)兼容。

#### `compute`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/question_answering.py#L143)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None question_column: str = 'question' context_column: str = 'context' id_column: str = 'id' label_column: str = 'answers' squad_v2_format: typing.Optional[bool] = None )
```

参数

+   model_or_pipeline（`str`或`Pipeline`或`Callable`或`PreTrainedModel`或`TFPreTrainedModel`，默认为`None`）—如果未指定参数，则我们会为任务初始化默认的pipeline（在本例中为`text-classification`或其别名 - `sentiment-analysis`）。如果参数是`str`类型或是模型实例，则我们将使用它来初始化一个新的具有给定模型的`Pipeline`。否则，我们假设参数指定了一个预初始化的pipeline。

+   data（`str`或`Dataset`，默认为`None`）—指定我们将在其上运行评估的数据集。如果是`str`类型，我们将其视为数据集名称，并加载它。否则，我们假设它表示预加载的数据集。

+   subset（`str`，默认为`None`）—定义要加载的数据集子集。如果传递了`None`，则加载默认子集。

+   split（`str`，默认为`None`）—定义要加载的数据集拆分。如果传递了`None`，则根据`choose_split`函数进行推断。

+   metric（`str`或`EvaluationModule`，默认为`None`）—指定评估器中使用的指标。如果是`str`类型，我们将其视为指标名称，并加载它。否则，我们假设它表示预加载的指标。

+   `tokenizer`（`str`或`PreTrainedTokenizer`，*可选*，默认为`None`）— 如果`model_or_pipeline`表示我们构建管道的模型，则可以使用此参数来覆盖默认的分词器。如果`model_or_pipeline`为`None`或预初始化的管道，则忽略此参数。

+   `strategy`（`Literal["simple", "bootstrap"]`，默认为“simple”）— 指定评估策略。可能的值为：

    +   `"simple"` - 我们评估度量标准并返回分数。

    +   `"bootstrap"` - 在计算度量分数的基础上，我们使用`scipy`的`bootstrap`方法计算每个返回的度量键的置信区间[https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   `confidence_level`（`float`，默认为`0.95`）— 如果选择了`"bootstrap"`策略，则传递给`bootstrap`的`confidence_level`值。

+   `n_resamples`（`int`，默认为`9999`）— 如果选择了`"bootstrap"`策略，则传递给`bootstrap`的`n_resamples`值。

+   `device`（`int`，默认为`None`）— 用于CPU/GPU支持的设备序数。将其设置为-1将利用CPU，正整数将在关联的CUDA设备ID上运行模型。如果提供`None`，它将被推断，如果可用，则使用CUDA:0，否则使用CPU。

+   `random_state`（`int`，*可选*，默认为`None`）— 如果选择了`"bootstrap"`策略，则传递给`bootstrap`的`random_state`值。用于调试。

为给定的管道和数据集组合计算度量标准。

示例：

```py
>>> from evaluate import evaluator
>>> from datasets import load_dataset
>>> task_evaluator = evaluator("question-answering")
>>> data = load_dataset("squad", split="validation[:2]")
>>> results = task_evaluator.compute(
>>>     model_or_pipeline="sshleifer/tiny-distilbert-base-cased-distilled-squad",
>>>     data=data,
>>>     metric="squad",
>>> )
```

支持答案可能在上下文中缺失的数据集，例如SQuAD v2数据集。在这种情况下，最好在`compute()`调用中传递`squad_v2_format=True`。

```py
>>> from evaluate import evaluator
>>> from datasets import load_dataset
>>> task_evaluator = evaluator("question-answering")
>>> data = load_dataset("squad_v2", split="validation[:2]")
>>> results = task_evaluator.compute(
>>>     model_or_pipeline="mrm8488/bert-tiny-finetuned-squadv2",
>>>     data=data,
>>>     metric="squad_v2",
>>>     squad_v2_format=True,
>>> )
```

### TextClassificationEvaluator

### `class evaluate.TextClassificationEvaluator`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text_classification.py#L47)

```py
( task = 'text-classification' default_metric_name = None )
```

文本分类评估器。这个文本分类评估器目前可以从[evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator)中加载，默认任务名称为`text-classification`或使用`"sentiment-analysis"`别名。该类中的方法假定数据格式与`TextClassificationPipeline`兼容 - 一个文本特征作为输入，一个分类标签作为输出。

#### `compute`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text_classification.py#L85)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None feature_extractor: typing.Union[str, ForwardRef('FeatureExtractionMixin'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' second_input_column: typing.Optional[str] = None label_column: str = 'label' label_mapping: typing.Union[typing.Dict[str, numbers.Number], NoneType] = None )
```

参数

+   `model_or_pipeline`（`str`或`Pipeline`或`Callable`或`PreTrainedModel`或`TFPreTrainedModel`，默认为`None`）— 如果未指定参数，则我们为任务初始化默认管道（在本例中为`text-classification`或其别名 - `sentiment-analysis`）。如果参数是`str`类型或是模型实例，则我们使用它来使用给定模型初始化新的`Pipeline`。否则，我们假定参数指定了一个预初始化的管道。

+   `data`（`str`或`Dataset`，默认为`None`）— 指定我们将在其上运行评估的数据集。如果是`str`类型，我们将其视为数据集名称，并加载它。否则，我们假定它表示一个预加载的数据集。

+   `subset`（`str`，默认为`None`）— 定义要加载的数据集子集。如果传递`None`，则加载默认子集。

+   `split`（`str`，默认为`None`）— 定义要加载的数据集拆分。如果传递`None`，则根据`choose_split`函数推断。

+   `metric`（`str`或`EvaluationModule`，默认为`None`）— 指定评估器中使用的度量标准。如果是`str`类型，我们将其视为度量标准名称，并加载它。否则，我们假定它表示一个预加载的度量标准。

+   `tokenizer` (`str` 或 `PreTrainedTokenizer`, *可选*, 默认为 `None`) — 如果 `model_or_pipeline` 表示我们构建 pipeline 的模型，则可以使用该参数来覆盖默认的 tokenizer。如果 `model_or_pipeline` 是 `None` 或预初始化的 pipeline，则忽略此参数。

+   `strategy` (`Literal["simple", "bootstrap"]`, 默认为 “simple”) — 指定评估策略。可能的值为：

    +   `"simple"` - 我们评估指标并返回分数。

    +   `"bootstrap"` - 除了计算指标分数外，我们还使用 `scipy` 的 `bootstrap` 方法计算每个返回的指标键的置信区间 [https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   `confidence_level` (`float`, 默认为 `0.95`) — 如果选择了`bootstrap`策略，则传递给 `bootstrap` 的 `confidence_level` 值。

+   `n_resamples` (`int`, 默认为 `9999`) — 如果选择了`bootstrap`策略，则传递给 `bootstrap` 的 `n_resamples` 值。

+   `device` (`int`, 默认为 `None`) — 用于 CPU/GPU 支持的设备序数。将其设置为 -1 将利用 CPU，正整数将在关联的 CUDA 设备 ID 上运行模型。如果提供了 `None`，则将被推断并在可用时使用 CUDA:0，否则使用 CPU。

+   `random_state` (`int`, *可选*, 默认为 `None`) — 如果选择了`bootstrap`策略，则传递给 `bootstrap` 的 `random_state` 值。用于调试。

为给定的 pipeline 和数据集组合计算指标。

示例：

```py
>>> from evaluate import evaluator
>>> from datasets import load_dataset
>>> task_evaluator = evaluator("text-classification")
>>> data = load_dataset("imdb", split="test[:2]")
>>> results = task_evaluator.compute(
>>>     model_or_pipeline="huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli",
>>>     data=data,
>>>     metric="accuracy",
>>>     label_mapping={"LABEL_0": 0.0, "LABEL_1": 1.0},
>>>     strategy="bootstrap",
>>>     n_resamples=10,
>>>     random_state=0
>>> )
```

### TokenClassificationEvaluator

### `class evaluate.TokenClassificationEvaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/token_classification.py#L86)

```py
( task = 'token-classification' default_metric_name = None )
```

标记分类评估器。

这个标记分类评估器目前可以通过 [evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator) 使用默认任务名称 `token-classification` 进行加载。

这个类中的方法假定数据格式与 `TokenClassificationPipeline` 兼容。

#### `compute`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/token_classification.py#L209)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: str = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: typing.Optional[int] = None random_state: typing.Optional[int] = None input_column: str = 'tokens' label_column: str = 'ner_tags' join_by: typing.Optional[str] = ' ' )
```

参数

+   `model_or_pipeline` (`str` 或 `Pipeline` 或 `Callable` 或 `PreTrainedModel` 或 `TFPreTrainedModel`, 默认为 `None`) — 如果未指定参数，则我们为任务初始化默认的 pipeline（在本例中为 `text-classification` 或其别名 - `sentiment-analysis`）。如果参数是 `str` 类型或是模型实例，则我们使用它来初始化具有给定模型的新 `Pipeline`。否则，我们假定参数指定了一个预初始化的 pipeline。

+   `data` (`str` 或 `Dataset`, 默认为 `None`) — 指定我们将在其上运行评估的数据集。如果它是 `str` 类型，我们将其视为数据集名称，并加载它。否则，我们假定它表示一个预加载的数据集。

+   `subset` (`str`, 默认为 `None`) — 定义要加载的数据集子集。如果传递了 `None`，则加载默认子集。

+   `split` (`str`, 默认为 `None`) — 定义要加载的数据集拆分。如果传递了 `None`，则根据 `choose_split` 函数进行推断。

+   `metric` (`str` 或 `EvaluationModule`, 默认为 `None`) — 指定评估器中使用的指标。如果它是 `str` 类型，我们将其视为指标名称，并加载它。否则，我们假定它表示一个预加载的指标。

+   `tokenizer` (`str` 或 `PreTrainedTokenizer`, *可选*, 默认为 `None`) — 如果 `model_or_pipeline` 表示我们构建 pipeline 的模型，则可以使用该参数来覆盖默认的 tokenizer。如果 `model_or_pipeline` 是 `None` 或预初始化的 pipeline，则忽略此参数。

+   `strategy` (`Literal["simple", "bootstrap"]`, 默认为 “simple”) — 指定评估策略。可能的值为：

    +   `"simple"` - 我们评估指标并返回分数。

    +   `"bootstrap"` - 除了计算指标分数外，我们还使用 `scipy` 的 `bootstrap` 方法为返回的每个指标键计算置信区间 [https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   `confidence_level` (`float`, 默认为 `0.95`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `confidence_level` 值。

+   `n_resamples` (`int`, 默认为 `9999`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `n_resamples` 值。

+   `device` (`int`, 默认为 `None`) — 流水线的 CPU/GPU 支持设备序数。将其设置为 -1 将利用 CPU，正整数将在关联的 CUDA 设备 ID 上运行模型。如果提供了 `None`，则将推断并在可用时使用 CUDA:0，否则使用 CPU。

+   `random_state` (`int`, *可选*, 默认为 `None`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `random_state` 值。用于调试。

计算给定流水线和数据集组合的指标。

预期数据集输入和标签列格式为单词列表和标签列表，分别遵循 [conll2003 数据集](https://huggingface.co/datasets/conll2003)。不支持输入为单个字符串，标签为偏移列表的数据集。

示例：

```py
>>> from evaluate import evaluator
>>> from datasets import load_dataset
>>> task_evaluator = evaluator("token-classification")
>>> data = load_dataset("conll2003", split="validation[:2]")
>>> results = task_evaluator.compute(
>>>     model_or_pipeline="elastic/distilbert-base-uncased-finetuned-conll03-english",
>>>     data=data,
>>>     metric="seqeval",
>>> )
```

例如，评估器接受以下数据集格式：

```py
dataset = Dataset.from_dict(
    mapping={
        "tokens": [["New", "York", "is", "a", "city", "and", "Felix", "a", "person", "."]],
        "ner_tags": [[1, 2, 0, 0, 0, 0, 3, 0, 0, 0]],
    },
    features=Features({
        "tokens": Sequence(feature=Value(dtype="string")),
        "ner_tags": Sequence(feature=ClassLabel(names=["O", "B-LOC", "I-LOC", "B-PER", "I-PER"])),
        }),
)
```

例如，评估器不接受以下数据集格式：

```py
dataset = Dataset.from_dict(
    mapping={
        "tokens": [["New York is a city and Felix a person."]],
        "starts": [[0, 23]],
        "ends": [[7, 27]],
        "ner_tags": [["LOC", "PER"]],
    },
    features=Features({
        "tokens": Value(dtype="string"),
        "starts": Sequence(feature=Value(dtype="int32")),
        "ends": Sequence(feature=Value(dtype="int32")),
        "ner_tags": Sequence(feature=Value(dtype="string")),
    }),
)
```

### TextGenerationEvaluator

### `class evaluate.TextGenerationEvaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text_generation.py#L31)

```py
( task = 'text-generation' default_metric_name = None predictions_prefix: str = 'generated' )
```

文本生成评估器。此文本生成评估器目前可以从 [evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator) 使用默认任务名称 `text-generation` 加载。此类中的方法假定数据格式与 `TextGenerationPipeline` 兼容。

#### `compute`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/base.py#L218)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None feature_extractor: typing.Union[str, ForwardRef('FeatureExtractionMixin'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' label_mapping: typing.Union[typing.Dict[str, numbers.Number], NoneType] = None )
```

### 文本生成评估器

### `class evaluate.Text2TextGenerationEvaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text2text_generation.py#L35)

```py
( task = 'text2text-generation' default_metric_name = None )
```

文本到文本生成评估器。此文本到文本生成评估器目前可以从 [evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator) 使用默认任务名称 `text2text-generation` 加载。此类中的方法假定数据格式与 `Text2TextGenerationPipeline` 兼容。

#### `compute`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text2text_generation.py#L52)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' generation_kwargs: dict = None )
```

参数

+   `model_or_pipeline` (`str` 或 `Pipeline` 或 `Callable` 或 `PreTrainedModel` 或 `TFPreTrainedModel`, 默认为 `None`) — 如果未指定参数，则初始化任务的默认流水线（在本例中为 `text-classification` 或其别名 - `sentiment-analysis`）。如果参数是 `str` 类型或是模型实例，则使用它来初始化具有给定模型的新 `Pipeline`。否则，我们假定参数指定了一个预初始化的流水线。

+   `data` (`str` 或 `Dataset`, 默认为 `None`) — 指定我们将在其上运行评估的数据集。如果它是 `str` 类型，则将其视为数据集名称，并加载它。否则，我们假定它表示一个预加载的数据集。

+   `subset` (`str`, 默认为 `None`) — 定义要加载的数据集子集。如果传递了 `None`，则加载默认子集。

+   `split` (`str`, 默认为 `None`) — 定义要加载的数据集拆分。如果传递了 `None`，则根据 `choose_split` 函数推断。

+   `metric` (`str` 或 `EvaluationModule`, 默认为 `None`) — 指定评估器中使用的度量。如果它是 `str` 类型，则将其视为度量名称，并加载它。否则，我们假定它表示一个预加载的度量。

+   `tokenizer` (`str` 或 `PreTrainedTokenizer`, *可选*, 默认为 `None`) — 如果 `model_or_pipeline` 表示我们构建管道的模型，则可以使用该参数来覆盖默认的分词器。如果 `model_or_pipeline` 为 `None` 或预初始化的管道，则忽略此参数。

+   `strategy` (`Literal["simple", "bootstrap"]`, 默认为 “simple”) — 指定评估策略。可能的值为:

    +   `"simple"` - 我们评估度量并返回分数。

    +   `"bootstrap"` - 在计算度量分数的基础上，我们使用 `scipy` 的 `bootstrap` 方法计算每个返回的度量键的置信区间 [https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   `confidence_level` (`float`, 默认为 `0.95`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `confidence_level` 值。

+   `n_resamples` (`int`, 默认为 `9999`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `n_resamples` 值。

+   `device` (`int`, 默认为 `None`) — 用于 CPU/GPU 支持的设备序数。将其设置为 -1 将利用 CPU，正整数将在关联的 CUDA 设备 ID 上运行模型。如果提供 `None`，则将进行推断，如果可用，则使用 CUDA:0，否则使用 CPU。

+   `random_state` (`int`, *可选*, 默认为 `None`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `random_state` 值。用于调试。

+   `input_column` (`str`, 默认为 `"text"`) — 数据集中包含输入文本的列的名称，由 `data` 指定。

+   `label_column` (`str`, 默认为 `"label"`) — 数据集中包含标签的列的名称，由 `data` 指定。

+   `generation_kwargs` (`Dict`, *可选*, 默认为 `None`) — 生成 kwargs 传递给管道，并设置文本生成策略。

计算给定管道和数据集组合的度量。

### SummarizationEvaluator

### `class evaluate.SummarizationEvaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text2text_generation.py#L113)

```py
( task = 'summarization' default_metric_name = None )
```

文本摘要评估器。此文本摘要评估器目前可以从 [evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator) 使用默认任务名称 `summarization` 加载。此类中的方法假定数据格式与 [SummarizationEvaluator](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.SummarizationEvaluator) 兼容。

#### `compute`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text2text_generation.py#L127)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' generation_kwargs: dict = None )
```

参数

+   `model_or_pipeline` (`str` 或 `Pipeline` 或 `Callable` 或 `PreTrainedModel` 或 `TFPreTrainedModel`, 默认为 `None`) — 如果未指定参数，则为任务初始化默认管道（在本例中为 `text-classification` 或其别名 - `sentiment-analysis`）。如果参数是 `str` 类型或是模型实例，则使用它来初始化具有给定模型的新 `Pipeline`。否则，我们假定参数指定了一个预初始化的管道。

+   `data` (`str` 或 `Dataset`, 默认为 `None`) — 指定我们将在其上运行评估的数据集。如果它是 `str` 类型，则将其视为数据集名称，并加载它。否则，我们假定它表示一个预加载的数据集。

+   `subset` (`str`, 默认为 `None`) — 定义要加载的数据集子集。如果传递 `None`，则加载默认子集。

+   `split` (`str`, 默认为 `None`) — 定义要加载的数据集拆分。如果传递 `None`，则根据 `choose_split` 函数进行推断。

+   `metric` (`str` 或 `EvaluationModule`, 默认为 `None`) — 指定评估器中使用的度量。如果是 `str` 类型，我们将其视为度量名称，并加载它。否则，我们假设它表示预加载的度量。

+   `tokenizer` (`str` 或 `PreTrainedTokenizer`, *optional*, 默认为 `None`) — 如果 `model_or_pipeline` 表示我们构建管道的模型，则可以使用此参数来覆盖默认的分词器。如果 `model_or_pipeline` 为 `None` 或预初始化的管道，则忽略此参数。

+   `strategy` (`Literal["simple", "bootstrap"]`, 默认为 “simple”) — 指定评估策略。可能的值为：

    +   `"simple"` - 我们评估度量并返回分数。

    +   `"bootstrap"` - 除了计算度量分数外，我们还使用 `scipy` 的 `bootstrap` 方法为返回的每个度量键计算置信区间 [https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   `confidence_level` (`float`, 默认为 `0.95`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `confidence_level` 值。

+   `n_resamples` (`int`, 默认为 `9999`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `n_resamples` 值。

+   `device` (`int`, 默认为 `None`) — 用于支持 CPU/GPU 的管道的设备序数。将其设置为 -1 将利用 CPU，正整数将在关联的 CUDA 设备 ID 上运行模型。如果提供 `None`，它将被推断，并在可用时使用 CUDA:0，否则使用 CPU。

+   `random_state` (`int`, *optional*, 默认为 `None`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `random_state` 值。用于调试。

+   `input_column` (`str`, 默认为 `"text"`) — 数据集中包含输入文本的列的名称，由 `data` 指定。

+   `label_column` (`str`, 默认为 `"label"`) — 数据集中包含标签的列的名称，由 `data` 指定。

+   `generation_kwargs` (`Dict`, *optional*, 默认为 `None`) — 生成 kwargs 传递给管道，并设置文本生成策略。

计算给定管道和数据集组合的度量。

### TranslationEvaluator

### `class evaluate.TranslationEvaluator`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text2text_generation.py#L184)

```py
( task = 'translation' default_metric_name = None )
```

翻译评估器。此翻译生成评估器目前可以从 [evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator) 中使用默认任务名称 `translation` 加载。此类中的方法假定数据格式与 `TranslationPipeline` 兼容。

#### `compute`

[< source >](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/text2text_generation.py#L198)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' generation_kwargs: dict = None )
```

参数

+   `model_or_pipeline` (`str` 或 `Pipeline` 或 `Callable` 或 `PreTrainedModel` 或 `TFPreTrainedModel`, 默认为 `None`) — 如果未指定参数，则我们将为任务初始化默认管道（在本例中为 `text-classification` 或其别名 - `sentiment-analysis`）。如果参数是 `str` 类型或是模型实例，则使用它来初始化具有给定模型的新 `Pipeline`。否则，我们假设参数指定了预初始化的管道。

+   `data` (`str` 或 `Dataset`, 默认为 `None`) — 指定我们将在其上运行评估的数据集。如果是 `str` 类型，我们将其视为数据集名称，并加载它。否则，我们假设它表示预加载的数据集。

+   `subset` (`str`, 默认为 `None`) — 定义要加载的数据集子集。如果传递了 `None`，则加载默认子集。

+   `split` (`str`, 默认为 `None`) — 定义要加载的数据集拆分。如果传递了 `None`，则根据 `choose_split` 函数进行推断。

+   `metric` (`str`或`EvaluationModule`，默认为`None`) — 指定评估器中使用的度量。如果它是`str`类型，我们将其视为度量名称，并加载它。否则，我们假定它表示预加载的度量。

+   `tokenizer` (`str`或`PreTrainedTokenizer`，*可选*，默认为`None`) — 如果`model_or_pipeline`表示我们构建管道的模型，则可以使用该参数来覆盖默认的分词器。如果`model_or_pipeline`为`None`或预初始化的管道，则忽略此参数。

+   `strategy` (`Literal["simple", "bootstrap"]`，默认为“simple”) — 指定评估策略。可能的值为：

    +   `"simple"` - 我们评估度量并返回分数。

    +   `"bootstrap"` - 除了计算度量分数外，我们还使用`scipy`的`bootstrap`方法[https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)为返回的每个度量键计算置信区间。

+   `confidence_level` (`float`，默认为`0.95`) — 如果选择了`"bootstrap"`策略，则将`confidence_level`值传递给`bootstrap`。

+   `n_resamples` (`int`，默认为`9999`) — 如果选择了`"bootstrap"`策略，则将`n_resamples`值传递给`bootstrap`。

+   `device` (`int`, 默认为`None`) — 用于CPU/GPU支持的设备序数。将其设置为-1将利用CPU，正整数将在关联的CUDA设备ID上运行模型。如果提供`None`，则将推断并在可用时使用CUDA:0，否则使用CPU。

+   `random_state` (`int`，*可选*，默认为`None`) — 如果选择了`"bootstrap"`策略，则将`random_state`值传递给`bootstrap`。用于调试。

+   `input_column` (`str`, 默认为`"text"`) — 包含输入文本的列的名称，在由`data`指定的数据集中。

+   `label_column` (`str`，默认为`"label"`) — 包含标签的列的名称，在由`data`指定的数据集中。

+   `generation_kwargs` (`Dict`，*可选*，默认为`None`) — 生成kwargs传递给管道，并设置文本生成策略。

为给定的管道和数据集组合计算度量。

### AutomaticSpeechRecognitionEvaluator

### `class evaluate.AutomaticSpeechRecognitionEvaluator`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/automatic_speech_recognition.py#L43)

```py
( task = 'automatic-speech-recognition' default_metric_name = None )
```

自动语音识别评估器。此自动语音识别评估器目前可以从[evaluator()](/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.evaluator)使用默认任务名称`automatic-speech-recognition`加载。此类中的方法假定数据格式与`AutomaticSpeechRecognitionPipeline`兼容。

#### `compute`

[<来源>](https://github.com/huggingface/evaluate/blob/v0.4.0/src/evaluate/evaluator/automatic_speech_recognition.py#L59)

```py
( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'path' label_column: str = 'sentence' generation_kwargs: dict = None )
```

参数

+   `model_or_pipeline` (`str`或`Pipeline`或`Callable`或`PreTrainedModel`或`TFPreTrainedModel`，默认为`None`) — 如果未指定参数，则为任务初始化默认管道（在本例中为`text-classification`或其别名 - `sentiment-analysis`）。如果参数是`str`类型或是模型实例，则使用它来初始化具有给定模型的新`Pipeline`。否则，我们假定参数指定了预初始化的管道。

+   `data` (`str`或`Dataset`，默认为`None`) — 指定我们将在其上运行评估的数据集。如果它是`str`类型，我们将其视为数据集名称，并加载它。否则，我们假定它表示预加载的数据集。

+   `subset` (`str`，默认为`None`) — 定义要加载的数据集子集。如果传递`None`，则加载默认子集。

+   `split` (`str`，默认为`None`) — 定义要加载的数据集拆分。如果传递`None`，则根据`choose_split`函数推断。

+   `metric` (`str` 或 `EvaluationModule`，默认为 `None`) — 指定评估器中使用的度量标准。如果是 `str` 类型，我们将其视为度量名称，并加载它。否则，我们假设它表示预加载的度量标准。

+   `tokenizer` (`str` 或 `PreTrainedTokenizer`，*可选*，默认为 `None`) — 如果 `model_or_pipeline` 表示我们构建管道的模型，则可以使用该参数来覆盖默认的分词器。如果 `model_or_pipeline` 为 `None` 或预初始化的管道，则忽略此参数。

+   `strategy` (`Literal["simple", "bootstrap"]`，默认为 “simple”) — 指定评估策略。可能的值为：

    +   `"simple"` - 我们评估度量标准并返回分数。

    +   `"bootstrap"` - 在计算度量分数的基础上，我们使用 `scipy` 的 `bootstrap` 方法计算每个返回的度量键的置信区间 [https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html)。

+   `confidence_level` (`float`，默认为 `0.95`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `confidence_level` 值。

+   `n_resamples` (`int`，默认为 `9999`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `n_resamples` 值。

+   `device` (`int`，默认为 `None`) — 用于支持管道的 CPU/GPU 设备序数。将其设置为 -1 将利用 CPU，正整数将在关联的 CUDA 设备 ID 上运行模型。如果提供 `None`，它将被推断，并在可用时使用 CUDA:0，否则使用 CPU。

+   `random_state` (`int`，*可选*，默认为 `None`) — 如果选择了 `"bootstrap"` 策略，则传递给 `bootstrap` 的 `random_state` 值。用于调试。

计算给定管道和数据集组合的度量标准。

示例：

```py
>>> from evaluate import evaluator
>>> from datasets import load_dataset
>>> task_evaluator = evaluator("automatic-speech-recognition")
>>> data = load_dataset("mozilla-foundation/common_voice_11_0", "en", split="validation[:40]")
>>> results = task_evaluator.compute(
>>>     model_or_pipeline="https://huggingface.co/openai/whisper-tiny.en",
>>>     data=data,
>>>     input_column="path",
>>>     label_column="sentence",
>>>     metric="wer",
>>> )
```
