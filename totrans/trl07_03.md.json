["```py\n# 0\\. imports\nimport torch\nfrom transformers import GPT2Tokenizer\n\nfrom trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n\n# 1\\. load a pretrained model\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\nmodel_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n\n# 2\\. initialize trainer\nppo_config = {\"batch_size\": 1}\nconfig = PPOConfig(**ppo_config)\nppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)\n\n# 3\\. encode a query\nquery_txt = \"This morning I went to the \"\nquery_tensor = tokenizer.encode(query_txt, return_tensors=\"pt\").to(model.pretrained_model.device)\n\n# 4\\. generate model response\ngeneration_kwargs = {\n    \"min_length\": -1,\n    \"top_k\": 0.0,\n    \"top_p\": 1.0,\n    \"do_sample\": True,\n    \"pad_token_id\": tokenizer.eos_token_id,\n    \"max_new_tokens\": 20,\n}\nresponse_tensor = ppo_trainer.generate([item for item in query_tensor], return_prompt=False, **generation_kwargs)\nresponse_txt = tokenizer.decode(response_tensor[0])\n\n# 5\\. define a reward for response\n# (this could be any reward such as human feedback or output from another model)\nreward = [torch.tensor(1.0, device=model.pretrained_model.device)]\n\n# 6\\. train model with ppo\ntrain_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)\n```", "```py\n\n# .. Let's assume we have a trained model using `PPOTrainer` and `AutoModelForCausalLMWithValueHead`\n\n# push the model on the Hub\nmodel.push_to_hub(\"my-fine-tuned-model-ppo\")\n\n# or save it locally\nmodel.save_pretrained(\"my-fine-tuned-model-ppo\")\n\n# load the model from the Hub\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"my-fine-tuned-model-ppo\")\n```", "```py\nfrom trl.model import AutoModelForCausalLMWithValueHead\n\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\"my-fine-tuned-model-ppo\")\n```"]