["```py\n>>> from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n\n>>> mname = \"facebook/blenderbot-400M-distill\"\n>>> model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n>>> tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n>>> UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n>>> inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n>>> reply_ids = model.generate(**inputs)\n>>> print(tokenizer.batch_decode(reply_ids))\n[\"<s> That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?</s>\"]\n```", "```py\n>>> from transformers import BlenderbotConfig, BlenderbotModel\n\n>>> # Initializing a Blenderbot facebook/blenderbot-3B style configuration\n>>> configuration = BlenderbotConfig()\n\n>>> # Initializing a model (with random weights) from the facebook/blenderbot-3B style configuration\n>>> model = BlenderbotModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import BlenderbotTokenizer\n\n>>> tokenizer = BlenderbotTokenizer.from_pretrained(\"facebook/blenderbot-3B\")\n>>> tokenizer.add_prefix_space = False\n>>> tokenizer(\"Hello world\")[\"input_ids\"]\n[47, 921, 86, 1085, 2]\n\n>>> tokenizer(\" Hello world\")[\"input_ids\"]\n[6950, 1085, 2]\n```", "```py\n>>> from transformers import BlenderbotTokenizerFast\n\n>>> tokenizer = BlenderbotTokenizerFast.from_pretrained(\"facebook/blenderbot-3B\")\n>>> tokenizer(\"Hello world\")[\"input_ids\"]\n[6950, 1085, 2]\n\n>>> tokenizer(\" Hello world\")[\"input_ids\"]\n[6950, 1085, 2]\n```", "```py\n>>> from transformers import AutoTokenizer, BlenderbotModel\n\n>>> model = BlenderbotModel.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> inputs = tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\")\n>>> decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n>>> outputs = model(input_ids=inputs.input_ids, decoder_input_ids=decoder_input_ids)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 6, 1280]\n```", "```py\n>>> from transformers import AutoTokenizer, BlenderbotForConditionalGeneration\n\n>>> mname = \"facebook/blenderbot-400M-distill\"\n>>> model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n>>> tokenizer = AutoTokenizer.from_pretrained(mname)\n>>> UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n>>> print(\"Human: \", UTTERANCE)\nHuman:  My friends are cool but they eat too many carbs.\n\n>>> inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n>>> reply_ids = model.generate(**inputs)\n>>> print(\"Bot: \", tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0])\nBot: That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?\n\n>>> REPLY = \"I'm not sure\"\n>>> print(\"Human: \", REPLY)\nHuman: I'm not sure\n\n>>> NEXT_UTTERANCE = (\n...     \"My friends are cool but they eat too many carbs.</s> <s>That's unfortunate. \"\n...     \"Are they trying to lose weight or are they just trying to be healthier?</s> \"\n...     \"<s> I'm not sure.\"\n... )\n>>> inputs = tokenizer([NEXT_UTTERANCE], return_tensors=\"pt\")\n>>> next_reply_ids = model.generate(**inputs)\n>>> print(\"Bot: \", tokenizer.batch_decode(next_reply_ids, skip_special_tokens=True)[0])\nBot:   I see. Well, it's good that they're trying to change their eating habits.\n```", "```py\n>>> from transformers import AutoTokenizer, BlenderbotForCausalLM\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> model = BlenderbotForCausalLM.from_pretrained(\"facebook/blenderbot-400M-distill\", add_cross_attention=False)\n>>> assert model.config.is_decoder, f\"{model.__class__} has to be configured as a decoder.\"\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n>>> expected_shape = [1, inputs.input_ids.shape[-1], model.config.vocab_size]\n>>> list(logits.shape) == expected_shape\nTrue\n```", "```py\n>>> from transformers import AutoTokenizer, TFBlenderbotModel\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> model = TFBlenderbotModel.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n>>> outputs = model(inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, TFBlenderbotForConditionalGeneration\n\n>>> mname = \"facebook/blenderbot-400M-distill\"\n>>> model = TFBlenderbotForConditionalGeneration.from_pretrained(mname)\n>>> tokenizer = AutoTokenizer.from_pretrained(mname)\n>>> UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n>>> print(\"Human: \", UTTERANCE)\n\n>>> inputs = tokenizer([UTTERANCE], return_tensors=\"tf\")\n>>> reply_ids = model.generate(**inputs)\n>>> print(\"Bot: \", tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0])\n\n>>> REPLY = \"I'm not sure\"\n>>> print(\"Human: \", REPLY)\n>>> NEXT_UTTERANCE = (\n...     \"My friends are cool but they eat too many carbs.</s> <s>That's unfortunate. \"\n...     \"Are they trying to lose weight or are they just trying to be healthier?</s> \"\n...     \"<s> I'm not sure.\"\n... )\n>>> inputs = tokenizer([NEXT_UTTERANCE], return_tensors=\"tf\")\n>>> next_reply_ids = model.generate(**inputs)\n>>> print(\"Bot: \", tokenizer.batch_decode(next_reply_ids, skip_special_tokens=True)[0])\n```", "```py\n>>> from transformers import AutoTokenizer, FlaxBlenderbotModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> model = FlaxBlenderbotModel.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"jax\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, FlaxBlenderbotForConditionalGeneration\n\n>>> model = FlaxBlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> text = \"My friends are cool but they eat too many carbs.\"\n>>> inputs = tokenizer(text, max_length=1024, return_tensors=\"jax\")\n>>> encoder_outputs = model.encode(**inputs)\n```", "```py\n>>> import jax.numpy as jnp\n>>> from transformers import AutoTokenizer, FlaxBlenderbotForConditionalGeneration\n\n>>> model = FlaxBlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> text = \"My friends are cool but they eat too many carbs.\"\n>>> inputs = tokenizer(text, max_length=1024, return_tensors=\"jax\")\n>>> encoder_outputs = model.encode(**inputs)\n\n>>> decoder_start_token_id = model.config.decoder_start_token_id\n>>> decoder_input_ids = jnp.ones((inputs.input_ids.shape[0], 1), dtype=\"i4\") * decoder_start_token_id\n\n>>> outputs = model.decode(decoder_input_ids, encoder_outputs)\n>>> last_decoder_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, FlaxBlenderbotForConditionalGeneration\n\n>>> model = FlaxBlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n>>> inputs = tokenizer([UTTERANCE], max_length=1024, return_tensors=\"np\")\n\n>>> # Generate Reply\n>>> reply_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=5, early_stopping=True).sequences\n>>> print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in reply_ids])\n```", "```py\n>>> from transformers import AutoTokenizer, FlaxBlenderbotForConditionalGeneration\n\n>>> model = FlaxBlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> text = \"My friends are cool but they eat too many carbs.\"\n>>> inputs = tokenizer(text, max_length=1024, return_tensors=\"jax\")\n>>> encoder_outputs = model.encode(**inputs)\n```", "```py\n>>> import jax.numpy as jnp\n>>> from transformers import AutoTokenizer, FlaxBlenderbotForConditionalGeneration\n\n>>> model = FlaxBlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n\n>>> text = \"My friends are cool but they eat too many carbs.\"\n>>> inputs = tokenizer(text, max_length=1024, return_tensors=\"jax\")\n>>> encoder_outputs = model.encode(**inputs)\n\n>>> decoder_start_token_id = model.config.decoder_start_token_id\n>>> decoder_input_ids = jnp.ones((inputs.input_ids.shape[0], 1), dtype=\"i4\") * decoder_start_token_id\n\n>>> outputs = model.decode(decoder_input_ids, encoder_outputs)\n>>> logits = outputs.logits\n```"]