["```py\nfrom transformers import LukeModel\n\nmodel = LukeModel.from_pretrained(\"studio-ousia/mluke-base\")\n```", "```py\nfrom transformers import MLukeTokenizer\n\ntokenizer = MLukeTokenizer.from_pretrained(\"studio-ousia/mluke-base\")\n```", "```py\n( vocab_file entity_vocab_file bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' task = None max_entity_length = 32 max_mention_length = 30 entity_token_1 = '<ent>' entity_token_2 = '<ent2>' entity_unk_token = '[UNK]' entity_pad_token = '[PAD]' entity_mask_token = '[MASK]' entity_mask2_token = '[MASK2]' sp_model_kwargs: Optional = None **kwargs )\n```", "```py\n( text: Union text_pair: Union = None entity_spans: Union = None entity_spans_pair: Union = None entities: Union = None entities_pair: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None max_entity_length: Optional = None stride: int = 0 is_split_into_words: Optional = False pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs ) \u2192 export const metadata = 'undefined';BatchEncoding\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```"]