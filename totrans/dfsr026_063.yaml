- en: T2I-Adapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/t2i_adapters](https://huggingface.co/docs/diffusers/training/t2i_adapters)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: '[T2I-Adapter](https://hf.co/papers/2302.08453) is a lightweight adapter model
    that provides an additional conditioning input image (line art, canny, sketch,
    depth, pose) to better control image generation. It is similar to a ControlNet,
    but it is a lot smaller (~77M parameters and ~300MB file size) because its only
    inserts weights into the UNet instead of copying and training it.'
  prefs: []
  type: TYPE_NORMAL
- en: The T2I-Adapter is only available for training with the Stable Diffusion XL
    (SDXL) model.
  prefs: []
  type: TYPE_NORMAL
- en: This guide will explore the [train_t2i_adapter_sdxl.py](https://github.com/huggingface/diffusers/blob/main/examples/t2i_adapter/train_t2i_adapter_sdxl.py)
    training script to help you become familiar with it, and how you can adapt it
    for your own use-case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before running the script, make sure you install the library from source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then navigate to the example folder containing the training script and install
    the required dependencies for the script youâ€™re using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ðŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ðŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize an ðŸ¤— Accelerate environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To setup a default ðŸ¤— Accelerate environment without choosing any configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Or if your environment doesnâ€™t support an interactive shell, like a notebook,
    you can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the script
    in detail. If youâ€™re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/t2i_adapter/train_t2i_adapter_sdxl.py)
    and let us know if you have any questions or concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Script parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The training script provides many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L233)
    function. It provides default values for each parameter, such as the training
    batch size and learning rate, but you can also set your own values in the training
    command if youâ€™d like.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to activate gradient accumulation, add the `--gradient_accumulation_steps`
    parameter to the training command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Many of the basic and important parameters are described in the [Text-to-image](text2image#script-parameters)
    training guide, so this guide just focuses on the relevant T2I-Adapter parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--pretrained_vae_model_name_or_path`: path to a pretrained VAE; the SDXL VAE
    is known to suffer from numerical instability, so this parameter allows you to
    specify a better [VAE](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--crops_coords_top_left_h` and `--crops_coords_top_left_w`: height and width
    coordinates to include in SDXLâ€™s crop coordinate embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--conditioning_image_column`: the column of the conditioning images in the
    dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--proportion_empty_prompts`: the proportion of image prompts to replace with
    empty strings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with the script parameters, a walkthrough of the training script is provided
    in the [Text-to-image](text2image#training-script) training guide. Instead, this
    guide takes a look at the T2I-Adapter relevant parts of the script.
  prefs: []
  type: TYPE_NORMAL
- en: The training script begins by preparing the dataset. This incudes [tokenizing](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L674)
    the prompt and [applying transforms](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L714)
    to the images and conditioning images.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the [`main()`](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L770)
    function, the T2I-Adapter is either loaded from a pretrained adapter or it is
    randomly initialized:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The [optimizer](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L952)
    is initialized for the T2I-Adapter parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, in the [training loop](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L1086),
    the adapter conditioning image and the text embeddings are passed to the UNet
    to predict the noise residual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers](../using-diffusers/write_own_pipeline) tutorial
    which breaks down the basic pattern of the denoising process.
  prefs: []
  type: TYPE_NORMAL
- en: Launch the script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now youâ€™re ready to launch the training script! ðŸš€
  prefs: []
  type: TYPE_NORMAL
- en: For this example training, youâ€™ll use the [fusing/fill50k](https://huggingface.co/datasets/fusing/fill50k)
    dataset. You can also create and use your own dataset if you want (see the [Create
    a dataset for training](https://moon-ci-docs.huggingface.co/docs/diffusers/pr_5512/en/training/create_dataset)
    guide).
  prefs: []
  type: TYPE_NORMAL
- en: Set the environment variable `MODEL_DIR` to a model id on the Hub or a path
    to a local model and `OUTPUT_DIR` to where you want to save the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the following images to condition your training with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: To monitor training progress with Weights & Biases, add the `--report_to=wandb`
    parameter to the training command. Youâ€™ll also need to add the `--validation_image`,
    `--validation_prompt`, and `--validation_steps` to the training command to keep
    track of results. This can be really useful for debugging the model and viewing
    intermediate results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once training is complete, you can use your T2I-Adapter for inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Next steps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Congratulations on training a T2I-Adapter model! ðŸŽ‰ To learn more:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the [Efficient Controllable Generation for SDXL with T2I-Adapters](https://huggingface.co/blog/t2i-sdxl-adapters)
    blog post to learn more details about the experimental results from the T2I-Adapter
    team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
