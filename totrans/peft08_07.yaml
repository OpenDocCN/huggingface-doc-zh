- en: PEFT integrations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PEFT集成
- en: 'Original text: [https://huggingface.co/docs/peft/tutorial/peft_integrations](https://huggingface.co/docs/peft/tutorial/peft_integrations)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/peft/tutorial/peft_integrations](https://huggingface.co/docs/peft/tutorial/peft_integrations)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: PEFT’s practical benefits extends to other Hugging Face libraries like [Diffusers](https://hf.co/docs/diffusers)
    and [Transformers](https://hf.co/docs/transformers). One of the main benefits
    of PEFT is that an adapter file generated by a PEFT method is a lot smaller than
    the original model, which makes it super easy to manage and use multiple adapters.
    You can use one pretrained base model for multiple tasks by simply loading a new
    adapter finetuned for the task you’re solving. Or you can combine multiple adapters
    with a text-to-image diffusion model to create new effects.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: PEFT的实际好处延伸到其他Hugging Face库，如[Diffusers](https://hf.co/docs/diffusers)和[Transformers](https://hf.co/docs/transformers)。PEFT的主要好处之一是，由PEFT方法生成的适配器文件比原始模型小得多，这使得管理和使用多个适配器变得非常容易。您可以通过简单加载针对您正在解决的任务进行微调的新适配器，使用一个预训练基础模型来执行多个任务。或者，您可以将多个适配器与文本到图像扩散模型结合起来，创建新的效果。
- en: This tutorial will show you how PEFT can help you manage adapters in Diffusers
    and Transformers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程将向您展示PEFT如何帮助您管理Diffusers和Transformers中的适配器。
- en: Diffusers
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Diffusers
- en: Diffusers is a generative AI library for creating images and videos from text
    or images with diffusion models. LoRA is an especially popular training method
    for diffusion models because you can very quickly train and share diffusion models
    to generate images in new styles. To make it easier to use and try multiple LoRA
    models, Diffusers uses the PEFT library to help manage different adapters for
    inference.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Diffusers是一个生成式AI库，用于从文本或图像生成图像和视频，使用扩散模型。LoRA是扩散模型的一种特别流行的训练方法，因为您可以非常快速地训练和共享扩散模型，以生成新风格的图像。为了更容易使用和尝试多个LoRA模型，Diffusers使用PEFT库来帮助管理不同的适配器进行推断。
- en: For example, load a base model and then load the [artificialguybr/3DRedmond-V1](https://huggingface.co/artificialguybr/3DRedmond-V1)
    adapter for inference with the [`load_lora_weights`](https://huggingface.co/docs/diffusers/v0.24.0/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    method. The `adapter_name` argument in the loading method is enabled by PEFT and
    allows you to set a name for the adapter so it is easier to reference.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，加载一个基础模型，然后使用[`load_lora_weights`](https://huggingface.co/docs/diffusers/v0.24.0/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)方法加载[artificialguybr/3DRedmond-V1](https://huggingface.co/artificialguybr/3DRedmond-V1)适配器进行推断。加载方法中的`adapter_name`参数由PEFT启用，允许您为适配器设置一个名称，以便更容易引用。
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/44d7d3f44fb0552b1f55c92fcbce7784.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44d7d3f44fb0552b1f55c92fcbce7784.png)'
- en: Now let’s try another cool LoRA model, [ostris/super-cereal-sdxl-lora](https://huggingface.co/ostris/super-cereal-sdxl-lora).
    All you need to do is load and name this new adapter with `adapter_name`, and
    use the [`set_adapters`](https://huggingface.co/docs/diffusers/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)
    method to set it as the currently active adapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试另一个很酷的LoRA模型，[ostris/super-cereal-sdxl-lora](https://huggingface.co/ostris/super-cereal-sdxl-lora)。您只需要加载并命名这个新的适配器，使用`adapter_name`，并使用[`set_adapters`](https://huggingface.co/docs/diffusers/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法将其设置为当前活动的适配器。
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/93e1d1297cecfeb1cad00cf824e024ed.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93e1d1297cecfeb1cad00cf824e024ed.png)'
- en: Finally, you can call the [`disable_lora`](https://huggingface.co/docs/diffusers/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.disable_lora)
    method to restore the base model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以调用[`disable_lora`](https://huggingface.co/docs/diffusers/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.disable_lora)方法来恢复基础模型。
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Learn more about how PEFT supports Diffusers in the [Inference with PEFT](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference)
    tutorial.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在[使用PEFT进行推断](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference)教程中了解更多关于PEFT如何支持Diffusers的信息。
- en: Transformers
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transformers
- en: Transformers is a collection of pretrained models for all types of tasks in
    all modalities. You can load these models for training or inference. Many of the
    models are large language models (LLMs), so it makes sense to integrate PEFT with
    Transformers to manage and train adapters.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers是各种任务和所有形式的预训练模型的集合。您可以加载这些模型进行训练或推断。许多模型都是大型语言模型（LLMs），因此将PEFT与Transformers集成以管理和训练适配器是有意义的。
- en: Load a base pretrained model to train.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 加载一个基础预训练模型进行训练。
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, add an adapter configuration to specify how to adapt the model parameters.
    Call the [add_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.add_adapter)
    method to add the configuration to the base model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，添加一个适配器配置来指定如何调整模型参数。调用[add_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.add_adapter)方法将配置添加到基础模型中。
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now you can train the model with Transformer’s [Trainer](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)
    class or whichever training framework you prefer.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用Transformer的[Trainer](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)类或您喜欢的任何训练框架来训练模型。
- en: To use the newly trained model for inference, the [AutoModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    class uses PEFT on the backend to load the adapter weights and configuration file
    into a base pretrained model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要将新训练的模型用于推断，[AutoModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)类在后端使用PEFT加载适配器权重和配置文件到基础预训练模型中。
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you’re interested in comparing or using more than one adapter, you can also
    call the [add_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.add_adapter)
    method to add the adapter configuration to the base model. The only requirement
    is the adapter type must be the same (you can’t mix a LoRA and LoHa adapter).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣比较或使用多个适配器，您也可以调用[add_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.add_adapter)方法将适配器配置添加到基础模型中。唯一的要求是适配器类型必须相同（不能混合LoRA和LoHa适配器）。
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Call [add_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.add_adapter)
    again to attach a new adapter to the base model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 再次调用[add_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.add_adapter)以将新的适配器附加到基础模型。
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Then you can use [set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)
    to set the currently active adapter.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用[set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)来设置当前活动的适配器。
- en: '[PRE8]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To disable the adapter, call the [disable_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.disable_adapter)
    method.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要禁用适配器，请调用[disable_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.disable_adapter)方法。
- en: '[PRE9]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you’re curious, check out the [Load and train adapters with PEFT](https://huggingface.co/docs/transformers/main/peft)
    tutorial to learn more.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，可以查看[使用PEFT加载和训练适配器](https://huggingface.co/docs/transformers/main/peft)教程以了解更多。
