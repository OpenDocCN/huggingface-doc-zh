# PhoBERT

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/phobert`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/phobert)

## 概述

PhoBERT 模型由 Dat Quoc Nguyen 和 Anh Tuan Nguyen 在[PhoBERT: Pre-trained language models for Vietnamese](https://www.aclweb.org/anthology/2020.findings-emnlp.92.pdf)中提出。

论文摘要如下：

*我们提出了两个版本的 PhoBERT，PhoBERT-base 和 PhoBERT-large，这是为越南语预训练的第一个公共大规模单语言模型。实验结果表明，PhoBERT 始终优于最近的最佳预训练多语言模型 XLM-R（Conneau 等，2020），并改进了多个越南特定的 NLP 任务的最新技术，包括词性标注、依存句法分析、命名实体识别和自然语言推理。*

此模型由[dqnguyen](https://huggingface.co/dqnguyen)贡献。原始代码可在[此处](https://github.com/VinAIResearch/PhoBERT)找到。

## 用法示例

```py
>>> import torch
>>> from transformers import AutoModel, AutoTokenizer

>>> phobert = AutoModel.from_pretrained("vinai/phobert-base")
>>> tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")

>>> # INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!
>>> line = "Tôi là sinh_viên trường đại_học Công_nghệ ."

>>> input_ids = torch.tensor([tokenizer.encode(line)])

>>> with torch.no_grad():
...     features = phobert(input_ids)  # Models outputs are now tuples

>>> # With TensorFlow 2.0+:
>>> # from transformers import TFAutoModel
>>> # phobert = TFAutoModel.from_pretrained("vinai/phobert-base")
```

PhoBERT 实现与 BERT 相同，除了分词。有关配置类及其参数的信息，请参考 EART 文档。下面记录了 PhoBERT 特定的标记器。

## PhobertTokenizer

### `class transformers.PhobertTokenizer`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/phobert/tokenization_phobert.py#L68)

```py
( vocab_file merges_file bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' **kwargs )
```

参数

+   `vocab_file` (`str`) — 词汇文件的路径。

+   `merges_file` (`str`) — 合并文件的路径。

+   `bos_token` (`st`, *optional*, defaults to `"<s>"`) — 在预训练期间使用的序列开始标记。可用作序列分类器标记。

    在构建使用特殊标记的序列时，这不是用于序列开头的标记。使用的标记是`cls_token`。

+   `eos_token` (`str`, *optional*, defaults to `"</s>"`) — 序列结束标记。

    在构建使用特殊标记的序列时，这不是用于序列结束的标记。使用的标记是`sep_token`。

+   `sep_token` (`str`, *optional*, defaults to `"</s>"`) — 分隔符标记，用于从多个序列构建序列，例如，用于序列分类的两个序列或用于问题回答的文本和问题。它还用作使用特殊标记构建的序列的最后一个标记。

+   `cls_token` (`str`, *optional*, defaults to `"<s>"`) — 用于进行序列分类时使用的分类器标记（对整个序列进行分类而不是对每个标记进行分类）。在使用特殊标记构建时，它是序列的第一个标记。

+   `unk_token` (`str`, *optional*, defaults to `"<unk>"`) — 未知标记。词汇表中不存在的标记无法转换为 ID，而是设置为此标记。

+   `pad_token` (`str`, *optional*, defaults to `"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。

+   `mask_token` (`str`, *optional*, defaults to `"<mask>"`) — 用于屏蔽值的标记。在训练此模型时使用的标记为掩码语言建模。这是模型将尝试预测的标记。

构建一个 PhoBERT 标记器。基于字节对编码。

此标记器继承自 PreTrainedTokenizer，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。

#### `add_from_file`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/phobert/tokenization_phobert.py#L346)

```py
( f )
```

从文本文件加载现有字典并将其符号添加到此实例。

#### `build_inputs_with_special_tokens`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/phobert/tokenization_phobert.py#L165)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）— 将添加特殊标记的 ID 列表。

+   `token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个 ID 列表。

返回

`List[int]`

具有适当特殊标记的 input IDs 列表。

通过连接和添加特殊标记，从序列或序列对构建用于序列分类任务的模型输入。PhoBERT 序列的格式如下：

+   单个序列：`<s> X </s>`

+   序列对：`<s> A </s></s> B </s>`

`convert_tokens_to_string`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/phobert/tokenization_phobert.py#L312)

```py
( tokens )
```

将一系列标记（字符串）转换为单个字符串。

#### `create_token_type_ids_from_sequences`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/phobert/tokenization_phobert.py#L219)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）— ID 列表。

+   `token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个 ID 列表。

返回

`List[int]`

零的列表。

从传递的两个序列创建一个用于序列对分类任务的掩码。PhoBERT 不使用标记类型 ID，因此返回一个零列表。

#### `get_special_tokens_mask`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/phobert/tokenization_phobert.py#L191)

```py
( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）— ID 列表。

+   `token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个 ID 列表。

+   `already_has_special_tokens`（`bool`，*可选*，默认为`False`）— 标记列表是否已经使用特殊标记格式化。

返回

`List[int]`

一个整数列表，范围为[0, 1]：1 表示特殊标记，0 表示序列标记。

从没有添加特殊标记的标记列表中检索序列 ID。当使用分词器的`prepare_for_model`方法添加特殊标记时，将调用此方法。
