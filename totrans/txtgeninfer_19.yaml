- en: Safetensors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/text-generation-inference/conceptual/safetensors](https://huggingface.co/docs/text-generation-inference/conceptual/safetensors)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Safetensors is a model serialization format for deep learning models. It is
    [faster](https://huggingface.co/docs/safetensors/speed) and safer compared to
    other serialization formats like pickle (which is used under the hood in many
    deep learning libraries).
  prefs: []
  type: TYPE_NORMAL
- en: TGI depends on safetensors format mainly to enable [tensor parallelism sharding](./tensor_parallelism).
    For a given model repository during serving, TGI looks for safetensors weights.
    If there are no safetensors weights, TGI converts the PyTorch weights to safetensors
    format.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about safetensors by reading the [safetensors documentation](https://huggingface.co/docs/safetensors/index).
  prefs: []
  type: TYPE_NORMAL
