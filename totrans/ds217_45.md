# 加载表格数据

> 原始文本：[https://huggingface.co/docs/datasets/tabular_load](https://huggingface.co/docs/datasets/tabular_load)

表格数据集是用于描述以行和列存储的任何数据的通用数据集，其中行代表一个示例，列代表一个特征（可以是连续的或分类的）。这些数据集通常存储在CSV文件、Pandas数据框和数据库表中。本指南将向您展示如何从以下内容加载和创建表格数据集：

+   CSV文件

+   Pandas数据框

+   数据库

## CSV文件

数据集可以通过在[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)方法中指定通用的`csv`数据集构建器名称来读取CSV文件。要加载多个CSV文件，将它们作为列表传递给`data_files`参数：

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("csv", data_files="my_file.csv")

# load multiple CSV files
>>> dataset = load_dataset("csv", data_files=["my_file_1.csv", "my_file_2.csv", "my_file_3.csv"])
```

您还可以将特定的CSV文件映射到训练和测试拆分：

```py
>>> dataset = load_dataset("csv", data_files={"train": ["my_train_file_1.csv", "my_train_file_2.csv"], "test": "my_test_file.csv"})
```

要加载远程CSV文件，请传递URLs：

```py
>>> base_url = "https://huggingface.co/datasets/lhoestq/demo1/resolve/main/data/"
>>> dataset = load_dataset('csv', data_files={"train": base_url + "train.csv", "test": base_url + "test.csv"})
```

要加载压缩的CSV文件：

```py
>>> url = "https://domain.org/train_data.zip"
>>> data_files = {"train": url}
>>> dataset = load_dataset("csv", data_files=data_files)
```

## Pandas数据框

🤗数据集还支持使用[from_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_pandas)方法从[Pandas数据框](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)加载数据集：

```py
>>> from datasets import Dataset
>>> import pandas as pd

# create a Pandas DataFrame
>>> df = pd.read_csv("https://huggingface.co/datasets/imodels/credit-card/raw/main/train.csv")
>>> df = pd.DataFrame(df)
# load Dataset from Pandas DataFrame
>>> dataset = Dataset.from_pandas(df)
```

使用`splits`参数指定数据集拆分的名称：

```py
>>> train_ds = Dataset.from_pandas(train_df, split="train")
>>> test_ds = Dataset.from_pandas(test_df, split="test")
```

如果数据集看起来不如预期，您应该明确[指定数据集特征](loading#specify-features)。[pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)可能并不总是携带足够的信息，以便Arrow自动推断数据类型。例如，如果DataFrame的长度为`0`，或者Series只包含`None/NaN`对象，类型将被设置为`null`。

## 数据库

通常通过SQL查询访问存储在数据库中的数据集。使用🤗数据集，您可以连接到数据库，查询所需的数据，并创建一个数据集。然后，您可以使用🤗数据集的所有处理功能来准备您的数据集进行训练。

### SQLite

SQLite是一个小型、轻量级的数据库，快速且易于设置。您可以使用现有的数据库，或者跟着开始从头开始。

首先，通过这个[纽约时报的Covid-19数据](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)创建一个快速的SQLite数据库：

```py
>>> import sqlite3
>>> import pandas as pd

>>> conn = sqlite3.connect("us_covid_data.db")
>>> df = pd.read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
>>> df.to_sql("states", conn, if_exists="replace")
```

这将在`us_covid_data.db`数据库中创建一个`states`表，您现在可以将其加载到数据集中。

要连接到数据库，您需要标识数据库的[URI字符串](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)。使用URI字符串连接到数据库会缓存返回的数据集。每个数据库方言的URI字符串都不同，因此请确保查看您使用的数据库的[数据库URL](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)。

对于SQLite，是这样的：

```py
>>> uri = "sqlite:///us_covid_data.db"
```

通过将表名和URI传递给[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)来加载表格：

```py
>>> from datasets import Dataset

>>> ds = Dataset.from_sql("states", uri)
>>> ds
Dataset({
    features: ['index', 'date', 'state', 'fips', 'cases', 'deaths'],
    num_rows: 54382
})
```

然后，您可以使用所有🤗数据集处理功能，例如[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)：

```py
>>> ds.filter(lambda x: x["state"] == "California")
```

您还可以从SQL查询而不是整个表加载数据集，这对于查询和连接多个表非常有用。

通过将查询和URI传递给[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)来加载数据集：

```py
>>> from datasets import Dataset

>>> ds = Dataset.from_sql('SELECT * FROM states WHERE state="California";', uri)
>>> ds
Dataset({
    features: ['index', 'date', 'state', 'fips', 'cases', 'deaths'],
    num_rows: 1019
})
```

然后，您可以使用所有🤗数据集处理功能，例如[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)：

```py
>>> ds.filter(lambda x: x["cases"] > 10000)
```

### PostgreSQL

您也可以连接并从PostgreSQL数据库加载数据集，但是我们不会在文档中直接演示如何操作，因为示例只能在笔记本中运行。相反，请查看如何在这个[notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)中安装和设置PostgreSQL服务器！

在设置好PostgreSQL数据库之后，您可以使用[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)方法从表格或查询中加载数据集。
