# 加载表格数据

> 原始文本：[`huggingface.co/docs/datasets/tabular_load`](https://huggingface.co/docs/datasets/tabular_load)

表格数据集是用于描述以行和列存储的任何数据的通用数据集，其中行代表一个示例，列代表一个特征（可以是连续的或分类的）。这些数据集通常存储在 CSV 文件、Pandas 数据框和数据库表中。本指南将向您展示如何从以下内容加载和创建表格数据集：

+   CSV 文件

+   Pandas 数据框

+   数据库

## CSV 文件

数据集可以通过在 load_dataset()方法中指定通用的`csv`数据集构建器名称来读取 CSV 文件。要加载多个 CSV 文件，将它们作为列表传递给`data_files`参数：

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("csv", data_files="my_file.csv")

# load multiple CSV files
>>> dataset = load_dataset("csv", data_files=["my_file_1.csv", "my_file_2.csv", "my_file_3.csv"])
```

您还可以将特定的 CSV 文件映射到训练和测试拆分：

```py
>>> dataset = load_dataset("csv", data_files={"train": ["my_train_file_1.csv", "my_train_file_2.csv"], "test": "my_test_file.csv"})
```

要加载远程 CSV 文件，请传递 URLs：

```py
>>> base_url = "https://huggingface.co/datasets/lhoestq/demo1/resolve/main/data/"
>>> dataset = load_dataset('csv', data_files={"train": base_url + "train.csv", "test": base_url + "test.csv"})
```

要加载压缩的 CSV 文件：

```py
>>> url = "https://domain.org/train_data.zip"
>>> data_files = {"train": url}
>>> dataset = load_dataset("csv", data_files=data_files)
```

## Pandas 数据框

🤗数据集还支持使用 from_pandas()方法从[Pandas 数据框](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)加载数据集：

```py
>>> from datasets import Dataset
>>> import pandas as pd

# create a Pandas DataFrame
>>> df = pd.read_csv("https://huggingface.co/datasets/imodels/credit-card/raw/main/train.csv")
>>> df = pd.DataFrame(df)
# load Dataset from Pandas DataFrame
>>> dataset = Dataset.from_pandas(df)
```

使用`splits`参数指定数据集拆分的名称：

```py
>>> train_ds = Dataset.from_pandas(train_df, split="train")
>>> test_ds = Dataset.from_pandas(test_df, split="test")
```

如果数据集看起来不如预期，您应该明确指定数据集特征。[pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)可能并不总是携带足够的信息，以便 Arrow 自动推断数据类型。例如，如果 DataFrame 的长度为`0`，或者 Series 只包含`None/NaN`对象，类型将被设置为`null`。

## 数据库

通常通过 SQL 查询访问存储在数据库中的数据集。使用🤗数据集，您可以连接到数据库，查询所需的数据，并创建一个数据集。然后，您可以使用🤗数据集的所有处理功能来准备您的数据集进行训练。

### SQLite

SQLite 是一个小型、轻量级的数据库，快速且易于设置。您可以使用现有的数据库，或者跟着开始从头开始。

首先，通过这个[纽约时报的 Covid-19 数据](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)创建一个快速的 SQLite 数据库：

```py
>>> import sqlite3
>>> import pandas as pd

>>> conn = sqlite3.connect("us_covid_data.db")
>>> df = pd.read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
>>> df.to_sql("states", conn, if_exists="replace")
```

这将在`us_covid_data.db`数据库中创建一个`states`表，您现在可以将其加载到数据集中。

要连接到数据库，您需要标识数据库的[URI 字符串](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)。使用 URI 字符串连接到数据库会缓存返回的数据集。每个数据库方言的 URI 字符串都不同，因此请确保查看您使用的数据库的[数据库 URL](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)。

对于 SQLite，是这样的：

```py
>>> uri = "sqlite:///us_covid_data.db"
```

通过将表名和 URI 传递给 from_sql()来加载表格：

```py
>>> from datasets import Dataset

>>> ds = Dataset.from_sql("states", uri)
>>> ds
Dataset({
    features: ['index', 'date', 'state', 'fips', 'cases', 'deaths'],
    num_rows: 54382
})
```

然后，您可以使用所有🤗数据集处理功能，例如 filter()：

```py
>>> ds.filter(lambda x: x["state"] == "California")
```

您还可以从 SQL 查询而不是整个表加载数据集，这对于查询和连接多个表非常有用。

通过将查询和 URI 传递给 from_sql()来加载数据集：

```py
>>> from datasets import Dataset

>>> ds = Dataset.from_sql('SELECT * FROM states WHERE state="California";', uri)
>>> ds
Dataset({
    features: ['index', 'date', 'state', 'fips', 'cases', 'deaths'],
    num_rows: 1019
})
```

然后，您可以使用所有🤗数据集处理功能，例如 filter()：

```py
>>> ds.filter(lambda x: x["cases"] > 10000)
```

### PostgreSQL

您也可以连接并从 PostgreSQL 数据库加载数据集，但是我们不会在文档中直接演示如何操作，因为示例只能在笔记本中运行。相反，请查看如何在这个[notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)中安装和设置 PostgreSQL 服务器！

在设置好 PostgreSQL 数据库之后，您可以使用 from_sql()方法从表格或查询中加载数据集。
