# åŠ è½½è¡¨æ ¼æ•°æ®

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/datasets/tabular_load](https://huggingface.co/docs/datasets/tabular_load)

è¡¨æ ¼æ•°æ®é›†æ˜¯ç”¨äºæè¿°ä»¥è¡Œå’Œåˆ—å­˜å‚¨çš„ä»»ä½•æ•°æ®çš„é€šç”¨æ•°æ®é›†ï¼Œå…¶ä¸­è¡Œä»£è¡¨ä¸€ä¸ªç¤ºä¾‹ï¼Œåˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å¾ï¼ˆå¯ä»¥æ˜¯è¿ç»­çš„æˆ–åˆ†ç±»çš„ï¼‰ã€‚è¿™äº›æ•°æ®é›†é€šå¸¸å­˜å‚¨åœ¨CSVæ–‡ä»¶ã€Pandasæ•°æ®æ¡†å’Œæ•°æ®åº“è¡¨ä¸­ã€‚æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä»ä»¥ä¸‹å†…å®¹åŠ è½½å’Œåˆ›å»ºè¡¨æ ¼æ•°æ®é›†ï¼š

+   CSVæ–‡ä»¶

+   Pandasæ•°æ®æ¡†

+   æ•°æ®åº“

## CSVæ–‡ä»¶

æ•°æ®é›†å¯ä»¥é€šè¿‡åœ¨[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)æ–¹æ³•ä¸­æŒ‡å®šé€šç”¨çš„`csv`æ•°æ®é›†æ„å»ºå™¨åç§°æ¥è¯»å–CSVæ–‡ä»¶ã€‚è¦åŠ è½½å¤šä¸ªCSVæ–‡ä»¶ï¼Œå°†å®ƒä»¬ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™`data_files`å‚æ•°ï¼š

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("csv", data_files="my_file.csv")

# load multiple CSV files
>>> dataset = load_dataset("csv", data_files=["my_file_1.csv", "my_file_2.csv", "my_file_3.csv"])
```

æ‚¨è¿˜å¯ä»¥å°†ç‰¹å®šçš„CSVæ–‡ä»¶æ˜ å°„åˆ°è®­ç»ƒå’Œæµ‹è¯•æ‹†åˆ†ï¼š

```py
>>> dataset = load_dataset("csv", data_files={"train": ["my_train_file_1.csv", "my_train_file_2.csv"], "test": "my_test_file.csv"})
```

è¦åŠ è½½è¿œç¨‹CSVæ–‡ä»¶ï¼Œè¯·ä¼ é€’URLsï¼š

```py
>>> base_url = "https://huggingface.co/datasets/lhoestq/demo1/resolve/main/data/"
>>> dataset = load_dataset('csv', data_files={"train": base_url + "train.csv", "test": base_url + "test.csv"})
```

è¦åŠ è½½å‹ç¼©çš„CSVæ–‡ä»¶ï¼š

```py
>>> url = "https://domain.org/train_data.zip"
>>> data_files = {"train": url}
>>> dataset = load_dataset("csv", data_files=data_files)
```

## Pandasæ•°æ®æ¡†

ğŸ¤—æ•°æ®é›†è¿˜æ”¯æŒä½¿ç”¨[from_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_pandas)æ–¹æ³•ä»[Pandasæ•°æ®æ¡†](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)åŠ è½½æ•°æ®é›†ï¼š

```py
>>> from datasets import Dataset
>>> import pandas as pd

# create a Pandas DataFrame
>>> df = pd.read_csv("https://huggingface.co/datasets/imodels/credit-card/raw/main/train.csv")
>>> df = pd.DataFrame(df)
# load Dataset from Pandas DataFrame
>>> dataset = Dataset.from_pandas(df)
```

ä½¿ç”¨`splits`å‚æ•°æŒ‡å®šæ•°æ®é›†æ‹†åˆ†çš„åç§°ï¼š

```py
>>> train_ds = Dataset.from_pandas(train_df, split="train")
>>> test_ds = Dataset.from_pandas(test_df, split="test")
```

å¦‚æœæ•°æ®é›†çœ‹èµ·æ¥ä¸å¦‚é¢„æœŸï¼Œæ‚¨åº”è¯¥æ˜ç¡®[æŒ‡å®šæ•°æ®é›†ç‰¹å¾](loading#specify-features)ã€‚[pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)å¯èƒ½å¹¶ä¸æ€»æ˜¯æºå¸¦è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä»¥ä¾¿Arrowè‡ªåŠ¨æ¨æ–­æ•°æ®ç±»å‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœDataFrameçš„é•¿åº¦ä¸º`0`ï¼Œæˆ–è€…SeriesåªåŒ…å«`None/NaN`å¯¹è±¡ï¼Œç±»å‹å°†è¢«è®¾ç½®ä¸º`null`ã€‚

## æ•°æ®åº“

é€šå¸¸é€šè¿‡SQLæŸ¥è¯¢è®¿é—®å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„æ•°æ®é›†ã€‚ä½¿ç”¨ğŸ¤—æ•°æ®é›†ï¼Œæ‚¨å¯ä»¥è¿æ¥åˆ°æ•°æ®åº“ï¼ŒæŸ¥è¯¢æ‰€éœ€çš„æ•°æ®ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ•°æ®é›†ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ğŸ¤—æ•°æ®é›†çš„æ‰€æœ‰å¤„ç†åŠŸèƒ½æ¥å‡†å¤‡æ‚¨çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚

### SQLite

SQLiteæ˜¯ä¸€ä¸ªå°å‹ã€è½»é‡çº§çš„æ•°æ®åº“ï¼Œå¿«é€Ÿä¸”æ˜“äºè®¾ç½®ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ç°æœ‰çš„æ•°æ®åº“ï¼Œæˆ–è€…è·Ÿç€å¼€å§‹ä»å¤´å¼€å§‹ã€‚

é¦–å…ˆï¼Œé€šè¿‡è¿™ä¸ª[çº½çº¦æ—¶æŠ¥çš„Covid-19æ•°æ®](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)åˆ›å»ºä¸€ä¸ªå¿«é€Ÿçš„SQLiteæ•°æ®åº“ï¼š

```py
>>> import sqlite3
>>> import pandas as pd

>>> conn = sqlite3.connect("us_covid_data.db")
>>> df = pd.read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
>>> df.to_sql("states", conn, if_exists="replace")
```

è¿™å°†åœ¨`us_covid_data.db`æ•°æ®åº“ä¸­åˆ›å»ºä¸€ä¸ª`states`è¡¨ï¼Œæ‚¨ç°åœ¨å¯ä»¥å°†å…¶åŠ è½½åˆ°æ•°æ®é›†ä¸­ã€‚

è¦è¿æ¥åˆ°æ•°æ®åº“ï¼Œæ‚¨éœ€è¦æ ‡è¯†æ•°æ®åº“çš„[URIå­—ç¬¦ä¸²](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)ã€‚ä½¿ç”¨URIå­—ç¬¦ä¸²è¿æ¥åˆ°æ•°æ®åº“ä¼šç¼“å­˜è¿”å›çš„æ•°æ®é›†ã€‚æ¯ä¸ªæ•°æ®åº“æ–¹è¨€çš„URIå­—ç¬¦ä¸²éƒ½ä¸åŒï¼Œå› æ­¤è¯·ç¡®ä¿æŸ¥çœ‹æ‚¨ä½¿ç”¨çš„æ•°æ®åº“çš„[æ•°æ®åº“URL](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)ã€‚

å¯¹äºSQLiteï¼Œæ˜¯è¿™æ ·çš„ï¼š

```py
>>> uri = "sqlite:///us_covid_data.db"
```

é€šè¿‡å°†è¡¨åå’ŒURIä¼ é€’ç»™[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)æ¥åŠ è½½è¡¨æ ¼ï¼š

```py
>>> from datasets import Dataset

>>> ds = Dataset.from_sql("states", uri)
>>> ds
Dataset({
    features: ['index', 'date', 'state', 'fips', 'cases', 'deaths'],
    num_rows: 54382
})
```

ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ‰€æœ‰ğŸ¤—æ•°æ®é›†å¤„ç†åŠŸèƒ½ï¼Œä¾‹å¦‚[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)ï¼š

```py
>>> ds.filter(lambda x: x["state"] == "California")
```

æ‚¨è¿˜å¯ä»¥ä»SQLæŸ¥è¯¢è€Œä¸æ˜¯æ•´ä¸ªè¡¨åŠ è½½æ•°æ®é›†ï¼Œè¿™å¯¹äºæŸ¥è¯¢å’Œè¿æ¥å¤šä¸ªè¡¨éå¸¸æœ‰ç”¨ã€‚

é€šè¿‡å°†æŸ¥è¯¢å’ŒURIä¼ é€’ç»™[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)æ¥åŠ è½½æ•°æ®é›†ï¼š

```py
>>> from datasets import Dataset

>>> ds = Dataset.from_sql('SELECT * FROM states WHERE state="California";', uri)
>>> ds
Dataset({
    features: ['index', 'date', 'state', 'fips', 'cases', 'deaths'],
    num_rows: 1019
})
```

ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ‰€æœ‰ğŸ¤—æ•°æ®é›†å¤„ç†åŠŸèƒ½ï¼Œä¾‹å¦‚[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)ï¼š

```py
>>> ds.filter(lambda x: x["cases"] > 10000)
```

### PostgreSQL

æ‚¨ä¹Ÿå¯ä»¥è¿æ¥å¹¶ä»PostgreSQLæ•°æ®åº“åŠ è½½æ•°æ®é›†ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸ä¼šåœ¨æ–‡æ¡£ä¸­ç›´æ¥æ¼”ç¤ºå¦‚ä½•æ“ä½œï¼Œå› ä¸ºç¤ºä¾‹åªèƒ½åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œã€‚ç›¸åï¼Œè¯·æŸ¥çœ‹å¦‚ä½•åœ¨è¿™ä¸ª[notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)ä¸­å®‰è£…å’Œè®¾ç½®PostgreSQLæœåŠ¡å™¨ï¼

åœ¨è®¾ç½®å¥½PostgreSQLæ•°æ®åº“ä¹‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)æ–¹æ³•ä»è¡¨æ ¼æˆ–æŸ¥è¯¢ä¸­åŠ è½½æ•°æ®é›†ã€‚
