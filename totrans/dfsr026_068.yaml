- en: LoRA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/diffusers/training/lora](https://huggingface.co/docs/diffusers/training/lora)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/144.2de054e3.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/HfOption.fc88c804.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/stores.aa51e67d.js">
  prefs: []
  type: TYPE_NORMAL
- en: This is experimental and the API may change in the future.
  prefs: []
  type: TYPE_NORMAL
- en: '[LoRA (Low-Rank Adaptation of Large Language Models)](https://hf.co/papers/2106.09685)
    is a popular and lightweight training technique that significantly reduces the
    number of trainable parameters. It works by inserting a smaller number of new
    weights into the model and only these are trained. This makes training with LoRA
    much faster, memory-efficient, and produces smaller model weights (a few hundred
    MBs), which are easier to store and share. LoRA can also be combined with other
    training techniques like DreamBooth to speedup training.'
  prefs: []
  type: TYPE_NORMAL
- en: LoRA is very versatile and supported for [DreamBooth](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py),
    [Kandinsky 2.2](https://github.com/huggingface/diffusers/blob/main/examples/kandinsky2_2/text_to_image/train_text_to_image_lora_decoder.py),
    [Stable Diffusion XL](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora_sdxl.py),
    [text-to-image](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py),
    and [Wuerstchen](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_lora_prior.py).
  prefs: []
  type: TYPE_NORMAL
- en: This guide will explore the [train_text_to_image_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before running the script, make sure you install the library from source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Navigate to the example folder with the training script and install the required
    dependencies for the script youâ€™re using:'
  prefs: []
  type: TYPE_NORMAL
- en: PyTorchFlax
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ðŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ðŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize an ðŸ¤— Accelerate environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To setup a default ðŸ¤— Accelerate environment without choosing any configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Or if your environment doesnâ€™t support an interactive shell, like a notebook,
    you can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the script
    in detail. If youâ€™re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py)
    and let us know if you have any questions or concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Script parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The training script has many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L85)
    function. Default values are provided for most parameters that work pretty well,
    but you can also set your own values in the training command if youâ€™d like.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to increase the number of epochs to train:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Many of the basic and important parameters are described in the [Text-to-image](text2image#script-parameters)
    training guide, so this guide just focuses on the LoRA relevant parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--rank`: the inner dimension of the low-rank matrices to train; a higher rank
    means more trainable parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--learning_rate`: the default learning rate is 1e-4, but with LoRA, you can
    use a higher learning rate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset preprocessing code and training loop are found in the [`main()`](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L371)
    function, and if you need to adapt the training script, this is where youâ€™ll make
    your changes.
  prefs: []
  type: TYPE_NORMAL
- en: As with the script parameters, a walkthrough of the training script is provided
    in the [Text-to-image](text2image#training-script) training guide. Instead, this
    guide takes a look at the LoRA relevant parts of the script.
  prefs: []
  type: TYPE_NORMAL
- en: 'The script begins by adding the [new LoRA weights](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L447)
    to the attention layers. This involves correctly configuring the weight size for
    each block in the UNet. Youâ€™ll see the `rank` parameter is used to create the
    [LoRAAttnProcessor](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.LoRAAttnProcessor):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The [optimizer](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L519)
    is initialized with the `lora_layers` because these are the only weights thatâ€™ll
    be optimized:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Aside from setting up the LoRA layers, the training script is more or less the
    same as train_text_to_image.py!
  prefs: []
  type: TYPE_NORMAL
- en: Launch the script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once youâ€™ve made all your changes or youâ€™re okay with the default configuration,
    youâ€™re ready to launch the training script! ðŸš€
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s train on the [PokÃ©mon BLIP captions](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)
    dataset to generate our yown PokÃ©mon. Set the environment variables `MODEL_NAME`
    and `DATASET_NAME` to the model and dataset respectively. You should also specify
    where to save the model in `OUTPUT_DIR`, and the name of the model to save to
    on the Hub with `HUB_MODEL_ID`. The script creates and saves the following files
    to your repository:'
  prefs: []
  type: TYPE_NORMAL
- en: saved model checkpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pytorch_lora_weights.safetensors` (the trained LoRA weights)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If youâ€™re training on more than one GPU, add the `--multi_gpu` parameter to
    the `accelerate launch` command.
  prefs: []
  type: TYPE_NORMAL
- en: A full training run takes ~5 hours on a 2080 Ti GPU with 11GB of VRAM.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once training has been completed, you can use your model for inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Next steps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Congratulations on training a new model with LoRA! To learn more about how
    to use your new model, the following guides may be helpful:'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to [load different LoRA formats](../using-diffusers/loading_adapters#LoRA)
    trained using community trainers like Kohya and TheLastBen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to use and [combine multiple LoRAâ€™s](../tutorials/using_peft_for_inference)
    with PEFT for inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
