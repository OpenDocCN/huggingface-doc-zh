# åœ¨ TPU ä¸Šä½¿ç”¨ğŸ¤— Accelerate è¿›è¡Œè®­ç»ƒ

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/accelerate/concept_guides/training_tpu`](https://huggingface.co/docs/accelerate/concept_guides/training_tpu)

åœ¨ TPU ä¸Šè®­ç»ƒå¯èƒ½ä¸åœ¨å¤š GPU ä¸Šè®­ç»ƒç•¥æœ‰ä¸åŒï¼Œå³ä½¿ä½¿ç”¨ğŸ¤— Accelerateã€‚æœ¬æŒ‡å—æ—¨åœ¨å‘æ‚¨å±•ç¤ºåº”è¯¥æ³¨æ„çš„åœ°æ–¹ä»¥åŠåŸå› ï¼Œä»¥åŠä¸€èˆ¬çš„æœ€ä½³å®è·µã€‚

## åœ¨ç¬”è®°æœ¬ä¸­è®­ç»ƒ

åœ¨ TPU ä¸Šè®­ç»ƒæ—¶çš„ä¸»è¦å…³æ³¨ç‚¹æ¥è‡ª notebook_launcher()ã€‚å¦‚åœ¨ notebook æ•™ç¨‹ä¸­æåˆ°çš„ï¼Œæ‚¨éœ€è¦å°†è®­ç»ƒä»£ç é‡æ„ä¸ºä¸€ä¸ªå¯ä»¥ä¼ é€’ç»™ notebook_launcher()å‡½æ•°çš„å‡½æ•°ï¼Œå¹¶æ³¨æ„ä¸è¦åœ¨ GPU ä¸Šå£°æ˜ä»»ä½•å¼ é‡ã€‚

åœ¨ TPU ä¸Šï¼Œæœ€åä¸€éƒ¨åˆ†å¹¶ä¸é‚£ä¹ˆé‡è¦ï¼Œéœ€è¦ç†è§£çš„ä¸€ä¸ªå…³é”®éƒ¨åˆ†æ˜¯ï¼Œå½“æ‚¨ä»ç¬”è®°æœ¬å¯åŠ¨ä»£ç æ—¶ï¼Œæ‚¨æ˜¯é€šè¿‡ä¸€ç§ç§°ä¸º**forking**çš„è¿‡ç¨‹è¿›è¡Œçš„ã€‚å½“ä»å‘½ä»¤è¡Œå¯åŠ¨æ—¶ï¼Œæ‚¨æ‰§è¡Œ**spawning**ï¼Œå…¶ä¸­ python è¿›ç¨‹å½“å‰æœªè¿è¡Œï¼Œæ‚¨*ç”Ÿæˆ*ä¸€ä¸ªæ–°è¿›ç¨‹ã€‚ç”±äºæ‚¨çš„ Jupyter ç¬”è®°æœ¬å·²ç»åœ¨ä½¿ç”¨ python è¿›ç¨‹ï¼Œå› æ­¤æ‚¨éœ€è¦ä»ä¸­*fork*ä¸€ä¸ªæ–°è¿›ç¨‹æ¥å¯åŠ¨æ‚¨çš„ä»£ç ã€‚

è¿™ä¸€ç‚¹çš„é‡è¦æ€§åœ¨äºå£°æ˜æ‚¨çš„æ¨¡å‹ã€‚åœ¨åˆ†å‰çš„ TPU è¿›ç¨‹ä¸­ï¼Œå»ºè®®æ‚¨å®ä¾‹åŒ–æ‚¨çš„æ¨¡å‹*ä¸€æ¬¡*ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æ‚¨çš„è®­ç»ƒå‡½æ•°ã€‚è¿™ä¸åœ¨ GPU ä¸Šè®­ç»ƒæ—¶åˆ›å»º`n`ä¸ªåœ¨æŸäº›æ—¶åˆ»åŒæ­¥æ¢¯åº¦å¹¶åå‘ä¼ æ’­çš„æ¨¡å‹ä¸åŒã€‚ç›¸åï¼Œä¸€ä¸ªæ¨¡å‹å®ä¾‹åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¹‹é—´å…±äº«ï¼Œå¹¶æ¥å›ä¼ é€’ã€‚è¿™åœ¨è®­ç»ƒä½èµ„æº TPU æ—¶å°¤ä¸ºé‡è¦ï¼Œä¾‹å¦‚åœ¨ Kaggle å†…æ ¸æˆ– Google Colaboratory ä¸­æä¾›çš„ TPU ä¸Šã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªä¼ é€’ç»™ notebook_launcher()çš„è®­ç»ƒå‡½æ•°ç¤ºä¾‹ï¼Œå¦‚æœåœ¨ CPU æˆ– GPU ä¸Šè®­ç»ƒï¼š

æ­¤ä»£ç ç‰‡æ®µåŸºäº`simple_nlp_example`ç¬”è®°æœ¬ä¸­çš„ä»£ç ï¼Œç¨ä½œä¿®æ”¹ä»¥ç®€åŒ–

```py
def training_function():
    # Initialize accelerator
    accelerator = Accelerator()
    model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=2)
    train_dataloader, eval_dataloader = create_dataloaders(
        train_batch_size=hyperparameters["train_batch_size"], eval_batch_size=hyperparameters["eval_batch_size"]
    )

    # Instantiate optimizer
    optimizer = AdamW(params=model.parameters(), lr=hyperparameters["learning_rate"])

    # Prepare everything
    # There is no specific order to remember, we just need to unpack the objects in the same order we gave them to the
    # prepare method.
    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
        model, optimizer, train_dataloader, eval_dataloader
    )

    num_epochs = hyperparameters["num_epochs"]
    # Now we train the model
    for epoch in range(num_epochs):
        model.train()
        for step, batch in enumerate(train_dataloader):
            outputs = model(**batch)
            loss = outputs.loss
            accelerator.backward(loss)

            optimizer.step()
            optimizer.zero_grad()
```

```py
from accelerate import notebook_launcher

notebook_launcher(training_function)
```

å¦‚æœğŸ¤— Accelerate å·²é…ç½®ä¸º TPUï¼Œåˆ™`notebook_launcher`å°†é»˜è®¤ä¸º 8 ä¸ªè¿›ç¨‹

å¦‚æœæ‚¨åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨æ­¤ç¤ºä¾‹å¹¶åœ¨å…¶ä¸­å£°æ˜æ¨¡å‹ï¼Œåˆ™åœ¨ä½èµ„æºç³»ç»Ÿä¸Šå¯èƒ½ä¼šçœ‹åˆ°é”™è¯¯ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
ProcessExitedException: process 0 terminated with signal SIGSEGV
```

è¿™ä¸ªé”™è¯¯*æå…¶*éš¾ä»¥ç†è§£ï¼Œä½†åŸºæœ¬è§£é‡Šæ˜¯æ‚¨çš„ç³»ç»Ÿ RAM ç”¨å®Œäº†ã€‚æ‚¨å¯ä»¥é€šè¿‡é‡æ–°é…ç½®è®­ç»ƒå‡½æ•°ä»¥æ¥å—å•ä¸ª`model`å‚æ•°å¹¶åœ¨å¤–éƒ¨å•å…ƒæ ¼ä¸­å£°æ˜å®ƒæ¥å®Œå…¨é¿å…è¿™ç§æƒ…å†µï¼š

```py
# In another Jupyter cell
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=2)
```

```py
+ def training_function(model):
      # Initialize accelerator
      accelerator = Accelerator()
-     model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=2)
      train_dataloader, eval_dataloader = create_dataloaders(
          train_batch_size=hyperparameters["train_batch_size"], eval_batch_size=hyperparameters["eval_batch_size"]
      )
  ...
```

æœ€åè°ƒç”¨è®­ç»ƒå‡½æ•°ï¼š

```py
  from accelerate import notebook_launcher
- notebook_launcher(training_function)
+ notebook_launcher(training_function, (model,))
```

ä¸Šè¿°è§£å†³æ–¹æ³•ä»…åœ¨ä» Jupyter Notebook å¯åŠ¨ TPU å®ä¾‹æ—¶éœ€è¦ï¼Œä¾‹å¦‚åœ¨ Google Colaboratory æˆ– Kaggle ç­‰ä½èµ„æºæœåŠ¡å™¨ä¸Šã€‚å¦‚æœä½¿ç”¨è„šæœ¬æˆ–åœ¨æ›´å¼ºå¤§çš„æœåŠ¡å™¨ä¸Šå¯åŠ¨ï¼Œåˆ™ä¸éœ€è¦äº‹å…ˆå£°æ˜æ¨¡å‹ã€‚

## æ··åˆç²¾åº¦å’Œå…¨å±€å˜é‡

å¦‚åœ¨æ··åˆç²¾åº¦æ•™ç¨‹ä¸­æåˆ°çš„ï¼ŒğŸ¤— Accelerate æ”¯æŒ fp16 å’Œ bf16ï¼Œä¸¤è€…éƒ½å¯ä»¥åœ¨ TPU ä¸Šä½¿ç”¨ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç†æƒ³æƒ…å†µä¸‹åº”è¯¥ä½¿ç”¨`bf16`ï¼Œå› ä¸ºå®ƒéå¸¸é«˜æ•ˆã€‚

åœ¨ TPU ä¸Šä½¿ç”¨`bf16`å’ŒğŸ¤— Accelerate æ—¶ï¼Œæœ‰ä¸¤ä¸ªâ€œå±‚â€ï¼Œå³åŸºæœ¬çº§åˆ«å’Œæ“ä½œçº§åˆ«ã€‚

åœ¨åŸºæœ¬çº§åˆ«ä¸Šï¼Œå½“å°†`mixed_precision="bf16"`ä¼ é€’ç»™`Accelerator`æ—¶ï¼Œè¿™æ˜¯å¯ç”¨çš„ï¼Œä¾‹å¦‚ï¼š

```py
accelerator = Accelerator(mixed_precision="bf16")
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨ TPU ä¸Šå°†`torch.float`å’Œ`torch.double`è½¬æ¢ä¸º`bfloat16`ã€‚è®¾ç½®çš„å…·ä½“é…ç½®æ˜¯å°†ç¯å¢ƒå˜é‡`XLA_USE_BF16`è®¾ç½®ä¸º`1`ã€‚

æ‚¨å¯ä»¥æ‰§è¡Œè¿›ä¸€æ­¥çš„é…ç½®ï¼Œå³è®¾ç½®`XLA_DOWNCAST_BF16`ç¯å¢ƒå˜é‡ã€‚å¦‚æœè®¾ç½®ä¸º`1`ï¼Œé‚£ä¹ˆ`torch.float`æ˜¯`bfloat16`ï¼Œ`torch.double`æ˜¯`float32`ã€‚

è¿™æ˜¯åœ¨ä¼ é€’`downcast_bf16=True`æ—¶åœ¨`Accelerator`å¯¹è±¡ä¸­æ‰§è¡Œçš„ã€‚

```py
accelerator = Accelerator(mixed_precision="bf16", downcast_bf16=True)
```

åœ¨è®¡ç®—æŒ‡æ ‡ã€è®°å½•å€¼ç­‰éœ€è¦ä½¿ç”¨åŸå§‹ bf16 å¼ é‡æ—¶ï¼Œä½¿ç”¨ downcasting è€Œä¸æ˜¯ bf16 æ˜¯å¾ˆå¥½çš„é€‰æ‹©ã€‚

## TPU ä¸Šçš„è®­ç»ƒæ—¶é—´

å½“æ‚¨å¯åŠ¨è„šæœ¬æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°è®­ç»ƒä¸€å¼€å§‹ä¼¼ä¹å¼‚å¸¸ç¼“æ…¢ã€‚è¿™æ˜¯å› ä¸º TPU é¦–å…ˆè¿è¡Œå‡ æ‰¹æ•°æ®ï¼Œä»¥æŸ¥çœ‹éœ€è¦åˆ†é…å¤šå°‘å†…å­˜ï¼Œç„¶åæ‰èƒ½æå…¶é«˜æ•ˆåœ°åˆ©ç”¨è¿™ä¸ªé…ç½®çš„å†…å­˜åˆ†é…ã€‚

å¦‚æœæ‚¨æ³¨æ„åˆ°è¯„ä¼°ä»£ç è®¡ç®—æ¨¡å‹æŒ‡æ ‡æ‰€éœ€çš„æ—¶é—´æ›´é•¿ï¼Œè¿™æ˜¯å› ä¸ºä½¿ç”¨äº†æ›´å¤§çš„æ‰¹é‡å¤§å°ï¼Œå»ºè®®å¦‚æœé€Ÿåº¦å¤ªæ…¢ï¼Œåˆ™ä¿æŒæ‰¹é‡å¤§å°ä¸è®­ç»ƒæ•°æ®ç›¸åŒã€‚å¦åˆ™ï¼Œåœ¨å‰å‡ æ¬¡è¿­ä»£ä¹‹åï¼Œå†…å­˜å°†é‡æ–°åˆ†é…åˆ°è¿™ä¸ªæ–°çš„æ‰¹é‡å¤§å°ã€‚

ä»…ä»…å› ä¸ºå†…å­˜è¢«åˆ†é…å¹¶ä¸æ„å‘³ç€å®ƒä¼šè¢«ä½¿ç”¨ï¼Œæˆ–è€…å½“è¿”å›åˆ°è®­ç»ƒæ•°æ®åŠ è½½å™¨æ—¶æ‰¹é‡å¤§å°ä¼šå¢åŠ ã€‚
