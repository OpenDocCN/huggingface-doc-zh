["```py\n( vocab_file bos_token = '<s>' eos_token = '</s>' unk_token = '<unk>' pad_token = '<pad>' phone_delimiter_token = ' ' word_delimiter_token = None do_phonemize = True phonemizer_lang = 'en-us' phonemizer_backend = 'espeak' **kwargs )\n```", "```py\n( text: Union = None text_pair: Union = None text_target: Union = None text_pair_target: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 is_split_into_words: bool = False pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs ) \u2192 export const metadata = 'undefined';BatchEncoding\n```", "```py\n( sequences: Union skip_special_tokens: bool = False clean_up_tokenization_spaces: bool = None output_char_offsets: bool = False **kwargs ) \u2192 export const metadata = 'undefined';List[str] or ~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput\n```", "```py\n( token_ids: Union skip_special_tokens: bool = False clean_up_tokenization_spaces: bool = None output_char_offsets: bool = False **kwargs ) \u2192 export const metadata = 'undefined';str or ~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput\n```", "```py\n( text: str phonemizer_lang: Optional = None )\n```"]