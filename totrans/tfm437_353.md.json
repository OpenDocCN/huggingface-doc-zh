["```py\n( vocab_size = 50265 hidden_size = 768 num_hidden_layers = 12 num_attention_heads = 12 intermediate_size = 3072 hidden_act = 'gelu' hidden_dropout_prob = 0.1 attention_probs_dropout_prob = 0.1 max_position_embeddings = 512 type_vocab_size = 2 initializer_range = 0.02 layer_norm_eps = 1e-05 pad_token_id = 1 bos_token_id = 0 eos_token_id = 2 max_2d_position_embeddings = 1024 coordinate_size = 128 shape_size = 128 has_relative_attention_bias = True rel_pos_bins = 32 max_rel_pos = 128 rel_2d_pos_bins = 64 max_rel_2d_pos = 256 has_spatial_attention_bias = True text_embed = True visual_embed = True input_size = 224 num_channels = 3 patch_size = 16 classifier_dropout = None **kwargs )\n```", "```py\n>>> from transformers import LayoutLMv3Config, LayoutLMv3Model\n\n>>> # Initializing a LayoutLMv3 microsoft/layoutlmv3-base style configuration\n>>> configuration = LayoutLMv3Config()\n\n>>> # Initializing a model (with random weights) from the microsoft/layoutlmv3-base style configuration\n>>> model = LayoutLMv3Model(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( *args **kwargs )\n```", "```py\n( images **kwargs )\n```", "```py\n( do_resize: bool = True size: Dict = None resample: Resampling = <Resampling.BILINEAR: 2> do_rescale: bool = True rescale_value: float = 0.00392156862745098 do_normalize: bool = True image_mean: Union = None image_std: Union = None apply_ocr: bool = True ocr_lang: Optional = None tesseract_config: Optional = '' **kwargs )\n```", "```py\n( images: Union do_resize: bool = None size: Dict = None resample = None do_rescale: bool = None rescale_factor: float = None do_normalize: bool = None image_mean: Union = None image_std: Union = None apply_ocr: bool = None ocr_lang: Optional = None tesseract_config: Optional = None return_tensors: Union = None data_format: ChannelDimension = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )\n```", "```py\n( vocab_file merges_file errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = True cls_token_box = [0, 0, 0, 0] sep_token_box = [0, 0, 0, 0] pad_token_box = [0, 0, 0, 0] pad_token_label = -100 only_label_first_subword = True **kwargs )\n```", "```py\n( text: Union text_pair: Union = None boxes: Union = None word_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```", "```py\n( vocab_file = None merges_file = None tokenizer_file = None errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = True trim_offsets = True cls_token_box = [0, 0, 0, 0] sep_token_box = [0, 0, 0, 0] pad_token_box = [0, 0, 0, 0] pad_token_label = -100 only_label_first_subword = True **kwargs )\n```", "```py\n( text: Union text_pair: Union = None boxes: Union = None word_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )\n```", "```py\n( image_processor = None tokenizer = None **kwargs )\n```", "```py\n( images text: Union = None text_pair: Union = None boxes: Union = None word_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True return_tensors: Union = None **kwargs )\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None bbox: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, AutoModel\n>>> from datasets import load_dataset\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = AutoModel.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n\n>>> encoding = processor(image, words, boxes=boxes, return_tensors=\"pt\")\n\n>>> outputs = model(**encoding)\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None bbox: Optional = None pixel_values: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.SequenceClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForSequenceClassification\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n\n>>> encoding = processor(image, words, boxes=boxes, return_tensors=\"pt\")\n>>> sequence_label = torch.tensor([1])\n\n>>> outputs = model(**encoding, labels=sequence_label)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None bbox: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None pixel_values: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.TokenClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForTokenClassification\n>>> from datasets import load_dataset\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = AutoModelForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=7)\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n>>> word_labels = example[\"ner_tags\"]\n\n>>> encoding = processor(image, words, boxes=boxes, word_labels=word_labels, return_tensors=\"pt\")\n\n>>> outputs = model(**encoding)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None start_positions: Optional = None end_positions: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None bbox: Optional = None pixel_values: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.QuestionAnsweringModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> question = \"what's his name?\"\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n\n>>> encoding = processor(image, question, words, boxes=boxes, return_tensors=\"pt\")\n>>> start_positions = torch.tensor([1])\n>>> end_positions = torch.tensor([3])\n\n>>> outputs = model(**encoding, start_positions=start_positions, end_positions=end_positions)\n>>> loss = outputs.loss\n>>> start_scores = outputs.start_logits\n>>> end_scores = outputs.end_logits\n```", "```py\n( config *inputs **kwargs )\n```", "```py\n( input_ids: tf.Tensor | None = None bbox: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None pixel_values: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFBaseModelOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoProcessor, TFAutoModel\n>>> from datasets import load_dataset\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = TFAutoModel.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n\n>>> encoding = processor(image, words, boxes=boxes, return_tensors=\"tf\")\n\n>>> outputs = model(**encoding)\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n( config: LayoutLMv3Config **kwargs )\n```", "```py\n( input_ids: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None bbox: tf.Tensor | None = None pixel_values: tf.Tensor | None = None training: Optional[bool] = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSequenceClassifierOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoProcessor, TFAutoModelForSequenceClassification\n>>> from datasets import load_dataset\n>>> import tensorflow as tf\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = TFAutoModelForSequenceClassification.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n\n>>> encoding = processor(image, words, boxes=boxes, return_tensors=\"tf\")\n>>> sequence_label = tf.convert_to_tensor([1])\n\n>>> outputs = model(**encoding, labels=sequence_label)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config: LayoutLMv3Config **kwargs )\n```", "```py\n( input_ids: tf.Tensor | None = None bbox: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None pixel_values: tf.Tensor | None = None training: Optional[bool] = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFTokenClassifierOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoProcessor, TFAutoModelForTokenClassification\n>>> from datasets import load_dataset\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = TFAutoModelForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=7)\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n>>> word_labels = example[\"ner_tags\"]\n\n>>> encoding = processor(image, words, boxes=boxes, word_labels=word_labels, return_tensors=\"tf\")\n\n>>> outputs = model(**encoding)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config: LayoutLMv3Config **kwargs )\n```", "```py\n( input_ids: tf.Tensor | None = None attention_mask: tf.Tensor | None = None token_type_ids: tf.Tensor | None = None position_ids: tf.Tensor | None = None head_mask: tf.Tensor | None = None inputs_embeds: tf.Tensor | None = None start_positions: tf.Tensor | None = None end_positions: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None bbox: tf.Tensor | None = None pixel_values: tf.Tensor | None = None return_dict: Optional[bool] = None training: bool = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoProcessor, TFAutoModelForQuestionAnswering\n>>> from datasets import load_dataset\n>>> import tensorflow as tf\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n>>> model = TFAutoModelForQuestionAnswering.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n>>> dataset = load_dataset(\"nielsr/funsd-layoutlmv3\", split=\"train\")\n>>> example = dataset[0]\n>>> image = example[\"image\"]\n>>> question = \"what's his name?\"\n>>> words = example[\"tokens\"]\n>>> boxes = example[\"bboxes\"]\n\n>>> encoding = processor(image, question, words, boxes=boxes, return_tensors=\"tf\")\n>>> start_positions = tf.convert_to_tensor([1])\n>>> end_positions = tf.convert_to_tensor([3])\n\n>>> outputs = model(**encoding, start_positions=start_positions, end_positions=end_positions)\n>>> loss = outputs.loss\n>>> start_scores = outputs.start_logits\n>>> end_scores = outputs.end_logits\n```"]