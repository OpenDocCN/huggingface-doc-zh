# KDPM2DiscreteScheduler

> 原始文本：[`huggingface.co/docs/diffusers/api/schedulers/dpm_discrete`](https://huggingface.co/docs/diffusers/api/schedulers/dpm_discrete)

`KDPM2DiscreteScheduler`受[Elucidating the Design Space of Diffusion-Based Generative Models](https://huggingface.co/papers/2206.00364)论文启发，调度器从[Katherine Crowson](https://github.com/crowsonkb/)移植并创建。

原始代码库可在[crowsonkb/k-diffusion](https://github.com/crowsonkb/k-diffusion)找到。

## KDPM2DiscreteScheduler

### `class diffusers.KDPM2DiscreteScheduler`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_discrete.py#L71)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.00085 beta_end: float = 0.012 beta_schedule: str = 'linear' trained_betas: Union = None use_karras_sigmas: Optional = False prediction_type: str = 'epsilon' timestep_spacing: str = 'linspace' steps_offset: int = 0 )
```

参数

+   `num_train_timesteps` (`int`, 默认为 1000) — 训练模型的扩散步骤数。

+   `beta_start` (`float`, 默认为 0.00085) — 推理的起始`beta`值。

+   `beta_end` (`float`, 默认为 0.012) — 最终的`beta`值。

+   `beta_schedule` (`str`, 默认为`"linear"`) — beta 调度，从 beta 范围映射到一系列用于步进模型的 beta。选择`linear`或`scaled_linear`。

+   `trained_betas` (`np.ndarray`, *可选*) — 直接传递一个 beta 数组给构造函数，以绕过`beta_start`和`beta_end`。

+   `use_karras_sigmas` (`bool`, *可选*, 默认为`False`) — 在采样过程中使用 Karras sigmas 作为噪声调度中的步长。如果为`True`，则 sigmas 根据噪声级别序列{σi}确定。

+   `prediction_type` (`str`, 默认为`epsilon`, *可选*) — 调度器函数的预测类型；可以是`epsilon`（预测扩散过程的噪声）、`sample`（直接预测有噪声的样本）或`v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文的第 2.4 节）。

+   `timestep_spacing` (`str`, 默认为`"linspace"`) — 时间步长应该如何缩放。有关更多信息，请参阅[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表 2。

+   `steps_offset` (`int`, 默认为 0) — 添加到推理步骤的偏移量。您可以使用`offset=1`和`set_alpha_to_one=False`的组合，使最后一步使用前一个 alpha 乘积的步骤 0，就像在 Stable Diffusion 中一样。

KDPM2DiscreteScheduler 受[Elucidating the Design Space of Diffusion-Based Generative Models](https://huggingface.co/papers/2206.00364)论文中的 DPMSolver2 和 Algorithm 2 启发。

该模型继承自 SchedulerMixin 和 ConfigMixin。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_discrete.py#L179)

```py
( sample: FloatTensor timestep: Union ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

+   `timestep` (`int`, *可选*) — 扩散链中的当前时间步长。

返回

`torch.FloatTensor`

一个缩放的输入样本。

确保与需要根据当前时间步长缩放去噪模型输入的调度器可以互换。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_discrete.py#L209)

```py
( num_inference_steps: int device: Union = None num_train_timesteps: Optional = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步骤数。

+   `device` (`str`或`torch.device`, *可选*) — 应将时间步长移动到的设备。如果为`None`，则不移动时间步长。

设置用于扩散链的离散时间步长（在推理之前运行）。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_discrete.py#L362)

```py
( model_output: Union timestep: Union sample: Union return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output`（`torch.FloatTensor`）— 来自学习扩散模型的直接输出。

+   `timestep`（`float`）— 扩散链中的当前离散时间步。

+   `sample`（`torch.FloatTensor`）— 由扩散过程创建的当前样本实例。

+   `return_dict`（`bool`）— 是否返回 SchedulerOutput 或元组。

返回值

SchedulerOutput 或`tuple`

如果`return_dict`为`True`，则返回 SchedulerOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 从上一个时间步预测样本。此函数从学习模型输出（通常是预测的噪声）中传播扩散过程。

## SchedulerOutput

### `class diffusers.schedulers.scheduling_utils.SchedulerOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_utils.py#L50)

```py
( prev_sample: FloatTensor )
```

参数

+   `prev_sample`（`torch.FloatTensor`，形状为`(batch_size, num_channels, height, width)`，用于图像）— 上一个时间步的计算样本`(x_{t-1})`。`prev_sample`应该在去噪循环中作为下一个模型输入使用。

调度器`step`函数的输出的基类。
