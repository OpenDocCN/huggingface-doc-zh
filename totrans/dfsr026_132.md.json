["```py\n>>> import scipy\n>>> import torch\n>>> from diffusers import AudioLDM2Pipeline\n\n>>> repo_id = \"cvssp/audioldm2\"\n>>> pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n\n>>> # define the prompts\n>>> prompt = \"The sound of a hammer hitting a wooden surface.\"\n>>> negative_prompt = \"Low quality.\"\n\n>>> # set the seed for generator\n>>> generator = torch.Generator(\"cuda\").manual_seed(0)\n\n>>> # run the generation\n>>> audio = pipe(\n...     prompt,\n...     negative_prompt=negative_prompt,\n...     num_inference_steps=200,\n...     audio_length_in_s=10.0,\n...     num_waveforms_per_prompt=3,\n...     generator=generator,\n... ).audios\n\n>>> # save the best audio sample (index 0) as a .wav file\n>>> scipy.io.wavfile.write(\"techno.wav\", rate=16000, data=audio[0])\n```", "```py\n>>> import scipy\n>>> import torch\n>>> from diffusers import AudioLDM2Pipeline\n\n>>> repo_id = \"cvssp/audioldm2\"\n>>> pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n\n>>> # Get text embedding vectors\n>>> prompt_embeds, attention_mask, generated_prompt_embeds = pipe.encode_prompt(\n...     prompt=\"Techno music with a strong, upbeat tempo and high melodic riffs\",\n...     device=\"cuda\",\n...     do_classifier_free_guidance=True,\n... )\n\n>>> # Pass text embeddings to pipeline for text-conditional audio generation\n>>> audio = pipe(\n...     prompt_embeds=prompt_embeds,\n...     attention_mask=attention_mask,\n...     generated_prompt_embeds=generated_prompt_embeds,\n...     num_inference_steps=200,\n...     audio_length_in_s=10.0,\n... ).audios[0]\n\n>>> # save generated audio sample\n>>> scipy.io.wavfile.write(\"techno.wav\", rate=16000, data=audio)\n```"]