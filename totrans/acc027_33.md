# æ¨è¿Ÿæ‰§è¡Œ

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/accelerate/concept_guides/deferring_execution](https://huggingface.co/docs/accelerate/concept_guides/deferring_execution)

å½“è¿è¡Œæ‚¨çš„å¸¸è§„è„šæœ¬æ—¶ï¼ŒæŒ‡ä»¤æŒ‰é¡ºåºæ‰§è¡Œã€‚ä½¿ç”¨ğŸ¤— Accelerateåœ¨å¤šä¸ªGPUä¸ŠåŒæ—¶éƒ¨ç½²è„šæœ¬ä¼šå¼•å…¥ä¸€ä¸ªå¤æ‚æ€§ï¼šè™½ç„¶æ¯ä¸ªè¿›ç¨‹æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æŒ‡ä»¤ï¼Œä½†æœ‰äº›å¯èƒ½æ¯”å…¶ä»–è¿›ç¨‹å¿«ã€‚

æ‚¨å¯èƒ½éœ€è¦ç­‰å¾…æ‰€æœ‰è¿›ç¨‹è¾¾åˆ°æŸä¸€ç‚¹åæ‰æ‰§è¡Œç»™å®šæŒ‡ä»¤ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¡®ä¿æ¯ä¸ªè¿›ç¨‹éƒ½å®Œæˆè®­ç»ƒä¹‹å‰ï¼Œä¸åº”è¯¥ä¿å­˜æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨åŠ è½½æ‰€æœ‰æ¨¡å‹æƒé‡ä¹‹å‰ä¸åº”è¯¥ç»§ç»­è®­ç»ƒã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œåªéœ€åœ¨æ‚¨çš„ä»£ç ä¸­ç¼–å†™ä»¥ä¸‹è¡Œï¼š

```py
accelerator.wait_for_everyone()
```

æ­¤æŒ‡ä»¤å°†é˜»æ­¢æ‰€æœ‰æœ€å…ˆåˆ°è¾¾çš„è¿›ç¨‹ï¼Œç›´åˆ°æ‰€æœ‰å…¶ä»–è¿›ç¨‹éƒ½è¾¾åˆ°è¯¥ç‚¹ï¼ˆå¦‚æœæ‚¨åªåœ¨ä¸€ä¸ªGPUæˆ–CPUä¸Šè¿è¡Œè„šæœ¬ï¼Œåˆ™ä¸ä¼šæ‰§è¡Œä»»ä½•æ“ä½œï¼‰ã€‚

ä»¥ä¸‹åˆ—å‡ºäº†ä½¿ç”¨æ­¤å®ç”¨ç¨‹åºçš„å‡ ä¸ªç¤ºä¾‹æƒ…å†µï¼š

å…¶ä¸­ä¸€äº›ä¸[main_process_first()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.main_process_first)ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸€èµ·ä½¿ç”¨ï¼Œè¯¥ç®¡ç†å™¨åˆ©ç”¨[wait_for_everyone()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.wait_for_everyone)åœ¨è§¦å‘å’Œå¯åŠ¨å…¶ä»–è¿›ç¨‹ä¹‹å‰åœ¨ä¸»è¿›ç¨‹ä¸Šè¿è¡Œä¸€ç»„ç‰¹å®šä»£ç 

## ä¸‹è½½æ•°æ®é›†

åœ¨ä¸‹è½½æ•°æ®é›†æ—¶ï¼Œåº”é¦–å…ˆåœ¨ä¸»è¿›ç¨‹ä¸Šä¸‹è½½æ•°æ®é›†ï¼Œç„¶ååŠ è½½ç¼“å­˜çš„æ•°æ®é›†

`load_dataset`å°†åœ¨å†…éƒ¨æ‰§è¡Œé”å®šï¼Œä»¥é˜»æ­¢åŒæ—¶å‘ç”Ÿå¤šæ¬¡ä¸‹è½½ï¼Œä½†å¦‚æœæ‚¨ä¸‹è½½çš„å†…å®¹ä¸ä½¿ç”¨æ­¤åº“ï¼Œåˆ™åº”ä½¿ç”¨æ­¤æ–¹æ³•ã€‚

```py
with accelerator.main_process_first():
    datasets = load_dataset("glue", "mrpc")
```

åœ¨å¹•åï¼Œè¿™ä¸è°ƒç”¨ç›¸åŒï¼š

```py
# First do something on the main process
if accelerator.is_main_process:
    datasets = load_dataset("glue", "mrpc")
else:
    accelerator.wait_for_everyone()

# And then send it to the rest of them
if not accelerator.is_main_process:
    datasets = load_dataset("glue", "mrpc")
else:
    accelerator.wait_for_everyone()
```

## ä¿å­˜state_dict

ä¿å­˜æ¨¡å‹çš„`state_dict`æ—¶ï¼Œç”±äºé€šå¸¸åªåœ¨ä¸»è¿›ç¨‹ä¸Šä¿å­˜ä¸€ä¸ªæ–‡ä»¶ï¼Œå› æ­¤åº”æŒ‡å®šï¼š

```py
if accelerator.is_main_process:
    model = accelerator.unwrap_model(model)
    torch.save(model.state_dict(), "weights.pth")
```

## åŠ è½½state_dict

åœ¨å°†`state_dict`åŠ è½½åˆ°æ¨¡å‹ã€ä¼˜åŒ–å™¨æˆ–è°ƒåº¦å™¨ä¸­æ—¶ï¼Œåº”ç­‰å¾…æ‰€æœ‰å·¥ä½œè¿›ç¨‹åŠ è½½æƒé‡åå†ç»§ç»­è®­ç»ƒ

```py
with accelerator.main_process_first():
    state = torch.load("weights.pth")
    model.load_state_dict(state)
```

## åº”ç”¨å¤šå·¥ä½œè¿›ç¨‹CPUæ“ä½œ

åœ¨å¤šä¸ªå·¥ä½œè¿›ç¨‹ä¸Šåº”ç”¨`map()`æ“ä½œï¼Œä¾‹å¦‚å¯¹ä»¤ç‰Œè¿›è¡Œæ ‡è®°åŒ–åº”è¯¥é¦–å…ˆåœ¨ä¸»è¿›ç¨‹ä¸Šæ‰§è¡Œï¼Œç„¶åä¼ æ’­åˆ°æ¯ä¸ªè¿›ç¨‹ã€‚

```py
datasets = load_dataset("glue", "mrpc")

with accelerator.main_process_first():
    tokenized_datasets = datasets.map(
        tokenize_function,
        batched=True,
        remove_columns=["idx", "sentence1", "sentence2"],
    )
```

## åº”ç”¨æ£€æŸ¥ï¼Œå¦‚æå‰åœæ­¢

è¦ä½¿ç”¨ç”±ç‰¹å®šè¿›ç¨‹è®¾ç½®çš„æ ‡å¿—è¿›è¡Œæ£€æŸ¥ï¼Œåº”ä½¿ç”¨`set_trigger`å’Œ`check_trigger`APIã€‚è¿™æ ·åšçš„æœ‰ç”¨ç¤ºä¾‹å¯ä»¥åŒ…æ‹¬ä½¿ç”¨æå‰åœæ­¢å¹¶ç›‘è§†æŸå¤±ï¼ˆå› ä¸ºæ¯ä¸ªè¿›ç¨‹ä¸Šçš„æŸå¤±ç•¥æœ‰ä¸åŒï¼‰ç­‰æƒ…å†µã€‚

å½“æ‚¨çš„æ¡ä»¶æ»¡è¶³æ—¶ï¼Œè¯·è°ƒç”¨[Accelerator.set_trigger()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.set_trigger)ï¼Œå¹¶åœ¨ä»»ä½•è¿›ç¨‹ä¸­æ£€æŸ¥è¯¥æ¡ä»¶æ˜¯å¦æ»¡è¶³æ—¶ä½¿ç”¨[Accelerator.check_trigger()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.check_trigger)ï¼š

```py
for (x,y) in data_loader:
    logits = model(x)
    loss = loss_func(logits, y)
    # Assume `should_do_early_stopping` is a custom defined function that returns a conditional
    if should_do_early_stopping(loss):
        accelerator.set_trigger()

    # Later in the training script when we need to check for the breakpoint
    if accelerator.check_trigger():
        break
```
