# 推迟执行

> 原始文本：[https://huggingface.co/docs/accelerate/concept_guides/deferring_execution](https://huggingface.co/docs/accelerate/concept_guides/deferring_execution)

当运行您的常规脚本时，指令按顺序执行。使用🤗 Accelerate在多个GPU上同时部署脚本会引入一个复杂性：虽然每个进程按顺序执行所有指令，但有些可能比其他进程快。

您可能需要等待所有进程达到某一点后才执行给定指令。例如，在确保每个进程都完成训练之前，不应该保存模型，并且在加载所有模型权重之前不应该继续训练。要做到这一点，只需在您的代码中编写以下行：

```py
accelerator.wait_for_everyone()
```

此指令将阻止所有最先到达的进程，直到所有其他进程都达到该点（如果您只在一个GPU或CPU上运行脚本，则不会执行任何操作）。

以下列出了使用此实用程序的几个示例情况：

其中一些与[main_process_first()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.main_process_first)上下文管理器一起使用，该管理器利用[wait_for_everyone()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.wait_for_everyone)在触发和启动其他进程之前在主进程上运行一组特定代码

## 下载数据集

在下载数据集时，应首先在主进程上下载数据集，然后加载缓存的数据集

`load_dataset`将在内部执行锁定，以阻止同时发生多次下载，但如果您下载的内容不使用此库，则应使用此方法。

```py
with accelerator.main_process_first():
    datasets = load_dataset("glue", "mrpc")
```

在幕后，这与调用相同：

```py
# First do something on the main process
if accelerator.is_main_process:
    datasets = load_dataset("glue", "mrpc")
else:
    accelerator.wait_for_everyone()

# And then send it to the rest of them
if not accelerator.is_main_process:
    datasets = load_dataset("glue", "mrpc")
else:
    accelerator.wait_for_everyone()
```

## 保存state_dict

保存模型的`state_dict`时，由于通常只在主进程上保存一个文件，因此应指定：

```py
if accelerator.is_main_process:
    model = accelerator.unwrap_model(model)
    torch.save(model.state_dict(), "weights.pth")
```

## 加载state_dict

在将`state_dict`加载到模型、优化器或调度器中时，应等待所有工作进程加载权重后再继续训练

```py
with accelerator.main_process_first():
    state = torch.load("weights.pth")
    model.load_state_dict(state)
```

## 应用多工作进程CPU操作

在多个工作进程上应用`map()`操作，例如对令牌进行标记化应该首先在主进程上执行，然后传播到每个进程。

```py
datasets = load_dataset("glue", "mrpc")

with accelerator.main_process_first():
    tokenized_datasets = datasets.map(
        tokenize_function,
        batched=True,
        remove_columns=["idx", "sentence1", "sentence2"],
    )
```

## 应用检查，如提前停止

要使用由特定进程设置的标志进行检查，应使用`set_trigger`和`check_trigger`API。这样做的有用示例可以包括使用提前停止并监视损失（因为每个进程上的损失略有不同）等情况。

当您的条件满足时，请调用[Accelerator.set_trigger()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.set_trigger)，并在任何进程中检查该条件是否满足时使用[Accelerator.check_trigger()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.check_trigger)：

```py
for (x,y) in data_loader:
    logits = model(x)
    loss = loss_func(logits, y)
    # Assume `should_do_early_stopping` is a custom defined function that returns a conditional
    if should_do_early_stopping(loss):
        accelerator.set_trigger()

    # Later in the training script when we need to check for the breakpoint
    if accelerator.check_trigger():
        break
```
