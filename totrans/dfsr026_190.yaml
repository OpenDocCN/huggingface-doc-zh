- en: DEISMultistepScheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/diffusers/api/schedulers/deis](https://huggingface.co/docs/diffusers/api/schedulers/deis)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/92.9f5c27d7.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Docstring.93f6f462.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: Diffusion Exponential Integrator Sampler (DEIS) is proposed in [Fast Sampling
    of Diffusion Models with Exponential Integrator](https://huggingface.co/papers/2204.13902)
    by Qinsheng Zhang and Yongxin Chen. `DEISMultistepScheduler` is a fast high order
    solver for diffusion ordinary differential equations (ODEs).
  prefs: []
  type: TYPE_NORMAL
- en: This implementation modifies the polynomial fitting formula in log-rho space
    instead of the original linear `t` space in the DEIS paper. The modification enjoys
    closed-form coefficients for exponential multistep update instead of replying
    on the numerical solver.
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The past few years have witnessed the great success of Diffusion models~(DMs)
    in generating high-fidelity samples in generative modeling tasks. A major limitation
    of the DM is its notoriously slow sampling procedure which normally requires hundreds
    to thousands of time discretization steps of the learned diffusion process to
    reach the desired accuracy. Our goal is to develop a fast sampling method for
    DMs with a much less number of steps while retaining high sample quality. To this
    end, we systematically analyze the sampling procedure in DMs and identify key
    factors that affect the sample quality, among which the method of discretization
    is most crucial. By carefully examining the learned diffusion process, we propose
    Diffusion Exponential Integrator Sampler~(DEIS). It is based on the Exponential
    Integrator designed for discretizing ordinary differential equations (ODEs) and
    leverages a semilinear structure of the learned diffusion process to reduce the
    discretization error. The proposed method can be applied to any DMs and can generate
    high-fidelity samples in as few as 10 steps. In our experiments, it takes about
    3 minutes on one A6000 GPU to generate 50k images from CIFAR10\. Moreover, by
    directly using pre-trained DMs, we achieve the state-of-art sampling performance
    when the number of score function evaluation~(NFE) is limited, e.g., 4.17 FID
    with 10 NFEs, 3.37 FID, and 9.74 IS with only 15 NFEs on CIFAR10\. Code is available
    at [this https URL](https://github.com/qsh-zh/deis).*'
  prefs: []
  type: TYPE_NORMAL
- en: Tips
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is recommended to set `solver_order` to 2 or 3, while `solver_order=1` is
    equivalent to [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler).
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic thresholding from [Imagen](https://huggingface.co/papers/2205.11487)
    is supported, and for pixel-space diffusion models, you can set `thresholding=True`
    to use the dynamic thresholding.
  prefs: []
  type: TYPE_NORMAL
- en: DEISMultistepScheduler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class diffusers.DEISMultistepScheduler'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L74)'
  prefs: []
  type: TYPE_NORMAL
- en: '( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float
    = 0.02 beta_schedule: str = ''linear'' trained_betas: Optional = None solver_order:
    int = 2 prediction_type: str = ''epsilon'' thresholding: bool = False dynamic_thresholding_ratio:
    float = 0.995 sample_max_value: float = 1.0 algorithm_type: str = ''deis'' solver_type:
    str = ''logrho'' lower_order_final: bool = True use_karras_sigmas: Optional =
    False timestep_spacing: str = ''linspace'' steps_offset: int = 0 )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**num_train_timesteps** (`int`, defaults to 1000) — The number of diffusion
    steps to train the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beta_start** (`float`, defaults to 0.0001) — The starting `beta` value of
    inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beta_end** (`float`, defaults to 0.02) — The final `beta` value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beta_schedule** (`str`, defaults to `"linear"`) — The beta schedule, a mapping
    from a beta range to a sequence of betas for stepping the model. Choose from `linear`,
    `scaled_linear`, or `squaredcos_cap_v2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trained_betas** (`np.ndarray`, *optional*) — Pass an array of betas directly
    to the constructor to bypass `beta_start` and `beta_end`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**solver_order** (`int`, defaults to 2) — The DEIS order which can be `1` or
    `2` or `3`. It is recommended to use `solver_order=2` for guided sampling, and
    `solver_order=3` for unconditional sampling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prediction_type** (`str`, defaults to `epsilon`) — Prediction type of the
    scheduler function; can be `epsilon` (predicts the noise of the diffusion process),
    `sample` (directly predicts the noisy sample`) or` v_prediction` (see section
    2.4 of [Imagen Video](https://imagen.research.google/video/paper.pdf) paper).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**thresholding** (`bool`, defaults to `False`) — Whether to use the “dynamic
    thresholding” method. This is unsuitable for latent-space diffusion models such
    as Stable Diffusion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dynamic_thresholding_ratio** (`float`, defaults to 0.995) — The ratio for
    the dynamic thresholding method. Valid only when `thresholding=True`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sample_max_value** (`float`, defaults to 1.0) — The threshold value for dynamic
    thresholding. Valid only when `thresholding=True`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**algorithm_type** (`str`, defaults to `deis`) — The algorithm type for the
    solver.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lower_order_final** (`bool`, defaults to `True`) — Whether to use lower-order
    solvers in the final steps. Only valid for < 15 inference steps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_karras_sigmas** (`bool`, *optional*, defaults to `False`) — Whether to
    use Karras sigmas for step sizes in the noise schedule during the sampling process.
    If `True`, the sigmas are determined according to a sequence of noise levels {σi}.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timestep_spacing** (`str`, defaults to `"linspace"`) — The way the timesteps
    should be scaled. Refer to Table 2 of the [Common Diffusion Noise Schedules and
    Sample Steps are Flawed](https://huggingface.co/papers/2305.08891) for more information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**steps_offset** (`int`, defaults to 0) — An offset added to the inference
    steps. You can use a combination of `offset=1` and `set_alpha_to_one=False` to
    make the last step use step 0 for the previous alpha product like in Stable Diffusion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DEISMultistepScheduler` is a fast high order solver for diffusion ordinary
    differential equations (ODEs).'
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  prefs: []
  type: TYPE_NORMAL
- en: '#### convert_model_output'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L351)'
  prefs: []
  type: TYPE_NORMAL
- en: '( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) → `torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**model_output** (`torch.FloatTensor`) — The direct output from the learned
    diffusion model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timestep** (`int`) — The current discrete timestep in the diffusion chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sample** (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: The converted model output.
  prefs: []
  type: TYPE_NORMAL
- en: Convert the model output to the corresponding type the DEIS algorithm needs.
  prefs: []
  type: TYPE_NORMAL
- en: '#### deis_first_order_update'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L408)'
  prefs: []
  type: TYPE_NORMAL
- en: '( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) → `torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**model_output** (`torch.FloatTensor`) — The direct output from the learned
    diffusion model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timestep** (`int`) — The current discrete timestep in the diffusion chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prev_timestep** (`int`) — The previous discrete timestep in the diffusion
    chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sample** (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: The sample tensor at the previous timestep.
  prefs: []
  type: TYPE_NORMAL
- en: One step for the first-order DEIS (equivalent to DDIM).
  prefs: []
  type: TYPE_NORMAL
- en: '#### multistep_deis_second_order_update'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L466)'
  prefs: []
  type: TYPE_NORMAL
- en: '( model_output_list: List *args sample: FloatTensor = None **kwargs ) → `torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**model_output_list** (`List[torch.FloatTensor]`) — The direct outputs from
    learned diffusion model at current and latter timesteps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sample** (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: The sample tensor at the previous timestep.
  prefs: []
  type: TYPE_NORMAL
- en: One step for the second-order multistep DEIS.
  prefs: []
  type: TYPE_NORMAL
- en: '#### multistep_deis_third_order_update'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L535)'
  prefs: []
  type: TYPE_NORMAL
- en: '( model_output_list: List *args sample: FloatTensor = None **kwargs ) → `torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**model_output_list** (`List[torch.FloatTensor]`) — The direct outputs from
    learned diffusion model at current and latter timesteps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sample** (`torch.FloatTensor`) — A current instance of a sample created by
    diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: The sample tensor at the previous timestep.
  prefs: []
  type: TYPE_NORMAL
- en: One step for the third-order multistep DEIS.
  prefs: []
  type: TYPE_NORMAL
- en: '#### scale_model_input'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L707)'
  prefs: []
  type: TYPE_NORMAL
- en: '( sample: FloatTensor *args **kwargs ) → `torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**sample** (`torch.FloatTensor`) — The input sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: A scaled input sample.
  prefs: []
  type: TYPE_NORMAL
- en: Ensures interchangeability with schedulers that need to scale the denoising
    model input depending on the current timestep.
  prefs: []
  type: TYPE_NORMAL
- en: '#### set_timesteps'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L199)'
  prefs: []
  type: TYPE_NORMAL
- en: '( num_inference_steps: int device: Union = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**num_inference_steps** (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**device** (`str` or `torch.device`, *optional*) — The device to which the
    timesteps should be moved to. If `None`, the timesteps are not moved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sets the discrete timesteps used for the diffusion chain (to be run before inference).
  prefs: []
  type: TYPE_NORMAL
- en: '#### step'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L642)'
  prefs: []
  type: TYPE_NORMAL
- en: '( model_output: FloatTensor timestep: int sample: FloatTensor return_dict:
    bool = True ) → [SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)
    or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**model_output** (`torch.FloatTensor`) — The direct output from learned diffusion
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timestep** (`float`) — The current discrete timestep in the diffusion chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sample** (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_dict** (`bool`) — Whether or not to return a [SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)
    or `tuple`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)
    or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If return_dict is `True`, [SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the sample with the multistep DEIS.
  prefs: []
  type: TYPE_NORMAL
- en: SchedulerOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class diffusers.schedulers.scheduling_utils.SchedulerOutput'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_utils.py#L50)'
  prefs: []
  type: TYPE_NORMAL
- en: '( prev_sample: FloatTensor )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**prev_sample** (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` for images) — Computed sample `(x_{t-1})` of previous timestep. `prev_sample`
    should be used as next model input in the denoising loop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base class for the output of a scheduler’s `step` function.
  prefs: []
  type: TYPE_NORMAL
