- en: FLAVA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FLAVA
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/flava](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/flava)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/flava](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/flava)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The FLAVA model was proposed in [FLAVA: A Foundational Language And Vision
    Alignment Model](https://arxiv.org/abs/2112.04482) by Amanpreet Singh, Ronghang
    Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and
    Douwe Kiela and is accepted at CVPR 2022.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'FLAVA模型在[FLAVA: A Foundational Language And Vision Alignment Model](https://arxiv.org/abs/2112.04482)中由Amanpreet
    Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus
    Rohrbach和Douwe Kiela提出，并已被CVPR 2022接受。'
- en: The paper aims at creating a single unified foundation model which can work
    across vision, language as well as vision-and-language multimodal tasks.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文旨在创建一个统一的基础模型，可以跨越视觉、语言以及视觉-语言多模态任务。
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*State-of-the-art vision and vision-and-language models rely on large-scale
    visio-linguistic pretraining for obtaining good performance on a variety of downstream
    tasks. Generally, such models are often either cross-modal (contrastive) or multi-modal
    (with earlier fusion) but not both; and they often only target specific modalities
    or tasks. A promising direction would be to use a single holistic universal model,
    as a “foundation”, that targets all modalities at once — a true vision and language
    foundation model should be good at vision tasks, language tasks, and cross- and
    multi-modal vision and language tasks. We introduce FLAVA as such a model and
    demonstrate impressive performance on a wide range of 35 tasks spanning these
    target modalities.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*最先进的视觉和视觉-语言模型依赖于大规模视觉-语言预训练，以在各种下游任务上获得良好的性能。通常，这些模型通常是跨模态（对比）或多模态（具有早期融合），但不是两者兼具；它们通常只针对特定的模态或任务。一个有前途的方向是使用一个单一的整体通用模型，作为“基础”，一次性针对所有模态
    —— 一个真正的视觉和语言基础模型应该擅长视觉任务、语言任务以及视觉和语言任务。我们介绍FLAVA作为这样一个模型，并展示了在涵盖这些目标模态的35个任务范围内的出色性能。*'
- en: This model was contributed by [aps](https://huggingface.co/aps). The original
    code can be found [here](https://github.com/facebookresearch/multimodal/tree/main/examples/flava).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[aps](https://huggingface.co/aps)贡献。原始代码可在[此处](https://github.com/facebookresearch/multimodal/tree/main/examples/flava)找到。
- en: FlavaConfig
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaConfig
- en: '### `class transformers.FlavaConfig`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L468)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L468)'
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize [FlavaTextConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextConfig).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_config` (`dict`, *optional*) — 用于初始化[FlavaTextConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextConfig)的配置选项字典。'
- en: '`image_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize [FlavaImageConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageConfig).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_config` (`dict`, *optional*) — 用于初始化[FlavaImageConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageConfig)的配置选项字典。'
- en: '`multimodal_config` (`dict`, *optional*) — Dictionary of configuration options
    used to initialize [FlavaMultimodalConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalConfig).'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_config` (`dict`, *optional*) — 用于初始化[FlavaMultimodalConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalConfig)的配置选项字典。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为768) — 编码器层和池化层的维度。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, 默认为1e-12) — 层归一化层使用的epsilon值。'
- en: '`projection_dim` (`int`, *optional*, defaults to 512) — Dimentionality of text
    and image projection layers.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_dim` (`int`, *optional*, 默认为512) — 文本和图像投影层的维度。'
- en: '`logit_scale_init_value` (`float`, *optional*, defaults to 2.6592) — The inital
    value of the *logit_scale* paramter. Default is used as per the original FLAVA/CLIP
    implementation.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logit_scale_init_value` (`float`, *optional*, 默认为2.6592) — *logit_scale*参数的初始值。默认值与原始FLAVA/CLIP实现相同。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, 默认为0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`ce_ignore_index` (`int`, *optional*, defaults to -100) — Cross entropy index
    to ignore.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ce_ignore_index` (`int`, *optional*, 默认为-100) — 用于忽略的交叉熵索引。'
- en: '`mim_weight` (`float`, *optional*, defaults to 1.0) — Weight to be assigned
    to MIM (Masked Image Modeling) unimodal loss'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mim_weight` (`float`, *optional*, 默认为1.0) — 分配给MIM（Masked Image Modeling）单模态损失的权重。'
- en: '`mlm_weight` (`float`, *optional*, defaults to 1.0) — Weight to be assigned
    to MLM (Masked Language Modeling) unimodal loss'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlm_weight` (`float`, *optional*, 默认为1.0) — 分配给MLM（Masked Language Modeling）单模态损失的权重。'
- en: '`global_contrastive_weight` (`float`, *optional*, defaults to 1.0) — Weight
    to be assigned to global contrastive cross-alignment loss.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`global_contrastive_weight` (`float`, *optional*, 默认为1.0) — 分配给全局对比度交叉对齐损失的权重。'
- en: '`itm_weight` (`float`, *optional*, defaults to 1.0) — Weight to be assigned
    to image-text matching multimodal loss.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`itm_weight` (`float`, *optional*, 默认为1.0) — 分配给图像-文本匹配多模态损失的权重。'
- en: '`mmm_image_weight` (`float`, *optional*, defaults to 1.0) — Weight to be assigned
    to MMM loss’s image part.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mmm_image_weight` (`float`, *optional*, 默认为1.0) — 分配给MMM损失图像部分的权重。'
- en: '`mmm_text_weight` (`float`, *optional*, defaults to 1.0) — Weight to be assigned
    to MMM loss’s text part.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mmm_text_weight` (`float`, *optional*, 默认为1.0) — 分配给MMM损失文本部分的权重。'
- en: '`global_backprop_contrastive` (`bool`, *optional*, defaults to `True`) — Whether
    to use global backpropgation through all workers in contrastive loss.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`global_backprop_contrastive` (`bool`, *optional*, 默认为`True`) — 是否在对比损失中通过所有工作器进行全局反向传播。'
- en: '`skip_unmasked_multimodal_encoder` (`bool`, *optional*, defaults to `True`)
    — Whether to skip running unmasked multimodal encoder whose outputs are not used
    by FLAVA losses.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_unmasked_multimodal_encoder`（`bool`，*可选*，默认为`True`）— 是否跳过运行未屏蔽的多模态编码器，其输出不被FLAVA损失使用。'
- en: '`return_loss` (`bool`, *optional*, defaults to `True`) — Whether to return
    loss or not'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_loss`（`bool`，*可选*，默认为`True`）— 是否返回损失或不返回'
- en: '`kwargs` (*optional*) — Dictionary of keyword arguments.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（*可选*）— 关键字参数的字典。'
- en: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    is the configuration class to store the configuration of a [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel).
    It is used to instantiate FLAVA model according to the specified arguments, defining
    the text model, image model, image codebook and multimodal model configs. Instantiating
    a configuration with the defaults will yield a similar configuration to that of
    the FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full) architecture.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)是用于存储[FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)配置的配置类。根据指定的参数实例化FLAVA模型，定义文本模型、图像模型、图像码书和多模态模型配置。使用默认值实例化配置将产生类似于FLAVA
    [facebook/flava-full](https://huggingface.co/facebook/flava-full)架构的配置。'
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#### `from_configs`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_configs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L742)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L742)'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Returns
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)'
- en: An instance of a configuration object
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象的实例
- en: Instantiate a [FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    (or a derived class) from flava text model configuration, flava image model configuration,
    flava multimodal model and flava codebook model configuration.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从flava文本模型配置、flava图像模型配置、flava多模态模型和flava码书模型配置中实例化一个[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)（或派生类）。
- en: FlavaTextConfig
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaTextConfig
- en: '### `class transformers.FlavaTextConfig`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaTextConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L150)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L150)'
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    BERT model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为30522）— BERT模型的词汇量。定义在调用[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)时可以表示的不同标记数量。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids` passed when calling [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).
    Note that even though text encoder allows `token_type_ids`’s value as 2, for text-only
    pretraining and fine-tuning, only 1 is used similar to RoBERTa.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size`（`int`，*可选*，默认为2）— 在调用[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)时传递的`token_type_ids`的词汇量大小。请注意，即使文本编码器允许`token_type_ids`的值为2，但对于仅文本的预训练和微调，类似于RoBERTa，只使用1。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048). For VL, max_length passed
    to model is 77.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings`（`int`，*可选*，默认为512）— 模型可能使用的最大序列长度。通常设置为较大的值以防万一（例如512、1024或2048）。对于VL，传递给模型的max_length为77。'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"absolute"`) — Type
    of position embedding. Choose one of `"absolute"`, `"relative_key"`, `"relative_key_query"`.
    For positional embeddings use `"absolute"`. For more information on `"relative_key"`,
    please refer to [Self-Attention with Relative Position Representations (Shaw et
    al.)](https://arxiv.org/abs/1803.02155). For more information on `"relative_key_query"`,
    please refer to *Method 4* in [Improve Transformer Models with Better Relative
    Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type`（`str`，*可选*，默认为`"absolute"`）— 位置嵌入的类型。选择`"absolute"`、`"relative_key"`、`"relative_key_query"`中的一个。对于位置嵌入，请使用`"absolute"`。有关`"relative_key"`的更多信息，请参考[Self-Attention
    with Relative Position Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)。有关`"relative_key_query"`的更多信息，请参考[Improve
    Transformer Models with Better Relative Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658)中的*Method
    4*。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`（`int`，*可选*，默认为768）— 编码器层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers`（`int`，*可选*，默认为12）— Transformer编码器中的隐藏层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads`（`int`，*可选*，默认为12）— Transformer编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size`（`int`，*可选*，默认为3072）— Transformer编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — 注意力概率的dropout比率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的epsilon。'
- en: '`image_size` (`int`, *optional*, defaults to 224) — The size (resolution) of
    each image.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *optional*, defaults to 224) — 每个图像的大小（分辨率）。'
- en: '`patch_size` (`int`, *optional*, defaults to 16) — The size (resolution) of
    each patch.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *optional*, defaults to 16) — 每个补丁的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, defaults to 3) — 输入通道的数量。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether to add a bias
    to the queries, keys and values.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — 是否为查询、键和值添加偏置。'
- en: This is the configuration class to store the configuration of a [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).
    It is used to instantiate an FLAVA model according to the specified arguments,
    defining the model architecture.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)配置的配置类。根据指定的参数实例化FLAVA模型，定义模型架构。
- en: Instantiating a configuration with the defaults will yield a similar configuration
    to that of the FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full)
    architecture.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认值实例化配置将产生类似于FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: FlavaImageConfig
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaImageConfig
- en: '### `class transformers.FlavaImageConfig`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaImageConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L31)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L31)'
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 编码器层和池化器层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Transformer编码器中的隐藏层数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Transformer编码器中每个注意力层的注意力头数量。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Transformer编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — 嵌入层、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — The
    dropout ratio for the attention probabilities.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — 注意力概率的dropout比率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的epsilon。'
- en: '`image_size` (`int`, *optional*, defaults to 224) — The size (resolution) of
    each image.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *optional*, defaults to 224) — 每个图像的大小（分辨率）。'
- en: '`patch_size` (`int`, *optional*, defaults to 16) — The size (resolution) of
    each patch.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *optional*, defaults to 16) — 每个补丁的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, defaults to 3) — 输入通道的数量。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether to add a bias
    to the queries, keys and values.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — 是否为查询、键和值添加偏置。'
- en: '`mask_token` (`bool`, *optional*, defaults to `True`) — Whether to use a mask
    token or not. Used in MIM (Masked Image Modeling) loss for FLAVA.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`bool`, *optional*, defaults to `True`) — 是否使用掩码标记。用于FLAVA的MIM（Masked
    Image Modeling）损失。'
- en: '`vocab_size` (`int`, *optional*, defaults to 8192) — Vocabulary size of the
    [FlavaImageCodebook](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebook)
    used in conjunction with [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)
    for MIM (Masked Image Modeling) loss for FLAVA.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`，*可选*，默认为8192) — 与[FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)一起用于FLAVA的MIM（Masked
    Image Modeling）损失的[FlavaImageCodebook](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebook)的词汇表大小。'
- en: This is the configuration class to store the configuration of a [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).
    It is used to instantiate an FLAVA model according to the specified arguments,
    defining the model architecture.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)配置的配置类。根据指定的参数实例化FLAVA模型，定义模型架构。
- en: Instantiating a configuration with the defaults will yield a similar configuration
    to that of the FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full)
    architecture.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认值实例化配置将产生类似于FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: FlavaMultimodalConfig
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaMultimodalConfig
- en: '### `class transformers.FlavaMultimodalConfig`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaMultimodalConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L280)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L280)'
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`，*可选*，默认为768) — 编码器层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 6) — Number of hidden layers
    in the Transformer encoder.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`，*可选*，默认为6) — Transformer编码器中的隐藏层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`，*可选*，默认为12) — Transformer编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`，*可选*，默认为3072) — Transformer编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`或`function`，*可选*，默认为`"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`，*可选*，默认为0.0) — 嵌入层、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — The
    dropout ratio for the attention probabilities.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`，*可选*，默认为0.0) — 注意力概率的dropout比率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`，*可选*，默认为0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`，*可选*，默认为1e-12) — 层归一化层使用的epsilon。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether to add a bias
    to the queries, keys and values.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`，*可选*，默认为`True`) — 是否向查询、键和值添加偏置。'
- en: '`use_cls_token` (`bool`, *optional*, defaults to `True`) — Whether to use an
    extra CLS token for multimodal settings. Usually needed by the FLAVA model.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cls_token` (`bool`，*可选*，默认为`True`) — 是否在多模态设置中使用额外的CLS标记。通常由FLAVA模型需要。'
- en: This is the configuration class to store the configuration of a [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel).
    It is used to instantiate an FLAVA model according to the specified arguments,
    defining the model architecture.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel)配置的配置类。根据指定的参数实例化FLAVA模型，定义模型架构。
- en: Instantiating a configuration with the defaults will yield a similar configuration
    to that of the FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full)
    architecture.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认值实例化配置将产生类似于FLAVA [facebook/flava-full](https://huggingface.co/facebook/flava-full)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE8]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: FlavaImageCodebookConfig
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaImageCodebookConfig
- en: '### `class transformers.FlavaImageCodebookConfig`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaImageCodebookConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L383)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/configuration_flava.py#L383)'
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: FlavaProcessor
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaProcessor
- en: '### `class transformers.FlavaProcessor`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/processing_flava.py#L28)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/processing_flava.py#L28)'
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` ([FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor),
    *optional*) — The image processor is a required input.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor`（[FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor)，*可选*）—
    图像处理器是必需的输入。'
- en: '`tokenizer` ([BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast),
    *optional*) — The tokenizer is a required input.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)，*可选*）—
    Tokenizer是必需的输入。'
- en: Constructs a FLAVA processor which wraps a FLAVA image processor and a FLAVA
    tokenizer into a single processor.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 构造一个FLAVA处理器，将FLAVA图像处理器和FLAVA标记器包装成单个处理器。
- en: '[FlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor)
    offers all the functionalities of [FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor)
    and [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast).
    See the `__call__()` and [decode()](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor.decode)
    for more information.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor)提供了[FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor)和[BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)的所有功能。有关更多信息，请参阅`__call__()`和[decode()](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor.decode)。'
- en: '#### `batch_decode`'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/processing_flava.py#L131)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/processing_flava.py#L131)'
- en: '[PRE11]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This method forwards all its arguments to BertTokenizerFast’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将其所有参数转发给BertTokenizerFast的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。有关更多信息，请参考此方法的文档字符串。
- en: '#### `decode`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/processing_flava.py#L138)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/processing_flava.py#L138)'
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This method forwards all its arguments to BertTokenizerFast’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将其所有参数转发给BertTokenizerFast的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。有关更多信息，请参考此方法的文档字符串。
- en: FlavaFeatureExtractor
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaFeatureExtractor
- en: '### `class transformers.FlavaFeatureExtractor`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/feature_extraction_flava.py#L26)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/feature_extraction_flava.py#L26)'
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: FlavaImageProcessor
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaImageProcessor
- en: '### `class transformers.FlavaImageProcessor`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/image_processing_flava.py#L135)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/image_processing_flava.py#L135)'
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions to the specified `size`. Can be overridden
    by the `do_resize` parameter in `preprocess`.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`（`bool`，*可选*，默认为`True`）— 是否将图像的（高度，宽度）尺寸调整为指定的`size`。可以被`preprocess`中的`do_resize`参数覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 224, "width":
    224}`): Size of the image after resizing. Can be overridden by the `size` parameter
    in `preprocess`.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`（`Dict[str, int]` *可选*，默认为`{"height" -- 224, "width": 224}`）：调整大小后的图像尺寸。可以被`preprocess`中的`size`参数覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`)
    — Resampling filter to use if resizing the image. Can be overridden by the `resample`
    parameter in `preprocess`.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample`（`PILImageResampling`，*可选*，默认为`PILImageResampling.BICUBIC`）— 如果调整图像大小，则要使用的重采样滤镜。可以被`preprocess`中的`resample`参数覆盖。'
- en: '`do_center_crop` (`bool`, *optional*, defaults to `True`) — Whether to center
    crop the images. Can be overridden by the `do_center_crop` parameter in `preprocess`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_center_crop`（`bool`，*可选*，默认为`True`）— 是否对图像进行中心裁剪。可以被`preprocess`中的`do_center_crop`参数覆盖。'
- en: '`crop_size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 224, "width":
    224}`): Size of image after the center crop `(crop_size["height"], crop_size["width"])`.
    Can be overridden by the `crop_size` parameter in `preprocess`.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crop_size`（`Dict[str, int]` *可选*，默认为`{"height" -- 224, "width": 224}`）：中心裁剪后图像的大小`(crop_size["height"],
    crop_size["width"])`。可以被`preprocess`中的`crop_size`参数覆盖。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`
    parameter in `preprocess`.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale`（`bool`，*可选*，默认为`True`）— 是否按指定比例`rescale_factor`对图像进行重新缩放。可以被`preprocess`中的`do_rescale`参数覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in `preprocess`.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor`（`int`或`float`，*可选*，默认为`1/255`）— 如果重新缩放图像，则要使用的比例因子。可以被`preprocess`中的`rescale_factor`参数覆盖。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in `preprocess`.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize`（`bool`，*可选*，默认为`True`）— 是否对图像进行归一化。可以被`preprocess`中的`do_normalize`参数覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *optional*, 默认为 `IMAGENET_STANDARD_MEAN`)
    — 如果对图像进行标准化，则使用的均值。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_mean`
    参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *optional*, 默认为 `IMAGENET_STANDARD_STD`)
    — 如果对图像进行标准化，则使用的标准差。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_std`
    参数覆盖。'
- en: '`return_image_mask` (`bool`, *optional*, defaults to `False`) — Whether to
    return the image mask. Can be overridden by the `return_image_mask` parameter
    in `preprocess`.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_image_mask` (`bool`, *optional*, 默认为 `False`) — 是否返回图像掩码。可以被 `preprocess`
    中的 `return_image_mask` 参数覆盖。'
- en: '`input_size_patches` (`int`, *optional*, defaults to 14) — Number of patches
    in the image in height and width direction. 14x14 = 196 total patches. Can be
    overridden by the `input_size_patches` parameter in `preprocess`.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_size_patches` (`int`, *optional*, 默认为 14) — 图像中高度和宽度方向的补丁数。14x14 = 总共
    196 个补丁。可以被 `preprocess` 中的 `input_size_patches` 参数覆盖。'
- en: '`total_mask_patches` (`int`, *optional*, defaults to 75) — Total number of
    patches that should be masked. Can be overridden by the `total_mask_patches` parameter
    in `preprocess`.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`total_mask_patches` (`int`, *optional*, 默认为 75) — 应该被遮蔽的总补丁数。可以被 `preprocess`
    中的 `total_mask_patches` 参数覆盖。'
- en: '`mask_group_min_patches` (`int`, *optional*, defaults to 16) — Minimum number
    of patches that should be masked. Can be overridden by the `mask_group_min_patches`
    parameter in `preprocess`.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_min_patches` (`int`, *optional*, 默认为 16) — 应该被遮蔽的最小补丁数。可以被 `preprocess`
    中的 `mask_group_min_patches` 参数覆盖。'
- en: '`mask_group_max_patches` (`int`, *optional*) — Maximum number of patches that
    should be masked. Can be overridden by the `mask_group_max_patches` parameter
    in `preprocess`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_max_patches` (`int`, *optional*) — 应该被遮蔽的最大补丁数。可以被 `preprocess`
    中的 `mask_group_max_patches` 参数覆盖。'
- en: '`mask_group_min_aspect_ratio` (`float`, *optional*, defaults to 0.3) — Minimum
    aspect ratio of the mask window. Can be overridden by the `mask_group_min_aspect_ratio`
    parameter in `preprocess`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_min_aspect_ratio` (`float`, *optional*, 默认为 0.3) — 掩码窗口的最小长宽比。可以被
    `preprocess` 中的 `mask_group_min_aspect_ratio` 参数覆盖。'
- en: '`mask_group_max_aspect_ratio` (`float`, *optional*) — Maximum aspect ratio
    of the mask window. Can be overridden by the `mask_group_max_aspect_ratio` parameter
    in `preprocess`.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_max_aspect_ratio` (`float`, *optional*) — 掩码窗口的最大长宽比。可以被 `preprocess`
    中的 `mask_group_max_aspect_ratio` 参数覆盖。'
- en: '`codebook_do_resize` (`bool`, *optional*, defaults to `True`) — Whether to
    resize the input for codebook to a certain. Can be overridden by the `codebook_do_resize`
    parameter in `preprocess`. `codebook_size`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_resize` (`bool`, *optional*, 默认为 `True`) — 是否将输入调整大小以适应码书。可以被
    `preprocess` 中的 `codebook_size` 参数覆盖。'
- en: '`codebook_size` (`Dict[str, int]`, *optional*, defaults to `{"height" -- 224,
    "width": 224}`): Resize the input for codebook to the given size. Can be overridden
    by the `codebook_size` parameter in `preprocess`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_size` (`Dict[str, int]`, *optional*, 默认为 `{"height" -- 224, "width":
    224}`): 将输入调整大小以适应码书到指定大小。可以被 `preprocess` 中的 `codebook_size` 参数覆盖。'
- en: '`codebook_resample` (`PILImageResampling`, *optional*, defaults to `PILImageResampling.LANCZOS`)
    — Resampling filter to use if resizing the codebook image. Can be overridden by
    the `codebook_resample` parameter in `preprocess`.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_resample` (`PILImageResampling`, *optional*, 默认为 `PILImageResampling.LANCZOS`)
    — 如果调整码书图像大小，则使用的重采样滤波器。可以被 `preprocess` 中的 `codebook_resample` 参数覆盖。'
- en: '`codebook_do_center_crop` (`bool`, *optional*, defaults to `True`) — Whether
    to crop the input for codebook at the center. If the input size is smaller than
    `codebook_crop_size` along any edge, the image is padded with 0’s and then center
    cropped. Can be overridden by the `codebook_do_center_crop` parameter in `preprocess`.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_center_crop` (`bool`, *optional*, 默认为 `True`) — 是否在码书输入中心裁剪输入。如果输入尺寸沿任何边缘小于
    `codebook_crop_size`，则图像将填充为 0，然后进行中心裁剪。可以被 `preprocess` 中的 `codebook_do_center_crop`
    参数覆盖。'
- en: '`codebook_crop_size` (`Dict[str, int]`, *optional*, defaults to `{"height"
    -- 224, "width": 224}`): Desired output size for codebook input when applying
    center-cropping. Can be overridden by the `codebook_crop_size` parameter in `preprocess`.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_crop_size` (`Dict[str, int]`, *optional*, 默认为 `{"height" -- 224,
    "width": 224}`): 应用中心裁剪时，码书输入的期望输出大小。可以被 `preprocess` 中的 `codebook_crop_size`
    参数覆盖。'
- en: '`codebook_do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to
    rescale the input for codebook by the specified scale `codebook_rescale_factor`.
    Can be overridden by the `codebook_do_rescale` parameter in `preprocess`.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_rescale` (`bool`, *optional*, 默认为 `True`) — 是否按照指定的比例因子 `codebook_rescale_factor`
    重新缩放码书输入。可以被 `preprocess` 中的 `codebook_do_rescale` 参数覆盖。'
- en: '`codebook_rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`)
    — Defines the scale factor to use if rescaling the codebook image. Can be overridden
    by the `codebook_rescale_factor` parameter in `preprocess`.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_rescale_factor` (`int` 或 `float`, *optional*, 默认为 `1/255`) — 如果重新缩放码书图像，则定义要使用的比例因子。可以被
    `preprocess` 中的 `codebook_rescale_factor` 参数覆盖。'
- en: '`codebook_do_map_pixels` (`bool`, *optional*, defaults to `True`) — Whether
    to map the pixel values of the codebook input to (1 - 2e)x + e. Can be overridden
    by the `codebook_do_map_pixels` parameter in `preprocess`.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_map_pixels` (`bool`, *optional*, 默认为 `True`) — 是否将码书输入的像素值映射到
    (1 - 2e)x + e。可以被 `preprocess` 中的 `codebook_do_map_pixels` 参数覆盖。'
- en: '`codebook_do_normalize` (`bool`, *optional*, defaults to `True`) — Whether
    or not to normalize the input for codebook with `codebook_image_mean` and `codebook_image_std`.
    Can be overridden by the `codebook_do_normalize` parameter in `preprocess`.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_normalize` (`bool`, *optional*, 默认为 `True`) — 是否对用于 codebook 的输入进行规范化，使用
    `codebook_image_mean` 和 `codebook_image_std`。可以被 `preprocess` 中的 `codebook_do_normalize`
    参数覆盖。'
- en: '`codebook_image_mean` (`Optional[Union[float, Iterable[float]]]`, *optional*,
    defaults to `[0, 0, 0]`) — The sequence of means for each channel, to be used
    when normalizing images for codebook. Can be overridden by the `codebook_image_mean`
    parameter in `preprocess`.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_image_mean` (`Optional[Union[float, Iterable[float]]]`, *optional*,
    默认为 `[0, 0, 0]`) — 每个通道的均值序列，在为 codebook 规范化图像时使用。可以被 `preprocess` 中的 `codebook_image_mean`
    参数覆盖。'
- en: '`codebook_image_std` (`Optional[Union[float, Iterable[float]]]`, *optional*,
    defaults to `[0.5, 0.5, 0.5]`) — The sequence of standard deviations for each
    channel, to be used when normalizing images for codebook. Can be overridden by
    the `codebook_image_std` parameter in `preprocess`.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_image_std` (`Optional[Union[float, Iterable[float]]]`, *optional*,
    默认为 `[0.5, 0.5, 0.5]`) — 每个通道的标准差序列，在为 codebook 规范化图像时使用。可以被 `preprocess` 中的 `codebook_image_std`
    参数覆盖。'
- en: Constructs a Flava image processor.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 Flava 图像处理器。
- en: '#### `preprocess`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/image_processing_flava.py#L447)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/image_processing_flava.py#L447)'
- en: '[PRE15]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像。期望单个图像或批量图像，像素值范围为 0 到 255。如果传入像素值在 0 到 1
    之间的图像，请设置 `do_rescale=False`。'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, 默认为 `self.do_resize`) — 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Size of the
    image.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *optional*, 默认为 `self.size`) — 图像的大小。'
- en: '`resample` (`int`, *optional*, defaults to `self.resample`) — Resampling filter
    to use if resizing the image. This can be one of the enum `PILImageResampling`,
    Only has an effect if `do_resize` is set to `True`.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`int`, *optional*, 默认为 `self.resample`) — 如果调整图像大小，则使用的重采样滤波器。这可以是
    `PILImageResampling` 枚举值之一，仅在 `do_resize` 设置为 `True` 时有效。'
- en: '`do_center_crop` (`bool`, *optional*, defaults to `self.do_center_crop`) —
    Whether to center crop the image.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_center_crop` (`bool`, *optional*, 默认为 `self.do_center_crop`) — 是否对图像进行中心裁剪。'
- en: '`crop_size` (`Dict[str, int]`, *optional*, defaults to `self.crop_size`) —
    Size of the center crop. Only has an effect if `do_center_crop` is set to `True`.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crop_size` (`Dict[str, int]`, *optional*, 默认为 `self.crop_size`) — 中心裁剪的大小。仅在
    `do_center_crop` 设置为 `True` 时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image values between [0 - 1].'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, 默认为 `self.do_rescale`) — 是否将图像值重新缩放在 [0 -
    1] 之间。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    Rescale factor to rescale the image by if `do_rescale` is set to `True`.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *optional*, 默认为 `self.rescale_factor`) — 如果 `do_rescale`
    设置为 `True`，则用于重新缩放图像的重新缩放因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, 默认为 `self.do_normalize`) — 是否对图像进行规范化。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    — Image mean.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *optional*, 默认为 `self.image_mean`) —
    图像均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    — Image standard deviation.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *optional*, 默认为 `self.image_std`) — 图像标准差。'
- en: '`return_image_mask` (`bool`, *optional*, defaults to `self.return_image_mask`)
    — Whether to return the image mask.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_image_mask` (`bool`, *optional*, 默认为 `self.return_image_mask`) — 是否返回图像掩码。'
- en: '`input_size_patches` (`int`, *optional*, defaults to `self.input_size_patches`)
    — Size of the patches to extract from the image.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_size_patches` (`int`, *optional*, 默认为 `self.input_size_patches`) — 从图像中提取的补丁的大小。'
- en: '`total_mask_patches` (`int`, *optional*, defaults to `self.total_mask_patches`)
    — Total number of patches to extract from the image.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`total_mask_patches` (`int`, *optional*, 默认为 `self.total_mask_patches`) — 从图像中提取的总补丁数。'
- en: '`mask_group_min_patches` (`int`, *optional*, defaults to `self.mask_group_min_patches`)
    — Minimum number of patches to extract from the image.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_min_patches` (`int`, *optional*, 默认为 `self.mask_group_min_patches`)
    — 从图像中提取的最小补丁数。'
- en: '`mask_group_max_patches` (`int`, *optional*, defaults to `self.mask_group_max_patches`)
    — Maximum number of patches to extract from the image.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_max_patches` (`int`, *optional*, 默认为 `self.mask_group_max_patches`)
    — 从图像中提取的补丁的最大数量。'
- en: '`mask_group_min_aspect_ratio` (`float`, *optional*, defaults to `self.mask_group_min_aspect_ratio`)
    — Minimum aspect ratio of the patches to extract from the image.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_min_aspect_ratio` (`float`, *optional*, 默认为 `self.mask_group_min_aspect_ratio`)
    — 从图像中提取的补丁的最小长宽比。'
- en: '`mask_group_max_aspect_ratio` (`float`, *optional*, defaults to `self.mask_group_max_aspect_ratio`)
    — Maximum aspect ratio of the patches to extract from the image.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_group_max_aspect_ratio` (`float`, *optional*, 默认为 `self.mask_group_max_aspect_ratio`)
    — 从图像中提取的补丁的最大长宽比。'
- en: '`return_codebook_pixels` (`bool`, *optional*, defaults to `self.return_codebook_pixels`)
    — Whether to return the codebook pixels.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_codebook_pixels` (`bool`, *optional*, 默认为 `self.return_codebook_pixels`)
    — 是否返回 codebook 像素。'
- en: '`codebook_do_resize` (`bool`, *optional*, defaults to `self.codebook_do_resize`)
    — Whether to resize the codebook pixels.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_resize` (`bool`, *optional*, 默认为 `self.codebook_do_resize`) —
    是否调整 codebook 像素的大小。'
- en: '`codebook_size` (`Dict[str, int]`, *optional*, defaults to `self.codebook_size`)
    — Size of the codebook pixels.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_size` (`Dict[str, int]`, *optional*, 默认为 `self.codebook_size`) —
    codebook 像素的大小。'
- en: '`codebook_resample` (`int`, *optional*, defaults to `self.codebook_resample`)
    — Resampling filter to use if resizing the codebook pixels. This can be one of
    the enum `PILImageResampling`, Only has an effect if `codebook_do_resize` is set
    to `True`.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_resample` (`int`, *可选*, 默认为 `self.codebook_resample`) — 如果调整码书像素大小，则要使用的重采样滤波器。这可以是枚举
    `PILImageResampling` 中的一个。仅在 `codebook_do_resize` 设置为 `True` 时有效。'
- en: '`codebook_do_center_crop` (`bool`, *optional*, defaults to `self.codebook_do_center_crop`)
    — Whether to center crop the codebook pixels.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_center_crop` (`bool`, *可选*, 默认为 `self.codebook_do_center_crop`)
    — 是否对码书像素进行中心裁剪。'
- en: '`codebook_crop_size` (`Dict[str, int]`, *optional*, defaults to `self.codebook_crop_size`)
    — Size of the center crop of the codebook pixels. Only has an effect if `codebook_do_center_crop`
    is set to `True`.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_crop_size` (`Dict[str, int]`, *可选*, 默认为 `self.codebook_crop_size`)
    — 码书像素中心裁剪的大小。仅在 `codebook_do_center_crop` 设置为 `True` 时有效。'
- en: '`codebook_do_rescale` (`bool`, *optional*, defaults to `self.codebook_do_rescale`)
    — Whether to rescale the codebook pixels values between [0 - 1].'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_rescale` (`bool`, *可选*, 默认为 `self.codebook_do_rescale`) — 是否将码书像素值重新缩放到
    [0 - 1] 之间。'
- en: '`codebook_rescale_factor` (`float`, *optional*, defaults to `self.codebook_rescale_factor`)
    — Rescale factor to rescale the codebook pixels by if `codebook_do_rescale` is
    set to `True`.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_rescale_factor` (`float`, *可选*, 默认为 `self.codebook_rescale_factor`)
    — 如果 `codebook_do_rescale` 设置为 `True`，则用于重新缩放码书像素的重新缩放因子。'
- en: '`codebook_do_map_pixels` (`bool`, *optional*, defaults to `self.codebook_do_map_pixels`)
    — Whether to map the codebook pixels values.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_map_pixels` (`bool`, *可选*, 默认为 `self.codebook_do_map_pixels`)
    — 是否映射码书像素值。'
- en: '`codebook_do_normalize` (`bool`, *optional*, defaults to `self.codebook_do_normalize`)
    — Whether to normalize the codebook pixels.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_do_normalize` (`bool`, *可选*, 默认为 `self.codebook_do_normalize`) —
    是否对码书像素进行归一化。'
- en: '`codebook_image_mean` (`float` or `List[float]`, *optional*, defaults to `self.codebook_image_mean`)
    — Codebook pixels mean to normalize the codebook pixels by if `codebook_do_normalize`
    is set to `True`.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `self.codebook_image_mean`)
    — 如果 `codebook_do_normalize` 设置为 `True`，则用于归一化码书像素的码书像素均值。'
- en: '`codebook_image_std` (`float` or `List[float]`, *optional*, defaults to `self.codebook_image_std`)
    — Codebook pixels standard deviation to normalize the codebook pixels by if `codebook_do_normalize`
    is set to `True`.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_image_std` (`float` 或 `List[float]`, *可选*, 默认为 `self.codebook_image_std`)
    — 如果 `codebook_do_normalize` 设置为 `True`，则用于归一化码书像素的码书像素标准差。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 `TensorType`, *可选*) — 要返回的张量类型。可以是以下之一：'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '未设置: 返回一个 `np.ndarray` 列表。'
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW` 或 `''tf''`: 返回类型为 `tf.Tensor` 的批次。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` 或 `''pt''`: 返回类型为 `torch.Tensor` 的批次。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY` 或 `''np''`: 返回类型为 `np.ndarray` 的批次。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX` 或 `''jax''`: 返回类型为 `jax.numpy.ndarray` 的批次。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` 或 `str`, *可选*, 默认为 `ChannelDimension.FIRST`)
    — 输出图像的通道维度格式。可以是以下之一：'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`: 图像以 (通道数、高度、宽度) 格式。'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`: 图像以 (高度、宽度、通道数) 格式。'
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format` (`ChannelDimension` 或 `str`, *可选*) — 输入图像的通道维度格式。如果未设置，则从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` 或 `ChannelDimension.FIRST`: 图像以 (通道数、高度、宽度) 格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` 或 `ChannelDimension.LAST`: 图像以 (高度、宽度、通道数) 格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` 或 `ChannelDimension.NONE`: 图像以 (高度、宽度) 格式。'
- en: Preprocess an image or batch of images.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或图像批次。
- en: FlavaForPreTraining
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaForPreTraining
- en: '### `class transformers.FlavaForPreTraining`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1714)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1714)'
- en: '[PRE16]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: '`image_codebook` (`nn.Module`) — If passed, the image codebook will be set
    to this. Otherwise. it will be initialized using the image_codebook_config defined
    in the config first as the first parameter.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_codebook` (`nn.Module`) — 如果传入，图像码书将设置为此值。否则，将使用配置中定义的 image_codebook_config
    作为第一个参数进行初始化。'
- en: The FLAVA model for pretraining which outputs losses, embeddings, logits and
    transformer outputs.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 用于预训练的 FLAVA 模型，输出损失、嵌入、对数和变换器输出。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1764)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1764)'
- en: '[PRE17]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids_masked` (`torch.LongTensor` of shape `(batch_size, text_seq_len)`)
    — Indices of input sequence tokens in the vocabulary. These ones are the masked
    version of the original task to be used with MLM. Indices can be obtained using
    [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    along with `DataCollatorForMaskedLanguageModeling`. See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids_masked`（形状为`(batch_size, text_seq_len)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。这些是原始任务的掩盖版本，用于MLM。索引可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)以及`DataCollatorForMaskedLanguageModeling`获取。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_len)`) — Indices
    of input sequence tokens in the vocabulary. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, text_seq_len)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。索引可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_len)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`(batch_size, text_seq_len)`的`torch.LongTensor`，*可选*）—
    段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。[什么是标记类型ID？](../glossary#token-type-ids)
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）—
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, image_num_patches)`)
    — Boolean masked positions. Indicates which patches are masked (1) and which aren’t
    (0).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos`（形状为`(batch_size, image_num_patches)`的`torch.BoolTensor`）—
    布尔掩码位置。指示哪些补丁被掩盖（1），哪些没有（0）。'
- en: '`interpolate_pos_encoding` (`bool`, *optional*) — Whether to interpolate the
    pre-trained position encodings.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`interpolate_pos_encoding`（*布尔值*，*可选*）— 是否插值预训练位置编码。'
- en: '`image_attention_mask` (`torch.FloatTensor` of shape `(batch_size, image_num_patches)`,
    *optional*) — Mask to avoid performing attention on padding token indices specifically
    for images. Mask values selected in `[0, 1]`:'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_attention_mask`（形状为`(batch_size, image_num_patches)`的`torch.FloatTensor`，*可选*）—
    用于避免特定于图像的填充令牌索引执行注意力的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被掩盖`的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`掩盖`的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`skip_unmasked_multimodal_encoder` (*bool*, *optional*) — Skip any calculations
    for multimodal encoder for unmasked inputs. FLAVA pretraining doesn’t need unmasked
    multimodal embeddings or outputs as of now.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_unmasked_multimodal_encoder`（*布尔值*，*可选*）— 跳过未掩盖输入的多模态编码器的任何计算。FLAVA预训练目前不需要未掩盖的多模态嵌入或输出。'
- en: '`mlm_labels` (`torch.LongTensor` of shape `(batch_size, text_seq_len)`, *optional*)
    — Labels for computing the left-to-right language and multimodal masked modeling
    loss (next word prediction). Indices should be in `[-100, 0, ..., text_config.vocab_size
    - 1]` (see `input_ids` docstring). Tokens with indices set to `-100` are ignored
    (masked), the loss is only computed for the tokens with labels in `[0, ..., text_config.vocab_size
    - 1]`.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlm_labels`（形状为`(batch_size, text_seq_len)`的`torch.LongTensor`，*可选*）— 用于计算从左到右的语言和多模态掩码建模损失（下一个词预测）的标签。索引应在`[-100,
    0, ..., text_config.vocab_size - 1]`中（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩盖），损失仅计算具有标签在`[0,
    ..., text_config.vocab_size - 1]`中的标记。'
- en: '`mim_labels` (`torch.LongTensor` of shape `(batch_size, image_num_patches)`,
    *optional*) — Labels for computing the image and multimodal masked modeling loss.
    Indices should be in `[-100, 0, ..., image_config.vocab_size - 1]`. Tokens with
    indices set to `-100` are ignored (masked), the loss is only computed for the
    tokens with labels in `[0, ..., image_config.vocab_size - 1]`. If not passed,
    they are generated automatically using the image codebook assigned to the model.
    By default, it uses [FlavaImageCodebook](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebook).
    See [FlavaImageCodebook](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebook)
    to understand how to generate mim_labels.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mim_labels`（形状为`(batch_size, image_num_patches)`的`torch.LongTensor`，*可选*）-
    用于计算图像和多模态掩码建模损失的标签。索引应在`[-100, 0, ..., image_config.vocab_size - 1]`中。将索引设置为`-100`的标记将被忽略（masked），仅对具有标签在`[0,
    ..., image_config.vocab_size - 1]`中的标记计算损失。如果未传递，则它们将使用分配给模型的图像码书自动生成。默认情况下，它使用[FlavaImageCodebook](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebook)。请参阅[FlavaImageCodebook](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebook)以了解如何生成mim_labels。'
- en: '`itm_labels` (`torch.LongTensor` of shape `(batch_size, 1)`, *optional*) —
    Labels for computing the image-text matching loss. 0 means the pairs don’t match
    and 1 means they match. The pairs with 0 will be skipped for calculation of MMM
    and global contrastive losses as well.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`itm_labels`（形状为`(batch_size, 1)`的`torch.LongTensor`，*可选*）- 用于计算图像文本匹配损失的标签。0表示配对不匹配，1表示匹配。标签为0的配对也将被跳过用于计算MMM和全局对比损失。'
- en: '`return_loss` (`bool`, *optional*, default to None) — Whether to return calculated
    loss or not.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_loss`（`bool`，*可选*，默认为None）- 是否返回计算的损失。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, text_seq_len)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, text_seq_len)`的`torch.FloatTensor`，*可选*）-
    用于避免在填充标记索引上执行注意力的掩码。掩码值选定在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）-
    用于使自注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部是`masked`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Examples —
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例 -
- en: Returns
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.flava.modeling_flava.FlavaForPreTrainingOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.flava.modeling_flava.FlavaForPreTrainingOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.flava.modeling_flava.FlavaForPreTrainingOutput` or a
    tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.flava.configuration_flava.FlavaConfig'>`)
    and inputs.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.flava.modeling_flava.FlavaForPreTrainingOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包括根据配置（`<class
    'transformers.models.flava.configuration_flava.FlavaConfig'>`）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor`, *optional*, returned when `return_loss` is True)
    — Total loss calculated for this model.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（`torch.FloatTensor`，*可选*，当`return_loss`为True时返回）- 为此模型计算的总损失。'
- en: '`loss_info` (`FlavaLosses`) — Detailed info for FLAVA Pretraining losses. Check
    `FlavaLosses` class description for the information on the keys.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_info`（`FlavaLosses`）- FLAVA预训练损失的详细信息。检查`FlavaLosses`类描述以获取关键信息。'
- en: '`image_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `pixel_values` are present) — The image embeddings which
    are basically the pooled output of [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeddings`（形状为`(batch_size, output_dim)`的`torch.FloatTensor`，*可选*，当存在`pixel_values`时返回）-
    这些基本上是[FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)的汇总输出的图像嵌入。'
- en: '`image_output` (`BaseModelOutputWithPooling`, *optional*, returned when `pixel_values`
    are present) — The output of the [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_output`（`BaseModelOutputWithPooling`，*可选*，当存在`pixel_values`时返回）- [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)的输出。'
- en: '`text_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `input_ids` are present) — The text embeddings which
    are basically the pooled output of [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_embeddings`（形状为`(batch_size, output_dim)`的`torch.FloatTensor`，*可选*，当存在`input_ids`时返回）-
    这些基本上是[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的汇总输出的文本嵌入。'
- en: '`text_output` (`BaseModelOutputWithPooling`, *optional*, returned when `input_ids`
    are present) — The output of the [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_output`（`BaseModelOutputWithPooling`，*可选*，当存在`input_ids`时返回）- [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的输出。'
- en: '`multimodal_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `input_ids` and `pixel_values` are present and `skip_unmasked_multimodal_encoder`
    is `None` or `False`) — The multimodal embeddings which are basically the pooled
    output of [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_embeddings`（`torch.FloatTensor`，形状为`(batch_size, output_dim)`，*可选*，当`input_ids`和`pixel_values`存在且`skip_unmasked_multimodal_encoder`为`None`或`False`时返回）-
    这些多模态嵌入基本上是[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的汇总输出。'
- en: '`multimodal_output` (`BaseModelOutputWithPooling`, returned when `input_ids`
    and `pixel_values` are present and `skip_unmasked_multimodal_encoder` is `None`
    or `False`) — The output of the [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_output`（`BaseModelOutputWithPooling`，当`input_ids`和`pixel_values`存在且`skip_unmasked_multimodal_encoder`为`None`或`False`时返回）-
    [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel)的输出。'
- en: '`image_masked_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `pixel_values` are present) — The image embeddings which
    are basically the pooled output of [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).
    Uses `bool_masked_pos` to create masked images.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_masked_embeddings`（`torch.FloatTensor`，形状为`(batch_size, output_dim)`，*可选*，当`pixel_values`存在时返回）-
    这些图像嵌入基本上是[FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)的汇总输出。使用`bool_masked_pos`来创建被屏蔽的图像。'
- en: '`image_masked_output` (`BaseModelOutputWithPooling`, *optional*, returned when
    `pixel_values` are present) — The output of the [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).
    Uses `bool_masked_pos` to create masked images.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_masked_output`（`BaseModelOutputWithPooling`，*可选*，当`pixel_values`存在时返回）-
    [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)的输出。使用`bool_masked_pos`来创建被屏蔽的图像。'
- en: '`text_masked_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `input_ids_masked` are present) — The text embeddings
    which are basically the pooled output of [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_masked_embeddings`（`torch.FloatTensor`，形状为`(batch_size, output_dim)`，*可选*，当`input_ids_masked`存在时返回）-
    这些文本嵌入基本上是[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的汇总输出。'
- en: '`text_masked_output` (`BaseModelOutputWithPooling`, *optional*, returned when
    `input_ids_masked` are present) — The output of the [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_masked_output`（`BaseModelOutputWithPooling`，*可选*，当`input_ids_masked`存在时返回）-
    [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的输出。'
- en: '`multimodal_masked_embeddings` (`torch.FloatTensor` of shape `(batch_size,
    output_dim)`, *optional*, returned when `input_ids` and `pixel_values` are present)
    — The multimodal embeddings which are basically the pooled output of [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_masked_embeddings`（`torch.FloatTensor`，形状为`(batch_size, output_dim)`，*可选*，当`input_ids`和`pixel_values`存在时返回）-
    这些多模态嵌入基本上是[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的汇总输出。'
- en: '`multimodal_masked_output` (`BaseModelOutputWithPooling`, returned when `input_ids_masked`
    and `pixel_values` are present) — The output of the [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_masked_output`（`BaseModelOutputWithPooling`，当`input_ids_masked`和`pixel_values`存在时返回）-
    [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel)的输出。'
- en: '`mim_logits` (`torch.FloatTensor` of shape `(batch_size, num_image_patches,
    image_vocab_size)` or of shape `(total_masked_patches, image_vocab_size)` , *optional*,
    returned when `pixel_values` are present and `input_ids_masked` are not) — The
    logits for MIM unimodal loss. Uses `book_masked_pos` to get masked patches. The
    flattened output is returned when `bool_masked_pos` has some of the patches masked.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mim_logits`（`torch.FloatTensor`，形状为`(batch_size, num_image_patches, image_vocab_size)`或形状为`(total_masked_patches,
    image_vocab_size)`，*可选*，当`pixel_values`存在且`input_ids_masked`不存在时返回）- MIM单模态损失的logits。使用`book_masked_pos`来获取被屏蔽的补丁。当`bool_masked_pos`中有一些补丁被屏蔽时，返回扁平化的输出。'
- en: '`mlm_logits` (`torch.FloatTensor` of shape `(batch_size, text_seq_length, text_vocab_size)`
    or of shape `(total_masked_seq_length, text_vocab_size)`, *optional*, returned
    when `input_ids_masked` are present and `pixel_values` are not) — The logits for
    MLM unimodal loss. The flattened output is returned when `input_ids_masked` has
    some of the tokens masked.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlm_logits`（`torch.FloatTensor`，形状为`(batch_size, text_seq_length, text_vocab_size)`或形状为`(total_masked_seq_length,
    text_vocab_size)`，*可选*，当`input_ids_masked`存在且`pixel_values`不存在时返回）- MLM单模态损失的logits。当`input_ids_masked`中有一些标记被屏蔽时，返回扁平化的输出。'
- en: '`itm_logits` (`torch.FloatTensor` of shape `(batch_size, 2)`, *optional*, returned
    when `input_ids_masked` and `pixel_values` are present) — The logits for ITM loss.
    Note that ITM loss is calculated on masked pairs in FLAVA.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`itm_logits`（`torch.FloatTensor`，形状为`(batch_size, 2)`，*可选*，当`input_ids_masked`和`pixel_values`存在时返回）-
    ITM损失的logits。请注意，ITM损失是在FLAVA中对被屏蔽的配对进行计算的。'
- en: '`mmm_image_logits` (`torch.FloatTensor` of shape `(batch_size, num_image_patches,
    image_vocab_size)` or of shape`(total_masked_patches, image_vocab_size)`, *optional*,
    returned when `pixel_values` and `input_ids_masked` are present) — The logits
    for MMM image multimodal loss. Uses `book_masked_pos` to get masked patches. The
    flattened output is returned when `bool_masked_pos` has some of the patches masked.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mmm_image_logits`（`torch.FloatTensor`，形状为`(batch_size, num_image_patches,
    image_vocab_size)`或形状为`(total_masked_patches, image_vocab_size)`，*可选*，当`pixel_values`和`input_ids_masked`存在时返回）-
    MMM图像多模态损失的logits。使用`book_masked_pos`来获取被屏蔽的补丁。当`bool_masked_pos`中有一些补丁被屏蔽时，返回扁平化的输出。'
- en: '`mmm_text_logits` (`torch.FloatTensor` of shape `(batch_size, text_seq_length,
    text_vocab_size)` or of shape `(`(total_masked_seq_length, text_vocab_size)`),
    *optional*, returned when` pixel_values`and`input_ids_masked`are present) -- The
    logits for MMM text multimodal loss. The flattened output is returned when`input_ids_masked`
    has some of the tokens masked.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mmm_text_logits`（形状为`(batch_size, text_seq_length, text_vocab_size)`或形状为`(total_masked_seq_length,
    text_vocab_size)`的`torch.FloatTensor`，*可选*，当`pixel_values`和`input_ids_masked`存在时返回）-
    用于MMM文本多模态损失的logits。当`input_ids_masked`中有一些标记被屏蔽时，返回扁平化的输出。'
- en: '`contrastive_logits_per_image` (`torch.FloatTensor` of shape `(image_batch_size,
    text_batch_size)`) — The scaled dot product scores between `image_embeddings`
    and `text_embeddings` but passed through FLAVA’s `image_projection` and `text_projection`
    layers respectively. This represents the image-text similarity scores. This is
    calculated on unmasked images and texts.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contrastive_logits_per_image`（形状为`(image_batch_size, text_batch_size)`的`torch.FloatTensor`）-
    `image_embeddings`和`text_embeddings`之间的缩放点积分数，但分别通过FLAVA的`image_projection`和`text_projection`层。这代表了图像文本相似性得分。这是在未屏蔽的图像和文本上计算的。'
- en: '`contrastive_logits_per_text` (`torch.FloatTensor` of shape `(text_batch_size,
    image_batch_size)`) — The scaled dot product scores between `text_embeddings`
    and `image_embeddings` but passed through FLAVA’s `text_projection` and `image_projection`
    layers respectively. This is calculated on unmasked images and texts.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contrastive_logits_per_text`（形状为`(text_batch_size, image_batch_size)`的`torch.FloatTensor`）-
    `text_embeddings`和`image_embeddings`之间的缩放点积分数，但分别通过FLAVA的`text_projection`和`image_projection`层。这是在未屏蔽的图像和文本上计算的。'
- en: The [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    forward method, overrides the `__call__` special method.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: FlavaModel
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaModel
- en: '### `class transformers.FlavaModel`'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1179)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1179)'
- en: '[PRE18]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)）-
    模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare FLAVA Model transformer outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的FLAVA模型变压器输出原始隐藏状态，没有特定的头部。这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1323)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1323)'
- en: '[PRE19]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）-
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, image_num_patches)`)
    — Boolean masked positions. Indicates which patches are masked (1) and which aren’t
    (0).'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos`（形状为`(batch_size, image_num_patches)`的`torch.BoolTensor`）-
    布尔掩码位置。指示哪些补丁被屏蔽（1），哪些没有（0）。'
- en: '`interpolate_pos_encoding` (`bool`, *optional*) — Whether to interpolate the
    pre-trained position encodings.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`interpolate_pos_encoding`（`bool`，*可选*）- 是否插值预训练位置编码。'
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, image_num_patches +
    text_seq_len)`) — Indices of input sequence tokens in the vocabulary. Indices
    can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, image_num_patches + text_seq_len)`的`torch.LongTensor`）-
    词汇表中输入序列标记的索引。索引可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, image_num_patches
    + text_seq_len)`, *optional*) — Segment token indices to indicate first and second
    portions of the inputs. Indices are selected in `[0, 1]`:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor`，形状为 `(batch_size, image_num_patches +
    text_seq_len)`，*可选*) — 段令牌索引，指示输入的第一部分和第二部分。 索引在 `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 令牌，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 令牌。 [什么是令牌类型 ID？](../glossary#token-type-ids)
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, image_num_patches
    + text_seq_len)`, *optional*) — Mask to avoid performing attention on padding
    token indices. Mask values selected in `[0, 1]`:'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`，形状为 `(batch_size, image_num_patches +
    text_seq_len)`，*可选*) — 用于避免在填充令牌索引上执行注意力的掩码。 选择的掩码值为 `[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被“掩盖”的令牌。
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被“掩盖”的令牌。 [什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块的选定头部无效的掩码。 选择的掩码值在 `[0, 1]` 中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被“掩盖”，
- en: 0 indicates the head is `masked`.
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被“掩盖”。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`skip_multimodal_encoder` (*bool*, *optional*) — Skip any calculations for
    multimodal encoder. Useful if multimodal encoding is not going to be used.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_multimodal_encoder` (*bool*，*可选*) — 跳过多模态编码的任何计算。 如果不打算使用多模态编码，则此选项很有用。'
- en: Returns
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.flava.modeling_flava.FlavaModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.flava.modeling_flava.FlavaModelOutput` 或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.flava.modeling_flava.FlavaModelOutput` or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.flava.configuration_flava.FlavaConfig'>`)
    and inputs.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `transformers.models.flava.modeling_flava.FlavaModelOutput` 或一个 `torch.FloatTensor`
    元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False` 时），包括根据配置 (`<class
    'transformers.models.flava.configuration_flava.FlavaConfig'>`) 和输入而异的各种元素。
- en: '`image_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `pixel_values` are present) — The image embeddings which
    are basically the pooled output of [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeddings` (`torch.FloatTensor`，形状为 `(batch_size, output_dim)`，*可选*，当
    `pixel_values` 存在时返回) — 基本上是 [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)
    的汇总输出的图像嵌入。'
- en: '`image_output` (`BaseModelOutputWithPooling`, *optional*, returned when `pixel_values`
    are present) — The output of the [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel).'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_output` (`BaseModelOutputWithPooling`，*可选*，当 `pixel_values` 存在时返回) —
    [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)
    的输出。'
- en: '`text_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `input_ids` are present) — The text embeddings which
    are basically the pooled output of [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_embeddings` (`torch.FloatTensor`，形状为 `(batch_size, output_dim)`，*可选*，当
    `input_ids` 存在时返回) — 基本上是 [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)
    的汇总输出的文本嵌入。'
- en: '`text_output` (`BaseModelOutputWithPooling`, *optional*, returned when `input_ids`
    are present) — The output of the [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_output` (`BaseModelOutputWithPooling`，*可选*，当 `input_ids` 存在时返回) — [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)
    的输出。'
- en: '`multimodal_embeddings` (`torch.FloatTensor` of shape `(batch_size, output_dim)`,
    *optional*, returned when `input_ids` and `pixel_values` are present and `skip_multimodal_encoder`
    is `None` or `False`) — The multimodal embeddings which are basically the pooled
    output of [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel).'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_embeddings` (`torch.FloatTensor`，形状为 `(batch_size, output_dim)`，*可选*，当
    `input_ids` 和 `pixel_values` 存在且 `skip_multimodal_encoder` 为 `None` 或 `False`
    时返回) — 基本上是 [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)
    的汇总输出的多模态嵌入。'
- en: '`multimodal_output` (`BaseModelOutputWithPooling`, returned when `input_ids`
    and `pixel_values` are present and `skip_multimodal_encoder` is `None` or `False`)
    — The output of the [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel).'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodal_output` (`BaseModelOutputWithPooling`，当 `input_ids` 和 `pixel_values`
    存在且 `skip_multimodal_encoder` 为 `None` 或 `False` 时返回) — [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel)
    的输出。'
- en: The [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    forward method, overrides the `__call__` special method.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE20]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `get_text_features`'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_text_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1229)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1229)'
- en: '[PRE21]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_length)`) —
    Indices of input sequence tokens in the vocabulary. Indices can be obtained using
    [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, text_seq_length)`的`torch.LongTensor`）— 输入序列标记在词汇表中的索引。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`(batch_size, text_seq_length)`的`torch.LongTensor`，*可选*）—
    段标记索引，指示输入的第一部分和第二部分。索引选择在`[0, 1]`中：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。[什么是标记类型ID？](../glossary#token-type-ids)
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, text_seq_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, text_seq_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被“masked”的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被“masked”掉的标记，值为0。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使自注意力模块的选定头部失效的掩码。掩码值选择在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被“masked”,
- en: 0 indicates the head is `masked`.
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“masked”。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    forward method, overrides the `__call__` special method.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: '#### `get_image_features`'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_image_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1273)'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1273)'
- en: '[PRE22]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）—
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, image_num_patches)`)
    — Boolean masked positions. Indicates which patches are masked (1) and which aren’t
    (0).'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos`（形状为`(batch_size, image_num_patches)`的`torch.BoolTensor`）—
    布尔掩码位置。指示哪些补丁被掩盖（1），哪些没有（0）。'
- en: '`interpolate_pos_encoding` (`bool`, *optional*) — Whether to interpolate the
    pre-trained position encodings.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`interpolate_pos_encoding`（`bool`，*可选*）— 是否插值预训练位置编码。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, image_num_patches)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, image_num_patches)`的`torch.FloatTensor`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-357
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被“masked”的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被“masked”掉的标记，值为0。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块中选择的头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-360
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被掩盖`,
- en: 0 indicates the head is `masked`.
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部`被掩盖`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    forward method, overrides the `__call__` special method.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: FlavaImageCodebook
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaImageCodebook
- en: '### `class transformers.FlavaImageCodebook`'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaImageCodebook`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1500)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1500)'
- en: '[PRE23]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FlavaImageCodebookConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebookConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([FlavaImageCodebookConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageCodebookConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The FLAVA’s image codebook model inspired from DALL-E’s original encoder. Outputs
    raw hidden states and can be used to generate image tokens for an image based
    on DALL-E’s vocab. Used to generate labels for MIM. Use `get_codebook_indices`
    to get image tokens for an image.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: FLAVA的图像代码簿模型受到DALL-E原始编码器的启发。输出原始隐藏状态，可用于根据DALL-E的词汇为基于图像的MIM生成图像标记。用于为MIM生成图像的图像标记，请使用`get_codebook_indices`。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1590)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1590)'
- en: '[PRE24]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#### `get_codebook_indices`'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_codebook_indices`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1558)'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1558)'
- en: '[PRE25]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#### `get_codebook_probs`'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_codebook_probs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1586)'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1586)'
- en: '[PRE26]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: FlavaTextModel
  id: totrans-384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaTextModel
- en: '### `class transformers.FlavaTextModel`'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaTextModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L976)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L976)'
- en: '[PRE27]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FlavaTextConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([FlavaTextConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare FLAVA Text Model transformer outputting raw hidden-states without any
    specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的FLAVA文本模型变压器输出原始隐藏状态，没有特定的头部。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1011)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1011)'
- en: '[PRE28]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_length)`) —
    Indices of input sequence tokens in the vocabulary. Indices can be obtained using
    [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_length)`) —
    Indices of input sequence tokens in the vocabulary. Indices can be obtained using
    [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, text_seq_length)`,
    *optional*) — 段标记索引，用于指示输入的第一部分和第二部分。索引选定在`[0, 1]`之间：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记。
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。[什么是标记类型ID？](../glossary#token-type-ids)
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, text_seq_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, text_seq_length)`,
    *optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被掩盖的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被掩盖的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块中的选定头部失效的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被掩盖，
- en: 0 indicates the head is `masked`.
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被掩盖。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FlavaTextConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextConfig))
    and inputs.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或一个`torch.FloatTensor`的元组（如果传递`return_dict=False`或当`config.return_dict=False`时），包括根据配置（[FlavaTextConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextConfig)）和输入的不同元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层的隐藏状态的序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型每一层的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)
    forward method, overrides the `__call__` special method.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaTextModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaTextModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: FlavaImageModel
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlavaImageModel
- en: '### `class transformers.FlavaImageModel`'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlavaImageModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L877)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L877)'
- en: '[PRE30]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FlavaImageConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[FlavaImageConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare FLAVA Image Model transformer outputting raw hidden-states without
    any specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的FLAVA图像模型变换器输出没有特定头部的原始隐藏状态。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L914)'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L914)'
- en: '[PRE31]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）—
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[FlavaImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, image_num_patches)`)
    — Boolean masked positions. Indicates which patches are masked (1) and which aren’t
    (0).'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos`（形状为`(batch_size, image_num_patches)`的`torch.BoolTensor`）—
    布尔掩码位置。指示哪些补丁被掩盖（1），哪些没有（0）。'
- en: '`interpolate_pos_encoding` (`bool`, *optional*) — Whether to interpolate the
    pre-trained position encodings.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`interpolate_pos_encoding`（`bool`，*可选*）— 是否插值预训练位置编码。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, image_num_patches)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（`torch.FloatTensor`，形状为`(batch_size, image_num_patches)`，*可选*）—
    用于避免在填充令牌索引上执行注意力的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的令牌，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的令牌。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*可选*）—
    用于使自注意力模块中的选定头部失效的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-439
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`。
- en: 0 indicates the head is `masked`.
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FlavaImageConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageConfig))
    and inputs.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FlavaImageModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageModel)
    forward method, overrides the `__call__` special method.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: FlavaMultimodalModel
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FlavaMultimodalModel`'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1081)'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([FlavaMultimodalConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare FLAVA Multimodal Model transformer outputting raw hidden-states without
    any specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/flava/modeling_flava.py#L1113)'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: '`hidden_states` (`torch.FloatTensor` of shape `(batch_size, image_num_patches
    + text_seq_len, hidden_size)`) — The concatenated hidden states of unimodal encoders.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, image_num_patches
    + text_seq_len)`, *optional*) — Mask to avoid performing attention on padding
    token indices. Mask values selected in `[0, 1]`:'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-471
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）
    — 用于使自注意力模块中选择的头部失效的掩码。在`[0, 1]`中选择的掩码值：'
- en: 1 indicates the head is `not masked`,
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*） — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*） — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*） — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FlavaMultimodalConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalConfig))
    and inputs.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[FlavaMultimodalConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalConfig)）和输入而异的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）
    — 模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`（形状为`(batch_size, hidden_size)`的`torch.FloatTensor`） — 经过用于辅助预训练任务的层进一步处理后，序列第一个标记（分类标记）的最后一层隐藏状态。例如，对于BERT系列模型，这将返回经过线性层和tanh激活函数处理后的分类标记。线性层的权重是在预训练期间从下一个句子预测（分类）目标中训练的。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出和每层的输出各一个）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel)
    forward method, overrides the `__call__` special method.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlavaMultimodalModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaMultimodalModel)
    的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Example:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE35]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
