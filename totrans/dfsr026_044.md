# 精炼稳定扩散推断

> 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd](https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd)

稳定扩散推断可能是一个计算密集型的过程，因为它必须迭代去噪潜变量以生成图像。为了减少计算负担，您可以使用[Nota AI](https://huggingface.co/nota-ai)的稳定扩散模型的*精炼*版本。他们稳定扩散模型的精炼版本消除了UNet中的一些残差和注意力块，将模型大小减少了51%，在CPU/GPU上的延迟提高了43%。

阅读这篇[博文](https://huggingface.co/blog/sd_distillation)以了解更多关于知识蒸馏训练如何工作以产生更快、更小、更便宜的生成模型。

让我们加载精炼稳定扩散模型并将其与原始稳定扩散模型进行比较：

```py
from diffusers import StableDiffusionPipeline
import torch

distilled = StableDiffusionPipeline.from_pretrained(
    "nota-ai/bk-sdm-small", torch_dtype=torch.float16, use_safetensors=True,
).to("cuda")

original = StableDiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16, use_safetensors=True,
).to("cuda")
```

给定一个提示，获取原始模型的推断时间：

```py
import time

seed = 2023
generator = torch.manual_seed(seed)

NUM_ITERS_TO_RUN = 3
NUM_INFERENCE_STEPS = 25
NUM_IMAGES_PER_PROMPT = 4

prompt = "a golden vase with different flowers"

start = time.time_ns()
for _ in range(NUM_ITERS_TO_RUN):
    images = original(
        prompt,
        num_inference_steps=NUM_INFERENCE_STEPS,
        generator=generator,
        num_images_per_prompt=NUM_IMAGES_PER_PROMPT
    ).images
end = time.time_ns()
original_sd = f"{(end - start) / 1e6:.1f}"

print(f"Execution time -- {original_sd} ms\n")
"Execution time -- 45781.5 ms"
```

计时精炼模型推断：

```py
start = time.time_ns()
for _ in range(NUM_ITERS_TO_RUN):
    images = distilled(
        prompt,
        num_inference_steps=NUM_INFERENCE_STEPS,
        generator=generator,
        num_images_per_prompt=NUM_IMAGES_PER_PROMPT
    ).images
end = time.time_ns()

distilled_sd = f"{(end - start) / 1e6:.1f}"
print(f"Execution time -- {distilled_sd} ms\n")
"Execution time -- 29884.2 ms"
```

![](../Images/f82acf1004076b7b492a9df026e46793.png)

原始稳定扩散（45781.5毫秒）

![](../Images/fdcbeffef0420159642acccb6336a302.png)

精炼稳定扩散（29884.2毫秒）

## 微型自动编码器

为了进一步加快推断速度，使用[Stable Diffusion VAE](https://huggingface.co/sayakpaul/taesdxl-diffusers)的微型精炼版本将潜变量去噪成图像。将微型VAE替换为精炼稳定扩散模型中的VAE：

```py
from diffusers import AutoencoderTiny

distilled.vae = AutoencoderTiny.from_pretrained(
    "sayakpaul/taesd-diffusers", torch_dtype=torch.float16, use_safetensors=True,
).to("cuda")
```

计时精炼模型和精炼VAE推断：

```py
start = time.time_ns()
for _ in range(NUM_ITERS_TO_RUN):
    images = distilled(
        prompt,
        num_inference_steps=NUM_INFERENCE_STEPS,
        generator=generator,
        num_images_per_prompt=NUM_IMAGES_PER_PROMPT
    ).images
end = time.time_ns()

distilled_tiny_sd = f"{(end - start) / 1e6:.1f}"
print(f"Execution time -- {distilled_tiny_sd} ms\n")
"Execution time -- 27165.7 ms"
```

![](../Images/3eae18d18492330797db5d70b23824f7.png)

精炼稳定扩散 + 微型自动编码器（27165.7毫秒）
