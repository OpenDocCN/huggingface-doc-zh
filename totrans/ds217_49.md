# 构建您的存储库

> 原始文本：[https://huggingface.co/docs/datasets/repository_structure](https://huggingface.co/docs/datasets/repository_structure)

要托管和共享您的数据集，请在Hugging Face Hub上创建一个数据集存储库并上传您的数据文件。

本指南将向您展示如何在上传时构建数据集存储库。具有支持的结构和文件格式（`.txt`、`.csv`、`.parquet`、`.jsonl`、`.mp3`、`.jpg`、`.zip`等）的数据集将自动加载，并且在Hub上的数据集页面上将有一个数据集查看器。

## 主要用例

最简单的数据集结构有两个文件：`train.csv`和`test.csv`（这适用于任何支持的文件格式）。

您的存储库还将包含一个`README.md`文件，显示在数据集页面上的[数据集卡片](dataset_card)。

```py
my_dataset_repository/
├── README.md
├── train.csv
└── test.csv
```

在这种简单情况下，您将获得一个包含`train.csv`中示例的`train`拆分和一个包含`test.csv`中示例的`test`拆分的数据集。

## 在YAML中定义您的拆分和子集

## 拆分

如果您有多个文件并且想要定义哪个文件放入哪个拆分，可以在README.md顶部使用YAML的`configs`字段。

例如，给定这样一个存储库：

```py
my_dataset_repository/
├── README.md
├── data.csv
└── holdout.csv
```

您可以通过在README.md顶部的YAML块中添加`configs`字段来定义您的拆分：

```py
---
configs:
- config_name: default
  data_files:
  - split: train
    path: "data.csv"
  - split: test
    path: "holdout.csv"
---
```

您可以使用路径列表选择每个拆分的多个文件：

```py
my_dataset_repository/
├── README.md
├── data/
│   ├── abc.csv
│   └── def.csv
└── holdout/
    └── ghi.csv
```

```py
---
configs:
- config_name: default
  data_files:
  - split: train
    path:
    - "data/abc.csv"
    - "data/def.csv"
  - split: test
    path: "holdout/ghi.csv"
---
```

或者您可以使用通配符模式自动列出所需的所有文件：

```py
---
configs:
- config_name: default
  data_files:
  - split: train
    path: "data/*.csv"
  - split: test
    path: "holdout/*.csv"
---
```

请注意，即使只有一个配置，`config_name`字段也是必需的。

## 配置

您的数据集可能有几个您希望能够单独加载的数据子集。在这种情况下，您可以在YAML的`configs`字段中定义一个配置列表：

```py
my_dataset_repository/
├── README.md
├── main_data.csv
└── additional_data.csv
```

```py
---
configs:
- config_name: main_data
  data_files: "main_data.csv"
- config_name: additional_data
  data_files: "additional_data.csv"
---
```

每个配置都单独显示在Hugging Face Hub上，并且可以通过将其名称作为第二个参数传递来加载：

```py
from datasets import load_dataset

main_data = load_dataset("my_dataset_repository", "main_data")
additional_data = load_dataset("my_dataset_repository", "additional_data")
```

## 构建器参数

不仅可以通过YAML传递`data_files`，还可以通过YAML传递其他特定于构建器的参数，从而在加载数据时提供更多灵活性而不需要任何自定义代码。例如，定义在哪个配置中使用哪个分隔符加载您的`csv`文件：

```py
---
configs:
- config_name: tab
  data_files: "main_data.csv"
  sep: "\t"
- config_name: comma
  data_files: "additional_data.csv"
  sep: ","
---
```

参考[特定构建器文档](./package_reference/builder_classes)以查看它们具有哪些配置参数。

您可以使用`default: true`来设置默认配置，例如，如果您设置了，您可以运行`main_data = load_dataset("my_dataset_repository")`

```py
- config_name: main_data
  data_files: "main_data.csv"
  default: true
```

## 自动拆分检测

如果没有提供YAML，🤗 数据集将搜索数据集存储库中的某些模式，以自动推断数据集拆分。这些模式有一定的顺序，从自定义文件名拆分格式开始，如果找不到任何模式，则将所有文件视为单个拆分。

### 目录名称

您的数据文件也可以放置在名为`train`、`test`和`validation`的不同目录中，每个目录包含该拆分的数据文件：

```py
my_dataset_repository/
├── README.md
└── data/
    ├── train/
    │   └── bees.csv
    ├── test/
    │   └── more_bees.csv
    └── validation/
        └── even_more_bees.csv
```

### 文件名拆分

如果您没有任何非传统拆分，那么您可以将拆分名称放在数据文件的任何位置，并且会自动推断。唯一的规则是拆分名称必须由非单词字符分隔，例如，`test-file.csv`而不是`testfile.csv`。支持的分隔符包括下划线、破折号、空格、点和数字。

例如，以下文件名都是可接受的：

+   训练拆分：`train.csv`、`my_train_file.csv`、`train1.csv`

+   验证拆分：`validation.csv`、`my_validation_file.csv`、`validation1.csv`

+   测试拆分：`test.csv`、`my_test_file.csv`、`test1.csv`

这是一个所有文件都放置在名为`data`的目录中的示例：

```py
my_dataset_repository/
├── README.md
└── data/
    ├── train.csv
    ├── test.csv
    └── validation.csv
```

### 自定义文件名拆分

如果您的数据集拆分具有非`train`、`test`或`validation`的自定义名称，则可以将数据文件命名为`data/<split_name>-xxxxx-of-xxxxx.csv`。

这是一个具有三个拆分`train`、`test`和`random`的示例：

```py
my_dataset_repository/
├── README.md
└── data/
    ├── train-00000-of-00003.csv
    ├── train-00001-of-00003.csv
    ├── train-00002-of-00003.csv
    ├── test-00000-of-00001.csv
    ├── random-00000-of-00003.csv
    ├── random-00001-of-00003.csv
    └── random-00002-of-00003.csv
```

### 单个拆分

当🤗数据集找不到以上任何模式时，它将把所有文件视为单个训练拆分。如果您的数据集拆分加载不符合预期，可能是由于不正确的模式。

### 拆分名称关键字

有几种命名拆分的方法。验证拆分有时称为“dev”，测试拆分可能被称为“eval”。这些其他拆分名称也受支持，以下关键字是等效的：

+   train，training

+   验证，有效，val，dev

+   测试，测试，评估，评估

以下结构是一个有效的存储库：

```py
my_dataset_repository/
├── README.md
└── data/
    ├── training.csv
    ├── eval.csv
    └── valid.csv
```

### 每个拆分多个文件

如果您的某个拆分包含多个文件，🤗数据集仍然可以推断出它是来自文件名的训练，验证和测试拆分。例如，如果您的训练和测试拆分跨越多个文件：

```py
my_dataset_repository/
├── README.md
├── train_0.csv
├── train_1.csv
├── train_2.csv
├── train_3.csv
├── test_0.csv
└── test_1.csv
```

确保您的`train`集的所有文件名称中都有*train*（测试和验证也是如此）。即使您在文件名中添加了前缀或后缀以`train`（例如`my_train_file_00001.csv`），🤗数据集仍然可以推断出适当的拆分。

为了方便起见，您还可以将数据文件放入不同的目录中。在这种情况下，拆分名称是从目录名称推断出来的。

```py
my_dataset_repository/
├── README.md
└── data/
    ├── train/
    │   ├── shard_0.csv
    │   ├── shard_1.csv
    │   ├── shard_2.csv
    │   └── shard_3.csv
    └── test/
        ├── shard_0.csv
        └── shard_1.csv
```

为了更灵活地加载和生成数据集，您还可以编写一个[数据集加载脚本]（./dataset_script）。
