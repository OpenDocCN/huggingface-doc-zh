# InstructPix2Pix

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/pix2pix](https://huggingface.co/docs/diffusers/api/pipelines/pix2pix)

[InstructPix2Pixï¼šå­¦ä¹ éµå¾ªå›¾åƒç¼–è¾‘è¯´æ˜](https://huggingface.co/papers/2211.09800)ç”±Tim Brooksã€Aleksander Holynskiå’ŒAlexei A. Efrosæ’°å†™ã€‚

è¯¥è®ºæ–‡çš„æ‘˜è¦ä¸ºï¼š

*æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ ¹æ®äººç±»æŒ‡ä»¤ç¼–è¾‘å›¾åƒçš„æ–¹æ³•ï¼šç»™å®šä¸€ä¸ªè¾“å…¥å›¾åƒå’Œä¸€æ¡ä¹¦é¢æŒ‡ä»¤å‘Šè¯‰æ¨¡å‹è¯¥åšä»€ä¹ˆï¼Œæˆ‘ä»¬çš„æ¨¡å‹éµå¾ªè¿™äº›æŒ‡ä»¤æ¥ç¼–è¾‘å›¾åƒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜çš„è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªå¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†-è¯­è¨€æ¨¡å‹ï¼ˆGPT-3ï¼‰å’Œæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼ˆç¨³å®šæ‰©æ•£ï¼‰-ç”Ÿæˆäº†å¤§é‡çš„å›¾åƒç¼–è¾‘ç¤ºä¾‹æ•°æ®é›†ã€‚æˆ‘ä»¬çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹InstructPix2Pixæ˜¯åœ¨æˆ‘ä»¬ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œå¹¶ä¸”åœ¨æ¨ç†æ—¶æ¨å¹¿åˆ°çœŸå®å›¾åƒå’Œç”¨æˆ·ç¼–å†™çš„æŒ‡ä»¤ã€‚ç”±äºå®ƒåœ¨å‰å‘ä¼ é€’ä¸­æ‰§è¡Œç¼–è¾‘ï¼Œä¸éœ€è¦æ¯ä¸ªç¤ºä¾‹çš„å¾®è°ƒæˆ–åæ¼”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨å‡ ç§’é’Ÿå†…å¿«é€Ÿç¼–è¾‘å›¾åƒã€‚æˆ‘ä»¬å±•ç¤ºäº†å¯¹å„ç§è¾“å…¥å›¾åƒå’Œä¹¦é¢æŒ‡ä»¤çš„å¼•äººæ³¨ç›®çš„ç¼–è¾‘ç»“æœã€‚*

æ‚¨å¯ä»¥åœ¨[é¡¹ç›®é¡µé¢](https://www.timothybrooks.com/instruct-pix2pix)ã€[åŸå§‹ä»£ç åº“](https://github.com/timothybrooks/instruct-pix2pix)å’Œ[æ¼”ç¤º](https://huggingface.co/spaces/timbrooks/instruct-pix2pix)ä¸­æ‰¾åˆ°æœ‰å…³InstructPix2Pixçš„å…¶ä»–ä¿¡æ¯ã€‚

ç¡®ä¿æŸ¥çœ‹è°ƒåº¦å™¨æŒ‡å—ä»¥äº†è§£å¦‚ä½•åœ¨è°ƒåº¦å™¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œå¹¶æŸ¥çœ‹é‡ç”¨ç»„ä»¶è·¨ç®¡é“éƒ¨åˆ†ä»¥äº†è§£å¦‚ä½•æœ‰æ•ˆåœ°å°†ç›¸åŒç»„ä»¶åŠ è½½åˆ°å¤šä¸ªç®¡é“ä¸­ã€‚

## ç¨³å®šæ‰©æ•£æŒ‡å¯¼Pix2Pixç®¡é“

### `class diffusers.StableDiffusionInstructPix2PixPipeline`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L75)

```py
( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: KarrasDiffusionSchedulers safety_checker: StableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor image_encoder: Optional = None requires_safety_checker: bool = True )
```

å‚æ•°

+   `vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKLï¼‰ï¼‰- å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç åˆ°å’Œä»æ½œåœ¨è¡¨ç¤ºä¸­ã€‚

+   `text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelï¼‰ï¼‰- å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚

+   `tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerï¼‰ï¼‰- ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°çš„`CLIPTokenizer`ã€‚

+   `unet`ï¼ˆ[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModelï¼‰ï¼‰- ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨çš„`UNet2DConditionModel`ã€‚

+   `scheduler`ï¼ˆ[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixinï¼‰ï¼‰- ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨çš„è°ƒåº¦å™¨ã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚

+   `safety_checker`ï¼ˆ`StableDiffusionSafetyChecker`ï¼‰- ä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è§†ä¸ºå…·æœ‰å†’çŠ¯æ€§æˆ–æœ‰å®³æ€§çš„åˆ†ç±»æ¨¡å—ã€‚è¯·å‚è€ƒ[æ¨¡å‹å¡ç‰‡](https://huggingface.co/runwayml/stable-diffusion-v1-5)ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `feature_extractor`ï¼ˆ[CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessorï¼‰ï¼‰- ç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾çš„`CLIPImageProcessor`ï¼›ä½œä¸º`safety_checker`çš„è¾“å…¥ã€‚

æ ¹æ®æ–‡æœ¬æŒ‡ä»¤è¿›è¡Œåƒç´ çº§å›¾åƒç¼–è¾‘çš„æµæ°´çº¿ï¼ˆåŸºäº Stable Diffusionï¼‰ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚

è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š

+   [load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion) ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥

+   [load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights) ç”¨äºåŠ è½½ LoRA æƒé‡

+   [save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights) ç”¨äºä¿å­˜ LoRA æƒé‡

+   [load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter) ç”¨äºåŠ è½½ IP é€‚é…å™¨

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L159)

```py
( prompt: Union = None image: Union = None num_inference_steps: int = 100 guidance_scale: float = 7.5 image_guidance_scale: float = 1.5 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None ip_adapter_image: Union = None output_type: Optional = 'pil' return_dict: bool = True callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] **kwargs ) â†’ export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple
```

å‚æ•°

+   `prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`prompt_embeds`ã€‚

+   `image` (`torch.FloatTensor` `np.ndarray`, `PIL.Image.Image`, `List[torch.FloatTensor]`, `List[PIL.Image.Image]`, æˆ– `List[np.ndarray]`) â€” è¡¨ç¤ºè¦æ ¹æ®`prompt`é‡æ–°ç»˜åˆ¶çš„å›¾åƒæ‰¹æ¬¡çš„`Image`æˆ–å¼ é‡ã€‚ä¹Ÿå¯ä»¥æ¥å—å›¾åƒæ½œå˜é‡ä½œä¸º`image`ï¼Œä½†å¦‚æœç›´æ¥ä¼ é€’æ½œå˜é‡ï¼Œåˆ™ä¸ä¼šå†æ¬¡ç¼–ç ã€‚

+   `num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º100) â€” é™å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„é™å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚

+   `guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`ç´§å¯†ç›¸å…³çš„å›¾åƒï¼Œä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚å½“`guidance_scale > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚

+   `image_guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º1.5) â€” å°†ç”Ÿæˆçš„å›¾åƒæ¨å‘åˆå§‹`image`ã€‚è®¾ç½®`image_guidance_scale > 1`å¯ä»¥å¯ç”¨å›¾åƒå¼•å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„å›¾åƒå¼•å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆçš„å›¾åƒä¸æº`image`ç´§å¯†ç›¸å…³ï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚æ­¤æµæ°´çº¿éœ€è¦è‡³å°‘`1`çš„å€¼ã€‚

+   `negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” æŒ‡å¯¼åœ¨å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`negative_prompt_embeds`ã€‚å½“ä¸ä½¿ç”¨å¼•å¯¼æ—¶ï¼ˆ`guidance_scale < 1`ï¼‰å°†è¢«å¿½ç•¥ã€‚

+   `num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚

+   `eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º0.0) â€” å¯¹åº”äº[DDIM](https://arxiv.org/abs/2010.02502)è®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ã€‚ä»…é€‚ç”¨äº[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚

+   `generator` (`torch.Generator`, *å¯é€‰*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚

+   `latents` (`torch.FloatTensor`, *å¯é€‰*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­æŠ½æ ·çš„é¢„ç”Ÿæˆå™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é€šè¿‡ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡ŒæŠ½æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚

+   `prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚

+   `negative_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œ`negative_prompt_embeds`å°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚ip_adapter_image â€”ï¼ˆ`PipelineImageInput`ï¼Œ*å¯é€‰*ï¼‰ï¼šå¯é€‰çš„å›¾åƒè¾“å…¥ä»¥ä¸IPé€‚é…å™¨ä¸€èµ·ä½¿ç”¨ã€‚

+   `output_type`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"pil"`ï¼‰â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹©`PIL.Image`æˆ–`np.array`ä¹‹é—´çš„ä¸€ä¸ªã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦è¿”å›[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `callback_on_step_end`ï¼ˆ`Callable`ï¼Œ*å¯é€‰*ï¼‰â€” åœ¨æ¨æ–­æœŸé—´æ¯ä¸ªå»å™ªæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`ã€‚`callback_kwargs`å°†åŒ…æ‹¬ç”±`callback_on_step_end_tensor_inputs`æŒ‡å®šçš„æ‰€æœ‰å¼ é‡çš„åˆ—è¡¨ã€‚

+   `callback_on_step_end_tensor_inputs`ï¼ˆ`List`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äº`callback_on_step_end`å‡½æ•°çš„å¼ é‡è¾“å…¥åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æŒ‡å®šçš„å¼ é‡å°†ä½œä¸º`callback_kwargs`å‚æ•°ä¼ é€’ã€‚æ‚¨åªèƒ½åŒ…å«åœ¨ç®¡é“ç±»çš„`._callback_tensor_inputs`å±æ€§ä¸­åˆ—å‡ºçš„å˜é‡ã€‚

è¿”å›

[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)æˆ–`tuple`

å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å›[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª`tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«ç›¸åº”ç”Ÿæˆå›¾åƒæ˜¯å¦åŒ…å«â€œä¸é€‚å®œå·¥ä½œâ€ï¼ˆnsfwï¼‰å†…å®¹çš„`bool`åˆ—è¡¨ã€‚

ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import PIL
>>> import requests
>>> import torch
>>> from io import BytesIO

>>> from diffusers import StableDiffusionInstructPix2PixPipeline

>>> def download_image(url):
...     response = requests.get(url)
...     return PIL.Image.open(BytesIO(response.content)).convert("RGB")

>>> img_url = "https://huggingface.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png"

>>> image = download_image(img_url).resize((512, 512))

>>> pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(
...     "timbrooks/instruct-pix2pix", torch_dtype=torch.float16
... )
>>> pipe = pipe.to("cuda")

>>> prompt = "make the mountains snowy"
>>> image = pipe(prompt=prompt, image=image).images[0]
```

#### `load_textual_inversion`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)

```py
( pretrained_model_name_or_path: Union token: Union = None tokenizer: Optional = None text_encoder: Optional = None **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path`ï¼ˆ`str`æˆ–`os.PathLike`æˆ–`List[stræˆ–os.PathLike]`æˆ–`Dict`æˆ–`List[Dict]`ï¼‰â€” å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å®ƒä»¬çš„åˆ—è¡¨ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨Hubä¸Šæ‰˜ç®¡çš„*æ¨¡å‹ID*ï¼ˆä¾‹å¦‚`sd-concepts-library/low-poly-hd-logos-icons`ï¼‰ã€‚

    +   åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„è·¯å¾„ä¸º*ç›®å½•*ï¼ˆä¾‹å¦‚`./my_text_inversion_directory/ï¼‰ã€‚

    +   åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„*æ–‡ä»¶*è·¯å¾„ï¼ˆä¾‹å¦‚`./my_text_inversions.pt`ï¼‰ã€‚

    +   ä¸€ä¸ª[torchçŠ¶æ€å­—å…¸](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)ã€‚

+   `token`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦†ç›–ç”¨äºæ–‡æœ¬åè½¬æƒé‡çš„ä»¤ç‰Œã€‚å¦‚æœ`pretrained_model_name_or_path`æ˜¯åˆ—è¡¨ï¼Œåˆ™`token`ä¹Ÿå¿…é¡»æ˜¯ç›¸åŒé•¿åº¦çš„åˆ—è¡¨ã€‚

+   `text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)ï¼Œ*å¯é€‰*ï¼‰â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨self.tokenizerã€‚

+   `tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºæ ‡è®°æ–‡æœ¬çš„`CLIPTokenizer`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨self.tokenizerã€‚

+   `weight_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” è‡ªå®šä¹‰æƒé‡æ–‡ä»¶çš„åç§°ã€‚åº”åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨ï¼š

    +   ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥ğŸ¤— Diffusersæ ¼å¼ä¿å­˜ï¼Œä½†æ˜¯ä¿å­˜åœ¨ç‰¹å®šæƒé‡åç§°ä¸‹ï¼Œä¾‹å¦‚`text_inv.bin`ã€‚

    +   ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥Automatic1111æ ¼å¼ä¿å­˜ã€‚

+   `cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®æ—¶ç¼“å­˜çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `force_download` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚

+   `proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†å°†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `local_files_only` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œæ¨¡å‹å°†ä¸ä¼šä»Hubä¸‹è½½ã€‚

+   `token` (`str` or *bool*, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ï¼‰ã€‚

+   `revision` (`str`, *optional*, defaults to `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤IDæˆ–Gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

+   `subfolder` (`str`, *optional*, defaults to `""`) â€” åœ¨Hubæˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­æ¨¡å‹æ–‡ä»¶çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚

+   `mirror` (`str`, *optional*) â€” é•œåƒæºï¼Œç”¨äºè§£å†³åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶çš„å¯è®¿é—®æ€§é—®é¢˜ã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚

å°†æ–‡æœ¬åè½¬åµŒå…¥åŠ è½½åˆ°[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)çš„æ–‡æœ¬ç¼–ç å™¨ä¸­ï¼ˆæ”¯æŒğŸ¤— Diffuserså’ŒAutomatic1111æ ¼å¼ï¼‰ã€‚

ç¤ºä¾‹ï¼š

è¦åŠ è½½ğŸ¤— Diffusersæ ¼å¼ä¸­çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼š

```py
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

pipe.load_textual_inversion("sd-concepts-library/cat-toy")

prompt = "A <cat-toy> backpack"

image = pipe(prompt, num_inference_steps=50).images[0]
image.save("cat-backpack.png")
```

è¦åŠ è½½Automatic1111æ ¼å¼ä¸­çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼Œè¯·ç¡®ä¿é¦–å…ˆä¸‹è½½å‘é‡ï¼ˆä¾‹å¦‚ä»[civitAI](https://civitai.com/models/3036?modelVersionId=9857)ï¼‰ï¼Œç„¶ååŠ è½½å‘é‡ã€‚

æœ¬åœ°ï¼š

```py
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

pipe.load_textual_inversion("./charturnerv2.pt", token="charturnerv2")

prompt = "charturnerv2, multiple views of the same character in the same outfit, a character turnaround of a woman wearing a black jacket and red shirt, best quality, intricate details."

image = pipe(prompt, num_inference_steps=50).images[0]
image.save("character.png")
```

#### `load_lora_weights`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)

```py
( pretrained_model_name_or_path_or_dict: Union adapter_name = None **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`) â€” æŸ¥çœ‹[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚

+   `kwargs` (`dict`, *optional*) â€” æŸ¥çœ‹[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚

+   `adapter_name` (`str`, *optional*) â€” ç”¨äºå¼•ç”¨åŠ è½½çš„é€‚é…å™¨æ¨¡å‹çš„é€‚é…å™¨åç§°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨`default_{i}`ï¼Œå…¶ä¸­iæ˜¯è¦åŠ è½½çš„é€‚é…å™¨æ€»æ•°ã€‚

å°†åœ¨`self.unet`å’Œ`self.text_encoder`ä¸­åŠ è½½æŒ‡å®šçš„LoRAæƒé‡ã€‚

æ‰€æœ‰kwargséƒ½å°†è½¬å‘åˆ°`self.lora_state_dict`ã€‚

æŸ¥çœ‹[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½çŠ¶æ€å­—å…¸çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

æŸ¥çœ‹[load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°`self.unet`çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

æŸ¥çœ‹[load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°`self.text_encoder`çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

#### `save_lora_weights`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)

```py
( save_directory: Union unet_lora_layers: Dict = None text_encoder_lora_layers: Dict = None transformer_lora_layers: Dict = None is_main_process: bool = True weight_name: str = None save_function: Callable = None safe_serialization: bool = True )
```

å‚æ•°

+   `save_directory` (`str` or `os.PathLike`) â€” ä¿å­˜LoRAå‚æ•°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†è¢«åˆ›å»ºã€‚

+   `unet_lora_layers`ï¼ˆ`Dict[str, torch.nn.Module]`æˆ–`Dict[str, torch.Tensor]`ï¼‰â€” ä¸`unet`å¯¹åº”çš„LoRAå±‚çš„çŠ¶æ€å­—å…¸ã€‚

+   `text_encoder_lora_layers`ï¼ˆ`Dict[str, torch.nn.Module]`æˆ–`Dict[str, torch.Tensor]`ï¼‰â€” ä¸`text_encoder`å¯¹åº”çš„LoRAå±‚çš„çŠ¶æ€å­—å…¸ã€‚å¿…é¡»æ˜¾å¼ä¼ é€’æ–‡æœ¬ç¼–ç å™¨LoRAçŠ¶æ€å­—å…¸ï¼Œå› ä¸ºå®ƒæ¥è‡ªğŸ¤— Transformersã€‚

+   `is_main_process`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´å¾ˆæœ‰ç”¨ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®`is_main_process=True`ï¼Œä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚

+   `save_function`ï¼ˆ`Callable`ï¼‰â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢`torch.save`æ—¶å¾ˆæœ‰ç”¨ã€‚å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡`DIFFUSERS_SAVE_MODE`è¿›è¡Œé…ç½®ã€‚

+   `safe_serialization`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä½¿ç”¨`safetensors`ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„PyTorchæ–¹å¼ä¸`pickle`ã€‚

ä¿å­˜ä¸UNetå’Œæ–‡æœ¬ç¼–ç å™¨å¯¹åº”çš„LoRAå‚æ•°ã€‚

#### `disable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L832)

```py
( )
```

ç¦ç”¨äº†å¯ç”¨çš„FreeUæœºåˆ¶ã€‚

#### `enable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L809)

```py
( s1: float s2: float b1: float b2: float )
```

å‚æ•°

+   `s1`ï¼ˆ`float`ï¼‰â€” ç”¨äºé˜»å°¼è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚

+   `s2`ï¼ˆ`float`ï¼‰â€” ç”¨äºé˜»å°¼è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚

+   `b1`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚

+   `b2`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚

å¯ç”¨äº†FreeUæœºåˆ¶ï¼Œå¦‚[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)ä¸­æ‰€è¿°ã€‚

ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬è¢«åº”ç”¨çš„é˜¶æ®µã€‚

è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚Stable Diffusion v1ã€v2å’ŒStable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚

## StableDiffusionXLInstructPix2PixPipeline

### `class diffusers.StableDiffusionXLInstructPix2PixPipeline`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L120)

```py
( vae: AutoencoderKL text_encoder: CLIPTextModel text_encoder_2: CLIPTextModelWithProjection tokenizer: CLIPTokenizer tokenizer_2: CLIPTokenizer unet: UNet2DConditionModel scheduler: KarrasDiffusionSchedulers force_zeros_for_empty_prompt: bool = True add_watermarker: Optional = None )
```

å‚æ•°

+   `vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)ï¼‰â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç ä»¥åŠä»æ½œåœ¨è¡¨ç¤ºä¸­ã€‚

+   `text_encoder`ï¼ˆ`CLIPTextModel`ï¼‰â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚Stable Diffusion XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)å˜ä½“ã€‚

+   `text_encoder_2`ï¼ˆ`CLIPTextModelWithProjection`ï¼‰â€” ç¬¬äºŒä¸ªå†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚Stable Diffusion XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection)çš„æ–‡æœ¬å’Œæ± éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)å˜ä½“ã€‚

+   `tokenizer`ï¼ˆ`CLIPTokenizer`ï¼‰â€” ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„åˆ†è¯å™¨ã€‚

+   `tokenizer_2` (`CLIPTokenizer`) â€” ç¬¬äºŒä¸ªç±»çš„Tokenizer [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)ã€‚

+   `unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)) â€” ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„æ¡ä»¶U-Netæ¶æ„ã€‚

+   `scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)) â€” ä¸`unet`ç»“åˆä½¿ç”¨çš„è°ƒåº¦å™¨ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚

+   `requires_aesthetics_score` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`"False"`) â€” `unet`åœ¨æ¨æ–­æœŸé—´æ˜¯å¦éœ€è¦é€šè¿‡å®¡ç¾è¯„åˆ†æ¡ä»¶ã€‚ä¹Ÿè¯·å‚é˜…`stabilityai/stable-diffusion-xl-refiner-1-0`çš„é…ç½®ã€‚

+   `force_zeros_for_empty_prompt` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`"True"`) â€” æ˜¯å¦å¼ºåˆ¶å°†è´Ÿæç¤ºåµŒå…¥å§‹ç»ˆè®¾ç½®ä¸º0ã€‚ä¹Ÿè¯·å‚é˜…`stabilityai/stable-diffusion-xl-base-1-0`çš„é…ç½®ã€‚

+   `add_watermarker` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨[invisible_watermarkåº“](https://github.com/ShieldMnt/invisible-watermark/)æ¥ç»™è¾“å‡ºå›¾åƒæ·»åŠ æ°´å°ã€‚å¦‚æœæœªå®šä¹‰ï¼Œä¸”è¯¥è½¯ä»¶åŒ…å·²å®‰è£…ï¼Œåˆ™é»˜è®¤ä¸ºTrueï¼Œå¦åˆ™å°†ä¸ä½¿ç”¨æ°´å°ã€‚

åŸºäºç¨³å®šæ‰©æ•£XLçš„åƒç´ çº§å›¾åƒç¼–è¾‘æµæ°´çº¿ï¼Œé€šè¿‡ä»¥ä¸‹æ–‡æœ¬æŒ‡ä»¤ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚

è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š

+   [load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion) ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥

+   [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file) ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶

+   [load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights) ç”¨äºåŠ è½½LoRAæƒé‡

+   `save_lora_weights()` ç”¨äºä¿å­˜LoRAæƒé‡

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L652)

```py
( prompt: Union = None prompt_2: Union = None image: Union = None height: Optional = None width: Optional = None num_inference_steps: int = 100 denoising_end: Optional = None guidance_scale: float = 5.0 image_guidance_scale: float = 1.5 negative_prompt: Union = None negative_prompt_2: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None guidance_rescale: float = 0.0 original_size: Tuple = None crops_coords_top_left: Tuple = (0, 0) target_size: Tuple = None ) â†’ export const metadata = 'undefined';~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput or tuple
```

å‚æ•°

+   `prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” å¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`prompt_embeds`ã€‚

+   `prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`prompt`ã€‚

+   `image` (`torch.FloatTensor` æˆ– `PIL.Image.Image` æˆ– `np.ndarray` æˆ– `List[torch.FloatTensor]` æˆ– `List[PIL.Image.Image]` æˆ– `List[np.ndarray]`) â€” è¦ä½¿ç”¨æµæ°´çº¿ä¿®æ”¹çš„å›¾åƒã€‚

+   `height` (`int`, *å¯é€‰*, é»˜è®¤ä¸ºself.unet.config.sample_size * self.vae_scale_factor) â€” ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚

+   `width` (`int`, *å¯é€‰*, é»˜è®¤ä¸ºself.unet.config.sample_size * self.vae_scale_factor) â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚

+   `num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨æ–­é€Ÿåº¦ã€‚

+   `denoising_end` (`float`, *å¯é€‰*) â€” å½“æŒ‡å®šæ—¶ï¼Œç¡®å®šåœ¨æœ‰æ„æå‰ç»ˆæ­¢ä¹‹å‰å®Œæˆçš„æ€»å»å™ªè¿‡ç¨‹çš„åˆ†æ•°ï¼ˆä»‹äº0.0å’Œ1.0ä¹‹é—´ï¼‰ã€‚å› æ­¤ï¼Œè¿”å›çš„æ ·æœ¬ä»å°†ä¿ç•™ç”±è°ƒåº¦ç¨‹åºé€‰æ‹©çš„ç¦»æ•£æ—¶é—´æ­¥ç¡®å®šçš„å¤§é‡å™ªå£°ã€‚å½“æ­¤ç®¡é“å½¢æˆâ€œå»å™ªå™¨æ··åˆâ€å¤šç®¡é“è®¾ç½®çš„ä¸€éƒ¨åˆ†æ—¶ï¼Œåº”ç†æƒ³åœ°åˆ©ç”¨ `denoising_end` å‚æ•°ï¼Œå¦‚[`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)ä¸­æ‰€è¿°ã€‚

+   `guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 5.0) â€” åœ¨[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)ä¸­å®šä¹‰çš„æŒ‡å¯¼æ¯”ä¾‹ã€‚`guidance_scale` å®šä¹‰ä¸º[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)ä¸­æ–¹ç¨‹å¼2çš„ `w`ã€‚é€šè¿‡è®¾ç½® `guidance_scale > 1` æ¥å¯ç”¨æŒ‡å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„æŒ‡å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆä¸æ–‡æœ¬ `prompt` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚

+   `image_guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 1.5) â€” å›¾åƒæŒ‡å¯¼æ¯”ä¾‹ç”¨äºå°†ç”Ÿæˆçš„å›¾åƒæ¨å‘åˆå§‹å›¾åƒ `image`ã€‚é€šè¿‡è®¾ç½® `image_guidance_scale > 1` æ¥å¯ç”¨å›¾åƒæŒ‡å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„å›¾åƒæŒ‡å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆä¸æºå›¾åƒ `image` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚æ­¤ç®¡é“éœ€è¦è‡³å°‘ `1` çš„å€¼ã€‚

+   `negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„è´Ÿé¢æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’ `negative_prompt_embeds`ã€‚å¦‚æœä¸ä½¿ç”¨æŒ‡å¯¼ï¼ˆå³ï¼Œå¦‚æœ `guidance_scale` å°äº `1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚

+   `negative_prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„è´Ÿé¢æç¤ºï¼Œå°†å‘é€åˆ° `tokenizer_2` å’Œ `text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­éƒ½ä½¿ç”¨ `negative_prompt`ã€‚

+   `num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚

+   `eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” å¯¹åº”äºDDIMè®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ï¼š[https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502)ã€‚ä»…é€‚ç”¨äº[schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œå¯¹å…¶ä»–æƒ…å†µå°†è¢«å¿½ç•¥ã€‚

+   `generator` (`torch.Generator` æˆ– `List[torch.Generator]`, *å¯é€‰*) â€” ä¸€ä¸ªæˆ–å¤šä¸ª[torchç”Ÿæˆå™¨](https://pytorch.org/docs/stable/generated/torch.Generator.html)ï¼Œç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§ã€‚

+   `latents` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„å˜ˆæ‚æ½œå˜é‡ï¼Œä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨æä¾›çš„éšæœº `generator` è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚

+   `prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä» `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚

+   `negative_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿé¢æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä» `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆ `negative_prompt_embeds`ã€‚

+   `pooled_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ± åŒ–æ–‡æœ¬åµŒå…¥å°†ä» `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚

+   `negative_pooled_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿé¢æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä» `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„è´Ÿé¢æç¤ºåµŒå…¥ã€‚

+   `output_type` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹©åœ¨ [PIL](https://pillow.readthedocs.io/en/stable/) ä¸­çš„ `PIL.Image.Image` æˆ– `np.array` ä¹‹é—´ã€‚

+   `return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„ tupleã€‚

+   `callback` (`Callable`, *å¯é€‰*) â€” æ¨æ–­æœŸé—´æ¯ `callback_steps` æ­¥è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback(step: int, timestep: int, latents: torch.FloatTensor)`ã€‚

+   `callback_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” `callback` å‡½æ•°å°†è¢«è°ƒç”¨çš„é¢‘ç‡ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†åœ¨æ¯ä¸€æ­¥è°ƒç”¨å›è°ƒå‡½æ•°ã€‚

+   `cross_attention_kwargs` (`dict`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™ `AttentionProcessor` çš„ kwargs å­—å…¸ï¼Œå¦‚åœ¨ [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py) ä¸­çš„ `self.processor` ä¸­å®šä¹‰ã€‚

+   `guidance_rescale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf) æå‡ºçš„æŒ‡å¯¼ç¼©æ”¾å› å­ã€‚`guidance_scale` åœ¨ [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf) çš„æ–¹ç¨‹å¼ 16 ä¸­å®šä¹‰ã€‚æŒ‡å¯¼ç¼©æ”¾å› å­åº”åœ¨ä½¿ç”¨é›¶ç»ˆç«¯ SNR æ—¶ä¿®å¤è¿‡æ›å…‰é—®é¢˜ã€‚

+   `original_size` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º (1024, 1024)) â€” å¦‚æœ `original_size` ä¸ `target_size` ä¸åŒï¼Œå›¾åƒå°†å‘ˆç°ä¸ºç¼©å°æˆ–æ”¾å¤§ã€‚å¦‚æœæœªæŒ‡å®šï¼Œ`original_size` é»˜è®¤ä¸º `(height, width)`ã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952) ç¬¬2.2èŠ‚ã€‚

+   `crops_coords_top_left` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º (0, 0)) â€” `crops_coords_top_left` å¯ç”¨äºç”Ÿæˆä¸€ä¸ªçœ‹èµ·æ¥ä»ä½ç½® `crops_coords_top_left` å‘ä¸‹â€œè£å‰ªâ€çš„å›¾åƒã€‚é€šå¸¸é€šè¿‡å°† `crops_coords_top_left` è®¾ç½®ä¸º (0, 0) æ¥å®ç°æœ‰åˆ©çš„ã€å±…ä¸­çš„å›¾åƒã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952) ç¬¬2.2èŠ‚ã€‚

+   `target_size` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º (1024, 1024)) â€” å¯¹äºå¤§å¤šæ•°æƒ…å†µï¼Œ`target_size` åº”è®¾ç½®ä¸ºç”Ÿæˆå›¾åƒçš„æœŸæœ›é«˜åº¦å’Œå®½åº¦ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º `(height, width)`ã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952) ç¬¬2.2èŠ‚ã€‚

+   `aesthetic_score` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 6.0) â€” é€šè¿‡å½±å“æ­£æ–‡æ¡ä»¶æ¥æ¨¡æ‹Ÿç”Ÿæˆå›¾åƒçš„ç¾å­¦è¯„åˆ†ã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952) ç¬¬2.2èŠ‚ã€‚

+   `negative_aesthetic_score` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 2.5) â€” è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952) ç¬¬2.2èŠ‚ã€‚å¯ç”¨äºé€šè¿‡å½±å“è´Ÿé¢æ–‡æœ¬æ¡ä»¶æ¥æ¨¡æ‹Ÿç”Ÿæˆå›¾åƒçš„ç¾å­¦è¯„åˆ†ã€‚

è¿”å›å€¼

`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` æˆ– `tuple`

å¦‚æœ `return_dict` ä¸º Trueï¼Œåˆ™è¿”å› `~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput`ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª `tuple`ã€‚å½“è¿”å›ä¸€ä¸ª tuple æ—¶ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ã€‚

è°ƒç”¨ç®¡é“è¿›è¡Œç”Ÿæˆæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import StableDiffusionXLInstructPix2PixPipeline
>>> from diffusers.utils import load_image

>>> resolution = 768
>>> image = load_image(
...     "https://hf.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png"
... ).resize((resolution, resolution))
>>> edit_instruction = "Turn sky into a cloudy one"

>>> pipe = StableDiffusionXLInstructPix2PixPipeline.from_pretrained(
...     "diffusers/sdxl-instructpix2pix-768", torch_dtype=torch.float16
... ).to("cuda")

>>> edited_image = pipe(
...     prompt=edit_instruction,
...     image=image,
...     height=resolution,
...     width=resolution,
...     guidance_scale=3.0,
...     image_guidance_scale=1.5,
...     num_inference_steps=30,
... ).images[0]
>>> edited_image
```

#### `disable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L648)

```py
( )
```

å¦‚æœå¯ç”¨äº†FreeUæœºåˆ¶ï¼Œåˆ™å°†å…¶ç¦ç”¨ã€‚

#### `disable_vae_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L217)

```py
( )
```

ç¦ç”¨åˆ†ç‰‡VAEè§£ç ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_vae_slicing`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

#### `disable_vae_tiling`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L233)

```py
( )
```

ç¦ç”¨åˆ†ç‰‡VAEè§£ç ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_vae_tiling`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

#### `enable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L625)

```py
( s1: float s2: float b1: float b2: float )
```

å‚æ•°

+   `s1`ï¼ˆ`float`ï¼‰â€” ç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚

+   `s2`ï¼ˆ`float`ï¼‰â€” ç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚

+   `b1`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚

+   `b2`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚

å¯ç”¨FreeUæœºåˆ¶ï¼Œå¦‚[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)ä¸­æ‰€è¿°ã€‚

ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬è¢«åº”ç”¨çš„é˜¶æ®µã€‚

è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚Stable Diffusion v1ã€v2å’ŒStable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚

#### `enable_vae_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L208)

```py
( )
```

å¯ç”¨åˆ†ç‰‡VAEè§£ç ã€‚

å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†åˆ†å‰²è¾“å…¥å¼ é‡ä»¥åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç ã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜å¹¶å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°éå¸¸æœ‰ç”¨ã€‚

#### `enable_vae_tiling`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L224)

```py
( )
```

å¯ç”¨åˆ†ç‰‡VAEè§£ç ã€‚

å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†åˆ†å‰²è¾“å…¥å¼ é‡ä»¥åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚

#### `encode_prompt`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L240)

```py
( prompt: str prompt_2: Optional = None device: Optional = None num_images_per_prompt: int = 1 do_classifier_free_guidance: bool = True negative_prompt: Optional = None negative_prompt_2: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None lora_scale: Optional = None )
```

å‚æ•°

+   `prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦ç¼–ç çš„æç¤º

+   `prompt_2`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`prompt`ã€‚è®¾å¤‡ â€” (`torch.device`): torchè®¾å¤‡

+   `num_images_per_prompt`ï¼ˆ`int`ï¼‰â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡

+   `do_classifier_free_guidance`ï¼ˆ`bool`ï¼‰â€” æ˜¯å¦ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼

+   `negative_prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚å¦‚æœä¸ä½¿ç”¨æŒ‡å¯¼ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚

+   `negative_prompt_2` (`str` or `List[str]`, *optional*) â€” ç”¨äºä¸æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºï¼Œå°†å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`negative_prompt`ã€‚

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆnegative_prompt_embedsã€‚

+   `pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„æ–‡æœ¬åµŒå…¥ã€‚

+   `negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional`) â€” é¢„ç”Ÿæˆçš„è´Ÿæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„negative_prompt_embedsã€‚

+   `lora_scale` (`float`, *optional*) â€” å¦‚æœåŠ è½½äº†LoRAå±‚ï¼Œåˆ™å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰LoRAå±‚çš„loraæ¯”ä¾‹ã€‚

å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
