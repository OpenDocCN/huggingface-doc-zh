# 从Hub加载数据集

> 原文链接：[https://huggingface.co/docs/datasets/load_hub](https://huggingface.co/docs/datasets/load_hub)

查找可重现且可访问的高质量数据集可能很困难。🤗 数据集的主要目标之一是提供一种简单的方式来加载任何格式或类型的数据集。开始的最简单方法是在[Hugging Face Hub](https://huggingface.co/datasets)上发现现有数据集 - 这是一个社区驱动的数据集集合，用于NLP、计算机视觉和音频任务 - 并使用🤗 数据集下载和生成数据集。

本教程使用[rotten_tomatoes](https://huggingface.co/datasets/rotten_tomatoes)和[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)数据集，但请随意加载您想要的任何数据集并跟随操作。立即前往Hub并找到适合您任务的数据集！

## 加载数据集

在花时间下载数据集之前，快速获取有关数据集的一般信息通常是有帮助的。数据集的信息存储在[DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo)中，可以包括数据集描述、特征和数据集大小等信息。

使用[load_dataset_builder()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset_builder)函数加载数据集构建器并检查数据集的属性，而不必下载它：

```py
>>> from datasets import load_dataset_builder
>>> ds_builder = load_dataset_builder("rotten_tomatoes")

# Inspect dataset description
>>> ds_builder.info.description
Movie Review Dataset. This is a dataset of containing 5,331 positive and 5,331 negative processed sentences from Rotten Tomatoes movie reviews. This data was first used in Bo Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.'', Proceedings of the ACL, 2005.

# Inspect dataset features
>>> ds_builder.info.features
{'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None),
 'text': Value(dtype='string', id=None)}
```

如果您对数据集满意，请使用[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)加载它：

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("rotten_tomatoes", split="train")
```

## 拆分

拆分是数据集的特定子集，如`train`和`test`。使用[get_dataset_split_names()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.get_dataset_split_names)函数列出数据集的拆分名称：

```py
>>> from datasets import get_dataset_split_names

>>> get_dataset_split_names("rotten_tomatoes")
['train', 'validation', 'test']
```

然后您可以使用`split`参数加载特定的拆分。加载数据集`split`将返回一个[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象：

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("rotten_tomatoes", split="train")
>>> dataset
Dataset({
    features: ['text', 'label'],
    num_rows: 8530
})
```

如果您没有指定`split`，🤗 数据集将返回一个[DatasetDict](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetDict)对象：

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("rotten_tomatoes")
DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 8530
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 1066
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 1066
    })
})
```

## 配置

一些数据集包含多个子数据集。例如，[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)数据集有多个子数据集，每个子数据集包含不同语言的音频数据。这些子数据集称为*配置*，在加载数据集时必须明确选择一个。如果您没有提供配置名称，🤗 数据集将引发`ValueError`并提醒您选择一个配置。

使用[get_dataset_config_names()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.get_dataset_config_names)函数检索数据集可用的所有可能配置的列表：

```py
>>> from datasets import get_dataset_config_names

>>> configs = get_dataset_config_names("PolyAI/minds14")
>>> print(configs)
['cs-CZ', 'de-DE', 'en-AU', 'en-GB', 'en-US', 'es-ES', 'fr-FR', 'it-IT', 'ko-KR', 'nl-NL', 'pl-PL', 'pt-PT', 'ru-RU', 'zh-CN', 'all']
```

然后加载您想要的配置：

```py
>>> from datasets import load_dataset

>>> mindsFR = load_dataset("PolyAI/minds14", "fr-FR", split="train")
```

## 远程代码

某些数据集存储库包含用于生成数据集的Python代码的加载脚本。这些数据集通常由Hugging Face导出为Parquet，以便🤗 数据集可以快速加载数据集而无需运行加载脚本。

即使Parquet导出不可用，您仍然可以使用`load_dataset`中的Python代码在其存储库中使用任何数据集。所有上传到Hub的文件和代码都会被扫描以检测恶意软件（有关更多信息，请参阅Hub安全文档），但您仍应查看数据集加载脚本和作者，以避免在您的计算机上执行恶意代码。您应该设置`trust_remote_code=True`以使用带有加载脚本的数据集，否则您将收到警告：

```py
>>> from datasets import get_dataset_config_names, get_dataset_split_names, load_dataset

>>> c4 = load_dataset("c4", "en", split="train", trust_remote_code=True)
>>> get_dataset_config_names("c4", trust_remote_code=True)
['en', 'realnewslike', 'en.noblocklist', 'en.noclean']
>>> get_dataset_split_names("c4", "en", trust_remote_code=True)
['train', 'validation']
```

在下一个主要版本中，🤗 数据集的新安全功能将默认禁用运行数据集加载脚本，并且您必须传递`trust_remote_code=True`以加载需要运行数据集脚本的数据集。
