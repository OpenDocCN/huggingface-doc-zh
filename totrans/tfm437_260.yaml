- en: DeiT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DeiT
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deit](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deit)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deit](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deit)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: The DeiT model was proposed in [Training data-efficient image transformers &
    distillation through attention](https://arxiv.org/abs/2012.12877) by Hugo Touvron,
    Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ©
    JÃ©gou. The [Vision Transformer (ViT)](vit) introduced in [Dosovitskiy et al.,
    2020](https://arxiv.org/abs/2010.11929) has shown that one can match or even outperform
    existing convolutional neural networks using a Transformer encoder (BERT-like).
    However, the ViT models introduced in that paper required training on expensive
    infrastructure for multiple weeks, using external data. DeiT (data-efficient image
    transformers) are more efficiently trained transformers for image classification,
    requiring far less data and far less computing resources compared to the original
    ViT models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: DeiTæ¨¡å‹æ˜¯ç”±Hugo Touvronã€Matthieu Cordã€Matthijs Douzeã€Francisco Massaã€Alexandre
    Sablayrollesã€HervÃ© JÃ©gouåœ¨[é€šè¿‡æ³¨æ„åŠ›è¿›è¡Œæ•°æ®é«˜æ•ˆå›¾åƒå˜æ¢å™¨è®­ç»ƒå’Œè’¸é¦](https://arxiv.org/abs/2012.12877)ä¸­æå‡ºçš„ã€‚[Vision
    Transformerï¼ˆViTï¼‰](vit)æ˜¯ç”±[Dosovitskiyç­‰äººï¼Œ2020](https://arxiv.org/abs/2010.11929)å¼•å…¥çš„ï¼Œå®ƒè¡¨æ˜å¯ä»¥ä½¿ç”¨Transformerç¼–ç å™¨ï¼ˆç±»ä¼¼BERTï¼‰åŒ¹é…ç”šè‡³è¶…è¶Šç°æœ‰çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚ç„¶è€Œï¼Œè¯¥è®ºæ–‡ä¸­ä»‹ç»çš„ViTæ¨¡å‹éœ€è¦åœ¨æ˜‚è´µçš„åŸºç¡€è®¾æ–½ä¸Šè¿›è¡Œå¤šå‘¨çš„è®­ç»ƒï¼Œä½¿ç”¨å¤–éƒ¨æ•°æ®ã€‚DeiTï¼ˆæ•°æ®é«˜æ•ˆå›¾åƒå˜æ¢å™¨ï¼‰æ˜¯æ›´é«˜æ•ˆçš„ç”¨äºå›¾åƒåˆ†ç±»çš„è®­ç»ƒå˜æ¢å™¨ï¼Œä¸åŸå§‹ViTæ¨¡å‹ç›¸æ¯”ï¼Œéœ€è¦æ›´å°‘çš„æ•°æ®å’Œæ›´å°‘çš„è®¡ç®—èµ„æºã€‚
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*Recently, neural networks purely based on attention were shown to address
    image understanding tasks such as image classification. However, these visual
    transformers are pre-trained with hundreds of millions of images using an expensive
    infrastructure, thereby limiting their adoption. In this work, we produce a competitive
    convolution-free transformer by training on Imagenet only. We train them on a
    single computer in less than 3 days. Our reference vision transformer (86M parameters)
    achieves top-1 accuracy of 83.1% (single-crop evaluation) on ImageNet with no
    external data. More importantly, we introduce a teacher-student strategy specific
    to transformers. It relies on a distillation token ensuring that the student learns
    from the teacher through attention. We show the interest of this token-based distillation,
    especially when using a convnet as a teacher. This leads us to report results
    competitive with convnets for both Imagenet (where we obtain up to 85.2% accuracy)
    and when transferring to other tasks. We share our code and models.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ€è¿‘ï¼Œçº¯åŸºäºæ³¨æ„åŠ›çš„ç¥ç»ç½‘ç»œè¢«è¯æ˜å¯ä»¥è§£å†³å›¾åƒç†è§£ä»»åŠ¡ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€‚ç„¶è€Œï¼Œè¿™äº›è§†è§‰å˜æ¢å™¨æ˜¯ä½¿ç”¨æ˜‚è´µçš„åŸºç¡€è®¾æ–½å¯¹æ•°äº¿å¼ å›¾åƒè¿›è¡Œé¢„è®­ç»ƒçš„ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„é‡‡ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»…åœ¨Imagenetä¸Šè¿›è¡Œè®­ç»ƒï¼Œåˆ¶ä½œäº†ä¸€æ¬¾ç«äº‰åŠ›å¼ºçš„æ— å·ç§¯å˜æ¢å™¨ã€‚æˆ‘ä»¬åœ¨ä¸åˆ°3å¤©çš„æ—¶é—´å†…åœ¨ä¸€å°è®¡ç®—æœºä¸Šå¯¹å®ƒä»¬è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„å‚è€ƒè§†è§‰å˜æ¢å™¨ï¼ˆ8600ä¸‡å‚æ•°ï¼‰åœ¨ImageNetä¸Šçš„å•è£å‰ªè¯„ä¼°ä¸­å®ç°äº†83.1%çš„top-1å‡†ç¡®ç‡ï¼Œæ²¡æœ‰ä½¿ç”¨å¤–éƒ¨æ•°æ®ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç‰¹å®šäºå˜æ¢å™¨çš„å¸ˆç”Ÿç­–ç•¥ã€‚å®ƒä¾èµ–äºä¸€ä¸ªè’¸é¦æ ‡è®°ï¼Œç¡®ä¿å­¦ç”Ÿé€šè¿‡æ³¨æ„åŠ›ä»è€å¸ˆé‚£é‡Œå­¦ä¹ ã€‚æˆ‘ä»¬å±•ç¤ºäº†åŸºäºè¿™ç§åŸºäºæ ‡è®°çš„è’¸é¦çš„å…´è¶£ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨å·ç§¯ç½‘ç»œä½œä¸ºè€å¸ˆæ—¶ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤ŸæŠ¥å‘Šä¸å·ç§¯ç½‘ç»œåœ¨Imagenetä¸Šç«äº‰çš„ç»“æœï¼ˆæˆ‘ä»¬çš„å‡†ç¡®ç‡é«˜è¾¾85.2%ï¼‰ï¼Œä»¥åŠåœ¨è½¬ç§»åˆ°å…¶ä»–ä»»åŠ¡æ—¶ã€‚æˆ‘ä»¬åˆ†äº«æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹ã€‚*'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The TensorFlow
    version of this model was added by [amyeroberts](https://huggingface.co/amyeroberts).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚è¯¥æ¨¡å‹çš„TensorFlowç‰ˆæœ¬ç”±[amyeroberts](https://huggingface.co/amyeroberts)æ·»åŠ ã€‚
- en: Usage tips
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æç¤º
- en: Compared to ViT, DeiT models use a so-called distillation token to effectively
    learn from a teacher (which, in the DeiT paper, is a ResNet like-model). The distillation
    token is learned through backpropagation, by interacting with the class ([CLS])
    and patch tokens through the self-attention layers.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ViTç›¸æ¯”ï¼ŒDeiTæ¨¡å‹ä½¿ç”¨æ‰€è°“çš„è’¸é¦æ ‡è®°æ¥æœ‰æ•ˆåœ°ä»è€å¸ˆé‚£é‡Œå­¦ä¹ ï¼ˆåœ¨DeiTè®ºæ–‡ä¸­ï¼Œè€å¸ˆæ˜¯ç±»ä¼¼ResNetçš„æ¨¡å‹ï¼‰ã€‚é€šè¿‡è‡ªæ³¨æ„åŠ›å±‚ï¼Œè’¸é¦æ ‡è®°é€šè¿‡ä¸ç±»ï¼ˆ[CLS]ï¼‰å’Œè¡¥ä¸æ ‡è®°çš„äº¤äº’è¿›è¡Œåå‘ä¼ æ’­å­¦ä¹ ã€‚
- en: There are 2 ways to fine-tune distilled models, either (1) in a classic way,
    by only placing a prediction head on top of the final hidden state of the class
    token and not using the distillation signal, or (2) by placing both a prediction
    head on top of the class token and on top of the distillation token. In that case,
    the [CLS] prediction head is trained using regular cross-entropy between the prediction
    of the head and the ground-truth label, while the distillation prediction head
    is trained using hard distillation (cross-entropy between the prediction of the
    distillation head and the label predicted by the teacher). At inference time,
    one takes the average prediction between both heads as final prediction. (2) is
    also called â€œfine-tuning with distillationâ€, because one relies on a teacher that
    has already been fine-tuned on the downstream dataset. In terms of models, (1)
    corresponds to [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    and (2) corresponds to [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher).
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è’¸é¦æ¨¡å‹è¿›è¡Œå¾®è°ƒæœ‰ä¸¤ç§æ–¹å¼ï¼Œè¦ä¹ˆï¼ˆ1ï¼‰é‡‡ç”¨ä¼ ç»Ÿæ–¹å¼ï¼Œåªåœ¨ç±»æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¸Šæ”¾ç½®ä¸€ä¸ªé¢„æµ‹å¤´ï¼Œä¸ä½¿ç”¨è’¸é¦ä¿¡å·ï¼Œè¦ä¹ˆï¼ˆ2ï¼‰åœ¨ç±»æ ‡è®°å’Œè’¸é¦æ ‡è®°çš„é¡¶éƒ¨éƒ½æ”¾ç½®ä¸€ä¸ªé¢„æµ‹å¤´ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ[CLS]é¢„æµ‹å¤´ä½¿ç”¨é¢„æµ‹å¤´å’Œåœ°é¢çœŸå®æ ‡ç­¾ä¹‹é—´çš„å¸¸è§„äº¤å‰ç†µè¿›è¡Œè®­ç»ƒï¼Œè€Œè’¸é¦é¢„æµ‹å¤´ä½¿ç”¨ç¡¬è’¸é¦è¿›è¡Œè®­ç»ƒï¼ˆè’¸é¦å¤´çš„é¢„æµ‹å’Œæ•™å¸ˆé¢„æµ‹çš„æ ‡ç­¾ä¹‹é—´çš„äº¤å‰ç†µï¼‰ã€‚åœ¨æ¨ç†æ—¶ï¼Œå°†ä¸¤ä¸ªå¤´ä¹‹é—´çš„å¹³å‡é¢„æµ‹ä½œä¸ºæœ€ç»ˆé¢„æµ‹ã€‚ï¼ˆ2ï¼‰ä¹Ÿè¢«ç§°ä¸ºâ€œè’¸é¦å¾®è°ƒâ€ï¼Œå› ä¸ºä¾èµ–äºå·²ç»åœ¨ä¸‹æ¸¸æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒçš„æ•™å¸ˆã€‚åœ¨æ¨¡å‹æ–¹é¢ï¼Œï¼ˆ1ï¼‰å¯¹åº”äº[DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)ï¼Œï¼ˆ2ï¼‰å¯¹åº”äº[DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)ã€‚
- en: Note that the authors also did try soft distillation for (2) (in which case
    the distillation prediction head is trained using KL divergence to match the softmax
    output of the teacher), but hard distillation gave the best results.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä½œè€…ä»¬è¿˜å°è¯•äº†å¯¹ï¼ˆ2ï¼‰è¿›è¡Œè½¯è’¸é¦ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè’¸é¦é¢„æµ‹å¤´ä½¿ç”¨KLæ•£åº¦è¿›è¡Œè®­ç»ƒï¼Œä»¥åŒ¹é…è€å¸ˆçš„softmaxè¾“å‡ºï¼‰ï¼Œä½†ç¡¬è’¸é¦æ•ˆæœæœ€å¥½ã€‚
- en: All released checkpoints were pre-trained and fine-tuned on ImageNet-1k only.
    No external data was used. This is in contrast with the original ViT model, which
    used external data like the JFT-300M dataset/Imagenet-21k for pre-training.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å‘å¸ƒçš„æ£€æŸ¥ç‚¹ä»…åœ¨ImageNet-1kä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒå’Œå¾®è°ƒã€‚æ²¡æœ‰ä½¿ç”¨å¤–éƒ¨æ•°æ®ã€‚è¿™ä¸åŸå§‹çš„ViTæ¨¡å‹å½¢æˆå¯¹æ¯”ï¼ŒåŸå§‹çš„ViTæ¨¡å‹ä½¿ç”¨äº†å¤–éƒ¨æ•°æ®ï¼Œå¦‚JFT-300Mæ•°æ®é›†/Imagenet-21kè¿›è¡Œé¢„è®­ç»ƒã€‚
- en: 'The authors of DeiT also released more efficiently trained ViT models, which
    you can directly plug into [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    or [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification).
    Techniques like data augmentation, optimization, and regularization were used
    in order to simulate training on a much larger dataset (while only using ImageNet-1k
    for pre-training). There are 4 variants available (in 3 different sizes): *facebook/deit-tiny-patch16-224*,
    *facebook/deit-small-patch16-224*, *facebook/deit-base-patch16-224* and *facebook/deit-base-patch16-384*.
    Note that one should use [DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor)
    in order to prepare images for the model.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeiTçš„ä½œè€…è¿˜å‘å¸ƒäº†æ›´é«˜æ•ˆè®­ç»ƒçš„ViTæ¨¡å‹ï¼Œæ‚¨å¯ä»¥ç›´æ¥æ’å…¥[ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)æˆ–[ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)ã€‚ä¸ºäº†æ¨¡æ‹Ÿåœ¨ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†ä¸Šè®­ç»ƒï¼ˆä»…ä½¿ç”¨ImageNet-1kè¿›è¡Œé¢„è®­ç»ƒï¼‰ï¼Œä½¿ç”¨äº†æ•°æ®å¢å¼ºã€ä¼˜åŒ–å’Œæ­£åˆ™åŒ–ç­‰æŠ€æœ¯ã€‚æœ‰4ä¸ªå˜ä½“å¯ç”¨ï¼ˆ3ç§ä¸åŒå¤§å°ï¼‰ï¼š*facebook/deit-tiny-patch16-224*ã€*facebook/deit-small-patch16-224*ã€*facebook/deit-base-patch16-224*å’Œ*facebook/deit-base-patch16-384*ã€‚è¯·æ³¨æ„ï¼Œåº”è¯¥ä½¿ç”¨[DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor)æ¥ä¸ºæ¨¡å‹å‡†å¤‡å›¾åƒã€‚
- en: Resources
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started with DeiT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç³»åˆ—å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨DeiTã€‚
- en: Image Classification
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒåˆ†ç±»
- en: '[DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)æ”¯æŒã€‚'
- en: 'See also: [Image classification task guide](../tasks/image_classification)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚è§ï¼š[å›¾åƒåˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/image_classification)
- en: 'Besides that:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼š
- en: '[DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)æ”¯æŒã€‚'
- en: If youâ€™re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and weâ€™ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ªPull Requestï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥ç†æƒ³åœ°å±•ç¤ºä¸€äº›æ–°ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: DeiTConfig
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTConfig
- en: '### `class transformers.DeiTConfig`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/configuration_deit.py#L37)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/configuration_deit.py#L37)'
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`hidden_size` (`int`, *optional*, defaults to 768) â€” Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º768ï¼‰â€” ç¼–ç å™¨å±‚å’Œæ± åŒ–å±‚çš„ç»´åº¦ã€‚'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) â€” Number of hidden
    layers in the Transformer encoder.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º12ï¼‰â€” Transformerç¼–ç å™¨ä¸­çš„éšè—å±‚æ•°é‡ã€‚'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) â€” Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º12ï¼‰â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) â€” Dimensionality
    of the â€œintermediateâ€ (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º3072ï¼‰â€” Transformerç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆå³å‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) â€” The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act`ï¼ˆ`str`æˆ–`function`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"gelu"`ï¼‰â€” ç¼–ç å™¨å’Œæ± åŒ–å±‚ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`ã€`"relu"`ã€`"selu"`å’Œ`"gelu_new"`ã€‚'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) â€” The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.0ï¼‰â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å±‚ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¤±æ¦‚ç‡ã€‚'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) â€” The
    dropout ratio for the attention probabilities.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.0ï¼‰â€” æ³¨æ„åŠ›æ¦‚ç‡çš„ä¸¢å¤±æ¯”ç‡ã€‚'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) â€” The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.02ï¼‰â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) â€” The epsilon used
    by the layer normalization layers.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º1e-12ï¼‰â€” å±‚å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„epsilonã€‚'
- en: '`image_size` (`int`, *optional*, defaults to 224) â€” The size (resolution) of
    each image.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º224ï¼‰â€” æ¯ä¸ªå›¾åƒçš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚'
- en: '`patch_size` (`int`, *optional*, defaults to 16) â€” The size (resolution) of
    each patch.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º16ï¼‰â€” æ¯ä¸ªè¡¥ä¸çš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚'
- en: '`num_channels` (`int`, *optional*, defaults to 3) â€” The number of input channels.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º3ï¼‰â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) â€” Whether to add a bias
    to the queries, keys and values.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä¸ºæŸ¥è¯¢ã€é”®å’Œå€¼æ·»åŠ åç½®ã€‚'
- en: '`encoder_stride` (`int`, *optional*, defaults to 16) â€” Factor to increase the
    spatial resolution by in the decoder head for masked image modeling.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_stride` (`int`, *optional*, é»˜è®¤ä¸º 16) â€” ç”¨äºåœ¨è§£ç å™¨å¤´éƒ¨å¢åŠ ç©ºé—´åˆ†è¾¨ç‡çš„å› å­ï¼Œç”¨äºé®è”½å›¾åƒå»ºæ¨¡ã€‚'
- en: This is the configuration class to store the configuration of a [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel).
    It is used to instantiate an DeiT model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the DeiT [facebook/deit-base-distilled-patch16-224](https://huggingface.co/facebook/deit-base-distilled-patch16-224)
    architecture.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ª DeiT æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº DeiT [facebook/deit-base-distilled-patch16-224](https://huggingface.co/facebook/deit-base-distilled-patch16-224)
    æ¶æ„çš„é…ç½®ã€‚
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»æ¥è‡ª
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: 'Example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: DeiTFeatureExtractor
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTFeatureExtractor
- en: '### `class transformers.DeiTFeatureExtractor`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/feature_extraction_deit.py#L26)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/feature_extraction_deit.py#L26)'
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `__call__`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Preprocess an image or a batch of images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒã€‚
- en: DeiTImageProcessor
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTImageProcessor
- en: '### `class transformers.DeiTImageProcessor`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/image_processing_deit.py#L45)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/image_processing_deit.py#L45)'
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) â€” Whether to resize the
    imageâ€™s (height, width) dimensions to the specified `size`. Can be overridden
    by `do_resize` in `preprocess`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†å›¾åƒçš„ (height, width) å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šçš„
    `size`ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `do_resize` è¦†ç›–ã€‚'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 256, "width":
    256}`): Size of the image after `resize`. Can be overridden by `size` in `preprocess`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *optional*, é»˜è®¤ä¸º `{"height" -- 256, "width": 256}`):
    `resize` åçš„å›¾åƒå°ºå¯¸ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `size` è¦†ç›–ã€‚'
- en: '`resample` (`PILImageResampling` filter, *optional*, defaults to `Resampling.BICUBIC`)
    â€” Resampling filter to use if resizing the image. Can be overridden by `resample`
    in `preprocess`.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling` è¿‡æ»¤å™¨, *optional*, é»˜è®¤ä¸º `Resampling.BICUBIC`)
    â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œè¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `resample` è¦†ç›–ã€‚'
- en: '`do_center_crop` (`bool`, *optional*, defaults to `True`) â€” Whether to center
    crop the image. If the input size is smaller than `crop_size` along any edge,
    the image is padded with 0â€™s and then center cropped. Can be overridden by `do_center_crop`
    in `preprocess`.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_center_crop` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚å¦‚æœè¾“å…¥å°ºå¯¸åœ¨ä»»ä¸€è¾¹å°äº
    `crop_size`ï¼Œåˆ™å›¾åƒå°†ç”¨ 0 å¡«å……ï¼Œç„¶åè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `do_center_crop` è¦†ç›–ã€‚'
- en: '`crop_size` (`Dict[str, int]`, *optional*, defaults to `{"height" -- 224, "width":
    224}`): Desired output size when applying center-cropping. Can be overridden by
    `crop_size` in `preprocess`.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crop_size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `{"height" -- 224, "width":
    224}`): åº”ç”¨ä¸­å¿ƒè£å‰ªæ—¶çš„æœŸæœ›è¾“å‡ºå°ºå¯¸ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `crop_size` è¦†ç›–ã€‚'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) â€” Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in the `preprocess` method.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` æˆ– `float`, *optional*, é»˜è®¤ä¸º `1/255`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œè¦ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚å¯ä»¥è¢«
    `preprocess` æ–¹æ³•ä¸­çš„ `rescale_factor` å‚æ•°è¦†ç›–ã€‚'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) â€” Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`
    parameter in the `preprocess` method.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor` é‡æ–°ç¼©æ”¾å›¾åƒã€‚å¯ä»¥è¢«
    `preprocess` æ–¹æ³•ä¸­çš„ `do_rescale` å‚æ•°è¦†ç›–ã€‚'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) â€” Whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚å¯ä»¥è¢« `preprocess`
    æ–¹æ³•ä¸­çš„ `do_normalize` å‚æ•°è¦†ç›–ã€‚'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    â€” Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `IMAGENET_STANDARD_MEAN`)
    â€” å¦‚æœå¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ï¼Œè¦ä½¿ç”¨çš„å‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_mean`
    å‚æ•°è¦†ç›–ã€‚'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    â€” Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `IMAGENET_STANDARD_STD`)
    â€” å¦‚æœå¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ï¼Œè¦ä½¿ç”¨çš„æ ‡å‡†å·®ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_std`
    å‚æ•°è¦†ç›–ã€‚'
- en: Constructs a DeiT image processor.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ª DeiT å›¾åƒå¤„ç†å™¨ã€‚
- en: '#### `preprocess`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/image_processing_deit.py#L161)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/image_processing_deit.py#L161)'
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`ImageInput`) â€” Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒã€‚æœŸæœ›å•ä¸ªå›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ï¼Œåƒç´ å€¼èŒƒå›´ä¸º 0 åˆ° 255ã€‚å¦‚æœä¼ å…¥åƒç´ å€¼åœ¨ 0 åˆ° 1
    ä¹‹é—´çš„å›¾åƒï¼Œè¯·è®¾ç½® `do_rescale=False`ã€‚'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) â€” Whether to
    resize the image.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_resize`) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) â€” Size of the
    image after `resize`.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `self.size`) â€” `resize` åçš„å›¾åƒå¤§å°ã€‚'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `self.resample`)
    â€” PILImageResampling filter to use if resizing the image Only has an effect if
    `do_resize` is set to `True`.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *optional*, é»˜è®¤ä¸º `self.resample`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™ä½¿ç”¨çš„
    PILImageResampling è¿‡æ»¤å™¨ã€‚ä»…åœ¨ `do_resize` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚'
- en: '`do_center_crop` (`bool`, *optional*, defaults to `self.do_center_crop`) â€”
    Whether to center crop the image.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_center_crop` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_center_crop`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚'
- en: '`crop_size` (`Dict[str, int]`, *optional*, defaults to `self.crop_size`) â€”
    Size of the image after center crop. If one edge the image is smaller than `crop_size`,
    it will be padded with zeros and then cropped'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crop_size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `self.crop_size`) â€” å±…ä¸­è£å‰ªåçš„å›¾åƒå¤§å°ã€‚å¦‚æœå›¾åƒçš„ä¸€æ¡è¾¹å°äº
    `crop_size`ï¼Œåˆ™å°†ç”¨é›¶å¡«å……ï¼Œç„¶åè£å‰ªã€‚'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) â€” Whether
    to rescale the image values between [0 - 1].'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_rescale`) â€” æ˜¯å¦å°†å›¾åƒå€¼é‡æ–°ç¼©æ”¾åˆ° [0 -
    1] ä¹‹é—´ã€‚'
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) â€”
    Rescale factor to rescale the image by if `do_rescale` is set to `True`.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *optional*, é»˜è®¤ä¸º `self.rescale_factor`) â€” å¦‚æœ `do_rescale`
    è®¾ç½®ä¸º `True`ï¼Œåˆ™ç”¨äºé‡æ–°ç¼©æ”¾å›¾åƒçš„é‡æ–°ç¼©æ”¾å› å­ã€‚'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) â€” Whether
    to normalize the image.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_normalize`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    â€” Image mean.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `self.image_mean`) â€”
    å›¾åƒå‡å€¼ã€‚'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    â€” Image standard deviation.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `self.image_std`) â€” å›¾åƒæ ‡å‡†å·®ã€‚'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) â€” The type of tensors
    to return. Can be one of:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` æˆ– `TensorType`, *optional*) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š'
- en: '`None`: Return a list of `np.ndarray`.'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`None`: è¿”å›ä¸€ä¸ª `np.ndarray` åˆ—è¡¨ã€‚'
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW` æˆ– `''tf''`: è¿”å›ç±»å‹ä¸º `tf.Tensor` çš„æ‰¹æ¬¡ã€‚'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` æˆ– `''pt''`: è¿”å›ç±»å‹ä¸º `torch.Tensor` çš„æ‰¹æ¬¡ã€‚'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY` æˆ– `''np''`: è¿”å›ç±»å‹ä¸º `np.ndarray` çš„æ‰¹æ¬¡ã€‚'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX` æˆ– `''jax''`: è¿”å›ç±»å‹ä¸º `jax.numpy.ndarray` çš„æ‰¹æ¬¡ã€‚'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    â€” The channel dimension format for the output image. Can be one of:'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` æˆ– `str`, *optional*, é»˜è®¤ä¸º `ChannelDimension.FIRST`)
    â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`: å›¾åƒä»¥ (num_channels, height, width) æ ¼å¼ã€‚'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`: å›¾åƒä»¥ (height, width, num_channels) æ ¼å¼ã€‚'
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) â€” The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format` (`ChannelDimension` æˆ– `str`, *optional*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` æˆ– `ChannelDimension.FIRST`: å›¾åƒä»¥ (num_channels, height, width)
    æ ¼å¼ã€‚'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` æˆ– `ChannelDimension.LAST`: å›¾åƒä»¥ (height, width, num_channels)
    æ ¼å¼ã€‚'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` æˆ– `ChannelDimension.NONE`: å›¾åƒä»¥ (height, width) æ ¼å¼ã€‚'
- en: Preprocess an image or batch of images.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚
- en: PytorchHide Pytorch content
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: DeiTModel
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTModel
- en: '### `class transformers.DeiTModel`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L447)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L447)'
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare DeiT Model transformer outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸ DeiT æ¨¡å‹å˜æ¢å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡¶éƒ¨å¤´ã€‚æ­¤æ¨¡å‹æ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L476)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L476)'
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]`ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«é®è”½ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„
    `attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„
    `hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`,
    *optional*) â€” Boolean masked positions. Indicates which patches are masked (1)
    and which arenâ€™t (0).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`,
    *optional*) â€” å¸ƒå°”æ©ç ä½ç½®ã€‚æŒ‡ç¤ºå“ªäº›è¡¥ä¸è¢«é®è”½ï¼ˆ1ï¼‰å“ªäº›æ²¡æœ‰ï¼ˆ0ï¼‰ã€‚'
- en: Returns
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    æˆ– `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    æˆ–ä¸€ä¸ª `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False`
    æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ä¸åŒå…ƒç´ ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    â€” Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    â€” åºåˆ—ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼Œåœ¨é€šè¿‡ç”¨äºè¾…åŠ©é¢„è®­ç»ƒä»»åŠ¡çš„å±‚è¿›ä¸€æ­¥å¤„ç†åã€‚ä¾‹å¦‚ï¼Œå¯¹äº BERT ç³»åˆ—æ¨¡å‹ï¼Œè¿™å°†è¿”å›ç»è¿‡çº¿æ€§å±‚å’ŒåŒæ›²æ­£åˆ‡æ¿€æ´»å‡½æ•°å¤„ç†åçš„åˆ†ç±»æ ‡è®°ã€‚çº¿æ€§å±‚æƒé‡æ˜¯ä»é¢„è®­ç»ƒæœŸé—´çš„ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒçš„ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’ `output_hidden_states=True`
    æˆ–å½“ `config.output_hidden_states=True` æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º `(batch_size, sequence_length,
    hidden_size)` çš„ `torch.FloatTensor` å…ƒç»„ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¯å±‚æ¨¡å‹çš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’ `output_attentions=True`
    æˆ–å½“ `config.output_attentions=True` æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º `(batch_size, num_heads, sequence_length,
    sequence_length)` çš„ `torch.FloatTensor` å…ƒç»„ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    forward method, overrides the `__call__` special method.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº† `__call__` ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨ `Module` å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: DeiTForMaskedImageModeling
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTForMaskedImageModeling
- en: '### `class transformers.DeiTForMaskedImageModeling`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTForMaskedImageModeling`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L559)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L559)'
- en: '[PRE9]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: DeiT Model with a decoder on top for masked image modeling, as proposed in [SimMIM](https://arxiv.org/abs/2111.09886).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¸¦æœ‰é¡¶éƒ¨è§£ç å™¨çš„DeiTæ¨¡å‹ï¼Œç”¨äºé®ç½©å›¾åƒå»ºæ¨¡ï¼Œå¦‚[SimMIM](https://arxiv.org/abs/2111.09886)ä¸­æå‡ºçš„ã€‚ '
- en: Note that we provide a script to pre-train this model on custom data in our
    [examples directory](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨æˆ‘ä»¬çš„[ç¤ºä¾‹ç›®å½•](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)ä¸­æä¾›äº†ä¸€ä¸ªè„šæœ¬ï¼Œç”¨äºåœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šé¢„è®­ç»ƒæ­¤æ¨¡å‹ã€‚
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚
- en: '#### `forward`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L589)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L589)'
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height,
    width)`) â€” åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`ï¼Œ*optional*)
    â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚åœ¨`[0, 1]`ä¸­é€‰æ‹©çš„æ©ç å€¼ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æ˜¯`not masked`,
- en: 0 indicates the head is `masked`.
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`)
    â€” Boolean masked positions. Indicates which patches are masked (1) and which arenâ€™t
    (0).'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos` (`torch.BoolTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_patches)`) â€” å¸ƒå°”æ©ç ä½ç½®ã€‚æŒ‡ç¤ºå“ªäº›è¡¥ä¸è¢«æ©ç›–ï¼ˆ1ï¼‰å“ªäº›æ²¡æœ‰ï¼ˆ0ï¼‰ã€‚'
- en: Returns
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.modeling_outputs.MaskedImageModelingOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_outputs.MaskedImageModelingOutput`æˆ–`tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_outputs.MaskedImageModelingOutput` or a tuple of `torch.FloatTensor`
    (if `return_dict=False` is passed or when `config.return_dict=False`) comprising
    various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.modeling_outputs.MaskedImageModelingOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå…·ä½“å–å†³äºé…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `bool_masked_pos`
    is provided) â€” Reconstruction loss.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`ï¼Œ*optional*ï¼Œå½“æä¾›`bool_masked_pos`æ—¶è¿”å›) â€”
    é‡å»ºæŸå¤±ã€‚'
- en: '`reconstruction` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) â€” Reconstructed / completed images.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reconstruction` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height,
    width)`) â€” é‡å»º/å®Œæˆçš„å›¾åƒã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æ—¶è¿”å›'
- en: '`when` `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the model at the output of each stage.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`when` `config.output_hidden_states=True`) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›'
- en: '`config.output_attentions=True):` Tuple of `torch.FloatTensor` (one for each
    layer) of shape `(batch_size, num_heads, patch_size, sequence_length)`. Attentions
    weights after the attention softmax, used to compute the weighted average in the
    self-attention heads.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_attentions=True):` å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚'
- en: The [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)
    forward method, overrides the `__call__` special method.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE11]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: DeiTForImageClassification
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTForImageClassification
- en: '### `class transformers.DeiTForImageClassification`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L676)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L676)'
- en: '[PRE12]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰-
    æ¨¡å‹çš„æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: DeiT Model transformer with an image classification head on top (a linear layer
    on top of the final hidden state of the [CLS] token) e.g. for ImageNet.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨çš„DeiTæ¨¡å‹å˜æ¢å™¨ï¼ˆåœ¨[CLS]æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L696)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L696)'
- en: '[PRE13]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰-
    åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” Labels
    for computing the image classification/regression loss. Indices should be in `[0,
    ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is
    computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0,
    ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels == 1`ï¼Œåˆ™è®¡ç®—å›å½’æŸå¤±ï¼ˆå‡æ–¹æŸå¤±ï¼‰ï¼Œå¦‚æœ`config.num_labels
    > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚'
- en: Returns
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.ImageClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.ImageClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutput)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.ImageClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.ImageClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ä¸åŒå…ƒç´ ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) â€”
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the model at the output of each stage.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, patch_size, sequence_length)`.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è‡ªæ³¨æ„åŠ›å¤´ä¸­ç”¨äºè®¡ç®—åŠ æƒå¹³å‡å€¼çš„æ³¨æ„åŠ›æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åã€‚
- en: The [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE14]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: DeiTForImageClassificationWithTeacher
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeiTForImageClassificationWithTeacher
- en: '### `class transformers.DeiTForImageClassificationWithTeacher`'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeiTForImageClassificationWithTeacher`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L821)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L821)'
- en: '[PRE15]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰â€”
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: DeiT Model transformer with image classification heads on top (a linear layer
    on top of the final hidden state of the [CLS] token and a linear layer on top
    of the final hidden state of the distillation token) e.g. for ImageNet.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: DeiTæ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´ï¼ˆåœ¨[CLS]ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼Œåœ¨è’¸é¦ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚
- en: '.. warning::'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '.. è­¦å‘Š::'
- en: This model supports inference-only. Fine-tuning with distillation (i.e. with
    a teacher) is not yet supported.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä»…æ”¯æŒæ¨ç†ã€‚å°šä¸æ”¯æŒä½¿ç”¨è’¸é¦ï¼ˆå³ä½¿ç”¨æ•™å¸ˆï¼‰è¿›è¡Œå¾®è°ƒã€‚
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L851)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L851)'
- en: '[PRE16]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰â€”
    åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput`æˆ–`tuple(torch.FloatTensor)`'
- en: A `transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ã€‚
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) â€”
    Prediction scores as the average of the cls_logits and distillation logits.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰- é¢„æµ‹åˆ†æ•°ï¼Œä½œä¸º`cls_logits`å’Œè’¸é¦`logits`çš„å¹³å‡å€¼ã€‚'
- en: '`cls_logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`)
    â€” Prediction scores of the classification head (i.e. the linear layer on top of
    the final hidden state of the class token).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰- åˆ†ç±»å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³ç±»ä»¤ç‰Œæœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨çš„çº¿æ€§å±‚ï¼‰ã€‚'
- en: '`distillation_logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`)
    â€” Prediction scores of the distillation head (i.e. the linear layer on top of
    the final hidden state of the distillation token).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distillation_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰-
    è’¸é¦å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³è’¸é¦ä»¤ç‰Œæœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨çš„çº¿æ€§å±‚ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`. Hidden-states of the model at the
    output of each layer plus the initial embedding outputs.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º
    + ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºå’Œåˆå§‹åµŒå…¥è¾“å‡ºå¤„çš„éšè—çŠ¶æ€ã€‚'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚'
- en: The [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)
    forward method, overrides the `__call__` special method.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE17]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: TensorFlowHide TensorFlow content
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè—TensorFlowå†…å®¹
- en: TFDeiTModel
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFDeiTModel
- en: '### `class transformers.TFDeiTModel`'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFDeiTModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L723)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L723)'
- en: '[PRE18]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰-
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare DeiT Model transformer outputting raw hidden-states without any specific
    head on top. This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer).
    Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸DeiTæ¨¡å‹å˜å‹å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šå¤´éƒ¨ã€‚æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ªTensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„TensorFlowæ¨¡å—ï¼Œå¹¶å‚è€ƒTensorFlowæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `call`'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L737)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L737)'
- en: '[PRE19]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰â€”
    åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰å®šåœ¨`[0, 1]`ä¸­ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨`æœªè¢«æ©ç›–`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨`è¢«æ©ç›–`ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling)
    or `tuple(tf.Tensor)`'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling)æˆ–`tuple(tf.Tensor)`'
- en: A [transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚'
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    â€” Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼‰â€”
    æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) â€” Last layer
    hidden-state of the first token of the sequence (classification token) further
    processed by a Linear layer and a Tanh activation function. The Linear layer weights
    are trained from the next sentence prediction (classification) objective during
    pretraining.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, hidden_size)`çš„`tf.Tensor`ï¼‰â€” åºåˆ—ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼Œç»è¿‡çº¿æ€§å±‚å’ŒTanhæ¿€æ´»å‡½æ•°è¿›ä¸€æ­¥å¤„ç†ã€‚çº¿æ€§å±‚çš„æƒé‡æ˜¯åœ¨é¢„è®­ç»ƒæœŸé—´ä»ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒçš„ã€‚'
- en: This output is usually *not* a good summary of the semantic content of the input,
    youâ€™re often better with averaging or pooling the sequence of hidden-states for
    the whole input sequence.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¾“å‡ºé€šå¸¸*ä¸æ˜¯*è¾“å…¥çš„è¯­ä¹‰å†…å®¹çš„å¥½æ‘˜è¦ï¼Œé€šå¸¸æœ€å¥½å¯¹æ•´ä¸ªè¾“å…¥åºåˆ—çš„éšè—çŠ¶æ€è¿›è¡Œå¹³å‡æˆ–æ± åŒ–ã€‚
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆåµŒå…¥è¾“å‡ºçš„ä¸€ä¸ª+æ¯å±‚è¾“å‡ºçš„ä¸€ä¸ªï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    forward method, overrides the `__call__` special method.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE20]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: TFDeiTForMaskedImageModeling
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFDeiTForMaskedImageModeling
- en: '### `class transformers.TFDeiTForMaskedImageModeling`'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFDeiTForMaskedImageModeling`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L859)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L859)'
- en: '[PRE21]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: DeiT Model with a decoder on top for masked image modeling, as proposed in [SimMIM](https://arxiv.org/abs/2111.09886).
    This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer).
    Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: DeiT æ¨¡å‹åœ¨é¡¶éƒ¨å¸¦æœ‰è§£ç å™¨ï¼Œç”¨äºé®è”½å›¾åƒå»ºæ¨¡ï¼Œå¦‚ [SimMIM](https://arxiv.org/abs/2111.09886) ä¸­æå‡ºçš„ã€‚æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ª
    TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„
    TensorFlow æ¨¡å—ï¼Œå¹¶å‚è€ƒ TensorFlow æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `call`'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L871)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L871)'
- en: '[PRE22]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æ˜¯ `not masked`,
- en: 0 indicates the head is `masked`.
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨æ˜¯ `masked`ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„
    `attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„
    `hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`bool_masked_pos` (`tf.Tensor` of type bool and shape `(batch_size, num_patches)`)
    â€” Boolean masked positions. Indicates which patches are masked (1) and which arenâ€™t
    (0).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos` (`tf.Tensor` of type bool and shape `(batch_size, num_patches)`)
    â€” å¸ƒå°”æ©ç ä½ç½®ã€‚æŒ‡ç¤ºå“ªäº›è¡¥ä¸è¢«é®è”½ï¼ˆ1ï¼‰å“ªäº›æ²¡æœ‰ï¼ˆ0ï¼‰ã€‚'
- en: Returns
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.modeling_tf_outputs.TFMaskedImageModelingOutput` or `tuple(tf.Tensor)`'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFMaskedImageModelingOutput` æˆ– `tuple(tf.Tensor)`'
- en: A `transformers.modeling_tf_outputs.TFMaskedImageModelingOutput` or a tuple
    of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª `transformers.modeling_tf_outputs.TFMaskedImageModelingOutput` æˆ–ä¸€ä¸ª `tf.Tensor`
    å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚
- en: '`loss` (`tf.Tensor` of shape `(1,)`, *optional*, returned when `bool_masked_pos`
    is provided) â€” Reconstruction loss.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`tf.Tensor` of shape `(1,)`, *optional*, returned when `bool_masked_pos`
    is provided) â€” Reconstruction loss.'
- en: '`reconstruction` (`tf.Tensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Reconstructed / completed images.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reconstruction` (`tf.Tensor` of shape `(batch_size, num_channels, height,
    width)`) â€” é‡å»º/å®Œæˆçš„å›¾åƒã€‚'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when'
- en: '`config.output_hidden_states=True):` Tuple of `tf.Tensor` (one for the output
    of the embeddings, if the model has an embedding layer, + one for the output of
    each stage) of shape `(batch_size, sequence_length, hidden_size)`. Hidden-states
    (also called feature maps) of the model at the output of each stage.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_hidden_states=True):` `tf.Tensor` å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹å…·æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º +
    ä¸€ä¸ªç”¨äºæ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰çš„å½¢çŠ¶ä¸º `(batch_size, sequence_length, hidden_size)`ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚'
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(tf.Tensor)`, *optional*, å½“ä¼ é€’ `output_attentions=True`
    æˆ–'
- en: '`config.output_attentions=True):` Tuple of `tf.Tensor` (one for each layer)
    of shape `(batch_size, num_heads, patch_size, sequence_length)`. Attentions weights
    after the attention softmax, used to compute the weighted average in the self-attention
    heads.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_attentions=True):` `tf.Tensor` å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰çš„å½¢çŠ¶ä¸º `(batch_size, num_heads,
    patch_size, sequence_length)`ã€‚æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚'
- en: The [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)
    forward method, overrides the `__call__` special method.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)
    çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº† `__call__` ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨ `Module` å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE23]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: TFDeiTForImageClassification
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFDeiTForImageClassification
- en: '### `class transformers.TFDeiTForImageClassification`'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFDeiTForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L983)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L983)'
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰â€”
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: DeiT Model transformer with an image classification head on top (a linear layer
    on top of the final hidden state of the [CLS] token) e.g. for ImageNet.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: DeiT æ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨ï¼ˆåœ¨ [CLS] æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äº ImageNetã€‚
- en: This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer).
    Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ª TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„
    TensorFlow æ¨¡å—ï¼Œå¹¶å‚è€ƒ TensorFlow æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `call`'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1005)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1005)'
- en: '[PRE25]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`ï¼ˆå½¢çŠ¶ä¸º `(batch_size, num_channels, height, width)` çš„ `tf.Tensor`ï¼‰â€”
    åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º `(num_heads,)` æˆ– `(num_layers, num_heads)` çš„ `tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰å®šåœ¨ `[0, 1]` èŒƒå›´å†…ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®ç½©ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«é®ç½©ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿”å›å¼ é‡ä¸‹çš„ `attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿”å›å¼ é‡ä¸‹çš„ `hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`tf.Tensor` of shape `(batch_size,)`, *optional*) â€” Labels for computing
    the image classification/regression loss. Indices should be in `[0, ..., config.num_labels
    - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square
    loss), If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`ï¼ˆå½¢çŠ¶ä¸º `(batch_size,)` çš„ `tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨ `[0,
    ..., config.num_labels - 1]` èŒƒå›´å†…ã€‚å¦‚æœ `config.num_labels == 1`ï¼Œåˆ™è®¡ç®—å›å½’æŸå¤±ï¼ˆå‡æ–¹æŸå¤±ï¼‰ï¼Œå¦‚æœ
    `config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚'
- en: Returns
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.modeling_tf_outputs.TFImageClassifierOutput` or `tuple(tf.Tensor)`'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFImageClassifierOutput` æˆ– `tuple(tf.Tensor)`'
- en: A `transformers.modeling_tf_outputs.TFImageClassifierOutput` or a tuple of `tf.Tensor`
    (if `return_dict=False` is passed or when `config.return_dict=False`) comprising
    various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFImageClassifierOutput` æˆ– `tuple(tf.Tensor)`ï¼ˆå¦‚æœä¼ é€’äº†
    `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ã€‚'
- en: '`loss` (`tf.Tensor` of shape `(1,)`, *optional*, returned when `labels` is
    provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`ï¼ˆå½¢çŠ¶ä¸º `(1,)` çš„ `tf.Tensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾› `labels` æ—¶è¿”å›ï¼‰â€” åˆ†ç±»ï¼ˆæˆ–å¦‚æœ `config.num_labels==1`
    åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚'
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) â€” Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º `(batch_size, config.num_labels)` çš„ `tf.Tensor`ï¼‰â€” åˆ†ç±»ï¼ˆæˆ–å¦‚æœ `config.num_labels==1`
    åˆ™ä¸ºå›å½’ï¼‰åˆ†æ•°ï¼ˆSoftMax ä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the model at the output of each stage.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹å…·æœ‰åµŒå…¥å±‚çš„è¾“å‡ºï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚'
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, patch_size, sequence_length)`.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE26]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: TFDeiTForImageClassificationWithTeacher
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFDeiTForImageClassificationWithTeacher
- en: '### `class transformers.TFDeiTForImageClassificationWithTeacher`'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFDeiTForImageClassificationWithTeacher`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1092)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1092)'
- en: '[PRE27]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰-
    æ¨¡å‹é…ç½®ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: DeiT Model transformer with image classification heads on top (a linear layer
    on top of the final hidden state of the [CLS] token and a linear layer on top
    of the final hidden state of the distillation token) e.g. for ImageNet.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: DeiTæ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´ï¼ˆåœ¨[CLS]ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼Œåœ¨è’¸é¦ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚
- en: '.. warning::'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '.. è­¦å‘Š::'
- en: This model supports inference-only. Fine-tuning with distillation (i.e. with
    a teacher) is not yet supported.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ä»…æ”¯æŒæ¨æ–­ã€‚å°šä¸æ”¯æŒä½¿ç”¨è’¸é¦ï¼ˆå³ä¸æ•™å¸ˆä¸€èµ·ï¼‰è¿›è¡Œå¾®è°ƒã€‚
- en: This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer).
    Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ªTensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„TensorFlowæ¨¡å—ï¼Œå¹¶å‚è€ƒTensorFlowæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `call`'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1124)'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1124)'
- en: '[PRE28]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰-
    åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¸­ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput`
    or `tuple(tf.Tensor)`'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput`æˆ–`tuple(tf.Tensor)`'
- en: A `transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig))
    and inputs.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput`æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆDeiTConfigï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) â€” Prediction
    scores as the average of the cls_logits and distillation logits.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰- é¢„æµ‹åˆ†æ•°ï¼Œä½œä¸ºcls_logitså’Œdistillation
    logitsçš„å¹³å‡å€¼ã€‚'
- en: '`cls_logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) â€” Prediction
    scores of the classification head (i.e. the linear layer on top of the final hidden
    state of the class token).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰- åˆ†ç±»å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³åœ¨ç±»ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ã€‚'
- en: '`distillation_logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`)
    â€” Prediction scores of the distillation head (i.e. the linear layer on top of
    the final hidden state of the distillation token).'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distillation_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰- è’¸é¦å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³åœ¨è’¸é¦ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`. Hidden-states of the model at the
    output of each layer plus the initial embedding outputs.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ã€‚æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚'
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ã€‚æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚'
- en: The [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)
    forward method, overrides the `__call__` special method.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: TFDeiTForImageClassificationWithTeacherçš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE29]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
