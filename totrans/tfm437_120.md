# 模型输出

> 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/output](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/output)

所有模型的输出都是 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) 的子类实例。这些是包含模型返回的所有信息的数据结构，但也可以用作元组或字典。

让我们看一个示例：

```py
from transformers import BertTokenizer, BertForSequenceClassification
import torch

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertForSequenceClassification.from_pretrained("bert-base-uncased")

inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1
outputs = model(**inputs, labels=labels)
```

`outputs` 对象是一个 [SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)，正如我们在下面该类的文档中所看到的，它包含一个可选的 `loss`，一个 `logits`，一个可选的 `hidden_states` 和一个可选的 `attentions` 属性。这里我们有 `loss`，因为我们传递了 `labels`，但是我们没有 `hidden_states` 和 `attentions`，因为我们没有传递 `output_hidden_states=True` 或 `output_attentions=True`。

当传递 `output_hidden_states=True` 时，您可以期望 `outputs.hidden_states[-1]` 与 `outputs.last_hidden_states` 完全匹配。然而，并非总是如此。当返回最后隐藏状态时，一些模型会应用归一化或后续处理。

您可以像通常一样访问每个属性，如果该属性未被模型返回，您将得到 `None`。例如，在这里 `outputs.loss` 是模型计算的损失，而 `outputs.attentions` 是 `None`。

将我们的 `outputs` 对象视为元组时，只考虑那些没有 `None` 值的属性。例如，在这里，它有两个元素，`loss` 然后 `logits`，所以

```py
outputs[:2]
```

例如，将返回元组 `(outputs.loss, outputs.logits)`。

将我们的 `outputs` 对象视为字典时，只考虑那些没有 `None` 值的属性。例如，在这里，它有两个键，即 `loss` 和 `logits`。

我们在这里记录了被多个模型类型使用的通用模型输出。特定的输出类型在其相应的模型页面上有文档。

## ModelOutput

### `class transformers.utils.ModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/generic.py#L288)

```py
( *args **kwargs )
```

作为数据类的所有模型输出的基类。具有 `__getitem__`，允许按整数或切片（如元组）或字符串（如字典）进行索引，将忽略 `None` 属性。否则，行为类似于常规的 Python 字典。

你不能直接解包一个 `ModelOutput`。在转换之前使用 [to_tuple()](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput.to_tuple) 方法将其转换为元组。

#### `to_tuple`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/generic.py#L424)

```py
( )
```

将自身转换为包含所有不是 `None` 的属性/键的元组。

## BaseModelOutput

### `class transformers.modeling_outputs.BaseModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L24)

```py
( last_hidden_state: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递 `output_hidden_states=True` 或当 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, sequence_length, hidden_size)` 的 `torch.FloatTensor` 元组。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当`output_attentions=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

模型输出的基类，具有潜在的隐藏状态和注意力。

## BaseModelOutputWithPooling

### `class transformers.modeling_outputs.BaseModelOutputWithPooling`

[来源](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L69)

```py
( last_hidden_state: FloatTensor = None pooler_output: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state` (`形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`) — 模型最后一层的隐藏状态序列。

+   `pooler_output` (`形状为`(batch_size, hidden_size)`的`torch.FloatTensor`) — 经过用于辅助预训练任务的层进一步处理后，序列中第一个标记（分类标记）的最后一层隐藏状态。例如，对于BERT系列模型，这返回经过线性层和tanh激活函数处理后的分类标记。线性层的权重是在预训练期间从下一个句子预测（分类）目标中训练的。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当`output_hidden_states=True`被传递或者当`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个，加上每层的一个）。

    模型在每一层输出的隐藏状态加上可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当`output_attentions=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

模型输出的基类，还包含最后隐藏状态的池化。

## BaseModelOutputWithCrossAttentions

### `class transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`

[来源](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L162)

```py
( last_hidden_state: FloatTensor = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )
```

参数

+   `last_hidden_state` (`形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`) — 模型最后一层的隐藏状态序列。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当`output_hidden_states=True`被传递或者当`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个，加上每层的一个）。

    模型在每一层输出的隐藏状态加上可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当`output_attentions=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当`output_attentions=True`和`config.add_cross_attention=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

模型输出的基类，具有潜在的隐藏状态和注意力。

## BaseModelOutputWithPoolingAndCrossAttentions

### `class transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L195)

```py
( last_hidden_state: FloatTensor = None pooler_output: FloatTensor = None hidden_states: Optional = None past_key_values: Optional = None attentions: Optional = None cross_attentions: Optional = None )
```

参数

+   `last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的输出的隐藏状态序列。

+   `pooler_output` (`torch.FloatTensor`，形状为`(batch_size, hidden_size)`) — 序列第一个标记（分类标记）的最后一层隐藏状态（经过用于辅助预训练任务的层进一步处理后）的输出。例如，对于BERT系列模型，这返回经过线性层和tanh激活函数处理后的分类标记。线性层的权重是从预训练期间的下一个句子预测（分类）目标中训练的。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选的*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） — 元组的`torch.FloatTensor`（如果模型有嵌入层，则为嵌入的输出+每一层的输出）的形状为`(batch_size, sequence_length, hidden_size)`。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选的*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`的元组（每层一个）。

    注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *可选的*，当传递`output_attentions=True`和`config.add_cross_attention=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`的元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`, *可选的*，当传递`use_cache=True`或`config.use_cache=True`时返回） — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，如果`config.is_encoder_decoder=True`还有2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块中的键和值，以及如果`config.is_encoder_decoder=True`在交叉注意力块中）可用于加速顺序解码（请参见`past_key_values`输入）。

模型输出的基类，还包含最后隐藏状态的池化。

## BaseModelOutputWithPast

### `class transformers.modeling_outputs.BaseModelOutputWithPast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L123)

```py
( last_hidden_state: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的输出的隐藏状态序列。

    如果使用`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。

+   `past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）- 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，如果`config.is_encoder_decoder=True`还有2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块中的键和值，以及在交叉注意力块中如果`config.is_encoder_decoder=True`的情况下）可以用来加速顺序解码。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

模型输出的基类，可能还包含过去的键/值（用于加速顺序解码）。

## BaseModelOutputWithPastAndCrossAttentions

### `class transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L244)

```py
( last_hidden_state: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）- 模型最后一层输出的隐藏状态序列。

    如果使用`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。

+   `past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）- 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，如果`config.is_encoder_decoder=True`还有2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块中的键和值，以及在交叉注意力块中如果`config.is_encoder_decoder=True`的情况下）可以用来加速顺序解码。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`和`config.add_cross_attention=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

模型输出的基类，可能还包含过去的键/值（用于加速顺序解码）。

## Seq2SeqModelOutput

### `class transformers.modeling_outputs.Seq2SeqModelOutput`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L515)

```py
( last_hidden_state: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型解码器最后一层的隐藏状态序列。

    如果使用`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后隐藏状态。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当`use_cache=True`被传递或者当`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当`output_hidden_states=True`被传递或者当`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入层的输出加上每层的输出）。

    解码器在每一层输出的隐藏状态加上可选的初始嵌入输出。

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当`output_hidden_states=True`被传递或者当`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入层的输出加上每层的输出）。

    编码器在每一层输出的隐藏状态加上可选的初始嵌入输出。

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax后使用，用于计算自注意力头中的加权平均值。

模型编码器输出的基类，还包含：预先计算的隐藏状态，可以加速顺序解码。

## CausalLMOutput

### `class transformers.modeling_outputs.CausalLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L648)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 语言建模损失（用于下一个标记的预测）。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的输出+每层的输出）。

    模型在每一层输出的隐藏状态，以及可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

因果语言模型（或自回归）输出的基类。

## CausalLMOutputWithCrossAttentions

### `class transformers.modeling_outputs.CausalLMOutputWithCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L713)

```py
( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 语言建模损失（用于下一个标记的预测）。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的输出+每层的输出）。

    模型在每一层输出的隐藏状态，以及可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    交叉注意力softmax后的注意力权重，用于计算交叉注意力头中的加权平均值。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`torch.FloatTensor`元组，每个元组包含自注意力和交叉注意力层的缓存键、值状态，如果模型用于编码器-解码器设置，则相关。仅在`config.is_decoder = True`时相关。

    包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码。

因果语言模型（或自回归）输出的基类。

## CausalLMOutputWithPast

### `class transformers.modeling_outputs.CausalLMOutputWithPast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L677)

```py
( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 语言建模损失（用于下一个标记的预测）。

+   `logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）— 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）— 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量）

    包含预先计算的隐藏状态（自注意力块中的键和值），可用于加速顺序解码。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

因果语言模型（或自回归）输出的基类。

## MaskedLMOutput

### `class transformers.modeling_outputs.MaskedLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L793)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 掩码语言建模（MLM）损失。

+   `logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）— 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

掩码语言模型输出的基类。

## Seq2SeqLMOutput

### `class transformers.modeling_outputs.Seq2SeqLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L822)

```py
( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 语言建模损失。

+   `logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）— 语言建模头的预测分数（SoftMax之前的每个词汇标记的分数）。

+   `past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）— 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，以及2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个+每层输出的一个）。

    每层解码器的隐藏状态加上初始嵌入输出。

+   `decoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state`（`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*）— 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个+每层输出的一个）。

    每层编码器的隐藏状态加上初始嵌入输出。

+   `encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列语言模型输出的基类。

## NextSentencePredictorOutput

### `class transformers.modeling_outputs.NextSentencePredictorOutput`

[`来源`](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L957)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss`（`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`next_sentence_label`时返回）— 下一个序列预测（分类）损失。

+   `logits`（形状为`(batch_size, 2)`的`torch.FloatTensor`）— 下一个序列预测（分类）头的预测分数（SoftMax之前的True/False延续分数）。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每层的输出）。

    模型每层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

预测两个句子是否连续的模型输出的基类。

## SequenceClassifierOutput

### `class transformers.modeling_outputs.SequenceClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L987)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，在提供`labels`时返回）— 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits`（形状为`(batch_size, config.num_labels)`的`torch.FloatTensor`）— 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每层的输出）。

    模型每层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

句子分类模型输出的基类。

## Seq2SeqSequenceClassifierOutput

### `class transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1016)

```py
( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，在提供`label`时返回）— 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits`（形状为`(batch_size, config.num_labels)`的`torch.FloatTensor`）— 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。

+   `past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）— 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（见`past_key_values`输入）。

+   `decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每层的输出）。

    每层解码器的隐藏状态以及初始嵌入输出。

+   `decoder_attentions` (`tuple(torch.FloatTensor)`，*可选的*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`，*可选的*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选的*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入层的输出，如果模型有嵌入层，+ 一个用于每一层的输出）。

    每层编码器的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(torch.FloatTensor)`，*可选的*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

序列到序列句子分类模型输出的基类。

## MultipleChoiceModelOutput

### `class transformers.modeling_outputs.MultipleChoiceModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1076)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为*(1,)*，*可选的*，当提供`labels`时返回) — 分类损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, num_choices)`) — *num_choices*是输入张量的第二维度。（参见上面的*input_ids*）。

    分类得分（SoftMax之前）。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选的*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入层的输出，如果模型有嵌入层，+ 一个用于每一层的输出）。

    模型每一层的隐藏状态加上可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`，*可选的*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。

多选模型输出的基类。

## TokenClassifierOutput

### `class transformers.modeling_outputs.TokenClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1107)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选的*，当提供`labels`时返回) — 分类损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.num_labels)`) — 分类得分（SoftMax之前）。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每层输出的总和）。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

用于标记分类模型输出的基类。

## QuestionAnsweringModelOutput

### `class transformers.modeling_outputs.QuestionAnsweringModelOutput`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1136)

```py
( loss: Optional = None start_logits: FloatTensor = None end_logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*optional*，当提供`labels`时返回) — 总跨度提取损失是起始位置和结束位置的交叉熵之和。

+   `start_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`) — 跨度起始得分（SoftMax之前）。

+   `end_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`) — 跨度结束得分（SoftMax之前）。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每层输出的总和）。

    模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

用于问答模型输出的基类。

## Seq2SeqQuestionAnsweringModelOutput

### `class transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1168)

```py
( loss: Optional = None start_logits: FloatTensor = None end_logits: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*optional*，当提供`labels`时返回) — 总跨度提取损失是起始位置和结束位置的交叉熵之和。

+   `start_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`) — 跨度起始得分（SoftMax之前）。

+   `end_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`) — 跨度结束得分（SoftMax之前）。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每个层的输出的一个）。

    每层解码器的隐藏状态加上初始嵌入输出。

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每个层的输出的一个）。

    每层编码器的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列问答模型输出的基类。

## Seq2SeqSpectrogramOutput

### `class transformers.modeling_outputs.Seq2SeqSpectrogramOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1501)

```py
( loss: Optional = None spectrogram: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*, 当提供`labels`时返回) — 频谱生成损失。

+   `spectrogram` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, num_bins)`) — 预测的频谱图。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`, *可选*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每个层的输出的一个）。

    每层解码器的隐藏状态加上初始嵌入输出。

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的输出的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每一层的输出的一个）。

    每一层输出的编码器的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列频谱图输出的基类。

## SemanticSegmenterOutput

### `class transformers.modeling_outputs.SemanticSegmenterOutput`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1231)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*, 当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels, logits_height, logits_width)`) — 每个像素的分类分数。

    返回的logits不一定与传入的`pixel_values`大小相同。这是为了避免进行两次插值并在用户需要将logits调整为原始图像大小时丢失一些质量。您应该始终检查您的logits形状并根据需要调整大小。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, patch_size, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个 + 每一层的输出的一个）。

    模型在每一层输出的隐藏状态加上可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, patch_size, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于语义分割模型输出的基类。

## ImageClassifierOutput

### `class transformers.modeling_outputs.ImageClassifierOutput`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1269)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。模型在每个阶段输出的隐藏状态（也称为特征图）。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, patch_size, sequence_length)`的`torch.FloatTensor`元组。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

图像分类模型输出的基类。

## ImageClassifierOutputWithNoAttention

### `class transformers.modeling_outputs.ImageClassifierOutputWithNoAttention`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1297)

```py
( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。模型在每个阶段输出的隐藏状态（也称为特征图）。

图像分类模型输出的基类。

## DepthEstimatorOutput

### `class transformers.modeling_outputs.DepthEstimatorOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1318)

```py
( loss: Optional = None predicted_depth: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。

+   `predicted_depth` (`torch.FloatTensor`，形状为`(batch_size, height, width)`) — 每个像素的预测深度。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。

    模型在每个层输出的隐藏状态加上可选的初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, patch_size, sequence_length)`的`torch.FloatTensor`元组。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

深度估计模型输出的基类。

## Wav2Vec2BaseModelOutput

### `class transformers.modeling_outputs.Wav2Vec2BaseModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1376)

```py
( last_hidden_state: FloatTensor = None extract_features: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层输出的隐藏状态序列。

+   `extract_features` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, conv_dim[-1])`) — 模型最后一个卷积层提取的特征向量序列。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每一层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于使用Wav2Vec2损失目标进行训练的模型的基类。

## XVectorOutput

### `class transformers.modeling_outputs.XVectorOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1405)

```py
( loss: Optional = None logits: FloatTensor = None embeddings: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, config.xvector_output_dim)`) — AMSoftmax之前的分类隐藏状态。

+   `embeddings` (`torch.FloatTensor`，形状为`(batch_size, config.xvector_output_dim)`) — 用于基于向量相似性检索的话语嵌入。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每一层一个）。

    注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。

[Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)的输出类型。

## Seq2SeqTSModelOutput

### `class transformers.modeling_outputs.Seq2SeqTSModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1561)

```py
( last_hidden_state: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None loc: Optional = None scale: Optional = None static_features: Optional = None )
```

参数

+   `last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型解码器最后一层的隐藏状态序列。

    如果使用了`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后隐藏状态。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — `torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入层的输出+每层的输出）的形状为`(batch_size, sequence_length, hidden_size)`。

    解码器在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — `torch.FloatTensor`元组（每层一个）的形状为`(batch_size, num_heads, sequence_length, sequence_length)`。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — `torch.FloatTensor`元组（每层一个）的形状为`(batch_size, num_heads, sequence_length, sequence_length)`。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — `torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入层的输出+每层的输出）的形状为`(batch_size, sequence_length, hidden_size)`。

    编码器在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — `torch.FloatTensor`元组（每层一个）的形状为`(batch_size, num_heads, sequence_length, sequence_length)`。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `loc` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`, *optional*) — 每个时间序列上下文窗口的偏移值，用于给模型输入相同数量级的输入，然后用于将其偏移回原始数量级。

+   `scale` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`, *optional*) — 每个时间序列上下文窗口的缩放值，用于给模型输入相同数量级的输入，然后用于将其重新缩放回原始数量级。

+   `static_features` (`torch.FloatTensor` of shape `(batch_size, feature size)`, *optional*) — 每个时间序列在批处理中的静态特征，在推断时复制到协变量中。

时间序列模型编码器输出的基类，还包含可以加速顺序解码的预计算隐藏状态。

## Seq2SeqTSPredictionOutput

### `class transformers.modeling_outputs.Seq2SeqTSPredictionOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1633)

```py
( loss: Optional = None params: Optional = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None loc: Optional = None scale: Optional = None static_features: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`future_values`时返回) — 分布损失。

+   `params` (`torch.FloatTensor` of shape `(batch_size, num_samples, num_params)`) — 所选分布的参数。

+   `past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。

    解码器每一层的输出隐藏状态加上初始嵌入输出。

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。

    解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。

    编码器每一层的输出隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `loc` (`torch.FloatTensor`，形状为`(batch_size,)`或`(batch_size, input_size)`，*optional*) — 每个时间序列上下文窗口的偏移值，用于给模型输入相同数量级的值，然后用于将其偏移回原始数量级。

+   `scale` (`torch.FloatTensor`，形状为`(batch_size,)`或`(batch_size, input_size)`，*optional*) — 每个时间序列上下文窗口的缩放值，用于给模型输入相同数量级的值，然后用于将其重新缩放回原始数量级。

+   `static_features` (`torch.FloatTensor`，形状为`(batch_size, feature size)`，*optional*) — 每个时间序列批次的静态特征，在推断时复制到协变量中。

时间序列模型解码器输出的基类，还包含损失以及所选分布的参数。

## SampleTSPredictionOutput

### `class transformers.modeling_outputs.SampleTSPredictionOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_outputs.py#L1705)

```py
( sequences: FloatTensor = None )
```

参数

+   `sequences` (`torch.FloatTensor`，形状为`(batch_size, num_samples, prediction_length)`或`(batch_size, num_samples, prediction_length, input_size)`) — 从选择的分布中抽样的值。

时间序列模型预测输出的基类，包含从选择的分布中抽样的值。

## TFBaseModelOutput

### `class transformers.modeling_tf_outputs.TFBaseModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L26)

```py
( last_hidden_state: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列。

+   `hidden_states` (`tuple(tf.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出 + 一个用于每一层的输出）。

    模型每一层的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

模型输出的基类，具有潜在的隐藏状态和注意力。

## TFBaseModelOutputWithPooling

### `class transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L71)

```py
( last_hidden_state: tf.Tensor = None pooler_output: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列。

+   `pooler_output` (`tf.Tensor`，形状为`(batch_size, hidden_size)`) — 序列第一个标记（分类标记）的最后一层隐藏状态，进一步由线性层和Tanh激活函数处理。线性层的权重是在预训练期间从下一个句子预测（分类）目标中训练的。

    这个输出通常*不是*输入语义内容的好摘要，通常最好对整个输入序列的隐藏状态进行平均或池化。

+   `hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出 + 一个用于每一层的输出）。

    模型每一层的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

模型输出的基类，还包含最后隐藏状态的汇聚。

## TFBaseModelOutputWithPoolingAndCrossAttentions

### `class transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L127)

```py
( last_hidden_state: tf.Tensor = None pooler_output: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列。

+   `pooler_output` (`tf.Tensor`，形状为`(batch_size, hidden_size)`) — 序列第一个标记（分类标记）的最后一层隐藏状态，经过线性层和Tanh激活函数进一步处理。线性层的权重在预训练期间从下一个句子预测（分类）目标中训练。

    该输出通常*不是*输入语义内容的良好摘要，通常最好对整个输入序列的隐藏状态序列进行平均或池化。

+   `past_key_values` (`List[tf.Tensor]`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    在自注意力头中使用注意力softmax后的注意力权重，用于计算加权平均值。

+   `cross_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    在解码器的交叉注意力层中使用注意力softmax后的注意力权重，用于计算交叉注意力头中的加权平均值。

模型输出的基类，还包含最后隐藏状态的池化。

## TFBaseModelOutputWithPast

### `class transformers.modeling_tf_outputs.TFBaseModelOutputWithPast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L175)

```py
( last_hidden_state: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列。

    如果使用`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后隐藏状态。

+   `past_key_values` (`List[tf.Tensor]`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    在自注意力头中使用注意力softmax后的注意力权重，用于计算加权平均值。

模型输出的基类，可能还包含过去的键/值（用于加速顺序解码）。

## TFBaseModelOutputWithPastAndCrossAttentions

### `class transformers.modeling_tf_outputs.TFBaseModelOutputWithPastAndCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L244)

```py
( last_hidden_state: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`）- 模型最后一层的隐藏状态序列。

    如果仅使用`past_key_values`，则输出序列的最后一个隐藏状态的形状为`(batch_size, 1, hidden_size)`。

+   `past_key_values`（`List[tf.Tensor]`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）- 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含预计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码。

+   `hidden_states`（`tuple(tf.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

+   `cross_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax后，用于计算交叉注意力头中的加权平均值。

模型输出的基类，可能还包含过去的键/值（用于加速顺序解码）。

## TFSeq2SeqModelOutput

### `class transformers.modeling_tf_outputs.TFSeq2SeqModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L287)

```py
( last_hidden_state: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`）- 模型解码器最后一层的隐藏状态序列。

    如果仅使用`past_key_values`，则输出序列的最后一个隐藏状态的形状为`(batch_size, 1, hidden_size)`。

+   `past_key_values`（`List[tf.Tensor]`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）- 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含解码器的预计算隐藏状态（注意力块中的键和值），可用于加速顺序解码。

+   `decoder_hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每层的输出）。

    解码器在每一层输出的隐藏状态加上初始嵌入输出。

+   `decoder_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(tf.Tensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型编码器在每个层的输出以及初始嵌入输出的隐藏状态。

+   `encoder_attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

模型编码器输出的基类，还包含：可以加速顺序解码的预先计算的隐藏状态。

## TFCausalLMOutput

### `class transformers.modeling_tf_outputs.TFCausalLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L347)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor`，形状为`(n,)`，*可选*, 当提供`labels`时返回，其中n是非掩码标签的数量) — 语言建模损失（用于下一个标记的预测）。

+   `logits` (`tf.Tensor`，形状为`(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(tf.Tensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

因果语言模型（或自回归）输出的基类。

## TFCausalLMOutputWithCrossAttentions

### `class transformers.modeling_tf_outputs.TFCausalLMOutputWithCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L412)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor`，形状为`(n,)`，*可选*, 当提供`labels`时返回，其中n是非掩码标签的数量) — 语言建模损失（用于下一个标记的预测）。

+   `logits` (`tf.Tensor`，形状为`(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(tf.Tensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    注意力权重在注意力SoftMax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    解码器交叉注意力层的注意力权重，在注意力SoftMax之后，用于计算交叉注意力头中的加权平均值。

+   `past_key_values` (`List[tf.Tensor]`, *可选*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码。

用于因果语言模型（或自回归）输出的基类。

## TFCausalLMOutputWithPast

### `class transformers.modeling_tf_outputs.TFCausalLMOutputWithPast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L376)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor` of shape `(n,)`, *可选*, 其中n是非掩码标签的数量，当提供`labels`时返回) — 语言建模损失（用于下一个标记预测）。

+   `logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`) — 语言建模头部的预测分数（SoftMax之前每个词汇标记的分数）。

+   `past_key_values` (`List[tf.Tensor]`, *可选*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码。

+   `hidden_states` (`tuple(tf.Tensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    每个层输出的模型隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    注意力权重在注意力SoftMax之后，用于计算自注意力头中的加权平均值。

用于因果语言模型（或自回归）输出的基类。

## TFMaskedLMOutput

### `class transformers.modeling_tf_outputs.TFMaskedLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L455)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor` of shape `(n,)`, *可选*, 其中n是非掩码标签的数量，当提供`labels`时返回) — 掩码语言建模（MLM）损失。

+   `logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`) — 语言建模头部的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(tf.Tensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

掩码语言模型输出的基类。

## TFSeq2SeqLMOutput

### `class transformers.modeling_tf_outputs.TFSeq2SeqLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L484)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor`，形状为`(n,)`，*可选*，当提供`labels`时返回) — 语言建模损失。

+   `logits` (`tf.Tensor`，形状为`(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `past_key_values` (`List[tf.Tensor]`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含解码器的预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出，一个用于每一层的输出）。

    解码器在每一层输出的隐藏状态以及初始嵌入输出。

+   `decoder_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(tf.Tensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出，一个用于每一层的输出）。

    编码器在每一层输出的隐藏状态以及初始嵌入输出。

+   `encoder_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列语言模型输出的基类。

## TFNextSentencePredictorOutput

### `class transformers.modeling_tf_outputs.TFNextSentencePredictorOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L543)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss`（形状为`(n,)`的`tf.Tensor`，*可选*，其中n是未屏蔽标签的数量，当提供`next_sentence_label`时返回）- 下一个句子预测损失。

+   `logits`（形状为`(batch_size, 2)`的`tf.Tensor`）- 下一个序列预测（分类）头的预测分数（SoftMax之前的True/False连续性分数）。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出，一个用于每一层的输出）。

    每一层模型的隐藏状态，加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

模型输出的基类，用于预测两个句子是否连续。

## TFSequenceClassifierOutput

### `class transformers.modeling_tf_outputs.TFSequenceClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L573)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss`（形状为`(batch_size,)`的`tf.Tensor`，*可选*，当提供`labels`时返回）- 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits`（形状为`(batch_size, config.num_labels)`的`tf.Tensor`）- 分类（如果`config.num_labels==1`则为回归）分数（SoftMax之前）。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出，一个用于每一层的输出）。

    每一层模型的隐藏状态，加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

句子分类模型输出的基类。

## TFSeq2SeqSequenceClassifierOutput

### `class transformers.modeling_tf_outputs.TFSeq2SeqSequenceClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L602)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss`（形状为`(1,)`的`tf.Tensor`，*可选*，当提供`label`时返回）- 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits`（形状为`(batch_size, config.num_labels)`的`tf.Tensor`）- 分类（如果`config.num_labels==1`则为回归）分数（SoftMax之前）。

+   `past_key_values`（`List[tf.Tensor]`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）- 长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含解码器的预计算隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出，一个用于每一层的输出）。

    每一层解码器的隐藏状态，加上初始嵌入输出。

+   `decoder_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

+   `encoder_last_hidden_state` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    编码器在每一层输出的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

序列到序列句子分类模型输出的基类。

## TFMultipleChoiceModelOutput

### `class transformers.modeling_tf_outputs.TFMultipleChoiceModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L753)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor`，形状为*(batch_size,)*，*可选*，当提供`labels`时返回） — 分类损失。

+   `logits` (`tf.Tensor`，形状为`(batch_size, num_choices)`) — *num_choices*是输入张量的第二维度。（参见上面的*input_ids*）。

    分类得分（SoftMax之前）。

+   `hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每一层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

多选模型输出的基类。

## TFTokenClassifierOutput

### `class transformers.modeling_tf_outputs.TFTokenClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L784)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor`，形状为`(n,)`，*可选*，其中n是未屏蔽标签的数量，当提供`labels`时返回） — 分类损失。

+   `logits` (`tf.Tensor`，形状为`(batch_size, sequence_length, config.num_labels)`) — 分类得分（SoftMax之前）。

+   `hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    在自注意力头中用于计算加权平均值的注意力权重。

用于标记分类模型输出的基类。

## TFQuestionAnsweringModelOutput

### `class transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L813)

```py
( loss: tf.Tensor | None = None start_logits: tf.Tensor = None end_logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`形状为`(batch_size, )`的`tf.Tensor`, *optional*, 当提供`start_positions`和`end_positions`时返回) — 总跨度提取损失是开始和结束位置的交叉熵之和。

+   `start_logits` (`形状为`(batch_size, sequence_length)`的`tf.Tensor`) — 跨度开始得分（SoftMax之前）。

+   `end_logits` (`形状为`(batch_size, sequence_length)`的`tf.Tensor`) — 跨度结束得分（SoftMax之前）。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    在自注意力头中用于计算加权平均值的注意力权重。

用于问答模型输出的基类。

## TFSeq2SeqQuestionAnsweringModelOutput

### `class transformers.modeling_tf_outputs.TFSeq2SeqQuestionAnsweringModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_outputs.py#L845)

```py
( loss: tf.Tensor | None = None start_logits: tf.Tensor = None end_logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`形状为`(1,)`的`tf.Tensor`, *optional*, 当提供`labels`时返回) — 总跨度提取损失是开始和结束位置的交叉熵之和。

+   `start_logits` (`形状为`(batch_size, sequence_length)`的`tf.Tensor`) — 跨度开始得分（SoftMax之前）。

+   `end_logits` (`形状为`(batch_size, sequence_length)`的`tf.Tensor`) — 跨度结束得分（SoftMax之前）。

+   `past_key_values` (`List[tf.Tensor]`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tf.Tensor`列表，每个张量形状为`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`。

    包含解码器预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    解码器在每一层输出的隐藏状态加上初始嵌入输出。

+   `decoder_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`, *optional*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(tf.Tensor)`，*optional*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入输出，一个用于每一层的输出）。

    编码器在每一层输出的隐藏状态以及初始嵌入输出。

+   `encoder_attentions` (`tuple(tf.Tensor)`，*optional*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    编码器的注意力权重，在注意力softmax后，用于计算自注意力头中的加权平均值。

用于序列到序列问答模型输出的基类。

## FlaxBaseModelOutput

### `class transformers.modeling_flax_outputs.FlaxBaseModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L22)

```py
( last_hidden_state: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列输出。

+   `hidden_states` (`tuple(jnp.ndarray)`，*optional*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`，*optional*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

模型输出的基类，具有潜在的隐藏状态和注意力。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxBaseModelOutputWithPast

### `class transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L106)

```py
( last_hidden_state: Array = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型最后一层的隐藏状态序列输出。

+   `past_key_values` (`Dict[str, jnp.ndarray]`) — 预先计算的隐藏状态（注意力块中的键和值）的字典，可用于快速自回归解码。预先计算的键和值隐藏状态的形状为*[batch_size, max_length]*。

+   `hidden_states` (`tuple(jnp.ndarray)`，*optional*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

模型输出的基类，具有潜在的隐藏状态和注意力。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxBaseModelOutputWithPooling

### `class transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L136)

```py
( last_hidden_state: Array = None pooler_output: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`）- 模型最后一层的隐藏状态序列。

+   `pooler_output`（形状为`(batch_size, hidden_size)`的`jnp.ndarray`）- 序列的第一个标记（分类标记）的最后一层隐藏状态，进一步由线性层和Tanh激活函数处理。线性层的权重是通过预训练期间的下一个句子预测（分类）目标进行训练的。

+   `hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。

模型输出的基类，还包含最后隐藏状态的池化。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

返回一个新对象，用新值替换指定的字段。

## FlaxBaseModelOutputWithPastAndCrossAttentions

### `class transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L216)

```py
( last_hidden_state: Array = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`）- 模型最后一层的隐藏状态序列。

    如果使用`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。

+   `past_key_values`（`tuple(tuple(jnp.ndarray))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）- 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，如果`config.is_encoder_decoder=True`还有2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块中的键和值，以及可选地在交叉注意力块中，如果`config.is_encoder_decoder=True`）可以使用（参见`past_key_values`输入）以加速顺序解码的基类。

+   `hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_attentions=True`和`config.add_cross_attention=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

模型输出的基类，可能还包含过去的键/值（用于加速顺序解码）。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个新对象，用新值替换指定字段。

## FlaxSeq2SeqModelOutput

### `class transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L262)

```py
( last_hidden_state: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`) — 模型解码器最后一层的隐藏状态序列。

    如果仅使用`past_key_values`，则输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。

+   `past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    解码器在每一层的隐藏状态加上初始嵌入输出。

+   `decoder_attentions` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    编码器在每一层的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

模型编码器输出的基类，还包含：预先计算的隐藏状态，可加速顺序解码。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxCausalLMOutputWithCrossAttentions

### `class transformers.modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L323)

```py
( logits: Array = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, sequence_length, config.vocab_size)`）— 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(jnp.ndarray)`, *可选的*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`, *可选的*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    自注意力头中的注意力权重在注意力softmax之后，用于计算加权平均值。

+   `cross_attentions` (`tuple(jnp.ndarray)`, *可选的*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    交叉注意力softmax之后的注意力权重，用于计算交叉注意力头中的加权平均值。

+   `past_key_values` (`tuple(tuple(jnp.ndarray))`, *可选的*，当传递`use_cache=True`或`config.use_cache=True`时返回）— 长度为`config.n_layers`的`jnp.ndarray`元组的元组，每个元组包含自注意力和交叉注意力层的缓存键、值状态。仅在`config.is_decoder = True`时相关。

    包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

因果语言模型（或自回归）输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxMaskedLMOutput

### `class transformers.modeling_flax_outputs.FlaxMaskedLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L364)

```py
( logits: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, sequence_length, config.vocab_size)`）— 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `hidden_states` (`tuple(jnp.ndarray)`, *可选的*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`, *可选的*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

掩码语言模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxSeq2SeqLMOutput

### `class transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L393)

```py
( logits: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `past_key_values` (`tuple(tuple(jnp.ndarray))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    解码器在每一层输出的隐藏状态加上初始嵌入输出。

+   `decoder_attentions` (`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    编码器在每一层输出的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列语言模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxNextSentencePredictorOutput

### `class transformers.modeling_flax_outputs.FlaxNextSentencePredictorOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L450)

```py
( logits: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, 2)`) — 下一个序列预测（分类）头的预测得分（SoftMax之前的True/False连续得分）。

+   `hidden_states` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_hidden_states=True`或者`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（嵌入输出和每一层输出各一个）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_attentions=True`或者`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    自注意力头中用于计算加权平均值的注意力权重softmax后的值。

预测两个句子是否连续的模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxSequenceClassifierOutput

### `class transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L477)

```py
( logits: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。

+   `hidden_states` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_hidden_states=True`或者`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（嵌入输出和每一层输出各一个）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_attentions=True`或者`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    自注意力头中用于计算加权平均值的注意力权重softmax后的值。

句子分类模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxSeq2SeqSequenceClassifierOutput

### `class transformers.modeling_flax_outputs.FlaxSeq2SeqSequenceClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L503)

```py
( logits: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。

+   `past_key_values` (`tuple(tuple(jnp.ndarray))`, *可选的*, 当传递`use_cache=True`或者`config.use_cache=True`时返回) — 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。

+   `decoder_hidden_states` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_hidden_states=True`或者`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（嵌入输出和每一层输出各一个）。

    解码器在每一层输出的隐藏状态以及初始嵌入输出。

+   `decoder_attentions` (`tuple(jnp.ndarray)`, *可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(jnp.ndarray)`, *可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(jnp.ndarray)`, *可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    编码器在每一层输出的隐藏状态以及初始嵌入输出。

+   `encoder_attentions` (`tuple(jnp.ndarray)`, *可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列句子分类模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“用新值替换指定字段的新对象。

## FlaxMultipleChoiceModelOutput

### `class transformers.modeling_flax_outputs.FlaxMultipleChoiceModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L560)

```py
( logits: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, num_choices)`) — *num_choices*是输入张量的第二维度。（参见上面的*input_ids*）。

    分类得分（SoftMax之前）。

+   `hidden_states` (`tuple(jnp.ndarray)`, *可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(jnp.ndarray)`, *可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。

多选模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“用新值替换指定字段的新对象。

## FlaxTokenClassifierOutput

### `class transformers.modeling_flax_outputs.FlaxTokenClassifierOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L588)

```py
( logits: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `logits` (`jnp.ndarray`，形状为`(batch_size, sequence_length, config.num_labels)`) — 分类得分（SoftMax之前）。

+   `hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions`（`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

用于标记分类模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个新对象，用新值替换指定的字段。

## FlaxQuestionAnsweringModelOutput

### `class transformers.modeling_flax_outputs.FlaxQuestionAnsweringModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L614)

```py
( start_logits: Array = None end_logits: Array = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `start_logits`（形状为`(batch_size, sequence_length)`的`jnp.ndarray`）— SoftMax之前的跨度起始分数。

+   `end_logits`（形状为`(batch_size, sequence_length)`的`jnp.ndarray`）— SoftMax之前的跨度结束分数。

+   `hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions`（`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每个层一个）。

    注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。

用于问答模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个新对象，用新值替换指定的字段。

## FlaxSeq2SeqQuestionAnsweringModelOutput

### `class transformers.modeling_flax_outputs.FlaxSeq2SeqQuestionAnsweringModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_outputs.py#L643)

```py
( start_logits: Array = None end_logits: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

参数

+   `start_logits`（形状为`(batch_size, sequence_length)`的`jnp.ndarray`）— SoftMax之前的跨度起始分数。

+   `end_logits`（形状为`(batch_size, sequence_length)`的`jnp.ndarray`）— SoftMax之前的跨度结束分数。

+   `past_key_values`（`tuple(tuple(jnp.ndarray))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）— 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，以及2个额外的形状为`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`的张量。

    包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可以用来加速顺序解码（请参见`past_key_values`输入）。

+   `decoder_hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    解码器在每个层的输出以及初始嵌入输出的隐藏状态。

+   `decoder_attentions` (`tuple(jnp.ndarray)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

+   `cross_attentions` (`tuple(jnp.ndarray)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。

+   `encoder_last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。

+   `encoder_hidden_states` (`tuple(jnp.ndarray)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。

    编码器每一层输出的隐藏状态加上初始嵌入输出。

+   `encoder_attentions` (`tuple(jnp.ndarray)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。

    编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。

用于序列到序列问答模型输出的基类。

#### `replace`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个新对象，用新值替换指定字段。
