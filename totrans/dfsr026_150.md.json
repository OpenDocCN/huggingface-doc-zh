["```py\n( vqvae: Union bert: PreTrainedModel tokenizer: PreTrainedTokenizer unet: Union scheduler: Union )\n```", "```py\n( prompt: Union height: Optional = None width: Optional = None num_inference_steps: Optional = 50 guidance_scale: Optional = 1.0 eta: Optional = 0.0 generator: Union = None latents: Optional = None output_type: Optional = 'pil' return_dict: bool = True **kwargs ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> from diffusers import DiffusionPipeline\n\n>>> # load model and scheduler\n>>> ldm = DiffusionPipeline.from_pretrained(\"CompVis/ldm-text2im-large-256\")\n\n>>> # run pipeline in inference (sample random noise and denoise)\n>>> prompt = \"A painting of a squirrel eating a burger\"\n>>> images = ldm([prompt], num_inference_steps=50, eta=0.3, guidance_scale=6).images\n\n>>> # save images\n>>> for idx, image in enumerate(images):\n...     image.save(f\"squirrel-{idx}.png\")\n```", "```py\n( vqvae: VQModel unet: UNet2DModel scheduler: Union )\n```", "```py\n( image: Union = None batch_size: Optional = 1 num_inference_steps: Optional = 100 eta: Optional = 0.0 generator: Union = None output_type: Optional = 'pil' return_dict: bool = True ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> import requests\n>>> from PIL import Image\n>>> from io import BytesIO\n>>> from diffusers import LDMSuperResolutionPipeline\n>>> import torch\n\n>>> # load model and scheduler\n>>> pipeline = LDMSuperResolutionPipeline.from_pretrained(\"CompVis/ldm-super-resolution-4x-openimages\")\n>>> pipeline = pipeline.to(\"cuda\")\n\n>>> # let's download an  image\n>>> url = (\n...     \"https://user-images.githubusercontent.com/38061659/199705896-b48e17b8-b231-47cd-a270-4ffa5a93fa3e.png\"\n... )\n>>> response = requests.get(url)\n>>> low_res_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> low_res_img = low_res_img.resize((128, 128))\n\n>>> # run pipeline in inference (sample random noise and denoise)\n>>> upscaled_image = pipeline(low_res_img, num_inference_steps=100, eta=1).images[0]\n>>> # save image\n>>> upscaled_image.save(\"ldm_generated_image.png\")\n```", "```py\n( images: Union )\n```"]