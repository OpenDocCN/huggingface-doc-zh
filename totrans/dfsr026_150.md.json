["```py\n>>> from diffusers import DiffusionPipeline\n\n>>> # load model and scheduler\n>>> ldm = DiffusionPipeline.from_pretrained(\"CompVis/ldm-text2im-large-256\")\n\n>>> # run pipeline in inference (sample random noise and denoise)\n>>> prompt = \"A painting of a squirrel eating a burger\"\n>>> images = ldm([prompt], num_inference_steps=50, eta=0.3, guidance_scale=6).images\n\n>>> # save images\n>>> for idx, image in enumerate(images):\n...     image.save(f\"squirrel-{idx}.png\")\n```", "```py\n>>> import requests\n>>> from PIL import Image\n>>> from io import BytesIO\n>>> from diffusers import LDMSuperResolutionPipeline\n>>> import torch\n\n>>> # load model and scheduler\n>>> pipeline = LDMSuperResolutionPipeline.from_pretrained(\"CompVis/ldm-super-resolution-4x-openimages\")\n>>> pipeline = pipeline.to(\"cuda\")\n\n>>> # let's download an  image\n>>> url = (\n...     \"https://user-images.githubusercontent.com/38061659/199705896-b48e17b8-b231-47cd-a270-4ffa5a93fa3e.png\"\n... )\n>>> response = requests.get(url)\n>>> low_res_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> low_res_img = low_res_img.resize((128, 128))\n\n>>> # run pipeline in inference (sample random noise and denoise)\n>>> upscaled_image = pipeline(low_res_img, num_inference_steps=100, eta=1).images[0]\n>>> # save image\n>>> upscaled_image.save(\"ldm_generated_image.png\")\n```"]