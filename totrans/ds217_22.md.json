["```py\n>>> from datasets import Dataset\n>>> df = spark.createDataFrame(\n...     data=[[1, \"Elia\"], [2, \"Teo\"], [3, \"Fang\"]],\n...     columns=[\"id\", \"name\"],\n... )\n>>> ds = Dataset.from_spark(df)\n```", "```py\n>>> from datasets import IterableDataset\n>>> df = spark.createDataFrame(\n...     data=[[1, \"Elia\"], [2, \"Teo\"], [3, \"Fang\"]],\n...     columns=[\"id\", \"name\"],\n... )\n>>> ds = IterableDataset.from_spark(df)\n>>> print(next(iter(ds)))\n{\"id\": 1, \"name\": \"Elia\"}\n```", "```py\n>>> from datasets import Dataset, Features, Image, Value\n>>> data = [(0, open(\"image.png\", \"rb\").read())]\n>>> df = spark.createDataFrame(data, \"idx: int, image: binary\")\n>>> # Also works if you have arrays\n>>> # data = [(0, np.zeros(shape=(32, 32, 3), dtype=np.int32).tolist())]\n>>> # df = spark.createDataFrame(data, \"idx: int, image: array<array<array<int>>>\")\n>>> features = Features({\"idx\": Value(\"int64\"), \"image\": Image()})\n>>> dataset = Dataset.from_spark(df, features=features)\n>>> dataset[0]\n{'idx': 0, 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>}\n```"]