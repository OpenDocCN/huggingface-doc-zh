["```py\n( prior: PriorTransformer text_encoder: CLIPTextModelWithProjection tokenizer: CLIPTokenizer scheduler: HeunDiscreteScheduler shap_e_renderer: ShapERenderer )\n```", "```py\n( prompt: str num_images_per_prompt: int = 1 num_inference_steps: int = 25 generator: Union = None latents: Optional = None guidance_scale: float = 4.0 frame_size: int = 64 output_type: Optional = 'pil' return_dict: bool = True ) \u2192 export const metadata = 'undefined';ShapEPipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from diffusers.utils import export_to_gif\n\n>>> device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n>>> repo = \"openai/shap-e\"\n>>> pipe = DiffusionPipeline.from_pretrained(repo, torch_dtype=torch.float16)\n>>> pipe = pipe.to(device)\n\n>>> guidance_scale = 15.0\n>>> prompt = \"a shark\"\n\n>>> images = pipe(\n...     prompt,\n...     guidance_scale=guidance_scale,\n...     num_inference_steps=64,\n...     frame_size=256,\n... ).images\n\n>>> gif_path = export_to_gif(images[0], \"shark_3d.gif\")\n```", "```py\n( prior: PriorTransformer image_encoder: CLIPVisionModel image_processor: CLIPImageProcessor scheduler: HeunDiscreteScheduler shap_e_renderer: ShapERenderer )\n```", "```py\n( image: Union num_images_per_prompt: int = 1 num_inference_steps: int = 25 generator: Union = None latents: Optional = None guidance_scale: float = 4.0 frame_size: int = 64 output_type: Optional = 'pil' return_dict: bool = True ) \u2192 export const metadata = 'undefined';ShapEPipelineOutput or tuple\n```", "```py\n>>> from PIL import Image\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from diffusers.utils import export_to_gif, load_image\n\n>>> device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n>>> repo = \"openai/shap-e-img2img\"\n>>> pipe = DiffusionPipeline.from_pretrained(repo, torch_dtype=torch.float16)\n>>> pipe = pipe.to(device)\n\n>>> guidance_scale = 3.0\n>>> image_url = \"https://hf.co/datasets/diffusers/docs-images/resolve/main/shap-e/corgi.png\"\n>>> image = load_image(image_url).convert(\"RGB\")\n\n>>> images = pipe(\n...     image,\n...     guidance_scale=guidance_scale,\n...     num_inference_steps=64,\n...     frame_size=256,\n... ).images\n\n>>> gif_path = export_to_gif(images[0], \"corgi_3d.gif\")\n```", "```py\n( images: Union )\n```"]