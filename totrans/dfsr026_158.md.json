["```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from diffusers.utils import export_to_gif\n\n>>> device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n>>> repo = \"openai/shap-e\"\n>>> pipe = DiffusionPipeline.from_pretrained(repo, torch_dtype=torch.float16)\n>>> pipe = pipe.to(device)\n\n>>> guidance_scale = 15.0\n>>> prompt = \"a shark\"\n\n>>> images = pipe(\n...     prompt,\n...     guidance_scale=guidance_scale,\n...     num_inference_steps=64,\n...     frame_size=256,\n... ).images\n\n>>> gif_path = export_to_gif(images[0], \"shark_3d.gif\")\n```", "```py\n>>> from PIL import Image\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from diffusers.utils import export_to_gif, load_image\n\n>>> device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n>>> repo = \"openai/shap-e-img2img\"\n>>> pipe = DiffusionPipeline.from_pretrained(repo, torch_dtype=torch.float16)\n>>> pipe = pipe.to(device)\n\n>>> guidance_scale = 3.0\n>>> image_url = \"https://hf.co/datasets/diffusers/docs-images/resolve/main/shap-e/corgi.png\"\n>>> image = load_image(image_url).convert(\"RGB\")\n\n>>> images = pipe(\n...     image,\n...     guidance_scale=guidance_scale,\n...     num_inference_steps=64,\n...     frame_size=256,\n... ).images\n\n>>> gif_path = export_to_gif(images[0], \"corgi_3d.gif\")\n```"]