# 从Jupyter环境启动多GPU训练

> 原始文本：[https://huggingface.co/docs/accelerate/basic_tutorials/notebook](https://huggingface.co/docs/accelerate/basic_tutorials/notebook)

本教程将教您如何使用🤗 Accelerate从Jupyter Notebook在分布式系统上微调计算机视觉模型。您还将学习如何设置确保环境正确配置、数据已正确准备以及最终如何启动训练所需的一些要求。

本教程也可作为Jupyter Notebook [在这里](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_cv_example.ipynb)查看

## 配置环境

在执行任何训练之前，系统中必须存在一个🤗 Accelerate配置文件。通常可以通过在终端中运行以下命令并回答提示来完成：

```py
accelerate config
```

但是，如果通用默认值是可以接受的，并且您*不*在TPU上运行，🤗Accelerate有一个实用程序，可以通过[utils.write_basic_config()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.commands.config.default.write_basic_config)快速将您的GPU配置写入配置文件。

以下代码将在写入配置后重新启动Jupyter，因为调用了CUDA代码来执行此操作。

在多GPU系统上，CUDA不能被初始化多次。在笔记本中进行调试并调用CUDA是可以的，但为了最终训练，需要执行完全清理和重新启动。

```py
import os
from accelerate.utils import write_basic_config

write_basic_config()  # Write a config file
os._exit(00)  # Restart the notebook
```

## 准备数据集和模型

接下来，您应该准备您的数据集。如前所述，在准备`DataLoaders`和模型时应格外小心，以确保**任何**东西都不会放在*任何* GPU上。

如果您这样做，建议将该特定代码放入一个函数中，并从笔记本启动器界面中调用该函数，稍后将显示该界面。

确保根据[这里](https://github.com/huggingface/accelerate/tree/main/examples#simple-vision-example)的说明下载数据集

```py
import os, re, torch, PIL
import numpy as np

from torch.optim.lr_scheduler import OneCycleLR
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import Compose, RandomResizedCrop, Resize, ToTensor

from accelerate import Accelerator
from accelerate.utils import set_seed
from timm import create_model
```

首先，您需要创建一个函数，根据文件名提取类名：

```py
import os

data_dir = "../../images"
fnames = os.listdir(data_dir)
fname = fnames[0]
print(fname)
```

```py
beagle_32.jpg
```

在这种情况下，标签是`beagle`。使用正则表达式可以从文件名中提取标签：

```py
import re

def extract_label(fname):
    stem = fname.split(os.path.sep)[-1]
    return re.search(r"^(.*)_\d+\.jpg$", stem).groups()[0]
```

```py
extract_label(fname)
```

您可以看到它正确返回了我们文件的正确名称：

```py
"beagle"
```

接下来应该制作一个`Dataset`类来处理获取图像和标签：

```py
class PetsDataset(Dataset):
    def __init__(self, file_names, image_transform=None, label_to_id=None):
        self.file_names = file_names
        self.image_transform = image_transform
        self.label_to_id = label_to_id

    def __len__(self):
        return len(self.file_names)

    def __getitem__(self, idx):
        fname = self.file_names[idx]
        raw_image = PIL.Image.open(fname)
        image = raw_image.convert("RGB")
        if self.image_transform is not None:
            image = self.image_transform(image)
        label = extract_label(fname)
        if self.label_to_id is not None:
            label = self.label_to_id[label]
        return {"image": image, "label": label}
```

现在开始构建数据集。在训练函数之外，您可以找到并声明所有的文件名和标签，并将它们用作启动函数内的参考：

```py
fnames = [os.path.join("../../images", fname) for fname in fnames if fname.endswith(".jpg")]
```

接下来收集所有的标签：

```py
all_labels = [extract_label(fname) for fname in fnames]
id_to_label = list(set(all_labels))
id_to_label.sort()
label_to_id = {lbl: i for i, lbl in enumerate(id_to_label)}
```

接下来，您应该制作一个`get_dataloaders`函数，该函数将为您返回构建的数据加载器。如前所述，如果在构建`DataLoaders`时数据会自动发送到GPU或TPU设备，则必须使用此方法构建它们。

```py
def get_dataloaders(batch_size: int = 64):
    "Builds a set of dataloaders with a batch_size"
    random_perm = np.random.permutation(len(fnames))
    cut = int(0.8 * len(fnames))
    train_split = random_perm[:cut]
    eval_split = random_perm[cut:]

    # For training a simple RandomResizedCrop will be used
    train_tfm = Compose([RandomResizedCrop((224, 224), scale=(0.5, 1.0)), ToTensor()])
    train_dataset = PetsDataset([fnames[i] for i in train_split], image_transform=train_tfm, label_to_id=label_to_id)

    # For evaluation a deterministic Resize will be used
    eval_tfm = Compose([Resize((224, 224)), ToTensor()])
    eval_dataset = PetsDataset([fnames[i] for i in eval_split], image_transform=eval_tfm, label_to_id=label_to_id)

    # Instantiate dataloaders
    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=4)
    eval_dataloader = DataLoader(eval_dataset, shuffle=False, batch_size=batch_size * 2, num_workers=4)
    return train_dataloader, eval_dataloader
```

最后，您应该导入稍后要使用的调度程序：

```py
from torch.optim.lr_scheduler import CosineAnnealingLR
```

## 编写训练函数

现在可以构建训练循环。[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)通过传入一个要调用的函数来工作，该函数将在分布式系统中运行。

这是一个用于动物分类问题的基本训练循环：

代码已经分割开来，以便对每个部分进行解释。可以复制并粘贴的完整版本将在最后提供

```py
def training_loop(mixed_precision="fp16", seed: int = 42, batch_size: int = 64):
    set_seed(seed)
    accelerator = Accelerator(mixed_precision=mixed_precision)
```

首先，您应该尽早在训练循环中设置种子并创建一个[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)对象。

如果在TPU上训练，您的训练循环应将模型作为参数传入，并且应在训练循环函数之外实例化。请参阅[TPU最佳实践](../concept_guides/training_tpu)以了解原因

接下来，您应该构建您的数据加载器并创建您的模型：

```py
    train_dataloader, eval_dataloader = get_dataloaders(batch_size)
    model = create_model("resnet50d", pretrained=True, num_classes=len(label_to_id))
```

在这里构建模型，以便种子也控制新的权重初始化

在此示例中进行迁移学习时，模型的编码器开始时是冻结的，因此模型的头部只能最初进行训练：

```py
    for param in model.parameters():
        param.requires_grad = False
    for param in model.get_classifier().parameters():
        param.requires_grad = True
```

对图像批次进行归一化将使训练速度稍快：

```py
    mean = torch.tensor(model.default_cfg["mean"])[None, :, None, None]
    std = torch.tensor(model.default_cfg["std"])[None, :, None, None]
```

为了使这些常量在活动设备上可用，您应该将其设置为加速器的设备：

```py
    mean = mean.to(accelerator.device)
    std = std.to(accelerator.device)
```

接下来实例化用于训练的其余PyTorch类：

```py
    optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-2 / 25)
    lr_scheduler = OneCycleLR(optimizer=optimizer, max_lr=3e-2, epochs=5, steps_per_epoch=len(train_dataloader))
```

在将所有内容传递给[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)之前。

没有特定的顺序需要记住，您只需要按照与prepare方法中给出的相同顺序解包对象。

```py
    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(
        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler
    )
```

现在训练模型：

```py
    for epoch in range(5):
        model.train()
        for batch in train_dataloader:
            inputs = (batch["image"] - mean) / std
            outputs = model(inputs)
            loss = torch.nn.functional.cross_entropy(outputs, batch["label"])
            accelerator.backward(loss)
            optimizer.step()
            lr_scheduler.step()
            optimizer.zero_grad()
```

评估循环与训练循环相比会稍有不同。传递的元素数量以及每个批次的总体准确率将添加到两个常量中：

```py
        model.eval()
        accurate = 0
        num_elems = 0
```

接下来是您标准PyTorch循环的其余部分：

```py
        for batch in eval_dataloader:
            inputs = (batch["image"] - mean) / std
            with torch.no_grad():
                outputs = model(inputs)
            predictions = outputs.argmax(dim=-1)
```

最后是最后一个主要区别。

在进行分布式评估时，需要通过[gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)传递预测和标签，以便所有数据都在当前设备上可用，并且可以实现正确计算的指标：

```py
            accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch["label"])
            num_elems += accurate_preds.shape[0]
            accurate += accurate_preds.long().sum()
```

现在您只需要计算此问题的实际指标，并可以在主进程上使用[print()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.print)打印它：

```py
        eval_metric = accurate.item() / num_elems
        accelerator.print(f"epoch {epoch}: {100 * eval_metric:.2f}")
```

下面提供了完整版本的训练循环：

```py
def training_loop(mixed_precision="fp16", seed: int = 42, batch_size: int = 64):
    set_seed(seed)
    # Initialize accelerator
    accelerator = Accelerator(mixed_precision=mixed_precision)
    # Build dataloaders
    train_dataloader, eval_dataloader = get_dataloaders(batch_size)

    # Instantiate the model (you build the model here so that the seed also controls new weight initaliziations)
    model = create_model("resnet50d", pretrained=True, num_classes=len(label_to_id))

    # Freeze the base model
    for param in model.parameters():
        param.requires_grad = False
    for param in model.get_classifier().parameters():
        param.requires_grad = True

    # You can normalize the batches of images to be a bit faster
    mean = torch.tensor(model.default_cfg["mean"])[None, :, None, None]
    std = torch.tensor(model.default_cfg["std"])[None, :, None, None]

    # To make these constants available on the active device, set it to the accelerator device
    mean = mean.to(accelerator.device)
    std = std.to(accelerator.device)

    # Instantiate the optimizer
    optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-2 / 25)

    # Instantiate the learning rate scheduler
    lr_scheduler = OneCycleLR(optimizer=optimizer, max_lr=3e-2, epochs=5, steps_per_epoch=len(train_dataloader))

    # Prepare everything
    # There is no specific order to remember, you just need to unpack the objects in the same order you gave them to the
    # prepare method.
    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(
        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler
    )

    # Now you train the model
    for epoch in range(5):
        model.train()
        for batch in train_dataloader:
            inputs = (batch["image"] - mean) / std
            outputs = model(inputs)
            loss = torch.nn.functional.cross_entropy(outputs, batch["label"])
            accelerator.backward(loss)
            optimizer.step()
            lr_scheduler.step()
            optimizer.zero_grad()

        model.eval()
        accurate = 0
        num_elems = 0
        for batch in eval_dataloader:
            inputs = (batch["image"] - mean) / std
            with torch.no_grad():
                outputs = model(inputs)
            predictions = outputs.argmax(dim=-1)
            accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch["label"])
            num_elems += accurate_preds.shape[0]
            accurate += accurate_preds.long().sum()

        eval_metric = accurate.item() / num_elems
        # Use accelerator.print to print only on the main process.
        accelerator.print(f"epoch {epoch}: {100 * eval_metric:.2f}")
```

## 使用notebook_launcher

剩下的就是使用[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)。

您传入函数、参数（作为元组）以及要训练的进程数。（有关更多信息，请参阅[文档](../package_reference/launchers)）

```py
from accelerate import notebook_launcher
```

```py
args = ("fp16", 42, 64)
notebook_launcher(training_loop, args, num_processes=2)
```

在多个节点上运行时，您需要在每个节点设置一个Jupyter会话，并同时运行启动单元格。

对于包含每台计算机有8个GPU的2个节点（计算机）的环境，主计算机的IP地址为“172.31.43.8”，会是这样的：

```py
notebook_launcher(training_loop, args, master_addr="172.31.43.8", node_rank=0, num_nodes=2, num_processes=8)
```

在另一台机器上的第二个Jupyter会话中：

注意`node_rank`已更改

```py
notebook_launcher(training_loop, args, master_addr="172.31.43.8", node_rank=1, num_nodes=2, num_processes=8)
```

在TPU上运行时，会是这样的：

```py
model = create_model("resnet50d", pretrained=True, num_classes=len(label_to_id))

args = (model, "fp16", 42, 64)
notebook_launcher(training_loop, args, num_processes=8)
```

在运行时，它将打印进度，并说明您运行在多少设备上。本教程使用了两个GPU：

```py
Launching training on 2 GPUs.
epoch 0: 88.12
epoch 1: 91.73
epoch 2: 92.58
epoch 3: 93.90
epoch 4: 94.71
```

就是这样！

## 调试

在运行`notebook_launcher`时常见的问题是收到CUDA已经初始化的问题。这通常源于笔记本中的导入或先前代码调用PyTorch的`torch.cuda`子库。为了帮助缩小问题范围，您可以在环境中使用`ACCELERATE_DEBUG_MODE=yes`启动`notebook_launcher`，并在生成时进行额外检查，以确保可以创建常规进程并无问题地利用CUDA。（您的CUDA代码仍然可以在之后运行）。

## 结论

本笔记本展示了如何从Jupyter Notebook内执行分布式训练。请记住一些关键要点：

+   确保保存使用CUDA的任何代码（或CUDA导入）以传递给[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)的函数。

+   将`num_processes`设置为用于训练的设备数量（例如GPU、CPU、TPU等的数量）

+   如果使用TPU，请在训练循环函数之外声明您的模型
