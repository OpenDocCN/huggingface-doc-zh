# 目标检测

> 原始文本：[https://huggingface.co/docs/datasets/object_detection](https://huggingface.co/docs/datasets/object_detection)

目标检测模型识别图像中的某些内容，目标检测数据集用于自动驾驶等应用以及检测自然灾害如野火。本指南将向您展示如何对目标检测数据集应用变换，遵循来自[Albumentations](https://albumentations.ai/docs/)的[教程](https://albumentations.ai/docs/examples/example_bboxes/)。

要运行这些示例，请确保您已安装了最新版本的`albumentations`和`cv2`：

```py
pip install -U albumentations opencv-python
```

在这个例子中，您将使用[`cppe-5`](https://huggingface.co/datasets/cppe-5)数据集来识别COVID-19大流行背景下的医疗个人防护装备（PPE）。

加载数据集并查看一个示例：

```py
>>> from datasets import load_dataset

>>> ds = load_dataset("cppe-5")
>>> example = ds['train'][0]
>>> example
{'height': 663,
 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=943x663 at 0x7FC3DC756250>,
 'image_id': 15,
 'objects': {'area': [3796, 1596, 152768, 81002],
  'bbox': [[302.0, 109.0, 73.0, 52.0],
   [810.0, 100.0, 57.0, 28.0],
   [160.0, 31.0, 248.0, 616.0],
   [741.0, 68.0, 202.0, 401.0]],
  'category': [4, 4, 0, 0],
  'id': [114, 115, 116, 117]},
 'width': 943}
```

数据集具有以下字段：

+   `image`: 包含图像的PIL.Image.Image对象。

+   `image_id`: 图像ID。

+   `height`: 图像高度。

+   `width`: 图像宽度。

+   `objects`: 包含图像中对象的边界框元数据的字典：

    +   `id`: 注释ID。

    +   `area`: 边界框的面积。

    +   `bbox`: 物体的边界框（以[coco](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/#coco)格式）。

    +   `category`: 物体的类别，可能的值包括`Coverall (0)`、`Face_Shield (1)`、`Gloves (2)`、`Goggles (3)`和`Mask (4)`。

您可以使用一些内部的torch工具在图像上可视化`bboxes`。为此，您需要引用与类别ID相关联的[ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel)特征，以便查找字符串标签：

```py
>>> import torch
>>> from torchvision.ops import box_convert
>>> from torchvision.utils import draw_bounding_boxes
>>> from torchvision.transforms.functional import pil_to_tensor, to_pil_image

>>> categories = ds['train'].features['objects'].feature['category']

>>> boxes_xywh = torch.tensor(example['objects']['bbox'])
>>> boxes_xyxy = box_convert(boxes_xywh, 'xywh', 'xyxy')
>>> labels = [categories.int2str(x) for x in example['objects']['category']]
>>> to_pil_image(
...     draw_bounding_boxes(
...         pil_to_tensor(example['image']),
...         boxes_xyxy,
...         colors="red",
...         labels=labels,
...     )
... )
```

![](../Images/a9d40d74ee60f02e6a49d5f578270811.png)

使用`albumentations`，您可以应用会影响图像的变换，同时也会相应地更新`bboxes`。在这种情况下，图像被调整大小为(480, 480)，水平翻转并变亮。

```py
>>> import albumentations
>>> import numpy as np

>>> transform = albumentations.Compose([
...     albumentations.Resize(480, 480),
...     albumentations.HorizontalFlip(p=1.0),
...     albumentations.RandomBrightnessContrast(p=1.0),
... ], bbox_params=albumentations.BboxParams(format='coco',  label_fields=['category']))

>>> image = np.array(example['image'])
>>> out = transform(
...     image=image,
...     bboxes=example['objects']['bbox'],
...     category=example['objects']['category'],
... )
```

现在当您可视化结果时，图像应该被翻转，但`bboxes`应该仍然在正确的位置。

```py
>>> image = torch.tensor(out['image']).permute(2, 0, 1)
>>> boxes_xywh = torch.stack([torch.tensor(x) for x in out['bboxes']])
>>> boxes_xyxy = box_convert(boxes_xywh, 'xywh', 'xyxy')
>>> labels = [categories.int2str(x) for x in out['category']]
>>> to_pil_image(
...     draw_bounding_boxes(
...         image,
...         boxes_xyxy,
...         colors='red',
...         labels=labels
...     )
... )
```

![](../Images/3ae1b1880287c632536e2bedf5d6330c.png)

创建一个函数来将变换应用到一批示例中：

```py
>>> def transforms(examples):
...     images, bboxes, categories = [], [], []
...     for image, objects in zip(examples['image'], examples['objects']):
...         image = np.array(image.convert("RGB"))
...         out = transform(
...             image=image,
...             bboxes=objects['bbox'],
...             category=objects['category']
...         )
...         images.append(torch.tensor(out['image']).permute(2, 0, 1))
...         bboxes.append(torch.tensor(out['bboxes']))
...         categories.append(out['category'])
...     return {'image': images, 'bbox': bboxes, 'category': categories}
```

使用[set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)函数即时应用变换，这样可以节省磁盘空间。数据增强的随机性可能会在访问相同示例两次时返回不同的图像。在训练模型多个时期时特别有用。

```py
>>> ds['train'].set_transform(transforms)
```

您可以通过可视化第10个示例来验证变换是否有效：

```py
>>> example = ds['train'][10]
>>> to_pil_image(
...     draw_bounding_boxes(
...         example['image'],
...         box_convert(example['bbox'], 'xywh', 'xyxy'),
...         colors='red',
...         labels=[categories.int2str(x) for x in example['category']]
...     )
... )
```

![](../Images/42946c738ac9cdd770f982346f8f9290.png)

现在您知道如何处理用于目标检测的数据集，请学习[如何训练目标检测模型](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/YOLOS/Fine_tuning_YOLOS_for_object_detection_on_custom_dataset_(balloon).ipynb)并将其用于推断。
