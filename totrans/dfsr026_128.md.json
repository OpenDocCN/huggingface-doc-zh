["```py\n>>> import torch\n>>> from diffusers import AmusedPipeline\n\n>>> pipe = AmusedPipeline.from_pretrained(\n...     \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> image = pipe(prompt).images[0]\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n>>> import torch\n>>> from diffusers import AmusedImg2ImgPipeline\n>>> from diffusers.utils import load_image\n\n>>> pipe = AmusedImg2ImgPipeline.from_pretrained(\n...     \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"winter mountains\"\n>>> input_image = (\n...     load_image(\n...         \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains.jpg\"\n...     )\n...     .resize((512, 512))\n...     .convert(\"RGB\")\n... )\n>>> image = pipe(prompt, input_image).images[0]\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n>>> import torch\n>>> from diffusers import AmusedInpaintPipeline\n>>> from diffusers.utils import load_image\n\n>>> pipe = AmusedInpaintPipeline.from_pretrained(\n...     \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"fall mountains\"\n>>> input_image = (\n...     load_image(\n...         \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains_1.jpg\"\n...     )\n...     .resize((512, 512))\n...     .convert(\"RGB\")\n... )\n>>> mask = (\n...     load_image(\n...         \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains_1_mask.png\"\n...     )\n...     .resize((512, 512))\n...     .convert(\"L\")\n... )\n>>> pipe(prompt, input_image, mask).images[0].save(\"out.png\")\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```"]