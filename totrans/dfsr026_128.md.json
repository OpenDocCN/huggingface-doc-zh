["```py\n( vqvae: VQModel tokenizer: CLIPTokenizer text_encoder: CLIPTextModelWithProjection transformer: UVit2DModel scheduler: AmusedScheduler )\n```", "```py\n( prompt: Union = None height: Optional = None width: Optional = None num_inference_steps: int = 12 guidance_scale: float = 10.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 generator: Optional = None latents: Optional = None prompt_embeds: Optional = None encoder_hidden_states: Optional = None negative_prompt_embeds: Optional = None negative_encoder_hidden_states: Optional = None output_type = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None micro_conditioning_aesthetic_score: int = 6 micro_conditioning_crop_coord: Tuple = (0, 0) temperature: Union = (2, 0) ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import AmusedPipeline\n\n>>> pipe = AmusedPipeline.from_pretrained(\n...     \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> image = pipe(prompt).images[0]\n```", "```py\n( attention_op: Optional = None )\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n( )\n```", "```py\n( vqvae: VQModel tokenizer: CLIPTokenizer text_encoder: CLIPTextModelWithProjection transformer: UVit2DModel scheduler: AmusedScheduler )\n```", "```py\n( prompt: Union = None image: Union = None strength: float = 0.5 num_inference_steps: int = 12 guidance_scale: float = 10.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 generator: Optional = None prompt_embeds: Optional = None encoder_hidden_states: Optional = None negative_prompt_embeds: Optional = None negative_encoder_hidden_states: Optional = None output_type = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None micro_conditioning_aesthetic_score: int = 6 micro_conditioning_crop_coord: Tuple = (0, 0) temperature: Union = (2, 0) ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import AmusedImg2ImgPipeline\n>>> from diffusers.utils import load_image\n\n>>> pipe = AmusedImg2ImgPipeline.from_pretrained(\n...     \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"winter mountains\"\n>>> input_image = (\n...     load_image(\n...         \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains.jpg\"\n...     )\n...     .resize((512, 512))\n...     .convert(\"RGB\")\n... )\n>>> image = pipe(prompt, input_image).images[0]\n```", "```py\n( attention_op: Optional = None )\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n( )\n```", "```py\n( vqvae: VQModel tokenizer: CLIPTokenizer text_encoder: CLIPTextModelWithProjection transformer: UVit2DModel scheduler: AmusedScheduler )\n```", "```py\n( prompt: Union = None image: Union = None mask_image: Union = None strength: float = 1.0 num_inference_steps: int = 12 guidance_scale: float = 10.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 generator: Optional = None prompt_embeds: Optional = None encoder_hidden_states: Optional = None negative_prompt_embeds: Optional = None negative_encoder_hidden_states: Optional = None output_type = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None micro_conditioning_aesthetic_score: int = 6 micro_conditioning_crop_coord: Tuple = (0, 0) temperature: Union = (2, 0) ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import AmusedInpaintPipeline\n>>> from diffusers.utils import load_image\n\n>>> pipe = AmusedInpaintPipeline.from_pretrained(\n...     \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"fall mountains\"\n>>> input_image = (\n...     load_image(\n...         \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains_1.jpg\"\n...     )\n...     .resize((512, 512))\n...     .convert(\"RGB\")\n... )\n>>> mask = (\n...     load_image(\n...         \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains_1_mask.png\"\n...     )\n...     .resize((512, 512))\n...     .convert(\"L\")\n... )\n>>> pipe(prompt, input_image, mask).images[0].save(\"out.png\")\n```", "```py\n( attention_op: Optional = None )\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n( )\n```"]