# Paint by Example

> 原始文本：[`huggingface.co/docs/diffusers/api/pipelines/paint_by_example`](https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example)

[Paint by Example: 基于示例的图像编辑与扩散模型](https://huggingface.co/papers/2211.13227)由 Binxin Yang、Shuyang Gu、Bo Zhang、Ting Zhang、Xuejin Chen、Xiaoyan Sun、Dong Chen、Fang Wen 撰写。

该论文的摘要如下：

*最近，语言引导的图像编辑取得了巨大成功。在本文中，我们首次研究了示例引导的图像编辑，以实现更精确的控制。我们通过利用自监督训练来解开和重新组织源图像和示例图像来实现这一目标。然而，朴素的方法会导致明显的融合伪影。我们仔细分析了这一点，并提出了信息瓶颈和强大的增强，以避免直接复制和粘贴示例图像的平凡解决方案。同时，为了确保编辑过程的可控性，我们为示例图像设计了任意形状的蒙版，并利用无分类器的指导来增加与示例图像的相似性。整个框架涉及扩散模型的单向传播，没有任何迭代优化。我们证明了我们的方法取得了令人印象深刻的性能，并实现了对野外图像的可控编辑，具有高保真度。*

原始代码库可在[Fantasy-Studio/Paint-by-Example](https://github.com/Fantasy-Studio/Paint-by-Example)找到，并且您可以在[演示](https://huggingface.co/spaces/Fantasy-Studio/Paint-by-Example)中尝试它。

## 提示

Paint by Example 由官方[Fantasy-Studio/Paint-by-Example](https://huggingface.co/Fantasy-Studio/Paint-by-Example)检查点支持。该检查点从[CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)开始，用于修复部分遮罩图像，条件是示例和参考图像。

请务必查看调度程序指南以了解如何探索调度程序速度和质量之间的权衡，并查看在多个管道中重用组件部分，以了解如何有效地将相同组件加载到多个管道中。

## PaintByExamplePipeline

### `class diffusers.PaintByExamplePipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L151)

```py
( vae: AutoencoderKL image_encoder: PaintByExampleImageEncoder unet: UNet2DConditionModel scheduler: Union safety_checker: StableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor requires_safety_checker: bool = False )
```

参数

+   `vae`（AutoencoderKL、LMSDiscreteScheduler 或 PNDMScheduler 之一。

+   `safety_checker` (`StableDiffusionSafetyChecker`) — 用于估计生成图像是否可能被视为具有冒犯性或有害的分类模块。请参考 [模型卡片](https://huggingface.co/runwayml/stable-diffusion-v1-5) 以获取有关模型潜在危害的更多详细信息。

+   `feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)) — 用于从生成的图像中提取特征的 `CLIPImageProcessor`；作为 `safety_checker` 的输入。

🧪 这是一个实验性功能！

使用 Stable Diffusion 进行图像引导修复的流水线。

该模型继承自 DiffusionPipeline。查看超类文档以获取所有流水线实现的通用方法（下载、保存、在特定设备上运行等）。

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L388)

```py
( example_image: Union image: Union mask_image: Union height: Optional = None width: Optional = None num_inference_steps: int = 50 guidance_scale: float = 5.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 ) → export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple
```

参数

+   `example_image` (`torch.FloatTensor` 或 `PIL.Image.Image` 或 `List[PIL.Image.Image]`) — 用于指导图像生成的示例图像。

+   `image` (`torch.FloatTensor` 或 `PIL.Image.Image` 或 `List[PIL.Image.Image]`) — 表示要修复的图像批次的图像或张量（图像的部分被 `mask_image` 掩盖，根据 `prompt` 重新绘制）。

+   `mask_image` (`torch.FloatTensor` 或 `PIL.Image.Image` 或 `List[PIL.Image.Image]`) — 代表要掩盖 `image` 的图像批次的图像或张量。掩盖中的白色像素被重新绘制，而黑色像素被保留。如果 `mask_image` 是 PIL 图像，则在使用之前将其转换为单通道（亮度）。如果是张量，则应该包含一个颜色通道（L）而不是 3，因此预期形状将是 `(B, H, W, 1)`。

+   `height` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`) — 生成图像的像素高度。

+   `width` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`) — 生成图像的像素宽度。

+   `num_inference_steps` (`int`, *可选*, 默认为 50) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `guidance_scale` (`float`, *可选*, 默认为 7.5) — 更高的引导比例值鼓励模型生成与文本 `prompt` 密切相关的图像，但会降低图像质量。当 `guidance_scale > 1` 时启用引导比例。

+   `negative_prompt` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成中不包括的提示。如果未定义，则需要传递 `negative_prompt_embeds`。在不使用引导时（`guidance_scale < 1`）将被忽略。

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。

+   `eta` (`float`, *可选*, 默认为 0.0) — 对应于 [DDIM](https://arxiv.org/abs/2010.02502) 论文中的参数 eta (η)。仅适用于 DDIMScheduler，在其他调度程序中将被忽略。

+   `generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 用于使生成过程确定性的 [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。

+   `latents` (`torch.FloatTensor`, *可选*) — 从高斯分布中采样的预生成嘈杂潜变量，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则通过使用提供的随机 `generator` 进行采样生成潜变量张量。

+   `output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。选择 `PIL.Image` 或 `np.array` 之间的一个。

+   `return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 StableDiffusionPipelineOutput 而不是普通元组。

+   `callback` (`Callable`, *可选*) — 在推断过程中每 `callback_steps` 步调用的函数。该函数使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *可选*, 默认为 1) — 调用 `callback` 函数的频率。如果未指定，则在每一步调用回调。

返回

StableDiffusionPipelineOutput 或 `tuple`

如果 `return_dict` 为 `True`，则返回 StableDiffusionPipelineOutput，否则返回一个 `tuple`，其中第一个元素是生成的图像列表，第二个元素是一个列表，指示相应生成的图像是否包含“不安全内容”（nsfw）。

将管道调用函数用于生成。

示例：

```py
>>> import PIL
>>> import requests
>>> import torch
>>> from io import BytesIO
>>> from diffusers import PaintByExamplePipeline

>>> def download_image(url):
...     response = requests.get(url)
...     return PIL.Image.open(BytesIO(response.content)).convert("RGB")

>>> img_url = (
...     "https://raw.githubusercontent.com/Fantasy-Studio/Paint-by-Example/main/examples/image/example_1.png"
... )
>>> mask_url = (
...     "https://raw.githubusercontent.com/Fantasy-Studio/Paint-by-Example/main/examples/mask/example_1.png"
... )
>>> example_url = "https://raw.githubusercontent.com/Fantasy-Studio/Paint-by-Example/main/examples/reference/example_1.jpg"

>>> init_image = download_image(img_url).resize((512, 512))
>>> mask_image = download_image(mask_url).resize((512, 512))
>>> example_image = download_image(example_url).resize((512, 512))

>>> pipe = PaintByExamplePipeline.from_pretrained(
...     "Fantasy-Studio/Paint-by-Example",
...     torch_dtype=torch.float16,
... )
>>> pipe = pipe.to("cuda")

>>> image = pipe(image=init_image, mask_image=mask_image, example_image=example_image).images[0]
>>> image
```

## StableDiffusionPipelineOutput

### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)

```py
( images: Union nsfw_content_detected: Optional )
```

参数

+   `images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为 `batch_size` 的去噪 PIL 图像列表或形状为 `(batch_size, height, width, num_channels)` 的 NumPy 数组。

+   `nsfw_content_detected` (`List[bool]`) — 列表，指示相应生成的图像是否包含“不安全内容”（nsfw）或如果无法执行安全检查，则为 `None`。

稳定扩散管道的输出类。
