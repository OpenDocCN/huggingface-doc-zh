# 🤗 Accelerate的内部机制

> 原文链接：[https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism](https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism)

在内部，🤗 Accelerate首先分析启动脚本的环境，以确定使用了哪种类型的分布式设置，有多少个不同的进程以及当前脚本在哪个进程中。所有这些信息都存储在`~AcceleratorState`中。

这个类在您第一次实例化[~Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)时初始化，以及执行任何特定于您的分布式设置需要的初始化。然后，它的状态通过所有[AcceleratorState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.state.AcceleratorState)实例唯一共享。（也可以使用[PartialState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.PartialState)来完成相同的操作，它是一个更简化的版本）

然后，在调用[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)时，库：

+   将您的模型包装在适用于分布式设置的容器中，

+   将您的优化器包装在[AcceleratedOptimizer](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.optimizer.AcceleratedOptimizer)中，

+   将您的调度程序包装在[AcceleratedScheduler](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.scheduler.AcceleratedScheduler)中

+   在[DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)或[DataLoaderDispatcher](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderDispatcher)中创建您的数据加载器的新版本

虽然模型、优化器和调度程序只是简单的包装器，但数据加载器是重新创建的。这主要是因为PyTorch不允许用户在创建后更改数据加载器的`batch_sampler`，而库通过将`batch_sampler`更改为每隔其他`num_processes`批次（如果启用）来处理数据在进程之间的分片。

[DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)子类`DataLoader`以添加以下功能：

+   它在每次新迭代时同步所有进程的适当随机数生成器，以确保任何随机化（如洗牌）在所有进程中都以完全相同的方式进行。

+   在产生批次之前将批次放在正确的设备上（除非您选择了`device_placement=True`）。

[DataLoaderDispatcher](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderDispatcher)子类与[DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)不同之处在于，当通过`DataLoader`迭代时，数据都是从进程0开始，然后再分割并发送到每个进程，而不是在数据集级别发生。

默认情况下，随机数生成器同步将同步：

+   给定采样器（如PyTorch的`RandomSampler`）的`generator`属性，适用于PyTorch >= 1.6

+   PyTorch <=1.5.1中的主随机数生成器

您可以通过主[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)的`rng_types`参数选择要与之同步的随机数生成器。在PyTorch >= 1.6中，建议依赖于本地`generator`，以避免在所有进程中设置相同的种子。

主要torch（或CUDA或XLA）随机数生成器的同步将影响数据集中可能存在的任何其他随机现象（如随机数据增强），因为所有进程将从torch随机模块中获得相同的随机数（因此如果由torch控制，则将应用相同的随机数据增强）。

您自定义采样器、批量采样器或可迭代数据集的随机化部分应该使用本地的`torch.Generator`对象来完成（在PyTorch >= 1.6中），可以参考传统的`RandomSampler`作为示例。

有关内部详细信息，请参阅[内部页面](package_reference/torch_wrappers)。
