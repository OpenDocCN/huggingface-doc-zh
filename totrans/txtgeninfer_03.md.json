["```py\nmodel=tiiuae/falcon-7b-instruct\nvolume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run\n\ndocker run --gpus all --shm-size 1g -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.4 --model-id $model\n```", "```py\ndocker run --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --device=/dev/kfd --device=/dev/dri --group-add video --ipc=host --shm-size 1g -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.4-rocm --model-id $model\n```", "```py\nimport requests\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n}\n\ndata = {\n    'inputs': 'What is Deep Learning?',\n    'parameters': {\n        'max_new_tokens': 20,\n    },\n}\n\nresponse = requests.post('http://127.0.0.1:8080/generate', headers=headers, json=data)\nprint(response.json())\n# {'generated_text': '\\n\\nDeep Learning is a subset of Machine Learning that is concerned with the development of algorithms that can'}\n```", "```py\ndocker run ghcr.io/huggingface/text-generation-inference:1.4 --help\n```"]