- en: TrOCR
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TrOCR
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/trocr](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/trocr)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/trocr](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/trocr)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The TrOCR model was proposed in [TrOCR: Transformer-based Optical Character
    Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282) by Minghao
    Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu
    Wei. TrOCR consists of an image Transformer encoder and an autoregressive text
    Transformer decoder to perform [optical character recognition (OCR)](https://en.wikipedia.org/wiki/Optical_character_recognition).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'TrOCR模型是由Minghao Li、Tengchao Lv、Lei Cui、Yijuan Lu、Dinei Florencio、Cha Zhang、Zhoujun
    Li、Furu Wei在[TrOCR: Transformer-based Optical Character Recognition with Pre-trained
    Models](https://arxiv.org/abs/2109.10282)中提出的。TrOCR包括一个图像Transformer编码器和一个自回归文本Transformer解码器，用于执行[光学字符识别（OCR）](https://en.wikipedia.org/wiki/Optical_character_recognition)。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的摘要如下：
- en: '*Text recognition is a long-standing research problem for document digitalization.
    Existing approaches for text recognition are usually built based on CNN for image
    understanding and RNN for char-level text generation. In addition, another language
    model is usually needed to improve the overall accuracy as a post-processing step.
    In this paper, we propose an end-to-end text recognition approach with pre-trained
    image Transformer and text Transformer models, namely TrOCR, which leverages the
    Transformer architecture for both image understanding and wordpiece-level text
    generation. The TrOCR model is simple but effective, and can be pre-trained with
    large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments
    show that the TrOCR model outperforms the current state-of-the-art models on both
    printed and handwritten text recognition tasks.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*文本识别是文档数字化的一个长期研究问题。现有的文本识别方法通常基于CNN进行图像理解和基于RNN进行字符级文本生成。此外，通常需要另一个语言模型作为后处理步骤来提高整体准确性。在本文中，我们提出了一种端到端的文本识别方法，使用预训练的图像Transformer和文本Transformer模型，即TrOCR，它利用Transformer架构进行图像理解和词片级文本生成。TrOCR模型简单而有效，可以使用大规模合成数据进行预训练，并使用人工标记的数据集进行微调。实验表明，TrOCR模型在印刷和手写文本识别任务上优于当前最先进的模型。*'
- en: '![drawing](../Images/38c5ef57a7dc1784f1413dccc805e29d.png) TrOCR architecture.
    Taken from the [original paper](https://arxiv.org/abs/2109.10282).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/38c5ef57a7dc1784f1413dccc805e29d.png) TrOCR架构。摘自[原始论文](https://arxiv.org/abs/2109.10282)。'
- en: Please refer to the `VisionEncoderDecoder` class on how to use this model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考`VisionEncoderDecoder`类如何使用这个模型。
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/microsoft/unilm/tree/6f60612e7cc86a2a1ae85c47231507a587ab4e01/trocr).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是由[nielsr](https://huggingface.co/nielsr)贡献的。原始代码可以在[这里](https://github.com/microsoft/unilm/tree/6f60612e7cc86a2a1ae85c47231507a587ab4e01/trocr)找到。
- en: Usage tips
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: The quickest way to get started with TrOCR is by checking the [tutorial notebooks](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/TrOCR),
    which show how to use the model at inference time as well as fine-tuning on custom
    data.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用TrOCR的最快方法是查看[教程笔记本](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/TrOCR)，展示了如何在推理时使用模型以及在自定义数据上进行微调。
- en: TrOCR is pre-trained in 2 stages before being fine-tuned on downstream datasets.
    It achieves state-of-the-art results on both printed (e.g. the [SROIE dataset](https://paperswithcode.com/dataset/sroie)
    and handwritten (e.g. the [IAM Handwriting dataset](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database%3E)
    text recognition tasks. For more information, see the [official models](https://huggingface.co/models?other=trocr%3E).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TrOCR在被微调到下游数据集之前经过2个阶段的预训练。它在印刷（例如[SROIE数据集](https://paperswithcode.com/dataset/sroie)）和手写（例如[IAM手写数据集](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database%3E)）文本识别任务上取得了最先进的结果。更多信息，请参阅[官方模型](https://huggingface.co/models?other=trocr%3E)。
- en: TrOCR is always used within the [VisionEncoderDecoder](vision-encoder-decoder)
    framework.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TrOCR始终在[VisionEncoderDecoder](vision-encoder-decoder)框架内使用。
- en: Resources
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with TrOCR. If you’re interested in submitting a resource
    to be included here, please feel free to open a Pull Request and we’ll review
    it! The resource should ideally demonstrate something new instead of duplicating
    an existing resource.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个官方的Hugging Face和社区资源列表（由🌎表示），帮助您开始使用TrOCR。如果您有兴趣提交资源以包含在此处，请随时打开一个Pull Request，我们将进行审核！资源应该展示一些新东西，而不是重复现有资源。
- en: Text Classification
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类
- en: A blog post on [Accelerating Document AI](https://huggingface.co/blog/document-ai)
    with TrOCR.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于[加速文档AI](https://huggingface.co/blog/document-ai)与TrOCR的博客文章。
- en: A blog post on how to [Document AI](https://github.com/philschmid/document-ai-transformers)
    with TrOCR.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于如何使用TrOCR进行[文档AI](https://github.com/philschmid/document-ai-transformers)的博客文章。
- en: A notebook on how to [finetune TrOCR on IAM Handwriting Database using Seq2SeqTrainer](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Fine_tune_TrOCR_on_IAM_Handwriting_Database_using_Seq2SeqTrainer.ipynb).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于如何使用Seq2SeqTrainer在IAM手写数据库上[微调TrOCR](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Fine_tune_TrOCR_on_IAM_Handwriting_Database_using_Seq2SeqTrainer.ipynb)的笔记本。
- en: A notebook on [inference with TrOCR](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Inference_with_TrOCR_%2B_Gradio_demo.ipynb)
    and Gradio demo.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于[inference with TrOCR](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Inference_with_TrOCR_%2B_Gradio_demo.ipynb)和Gradio演示的笔记本。
- en: A notebook on [finetune TrOCR on the IAM Handwriting Database](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Fine_tune_TrOCR_on_IAM_Handwriting_Database_using_native_PyTorch.ipynb)
    using native PyTorch.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于在IAM手写数据库上[微调TrOCR](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Fine_tune_TrOCR_on_IAM_Handwriting_Database_using_native_PyTorch.ipynb)使用原生PyTorch的笔记本。
- en: A notebook on [evaluating TrOCR on the IAM test set](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Evaluating_TrOCR_base_handwritten_on_the_IAM_test_set.ipynb).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于[在IAM测试集上评估TrOCR](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Evaluating_TrOCR_base_handwritten_on_the_IAM_test_set.ipynb)的笔记本。
- en: Text Generation
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成
- en: '[Casual language modeling](https://huggingface.co/docs/transformers/tasks/language_modeling)
    task guide.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语言建模](https://huggingface.co/docs/transformers/tasks/language_modeling)任务指南。'
- en: ⚡️ Inference
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ⚡️ 推理
- en: An interactive-demo on [TrOCR handwritten character recognition](https://huggingface.co/spaces/nielsr/TrOCR-handwritten).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于[TrOCR手写字符识别](https://huggingface.co/spaces/nielsr/TrOCR-handwritten)的交互式演示。
- en: Inference
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: TrOCR’s `VisionEncoderDecoder` model accepts images as input and makes use of
    [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    to autoregressively generate text given the input image.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: TrOCR的`VisionEncoderDecoder`模型接受图像作为输入，并利用[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)来自回归地生成给定输入图像的文本。
- en: The [`ViTImageProcessor`/`DeiTImageProcessor`] class is responsible for preprocessing
    the input image and [`RobertaTokenizer`/`XLMRobertaTokenizer`] decodes the generated
    target tokens to the target string. The [TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)
    wraps [`ViTImageProcessor`/`DeiTImageProcessor`] and [`RobertaTokenizer`/`XLMRobertaTokenizer`]
    into a single instance to both extract the input features and decode the predicted
    token ids.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[`ViTImageProcessor`/`DeiTImageProcessor`]类负责预处理输入图像，[`RobertaTokenizer`/`XLMRobertaTokenizer`]解码生成的目标令牌为目标字符串。[TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)将[`ViTImageProcessor`/`DeiTImageProcessor`]和[`RobertaTokenizer`/`XLMRobertaTokenizer`]封装成单个实例，用于提取输入特征和解码预测的令牌ID。'
- en: Step-by-step Optical Character Recognition (OCR)
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步光学字符识别（OCR）
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: See the [model hub](https://huggingface.co/models?filter=trocr) to look for
    TrOCR checkpoints.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[模型中心](https://huggingface.co/models?filter=trocr)以查找TrOCR检查点。
- en: TrOCRConfig
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TrOCRConfig
- en: '### `class transformers.TrOCRConfig`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TrOCRConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/configuration_trocr.py#L31)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/configuration_trocr.py#L31)'
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 50265) — Vocabulary size of the
    TrOCR model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 50265) — TrOCR模型的词汇量。定义了在调用[TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)时可以表示的不同令牌数量。'
- en: '`d_model` (`int`, *optional*, defaults to 1024) — Dimensionality of the layers
    and the pooler layer.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *optional*, defaults to 1024) — 层和池化层的维度。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 12) — Number of decoder layers.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *optional*, defaults to 12) — 解码器层数。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 16) — Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, defaults to 16) — Transformer解码器中每个注意力层的注意力头数。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 4096) — Dimensionality of
    the “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, defaults to 4096) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    — The non-linear activation function (function or string) in the pooler. If string,
    `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    — 池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — 此模型可能使用的最大序列长度。通常将其设置为较大的值以防万一（例如512、1024或2048）。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, and pooler.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.1) — 嵌入层和池化器中所有全连接层的丢弃概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — 注意力概率的丢弃比例。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — 全连接层内激活的丢弃比例。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the decoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.0) — 解码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop论文](see
    [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: '`scale_embedding` (`bool`, *optional*, defaults to `False`) — Whether or not
    to scale the word embeddings by sqrt(d_model).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale_embedding` (`bool`, *optional*, defaults to `False`) — 是否将词嵌入按sqrt(d_model)进行缩放。'
- en: '`use_learned_position_embeddings` (`bool`, *optional*, defaults to `True`)
    — Whether or not to use learned position embeddings. If not, sinusoidal position
    embeddings will be used.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_learned_position_embeddings` (`bool`, *optional*, defaults to `True`)
    — 是否使用学习的位置嵌入。如果不是，则将使用正弦位置嵌入。'
- en: '`layernorm_embedding` (`bool`, *optional*, defaults to `True`) — Whether or
    not to use a layernorm after the word + position embeddings.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layernorm_embedding`（`bool`，*可选*，默认为`True`）—是否在单词+位置嵌入后使用layernorm。'
- en: This is the configuration class to store the configuration of a [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM).
    It is used to instantiate an TrOCR model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the TrOCR [microsoft/trocr-base-handwritten](https://huggingface.co/microsoft/trocr-base-handwritten)
    architecture.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是配置类，用于存储[TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)的配置。它用于根据指定的参数实例化TrOCR模型，定义模型架构。使用默认值实例化配置将产生类似于TrOCR
    [microsoft/trocr-base-handwritten](https://huggingface.co/microsoft/trocr-base-handwritten)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: TrOCRProcessor
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TrOCRProcessor
- en: '### `class transformers.TrOCRProcessor`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TrOCRProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L24)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L24)'
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` ([`ViTImageProcessor`/`DeiTImageProcessor`], *optional*)
    — An instance of [`ViTImageProcessor`/`DeiTImageProcessor`]. The image processor
    is a required input.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor`（[`ViTImageProcessor`/`DeiTImageProcessor`]，*可选*）—[`ViTImageProcessor`/`DeiTImageProcessor`]的实例。图像处理器是必需的输入。'
- en: '`tokenizer` ([`RobertaTokenizer`/`XLMRobertaTokenizer`], *optional*) — An instance
    of [`RobertaTokenizer`/`XLMRobertaTokenizer`]. The tokenizer is a required input.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[`RobertaTokenizer`/`XLMRobertaTokenizer`]，*可选*）—[`RobertaTokenizer`/`XLMRobertaTokenizer`]的实例。标记器是必需的输入。'
- en: Constructs a TrOCR processor which wraps a vision image processor and a TrOCR
    tokenizer into a single processor.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个TrOCR处理器，将视觉图像处理器和TrOCR标记器封装到单个处理器中。
- en: '[TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)
    offers all the functionalities of [`ViTImageProcessor`/`DeiTImageProcessor`] and
    [`RobertaTokenizer`/`XLMRobertaTokenizer`]. See the [**call**()](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor.__call__)
    and [decode()](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor.decode)
    for more information.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)提供了所有[`ViTImageProcessor`/`DeiTImageProcessor`]和[`RobertaTokenizer`/`XLMRobertaTokenizer`]的功能。查看[**call**()](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor.__call__)和[decode()](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor.decode)以获取更多信息。'
- en: '#### `__call__`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L63)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L63)'
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When used in normal mode, this method forwards all its arguments to AutoImageProcessor’s
    `__call__()` and returns its output. If used in the context `as_target_processor()`
    this method forwards all its arguments to TrOCRTokenizer’s `~TrOCRTokenizer.__call__`.
    Please refer to the doctsring of the above two methods for more information.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常模式下使用时，此方法将所有参数转发到AutoImageProcessor的`__call__()`并返回其输出。如果在上下文`as_target_processor()`中使用此方法，则将所有参数转发到TrOCRTokenizer的`~TrOCRTokenizer.__call__`。请参考上述两种方法的文档获取更多信息。
- en: '#### `from_pretrained`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）—这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练特征提取器的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)方法保存的特征提取器文件，例如`./my_model_directory/`。
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs — Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个保存的特征提取器JSON *文件*的路径或URL，例如`./my_model_directory/preprocessor_config.json`。**kwargs
    —传递给[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)和`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`的额外关键字参数。
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化与预训练模型相关联的处理器。
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用特征提取器[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)、图像处理器[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)和分词器`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`方法。有关更多信息，请参阅上述方法的文档字符串。
- en: '#### `save_pretrained`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str`或`os.PathLike`) — 特征提取器JSON文件和分词器文件将保存在的目录（如果目录不存在将被创建）。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为`False`) — 是否在保存后将模型推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您命名空间中的`save_directory`名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) — 传递给[push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的额外关键字参数。'
- en: Saves the attributes of this processor (feature extractor, tokenizer…) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处理器的属性（特征提取器、分词器等）保存在指定目录中，以便可以使用[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)方法重新加载。
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)和[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)。有关更多信息，请参阅上述方法的文档字符串。
- en: '#### `batch_decode`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L96)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L96)'
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This method forwards all its arguments to TrOCRTokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将所有参数转发给TrOCRTokenizer的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。有关更多信息，请参阅此方法的文档字符串。
- en: '#### `decode`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L103)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/processing_trocr.py#L103)'
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This method forwards all its arguments to TrOCRTokenizer’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将所有参数转发给TrOCRTokenizer的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。有关更多信息，请参阅此方法的文档字符串。
- en: TrOCRForCausalLM
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TrOCRForCausalLM
- en: '### `class transformers.TrOCRForCausalLM`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TrOCRForCausalLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/modeling_trocr.py#L724)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/modeling_trocr.py#L724)'
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The TrOCR Decoder with a language modeling head. Can be used as the decoder
    part of [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)
    and `VisionEncoderDecoder`. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的TrOCR解码器。可用作[EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)和`VisionEncoderDecoder`的解码器部分。此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/modeling_trocr.py#L762)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/trocr/modeling_trocr.py#L762)'
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。默认情况下将忽略填充。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.Tensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0,
    1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示标记是`未被掩码`，
- en: 0 for tokens that are `masked`.
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示标记是`被掩码`。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`encoder_hidden_states` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention if the model is configured as
    a decoder.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    编码器最后一层的隐藏状态序列。如果模型配置为解码器，则在交叉注意力中使用。'
- en: '`encoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on the padding token indices
    of the encoder input. This mask is used in the cross-attention if the model is
    configured as a decoder. Mask values selected in `[0, 1]`:'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在编码器输入的填充标记索引上执行注意力的掩码。如果模型配置为解码器，则在交叉注意力中使用此掩码。掩码值选在`[0, 1]`之间：'
- en: '`head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules. Mask values
    selected in `[0, 1]`:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使注意力模块的选定头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部是`未被掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部是`被掩码`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使交叉注意力模块的选定头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部是`未被掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部是`被掩码`。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.
    The two additional tensors are only required when the model is used as a decoder
    in a Sequence to Sequence model.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）—
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量）和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。当模型用作序列到序列模型中的解码器时，这两个额外的张量是必需的。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的）形状为`(batch_size,
    1)`，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_ids`。
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should either
    be in `[0, ..., config.vocab_size]` or -100 (see `input_ids` docstring). Tokens
    with indices set to `-100` are ignored (masked), the loss is only computed for
    the tokens with labels in `[0, ..., config.vocab_size]`.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 用于计算掩码语言建模损失的标签。索引应该在`[0,
    ..., config.vocab_size]`或-100（参见`input_ids`文档字符串）。将索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`中的标记。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）— 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: 1 for tokens that are `not masked`,
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)
    or `tuple(torch.FloatTensor)`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig))
    and inputs.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)
    或一个 `torch.FloatTensor` 元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（[TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss (for next-token prediction).'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 语言建模损失（用于下一个标记预测）。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的输出
    + 每层输出的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Cross attentions weights after the attention softmax, used to compute the weighted
    average in the cross-attention heads.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的交叉注意力权重，用于计算交叉注意力头中的加权平均值。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `torch.FloatTensor`
    tuples of length `config.n_layers`, with each tuple containing the cached key,
    value states of the self-attention and the cross-attention layers if model is
    used in encoder-decoder setting. Only relevant if `config.is_decoder = True`.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）
    — 长度为`config.n_layers`的`torch.FloatTensor`元组的元组，每个元组包含自注意力和交叉注意力层的缓存键、值状态，如果模型用于编码器-解码器设置，则相关。仅在`config.is_decoder
    = True`时相关。'
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码。
- en: 'Example:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE11]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
