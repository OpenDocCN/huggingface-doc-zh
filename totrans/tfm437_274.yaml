- en: MaskFormer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/maskformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/maskformer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This is a recently introduced model so the API hasn’t been tested extensively.
    There may be some bugs or slight breaking changes to fix it in the future. If
    you see something strange, file a [Github Issue](https://github.com/huggingface/transformers/issues/new?assignees=&labels=&template=bug-report.md&title).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The MaskFormer model was proposed in [Per-Pixel Classification is Not All You
    Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278) by Bowen Cheng,
    Alexander G. Schwing, Alexander Kirillov. MaskFormer addresses semantic segmentation
    with a mask classification paradigm instead of performing classic pixel-level
    classification.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '*Modern approaches typically formulate semantic segmentation as a per-pixel
    classification task, while instance-level segmentation is handled with an alternative
    mask classification. Our key insight: mask classification is sufficiently general
    to solve both semantic- and instance-level segmentation tasks in a unified manner
    using the exact same model, loss, and training procedure. Following this observation,
    we propose MaskFormer, a simple mask classification model which predicts a set
    of binary masks, each associated with a single global class label prediction.
    Overall, the proposed mask classification-based method simplifies the landscape
    of effective approaches to semantic and panoptic segmentation tasks and shows
    excellent empirical results. In particular, we observe that MaskFormer outperforms
    per-pixel classification baselines when the number of classes is large. Our mask
    classification-based method outperforms both current state-of-the-art semantic
    (55.6 mIoU on ADE20K) and panoptic segmentation (52.7 PQ on COCO) models.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The figure below illustrates the architecture of MaskFormer. Taken from the
    [original paper](https://arxiv.org/abs/2107.06278).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f3d238eca99c99399c901e43c598a16.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
- en: This model was contributed by [francesco](https://huggingface.co/francesco).
    The original code can be found [here](https://github.com/facebookresearch/MaskFormer).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Usage tips
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MaskFormer’s Transformer decoder is identical to the decoder of [DETR](detr).
    During training, the authors of DETR did find it helpful to use auxiliary losses
    in the decoder, especially to help the model output the correct number of objects
    of each class. If you set the parameter `use_auxilary_loss` of [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    to `True`, then prediction feedforward neural networks and Hungarian losses are
    added after each decoder layer (with the FFNs sharing parameters).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to train the model in a distributed environment across multiple
    nodes, then one should update the `get_num_masks` function inside in the `MaskFormerLoss`
    class of `modeling_maskformer.py`. When training on multiple nodes, this should
    be set to the average number of target masks across all nodes, as can be seen
    in the original implementation [here](https://github.com/facebookresearch/MaskFormer/blob/da3e60d85fdeedcb31476b5edd7d328826ce56cc/mask_former/modeling/criterion.py#L169).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One can use [MaskFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerImageProcessor)
    to prepare images for the model and optional targets for the model.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get the final segmentation, depending on the task, you can call [post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_semantic_segmentation)
    or [post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_panoptic_segmentation).
    Both tasks can be solved using [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    output, panoptic segmentation accepts an optional `label_ids_to_fuse` argument
    to fuse instances of the target object/s (e.g. sky) together.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要获得最终的分割结果，根据任务，您可以调用[post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_semantic_segmentation)或[post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_panoptic_segmentation)。这两个任务都可以使用[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)输出来解决，全景分割接受一个可选的`label_ids_to_fuse`参数，用于将目标对象（例如天空）的实例融合在一起。
- en: Resources
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: Image Segmentation
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分割
- en: All notebooks that illustrate inference as well as fine-tuning on custom data
    with MaskFormer can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/MaskFormer).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有演示推断以及使用MaskFormer在自定义数据上进行微调的笔记本都可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/MaskFormer)找到。
- en: MaskFormer specific outputs
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormer特定的输出
- en: '### `class transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L146)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L146)'
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Last hidden states (final feature map) of the last stage of
    the encoder model (backbone).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 编码器模型（骨干）最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — Last hidden states (final feature map) of the
    last stage of the pixel decoder model (FPN).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 像素解码器模型（FPN）最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    sequence_length, hidden_size)`) — Last hidden states (final feature map) of the
    last stage of the transformer decoder model.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size,
    sequence_length, hidden_size)`) — 变换器解码器模型最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the encoder model at the output of
    each stage.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。编码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*,
    returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the transformer decoder at the output
    of each stage.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。变换器解码器在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`hidden_states` `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    containing `encoder_hidden_states`, `pixel_decoder_hidden_states` and `decoder_hidden_states`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` `tuple(torch.FloatTensor)`，*可选的*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 包含`encoder_hidden_states`、`pixel_decoder_hidden_states`和`decoder_hidden_states`的`torch.FloatTensor`元组。'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights from Detr’s decoder after the attention softmax, used to compute
    the weighted average in the self-attention heads.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。Detr解码器中注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: Class for outputs of [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel).
    This class returns all the needed hidden states to compute the logits.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 用于[MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)输出的类。该类返回计算logits所需的所有隐藏状态。
- en: '### `class transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L189)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L189)'
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`loss` (`torch.Tensor`, *optional*) — The computed loss, returned when labels
    are present.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.Tensor`, *可选*) — 计算得到的损失，在存在标签时返回。'
- en: '`class_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, num_labels + 1)` representing the proposed classes for each query.
    Note the `+ 1` is needed because we incorporate the null class.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_queries_logits` (`torch.FloatTensor`) — 形状为`(batch_size, num_queries,
    num_labels + 1)`的张量，表示每个查询的提议类别。请注意`+ 1`是因为我们包含了空类。'
- en: '`masks_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, height, width)` representing the proposed masks for each query.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_queries_logits` (`torch.FloatTensor`) — 形状为`(batch_size, num_queries,
    height, width)`的张量，表示每个查询的提议掩码。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Last hidden states (final feature map) of the last stage of
    the encoder model (backbone).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 编码器模型（骨干）最后阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — Last hidden states (final feature map) of the
    last stage of the pixel decoder model (FPN).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 像素解码器模型（FPN）最后阶段的最后隐藏状态（最终特征图）。'
- en: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    sequence_length, hidden_size)`) — Last hidden states (final feature map) of the
    last stage of the transformer decoder model.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size,
    sequence_length, hidden_size)`) — transformer解码器模型最后阶段的最后隐藏状态（最终特征图）。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the encoder model at the output of
    each stage.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。编码器模型在每个阶段的输出的隐藏状态（也称为特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。像素解码器模型在每个阶段的输出的隐藏状态（也称为特征图）。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*,
    returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the transformer decoder at the output of each stage.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。每个阶段的transformer解码器的隐藏状态。'
- en: '`hidden_states` `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    containing `encoder_hidden_states`, `pixel_decoder_hidden_states` and `decoder_hidden_states`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 包含`encoder_hidden_states`、`pixel_decoder_hidden_states`和`decoder_hidden_states`的`torch.FloatTensor`元组。'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights from Detr’s decoder after the attention softmax, used to compute
    the weighted average in the self-attention heads.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。Detr解码器在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: Class for outputs of [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 用于[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)的输出类。
- en: This output can be directly passed to [post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_semantic_segmentation)
    or or [post_process_instance_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_instance_segmentation)
    or [post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_panoptic_segmentation)
    depending on the task. Please, see [`~MaskFormerImageProcessor] for details regarding
    usage.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出可以直接传递给[post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_semantic_segmentation)或[post_process_instance_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_instance_segmentation)或[post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.post_process_panoptic_segmentation)，具体取决于任务。有关使用详情，请参阅[`~MaskFormerImageProcessor]。
- en: MaskFormerConfig
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormerConfig
- en: '### `class transformers.MaskFormerConfig`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MaskFormerConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/configuration_maskformer.py#L35)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/configuration_maskformer.py#L35)'
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`mask_feature_size` (`int`, *optional*, defaults to 256) — The masks’ features
    size, this value will also be used to specify the Feature Pyramid Network features’
    size.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_size` (`int`, *可选*, 默认为 256) — mask的特征大小，此值还将用于指定特征金字塔网络特征的大小。'
- en: '`no_object_weight` (`float`, *optional*, defaults to 0.1) — Weight to apply
    to the null (no object) class.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_object_weight` (`float`, *可选*, 默认为 0.1) — 用于应用于空（无对象）类的权重。'
- en: '`use_auxiliary_loss(bool,` *optional*, defaults to `False`) — If `True` `MaskFormerForInstanceSegmentationOutput`
    will contain the auxiliary losses computed using the logits from each decoder’s
    stage.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_auxiliary_loss(bool,` *可选*, 默认为 `False`) — 如果为 `True`，`MaskFormerForInstanceSegmentationOutput`
    将包含使用每个解码器阶段的logits计算的辅助损失。'
- en: '`backbone_config` (`Dict`, *optional*) — The configuration passed to the backbone,
    if unset, the configuration corresponding to `swin-base-patch4-window12-384` will
    be used.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` (`Dict`, *可选*) — 传递给骨干的配置，如果未设置，将使用与`swin-base-patch4-window12-384`对应的配置。'
- en: '`decoder_config` (`Dict`, *optional*) — The configuration passed to the transformer
    decoder model, if unset the base config for `detr-resnet-50` will be used.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_config` (`Dict`, *可选*) — 传递给变压器解码器模型的配置，如果未设置，则将使用`detr-resnet-50`的基本配置。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *可选*, 默认为 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`init_xavier_std` (`float`, *optional*, defaults to 1) — The scaling factor
    used for the Xavier initialization gain in the HM Attention map module.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_xavier_std` (`float`, *可选*, 默认为 1) — 用于HM Attention map模块中Xavier初始化增益的缩放因子。'
- en: '`dice_weight` (`float`, *optional*, defaults to 1.0) — The weight for the dice
    loss.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dice_weight` (`float`, *可选*, 默认为 1.0) — dice损失的权重。'
- en: '`cross_entropy_weight` (`float`, *optional*, defaults to 1.0) — The weight
    for the cross entropy loss.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_entropy_weight` (`float`, *可选*, 默认为 1.0) — 交叉熵损失的权重。'
- en: '`mask_weight` (`float`, *optional*, defaults to 20.0) — The weight for the
    mask loss.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_weight` (`float`, *可选*, 默认为 20.0) — mask损失的权重。'
- en: '`output_auxiliary_logits` (`bool`, *optional*) — Should the model output its
    `auxiliary_logits` or not.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_auxiliary_logits` (`bool`, *可选*) — 模型是否输出其`auxiliary_logits`。'
- en: Raises
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '`ValueError`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`ValueError`'
- en: '`ValueError` — Raised if the backbone model type selected is not in `["swin"]`
    or the decoder model type selected is not in `["detr"]`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValueError` — 如果选择的骨干模型类型不在 `["swin"]` 中，或者选择的解码器模型类型不在 `["detr"]` 中'
- en: This is the configuration class to store the configuration of a [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel).
    It is used to instantiate a MaskFormer model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the MaskFormer [facebook/maskformer-swin-base-ade](https://huggingface.co/facebook/maskformer-swin-base-ade)
    architecture trained on [ADE20k-150](https://huggingface.co/datasets/scene_parse_150).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)的配置。它用于根据指定的参数实例化一个MaskFormer模型，定义模型架构。使用默认值实例化配置将产生类似于在[ADE20k-150](https://huggingface.co/datasets/scene_parse_150)上训练的MaskFormer
    [facebook/maskformer-swin-base-ade](https://huggingface.co/facebook/maskformer-swin-base-ade)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: Currently, MaskFormer only supports the [Swin Transformer](swin) as backbone.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，MaskFormer仅支持[Swin Transformer](swin)作为骨干网络。
- en: 'Examples:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#### `from_backbone_and_decoder_configs`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_backbone_and_decoder_configs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/configuration_maskformer.py#L182)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/configuration_maskformer.py#L182)'
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`backbone_config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The backbone configuration.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 骨干配置。'
- en: '`decoder_config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The transformer decoder configuration to use.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    要使用的变压器解码器配置。'
- en: Returns
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)'
- en: An instance of a configuration object
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象的一个实例
- en: Instantiate a [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    (or a derived class) from a pre-trained backbone model configuration and DETR
    model configuration.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练的骨干模型配置和DETR模型配置实例化一个[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)（或派生类）。
- en: MaskFormerImageProcessor
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormerImageProcessor
- en: '### `class transformers.MaskFormerImageProcessor`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MaskFormerImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L347)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L347)'
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    input to a certain `size`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`（`bool`，*可选*，默认为`True`）— 是否将输入调整大小到特定的`size`。'
- en: '`size` (`int`, *optional*, defaults to 800) — Resize the input to the given
    size. Only has an effect if `do_resize` is set to `True`. If size is a sequence
    like `(width, height)`, output size will be matched to this. If size is an int,
    smaller edge of the image will be matched to this number. i.e, if `height > width`,
    then image will be rescaled to `(size * height / width, size)`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`（`int`，*可选*，默认为800）— 将输入调整大小到给定的大小。仅在`do_resize`设置为`True`时有效。如果size是一个类似`(width,
    height)`的序列，输出大小将匹配到这个。如果size是一个整数，图像的较小边将匹配到这个数字。即，如果`height > width`，则图像将重新缩放为`(size
    * height / width, size)`。'
- en: '`size_divisor` (`int`, *optional*, defaults to 32) — Some backbones need images
    divisible by a certain number. If not passed, it defaults to the value used in
    Swin Transformer.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisor`（`int`，*可选*，默认为32）— 一些骨干需要能够被某个数字整除的图像。如果未传递，则默认为Swin Transformer中使用的值。'
- en: '`resample` (`int`, *optional*, defaults to `Resampling.BILINEAR`) — An optional
    resampling filter. This can be one of `PIL.Image.Resampling.NEAREST`, `PIL.Image.Resampling.BOX`,
    `PIL.Image.Resampling.BILINEAR`, `PIL.Image.Resampling.HAMMING`, `PIL.Image.Resampling.BICUBIC`
    or `PIL.Image.Resampling.LANCZOS`. Only has an effect if `do_resize` is set to
    `True`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample`（`int`，*可选*，默认为`Resampling.BILINEAR`）— 一个可选的重采样滤波器。可以是`PIL.Image.Resampling.NEAREST`、`PIL.Image.Resampling.BOX`、`PIL.Image.Resampling.BILINEAR`、`PIL.Image.Resampling.HAMMING`、`PIL.Image.Resampling.BICUBIC`或`PIL.Image.Resampling.LANCZOS`之一。仅在`do_resize`设置为`True`时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the input to a certain `scale`.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale`（`bool`，*可选*，默认为`True`）— 是否将输入调整大小到特定的`scale`。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `1/ 255`) — Rescale the
    input by the given factor. Only has an effect if `do_rescale` is set to `True`.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor`（`float`，*可选*，默认为`1/255`）— 通过给定的因子重新缩放输入。仅在`do_rescale`设置为`True`时有效。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether or not to
    normalize the input with mean and standard deviation.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize`（`bool`，*可选*，默认为`True`）— 是否对输入进行均值和标准差归一化。'
- en: '`image_mean` (`int`, *optional*, defaults to `[0.485, 0.456, 0.406]`) — The
    sequence of means for each channel, to be used when normalizing images. Defaults
    to the ImageNet mean.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean`（`int`，*可选*，默认为`[0.485, 0.456, 0.406]`）— 每个通道的均值序列，在归一化图像时使用。默认为ImageNet均值。'
- en: '`image_std` (`int`, *optional*, defaults to `[0.229, 0.224, 0.225]`) — The
    sequence of standard deviations for each channel, to be used when normalizing
    images. Defaults to the ImageNet std.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std`（`int`，*可选*，默认为`[0.229, 0.224, 0.225]`）— 每个通道的标准差序列，在归一化图像时使用。默认为ImageNet标准差。'
- en: '`ignore_index` (`int`, *optional*) — Label to be assigned to background pixels
    in segmentation maps. If provided, segmentation map pixels denoted with 0 (background)
    will be replaced with `ignore_index`.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_index`（`int`，*可选*）— 分割地图中要分配给背景像素的标签。如果提供，用0（背景）表示的分割地图像素将被替换为`ignore_index`。'
- en: '`do_reduce_labels` (`bool`, *optional*, defaults to `False`) — Whether or not
    to decrement all label values of segmentation maps by 1\. Usually used for datasets
    where 0 is used for background, and background itself is not included in all classes
    of a dataset (e.g. ADE20k). The background label will be replaced by `ignore_index`.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_reduce_labels`（`bool`，*可选*，默认为`False`）— 是否减少所有分割地图的标签值。通常用于数据集中使用0表示背景，并且背景本身不包含在数据集的所有类中（例如ADE20k）。背景标签将被替换为`ignore_index`。'
- en: Constructs a MaskFormer image processor. The image processor can be used to
    prepare image(s) and optional targets for the model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 构造一个MaskFormer图像处理器。该图像处理器可用于为模型准备图像和可选目标。
- en: This image processor inherits from `BaseImageProcessor` which contains most
    of the main methods. Users should refer to this superclass for more information
    regarding those methods.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 该图像处理器继承自`BaseImageProcessor`，其中包含大部分主要方法。用户应参考这个超类以获取有关这些方法的更多信息。
- en: '#### `preprocess`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L677)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L677)'
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `encode_inputs`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_inputs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L875)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L875)'
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values_list` (`List[ImageInput]`) — List of images (pixel values) to
    be padded. Each image should be a tensor of shape `(channels, height, width)`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values_list`（`List[ImageInput]`）— 要填充的图像（像素值）列表。每个图像应该是形状为`(channels,
    height, width)`的张量。'
- en: '`segmentation_maps` (`ImageInput`, *optional*) — The corresponding semantic
    segmentation maps with the pixel-wise annotations.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation_maps`（`ImageInput`，*可选*）— 具有像素级注释的相应语义分割地图。'
- en: '(`bool`, *optional*, defaults to `True`): Whether or not to pad images up to
    the largest image in a batch and create a pixel mask.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: （`bool`，*可选*，默认为`True`）：是否将图像填充到批次中最大的图像，并创建像素掩模。
- en: 'If left to the default, will return a pixel mask that is:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果保持默认设置，将返回像素掩模：
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示真实像素（即`未掩模`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于填充像素（即`掩模`），值为0。
- en: '`instance_id_to_semantic_id` (`List[Dict[int, int]]` or `Dict[int, int]`, *optional*)
    — A mapping between object instance ids and class ids. If passed, `segmentation_maps`
    is treated as an instance segmentation map where each pixel represents an instance
    id. Can be provided as a single dictionary with a global/dataset-level mapping
    or as a list of dictionaries (one per image), to map instance ids in each image
    separately.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance_id_to_semantic_id`（`List[Dict[int, int]]`或`Dict[int, int]`，*可选*）—
    对象实例ID和类别ID之间的映射。如果传递了此参数，则`segmentation_maps`将被视为实例分割地图，其中每个像素表示一个实例ID。可以提供一个全局/数据集级别映射的单个字典，或者作为字典列表（每个图像一个），以分别映射每个图像中的实例ID。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of NumPy arrays. If set to `''pt''`,
    return PyTorch `torch.Tensor` objects.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）—
    如果设置，将返回张量而不是NumPy数组。如果设置为`''pt''`，则返回PyTorch的`torch.Tensor`对象。'
- en: Returns
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)'
- en: 'A [BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)
    with the following fields:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)：
- en: '`pixel_values` — Pixel values to be fed to a model.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` — 用于向模型提供输入的像素值。'
- en: '`pixel_mask` — Pixel mask to be fed to a model (when `=True` or if `pixel_mask`
    is in `self.model_input_names`).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` — 用于向模型提供输入的像素掩模（当`=True`或`pixel_mask`在`self.model_input_names`中时）。'
- en: '`mask_labels` — Optional list of mask labels of shape `(labels, height, width)`
    to be fed to a model (when `annotations` are provided).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_labels` — 可选的掩模标签列表，形状为`(labels, height, width)`，用于向模型提供输入（当提供`annotations`时）。'
- en: '`class_labels` — Optional list of class labels of shape `(labels)` to be fed
    to a model (when `annotations` are provided). They identify the labels of `mask_labels`,
    e.g. the label of `mask_labels[i][j]` if `class_labels[i][j]`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels` — 可选的类标签列表，形状为`(labels)`，用于向模型提供输入（当提供`annotations`时）。它们标识了`mask_labels`的标签，例如`mask_labels[i][j]`的标签为`class_labels[i][j]`。'
- en: Pad images up to the largest image in a batch and create a corresponding `pixel_mask`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像填充到批次中最大的图像，并创建相应的`pixel_mask`。
- en: MaskFormer addresses semantic segmentation with a mask classification paradigm,
    thus input segmentation maps will be converted to lists of binary masks and their
    respective labels. Let’s see an example, assuming `segmentation_maps = [[2,6,7,9]]`,
    the output will contain `mask_labels = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]`
    (four binary masks) and `class_labels = [2,6,7,9]`, the labels for each mask.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: MaskFormer通过掩模分类范式解决语义分割问题，因此输入的分割地图将被转换为二进制掩模列表及其相应的标签。让我们看一个例子，假设`segmentation_maps
    = [[2,6,7,9]]`，输出将包含`mask_labels = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]`（四个二进制掩模）和`class_labels
    = [2,6,7,9]`，每个掩模的标签。
- en: '#### `post_process_semantic_segmentation`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_semantic_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1029)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1029)'
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` ([MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation))
    — Raw outputs of the model.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`（[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)）—
    模型的原始输出。'
- en: '`target_sizes` (`List[Tuple[int, int]]`, *optional*) — List of length (batch_size),
    where each list item (`Tuple[int, int]]`) corresponds to the requested final size
    (height, width) of each prediction. If left to None, predictions will not be resized.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes`（`List[Tuple[int, int]]`，*可选*）— 长度为`batch_size`的列表，其中每个列表项（`Tuple[int,
    int]]`对应于每个预测的请求最终大小（高度，宽度）。如果保持为None，则不会调整预测。'
- en: Returns
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[torch.Tensor]`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[torch.Tensor]`'
- en: A list of length `batch_size`, where each item is a semantic segmentation map
    of shape (height, width) corresponding to the target_sizes entry (if `target_sizes`
    is specified). Each entry of each `torch.Tensor` correspond to a semantic class
    id.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一个长度为`batch_size`的列表，其中每个项目是形状为（高度，宽度）的语义分割地图，对应于目标大小条目（如果指定了`target_sizes`）。每个`torch.Tensor`的每个条目对应于一个语义类别ID。
- en: Converts the output of [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    into semantic segmentation maps. Only supports PyTorch.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 将[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)的输出转换为语义分割地图。仅支持PyTorch。
- en: '#### `post_process_instance_segmentation`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_instance_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1079)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1079)'
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` ([MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation))
    — Raw outputs of the model.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`（[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)）—
    模型的原始输出。'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The probability score
    threshold to keep predicted instance masks.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold`（`float`，*可选*，默认为0.5）— 保留预测实例掩模的概率分数阈值。'
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — 将预测的掩码转换为二进制值时使用的阈值。'
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — The
    overlap mask area threshold to merge or discard small disconnected parts within
    each binary instance mask.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — 重叠掩码面积阈值，用于合并或丢弃每个二进制实例掩码中的小断开部分。'
- en: '`target_sizes` (`List[Tuple]`, *optional*) — List of length (batch_size), where
    each list item (`Tuple[int, int]]`) corresponds to the requested final size (height,
    width) of each prediction. If left to None, predictions will not be resized.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes` (`List[Tuple]`, *optional*) — 长度为（batch_size）的列表，其中每个列表项（`Tuple[int,
    int]`）对应于每个预测的请求最终大小（高度，宽度）。如果设置为`None`，则不会调整预测大小。'
- en: '`return_coco_annotation` (`bool`, *optional*, defaults to `False`) — If set
    to `True`, segmentation maps are returned in COCO run-length encoding (RLE) format.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_coco_annotation` (`bool`, *optional*, defaults to `False`) — 如果设置为`True`，分割地图将以COCO运行长度编码（RLE）格式返回。'
- en: '`return_binary_maps` (`bool`, *optional*, defaults to `False`) — If set to
    `True`, segmentation maps are returned as a concatenated tensor of binary segmentation
    maps (one per detected instance).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_binary_maps` (`bool`, *optional*, defaults to `False`) — 如果设置为`True`，分割地图将作为二进制分割地图的连接张量返回（每个检测到的实例一个）。'
- en: Returns
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: 'A list of dictionaries, one per image, each dictionary containing two keys:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个图像一个，每个字典包含两个键：
- en: '`segmentation` — A tensor of shape `(height, width)` where each pixel represents
    a `segment_id` or `List[List]` run-length encoding (RLE) of the segmentation map
    if return_coco_annotation is set to `True`. Set to `None` if no mask if found
    above `threshold`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation` — 形状为`(height, width)`的张量，其中每个像素表示`segment_id`或分割地图的`List[List]`运行长度编码（RLE），如果`return_coco_annotation`设置为`True`，则设置为`None`，如果未找到高于`threshold`的掩码。'
- en: '`segments_info` — A dictionary that contains additional information on each
    segment.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segments_info` — 包含每个段的附加信息的字典。'
- en: '`id` — An integer representing the `segment_id`.'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` — 代表`segment_id`的整数。'
- en: '`label_id` — An integer representing the label / semantic class id corresponding
    to `segment_id`.'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_id` — 代表与`segment_id`对应的标签/语义类别ID的整数。'
- en: '`score` — Prediction score of segment with `segment_id`.'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score` — 带有`segment_id`的段的预测分数。'
- en: Converts the output of `MaskFormerForInstanceSegmentationOutput` into instance
    segmentation predictions. Only supports PyTorch.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 将`MaskFormerForInstanceSegmentationOutput`的输出转换为实例分割预测。仅支持PyTorch。
- en: '#### `post_process_panoptic_segmentation`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_panoptic_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1193)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1193)'
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` (`MaskFormerForInstanceSegmentationOutput`) — The outputs from [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs` (`MaskFormerForInstanceSegmentationOutput`) — 来自[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)的输出。'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The probability score
    threshold to keep predicted instance masks.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`, *optional*, defaults to 0.5) — 保留预测实例掩码的概率分数阈值。'
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — 将预测的掩码转换为二进制值时使用的阈值。'
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — The
    overlap mask area threshold to merge or discard small disconnected parts within
    each binary instance mask.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — 重叠掩码面积阈值，用于合并或丢弃每个二进制实例掩码中的小断开部分。'
- en: '`label_ids_to_fuse` (`Set[int]`, *optional*) — The labels in this state will
    have all their instances be fused together. For instance we could say there can
    only be one sky in an image, but several persons, so the label ID for sky would
    be in that set, but not the one for person.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_ids_to_fuse` (`Set[int]`, *optional*) — 此状态中的标签将使其所有实例被融合在一起。例如，我们可以说一张图像中只能有一个天空，但可以有多个人，因此天空的标签ID将在该集合中，但人的标签ID不在其中。'
- en: '`target_sizes` (`List[Tuple]`, *optional*) — List of length (batch_size), where
    each list item (`Tuple[int, int]]`) corresponds to the requested final size (height,
    width) of each prediction in batch. If left to None, predictions will not be resized.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes` (`List[Tuple]`, *optional*) — 长度为（batch_size）的列表，其中每个列表项（`Tuple[int,
    int]`）对应于批处理中每个预测的请求最终大小（高度，宽度）。如果设置为`None`，则不会调整预测大小。'
- en: Returns
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: 'A list of dictionaries, one per image, each dictionary containing two keys:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个图像一个，每个字典包含两个键：
- en: '`segmentation` — a tensor of shape `(height, width)` where each pixel represents
    a `segment_id`, set to `None` if no mask if found above `threshold`. If `target_sizes`
    is specified, segmentation is resized to the corresponding `target_sizes` entry.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation` — 形状为`(height, width)`的张量，其中每个像素表示`segment_id`，如果未找到高于`threshold`的掩码，则设置为`None`。如果指定了`target_sizes`，则将分割调整为相应的`target_sizes`条目。'
- en: '`segments_info` — A dictionary that contains additional information on each
    segment.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segments_info` — 包含每个段的附加信息的字典。'
- en: '`id` — an integer representing the `segment_id`.'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` — 代表`segment_id`的整数。'
- en: '`label_id` — An integer representing the label / semantic class id corresponding
    to `segment_id`.'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_id` — 代表与`segment_id`对应的标签/语义类别ID的整数。'
- en: '`was_fused` — a boolean, `True` if `label_id` was in `label_ids_to_fuse`, `False`
    otherwise. Multiple instances of the same class / label were fused and assigned
    a single `segment_id`.'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`was_fused` — 一个布尔值，如果`label_id`在`label_ids_to_fuse`中则为`True`，否则为`False`。相同类别/标签的多个实例被融合并分配一个单独的`segment_id`。'
- en: '`score` — Prediction score of segment with `segment_id`.'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score` — 带有`segment_id`的段的预测分数。'
- en: Converts the output of `MaskFormerForInstanceSegmentationOutput` into image
    panoptic segmentation predictions. Only supports PyTorch.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 将`MaskFormerForInstanceSegmentationOutput`的输出转换为图像全景分割预测。仅支持PyTorch。
- en: MaskFormerFeatureExtractor
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormerFeatureExtractor
- en: '### `class transformers.MaskFormerFeatureExtractor`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MaskFormerFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/feature_extraction_maskformer.py#L26)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/feature_extraction_maskformer.py#L26)'
- en: '[PRE11]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#### `__call__`'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L571)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L571)'
- en: '[PRE12]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `encode_inputs`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_inputs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L875)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L875)'
- en: '[PRE13]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values_list` (`List[ImageInput]`) — List of images (pixel values) to
    be padded. Each image should be a tensor of shape `(channels, height, width)`.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values_list`（`List[ImageInput]`） — 要填充的图像（像素值）列表。每个图像应该是形状为`(channels,
    height, width)`的张量。'
- en: '`segmentation_maps` (`ImageInput`, *optional*) — The corresponding semantic
    segmentation maps with the pixel-wise annotations.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation_maps`（`ImageInput`，*可选*） — 具有像素级注释的相应语义分割图。'
- en: '(`bool`, *optional*, defaults to `True`): Whether or not to pad images up to
    the largest image in a batch and create a pixel mask.'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: （*可选*，默认为`True`）：是否将图像填充到批次中最大的图像并创建像素掩码。
- en: 'If left to the default, will return a pixel mask that is:'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果保持默认值，将返回一个像素掩码，即：
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示真实像素（即`未被遮罩`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示填充像素（即`被遮罩`）。
- en: '`instance_id_to_semantic_id` (`List[Dict[int, int]]` or `Dict[int, int]`, *optional*)
    — A mapping between object instance ids and class ids. If passed, `segmentation_maps`
    is treated as an instance segmentation map where each pixel represents an instance
    id. Can be provided as a single dictionary with a global/dataset-level mapping
    or as a list of dictionaries (one per image), to map instance ids in each image
    separately.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance_id_to_semantic_id`（`List[Dict[int, int]]`或`Dict[int, int]`，*可选*）
    — 对象实例id和类id之间的映射。如果传递，`segmentation_maps`将被视为实例分割图，其中每个像素表示一个实例id。可以提供为一个包含全局/数据集级映射的单个字典，或者作为字典列表（每个图像一个），以分别映射每个图像中的实例id。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of NumPy arrays. If set to `''pt''`,
    return PyTorch `torch.Tensor` objects.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）
    — 如果设置，将返回张量而不是NumPy数组。如果设置为`''pt''`，则返回PyTorch的`torch.Tensor`对象。'
- en: Returns
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)'
- en: 'A [BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)
    with the following fields:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)：
- en: '`pixel_values` — Pixel values to be fed to a model.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` — 要馈送给模型的像素值。'
- en: '`pixel_mask` — Pixel mask to be fed to a model (when `=True` or if `pixel_mask`
    is in `self.model_input_names`).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` — 要馈送给模型的像素掩码（当`=True`或`pixel_mask`在`self.model_input_names`中时）。'
- en: '`mask_labels` — Optional list of mask labels of shape `(labels, height, width)`
    to be fed to a model (when `annotations` are provided).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_labels` — 可选的形状为`(labels, height, width)`的掩码标签列表，用于馈送给模型（当提供`annotations`时）。'
- en: '`class_labels` — Optional list of class labels of shape `(labels)` to be fed
    to a model (when `annotations` are provided). They identify the labels of `mask_labels`,
    e.g. the label of `mask_labels[i][j]` if `class_labels[i][j]`.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels` — 可选的形状为`(labels)`的类标签列表，用于馈送给模型（当提供`annotations`时）。它们标识`mask_labels`的标签，例如如果`class_labels[i][j]`的标签是`mask_labels[i][j]`的标签。'
- en: Pad images up to the largest image in a batch and create a corresponding `pixel_mask`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像填充到批次中最大的图像，并创建相应的`pixel_mask`。
- en: MaskFormer addresses semantic segmentation with a mask classification paradigm,
    thus input segmentation maps will be converted to lists of binary masks and their
    respective labels. Let’s see an example, assuming `segmentation_maps = [[2,6,7,9]]`,
    the output will contain `mask_labels = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]`
    (four binary masks) and `class_labels = [2,6,7,9]`, the labels for each mask.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: MaskFormer使用掩码分类范式解决语义分割问题，因此输入分割图将被转换为二进制掩码列表及其相应的标签。让我们看一个例子，假设`segmentation_maps
    = [[2,6,7,9]]`，输出将包含`mask_labels = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]`（四个二进制掩码）和`class_labels
    = [2,6,7,9]`，每个掩码的标签。
- en: '#### `post_process_semantic_segmentation`'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_semantic_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1029)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1029)'
- en: '[PRE14]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` ([MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation))
    — Raw outputs of the model.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`（[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)）
    — 模型的原始输出。'
- en: '`target_sizes` (`List[Tuple[int, int]]`, *optional*) — List of length (batch_size),
    where each list item (`Tuple[int, int]]`) corresponds to the requested final size
    (height, width) of each prediction. If left to None, predictions will not be resized.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes`（`List[Tuple[int, int]]`，*可选*） — 长度为`batch_size`的列表，其中每个列表项（`Tuple[int,
    int]`）对应于每个预测的请求最终大小（高度，宽度）。如果保持为`None`，则不会调整预测大小。'
- en: Returns
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[torch.Tensor]`'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[torch.Tensor]`'
- en: A list of length `batch_size`, where each item is a semantic segmentation map
    of shape (height, width) corresponding to the target_sizes entry (if `target_sizes`
    is specified). Each entry of each `torch.Tensor` correspond to a semantic class
    id.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 长度为`batch_size`的列表，其中每个项目是形状为`(height, width)`的语义分割图，对应于`target_sizes`条目（如果指定了`target_sizes`）。每个`torch.Tensor`的每个条目对应于一个语义类别id。
- en: Converts the output of [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    into semantic segmentation maps. Only supports PyTorch.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 将 [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    的输出转换为语义分割图。仅支持 PyTorch。
- en: '#### `post_process_instance_segmentation`'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_instance_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1079)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1079)'
- en: '[PRE15]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` ([MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation))
    — Raw outputs of the model.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs` ([MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation))
    — 模型的原始输出。'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The probability score
    threshold to keep predicted instance masks.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`, *optional*, defaults to 0.5) — 保留预测实例掩模的概率分数阈值。'
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — 将预测掩模转换为二进制值时使用的阈值。'
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — The
    overlap mask area threshold to merge or discard small disconnected parts within
    each binary instance mask.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — 合并或丢弃每个二进制实例掩模中的小断开部分的重叠掩模区域阈值。'
- en: '`target_sizes` (`List[Tuple]`, *optional*) — List of length (batch_size), where
    each list item (`Tuple[int, int]]`) corresponds to the requested final size (height,
    width) of each prediction. If left to None, predictions will not be resized.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes` (`List[Tuple]`, *optional*) — 长度为 (batch_size) 的列表，其中每个列表项 (`Tuple[int,
    int]]`) 对应于每个预测的请求的请求最终大小（高度，宽度）。如果保持为 None，则不会调整预测大小。'
- en: '`return_coco_annotation` (`bool`, *optional*, defaults to `False`) — If set
    to `True`, segmentation maps are returned in COCO run-length encoding (RLE) format.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_coco_annotation` (`bool`, *optional*, defaults to `False`) — 如果设置为
    `True`，则以 COCO run-length 编码（RLE）格式返回分割图。'
- en: '`return_binary_maps` (`bool`, *optional*, defaults to `False`) — If set to
    `True`, segmentation maps are returned as a concatenated tensor of binary segmentation
    maps (one per detected instance).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_binary_maps` (`bool`, *optional*, defaults to `False`) — 如果设置为 `True`，则分割图将作为二进制分割图的连接张量返回（每个检测到的实例一个）。'
- en: Returns
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: 'A list of dictionaries, one per image, each dictionary containing two keys:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个图像一个字典，每个字典包含两个键：
- en: '`segmentation` — A tensor of shape `(height, width)` where each pixel represents
    a `segment_id` or `List[List]` run-length encoding (RLE) of the segmentation map
    if return_coco_annotation is set to `True`. Set to `None` if no mask if found
    above `threshold`.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation` — 形状为 `(height, width)` 的张量，其中每个像素表示 `segment_id` 或分割图的 `List[List]`
    run-length 编码（RLE），如果 return_coco_annotation 设置为 `True`。如果未找到高于 `threshold` 的掩模，则设置为
    `None`。'
- en: '`segments_info` — A dictionary that contains additional information on each
    segment.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segments_info` — 包含每个段的其他信息的字典。'
- en: '`id` — An integer representing the `segment_id`.'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` — 表示 `segment_id` 的整数。'
- en: '`label_id` — An integer representing the label / semantic class id corresponding
    to `segment_id`.'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_id` — 表示与 `segment_id` 对应的标签 / 语义类别 ID 的整数。'
- en: '`score` — Prediction score of segment with `segment_id`.'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score` — 具有 `segment_id` 的段的预测分数。'
- en: Converts the output of `MaskFormerForInstanceSegmentationOutput` into instance
    segmentation predictions. Only supports PyTorch.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `MaskFormerForInstanceSegmentationOutput` 的输出转换为实例分割预测。仅支持 PyTorch。
- en: '#### `post_process_panoptic_segmentation`'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_panoptic_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1193)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/image_processing_maskformer.py#L1193)'
- en: '[PRE16]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` (`MaskFormerForInstanceSegmentationOutput`) — The outputs from [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs` (`MaskFormerForInstanceSegmentationOutput`) — 来自 [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    的输出。'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The probability score
    threshold to keep predicted instance masks.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`, *optional*, defaults to 0.5) — 保留预测实例掩模的概率分数阈值。'
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — 将预测掩模转换为二进制值时使用的阈值。'
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — The
    overlap mask area threshold to merge or discard small disconnected parts within
    each binary instance mask.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — 合并或丢弃每个二进制实例掩模中的小断开部分的重叠掩模区域阈值。'
- en: '`label_ids_to_fuse` (`Set[int]`, *optional*) — The labels in this state will
    have all their instances be fused together. For instance we could say there can
    only be one sky in an image, but several persons, so the label ID for sky would
    be in that set, but not the one for person.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_ids_to_fuse` (`Set[int]`, *optional*) — 此状态中的标签将使其所有实例被融合在一起。例如，我们可以说图像中只能有一个天空，但可以有几个人，因此天空的标签
    ID 将在该集合中，但人的标签 ID 不在其中。'
- en: '`target_sizes` (`List[Tuple]`, *optional*) — List of length (batch_size), where
    each list item (`Tuple[int, int]]`) corresponds to the requested final size (height,
    width) of each prediction in batch. If left to None, predictions will not be resized.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes` (`List[Tuple]`, *optional*) — 长度为 (batch_size) 的列表，其中每个列表项 (`Tuple[int,
    int]]`) 对应于批处理中每个预测的请求的最终大小（高度，宽度）。如果保持为 None，则不会调整预测大小。'
- en: Returns
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: 'A list of dictionaries, one per image, each dictionary containing two keys:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个图像一个字典，每个字典包含两个键：
- en: '`segmentation` — a tensor of shape `(height, width)` where each pixel represents
    a `segment_id`, set to `None` if no mask if found above `threshold`. If `target_sizes`
    is specified, segmentation is resized to the corresponding `target_sizes` entry.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation` - 形状为`(height, width)`的张量，其中每个像素表示一个`segment_id`，如果未找到高于`threshold`的掩码，则设置为`None`。如果指定了`target_sizes`，则将分割调整为相应的`target_sizes`条目。'
- en: '`segments_info` — A dictionary that contains additional information on each
    segment.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segments_info` - 包含每个段的其他信息的字典。'
- en: '`id` — an integer representing the `segment_id`.'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` - 表示`segment_id`的整数。'
- en: '`label_id` — An integer representing the label / semantic class id corresponding
    to `segment_id`.'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_id` - 表示与`segment_id`对应的标签/语义类别id的整数。'
- en: '`was_fused` — a boolean, `True` if `label_id` was in `label_ids_to_fuse`, `False`
    otherwise. Multiple instances of the same class / label were fused and assigned
    a single `segment_id`.'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`was_fused` - 一个布尔值，如果`label_id`在`label_ids_to_fuse`中，则为`True`，否则为`False`。同一类别/标签的多个实例被融合并分配一个单一的`segment_id`。'
- en: '`score` — Prediction score of segment with `segment_id`.'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score` - 具有`segment_id`的段的预测分数。'
- en: Converts the output of `MaskFormerForInstanceSegmentationOutput` into image
    panoptic segmentation predictions. Only supports PyTorch.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 将`MaskFormerForInstanceSegmentationOutput`的输出转换为图像全景分割预测。仅支持PyTorch。
- en: MaskFormerModel
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormerModel
- en: '### `class transformers.MaskFormerModel`'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MaskFormerModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1597)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1597)'
- en: '[PRE17]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)）-
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare MaskFormer Model outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的MaskFormer模型输出原始隐藏状态，没有特定的头部。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1611)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1611)'
- en: '[PRE18]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [MaskFormerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.__call__)
    for details.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）-
    像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅[MaskFormerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.__call__)。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask`（形状为`(batch_size, height, width)`的`torch.LongTensor`，*可选*）- 避免在填充像素值上执行注意力的掩码。选择的掩码值在`[0,
    1]`范围内：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示真实像素（即`未遮罩`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示填充像素（即`已遮罩`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力掩码是什么？
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of Detr’s decoder attention layers.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回Detr解码器注意力层的注意力张量。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a `~MaskFormerModelOutput`
    instead of a plain tuple.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回`~MaskFormerModelOutput`而不是普通元组。'
- en: Returns
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig))
    and inputs.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerModelOutput)或`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含根据配置（[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)）和输入的各种元素。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Last hidden states (final feature map) of the last stage of
    the encoder model (backbone).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — 编码器模型（骨干）最后阶段的隐藏状态（最终特征图）。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — Last hidden states (final feature map) of the
    last stage of the pixel decoder model (FPN).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — 像素解码器模型（FPN）最后阶段的隐藏状态（最终特征图）。'
- en: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    sequence_length, hidden_size)`) — Last hidden states (final feature map) of the
    last stage of the transformer decoder model.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    sequence_length, hidden_size)`) — 变压器解码器模型最后阶段的隐藏状态（最终特征图）。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the encoder model at the output of
    each stage.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。编码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*,
    returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the transformer decoder at the output
    of each stage.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。变压器解码器在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`hidden_states` `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    containing `encoder_hidden_states`, `pixel_decoder_hidden_states` and `decoder_hidden_states`'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` `tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 包含`encoder_hidden_states`、`pixel_decoder_hidden_states`和`decoder_hidden_states`的`torch.FloatTensor`元组'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights from Detr’s decoder after the attention softmax, used to compute
    the weighted average in the self-attention heads.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 包含每个层的`torch.FloatTensor`元组，形状为`(batch_size, num_heads, sequence_length, sequence_length)`。Detr解码器在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: The [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    forward method, overrides the `__call__` special method.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE19]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: MaskFormerForInstanceSegmentation
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormerForInstanceSegmentation
- en: '### `class transformers.MaskFormerForInstanceSegmentation`'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MaskFormerForInstanceSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1700)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1700)'
- en: '[PRE20]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `forward`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1795)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/maskformer/modeling_maskformer.py#L1795)'
- en: '[PRE21]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [MaskFormerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.__call__)
    for details.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。有关详细信息，请参阅[MaskFormerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor.__call__)。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`，*可选*)
    — 用于避免在填充像素值上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表真实像素（即`未被遮蔽`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于填充像素为0（即`masked`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of Detr’s decoder attention layers.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回Detr解码器注意力层的注意力张量。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a `~MaskFormerModelOutput`
    instead of a plain tuple.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回`~MaskFormerModelOutput`而不是普通元组。'
- en: '`mask_labels` (`List[torch.Tensor]`, *optional*) — List of mask labels of shape
    `(num_labels, height, width)` to be fed to a model'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_labels` (`List[torch.Tensor]`, *可选*) — 形状为`(num_labels, height, width)`的掩码标签列表，用于馈送给模型。'
- en: '`class_labels` (`List[torch.LongTensor]`, *optional*) — list of target class
    labels of shape `(num_labels, height, width)` to be fed to a model. They identify
    the labels of `mask_labels`, e.g. the label of `mask_labels[i][j]` if `class_labels[i][j]`.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels` (`List[torch.LongTensor]`, *可选*) — 形状为`(num_labels, height,
    width)`的目标类标签列表，用于馈送给模型。它们标识`mask_labels`的标签，例如`class_labels[i][j]`的标签是`mask_labels[i][j]`的标签。'
- en: Returns
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig))
    and inputs.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.models.maskformer.modeling_maskformer.MaskFormerForInstanceSegmentationOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)）和输入的各种元素。
- en: '`loss` (`torch.Tensor`, *optional*) — The computed loss, returned when labels
    are present.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.Tensor`, *可选*) — 计算的损失，在存在标签时返回。'
- en: '`class_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, num_labels + 1)` representing the proposed classes for each query.
    Note the `+ 1` is needed because we incorporate the null class.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_queries_logits` (`torch.FloatTensor`) — 形状为`(batch_size, num_queries,
    num_labels + 1)`的张量，表示每个查询的提议类别。注意`+ 1`是因为我们包含了空类。'
- en: '`masks_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, height, width)` representing the proposed masks for each query.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_queries_logits` (`torch.FloatTensor`) — 形状为`(batch_size, num_queries,
    height, width)`的张量，表示每个查询的提议掩码。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Last hidden states (final feature map) of the last stage of
    the encoder model (backbone).'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — 编码器模型（骨干）最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — Last hidden states (final feature map) of the
    last stage of the pixel decoder model (FPN).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — 最后一个阶段像素解码器模型（FPN）的最后隐藏状态（最终特征图）。'
- en: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    sequence_length, hidden_size)`) — Last hidden states (final feature map) of the
    last stage of the transformer decoder model.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    sequence_length, hidden_size)`) — 变压器解码器模型最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the encoder model at the output of
    each stage.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。编码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*,
    returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the transformer decoder at the output of each stage.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。变压器解码器在每个阶段输出的隐藏状态。'
- en: '`hidden_states` `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    containing `encoder_hidden_states`, `pixel_decoder_hidden_states` and `decoder_hidden_states`.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    containing `encoder_hidden_states`, `pixel_decoder_hidden_states` and `decoder_hidden_states`.'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights from Detr’s decoder after the attention softmax, used to compute
    the weighted average in the self-attention heads.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights from Detr’s decoder after the attention softmax, used to compute
    the weighted average in the self-attention heads.'
- en: The [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    forward method, overrides the `__call__` special method.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Examples:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'Semantic segmentation example:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割示例：
- en: '[PRE22]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Panoptic segmentation example:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 全景分割示例：
- en: '[PRE23]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
