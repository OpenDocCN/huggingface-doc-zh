- en: Textual Inversion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åè½¬
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Textual Inversion](https://hf.co/papers/2208.01618) is a training technique
    for personalizing image generation models with just a few example images of what
    you want it to learn. This technique works by learning and updating the text embeddings
    (the new embeddings are tied to a special word you must use in the prompt) to
    match the example images you provide.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Textual Inversion](https://hf.co/papers/2208.01618)æ˜¯ä¸€ç§è®­ç»ƒæŠ€æœ¯ï¼Œç”¨äºä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œåªéœ€æä¾›å‡ ä¸ªç¤ºä¾‹å›¾åƒï¼Œè®©æ¨¡å‹å­¦ä¹ ã€‚è¯¥æŠ€æœ¯é€šè¿‡å­¦ä¹ å’Œæ›´æ–°æ–‡æœ¬åµŒå…¥ï¼ˆæ–°åµŒå…¥ä¸æ‚¨åœ¨æç¤ºä¸­å¿…é¡»ä½¿ç”¨çš„ç‰¹æ®Šå•è¯ç›¸å…³è”ï¼‰æ¥åŒ¹é…æ‚¨æä¾›çš„ç¤ºä¾‹å›¾åƒã€‚'
- en: If youâ€™re training on a GPU with limited vRAM, you should try enabling the `gradient_checkpointing`
    and `mixed_precision` parameters in the training command. You can also reduce
    your memory footprint by using memory-efficient attention with [xFormers](../optimization/xformers).
    JAX/Flax training is also supported for efficient training on TPUs and GPUs, but
    it doesnâ€™t support gradient checkpointing or xFormers. With the same configuration
    and setup as PyTorch, the Flax training script should be at least ~70% faster!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨åœ¨å…·æœ‰æœ‰é™vRAMçš„GPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ‚¨åº”è¯¥å°è¯•åœ¨è®­ç»ƒå‘½ä»¤ä¸­å¯ç”¨`gradient_checkpointing`å’Œ`mixed_precision`å‚æ•°ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡ä½¿ç”¨[xFormers](../optimization/xformers)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æ¥å‡å°‘å†…å­˜å ç”¨ã€‚JAX/Flaxè®­ç»ƒä¹Ÿæ”¯æŒåœ¨TPUå’ŒGPUä¸Šè¿›è¡Œé«˜æ•ˆè®­ç»ƒï¼Œä½†ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹æˆ–xFormersã€‚ä¸PyTorchç›¸åŒçš„é…ç½®å’Œè®¾ç½®ï¼ŒFlaxè®­ç»ƒè„šæœ¬åº”è‡³å°‘å¿«çº¦70%ï¼
- en: This guide will explore the [textual_inversion.py](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†æ¢è®¨[textual_inversion.py](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)è„šæœ¬ï¼Œå¸®åŠ©æ‚¨æ›´ç†Ÿæ‚‰å®ƒï¼Œå¹¶äº†è§£å¦‚ä½•ä¸ºè‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨ä»æºä»£ç å®‰è£…åº“ï¼š
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Navigate to the example folder with the training script and install the required
    dependencies for the script youâ€™re using:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ‚¨æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š
- en: PyTorchFlax
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ğŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Accelerateæ˜¯ä¸€ä¸ªåº“ï¼Œå¯ä»¥å¸®åŠ©æ‚¨åœ¨å¤šä¸ªGPU/TPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œæˆ–è€…ä½¿ç”¨æ··åˆç²¾åº¦ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤— Accelerate
    [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚
- en: 'Initialize an ğŸ¤— Accelerate environment:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–ğŸ¤— Accelerateç¯å¢ƒï¼š
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default ğŸ¤— Accelerate environment without choosing any configurations:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è®¾ç½®é»˜è®¤çš„ğŸ¤— Accelerateç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesnâ€™t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼shellï¼Œæ¯”å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the script
    in detail. If youâ€™re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)
    and let us know if you have any questions or concerns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹éƒ¨åˆ†çªå‡ºæ˜¾ç¤ºäº†è®­ç»ƒè„šæœ¬çš„é‡è¦éƒ¨åˆ†ï¼Œæœ‰åŠ©äºäº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)ï¼Œå¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ã€‚
- en: Script parameters
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è„šæœ¬å‚æ•°
- en: The training script has many parameters to help you tailor the training run
    to your needs. All of the parameters and their descriptions are listed in the
    [`parse_args()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L176)
    function. Where applicable, Diffusers provides default values for each parameter
    such as the training batch size and learning rate, but feel free to change these
    values in the training command if youâ€™d like.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬æœ‰è®¸å¤šå‚æ•°ï¼Œå¯å¸®åŠ©æ‚¨æ ¹æ®éœ€è¦å®šåˆ¶è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½åˆ—åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L176)å‡½æ•°ä¸­ã€‚åœ¨é€‚ç”¨çš„æƒ…å†µä¸‹ï¼ŒDiffusersä¸ºæ¯ä¸ªå‚æ•°æä¾›é»˜è®¤å€¼ï¼Œå¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ›´æ”¹è¿™äº›å€¼ã€‚
- en: 'For example, to increase the number of gradient accumulation steps above the
    default value of 1:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¦å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œè¶…è¿‡é»˜è®¤å€¼1ï¼š
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Some other basic and important parameters to specify include:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€äº›å…¶ä»–åŸºæœ¬å’Œé‡è¦çš„å‚æ•°éœ€è¦æŒ‡å®šï¼š
- en: '`--pretrained_model_name_or_path`: the name of the model on the Hub or a local
    path to the pretrained model'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--pretrained_model_name_or_path`: Hubä¸Šæ¨¡å‹çš„åç§°æˆ–é¢„è®­ç»ƒæ¨¡å‹çš„æœ¬åœ°è·¯å¾„'
- en: '`--train_data_dir`: path to a folder containing the training dataset (example
    images)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--train_data_dir`: æŒ‡å‘åŒ…å«è®­ç»ƒæ•°æ®é›†ï¼ˆä¾‹å¦‚å›¾åƒï¼‰çš„æ–‡ä»¶å¤¹è·¯å¾„'
- en: '`--output_dir`: where to save the trained model'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_dir`: ä¿å­˜è®­ç»ƒæ¨¡å‹çš„ä½ç½®'
- en: '`--push_to_hub`: whether to push the trained model to the Hub'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--push_to_hub`: æ˜¯å¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ°Hub'
- en: '`--checkpointing_steps`: frequency of saving a checkpoint as the model trains;
    this is useful if for some reason training is interrupted, you can continue training
    from that checkpoint by adding `--resume_from_checkpoint` to your training command'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--checkpointing_steps`: ä¿å­˜æ£€æŸ¥ç‚¹çš„é¢‘ç‡ï¼Œå½“æ¨¡å‹è®­ç»ƒæ—¶ï¼›å¦‚æœç”±äºæŸç§åŸå› è®­ç»ƒä¸­æ–­ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--resume_from_checkpoint`æ¥ä»è¯¥æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ'
- en: '`--num_vectors`: the number of vectors to learn the embeddings with; increasing
    this parameter helps the model learn better but it comes with increased training
    costs'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_vectors`ï¼šè¦å­¦ä¹ åµŒå…¥çš„å‘é‡æ•°é‡ï¼›å¢åŠ æ­¤å‚æ•°æœ‰åŠ©äºæ¨¡å‹å­¦ä¹ æ›´å¥½ï¼Œä½†ä¼šå¢åŠ è®­ç»ƒæˆæœ¬'
- en: '`--placeholder_token`: the special word to tie the learned embeddings to (you
    must use the word in your prompt for inference)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--placeholder_token`ï¼šå°†å­¦ä¹ çš„åµŒå…¥ä¸ä¹‹å…³è”çš„ç‰¹æ®Šå•è¯ï¼ˆæ‚¨å¿…é¡»åœ¨æ¨ç†ä¸­ä½¿ç”¨è¯¥å•è¯ï¼‰'
- en: '`--initializer_token`: a single-word that roughly describes the object or style
    youâ€™re trying to train on'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--initializer_token`ï¼šå¤§è‡´æè¿°æ‚¨è¦è®­ç»ƒçš„å¯¹è±¡æˆ–é£æ ¼çš„å•è¯'
- en: '`--learnable_property`: whether youâ€™re training the model to learn a new â€œstyleâ€
    (for example, Van Goghâ€™s painting style) or â€œobjectâ€ (for example, your dog)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--learnable_property`ï¼šæ‚¨æ˜¯å¦æ­£åœ¨è®­ç»ƒæ¨¡å‹å­¦ä¹ æ–°çš„â€œé£æ ¼â€ï¼ˆä¾‹å¦‚ï¼Œæ¢µé«˜çš„ç»˜ç”»é£æ ¼ï¼‰æˆ–â€œå¯¹è±¡â€ï¼ˆä¾‹å¦‚ï¼Œæ‚¨çš„ç‹—ï¼‰'
- en: Training script
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬
- en: Unlike some of the other training scripts, textual_inversion.py has a custom
    dataset class, [`TextualInversionDataset`](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L487)
    for creating a dataset. You can customize the image size, placeholder token, interpolation
    method, whether to crop the image, and more. If you need to change how the dataset
    is created, you can modify `TextualInversionDataset`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–ä¸€äº›è®­ç»ƒè„šæœ¬ä¸åŒï¼Œtextual_inversion.pyå…·æœ‰ä¸€ä¸ªè‡ªå®šä¹‰æ•°æ®é›†ç±»ï¼Œ[`TextualInversionDataset`](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L487)ç”¨äºåˆ›å»ºæ•°æ®é›†ã€‚æ‚¨å¯ä»¥è‡ªå®šä¹‰å›¾åƒå¤§å°ã€å ä½ç¬¦æ ‡è®°ã€æ’å€¼æ–¹æ³•ã€æ˜¯å¦è£å‰ªå›¾åƒç­‰ã€‚å¦‚æœæ‚¨éœ€è¦æ›´æ”¹æ•°æ®é›†çš„åˆ›å»ºæ–¹å¼ï¼Œå¯ä»¥ä¿®æ”¹`TextualInversionDataset`ã€‚
- en: Next, youâ€™ll find the dataset preprocessing code and training loop in the [`main()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L573)
    function.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæ‚¨å°†åœ¨[`main()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L573)å‡½æ•°ä¸­æ‰¾åˆ°æ•°æ®é›†é¢„å¤„ç†ä»£ç å’Œè®­ç»ƒå¾ªç¯ã€‚
- en: 'The script starts by loading the [tokenizer](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L616),
    [scheduler and model](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L622):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è„šæœ¬é¦–å…ˆåŠ è½½[tokenizer](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L616)ã€[schedulerå’Œmodel](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L622)ï¼š
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The special [placeholder token](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L632)
    is added next to the tokenizer, and the embedding is readjusted to account for
    the new token.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥åœ¨tokenizeræ—è¾¹æ·»åŠ ç‰¹æ®Šçš„[å ä½ç¬¦æ ‡è®°](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L632)ï¼Œå¹¶è°ƒæ•´åµŒå…¥ä»¥è€ƒè™‘æ–°æ ‡è®°ã€‚
- en: 'Then, the script [creates a dataset](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L716)
    from the `TextualInversionDataset`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œè„šæœ¬ä»`TextualInversionDataset`ä¸­[åˆ›å»ºæ•°æ®é›†](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L716)ï¼š
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finally, the [training loop](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L784)
    handles everything else from predicting the noisy residual to updating the embedding
    weights of the special placeholder token.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L784)å¤„ç†ä»é¢„æµ‹å˜ˆæ‚æ®‹å·®åˆ°æ›´æ–°ç‰¹æ®Šå ä½ç¬¦æ ‡è®°çš„åµŒå…¥æƒé‡çš„æ‰€æœ‰å…¶ä»–å†…å®¹ã€‚
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers](../using-diffusers/write_own_pipeline) tutorial
    which breaks down the basic pattern of the denoising process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[ç†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨](../using-diffusers/write_own_pipeline)æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è§£é‡Šäº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚
- en: Launch the script
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯åŠ¨è„šæœ¬
- en: Once youâ€™ve made all your changes or youâ€™re okay with the default configuration,
    youâ€™re ready to launch the training script! ğŸš€
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨å®Œæˆäº†æ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€
- en: For this guide, youâ€™ll download some images of a [cat toy](https://huggingface.co/datasets/diffusers/cat_toy_example)
    and store them in a directory. But remember, you can create and use your own dataset
    if you want (see the [Create a dataset for training](create_dataset) guide).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæœ¬æŒ‡å—ï¼Œæ‚¨å°†ä¸‹è½½ä¸€äº›[çŒ«ç©å…·çš„å›¾åƒ](https://huggingface.co/datasets/diffusers/cat_toy_example)å¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªç›®å½•ä¸­ã€‚ä½†è¯·è®°ä½ï¼Œå¦‚æœæ‚¨æ„¿æ„ï¼Œæ‚¨å¯ä»¥åˆ›å»ºå¹¶ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼ˆè¯·å‚é˜…[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼‰ã€‚
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set the environment variable `MODEL_NAME` to a model id on the Hub or a path
    to a local model, and `DATA_DIR` to the path where you just downloaded the cat
    images to. The script creates and saves the following files to your repository:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç¯å¢ƒå˜é‡`MODEL_NAME`è®¾ç½®ä¸ºHubä¸Šçš„æ¨¡å‹IDæˆ–æœ¬åœ°æ¨¡å‹çš„è·¯å¾„ï¼Œå¹¶å°†`DATA_DIR`è®¾ç½®ä¸ºæ‚¨åˆšä¸‹è½½çŒ«å›¾åƒçš„è·¯å¾„ã€‚è„šæœ¬å°†ä»¥ä¸‹æ–‡ä»¶åˆ›å»ºå¹¶ä¿å­˜åˆ°æ‚¨çš„å­˜å‚¨åº“ä¸­ï¼š
- en: '`learned_embeds.bin`: the learned embedding vectors corresponding to your example
    images'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learned_embeds.bin`ï¼šä¸æ‚¨çš„ç¤ºä¾‹å›¾åƒå¯¹åº”çš„å­¦ä¹ åµŒå…¥å‘é‡'
- en: '`token_identifier.txt`: the special placeholder token'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_identifier.txt`ï¼šç‰¹æ®Šçš„å ä½ç¬¦æ ‡è®°'
- en: '`type_of_concept.txt`: the type of concept youâ€™re training on (either â€œobjectâ€
    or â€œstyleâ€)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_of_concept.txt`ï¼šæ‚¨æ­£åœ¨è®­ç»ƒçš„æ¦‚å¿µç±»å‹ï¼ˆâ€œå¯¹è±¡â€æˆ–â€œé£æ ¼â€ï¼‰'
- en: A full training run takes ~1 hour on a single V100 GPU.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å•ä¸ªV100 GPUä¸Šè¿›è¡Œå®Œæ•´çš„è®­ç»ƒéœ€è¦çº¦1å°æ—¶ã€‚
- en: 'One more thing before you launch the script. If youâ€™re interested in following
    along with the training process, you can periodically save generated images as
    training progresses. Add the following parameters to the training command:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯åŠ¨è„šæœ¬ä¹‹å‰è¿˜æœ‰ä¸€ä»¶äº‹ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£è·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹ï¼Œæ‚¨å¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸä¿å­˜ç”Ÿæˆçš„å›¾åƒã€‚å°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: PyTorchFlax
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After training is complete, you can use your newly trained model for inference
    like:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥åƒè¿™æ ·ä½¿ç”¨æ‚¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š
- en: PyTorchFlax
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next steps
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥
- en: 'Congratulations on training your own Textual Inversion model! ğŸ‰ To learn more
    about how to use your new model, the following guides may be helpful:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œæ‚¨è®­ç»ƒå‡ºè‡ªå·±çš„æ–‡æœ¬åè½¬æ¨¡å‹ï¼ğŸ‰ è¦äº†è§£å¦‚ä½•ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ï¼Œä»¥ä¸‹æŒ‡å—å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š
- en: Learn how to [load Textual Inversion embeddings](../using-diffusers/loading_adapters)
    and also use them as negative embeddings.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¦‚ä½•[åŠ è½½æ–‡æœ¬åè½¬åµŒå…¥](../using-diffusers/loading_adapters)ï¼Œå¹¶å°†å…¶ç”¨ä½œè´ŸåµŒå…¥ã€‚
- en: Learn how to use [Textual Inversion](textual_inversion_inference) for inference
    with Stable Diffusion 1/2 and Stable Diffusion XL.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¦‚ä½•ä½¿ç”¨[æ–‡æœ¬åè½¬](textual_inversion_inference)è¿›è¡Œæ¨ç†ï¼ŒåŒ…æ‹¬ Stable Diffusion 1/2 å’Œ Stable
    Diffusion XLã€‚
