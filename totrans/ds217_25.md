# æœç´¢ç´¢å¼•

> åŽŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/datasets/faiss_es](https://huggingface.co/docs/datasets/faiss_es)

[FAISS](https://github.com/facebookresearch/faiss)å’Œ[Elasticsearch](https://www.elastic.co/elasticsearch/)ä½¿å¾—åœ¨æ•°æ®é›†ä¸­æœç´¢ç¤ºä¾‹æˆä¸ºå¯èƒ½ã€‚å½“æ‚¨æƒ³è¦ä»Žæ•°æ®é›†ä¸­æ£€ç´¢ä¸Žæ‚¨çš„NLPä»»åŠ¡ç›¸å…³çš„ç‰¹å®šç¤ºä¾‹æ—¶ï¼Œè¿™å¯èƒ½éžå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æžœæ‚¨æ­£åœ¨å¤„ç†å¼€æ”¾åŸŸé—®ç­”ä»»åŠ¡ï¼Œæ‚¨å¯èƒ½åªæƒ³è¿”å›žä¸Žå›žç­”æ‚¨é—®é¢˜ç›¸å…³çš„ç¤ºä¾‹ã€‚

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä¸ºæ‚¨çš„æ•°æ®é›†æž„å»ºä¸€ä¸ªç´¢å¼•ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥å¯¹å…¶è¿›è¡Œæœç´¢ã€‚

## FAISS

FAISSæ ¹æ®å…¶å‘é‡è¡¨ç¤ºçš„ç›¸ä¼¼æ€§æ£€ç´¢æ–‡æ¡£ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨[DPR](https://huggingface.co/transformers/model_doc/dpr.html)æ¨¡åž‹ç”Ÿæˆå‘é‡è¡¨ç¤ºã€‚

1.  ä»ŽðŸ¤— Transformersä¸‹è½½DPRæ¨¡åž‹ï¼š

```py
>>> from transformers import DPRContextEncoder, DPRContextEncoderTokenizer
>>> import torch
>>> torch.set_grad_enabled(False)
>>> ctx_encoder = DPRContextEncoder.from_pretrained("facebook/dpr-ctx_encoder-single-nq-base")
>>> ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained("facebook/dpr-ctx_encoder-single-nq-base")
```

1.  åŠ è½½æ‚¨çš„æ•°æ®é›†å¹¶è®¡ç®—å‘é‡è¡¨ç¤ºï¼š

```py
>>> from datasets import load_dataset
>>> ds = load_dataset('crime_and_punish', split='train[:100]')
>>> ds_with_embeddings = ds.map(lambda example: {'embeddings': ctx_encoder(**ctx_tokenizer(example["line"], return_tensors="pt"))[0][0].numpy()})
```

1.  ä½¿ç”¨[Dataset.add_faiss_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.add_faiss_index)åˆ›å»ºç´¢å¼•ï¼š

```py
>>> ds_with_embeddings.add_faiss_index(column='embeddings')
```

1.  çŽ°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨`embeddings`ç´¢å¼•æŸ¥è¯¢æ‚¨çš„æ•°æ®é›†ã€‚åŠ è½½DPRé—®é¢˜ç¼–ç å™¨ï¼Œå¹¶ä½¿ç”¨[Dataset.get_nearest_examples()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.get_nearest_examples)æœç´¢é—®é¢˜ï¼š

```py
>>> from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer
>>> q_encoder = DPRQuestionEncoder.from_pretrained("facebook/dpr-question_encoder-single-nq-base")
>>> q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained("facebook/dpr-question_encoder-single-nq-base")

>>> question = "Is it serious ?"
>>> question_embedding = q_encoder(**q_tokenizer(question, return_tensors="pt"))[0][0].numpy()
>>> scores, retrieved_examples = ds_with_embeddings.get_nearest_examples('embeddings', question_embedding, k=10)
>>> retrieved_examples["line"][0]
'_that_ serious? It is not serious at all. Itâ€™s simply a fantasy to amuse\r\n'
```

1.  æ‚¨å¯ä»¥ä½¿ç”¨[Dataset.get_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.get_index)è®¿é—®ç´¢å¼•ï¼Œå¹¶å°†å…¶ç”¨äºŽç‰¹æ®Šæ“ä½œï¼Œä¾‹å¦‚ä½¿ç”¨`range_search`è¿›è¡ŒæŸ¥è¯¢ï¼š

```py
>>> faiss_index = ds_with_embeddings.get_index('embeddings').faiss_index
>>> limits, distances, indices = faiss_index.range_search(x=question_embedding.reshape(1, -1), thresh=0.95)
```

1.  å½“æ‚¨å®ŒæˆæŸ¥è¯¢æ—¶ï¼Œè¯·ä½¿ç”¨[Dataset.save_faiss_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_faiss_index)å°†ç´¢å¼•ä¿å­˜åœ¨ç£ç›˜ä¸Šï¼š

```py
>>> ds_with_embeddings.save_faiss_index('embeddings', 'my_index.faiss')
```

1.  ç¨åŽä½¿ç”¨[Dataset.load_faiss_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.load_faiss_index)é‡æ–°åŠ è½½å®ƒï¼š

```py
>>> ds = load_dataset('crime_and_punish', split='train[:100]')
>>> ds.load_faiss_index('embeddings', 'my_index.faiss')
```

## Elasticsearch

ä¸ŽFAISSä¸åŒï¼ŒElasticsearchæ ¹æ®ç²¾ç¡®åŒ¹é…æ£€ç´¢æ–‡æ¡£ã€‚

åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šå¯åŠ¨Elasticsearchï¼Œæˆ–è€…æŸ¥çœ‹[Elasticsearchå®‰è£…æŒ‡å—](https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html)å¦‚æžœæ‚¨å°šæœªå®‰è£…å®ƒã€‚

1.  åŠ è½½æ‚¨æƒ³è¦ç´¢å¼•çš„æ•°æ®é›†ï¼š

```py
>>> from datasets import load_dataset
>>> squad = load_dataset('squad', split='validation')
```

1.  ä½¿ç”¨[Dataset.add_elasticsearch_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.add_elasticsearch_index)æž„å»ºç´¢å¼•ï¼š

```py
>>> squad.add_elasticsearch_index("context", host="localhost", port="9200")
```

1.  ç„¶åŽæ‚¨å¯ä»¥ä½¿ç”¨[Dataset.get_nearest_examples()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.get_nearest_examples)æŸ¥è¯¢`context`ç´¢å¼•ï¼š

```py
>>> query = "machine"
>>> scores, retrieved_examples = squad.get_nearest_examples("context", query, k=10)
>>> retrieved_examples["title"][0]
'Computational_complexity_theory'
```

1.  å¦‚æžœæ‚¨æƒ³é‡å¤ä½¿ç”¨ç´¢å¼•ï¼Œè¯·åœ¨æž„å»ºç´¢å¼•æ—¶å®šä¹‰`es_index_name`å‚æ•°ï¼š

```py
>>> from datasets import load_dataset
>>> squad = load_dataset('squad', split='validation')
>>> squad.add_elasticsearch_index("context", host="localhost", port="9200", es_index_name="hf_squad_val_context")
>>> squad.get_index("context").es_index_name
hf_squad_val_context
```

1.  ç¨åŽé‡æ–°åŠ è½½æ—¶ï¼Œè¯·åœ¨è°ƒç”¨[Dataset.load_elasticsearch_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.load_elasticsearch_index)æ—¶æä¾›ç´¢å¼•åç§°ï¼š

```py
>>> from datasets import load_dataset
>>> squad = load_dataset('squad', split='validation')
>>> squad.load_elasticsearch_index("context", host="localhost", port="9200", es_index_name="hf_squad_val_context")
>>> query = "machine"
>>> scores, retrieved_examples = squad.get_nearest_examples("context", query, k=10)
```

å¯¹äºŽæ›´é«˜çº§çš„Elasticsearchç”¨æ³•ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰è®¾ç½®æŒ‡å®šè‡ªå·±çš„é…ç½®ï¼š

```py
>>> import elasticsearch as es
>>> import elasticsearch.helpers
>>> from elasticsearch import Elasticsearch
>>> es_client = Elasticsearch([{"host": "localhost", "port": "9200"}])  # default client
>>> es_config = {
...     "settings": {
...         "number_of_shards": 1,
...         "analysis": {"analyzer": {"stop_standard": {"type": "standard", " stopwords": "_english_"}}},
...     },
...     "mappings": {"properties": {"text": {"type": "text", "analyzer": "standard", "similarity": "BM25"}}},
... }  # default config
>>> es_index_name = "hf_squad_context"  # name of the index in Elasticsearch
>>> squad.add_elasticsearch_index("context", es_client=es_client, es_config=es_config, es_index_name=es_index_name)
```
