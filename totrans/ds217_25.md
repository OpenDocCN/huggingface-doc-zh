# 搜索索引

> 原始文本：[https://huggingface.co/docs/datasets/faiss_es](https://huggingface.co/docs/datasets/faiss_es)

[FAISS](https://github.com/facebookresearch/faiss)和[Elasticsearch](https://www.elastic.co/elasticsearch/)使得在数据集中搜索示例成为可能。当您想要从数据集中检索与您的NLP任务相关的特定示例时，这可能非常有用。例如，如果您正在处理开放域问答任务，您可能只想返回与回答您问题相关的示例。

本指南将向您展示如何为您的数据集构建一个索引，以便您可以对其进行搜索。

## FAISS

FAISS根据其向量表示的相似性检索文档。在此示例中，您将使用[DPR](https://huggingface.co/transformers/model_doc/dpr.html)模型生成向量表示。

1.  从🤗 Transformers下载DPR模型：

```py
>>> from transformers import DPRContextEncoder, DPRContextEncoderTokenizer
>>> import torch
>>> torch.set_grad_enabled(False)
>>> ctx_encoder = DPRContextEncoder.from_pretrained("facebook/dpr-ctx_encoder-single-nq-base")
>>> ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained("facebook/dpr-ctx_encoder-single-nq-base")
```

1.  加载您的数据集并计算向量表示：

```py
>>> from datasets import load_dataset
>>> ds = load_dataset('crime_and_punish', split='train[:100]')
>>> ds_with_embeddings = ds.map(lambda example: {'embeddings': ctx_encoder(**ctx_tokenizer(example["line"], return_tensors="pt"))[0][0].numpy()})
```

1.  使用[Dataset.add_faiss_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.add_faiss_index)创建索引：

```py
>>> ds_with_embeddings.add_faiss_index(column='embeddings')
```

1.  现在您可以使用`embeddings`索引查询您的数据集。加载DPR问题编码器，并使用[Dataset.get_nearest_examples()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.get_nearest_examples)搜索问题：

```py
>>> from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer
>>> q_encoder = DPRQuestionEncoder.from_pretrained("facebook/dpr-question_encoder-single-nq-base")
>>> q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained("facebook/dpr-question_encoder-single-nq-base")

>>> question = "Is it serious ?"
>>> question_embedding = q_encoder(**q_tokenizer(question, return_tensors="pt"))[0][0].numpy()
>>> scores, retrieved_examples = ds_with_embeddings.get_nearest_examples('embeddings', question_embedding, k=10)
>>> retrieved_examples["line"][0]
'_that_ serious? It is not serious at all. It’s simply a fantasy to amuse\r\n'
```

1.  您可以使用[Dataset.get_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.get_index)访问索引，并将其用于特殊操作，例如使用`range_search`进行查询：

```py
>>> faiss_index = ds_with_embeddings.get_index('embeddings').faiss_index
>>> limits, distances, indices = faiss_index.range_search(x=question_embedding.reshape(1, -1), thresh=0.95)
```

1.  当您完成查询时，请使用[Dataset.save_faiss_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_faiss_index)将索引保存在磁盘上：

```py
>>> ds_with_embeddings.save_faiss_index('embeddings', 'my_index.faiss')
```

1.  稍后使用[Dataset.load_faiss_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.load_faiss_index)重新加载它：

```py
>>> ds = load_dataset('crime_and_punish', split='train[:100]')
>>> ds.load_faiss_index('embeddings', 'my_index.faiss')
```

## Elasticsearch

与FAISS不同，Elasticsearch根据精确匹配检索文档。

在您的计算机上启动Elasticsearch，或者查看[Elasticsearch安装指南](https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html)如果您尚未安装它。

1.  加载您想要索引的数据集：

```py
>>> from datasets import load_dataset
>>> squad = load_dataset('squad', split='validation')
```

1.  使用[Dataset.add_elasticsearch_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.add_elasticsearch_index)构建索引：

```py
>>> squad.add_elasticsearch_index("context", host="localhost", port="9200")
```

1.  然后您可以使用[Dataset.get_nearest_examples()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.get_nearest_examples)查询`context`索引：

```py
>>> query = "machine"
>>> scores, retrieved_examples = squad.get_nearest_examples("context", query, k=10)
>>> retrieved_examples["title"][0]
'Computational_complexity_theory'
```

1.  如果您想重复使用索引，请在构建索引时定义`es_index_name`参数：

```py
>>> from datasets import load_dataset
>>> squad = load_dataset('squad', split='validation')
>>> squad.add_elasticsearch_index("context", host="localhost", port="9200", es_index_name="hf_squad_val_context")
>>> squad.get_index("context").es_index_name
hf_squad_val_context
```

1.  稍后重新加载时，请在调用[Dataset.load_elasticsearch_index()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.load_elasticsearch_index)时提供索引名称：

```py
>>> from datasets import load_dataset
>>> squad = load_dataset('squad', split='validation')
>>> squad.load_elasticsearch_index("context", host="localhost", port="9200", es_index_name="hf_squad_val_context")
>>> query = "machine"
>>> scores, retrieved_examples = squad.get_nearest_examples("context", query, k=10)
```

对于更高级的Elasticsearch用法，您可以使用自定义设置指定自己的配置：

```py
>>> import elasticsearch as es
>>> import elasticsearch.helpers
>>> from elasticsearch import Elasticsearch
>>> es_client = Elasticsearch([{"host": "localhost", "port": "9200"}])  # default client
>>> es_config = {
...     "settings": {
...         "number_of_shards": 1,
...         "analysis": {"analyzer": {"stop_standard": {"type": "standard", " stopwords": "_english_"}}},
...     },
...     "mappings": {"properties": {"text": {"type": "text", "analyzer": "standard", "similarity": "BM25"}}},
... }  # default config
>>> es_index_name = "hf_squad_context"  # name of the index in Elasticsearch
>>> squad.add_elasticsearch_index("context", es_client=es_client, es_config=es_config, es_index_name=es_index_name)
```
