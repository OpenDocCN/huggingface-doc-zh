["```py\n>>> from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-ul2\", load_in_8bit=True, device_map=\"auto\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/flan-ul2\")\n\n>>> inputs = tokenizer(\"A step by step recipe to make bolognese pasta:\", return_tensors=\"pt\")\n>>> outputs = model.generate(**inputs)\n>>> print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n['In a large skillet, brown the ground beef and onion over medium heat. Add the garlic']\n```"]