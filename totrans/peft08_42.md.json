["```py\n( peft_type: Union = None auto_mapping: Optional = None base_model_name_or_path: Optional = None revision: Optional = None task_type: Union = None inference_mode: bool = False num_virtual_tokens: int = None token_dim: int = None num_transformer_submodules: Optional = None num_attention_heads: Optional = None num_layers: Optional = None prompt_tuning_init: Union = <MultitaskPromptTuningInit.RANDOM: 'RANDOM'> prompt_tuning_init_text: Optional = None tokenizer_name_or_path: Optional = None tokenizer_kwargs: Optional = None prompt_tuning_init_state_dict_path: Optional = None prompt_tuning_init_task: Optional = 0 num_ranks: Optional = 1 num_tasks: Optional = 1 )\n```", "```py\n( config: MultitaskPromptTuningConfig word_embeddings )\n```"]