- en: ScoreSdeVpScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/score_sde_vp](https://huggingface.co/docs/diffusers/api/schedulers/score_sde_vp)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '`ScoreSdeVpScheduler` is a variance preserving stochastic differential equation
    (SDE) scheduler. It was introduced in the [Score-Based Generative Modeling through
    Stochastic Differential Equations](https://huggingface.co/papers/2011.13456) paper
    by Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano
    Ermon, Ben Poole.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '*Creating noise from data is easy; creating data from noise is generative modeling.
    We present a stochastic differential equation (SDE) that smoothly transforms a
    complex data distribution to a known prior distribution by slowly injecting noise,
    and a corresponding reverse-time SDE that transforms the prior distribution back
    into the data distribution by slowly removing the noise. Crucially, the reverse-time
    SDE depends only on the time-dependent gradient field (\aka, score) of the perturbed
    data distribution. By leveraging advances in score-based generative modeling,
    we can accurately estimate these scores with neural networks, and use numerical
    SDE solvers to generate samples. We show that this framework encapsulates previous
    approaches in score-based generative modeling and diffusion probabilistic modeling,
    allowing for new sampling procedures and new modeling capabilities. In particular,
    we introduce a predictor-corrector framework to correct errors in the evolution
    of the discretized reverse-time SDE. We also derive an equivalent neural ODE that
    samples from the same distribution as the SDE, but additionally enables exact
    likelihood computation, and improved sampling efficiency. In addition, we provide
    a new way to solve inverse problems with score-based models, as demonstrated with
    experiments on class-conditional generation, image inpainting, and colorization.
    Combined with multiple architectural improvements, we achieve record-breaking
    performance for unconditional image generation on CIFAR-10 with an Inception score
    of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate
    high fidelity generation of 1024 x 1024 images for the first time from a score-based
    generative model.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: üöß This scheduler is under construction!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: ScoreSdeVpScheduler
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.schedulers.ScoreSdeVpScheduler`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L27)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '`num_train_timesteps` (`int`, defaults to 2000) ‚Äî The number of diffusion steps
    to train the model.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beta_min` (`int`, defaults to 0.1) ‚Äî'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beta_max` (`int`, defaults to 20) ‚Äî'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sampling_eps` (`int`, defaults to 1e-3) ‚Äî The end value of sampling where
    timesteps decrease progressively from 1 to epsilon.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ScoreSdeVpScheduler` is a variance preserving stochastic differential equation
    (SDE) scheduler.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '#### `set_timesteps`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L51)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`) ‚Äî The number of diffusion steps used when generating
    samples with a pre-trained model.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`str` or `torch.device`, *optional*) ‚Äî The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sets the continuous timesteps used for the diffusion chain (to be run before
    inference).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '#### `step_pred`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L63)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '`score` () ‚Äî'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x` () ‚Äî'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t` () ‚Äî'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) ‚Äî A random number generator.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`Ôºà`torch.Generator`Ôºå*ÂèØÈÄâ*Ôºâ‚Äî ‰∏Ä‰∏™ÈöèÊú∫Êï∞ÁîüÊàêÂô®„ÄÇ'
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ÈÄöËøáÂèçËΩ¨SDEÊù•È¢ÑÊµã‰∏ä‰∏Ä‰∏™Êó∂Èó¥Ê≠•ÁöÑÊ†∑Êú¨„ÄÇËøô‰∏™ÂáΩÊï∞‰ªéÂ≠¶‰π†Ê®°ÂûãÁöÑËæìÂá∫ÔºàÈÄöÂ∏∏ÊòØÈ¢ÑÊµãÁöÑÂô™Èü≥Ôºâ‰∏≠‰º†Êí≠Êâ©Êï£ËøáÁ®ã„ÄÇ
