# VAE 图像处理器

> 原始文本：[`huggingface.co/docs/diffusers/api/image_processor`](https://huggingface.co/docs/diffusers/api/image_processor)

`VaeImageProcessor`为 StableDiffusionPipeline 提供了统一的 API，用于为 VAE 编码准备图像输入并在解码后对输出进行后处理。这包括调整大小、归一化和在 PIL 图像、PyTorch 和 NumPy 数组之间转换。

所有具有`VaeImageProcessor`的管道都接受 PIL 图像、PyTorch 张量或 NumPy 数组作为图像输入，并根据用户的`output_type`参数返回输出。您可以直接将编码的图像潜变量传递给管道，并使用`output_type`参数（例如`output_type="latent"`）从管道返回特定输出的潜变量。这使您可以将一个管道生成的潜变量传递给另一个管道作为输入，而不离开潜变量空间。通过直接在不同管道之间传递 PyTorch 张量，也更容易将多个管道一起使用。

## VaeImageProcessor

### `class diffusers.image_processor.VaeImageProcessor`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L39)

```py
( do_resize: bool = True vae_scale_factor: int = 8 resample: str = 'lanczos' do_normalize: bool = True do_binarize: bool = False do_convert_rgb: bool = False do_convert_grayscale: bool = False )
```

参数

+   `do_resize`（`布尔`，*可选*，默认为`True`）— 是否将图像的（高度，宽度）维度缩小为`vae_scale_factor`的倍数。可以从 image_processor.VaeImageProcessor.preprocess()方法接受`height`和`width`参数。

+   `vae_scale_factor`（`整数`，*可选*，默认为`8`）— VAE 比例因子。如果`do_resize`为`True`，则图像会自动调整大小为此因子的倍数。

+   `resample`（`str`，*可选*，默认为`lanczos`）— 调整图像大小时要使用的重采样滤波器。

+   `do_normalize`（`布尔`，*可选*，默认为`True`）— 是否将图像归一化为[-1,1]。

+   `do_binarize`（`布尔`，*可选*，默认为`False`）— 是否将图像二值化为 0/1。

+   `do_convert_rgb`（`布尔`，*可选*，默认为`False`）— 是否将图像转换为 RGB 格式。

+   `do_convert_grayscale`（`布尔`，*可选*，默认为`False`）— 是否将图像转换为灰度格式。

用于 VAE 的图像处理器。

#### `apply_overlay`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L610)

```py
( mask: Image init_image: Image image: Image crop_coords: Optional = None )
```

将修补输出覆盖到原始图像

#### `binarize`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L384)

```py
( image: Image ) → export const metadata = 'undefined';PIL.Image.Image
```

参数

+   `image`（`PIL.Image.Image`）— 输入图像，应为 PIL 图像。

返回

`PIL.Image.Image`

二值化图像。小于 0.5 的值设为 0，大于 0.5 的值设为 1。

创建一个蒙版。

#### `blur`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L162)

```py
( image: Image blur_factor: int = 4 )
```

将高斯模糊应用于图像。

#### `convert_to_grayscale`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L153)

```py
( image: Image )
```

将 PIL 图像转换为灰度格式。

#### `convert_to_rgb`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L144)

```py
( image: Image )
```

将 PIL 图像转换为 RGB 格式。

#### `denormalize`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L137)

```py
( images: Union )
```

将图像数组反标准化为[0,1]。

#### `get_crop_region`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L171)

```py
( mask_image: Image width: int height: int pad = 0 ) → export const metadata = 'undefined';tuple
```

参数

+   `mask_image`（PIL.Image.Image）— 掩模图像。

+   `width`（整数）— 要处理的图像的宽度。

+   `height`（整数）— 要处理的图像的高度。

+   `pad`（整数，可选）— 要添加到裁剪区域的填充。默认为 0。

返回

元组

（x1，y1，x2，y2）表示包含图像中所有蒙版区域并匹配原始长宽比的矩形区域。

找到一个包含图像中所有蒙版区域并扩展区域以匹配原始图像长宽比的矩形区域；例如，如果用户在一个 128x32 的区域中绘制了蒙版，并且处理的尺寸为 512x512，则该区域将扩展为 128x128。

#### `get_default_height_width`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L401)

```py
( image: Union height: Optional = None width: Optional = None )
```

参数

+   `image(PIL.Image.Image,` `np.ndarray`或`torch.Tensor`) — 图像输入，可以是 PIL 图像、NumPy 数组或 PyTorch 张量。如果是 NumPy 数组，应该具有形状`[batch, height, width]`或`[batch, height, width, channel]`，如果是 PyTorch 张量，应该具有形状`[batch, channel, height, width]`。

+   `height` (`int`, *optional*, defaults to `None`) — 图像的预处理高度。如果为`None`，将使用`image`输入的高度。

+   `width` (`int`, *optional*`, defaults to` None`) -- 预处理中的宽度。如果为`None`，将使用`image`输入的宽度。

此函数返回高度和宽度，这些高度和宽度被缩小到`vae_scale_factor`的下一个整数倍。

#### `normalize`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L130)

```py
( images: Union )
```

将图像数组归一化为[-1,1]。

#### `numpy_to_pil`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L83)

```py
( images: ndarray )
```

将一个 NumPy 图像或一批图像转换为 PIL 图像。

#### `numpy_to_pt`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L111)

```py
( images: ndarray )
```

将 NumPy 图像转换为 PyTorch 张量。

#### `pil_to_numpy`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L99)

```py
( images: Union )
```

将 PIL 图像或一组 PIL 图像转换为 NumPy 数组。

#### `postprocess`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L555)

```py
( image: FloatTensor output_type: str = 'pil' do_denormalize: Optional = None ) → export const metadata = 'undefined';PIL.Image.Image, np.ndarray or torch.FloatTensor
```

参数

+   `image` (`torch.FloatTensor`) — 图像输入，应该是一个形状为`B x C x H x W`的 PyTorch 张量。

+   `output_type` (`str`, *optional*, defaults to `pil`) — 图像的输出类型，可以是`pil`、`np`、`pt`、`latent`中的一个。

+   `do_denormalize` (`List[bool]`, *optional*, defaults to `None`) — 是否将图像反归一化为[0,1]。如果为`None`，将使用`VaeImageProcessor`配置中的`do_normalize`的值。

返回

`PIL.Image.Image`、`np.ndarray`或`torch.FloatTensor`

后处理的图像。

将从张量输出的图像后处理为`output_type`。

#### `preprocess`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L444)

```py
( image: Union height: Optional = None width: Optional = None resize_mode: str = 'default' crops_coords: Optional = None )
```

参数

+   `image` (`pipeline_image_input`) — 图像输入，接受的格式为 PIL 图像、NumPy 数组、PyTorch 张量；也接受支持的格式列表。

+   `height` (`int`, *optional*, defaults to `None`) — 图像的预处理高度。如果为`None`，将使用`get_default_height_width()`获取默认高度。

+   `width` (`int`, *optional*`, defaults to` None`) -- 预处理中的宽度。如果为`None`，将使用`get_default_height_width()`获取默认宽度。

+   `resize_mode` (`str`, *optional*, defaults to `default`) — 调整大小模式，可以是`default`或`fill`中的一个。如果是`default`，将调整图像大小以适应指定的宽度和高度，可能不保持原始长宽比。如果是`fill`，将调整图像大小以适应指定的宽度和高度，保持长宽比，然后将图像居中在尺寸内，用图像中的数据填充空白。如果是`crop`，将调整图像大小以适应指定的宽度和高度，保持长宽比，然后将图像居中在尺寸内，裁剪多余部分。请注意，`fill`和`crop`调整大小模式仅支持 PIL 图像输入。

+   `crops_coords`（`List[Tuple[int, int, int, int]]`，*可选*，默认为`None`）— 批处理中每个图像的裁剪坐标。如果为`None`，将不裁剪图像。

预处理图像输入。

#### `pt_to_numpy`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L122)

```py
( images: FloatTensor )
```

将 PyTorch 张量转换为 NumPy 图像。

#### `resize`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L328)

```py
( image: Union height: int width: int resize_mode: str = 'default' ) → export const metadata = 'undefined';PIL.Image.Image, np.ndarray or torch.Tensor
```

参数

+   `image`（`PIL.Image.Image`，`np.ndarray`或`torch.Tensor`）— 图像输入，可以是 PIL 图像、numpy 数组或 pytorch 张量。

+   `height`（`int`）— 要调整大小的高度。

+   `width`（`int`）— 要调整大小的宽度。

+   `resize_mode`（`str`，*可选*，默认为`default`）— 要使用的调整大小模式，可以是`default`或`fill`之一。如果是`default`，将调整图像大小以适应指定的宽度和高度，可能不保持原始纵横比。如果是`fill`，将调整图像大小以适应指定的宽度和高度，保持纵横比，然后将图像居中在尺寸内，用图像数据填充空白。如果是`crop`，将调整图像大小以适应指定的宽度和高度，保持纵横比，然后将图像居中在尺寸内，裁剪多余部分。请注意，`fill`和`crop`调整大小模式仅支持 PIL 图像输入。

返回

`PIL.Image.Image`，`np.ndarray`或`torch.Tensor`

调整大小后的图像。

调整图像大小。

## VaeImageProcessorLDM3D

`VaeImageProcessorLDM3D`接受 RGB 和深度输入，并返回 RGB 和深度输出。

### `class diffusers.image_processor.VaeImageProcessorLDM3D`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L646)

```py
( do_resize: bool = True vae_scale_factor: int = 8 resample: str = 'lanczos' do_normalize: bool = True )
```

参数

+   `do_resize`（`bool`，*可选*，默认为`True`）— 是否将图像的（高度，宽度）尺寸缩小为`vae_scale_factor`的倍数。

+   `vae_scale_factor`（`int`，*可选*，默认为`8`）— VAE 比例因子。如果`do_resize`为`True`，则图像会自动调整大小为此因子的倍数。

+   `resample`（`str`，*可选*，默认为`lanczos`）— 调整图像大小时要使用的重采样滤波器。

+   `do_normalize`（`bool`，*可选*，默认为`True`）— 是否将图像归一化为[-1,1]。

用于 VAE LDM3D 的图像处理器。

#### `depth_pil_to_numpy`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L689)

```py
( images: Union )
```

将 PIL 图像或 PIL 图像列表转换为 NumPy 数组。

#### `numpy_to_depth`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L712)

```py
( images: ndarray )
```

将 NumPy 深度图像或一批图像转换为 PIL 图像。

#### `numpy_to_pil`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L673)

```py
( images: ndarray )
```

将 NumPy 图像或一批图像转换为 PIL 图像。

#### `preprocess`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L787)

```py
( rgb: Union depth: Union height: Optional = None width: Optional = None target_res: Optional = None )
```

预处理图像输入。接受的格式为 PIL 图像、NumPy 数组或 PyTorch 张量。

#### `rgblike_to_depthmap`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/image_processor.py#L701)

```py
( image: Union )
```

返回：深度图
