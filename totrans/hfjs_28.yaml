- en: 'Interface: TextGenerationStreamPrefillToken'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/huggingface.js/inference/interfaces/TextGenerationStreamPrefillToken](https://huggingface.co/docs/huggingface.js/inference/interfaces/TextGenerationStreamPrefillToken)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: id
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `id`: `number`'
  prefs: []
  type: TYPE_NORMAL
- en: Token ID from the model tokenizer
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:21](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L21)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: logprob
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `Optional` `logprob`: `number`'
  prefs: []
  type: TYPE_NORMAL
- en: Logprob Optional since the logprob of the first token cannot be computed
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:28](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L28)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `text`: `string`'
  prefs: []
  type: TYPE_NORMAL
- en: Token text
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:23](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L23)'
  prefs: []
  type: TYPE_NORMAL
