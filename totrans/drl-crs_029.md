# 什么是强化学习？简短回顾

> 原文链接：[https://huggingface.co/learn/deep-rl-course/unit2/what-is-rl](https://huggingface.co/learn/deep-rl-course/unit2/what-is-rl)

在强化学习中，我们构建一个能够**做出明智决策**的agent。例如，一个**学会玩视频游戏**的agent。或者一个**通过决定**买入哪些股票和何时卖出**来最大化利益**的交易agent。

![强化学习过程](../Images/75d6b22440b9c5d7d5b653bfb590c8e0.png)

为了做出智能决策，我们的agent将通过与环境的互动来学习，通过试错来接收奖励（正面或负面）作为独特的反馈。

它的目标**是最大化其期望累积奖励**（因为奖励假设）。

**agent的决策过程称为策略π**：给定一个状态，策略将输出一个动作或动作的概率分布。也就是说，给定环境的观察，策略将提供一个代理应该采取的动作（或每个动作的多个概率）。

![策略](../Images/eb29b1cbd14496d16a36efc7ba1b5298.png)

**我们的目标是找到一个最优策略π**，即，一个导致最佳期望累积奖励的策略。

为了找到这个最优策略（从而解决强化学习问题），有两种主要类型的强化学习方法：

+   *基于策略的方法*：**直接训练策略**，学习在给定状态下采取哪个动作。

+   *基于价值的方法*：**训练一个价值函数**，学习**哪个状态更有价值**，并使用这个价值函数**采取导致它的动作**。

![两种强化学习方法](../Images/ea1be9a83e2be724fd67093267c9958b.png)

在这个单元中，我们将深入探讨基于价值的方法。
