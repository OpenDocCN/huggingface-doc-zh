["```py\nimport torch\nfrom accelerate import PartialState\nfrom diffusers import DiffusionPipeline\n\npipeline = DiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n)\ndistributed_state = PartialState()\npipeline.to(distributed_state.device)\n\nwith distributed_state.split_between_processes([\"a dog\", \"a cat\"]) as prompt:\n    result = pipeline(prompt).images[0]\n    result.save(f\"result_{distributed_state.process_index}.png\")\n```", "```py\naccelerate launch run_distributed.py --num_processes=2\n```", "```py\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\nfrom diffusers import DiffusionPipeline\n\nsd = DiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n)\n```", "```py\ndef run_inference(rank, world_size):\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\n    sd.to(rank)\n\n    if torch.distributed.get_rank() == 0:\n        prompt = \"a dog\"\n    elif torch.distributed.get_rank() == 1:\n        prompt = \"a cat\"\n\n    image = sd(prompt).images[0]\n    image.save(f\"./{'_'.join(prompt)}.png\")\n```", "```py\ndef main():\n    world_size = 2\n    mp.spawn(run_inference, args=(world_size,), nprocs=world_size, join=True)\n\nif __name__ == \"__main__\":\n    main()\n```", "```py\ntorchrun run_distributed.py --nproc_per_node=2\n```"]