# AutoPipeline

> 原文：[https://huggingface.co/docs/diffusers/tutorials/autopipeline](https://huggingface.co/docs/diffusers/tutorials/autopipeline)

🤗 Diffusers能够完成许多不同的任务，您通常可以重复使用相同的预训练权重来完成多个任务，如文本到图像、图像到图像和修复。但是，如果您对库和扩散模型不熟悉，可能很难知道要为任务使用哪个管道。例如，如果您正在使用[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)检查点进行文本到图像，您可能不知道您也可以通过使用[StableDiffusionImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/img2img#diffusers.StableDiffusionImg2ImgPipeline)和[StableDiffusionInpaintPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline)类分别加载检查点进行图像到图像和修复。

`AutoPipeline`类旨在简化🤗 Diffusers中各种管道。它是一个通用的、*任务优先*的管道，让您专注于任务。`AutoPipeline`会自动检测要使用的正确管道类，这使得在不知道特定管道类名称的情况下为任务加载检查点变得更容易。

查看[AutoPipeline](../api/pipelines/auto_pipeline)参考以查看支持的任务。目前，它支持文本到图像、图像到图像和修复。

本教程向您展示如何使用`AutoPipeline`自动推断要加载的特定任务的管道类，给定预训练权重。

## 为您的任务选择一个AutoPipeline

首先选择一个检查点。例如，如果您对使用[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)检查点进行文本到图像感兴趣，请使用[AutoPipelineForText2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForText2Image)：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
prompt = "peasant and dragon combat, wood cutting style, viking era, bevel with rune"

image = pipeline(prompt, num_inference_steps=25).images[0]
image
```

![生成的农民与龙在木刻风格中战斗的图像](../Images/6b36788d2ba60d3bbff51fcbbb0d71e8.png)

在幕后，[AutoPipelineForText2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForText2Image)：

1.  自动从[`model_index.json`](https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json)文件中检测到一个`"stable-diffusion"`类

1.  根据`"stable-diffusion"`类名加载相应的文本到图像[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)

同样，对于图像到图像，[AutoPipelineForImage2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)会从`model_index.json`文件中检测到一个`"stable-diffusion"`检查点，并在幕后加载相应的[StableDiffusionImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/img2img#diffusers.StableDiffusionImg2ImgPipeline)。您还可以传递任何特定于管道类的其他参数，如`strength`，它确定添加到输入图像的噪音或变化的量：

```py
from diffusers import AutoPipelineForImage2Image
import torch
import requests
from PIL import Image
from io import BytesIO

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True,
).to("cuda")
prompt = "a portrait of a dog wearing a pearl earring"

url = "https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/1665_Girl_with_a_Pearl_Earring.jpg/800px-1665_Girl_with_a_Pearl_Earring.jpg"

response = requests.get(url)
image = Image.open(BytesIO(response.content)).convert("RGB")
image.thumbnail((768, 768))

image = pipeline(prompt, image, num_inference_steps=200, strength=0.75, guidance_scale=10.5).images[0]
image
```

![生成的戴珍珠耳环的狗的维梅尔肖像](../Images/324a523572635d35cf0a7729b6276327.png)

如果您想要进行修复，则[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)以相同的方式加载底层的[StableDiffusionInpaintPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline)类：

```py
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
import torch

pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = load_image(img_url).convert("RGB")
mask_image = load_image(mask_url).convert("RGB")

prompt = "A majestic tiger sitting on a bench"
image = pipeline(prompt, image=init_image, mask_image=mask_image, num_inference_steps=50, strength=0.80).images[0]
image
```

![生成的老虎坐在长椅上的图像](../Images/0a4e68dcc87ca3b2dd1efff748f52b7d.png)

如果尝试加载不受支持的检查点，将会抛出错误：

```py
from diffusers import AutoPipelineForImage2Image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "openai/shap-e-img2img", torch_dtype=torch.float16, use_safetensors=True
)
"ValueError: AutoPipeline can't find a pipeline linked to ShapEImg2ImgPipeline for None"
```

## 使用多个管道

对于某些工作流程或者如果您正在加载许多流水线，更节省内存的方法是重复使用来自检查点的相同组件，而不是重新加载它们，这样会不必要地消耗额外的内存。例如，如果您正在使用一个用于文本到图像的检查点，并且想要再次用于图像到图像，可以使用[from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)方法。这个方法以零额外内存成本从先前加载的流水线的组件创建一个新的流水线。

[from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)方法检测原始流水线类，并将其映射到您想要执行的任务对应的新流水线类。例如，如果您加载了一个用于文本到图像的`"stable-diffusion"`类流水线：

```py
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch

pipeline_text2img = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
print(type(pipeline_text2img))
"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>"
```

然后[from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)将原始的`"stable-diffusion"`流水线类映射到[StableDiffusionImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/img2img#diffusers.StableDiffusionImg2ImgPipeline)：

```py
pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)
print(type(pipeline_img2img))
"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'>"
```

如果您向原始流水线传递了一个可选参数 - 比如禁用安全检查器 - 这个参数也会传递给新的流水线：

```py
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch

pipeline_text2img = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True,
    requires_safety_checker=False,
).to("cuda")

pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)
print(pipeline_img2img.config.requires_safety_checker)
"False"
```

如果您想要更改新流水线的行为，可以覆盖原始流水线的任何参数甚至配置。例如，要重新打开安全检查器并添加`strength`参数：

```py
pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img, requires_safety_checker=True, strength=0.3)
print(pipeline_img2img.config.requires_safety_checker)
"True"
```
