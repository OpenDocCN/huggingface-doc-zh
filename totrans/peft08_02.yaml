- en: PEFT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PEFT
- en: 'Original text: [https://huggingface.co/docs/peft/index](https://huggingface.co/docs/peft/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/peft/index](https://huggingface.co/docs/peft/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 🤗 PEFT (Parameter-Efficient Fine-Tuning) is a library for efficiently adapting
    large pretrained models to various downstream applications without fine-tuning
    all of a model’s parameters because it is prohibitively costly. PEFT methods only
    fine-tune a small number of (extra) model parameters - significantly decreasing
    computational and storage costs - while yielding performance comparable to a fully
    fine-tuned model. This makes it more accessible to train and store large language
    models (LLMs) on consumer hardware.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 PEFT（参数高效微调）是一个库，用于有效地调整大型预训练模型以适应各种下游应用，而无需微调所有模型参数，因为这是代价高昂的。PEFT方法仅微调少量（额外的）模型参数
    - 显著降低计算和存储成本 - 同时产生与完全微调模型相当的性能。这使得在消费者硬件上训练和存储大型语言模型（LLMs）更加容易。
- en: PEFT is integrated with the Transformers, Diffusers, and Accelerate libraries
    to provide a faster and easier way to load, train, and use large models for inference.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: PEFT与Transformers、Diffusers和Accelerate库集成，提供了一种更快更简单的方式来加载、训练和使用大型模型进行推断。
- en: '[Get started'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[开始'
- en: Start here if you're new to 🤗 PEFT to get an overview of the library's main
    features, and how to train a model with a PEFT method.](quicktour) [How-to guides
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是🤗 PEFT的新手，请从这里开始，了解库的主要特点以及如何使用PEFT方法训练模型。](quicktour) [操作指南
- en: Practical guides demonstrating how to apply various PEFT methods across different
    types of tasks like image classification, causal language modeling, automatic
    speech recognition, and more. Learn how to use 🤗 PEFT with the DeepSpeed and Fully
    Sharded Data Parallel scripts.](./task_guides/image_classification_lora) [Conceptual
    guides
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 实用指南演示如何在不同类型的任务（如图像分类、因果语言建模、自动语音识别等）中应用各种PEFT方法。学习如何使用🤗 PEFT与DeepSpeed和Fully
    Sharded Data Parallel脚本。](./task_guides/image_classification_lora) [概念指南
- en: Get a better theoretical understanding of how LoRA and various soft prompting
    methods help reduce the number of trainable parameters to make training more efficient.](./conceptual_guides/lora)
    [Reference
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过更好地理解LoRA和各种软提示方法如何帮助减少可训练参数的数量，从而使训练更加高效。](./conceptual_guides/lora) [参考
- en: Technical descriptions of how 🤗 PEFT classes and methods work.](./package_reference/config)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 技术描述了🤗 PEFT类和方法的工作原理。](./package_reference/config)
- en: '[https://stevhliu-peft-methods.hf.space](https://stevhliu-peft-methods.hf.space)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://stevhliu-peft-methods.hf.space](https://stevhliu-peft-methods.hf.space)'
