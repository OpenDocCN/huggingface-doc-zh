- en: Understanding how big of a model can fit on your machine
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº†è§£ä¸€ä¸ªæ¨¡å‹æœ‰å¤šå¤§å¯ä»¥é€‚åˆæ‚¨çš„æœºå™¨
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator](https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator](https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: One very difficult aspect when exploring potential models to use on your machine
    is knowing just how big of a model will *fit* into memory with your current graphics
    card (such as loading the model onto CUDA).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¢ç´¢æ½œåœ¨æ¨¡å‹åœ¨æ‚¨çš„æœºå™¨ä¸Šæ˜¯å¦é€‚åˆå†…å­˜ï¼ˆä¾‹å¦‚å°†æ¨¡å‹åŠ è½½åˆ°CUDAï¼‰æ—¶ï¼Œä¸€ä¸ªéå¸¸å›°éš¾çš„æ–¹é¢æ˜¯çŸ¥é“ä¸€ä¸ªæ¨¡å‹æœ‰å¤šå¤§ï¼Œæ‰èƒ½é€‚åˆæ‚¨å½“å‰çš„æ˜¾å¡ã€‚
- en: To help alleviate this, ğŸ¤— Accelerate has a CLI interface through `accelerate
    estimate-memory`. This tutorial will help walk you through using it, what to expect,
    and at the end link to the interactive demo hosted on the ğŸ¤— Hub which will even
    let you post those results directly on the model repo!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¸®åŠ©ç¼“è§£è¿™ä¸€é—®é¢˜ï¼ŒğŸ¤— Accelerateé€šè¿‡`accelerate estimate-memory`æä¾›äº†ä¸€ä¸ªCLIç•Œé¢ã€‚æœ¬æ•™ç¨‹å°†å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä½¿ç”¨å®ƒï¼Œé¢„æœŸç»“æœï¼Œå¹¶åœ¨æœ€åé“¾æ¥åˆ°ğŸ¤—
    Hubä¸Šæ‰˜ç®¡çš„äº¤äº’å¼æ¼”ç¤ºï¼Œç”šè‡³è®©æ‚¨ç›´æ¥å‘å¸ƒè¿™äº›ç»“æœåˆ°æ¨¡å‹ä»“åº“ï¼
- en: Currently we support searching for models that can be used in `timm` and `transformers`.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰æˆ‘ä»¬æ”¯æŒæœç´¢å¯ä»¥åœ¨`timm`å’Œ`transformers`ä¸­ä½¿ç”¨çš„æ¨¡å‹ã€‚
- en: This API will load the model into memory on the `meta` device, so we are not
    actually downloading and loading the full weights of the model into memory, nor
    do we need to. As a result itâ€™s perfectly fine to measure 8 billion parameter
    models (or more), without having to worry about if your CPU can handle it!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIå°†åœ¨`meta`è®¾å¤‡ä¸Šå°†æ¨¡å‹åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå› æ­¤æˆ‘ä»¬å®é™…ä¸Šå¹¶æ²¡æœ‰ä¸‹è½½å’ŒåŠ è½½æ¨¡å‹çš„å…¨éƒ¨æƒé‡åˆ°å†…å­˜ä¸­ï¼Œä¹Ÿä¸éœ€è¦ã€‚å› æ­¤ï¼Œå¯ä»¥å®Œå…¨æ”¾å¿ƒåœ°æµ‹é‡80äº¿å‚æ•°æ¨¡å‹ï¼ˆç”šè‡³æ›´å¤šï¼‰ï¼Œè€Œä¸å¿…æ‹…å¿ƒæ‚¨çš„CPUæ˜¯å¦èƒ½å¤Ÿå¤„ç†ï¼
- en: Gradio Demos
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gradioæ¼”ç¤º
- en: 'Below are a few gradio demos related to what was described above. The first
    is the official Hugging Face memory estimation space, utilizing Accelerate directly:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸ä¸Šè¿°æè¿°ç›¸å…³çš„ä¸€äº›gradioæ¼”ç¤ºã€‚ç¬¬ä¸€ä¸ªæ˜¯å®˜æ–¹çš„Hugging Faceå†…å­˜ä¼°ç®—ç©ºé—´ï¼Œç›´æ¥åˆ©ç”¨Accelerateï¼š
- en: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=light](https://hf-accelerate-model-memory-usage.hf.space?__theme=light)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=light](https://hf-accelerate-model-memory-usage.hf.space?__theme=light)'
- en: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=dark](https://hf-accelerate-model-memory-usage.hf.space?__theme=dark)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=dark](https://hf-accelerate-model-memory-usage.hf.space?__theme=dark)'
- en: A community member has taken the idea and expended it further, allowing you
    to filter models directly and see if you can run a particular LLM given GPU constraints
    and LoRA configurations. To play with it, see [here](https://huggingface.co/spaces/Vokturz/can-it-run-llm)
    for more details.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤¾åŒºæˆå‘˜è¿›ä¸€æ­¥å‘å±•äº†è¿™ä¸ªæƒ³æ³•ï¼Œä½¿æ‚¨å¯ä»¥ç›´æ¥ç­›é€‰æ¨¡å‹ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥åœ¨ç»™å®šGPUçº¦æŸå’ŒLoRAé…ç½®ä¸‹è¿è¡Œç‰¹å®šçš„LLMã€‚è¦å°è¯•ï¼Œè¯·æŸ¥çœ‹[æ­¤å¤„](https://huggingface.co/spaces/Vokturz/can-it-run-llm)ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: The Command
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‘½ä»¤
- en: When using `accelerate estimate-memory`, you need to pass in the name of the
    model you want to use, potentially the framework that model utilizing (if it canâ€™t
    be found automatically), and the data types you want the model to be loaded in
    with.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨`accelerate estimate-memory`æ—¶ï¼Œæ‚¨éœ€è¦ä¼ å…¥è¦ä½¿ç”¨çš„æ¨¡å‹çš„åç§°ï¼Œå¯èƒ½æ˜¯è¯¥æ¨¡å‹ä½¿ç”¨çš„æ¡†æ¶ï¼ˆå¦‚æœæ— æ³•è‡ªåŠ¨æ‰¾åˆ°ï¼‰ï¼Œä»¥åŠæ‚¨å¸Œæœ›æ¨¡å‹åŠ è½½çš„æ•°æ®ç±»å‹ã€‚
- en: 'For example, here is how we can calculate the memory footprint for `bert-base-cased`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¿™æ˜¯å¦‚ä½•è®¡ç®—`bert-base-cased`çš„å†…å­˜å ç”¨é‡çš„æ–¹æ³•ï¼š
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will download the `config.json` for `bert-based-cased`, load the model
    on the `meta` device, and report back how much space it will use:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†ä¸‹è½½`bert-based-cased`çš„`config.json`ï¼Œå°†æ¨¡å‹åŠ è½½åˆ°`meta`è®¾å¤‡ä¸Šï¼Œå¹¶æŠ¥å‘Šå®ƒå°†ä½¿ç”¨å¤šå°‘ç©ºé—´ï¼š
- en: 'Memory Usage for loading `bert-base-cased`:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½`bert-base-cased`çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼š
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®ç±»å‹ | æœ€å¤§å±‚ | æ€»å¤§å° | ä½¿ç”¨Adamè¿›è¡Œè®­ç»ƒ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 84.95 MB | 418.18 MB | 1.61 GB |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 84.95 MB | 418.18 MB | 1.61 GB |'
- en: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
- en: '| int8 | 21.24 MB | 103.29 MB | 413.18 MB |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| int8 | 21.24 MB | 103.29 MB | 413.18 MB |'
- en: '| int4 | 10.62 MB | 51.65 MB | 206.59 MB |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| int4 | 10.62 MB | 51.65 MB | 206.59 MB |'
- en: By default it will return all the supported dtypes (`int4` through `float32`),
    but if you are interested in specific ones these can be filtered.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†è¿”å›æ‰€æœ‰æ”¯æŒçš„æ•°æ®ç±»å‹ï¼ˆä»`int4`åˆ°`float32`ï¼‰ï¼Œä½†å¦‚æœæ‚¨å¯¹ç‰¹å®šæ•°æ®ç±»å‹æ„Ÿå…´è¶£ï¼Œå¯ä»¥è¿›è¡Œç­›é€‰ã€‚
- en: Specific libraries
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç‰¹å®šåº“
- en: If the source library cannot be determined automatically (like it could in the
    case of `bert-base-cased`), a library name can be passed in.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ— æ³•è‡ªåŠ¨ç¡®å®šæºåº“ï¼ˆå°±åƒåœ¨`bert-base-cased`çš„æƒ…å†µä¸‹ï¼‰ï¼Œåˆ™å¯ä»¥ä¼ å…¥åº“åç§°ã€‚
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Memory Usage for loading `HuggingFaceM4/idefics-80b-instruct`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½`HuggingFaceM4/idefics-80b-instruct`çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼š
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®ç±»å‹ | æœ€å¤§å±‚ | æ€»å¤§å° | ä½¿ç”¨Adamè¿›è¡Œè®­ç»ƒ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 3.02 GB | 297.12 GB | 1.16 TB |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 3.02 GB | 297.12 GB | 1.16 TB |'
- en: '| float16 | 1.51 GB | 148.56 GB | 594.24 GB |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 1.51 GB | 148.56 GB | 594.24 GB |'
- en: '| int8 | 772.52 MB | 74.28 GB | 297.12 GB |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| int8 | 772.52 MB | 74.28 GB | 297.12 GB |'
- en: '| int4 | 386.26 MB | 37.14 GB | 148.56 GB |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| int4 | 386.26 MB | 37.14 GB | 148.56 GB |'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Memory Usage for loading `timm/resnet50.a1_in1k`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½`timm/resnet50.a1_in1k`çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼š
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®ç±»å‹ | æœ€å¤§å±‚ | æ€»å¤§å° | ä½¿ç”¨Adamè¿›è¡Œè®­ç»ƒ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 9.0 MB | 97.7 MB | 390.78 MB |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 9.0 MB | 97.7 MB | 390.78 MB |'
- en: '| float16 | 4.5 MB | 48.85 MB | 195.39 MB |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 4.5 MB | 48.85 MB | 195.39 MB |'
- en: '| int8 | 2.25 MB | 24.42 MB | 97.7 MB |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| int8 | 2.25 MB | 24.42 MB | 97.7 MB |'
- en: '| int4 | 1.12 MB | 12.21 MB | 48.85 MB |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| int4 | 1.12 MB | 12.21 MB | 48.85 MB |'
- en: Specific dtypes
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç‰¹å®šæ•°æ®ç±»å‹
- en: As mentioned earlier, while we return `int4` through `float32` by default, any
    dtype can be used from `float32`, `float16`, `int8`, and `int4`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œè™½ç„¶é»˜è®¤æƒ…å†µä¸‹æˆ‘ä»¬è¿”å›`int4`åˆ°`float32`ï¼Œä½†ä»»ä½•æ•°æ®ç±»å‹éƒ½å¯ä»¥ä½¿ç”¨ï¼ŒåŒ…æ‹¬`float32`ã€`float16`ã€`int8`å’Œ`int4`ã€‚
- en: 'To do so, pass them in after specifying `--dtypes`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œåœ¨æŒ‡å®š`--dtypes`åä¼ å…¥å®ƒä»¬ï¼š
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Memory Usage for loading `bert-base-cased`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½`bert-base-cased`çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼š
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®ç±»å‹ | æœ€å¤§å±‚ | æ€»å¤§å° | ä½¿ç”¨Adamè¿›è¡Œè®­ç»ƒ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 84.95 MB | 413.18 MB | 1.61 GB |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 84.95 MB | 413.18 MB | 1.61 GB |'
- en: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
- en: Caveats with this calculator
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè®¡ç®—å™¨çš„æ³¨æ„äº‹é¡¹
- en: This calculator will tell you how much memory is needed to purely load the model
    in, *not* to perform inference.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè®¡ç®—å™¨å°†å‘Šè¯‰æ‚¨åŠ è½½æ¨¡å‹æ‰€éœ€çš„å†…å­˜é‡ï¼Œ*è€Œä¸æ˜¯*æ‰§è¡Œæ¨æ–­ã€‚
- en: This calculation is accurate within a few % of the actual value, so it is a
    very good view of just how much memory it will take. For instance loading `bert-base-cased`
    actually takes `413.68 MB` when loaded on CUDA in full precision, and the calculator
    estimates `413.18 MB`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè®¡ç®—å‡†ç¡®åº¦åœ¨å®é™…å€¼çš„å‡ ä¸ªç™¾åˆ†ç‚¹å†…ï¼Œå› æ­¤å®ƒéå¸¸å¥½åœ°å±•ç¤ºäº†éœ€è¦å¤šå°‘å†…å­˜ã€‚ä¾‹å¦‚ï¼Œå®Œæ•´ç²¾åº¦ä¸‹åŠ è½½`bert-base-cased`å®é™…ä¸Šéœ€è¦`413.68
    MB`ï¼Œè€Œè®¡ç®—å™¨ä¼°è®¡ä¸º`413.18 MB`ã€‚
- en: When performing inference you can expect to add up to an additional 20% as found
    by [EleutherAI](https://blog.eleuther.ai/transformer-math/). Weâ€™ll be conducting
    research into finding a more accurate estimate to these values, and will update
    this calculator once done.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰§è¡Œæ¨æ–­æ—¶ï¼Œæ‚¨å¯ä»¥æœŸæœ›é¢å¤–å¢åŠ é«˜è¾¾20%ï¼Œè¿™æ˜¯ç”±[EleutherAI](https://blog.eleuther.ai/transformer-math/)å‘ç°çš„ã€‚æˆ‘ä»¬å°†è¿›è¡Œç ”ç©¶ï¼Œä»¥æ‰¾åˆ°è¿™äº›å€¼æ›´å‡†ç¡®çš„ä¼°è®¡ï¼Œå¹¶åœ¨å®Œæˆåæ›´æ–°è¿™ä¸ªè®¡ç®—å™¨ã€‚
