["```py\n>>> import os; import psutil; import timeit\n>>> from datasets import load_dataset\n\n# Process.memory_info is expressed in bytes, so convert to megabytes \n>>> mem_before = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n>>> wiki = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train\")\n>>> mem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n\n>>> print(f\"RAM memory used: {(mem_after - mem_before)} MB\")\nRAM memory used: 50 MB\n```", "```py\n>>> s = \"\"\"batch_size = 1000\n... for batch in wiki.iter(batch_size):\n...     ...\n... \"\"\"\n\n>>> elapsed_time = timeit.timeit(stmt=s, number=1, globals=globals())\n>>> print(f\"Time to iterate over the {wiki.dataset_size >> 30} GB dataset: {elapsed_time:.1f} sec, \"\n...       f\"ie. {float(wiki.dataset_size >> 27)/elapsed_time:.1f} Gb/s\")\nTime to iterate over the 18 GB dataset: 31.8 sec, ie. 4.8 Gb/s\n```"]