["```py\n( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: EulerDiscreteScheduler )\n```", "```py\n( prompt: Union image: Union = None num_inference_steps: int = 75 guidance_scale: float = 9.0 negative_prompt: Union = None generator: Union = None latents: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 ) \u2192 export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> from diffusers import StableDiffusionLatentUpscalePipeline, StableDiffusionPipeline\n>>> import torch\n\n>>> pipeline = StableDiffusionPipeline.from_pretrained(\n...     \"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16\n... )\n>>> pipeline.to(\"cuda\")\n\n>>> model_id = \"stabilityai/sd-x2-latent-upscaler\"\n>>> upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n>>> upscaler.to(\"cuda\")\n\n>>> prompt = \"a photo of an astronaut high resolution, unreal engine, ultra realistic\"\n>>> generator = torch.manual_seed(33)\n\n>>> low_res_latents = pipeline(prompt, generator=generator, output_type=\"latent\").images\n\n>>> with torch.no_grad():\n...     image = pipeline.decode_latents(low_res_latents)\n>>> image = pipeline.numpy_to_pil(image)[0]\n\n>>> image.save(\"../images/a1.png\")\n\n>>> upscaled_image = upscaler(\n...     prompt=prompt,\n...     image=low_res_latents,\n...     num_inference_steps=20,\n...     guidance_scale=0,\n...     generator=generator,\n... ).images[0]\n\n>>> upscaled_image.save(\"../images/a2.png\")\n```", "```py\n( gpu_id: Optional = None device: Union = 'cuda' )\n```", "```py\n( slice_size: Union = 'auto' )\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionPipeline\n\n>>> pipe = StableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\",\n...     torch_dtype=torch.float16,\n...     use_safetensors=True,\n... )\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> pipe.enable_attention_slicing()\n>>> image = pipe(prompt).images[0]\n```", "```py\n( )\n```", "```py\n( attention_op: Optional = None )\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( s1: float s2: float b1: float b2: float )\n```", "```py\n( images: Union nsfw_content_detected: Optional )\n```"]