["```py\n  import torch\n  from diffusers import ConsistencyModelPipeline\n\n  device = \"cuda\"\n  # Load the cd_bedroom256_lpips checkpoint.\n  model_id_or_path = \"openai/diffusers-cd_bedroom256_lpips\"\n  pipe = ConsistencyModelPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n  pipe.to(device)\n\n+ pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)\n\n  # Multistep sampling\n  # Timesteps can be explicitly specified; the particular timesteps below are from the original GitHub repo:\n  # https://github.com/openai/consistency_models/blob/main/scripts/launch.sh#L83\n  for _ in range(10):\n      image = pipe(timesteps=[17, 0]).images[0]\n      image.show()\n```", "```py\n>>> import torch\n\n>>> from diffusers import ConsistencyModelPipeline\n\n>>> device = \"cuda\"\n>>> # Load the cd_imagenet64_l2 checkpoint.\n>>> model_id_or_path = \"openai/diffusers-cd_imagenet64_l2\"\n>>> pipe = ConsistencyModelPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n>>> pipe.to(device)\n\n>>> # Onestep Sampling\n>>> image = pipe(num_inference_steps=1).images[0]\n>>> image.save(\"cd_imagenet64_l2_onestep_sample.png\")\n\n>>> # Onestep sampling, class-conditional image generation\n>>> # ImageNet-64 class label 145 corresponds to king penguins\n>>> image = pipe(num_inference_steps=1, class_labels=145).images[0]\n>>> image.save(\"cd_imagenet64_l2_onestep_sample_penguin.png\")\n\n>>> # Multistep sampling, class-conditional image generation\n>>> # Timesteps can be explicitly specified; the particular timesteps below are from the original Github repo:\n>>> # https://github.com/openai/consistency_models/blob/main/scripts/launch.sh#L77\n>>> image = pipe(num_inference_steps=None, timesteps=[22, 0], class_labels=145).images[0]\n>>> image.save(\"cd_imagenet64_l2_multistep_sample_penguin.png\")\n```"]