["```py\nfrom huggingface_hub import login\nfrom diffusers import DiffusionPipeline\nimport torch\n\nlogin()\n\npipeline = DiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n)\n```", "```py\npipeline.to(\"cuda\")\n```", "```py\npipeline.scheduler\n```", "```py\nPNDMScheduler {\n  \"_class_name\": \"PNDMScheduler\",\n  \"_diffusers_version\": \"0.21.4\",\n  \"beta_end\": 0.012,\n  \"beta_schedule\": \"scaled_linear\",\n  \"beta_start\": 0.00085,\n  \"clip_sample\": false,\n  \"num_train_timesteps\": 1000,\n  \"set_alpha_to_one\": false,\n  \"skip_prk_steps\": true,\n  \"steps_offset\": 1,\n  \"timestep_spacing\": \"leading\",\n  \"trained_betas\": null\n}\n```", "```py\nprompt = \"A photograph of an astronaut riding a horse on Mars, high resolution, high definition.\"\n```", "```py\ngenerator = torch.Generator(device=\"cuda\").manual_seed(8)\nimage = pipeline(prompt, generator=generator).images[0]\nimage\n```", "```py\npipeline.scheduler.compatibles\n```", "```py\n[diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler,\n diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,\n diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,\n diffusers.schedulers.scheduling_ddim.DDIMScheduler,\n diffusers.schedulers.scheduling_ddpm.DDPMScheduler,\n diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,\n diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,\n diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,\n diffusers.schedulers.scheduling_pndm.PNDMScheduler,\n diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,\n diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,\n diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,\n diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,\n diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler]\n```", "```py\npipeline.scheduler.config\n```", "```py\nFrozenDict([('num_train_timesteps', 1000),\n            ('beta_start', 0.00085),\n            ('beta_end', 0.012),\n            ('beta_schedule', 'scaled_linear'),\n            ('trained_betas', None),\n            ('skip_prk_steps', True),\n            ('set_alpha_to_one', False),\n            ('prediction_type', 'epsilon'),\n            ('timestep_spacing', 'leading'),\n            ('steps_offset', 1),\n            ('_use_default_values', ['timestep_spacing', 'prediction_type']),\n            ('_class_name', 'PNDMScheduler'),\n            ('_diffusers_version', '0.21.4'),\n            ('clip_sample', False)])\n```", "```py\nfrom diffusers import DDIMScheduler\n\npipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n```", "```py\ngenerator = torch.Generator(device=\"cuda\").manual_seed(8)\nimage = pipeline(prompt, generator=generator).images[0]\nimage\n```", "```py\nfrom diffusers import LMSDiscreteScheduler\n\npipeline.scheduler = LMSDiscreteScheduler.from_config(pipeline.scheduler.config)\n\ngenerator = torch.Generator(device=\"cuda\").manual_seed(8)\nimage = pipeline(prompt, generator=generator).images[0]\nimage\n```", "```py\nfrom diffusers import EulerDiscreteScheduler\n\npipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)\n\ngenerator = torch.Generator(device=\"cuda\").manual_seed(8)\nimage = pipeline(prompt, generator=generator, num_inference_steps=30).images[0]\nimage\n```", "```py\nfrom diffusers import EulerAncestralDiscreteScheduler\n\npipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n\ngenerator = torch.Generator(device=\"cuda\").manual_seed(8)\nimage = pipeline(prompt, generator=generator, num_inference_steps=30).images[0]\nimage\n```", "```py\nfrom diffusers import DPMSolverMultistepScheduler\n\npipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n\ngenerator = torch.Generator(device=\"cuda\").manual_seed(8)\nimage = pipeline(prompt, generator=generator, num_inference_steps=20).images[0]\nimage\n```", "```py\nimport jax\nimport numpy as np\nfrom flax.jax_utils import replicate\nfrom flax.training.common_utils import shard\n\nfrom diffusers import FlaxStableDiffusionPipeline, FlaxDPMSolverMultistepScheduler\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\nscheduler, scheduler_state = FlaxDPMSolverMultistepScheduler.from_pretrained(\n    model_id,\n    subfolder=\"scheduler\"\n)\npipeline, params = FlaxStableDiffusionPipeline.from_pretrained(\n    model_id,\n    scheduler=scheduler,\n    revision=\"bf16\",\n    dtype=jax.numpy.bfloat16,\n)\nparams[\"scheduler\"] = scheduler_state\n\n# Generate 1 image per parallel device (8 on TPUv2-8 or TPUv3-8)\nprompt = \"a photo of an astronaut riding a horse on mars\"\nnum_samples = jax.device_count()\nprompt_ids = pipeline.prepare_inputs([prompt] * num_samples)\n\nprng_seed = jax.random.PRNGKey(0)\nnum_inference_steps = 25\n\n# shard inputs and rng\nparams = replicate(params)\nprng_seed = jax.random.split(prng_seed, jax.device_count())\nprompt_ids = shard(prompt_ids)\n\nimages = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images\nimages = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))\n```"]