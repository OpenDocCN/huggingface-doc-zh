# 贡献给🤗 Transformers

> 原文：[https://huggingface.co/docs/transformers/v4.37.2/en/contributing](https://huggingface.co/docs/transformers/v4.37.2/en/contributing)

欢迎每个人贡献，我们重视每个人的贡献。代码贡献并不是帮助社区的唯一方式。回答问题，帮助他人，改进文档也是非常有价值的。

如果您帮助传播消息，也会对我们有所帮助！在博客文章中提到这个令人惊叹的项目所可能实现的项目，每次它帮助您时在Twitter上大声疾呼，或者简单地⭐️这个存储库以表示感谢。

无论您选择如何贡献，请注意并尊重我们的[行为准则](https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md)。

**本指南受到了令人惊叹的[scikit-learn贡献指南](https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md)的启发。**

## 贡献的方式

有几种方式可以为🤗 Transformers做出贡献：

+   修复现有代码中的未解决问题。

+   提交与错误或期望的新功能相关的问题。

+   实现新模型。

+   为示例或文档做出贡献。

如果您不知道从哪里开始，有一个特殊的[Good First Issue](https://github.com/huggingface/transformers/contribute)列表。它将为您提供一份友好的初学者的问题列表，并帮助您开始为开源项目做出贡献。只需在您想要处理的问题上发表评论即可。

对于稍微具有挑战性的事情，您还可以查看[Good Second Issue](https://github.com/huggingface/transformers/labels/Good%20Second%20Issue)列表。总的来说，如果您觉得自己知道在做什么，就去做吧，我们会帮助您实现目标！🚀

> 所有贡献对社区都同样有价值。🥰

## 修复未解决的问题

如果您注意到现有代码中存在问题并有解决方案，请随时[开始贡献](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md/#create-a-pull-request)并打开一个拉取请求！

## 提交与错误相关的问题或功能请求

在提交与错误相关的问题或功能请求时，请尽力遵循这些准则。这将使我们更容易快速回复您并提供良好的反馈。

### 您发现了一个错误吗？

🤗 Transformers库之所以强大可靠，要感谢那些报告他们遇到问题的用户。

在报告问题之前，我们真的很感激您**确保错误尚未被报告**（在GitHub的问题下使用搜索栏）。您的问题也应与库本身中的错误有关，而不是您的代码。如果您不确定错误是在您的代码中还是在库中，请先在[论坛](https://discuss.huggingface.co/)中询问。这有助于我们更快地回应与库相关的问题，而不是一般问题。

一旦确认错误尚未被报告，请在您的问题中包含以下信息，以便我们能够快速解决：

+   您的**操作系统类型和版本**以及**Python**，**PyTorch**和**TensorFlow**版本（如果适用）。

+   一个简短的、自包含的代码片段，使我们能够在不到30秒内重现错误。

+   *完整*的异常跟踪信息。

+   附加任何其他可能有助于的信息，如截图。

要自动获取操作系统和软件版本，请运行以下命令：

```py
transformers-cli env
```

您还可以从存储库的根目录运行相同的命令：

```py
python src/transformers/commands/transformers_cli.py env
```

### 您想要一个新功能吗？

如果您希望在🤗 Transformers中看到一个新功能，请打开一个问题并描述：

1.  这个功能背后的*动机*是什么？它是否与库中的问题或挫折有关？它是否与您需要的项目相关的功能？它是否是您正在开发的东西，您认为它可能有益于社区？

    无论是什么，我们都很乐意听到！

1.  尽可能详细地描述您请求的功能。您能告诉我们的越多，我们就能更好地帮助您。

1.  提供一个演示功能使用的*代码片段*。

1.  如果功能与论文相关，请包含链接。

如果您的问题写得很好，那么在您创建问题时我们已经完成了80%的工作。

我们已经添加了[模板](https://github.com/huggingface/transformers/tree/main/templates)来帮助您开始解决问题。

## 您想要实现一个新模型吗？

新模型不断发布，如果您想实现新模型，请提供以下信息

+   模型的简短描述和论文链接。

+   如果实现是开源的，请提供实现的链接。

+   如果模型权重可用，请提供模型权重的链接。

如果您愿意贡献模型，请告诉我们，这样我们就可以帮助您将其添加到🤗 Transformers中！

我们已经添加了一个[详细指南和模板](https://github.com/huggingface/transformers/tree/main/templates)来帮助您开始添加新模型，我们还有一个更详细的指南，介绍了[如何向🤗 Transformers添加模型](https://huggingface.co/docs/transformers/add_new_model)。

## 您想添加文档吗？

我们始终在寻找使文档更清晰和准确的改进。请告诉我们如何改进文档，例如拼写错误和任何缺失、不清晰或不准确的内容。如果您有兴趣，我们将很乐意进行更改或帮助您做出贡献！

有关如何生成、构建和编写文档的更多详细信息，请查看文档[README](https://github.com/huggingface/transformers/tree/main/docs)。

## 创建一个Pull Request

在编写任何代码之前，我们强烈建议您搜索现有的PR或问题，以确保没有人已经在处理相同的事情。如果您不确定，最好打开一个问题以获得一些反馈。

您需要基本的`git`熟练技能才能为🤗 Transformers做出贡献。虽然`git`不是最容易使用的工具，但它有最详尽的手册。在shell中键入`git --help`并享受！如果您更喜欢书籍，[Pro Git](https://git-scm.com/book/en/v2)是一个非常好的参考。

您需要**[Python 3.8]((https://github.com/huggingface/transformers/blob/main/setup.py#L426))**或更高版本才能为🤗 Transformers做出贡献。请按照以下步骤开始贡献：

1.  通过点击存储库页面上的**[Fork](https://github.com/huggingface/transformers/fork)**按钮来fork [存储库](https://github.com/huggingface/transformers)。这将在您的GitHub用户帐户下创建代码副本。

1.  将您的fork克隆到本地磁盘，并将基本存储库添加为远程：

    ```py
    git clone git@github.com:<your Github handle>/transformers.git
    cd transformers
    git remote add upstream https://github.com/huggingface/transformers.git
    ```

1.  创建一个新分支来保存您的开发更改：

    ```py
    git checkout -b a-descriptive-name-for-my-changes
    ```

    🚨 **不要**在`main`分支上工作！

1.  在虚拟环境中运行以下命令设置开发环境：

    ```py
    pip install -e ".[dev]"
    ```

    如果🤗 Transformers已经安装在虚拟环境中，请在重新安装时使用`pip uninstall transformers`将其删除，然后使用`-e`标志以可编辑模式重新安装。

    根据您的操作系统，由于Transformers的可选依赖项数量正在增加，您可能会在此命令中遇到失败。如果是这种情况，请确保安装您正在使用的深度学习框架（PyTorch、TensorFlow和/或Flax），然后执行：

    ```py
    pip install -e ".[quality]"
    ```

    这对大多数用例来说应该足够了。

1.  在您的分支中开发功能。

    在编写代码时，您应确保测试套件通过。运行受您更改影响的测试如下：

    ```py
    pytest tests/<TEST_TO_RUN>.py
    ```

    有关测试的更多信息，请查看[Testing](https://huggingface.co/docs/transformers/testing)指南。

    🤗 Transformers依赖于`black`和`ruff`来一致格式化其源代码。在进行更改后，应用自动样式更正和代码验证，这些更改无法一次性自动完成：

    ```py
    make fixup
    ```

    此目标还经过优化，仅适用于您正在处理的PR修改的文件。

    如果您更喜欢逐个运行检查，以下命令适用于样式更正：

    ```py
    make style
    ```

    🤗 Transformers还使用`ruff`和一些自定义脚本来检查编码错误。质量控制由CI运行，但您也可以使用相同的检查运行：

    ```py
    make quality
    ```

    最后，我们有很多脚本，以确保在添加新模型时不会忘记更新一些文件。您可以使用以下命令运行这些脚本：

    ```py
    make repo-consistency
    ```

    要了解更多关于这些检查以及如何解决其中任何问题的信息，请查看[拉取请求上的检查](https://huggingface.co/docs/transformers/pr_checks)指南。

    如果您修改了`docs/source`目录下的文档，请确保文档仍然可以构建。当您打开拉取请求时，此检查也将在CI中运行。要运行本地检查，请确保安装文档生成器：

    ```py
    pip install ".[docs]"
    ```

    从存储库的根目录运行以下命令：

    ```py
    doc-builder build transformers docs/source/en --build_dir ~/tmp/test-build
    ```

    这将在`~/tmp/test-build`文件夹中构建文档，您可以使用您喜欢的编辑器检查生成的Markdown文件。您还可以在打开拉取请求时在GitHub上预览文档。

    当您对更改满意时，请使用`git add`添加更改的文件，并使用`git commit`在本地记录您的更改：

    ```py
    git add modified_file.py
    git commit
    ```

    请记得写[良好的提交消息](https://chris.beams.io/posts/git-commit/)，以清楚地传达您所做的更改！

    为了使您的代码副本与原始存储库保持最新，请在打开拉取请求之前或维护者要求时，在`upstream/branch`上对您的分支进行变基：

    ```py
    git fetch upstream
    git rebase upstream/main
    ```

    将更改推送到您的分支：

    ```py
    git push -u origin a-descriptive-name-for-my-changes
    ```

    如果您已经打开了一个拉取请求，您需要使用`--force`标志进行强制推送。否则，如果拉取请求尚未打开，您可以正常推送您的更改。

1.  现在，您可以转到GitHub上存储库的分支，并单击**拉取请求**以打开拉取请求。确保您在下面的[检查列表](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md/#pull-request-checklist)上勾选所有框。当您准备好时，您可以将更改发送给项目维护者进行审查。

1.  如果维护者要求更改，那没关系，我们的核心贡献者也会遇到这种情况！这样每个人都可以在拉取请求中看到更改，您可以在本地分支上工作并将更改推送到您的分支。它们将自动出现在拉取请求中。

### 拉取请求检查列表

☐ 拉取请求标题应总结您的贡献。

☐ 如果您的拉取请求解决了一个问题，请在拉取请求描述中提及问题编号，以确保它们链接在一起（并且查看问题的人知道您正在处理它）。

☐ 要指示正在进行的工作，请在标题前加上`[WIP]`。这对于避免重复工作以及将其与准备合并的PR区分开很有用。

☐ 确保现有测试通过。

☐ 如果要添加新功能，请为其添加测试。

+   如果要添加新模型，请确保使用`ModelTester.all_model_classes = (MyModel, MyModelWithLMHead,...)`来触发常见测试。

+   如果要添加新的`@slow`测试，请确保使用`RUN_SLOW=1 python -m pytest tests/models/my_new_model/test_my_new_model.py`来运行它们。

+   如果要添加新的分词器，请编写测试并确保`RUN_SLOW=1 python -m pytest tests/models/{your_model_name}/test_tokenization_{your_model_name}.py`通过。

+   CircleCI不运行慢速测试，但GitHub Actions每晚都会运行！

☐ 所有公共方法必须具有信息性的文档字符串（请参阅[`modeling_bert.py`](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py)作为示例）。

☐ 由于存储库正在迅速增长，请不要添加任何图像、视频和其他非文本文件，这些文件会显著增加存储库的大小。相反，请使用 Hub 存储库，例如 [`hf-internal-testing`](https://huggingface.co/hf-internal-testing) 来托管这些文件，并通过 URL 引用它们。我们建议将与文档相关的图像放在以下存储库中：[huggingface/documentation-images](https://huggingface.co/datasets/huggingface/documentation-images)。您可以在此数据集存储库上打开一个 PR，并请求 Hugging Face 成员合并它。

有关在拉取请求上运行的检查的更多信息，请查看我们的 [拉取请求上的检查](https://huggingface.co/docs/transformers/pr_checks) 指南。

### 测试

包含了一个广泛的测试套件，用于测试库的行为和几个示例。库测试可以在 [tests](https://github.com/huggingface/transformers/tree/main/tests) 文件夹中找到，示例测试可以在 [examples](https://github.com/huggingface/transformers/tree/main/examples) 文件夹中找到。

我们喜欢 `pytest` 和 `pytest-xdist`，因为它更快。从存储库的根目录开始，指定一个*子文件夹路径或测试文件*来运行测试。

```py
python -m pytest -n auto --dist=loadfile -s -v ./tests/models/my_new_model
```

同样，对于 `examples` 目录，指定一个*子文件夹路径或测试文件*来运行测试。例如，以下命令测试 PyTorch `examples` 目录中的文本分类子文件夹：

```py
pip install -r examples/xxx/requirements.txt  # only needed the first time
python -m pytest -n auto --dist=loadfile -s -v ./examples/pytorch/text-classification
```

实际上，这就是我们实现 `make test` 和 `make test-examples` 命令的方式（不包括 `pip install`）！

您还可以指定一小组较小的测试，以便仅测试您正在处理的功能。

默认情况下，慢测试会被跳过，但您可以将 `RUN_SLOW` 环境变量设置为 `yes` 来运行它们。这将下载许多千兆字节的模型，因此请确保您有足够的磁盘空间、良好的互联网连接或足够的耐心！

记得指定一个*子文件夹路径或测试文件*来运行测试。否则，您将运行 `tests` 或 `examples` 文件夹中的所有测试，这将花费很长时间！

```py
RUN_SLOW=yes python -m pytest -n auto --dist=loadfile -s -v ./tests/models/my_new_model
RUN_SLOW=yes python -m pytest -n auto --dist=loadfile -s -v ./examples/pytorch/text-classification
```

与慢测试类似，还有其他环境变量可用，这些环境变量在测试期间默认未启用：

+   `RUN_CUSTOM_TOKENIZERS`: 启用自定义分词器的测试。

+   `RUN_PT_FLAX_CROSS_TESTS`: 启用 PyTorch + Flax 集成的测试。

+   `RUN_PT_TF_CROSS_TESTS`: 启用 TensorFlow + PyTorch 集成的测试。

更多环境变量和其他信息可以在 [testing_utils.py](src/transformers/testing_utils.py) 中找到。

🤗 Transformers 仅使用 `pytest` 作为测试运行器。它不在测试套件本身中使用任何 `pytest` 特定功能。

这意味着 `unittest` 得到了完全支持。以下是如何使用 `unittest` 运行测试的方法：

```py
python -m unittest discover -s tests -t . -v
python -m unittest discover -s examples -t examples -v
```

### 样式指南

对于文档字符串，🤗 Transformers 遵循 [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)。查看我们的 [文档编写指南](https://github.com/huggingface/transformers/tree/main/docs#writing-documentation---specification) 获取更多信息。

### 在 Windows 上开发

在 Windows 上（除非您在 [Windows Subsystem for Linux](https://learn.microsoft.com/en-us/windows/wsl/) 或 WSL 中工作），您需要配置 git 将 Windows 的 `CRLF` 行结束符转换为 Linux 的 `LF` 行结束符：

```py
git config core.autocrlf input
```

在 Windows 上运行 `make` 命令的一种方法是使用 MSYS2：

1.  [下载 MSYS2](https://www.msys2.org/)，我们假设它安装在 `C:\msys64` 中。

1.  打开命令行 `C:\msys64\msys2.exe`（应该可以从**开始**菜单中找到）。

1.  在 shell 中运行：`pacman -Syu` 并使用 `pacman -S make` 安装 `make`。

1.  将 `C:\msys64\usr\bin` 添加到您的 PATH 环境变量中。

您现在可以从任何终端（Powershell、cmd.exe 等）使用 `make` 了！🎉

### 将派生存储库与上游主存储库同步（Hugging Face 存储库）

更新分叉存储库的主分支时，请按照以下步骤操作，以避免向上游存储库发送引用注释并向参与这些拉取请求的开发人员发送不必要的通知。

1.  尽量避免使用分支和拉取请求与上游同步。而是直接合并到分叉主分支。

1.  如果绝对必要，使用以下步骤在检出分支后：

```py
git checkout -b your-branch-for-syncing
git pull --squash --no-commit upstream main
git commit -m '<your message without GitHub references>'
git push --set-upstream origin your-branch-for-syncing
```
