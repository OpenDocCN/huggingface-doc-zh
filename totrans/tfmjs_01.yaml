- en: Transformers.js
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Transformers.js
- en: 'Original text: [https://huggingface.co/docs/transformers.js/index](https://huggingface.co/docs/transformers.js/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://huggingface.co/docs/transformers.js/index](https://huggingface.co/docs/transformers.js/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: State-of-the-art Machine Learning for the web. Run ğŸ¤— Transformers directly in
    your browser, with no need for a server!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç»œçš„æœ€æ–°æœºå™¨å­¦ä¹ ã€‚åœ¨æµè§ˆå™¨ä¸­ç›´æ¥è¿è¡ŒğŸ¤— Transformersï¼Œæ— éœ€æœåŠ¡å™¨ï¼
- en: 'Transformers.js is designed to be functionally equivalent to Hugging Faceâ€™s
    [transformers](https://github.com/huggingface/transformers) python library, meaning
    you can run the same pretrained models using a very similar API. These models
    support common tasks in different modalities, such as:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers.jsæ—¨åœ¨ä¸Hugging Faceçš„[transformers](https://github.com/huggingface/transformers)
    Pythonåº“åœ¨åŠŸèƒ½ä¸Šç­‰æ•ˆï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥ä½¿ç”¨éå¸¸ç›¸ä¼¼çš„APIè¿è¡Œç›¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹æ”¯æŒä¸åŒæ¨¡æ€ä¸­çš„å¸¸è§ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š
- en: 'ğŸ“ **Natural Language Processing**: text classification, named entity recognition,
    question answering, language modeling, summarization, translation, multiple choice,
    and text generation.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“ **è‡ªç„¶è¯­è¨€å¤„ç†**ï¼šæ–‡æœ¬åˆ†ç±»ï¼Œå‘½åå®ä½“è¯†åˆ«ï¼Œé—®ç­”ï¼Œè¯­è¨€å»ºæ¨¡ï¼Œæ‘˜è¦ï¼Œç¿»è¯‘ï¼Œå¤šé¡¹é€‰æ‹©å’Œæ–‡æœ¬ç”Ÿæˆã€‚
- en: 'ğŸ–¼ï¸ **Computer Vision**: image classification, object detection, and segmentation.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ–¼ï¸ **è®¡ç®—æœºè§†è§‰**ï¼šå›¾åƒåˆ†ç±»ï¼Œç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ã€‚
- en: 'ğŸ—£ï¸ **Audio**: automatic speech recognition and audio classification.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ—£ï¸ **éŸ³é¢‘**ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘åˆ†ç±»ã€‚
- en: 'ğŸ™ **Multimodal**: zero-shot image classification.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ™ **å¤šæ¨¡æ€**ï¼šé›¶æ ·æœ¬å›¾åƒåˆ†ç±»ã€‚
- en: Transformers.js uses [ONNX Runtime](https://onnxruntime.ai/) to run models in
    the browser. The best part about it, is that you can easily [convert](#convert-your-models-to-onnx)
    your pretrained PyTorch, TensorFlow, or JAX models to ONNX using [ğŸ¤— Optimum](https://github.com/huggingface/optimum#onnx--onnx-runtime).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers.jsä½¿ç”¨[ONNX Runtime](https://onnxruntime.ai/)åœ¨æµè§ˆå™¨ä¸­è¿è¡Œæ¨¡å‹ã€‚æœ€å¥½çš„éƒ¨åˆ†æ˜¯ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[ğŸ¤—
    Optimum](https://github.com/huggingface/optimum#onnx--onnx-runtime)è½»æ¾åœ°å°†æ‚¨çš„é¢„è®­ç»ƒçš„PyTorchï¼ŒTensorFlowæˆ–JAXæ¨¡å‹è½¬æ¢ä¸ºONNXã€‚
- en: For more information, check out the full [documentation](https://huggingface.co/docs/transformers.js).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è·å–æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹å®Œæ•´çš„[æ–‡æ¡£](https://huggingface.co/docs/transformers.js)ã€‚
- en: Quick tour
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¿«é€Ÿä»‹ç»
- en: Itâ€™s super simple to translate from existing code! Just like the python library,
    we support the `pipeline` API. Pipelines group together a pretrained model with
    preprocessing of inputs and postprocessing of outputs, making it the easiest way
    to run models with the library.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç°æœ‰ä»£ç è¿›è¡Œç¿»è¯‘éå¸¸ç®€å•ï¼å°±åƒPythonåº“ä¸€æ ·ï¼Œæˆ‘ä»¬æ”¯æŒ`pipeline` APIã€‚ç®¡é“å°†é¢„è®­ç»ƒæ¨¡å‹ä¸è¾“å…¥çš„é¢„å¤„ç†å’Œè¾“å‡ºçš„åå¤„ç†ç»„åˆåœ¨ä¸€èµ·ï¼Œä½¿å…¶æˆä¸ºä½¿ç”¨åº“è¿è¡Œæ¨¡å‹çš„æœ€ç®€å•æ–¹å¼ã€‚
- en: '| **Python (original)** | **Javascript (ours)** |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **Pythonï¼ˆåŸå§‹ï¼‰** | **Javascriptï¼ˆæˆ‘ä»¬çš„ï¼‰** |'
- en: '|'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '|'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'You can also use a different model by specifying the model id or path as the
    second argument to the `pipeline` function. For example:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥é€šè¿‡å°†æ¨¡å‹IDæˆ–è·¯å¾„æŒ‡å®šä¸º`pipeline`å‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°æ¥ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼š
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Contents
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›®å½•
- en: 'The documentation is organized into 4 sections:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æ¡£åˆ†ä¸º4ä¸ªéƒ¨åˆ†ï¼š
- en: '**GET STARTED** provides a quick tour of the library and installation instructions
    to get up and running.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å…¥é—¨** æä¾›äº†å¯¹åº“çš„å¿«é€Ÿä»‹ç»å’Œå®‰è£…è¯´æ˜ï¼Œä»¥ä¾¿å¿«é€Ÿä¸Šæ‰‹ã€‚'
- en: '**TUTORIALS** are a great place to start if youâ€™re a beginner! We also include
    sample applications for you to play around with!'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ•™ç¨‹** æ˜¯åˆå­¦è€…å¼€å§‹çš„å¥½åœ°æ–¹ï¼æˆ‘ä»¬è¿˜æä¾›äº†ä¸€äº›ç¤ºä¾‹åº”ç”¨ä¾›æ‚¨ç©è€ï¼'
- en: '**DEVELOPER GUIDES** show you how to use the library to achieve a specific
    goal.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¼€å‘è€…æŒ‡å—** å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨åº“æ¥å®ç°ç‰¹å®šç›®æ ‡ã€‚'
- en: '**API REFERENCE** describes all classes and functions, as well as their available
    parameters and types.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**APIå‚è€ƒ** æè¿°äº†æ‰€æœ‰ç±»å’Œå‡½æ•°ï¼Œä»¥åŠå®ƒä»¬å¯ç”¨çš„å‚æ•°å’Œç±»å‹ã€‚'
- en: Examples
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹
- en: 'Want to jump straight in? Get started with one of our sample applications/templates:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è¦ç«‹å³å¼€å§‹å—ï¼Ÿä»æˆ‘ä»¬çš„ç¤ºä¾‹åº”ç”¨ç¨‹åº/æ¨¡æ¿å¼€å§‹ï¼š
- en: '| Name | Description | Links |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| åç§° | æè¿° | é“¾æ¥ |'
- en: '| --- | --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Whisper Web | Speech recognition w/ Whisper | [code](https://github.com/xenova/whisper-web),
    [demo](https://huggingface.co/spaces/Xenova/whisper-web) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Whisper Web | Whisperçš„è¯­éŸ³è¯†åˆ« | [ä»£ç ](https://github.com/xenova/whisper-web),
    [æ¼”ç¤º](https://huggingface.co/spaces/Xenova/whisper-web) |'
- en: '| Doodle Dash | Real-time sketch-recognition game | [blog](https://huggingface.co/blog/ml-web-games),
    [code](https://github.com/xenova/doodle-dash), [demo](https://huggingface.co/spaces/Xenova/doodle-dash)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Doodle Dash | å®æ—¶æ¶‚é¸¦è¯†åˆ«æ¸¸æˆ | [åšå®¢](https://huggingface.co/blog/ml-web-games),
    [ä»£ç ](https://github.com/xenova/doodle-dash), [æ¼”ç¤º](https://huggingface.co/spaces/Xenova/doodle-dash)
    |'
- en: '| Code Playground | In-browser code completion website | [code](https://github.com/xenova/transformers.js/tree/main/examples/code-completion/),
    [demo](https://huggingface.co/spaces/Xenova/ai-code-playground) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| ä»£ç æ’­æ”¾å™¨ | æµè§ˆå™¨ä»£ç è¡¥å…¨ç½‘ç«™ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/code-completion/),
    [æ¼”ç¤º](https://huggingface.co/spaces/Xenova/ai-code-playground) |'
- en: '| Semantic Image Search (client-side) | Search for images with text | [code](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search-client/),
    [demo](https://huggingface.co/spaces/Xenova/semantic-image-search-client) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| è¯­ä¹‰å›¾åƒæœç´¢ï¼ˆå®¢æˆ·ç«¯ï¼‰ | ä½¿ç”¨æ–‡æœ¬æœç´¢å›¾åƒ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search-client/),
    [æ¼”ç¤º](https://huggingface.co/spaces/Xenova/semantic-image-search-client) |'
- en: '| Semantic Image Search (server-side) | Search for images with text (Supabase)
    | [code](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search/),
    [demo](https://huggingface.co/spaces/Xenova/semantic-image-search) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| è¯­ä¹‰å›¾åƒæœç´¢ï¼ˆæœåŠ¡å™¨ç«¯ï¼‰ | ä½¿ç”¨æ–‡æœ¬æœç´¢å›¾åƒï¼ˆSupabaseï¼‰ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search/),
    [æ¼”ç¤º](https://huggingface.co/spaces/Xenova/semantic-image-search) |'
- en: '| Vanilla JavaScript | In-browser object detection | [video](https://scrimba.com/scrim/cKm9bDAg),
    [code](https://github.com/xenova/transformers.js/tree/main/examples/vanilla-js/),
    [demo](https://huggingface.co/spaces/Scrimba/vanilla-js-object-detector) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla JavaScript | æµè§ˆå™¨å¯¹è±¡æ£€æµ‹ | [è§†é¢‘](https://scrimba.com/scrim/cKm9bDAg),
    [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/vanilla-js/),
    [æ¼”ç¤º](https://huggingface.co/spaces/Scrimba/vanilla-js-object-detector) |'
- en: '| React | Multilingual translation website | [code](https://github.com/xenova/transformers.js/tree/main/examples/react-translator/),
    [demo](https://huggingface.co/spaces/Xenova/react-translator) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| React | å¤šè¯­è¨€ç¿»è¯‘ç½‘ç«™ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/react-translator/),
    [æ¼”ç¤º](https://huggingface.co/spaces/Xenova/react-translator) |'
- en: '| Text to speech (client-side) | In-browser speech synthesis | [code](https://github.com/xenova/transformers.js/tree/main/examples/text-to-speech-client/),
    [demo](https://huggingface.co/spaces/Xenova/text-to-speech-client) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå®¢æˆ·ç«¯ï¼‰ | æµè§ˆå™¨å†…è¯­éŸ³åˆæˆ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/text-to-speech-client/)ï¼Œ[æ¼”ç¤º](https://huggingface.co/spaces/Xenova/text-to-speech-client)
    |'
- en: '| Browser extension | Text classification extension | [code](https://github.com/xenova/transformers.js/tree/main/examples/extension/)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| æµè§ˆå™¨æ‰©å±• | æ–‡æœ¬åˆ†ç±»æ‰©å±• | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/extension/)
    |'
- en: '| Electron | Text classification application | [code](https://github.com/xenova/transformers.js/tree/main/examples/electron/)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| ç”µå­ | æ–‡æœ¬åˆ†ç±»åº”ç”¨ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/electron/)
    |'
- en: '| Next.js (client-side) | Sentiment analysis (in-browser inference) | [code](https://github.com/xenova/transformers.js/tree/main/examples/next-client/),
    [demo](https://huggingface.co/spaces/Xenova/next-example-app) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| Next.jsï¼ˆå®¢æˆ·ç«¯ï¼‰ | æƒ…æ„Ÿåˆ†æï¼ˆæµè§ˆå™¨æ¨æ–­ï¼‰ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/next-client/)ï¼Œ[æ¼”ç¤º](https://huggingface.co/spaces/Xenova/next-example-app)
    |'
- en: '| Next.js (server-side) | Sentiment analysis (Node.js inference) | [code](https://github.com/xenova/transformers.js/tree/main/examples/next-server/),
    [demo](https://huggingface.co/spaces/Xenova/next-server-example-app) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Next.jsï¼ˆæœåŠ¡å™¨ç«¯ï¼‰ | æƒ…æ„Ÿåˆ†æï¼ˆNode.js æ¨æ–­ï¼‰ | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/next-server/)ï¼Œ[æ¼”ç¤º](https://huggingface.co/spaces/Xenova/next-server-example-app)
    |'
- en: '| Node.js | Sentiment analysis API | [code](https://github.com/xenova/transformers.js/tree/main/examples/node/)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| Node.js | æƒ…æ„Ÿåˆ†æAPI | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/node/)
    |'
- en: '| Demo site | A collection of demos | [code](https://github.com/xenova/transformers.js/tree/main/examples/demo-site/),
    [demo](https://xenova.github.io/transformers.js/) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| æ¼”ç¤ºç«™ç‚¹ | ä¸€ç³»åˆ—æ¼”ç¤º | [ä»£ç ](https://github.com/xenova/transformers.js/tree/main/examples/demo-site/)ï¼Œ[æ¼”ç¤º](https://xenova.github.io/transformers.js/)
    |'
- en: Check out the Transformers.js [template](https://huggingface.co/new-space?template=static-templates%2Ftransformers.js)
    on Hugging Face to get started in one click!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹Transformers.jsåœ¨Hugging Faceä¸Šçš„[æ¨¡æ¿](https://huggingface.co/new-space?template=static-templates%2Ftransformers.js)ï¼Œä¸€é”®å¼€å§‹ï¼
- en: Supported tasks/models
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ”¯æŒçš„ä»»åŠ¡/æ¨¡å‹
- en: Here is the list of all tasks and architectures currently supported by Transformers.js.
    If you donâ€™t see your task/model listed here or it is not yet supported, feel
    free to open up a feature request [here](https://github.com/xenova/transformers.js/issues/new/choose).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯Transformers.jså½“å‰æ”¯æŒçš„æ‰€æœ‰ä»»åŠ¡å’Œæ¶æ„åˆ—è¡¨ã€‚å¦‚æœæ‚¨åœ¨æ­¤å¤„çœ‹ä¸åˆ°æ‚¨çš„ä»»åŠ¡/æ¨¡å‹æˆ–å°šæœªæ”¯æŒï¼Œè¯·éšæ—¶åœ¨[æ­¤å¤„](https://github.com/xenova/transformers.js/issues/new/choose)æå‡ºåŠŸèƒ½è¯·æ±‚ã€‚
- en: To find compatible models on the Hub, select the â€œtransformers.jsâ€ library tag
    in the filter menu (or visit [this link](https://huggingface.co/models?library=transformers.js)).
    You can refine your search by selecting the task youâ€™re interested in (e.g., [text-classification](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨Hubä¸Šæ‰¾åˆ°å…¼å®¹çš„æ¨¡å‹ï¼Œè¯·åœ¨è¿‡æ»¤èœå•ä¸­é€‰æ‹©â€œtransformers.jsâ€åº“æ ‡ç­¾ï¼ˆæˆ–è®¿é—®[æ­¤é“¾æ¥](https://huggingface.co/models?library=transformers.js)ï¼‰ã€‚æ‚¨å¯ä»¥é€šè¿‡é€‰æ‹©æ‚¨æ„Ÿå…´è¶£çš„ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œ[æ–‡æœ¬åˆ†ç±»](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)ï¼‰æ¥ç»†åŒ–æœç´¢ã€‚
- en: Tasks
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»»åŠ¡
- en: Natural Language Processing
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€å¤„ç†
- en: '| Task | ID | Description | Supported? |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| ä»»åŠ¡ | ID | æè¿° | æ˜¯å¦æ”¯æŒï¼Ÿ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Conversational](https://huggingface.co/tasks/conversational) | `conversational`
    | Generating conversational text that is relevant, coherent and knowledgable given
    a prompt. | âŒ |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| [å¯¹è¯](https://huggingface.co/tasks/conversational) | `conversational` | åœ¨ç»™å®šæç¤ºçš„æƒ…å†µä¸‹ç”Ÿæˆç›¸å…³ã€è¿è´¯å’ŒçŸ¥è¯†ä¸°å¯Œçš„å¯¹è¯æ–‡æœ¬ã€‚
    | âŒ |'
- en: '| [Fill-Mask](https://huggingface.co/tasks/fill-mask) | `fill-mask` | Masking
    some of the words in a sentence and predicting which words should replace those
    masks. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FillMaskPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=fill-mask&library=transformers.js)
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| [å¡«å……æ©ç ](https://huggingface.co/tasks/fill-mask) | `fill-mask` | æ©ç›–å¥å­ä¸­çš„ä¸€äº›å•è¯å¹¶é¢„æµ‹åº”è¯¥æ›¿æ¢è¿™äº›æ©ç çš„å•è¯ã€‚
    | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FillMaskPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=fill-mask&library=transformers.js)
    |'
- en: '| [Question Answering](https://huggingface.co/tasks/question-answering) | `question-answering`
    | Retrieve the answer to a question from a given text. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.QuestionAnsweringPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=question-answering&library=transformers.js)
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| [é—®ç­”](https://huggingface.co/tasks/question-answering) | `question-answering`
    | ä»ç»™å®šæ–‡æœ¬ä¸­æ£€ç´¢é—®é¢˜çš„ç­”æ¡ˆã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.QuestionAnsweringPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=question-answering&library=transformers.js)
    |'
- en: '| [Sentence Similarity](https://huggingface.co/tasks/sentence-similarity) |
    `sentence-similarity` | Determining how similar two texts are. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| [å¥å­ç›¸ä¼¼åº¦](https://huggingface.co/tasks/sentence-similarity) | `sentence-similarity`
    | ç¡®å®šä¸¤ä¸ªæ–‡æœ¬æœ‰å¤šç›¸ä¼¼ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
- en: '| [Summarization](https://huggingface.co/tasks/summarization) | `summarization`
    | Producing a shorter version of a document while preserving its important information.
    | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.SummarizationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=summarization&library=transformers.js)
    |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| [æ‘˜è¦](https://huggingface.co/tasks/summarization) | `summarization` | ç”Ÿæˆæ–‡æ¡£çš„ç®€çŸ­ç‰ˆæœ¬ï¼ŒåŒæ—¶ä¿ç•™å…¶é‡è¦ä¿¡æ¯ã€‚
    | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.SummarizationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=summarization&library=transformers.js)
    |'
- en: '| [Table Question Answering](https://huggingface.co/tasks/table-question-answering)
    | `table-question-answering` | Answering a question about information from a given
    table. | âŒ |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| [è¡¨æ ¼é—®ç­”](https://huggingface.co/tasks/table-question-answering) | `table-question-answering`
    | å›ç­”å…³äºç»™å®šè¡¨æ ¼ä¿¡æ¯çš„é—®é¢˜ã€‚ | âŒ |'
- en: '| [Text Classification](https://huggingface.co/tasks/text-classification) |
    `text-classification` or `sentiment-analysis` | Assigning a label or class to
    a given text. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬åˆ†ç±»](https://huggingface.co/tasks/text-classification) | `text-classification`
    æˆ– `sentiment-analysis` | ä¸ºç»™å®šæ–‡æœ¬åˆ†é…ä¸€ä¸ªæ ‡ç­¾æˆ–ç±»åˆ«ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)
    |'
- en: '| [Text Generation](https://huggingface.co/tasks/text-generation#completion-generation-models)
    | `text-generation` | Producing new text by predicting the next word in a sequence.
    | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextGenerationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text-generation&library=transformers.js)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬ç”Ÿæˆ](https://huggingface.co/tasks/text-generation#completion-generation-models)
    | `text-generation` | é€šè¿‡é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ç”Ÿæˆæ–°æ–‡æœ¬ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextGenerationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=text-generation&library=transformers.js)
    |'
- en: '| [Text-to-text Generation](https://huggingface.co/tasks/text-generation#text-to-text-generation-models)
    | `text2text-generation` | Converting one text sequence into another text sequence.
    | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.Text2TextGenerationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text2text-generation&library=transformers.js)
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬åˆ°æ–‡æœ¬ç”Ÿæˆ](https://huggingface.co/tasks/text-generation#text-to-text-generation-models)
    | `text2text-generation` | å°†ä¸€ä¸ªæ–‡æœ¬åºåˆ—è½¬æ¢ä¸ºå¦ä¸€ä¸ªæ–‡æœ¬åºåˆ—ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.Text2TextGenerationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=text2text-generation&library=transformers.js)
    |'
- en: '| [Token Classification](https://huggingface.co/tasks/token-classification)
    | `token-classification` or `ner` | Assigning a label to each token in a text.
    | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TokenClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=token-classification&library=transformers.js)
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| [æ ‡è®°åˆ†ç±»](https://huggingface.co/tasks/token-classification) | `token-classification`
    æˆ– `ner` | ä¸ºæ–‡æœ¬ä¸­çš„æ¯ä¸ªæ ‡è®°åˆ†é…ä¸€ä¸ªæ ‡ç­¾ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TokenClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=token-classification&library=transformers.js)
    |'
- en: '| [Translation](https://huggingface.co/tasks/translation) | `translation` |
    Converting text from one language to another. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TranslationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=translation&library=transformers.js)
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| [ç¿»è¯‘](https://huggingface.co/tasks/translation) | `translation` | å°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€è½¬æ¢ä¸ºå¦ä¸€ç§è¯­è¨€ã€‚
    | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TranslationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=translation&library=transformers.js)
    |'
- en: '| [Zero-Shot Classification](https://huggingface.co/tasks/zero-shot-classification)
    | `zero-shot-classification` | Classifying text into classes that are unseen during
    training. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=zero-shot-classification&library=transformers.js)
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| [é›¶æ ·æœ¬åˆ†ç±»](https://huggingface.co/tasks/zero-shot-classification) | `zero-shot-classification`
    | å°†æ–‡æœ¬åˆ†ç±»ä¸ºè®­ç»ƒæœŸé—´æœªè§è¿‡çš„ç±»åˆ«ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=zero-shot-classification&library=transformers.js)
    |'
- en: Vision
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Vision
- en: '| Task | ID | Description | Supported? |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| ä»»åŠ¡ | ID | æè¿° | æ”¯æŒï¼Ÿ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Depth Estimation](https://huggingface.co/tasks/depth-estimation) | `depth-estimation`
    | Predicting the depth of objects present in an image. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DepthEstimationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=depth-estimation&library=transformers.js)
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| [æ·±åº¦ä¼°è®¡](https://huggingface.co/tasks/depth-estimation) | `depth-estimation`
    | é¢„æµ‹å›¾åƒä¸­å­˜åœ¨çš„å¯¹è±¡çš„æ·±åº¦ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DepthEstimationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=depth-estimation&library=transformers.js)
    |'
- en: '| [Image Classification](https://huggingface.co/tasks/image-classification)
    | `image-classification` | Assigning a label or class to an entire image. | âœ…
    [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-classification&library=transformers.js)
    |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| [å›¾åƒåˆ†ç±»](https://huggingface.co/tasks/image-classification) | `image-classification`
    | ä¸ºæ•´ä¸ªå›¾åƒåˆ†é…ä¸€ä¸ªæ ‡ç­¾æˆ–ç±»åˆ«ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=image-classification&library=transformers.js)
    |'
- en: '| [Image Segmentation](https://huggingface.co/tasks/image-segmentation) | `image-segmentation`
    | Divides an image into segments where each pixel is mapped to an object. This
    task has multiple variants such as instance segmentation, panoptic segmentation
    and semantic segmentation. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageSegmentationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-segmentation&library=transformers.js)
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| [å›¾åƒåˆ†å‰²](https://huggingface.co/tasks/image-segmentation) | `image-segmentation`
    | å°†å›¾åƒåˆ†å‰²æˆæ¯ä¸ªåƒç´ æ˜ å°„åˆ°ä¸€ä¸ªå¯¹è±¡çš„æ®µã€‚è¿™ä¸ªä»»åŠ¡æœ‰å¤šä¸ªå˜ä½“ï¼Œå¦‚å®ä¾‹åˆ†å‰²ã€å…¨æ™¯åˆ†å‰²å’Œè¯­ä¹‰åˆ†å‰²ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageSegmentationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=image-segmentation&library=transformers.js)
    |'
- en: '| [Image-to-Image](https://huggingface.co/tasks/image-to-image) | `image-to-image`
    | Transforming a source image to match the characteristics of a target image or
    a target image domain. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToImagePipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-to-image&library=transformers.js)
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| [å›¾åƒåˆ°å›¾åƒ](https://huggingface.co/tasks/image-to-image) | `image-to-image` |
    å°†æºå›¾åƒè½¬æ¢ä¸ºä¸ç›®æ ‡å›¾åƒæˆ–ç›®æ ‡å›¾åƒåŸŸçš„ç‰¹å¾ç›¸åŒ¹é…çš„å›¾åƒã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToImagePipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=image-to-image&library=transformers.js)
    |'
- en: '| [Mask Generation](https://huggingface.co/tasks/mask-generation) | `mask-generation`
    | Generate masks for the objects in an image. | âŒ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| [æ©æ¨¡ç”Ÿæˆ](https://huggingface.co/tasks/mask-generation) | `mask-generation`
    | ä¸ºå›¾åƒä¸­çš„å¯¹è±¡ç”Ÿæˆæ©æ¨¡ã€‚ | âŒ |'
- en: '| [Object Detection](https://huggingface.co/tasks/object-detection) | `object-detection`
    | Identify objects of certain defined classes within an image. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ObjectDetectionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=object-detection&library=transformers.js)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| [ç›®æ ‡æ£€æµ‹](https://huggingface.co/tasks/object-detection) | `object-detection`
    | åœ¨å›¾åƒä¸­è¯†åˆ«ç‰¹å®šå®šä¹‰ç±»åˆ«çš„å¯¹è±¡ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ObjectDetectionPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=object-detection&library=transformers.js)
    |'
- en: '| [Video Classification](https://huggingface.co/tasks/video-classification)
    | n/a | Assigning a label or class to an entire video. | âŒ |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| [è§†é¢‘åˆ†ç±»](https://huggingface.co/tasks/video-classification) | n/a | ä¸ºæ•´ä¸ªè§†é¢‘åˆ†é…æ ‡ç­¾æˆ–ç±»åˆ«ã€‚
    | âŒ |'
- en: '| [Unconditional Image Generation](https://huggingface.co/tasks/unconditional-image-generation)
    | n/a | Generating images with no condition in any context (like a prompt text
    or another image). | âŒ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| [æ— æ¡ä»¶å›¾åƒç”Ÿæˆ](https://huggingface.co/tasks/unconditional-image-generation) |
    n/a | åœ¨ä»»ä½•æƒ…å¢ƒä¸­ï¼ˆå¦‚æç¤ºæ–‡æœ¬æˆ–å¦ä¸€å›¾åƒï¼‰ç”Ÿæˆæ— æ¡ä»¶çš„å›¾åƒã€‚ | âŒ |'
- en: Audio
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: éŸ³é¢‘
- en: '| Task | ID | Description | Supported? |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| ä»»åŠ¡ | ID | æè¿° | æ˜¯å¦æ”¯æŒï¼Ÿ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Audio Classification](https://huggingface.co/tasks/audio-classification)
    | `audio-classification` | Assigning a label or class to a given audio. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AudioClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=audio-classification&library=transformers.js)
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [éŸ³é¢‘åˆ†ç±»](https://huggingface.co/tasks/audio-classification) | `audio-classification`
    | ä¸ºç»™å®šéŸ³é¢‘åˆ†é…æ ‡ç­¾æˆ–ç±»åˆ«ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AudioClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=audio-classification&library=transformers.js)
    |'
- en: '| [Audio-to-Audio](https://huggingface.co/tasks/audio-to-audio) | n/a | Generating
    audio from an input audio source. | âŒ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| [éŸ³é¢‘åˆ°éŸ³é¢‘](https://huggingface.co/tasks/audio-to-audio) | n/a | ä»è¾“å…¥éŸ³é¢‘æºç”ŸæˆéŸ³é¢‘ã€‚
    | âŒ |'
- en: '| [Automatic Speech Recognition](https://huggingface.co/tasks/automatic-speech-recognition)
    | `automatic-speech-recognition` | Transcribing a given audio into text. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AutomaticSpeechRecognitionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&library=transformers.js)
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| [è‡ªåŠ¨è¯­éŸ³è¯†åˆ«](https://huggingface.co/tasks/automatic-speech-recognition) | `automatic-speech-recognition`
    | å°†ç»™å®šéŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AutomaticSpeechRecognitionPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&library=transformers.js)
    |'
- en: '| [Text-to-Speech](https://huggingface.co/tasks/text-to-speech) | `text-to-speech`
    or `text-to-audio` | Generating natural-sounding speech given text input. | âœ…
    [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextToAudioPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text-to-audio&library=transformers.js)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬åˆ°è¯­éŸ³](https://huggingface.co/tasks/text-to-speech) | `text-to-speech` æˆ–
    `text-to-audio` | æ ¹æ®æ–‡æœ¬è¾“å…¥ç”Ÿæˆè‡ªç„¶éŸ³è´¨çš„è¯­éŸ³ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextToAudioPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=text-to-audio&library=transformers.js)
    |'
- en: Tabular
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è¡¨æ ¼
- en: '| Task | ID | Description | Supported? |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| ä»»åŠ¡ | ID | æè¿° | æ˜¯å¦æ”¯æŒï¼Ÿ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Tabular Classification](https://huggingface.co/tasks/tabular-classification)
    | n/a | Classifying a target category (a group) based on set of attributes. |
    âŒ |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| [è¡¨æ ¼åˆ†ç±»](https://huggingface.co/tasks/tabular-classification) | n/a | æ ¹æ®å±æ€§é›†å¯¹ç›®æ ‡ç±»åˆ«ï¼ˆä¸€ç»„ï¼‰è¿›è¡Œåˆ†ç±»ã€‚
    | âŒ |'
- en: '| [Tabular Regression](https://huggingface.co/tasks/tabular-regression) | n/a
    | Predicting a numerical value given a set of attributes. | âŒ |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [è¡¨æ ¼å›å½’](https://huggingface.co/tasks/tabular-regression) | n/a | æ ¹æ®å±æ€§é›†é¢„æµ‹æ•°å€¼ã€‚
    | âŒ |'
- en: Multimodal
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¤šæ¨¡æ€
- en: '| Task | ID | Description | Supported? |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| ä»»åŠ¡ | ID | æè¿° | æ˜¯å¦æ”¯æŒï¼Ÿ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Document Question Answering](https://huggingface.co/tasks/document-question-answering)
    | `document-question-answering` | Answering questions on document images. | âœ…
    [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DocumentQuestionAnsweringPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=document-question-answering&library=transformers.js)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æ¡£é—®ç­”](https://huggingface.co/tasks/document-question-answering) | `document-question-answering`
    | å›ç­”æ–‡æ¡£å›¾åƒä¸Šçš„é—®é¢˜ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DocumentQuestionAnsweringPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=document-question-answering&library=transformers.js)
    |'
- en: '| [Feature Extraction](https://huggingface.co/tasks/feature-extraction) | `feature-extraction`
    | Transforming raw data into numerical features that can be processed while preserving
    the information in the original dataset. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| [ç‰¹å¾æå–](https://huggingface.co/tasks/feature-extraction) | `feature-extraction`
    | å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºå¯ä»¥å¤„ç†çš„æ•°å€¼ç‰¹å¾ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹æ•°æ®é›†ä¸­çš„ä¿¡æ¯ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
- en: '| [Image-to-Text](https://huggingface.co/tasks/image-to-text) | `image-to-text`
    | Output text from a given image. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToTextPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-to-text&library=transformers.js)
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| [å›¾åƒåˆ°æ–‡æœ¬](https://huggingface.co/tasks/image-to-text) | `image-to-text` | ä»ç»™å®šå›¾åƒè¾“å‡ºæ–‡æœ¬ã€‚
    | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToTextPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=image-to-text&library=transformers.js)
    |'
- en: '| [Text-to-Image](https://huggingface.co/tasks/text-to-image) | `text-to-image`
    | Generates images from input text. | âŒ |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬åˆ°å›¾åƒ](https://huggingface.co/tasks/text-to-image) | `text-to-image` | ä»è¾“å…¥æ–‡æœ¬ç”Ÿæˆå›¾åƒã€‚
    | âŒ |'
- en: '| [Visual Question Answering](https://huggingface.co/tasks/visual-question-answering)
    | `visual-question-answering` | Answering open-ended questions based on an image.
    | âŒ |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| [è§†è§‰é—®ç­”](https://huggingface.co/tasks/visual-question-answering) | `visual-question-answering`
    | æ ¹æ®å›¾åƒå›ç­”å¼€æ”¾å¼é—®é¢˜ã€‚ | âŒ |'
- en: '| [Zero-Shot Audio Classification](https://huggingface.co/learn/audio-course/chapter4/classification_models#zero-shot-audio-classification)
    | `zero-shot-audio-classification` | Classifying audios into classes that are
    unseen during training. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotAudioClassificationPipeline)
    [(models)](https://huggingface.co/models?other=zero-shot-audio-classification&library=transformers.js)
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| [é›¶æ ·æœ¬éŸ³é¢‘åˆ†ç±»](https://huggingface.co/learn/audio-course/chapter4/classification_models#zero-shot-audio-classification)
    | `zero-shot-audio-classification` | å°†éŸ³é¢‘åˆ†ç±»ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœªè§è¿‡çš„ç±»åˆ«ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotAudioClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?other=zero-shot-audio-classification&library=transformers.js)
    |'
- en: '| [Zero-Shot Image Classification](https://huggingface.co/tasks/zero-shot-image-classification)
    | `zero-shot-image-classification` | Classifying images into classes that are
    unseen during training. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotImageClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&library=transformers.js)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| [é›¶æ ·æœ¬å›¾åƒåˆ†ç±»](https://huggingface.co/tasks/zero-shot-image-classification) |
    `zero-shot-image-classification` | å°†å›¾åƒåˆ†ç±»ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœªè§è¿‡çš„ç±»åˆ«ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotImageClassificationPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&library=transformers.js)
    |'
- en: '| [Zero-Shot Object Detection](https://huggingface.co/tasks/zero-shot-object-detection)
    | `zero-shot-object-detection` | Identify objects of classes that are unseen during
    training. | âœ… [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotObjectDetectionPipeline)
    [(models)](https://huggingface.co/models?other=zero-shot-object-detection&library=transformers.js)
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| [é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹](https://huggingface.co/tasks/zero-shot-object-detection) | `zero-shot-object-detection`
    | è¯†åˆ«åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœªè§è¿‡çš„ç±»åˆ«çš„å¯¹è±¡ã€‚ | âœ… [(æ–‡æ¡£)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotObjectDetectionPipeline)
    [(æ¨¡å‹)](https://huggingface.co/models?other=zero-shot-object-detection&library=transformers.js)
    |'
- en: Reinforcement Learning
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ 
- en: '| Task | ID | Description | Supported? |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| ä»»åŠ¡ | ID | æè¿° | æ˜¯å¦æ”¯æŒï¼Ÿ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Reinforcement Learning](https://huggingface.co/tasks/reinforcement-learning)
    | n/a | Learning from actions by interacting with an environment through trial
    and error and receiving rewards (negative or positive) as feedback. | âŒ |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| [å¼ºåŒ–å­¦ä¹ ](https://huggingface.co/tasks/reinforcement-learning) | n/a | é€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨ï¼Œé€šè¿‡è¯•é”™å­¦ä¹ è¡Œä¸ºï¼Œå¹¶æ ¹æ®å¥–åŠ±ï¼ˆè´Ÿé¢æˆ–æ­£é¢ï¼‰ä½œä¸ºåé¦ˆã€‚
    | âŒ |'
- en: Models
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¨¡å‹
- en: '**[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from
    Google Research and the Toyota Technological Institute at Chicago) released with
    the paper [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942),
    by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma,
    Radu Soricut.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)**ï¼ˆæ¥è‡ªGoogle
    Researchå’ŒèŠåŠ å“¥ä¸°ç”°æŠ€æœ¯ç ”ç©¶æ‰€ï¼‰å‘å¸ƒäº†è®ºæ–‡[ALBERT:è‡ªç›‘ç£å­¦ä¹ è¯­è¨€è¡¨ç¤ºçš„è½»é‡BERT](https://arxiv.org/abs/1909.11942)ï¼Œä½œè€…æ˜¯Zhenzhong
    Lanï¼ŒMingda Chenï¼ŒSebastian Goodmanï¼ŒKevin Gimpelï¼ŒPiyush Sharmaï¼ŒRadu Soricutã€‚'
- en: '**[Audio Spectrogram Transformer](https://huggingface.co/docs/transformers/model_doc/audio-spectrogram-transformer)**
    (from MIT) released with the paper [AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778)
    by Yuan Gong, Yu-An Chung, James Glass.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[éŸ³é¢‘é¢‘è°±å˜æ¢å™¨](https://huggingface.co/docs/transformers/model_doc/audio-spectrogram-transformer)**ï¼ˆæ¥è‡ªMITï¼‰å‘å¸ƒäº†è®ºæ–‡[AST:éŸ³é¢‘é¢‘è°±å˜æ¢å™¨](https://arxiv.org/abs/2104.01778)ï¼Œä½œè€…æ˜¯Yuan
    Gongï¼ŒYu-An Chungï¼ŒJames Glassã€‚'
- en: '**[BART](https://huggingface.co/docs/transformers/model_doc/bart)** (from Facebook)
    released with the paper [BART: Denoising Sequence-to-Sequence Pre-training for
    Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)
    by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
    Omer Levy, Ves Stoyanov and Luke Zettlemoyer.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BART](https://huggingface.co/docs/transformers/model_doc/bart)**ï¼ˆæ¥è‡ªFacebookï¼‰å‘å¸ƒäº†è®ºæ–‡[BART:å»å™ªåºåˆ—åˆ°åºåˆ—é¢„è®­ç»ƒç”¨äºè‡ªç„¶è¯­è¨€ç”Ÿæˆã€ç¿»è¯‘å’Œç†è§£](https://arxiv.org/abs/1910.13461)ï¼Œä½œè€…æ˜¯Mike
    Lewisï¼ŒYinhan Liuï¼ŒNaman Goyalï¼ŒMarjan Ghazvininejadï¼ŒAbdelrahman Mohamedï¼ŒOmer Levyï¼ŒVes
    Stoyanovå’ŒLuke Zettlemoyerã€‚'
- en: '**[BEiT](https://huggingface.co/docs/transformers/model_doc/beit)** (from Microsoft)
    released with the paper [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254)
    by Hangbo Bao, Li Dong, Furu Wei.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BEiT](https://huggingface.co/docs/transformers/model_doc/beit)**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰å‘å¸ƒäº†è®ºæ–‡[BEiT:
    å›¾åƒTransformerçš„BERTé¢„è®­ç»ƒ](https://arxiv.org/abs/2106.08254)ï¼Œä½œè€…æ˜¯Hangbo Baoï¼ŒLi Dongï¼ŒFuru
    Weiã€‚'
- en: '**[BERT](https://huggingface.co/docs/transformers/model_doc/bert)** (from Google)
    released with the paper [BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding](https://arxiv.org/abs/1810.04805) by Jacob Devlin,
    Ming-Wei Chang, Kenton Lee and Kristina Toutanova.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BERT](https://huggingface.co/docs/transformers/model_doc/bert)**ï¼ˆæ¥è‡ªGoogleï¼‰å‘å¸ƒäº†è®ºæ–‡[BERT:æ·±åº¦åŒå‘Transformerçš„é¢„è®­ç»ƒç”¨äºè¯­è¨€ç†è§£](https://arxiv.org/abs/1810.04805)ï¼Œä½œè€…æ˜¯Jacob
    Devlinï¼ŒMing-Wei Changï¼ŒKenton Leeå’ŒKristina Toutanovaã€‚'
- en: '**[Blenderbot](https://huggingface.co/docs/transformers/model_doc/blenderbot)**
    (from Facebook) released with the paper [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637)
    by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu,
    Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Blenderbot](https://huggingface.co/docs/transformers/model_doc/blenderbot)**ï¼ˆæ¥è‡ªFacebookï¼‰å‘å¸ƒäº†è®ºæ–‡[æ„å»ºå¼€æ”¾åŸŸèŠå¤©æœºå™¨äººçš„é…æ–¹](https://arxiv.org/abs/2004.13637)ï¼Œä½œè€…æ˜¯Stephen
    Rollerï¼ŒEmily Dinanï¼ŒNaman Goyalï¼ŒDa Juï¼ŒMary Williamsonï¼ŒYinhan Liuï¼ŒJing Xuï¼ŒMyle Ottï¼ŒKurt
    Shusterï¼ŒEric M. Smithï¼ŒY-Lan Boureauï¼ŒJason Westonã€‚'
- en: '**[BlenderbotSmall](https://huggingface.co/docs/transformers/model_doc/blenderbot-small)**
    (from Facebook) released with the paper [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637)
    by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu,
    Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BlenderbotSmall](https://huggingface.co/docs/transformers/model_doc/blenderbot-small)**ï¼ˆæ¥è‡ªFacebookï¼‰ç”±Stephen
    Rollerã€Emily Dinanã€Naman Goyalã€Da Juã€Mary Williamsonã€Yinhan Liuã€Jing Xuã€Myle Ottã€Kurt
    Shusterã€Eric M. Smithã€Y-Lan Boureauã€Jason Westonå‘å¸ƒçš„è®ºæ–‡[Recipes for building an
    open-domain chatbot](https://arxiv.org/abs/2004.13637)ã€‚'
- en: '**[BLOOM](https://huggingface.co/docs/transformers/model_doc/bloom)** (from
    BigScience workshop) released by the [BigScience Workshop](https://bigscience.huggingface.co/).'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BLOOM](https://huggingface.co/docs/transformers/model_doc/bloom)**ï¼ˆæ¥è‡ªBigScience
    workshopï¼‰ç”±[BigScience Workshop](https://bigscience.huggingface.co/)å‘å¸ƒã€‚'
- en: '**[CamemBERT](https://huggingface.co/docs/transformers/model_doc/camembert)**
    (from Inria/Facebook/Sorbonne) released with the paper [CamemBERT: a Tasty French
    Language Model](https://arxiv.org/abs/1911.03894) by Louis Martin*, Benjamin Muller*,
    Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la
    Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CamemBERT](https://huggingface.co/docs/transformers/model_doc/camembert)**ï¼ˆæ¥è‡ªInria/Facebook/Sorbonneï¼‰ç”±Louis
    Martin*ã€Benjamin Muller*ã€Pedro Javier Ortiz SuÃ¡rez*ã€Yoann Dupontã€Laurent Romaryã€Ã‰ric
    Villemonte de la Clergerieã€DjamÃ© Seddahå’ŒBenoÃ®t Sagotå‘å¸ƒçš„è®ºæ–‡[CamemBERT: a Tasty French
    Language Model](https://arxiv.org/abs/1911.03894)ã€‚'
- en: '**[Chinese-CLIP](https://huggingface.co/docs/transformers/model_doc/chinese_clip)**
    (from OFA-Sys) released with the paper [Chinese CLIP: Contrastive Vision-Language
    Pretraining in Chinese](https://arxiv.org/abs/2211.01335) by An Yang, Junshu Pan,
    Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Chinese-CLIP](https://huggingface.co/docs/transformers/model_doc/chinese_clip)**ï¼ˆæ¥è‡ªOFA-Sysï¼‰ç”±An
    Yangã€Junshu Panã€Junyang Linã€Rui Menã€Yichang Zhangã€Jingren Zhouã€Chang Zhouå‘å¸ƒçš„è®ºæ–‡[Chinese
    CLIP: Contrastive Vision-Language Pretraining in Chinese](https://arxiv.org/abs/2211.01335)ã€‚'
- en: '**[CLAP](https://huggingface.co/docs/transformers/model_doc/clap)** (from LAION-AI)
    released with the paper [Large-scale Contrastive Language-Audio Pretraining with
    Feature Fusion and Keyword-to-Caption Augmentation](https://arxiv.org/abs/2211.06687)
    by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo
    Dubnov.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CLAP](https://huggingface.co/docs/transformers/model_doc/clap)**ï¼ˆæ¥è‡ªLAION-AIï¼‰ç”±Yusong
    Wuã€Ke Chenã€Tianyu Zhangã€Yuchen Huiã€Taylor Berg-Kirkpatrickã€Shlomo Dubnovå‘å¸ƒçš„è®ºæ–‡[Large-scale
    Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption
    Augmentation](https://arxiv.org/abs/2211.06687)ã€‚'
- en: '**[CLIP](https://huggingface.co/docs/transformers/model_doc/clip)** (from OpenAI)
    released with the paper [Learning Transferable Visual Models From Natural Language
    Supervision](https://arxiv.org/abs/2103.00020) by Alec Radford, Jong Wook Kim,
    Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda
    Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CLIP](https://huggingface.co/docs/transformers/model_doc/clip)**ï¼ˆæ¥è‡ªOpenAIï¼‰ç”±Alec
    Radfordã€Jong Wook Kimã€Chris Hallacyã€Aditya Rameshã€Gabriel Gohã€Sandhini Agarwalã€Girish
    Sastryã€Amanda Askellã€Pamela Mishkinã€Jack Clarkã€Gretchen Kruegerã€Ilya Sutskeverå‘å¸ƒçš„è®ºæ–‡[Learning
    Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)ã€‚'
- en: '**[CLIPSeg](https://huggingface.co/docs/transformers/model_doc/clipseg)** (from
    University of GÃ¶ttingen) released with the paper [Image Segmentation Using Text
    and Image Prompts](https://arxiv.org/abs/2112.10003) by Timo LÃ¼ddecke and Alexander
    Ecker.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CLIPSeg](https://huggingface.co/docs/transformers/model_doc/clipseg)**ï¼ˆæ¥è‡ªGÃ¶ttingenå¤§å­¦ï¼‰ç”±Timo
    LÃ¼ddeckeå’ŒAlexander Eckerå‘å¸ƒçš„è®ºæ–‡[Image Segmentation Using Text and Image Prompts](https://arxiv.org/abs/2112.10003)ã€‚'
- en: '**[CodeGen](https://huggingface.co/docs/transformers/model_doc/codegen)** (from
    Salesforce) released with the paper [A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474)
    by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio
    Savarese, Caiming Xiong.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CodeGen](https://huggingface.co/docs/transformers/model_doc/codegen)**ï¼ˆæ¥è‡ªSalesforceï¼‰ç”±Erik
    Nijkampã€Bo Pangã€Hiroaki Hayashiã€Lifu Tuã€Huan Wangã€Yingbo Zhouã€Silvio Savareseã€Caiming
    Xiongå‘å¸ƒçš„è®ºæ–‡[A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474)ã€‚'
- en: '**[CodeLlama](https://huggingface.co/docs/transformers/model_doc/llama_code)**
    (from MetaAI) released with the paper [Code Llama: Open Foundation Models for
    Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)
    by Baptiste RoziÃ¨re, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing
    Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, JÃ©rÃ©my Rapin, Artyom Kozhevnikov,
    Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori,
    Wenhan Xiong, Alexandre DÃ©fossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis
    Martin, Nicolas Usunier, Thomas Scialom, Gabriel Synnaeve.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CodeLlama](https://huggingface.co/docs/transformers/model_doc/llama_code)**ï¼ˆæ¥è‡ªMetaAIï¼‰ç”±Baptiste
    RoziÃ¨reã€Jonas Gehringã€Fabian Gloeckleã€Sten Sootlaã€Itai Gatã€Xiaoqing Ellen Tanã€Yossi
    Adiã€Jingyu Liuã€Tal Remezã€JÃ©rÃ©my Rapinã€Artyom Kozhevnikovã€Ivan Evtimovã€Joanna Bittonã€Manish
    Bhattã€Cristian Canton Ferrerã€Aaron Grattafioriã€Wenhan Xiongã€Alexandre DÃ©fossezã€Jade
    Copetã€Faisal Azharã€Hugo Touvronã€Louis Martinã€Nicolas Usunierã€Thomas Scialomã€Gabriel
    Synnaeveå‘å¸ƒçš„è®ºæ–‡[Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code)ã€‚'
- en: '**[ConvBERT](https://huggingface.co/docs/transformers/model_doc/convbert)**
    (from YituTech) released with the paper [ConvBERT: Improving BERT with Span-based
    Dynamic Convolution](https://arxiv.org/abs/2008.02496) by Zihang Jiang, Weihao
    Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ConvBERT](https://huggingface.co/docs/transformers/model_doc/convbert)**ï¼ˆæ¥è‡ªYituTechï¼‰ç”±Zihang
    Jiangã€Weihao Yuã€Daquan Zhouã€Yunpeng Chenã€Jiashi Fengã€Shuicheng Yanå‘å¸ƒçš„è®ºæ–‡[ConvBERT:
    Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496)ã€‚'
- en: '**[ConvNeXT](https://huggingface.co/docs/transformers/model_doc/convnext)**
    (from Facebook AI) released with the paper [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
    by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
    Saining Xie.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ConvNeXT](https://huggingface.co/docs/transformers/model_doc/convnext)**ï¼ˆæ¥è‡ªFacebook
    AIï¼‰ç”±Zhuang Liuã€Hanzi Maoã€Chao-Yuan Wuã€Christoph Feichtenhoferã€Trevor Darrellã€Saining
    Xieå‘å¸ƒçš„è®ºæ–‡[A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)ã€‚'
- en: '**[ConvNeXTV2](https://huggingface.co/docs/transformers/model_doc/convnextv2)**
    (from Facebook AI) released with the paper [ConvNeXt V2: Co-designing and Scaling
    ConvNets with Masked Autoencoders](https://arxiv.org/abs/2301.00808) by Sanghyun
    Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining
    Xie.'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ConvNeXTV2](https://huggingface.co/docs/transformers/model_doc/convnextv2)**ï¼ˆæ¥è‡ªFacebook
    AIï¼‰ä¸Sanghyun Wooã€Shoubhik Debnathã€Ronghang Huã€Xinlei Chenã€Zhuang Liuã€In So Kweonã€Saining
    Xie çš„è®ºæ–‡[ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders](https://arxiv.org/abs/2301.00808)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta)** (from
    Microsoft) released with the paper [DeBERTa: Decoding-enhanced BERT with Disentangled
    Attention](https://arxiv.org/abs/2006.03654) by Pengcheng He, Xiaodong Liu, Jianfeng
    Gao, Weizhu Chen.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta)**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰ä¸Pengcheng
    Heã€Xiaodong Liuã€Jianfeng Gaoã€Weizhu Chen çš„è®ºæ–‡[DeBERTa: Decoding-enhanced BERT with
    Disentangled Attention](https://arxiv.org/abs/2006.03654)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)**
    (from Microsoft) released with the paper [DeBERTa: Decoding-enhanced BERT with
    Disentangled Attention](https://arxiv.org/abs/2006.03654) by Pengcheng He, Xiaodong
    Liu, Jianfeng Gao, Weizhu Chen.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰ä¸Pengcheng
    Heã€Xiaodong Liuã€Jianfeng Gaoã€Weizhu Chen çš„è®ºæ–‡[DeBERTa: Decoding-enhanced BERT with
    Disentangled Attention](https://arxiv.org/abs/2006.03654)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DeiT](https://huggingface.co/docs/transformers/model_doc/deit)** (from Facebook)
    released with the paper [Training data-efficient image transformers & distillation
    through attention](https://arxiv.org/abs/2012.12877) by Hugo Touvron, Matthieu
    Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ© JÃ©gou.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DeiT](https://huggingface.co/docs/transformers/model_doc/deit)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸Hugo
    Touvronã€Matthieu Cordã€Matthijs Douzeã€Francisco Massaã€Alexandre Sablayrollesã€HervÃ©
    JÃ©gou çš„è®ºæ–‡[Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[Depth Anything](https://huggingface.co/docs/transformers/main/model_doc/depth_anything)**
    (from University of Hong Kong and TikTok) released with the paper [Depth Anything:
    Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891)
    by Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, Hengshuang
    Zhao.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Depth Anything](https://huggingface.co/docs/transformers/main/model_doc/depth_anything)**ï¼ˆæ¥è‡ªé¦™æ¸¯å¤§å­¦å’ŒTikTokï¼‰ä¸Lihe
    Yangã€Bingyi Kangã€Zilong Huangã€Xiaogang Xuã€Jiashi Fengã€Hengshuang Zhao çš„è®ºæ–‡[Depth
    Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DETR](https://huggingface.co/docs/transformers/model_doc/detr)** (from Facebook)
    released with the paper [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)
    by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
    Kirillov, Sergey Zagoruyko.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DETR](https://huggingface.co/docs/transformers/model_doc/detr)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸Nicolas
    Carionã€Francisco Massaã€Gabriel Synnaeveã€Nicolas Usunierã€Alexander Kirillovã€Sergey
    Zagoruyko çš„è®ºæ–‡[End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DINOv2](https://huggingface.co/docs/transformers/model_doc/dinov2)** (from
    Meta AI) released with the paper [DINOv2: Learning Robust Visual Features without
    Supervision](https://arxiv.org/abs/2304.07193) by Maxime Oquab, TimothÃ©e Darcet,
    ThÃ©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel
    Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech
    Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat,
    Vasu Sharma, Gabriel Synnaeve, Hu Xu, HervÃ© Jegou, Julien Mairal, Patrick Labatut,
    Armand Joulin, Piotr Bojanowski.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DINOv2](https://huggingface.co/docs/transformers/model_doc/dinov2)**ï¼ˆæ¥è‡ªMeta
    AIï¼‰ä¸Maxime Oquabã€TimothÃ©e Darcetã€ThÃ©o Moutakanniã€Huy Voã€Marc Szafraniecã€Vasil
    Khalidovã€Pierre Fernandezã€Daniel Hazizaã€Francisco Massaã€Alaaeldin El-Noubyã€Mahmoud
    Assranã€Nicolas Ballasã€Wojciech Galubaã€Russell Howesã€Po-Yao Huangã€Shang-Wen Liã€Ishan
    Misraã€Michael Rabbatã€Vasu Sharmaã€Gabriel Synnaeveã€Hu Xuã€HervÃ© Jegouã€Julien Mairalã€Patrick
    Labatutã€Armand Joulinã€Piotr Bojanowski çš„è®ºæ–‡[DINOv2: Learning Robust Visual Features
    without Supervision](https://arxiv.org/abs/2304.07193)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)**
    (from HuggingFace), released together with the paper [DistilBERT, a distilled
    version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)
    by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied
    to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation),
    RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation),
    Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)
    and a German version of DistilBERT.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)**ï¼ˆæ¥è‡ªHuggingFaceï¼‰ä¸Victor
    Sanhã€Lysandre Debut å’Œ Thomas Wolf çš„è®ºæ–‡[DistilBERT, a distilled version of BERT:
    smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)ä¸€åŒå‘å¸ƒã€‚ç›¸åŒçš„æ–¹æ³•å·²è¢«åº”ç”¨äºå°†GPT2å‹ç¼©ä¸º[DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)ã€RoBERTaå‹ç¼©ä¸º[DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)ã€Multilingual
    BERTå‹ç¼©ä¸º[DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)ä»¥åŠå¾·è¯­ç‰ˆæœ¬çš„DistilBERTã€‚'
- en: '**[DiT](https://huggingface.co/docs/transformers/model_doc/dit)** (from Microsoft
    Research) released with the paper [DiT: Self-supervised Pre-training for Document
    Image Transformer](https://arxiv.org/abs/2203.02378) by Junlong Li, Yiheng Xu,
    Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DiT](https://huggingface.co/docs/transformers/model_doc/dit)**ï¼ˆæ¥è‡ªå¾®è½¯ç ”ç©¶ï¼‰ä¸Junlong
    Liã€Yiheng Xuã€Tengchao Lvã€Lei Cuiã€Cha Zhangã€Furu Wei çš„è®ºæ–‡[DiT: Self-supervised Pre-training
    for Document Image Transformer](https://arxiv.org/abs/2203.02378)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[Donut](https://huggingface.co/docs/transformers/model_doc/donut)** (from
    NAVER), released together with the paper [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664)
    by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong
    Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Donut](https://huggingface.co/docs/transformers/model_doc/donut)**ï¼ˆæ¥è‡ªNAVERï¼‰ä¸Geewook
    Kimã€Teakgyu Hongã€Moonbin Yimã€Jeongyeon Namã€Jinyoung Parkã€Jinyeong Yimã€Wonseok
    Hwangã€Sangdoo Yunã€Dongyoon Hanã€Seunghyun Park çš„è®ºæ–‡[OCR-free Document Understanding
    Transformer](https://arxiv.org/abs/2111.15664)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[DPT](https://huggingface.co/docs/transformers/master/model_doc/dpt)** (from
    Intel Labs) released with the paper [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)
    by RenÃ© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DPT](https://huggingface.co/docs/transformers/master/model_doc/dpt)**ï¼ˆæ¥è‡ªè‹±ç‰¹å°”å®éªŒå®¤ï¼‰ä¸RenÃ©
    Ranftlã€Alexey Bochkovskiyã€Vladlen Koltunåˆè‘—çš„è®ºæ–‡[ç”¨äºå¯†é›†é¢„æµ‹çš„è§†è§‰Transformer](https://arxiv.org/abs/2103.13413)ä¸€èµ·å‘å¸ƒã€‚'
- en: '**[ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)** (from
    Google Research/Stanford University) released with the paper [ELECTRA: Pre-training
    text encoders as discriminators rather than generators](https://arxiv.org/abs/2003.10555)
    by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)**ï¼ˆæ¥è‡ªGoogle
    Research/æ–¯å¦ç¦å¤§å­¦ï¼‰ä¸Kevin Clarkã€Minh-Thang Luongã€Quoc V. Leã€Christopher D. Manningåˆè‘—çš„è®ºæ–‡[å°†æ–‡æœ¬ç¼–ç å™¨é¢„è®­ç»ƒä¸ºåˆ¤åˆ«å™¨è€Œä¸æ˜¯ç”Ÿæˆå™¨](https://arxiv.org/abs/2003.10555)ä¸€èµ·å‘å¸ƒã€‚'
- en: '**[ESM](https://huggingface.co/docs/transformers/model_doc/esm)** (from Meta
    AI) are transformer protein language models. **ESM-1b** was released with the
    paper [Biological structure and function emerge from scaling unsupervised learning
    to 250 million protein sequences](https://www.pnas.org/content/118/15/e2016239118)
    by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason
    Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. **ESM-1v**
    was released with the paper [Language models enable zero-shot prediction of the
    effects of mutations on protein function](https://doi.org/10.1101/2021.07.09.450648)
    by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander
    Rives. **ESM-2 and ESMFold** were released with the paper [Language models of
    protein sequences at the scale of evolution enable accurate structure prediction](https://doi.org/10.1101/2022.07.20.500902)
    by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan
    dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ESM](https://huggingface.co/docs/transformers/model_doc/esm)**ï¼ˆæ¥è‡ªMeta AIï¼‰æ˜¯å˜å‹å™¨è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ã€‚**ESM-1b**ä¸Alexander
    Rivesã€Joshua Meierã€Tom Sercuã€Siddharth Goyalã€Zeming Linã€Jason Liuã€Demi Guoã€Myle
    Ottã€C. Lawrence Zitnickã€Jerry Maå’ŒRob Fergusåˆè‘—çš„è®ºæ–‡[ä»æ‰©å±•æ— ç›‘ç£å­¦ä¹ åˆ°2.5äº¿è›‹ç™½è´¨åºåˆ—çš„ç”Ÿç‰©ç»“æ„å’ŒåŠŸèƒ½](https://www.pnas.org/content/118/15/e2016239118)ä¸€èµ·å‘å¸ƒã€‚**ESM-1v**ä¸Joshua
    Meierã€Roshan Raoã€Robert Verkuilã€Jason Liuã€Tom Sercuå’ŒAlexander Rivesåˆè‘—çš„è®ºæ–‡[è¯­è¨€æ¨¡å‹å®ç°å¯¹è›‹ç™½è´¨åŠŸèƒ½çªå˜çš„é›¶æ ·æœ¬é¢„æµ‹](https://doi.org/10.1101/2021.07.09.450648)ä¸€èµ·å‘å¸ƒã€‚**ESM-2å’ŒESMFold**ä¸Zeming
    Linã€Halil Akinã€Roshan Raoã€Brian Hieã€Zhongkai Zhuã€Wenting Luã€Allan dos Santos Costaã€Maryam
    Fazel-Zarandiã€Tom Sercuã€Sal Candidoã€Alexander Rivesåˆè‘—çš„è®ºæ–‡[è›‹ç™½è´¨åºåˆ—çš„è¯­è¨€æ¨¡å‹åœ¨æ¼”åŒ–å°ºåº¦ä¸Šå®ç°å‡†ç¡®çš„ç»“æ„é¢„æµ‹](https://doi.org/10.1101/2022.07.20.500902)ä¸€èµ·å‘å¸ƒã€‚'
- en: '**[Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)** (from
    Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and
    Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah,
    Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic,
    Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)**ï¼ˆæ¥è‡ªæŠ€æœ¯åˆ›æ–°ç ”ç©¶æ‰€ï¼‰ç”±Almazroueiã€Ebtesamã€Alobeidliã€Hamzaã€Alshamsiã€Abdulazizã€Cappelliã€Alessandroã€Cojocaruã€Ruxandraã€Debbahã€Merouaneã€Goffinetã€Etienneã€Heslowã€Danielã€Launayã€Julienã€Malarticã€Quentinã€Nouneã€Badreddineã€Pannierã€Baptisteã€Penedoã€Guilhermeç­‰äººåˆä½œã€‚'
- en: '**[FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)** (from
    Google AI) released in the repository [google-research/t5x](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints)
    by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
    Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang
    Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang,
    Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu,
    Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc
    V. Le, and Jason Wei'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰ç”±Hyung Won Chungã€Le Houã€Shayne Longpreã€Barret Zophã€Yi Tayã€William Fedusã€Eric
    Liã€Xuezhi Wangã€Mostafa Dehghaniã€Siddhartha Brahmaã€Albert Websonã€Shixiang Shane
    Guã€Zhuyun Daiã€Mirac Suzgunã€Xinyun Chenã€Aakanksha Chowdheryã€Sharan Narangã€Gaurav
    Mishraã€Adams Yuã€Vincent Zhaoã€Yanping Huangã€Andrew Daiã€Hongkun Yuã€Slav Petrovã€Ed
    H. Chiã€Jeff Deanã€Jacob Devlinã€Adam Robertsã€Denny Zhouã€Quoc V. Leå’ŒJason Weiåˆä½œå‘å¸ƒã€‚'
- en: '**[GLPN](https://huggingface.co/docs/transformers/model_doc/glpn)** (from KAIST)
    released with the paper [Global-Local Path Networks for Monocular Depth Estimation
    with Vertical CutDepth](https://arxiv.org/abs/2201.07436) by Doyeon Kim, Woonghyun
    Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GLPN](https://huggingface.co/docs/transformers/model_doc/glpn)**ï¼ˆæ¥è‡ªKAISTï¼‰ä¸Doyeon
    Kimã€Woonghyun Gaã€Pyungwhan Ahnã€Donggyu Jooã€Sehwan Chunã€Junmo Kimåˆè‘—çš„è®ºæ–‡[å…¨å±€-å±€éƒ¨è·¯å¾„ç½‘ç»œç”¨äºå•ç›®æ·±åº¦ä¼°è®¡ä¸å‚ç›´åˆ‡å‰²æ·±åº¦](https://arxiv.org/abs/2201.07436)ä¸€èµ·å‘å¸ƒã€‚'
- en: '**[GPT Neo](https://huggingface.co/docs/transformers/model_doc/gpt_neo)** (from
    EleutherAI) released in the repository [EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo)
    by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT Neo](https://huggingface.co/docs/transformers/model_doc/gpt_neo)**ï¼ˆæ¥è‡ªEleutherAIï¼‰ç”±Sid
    Blackã€Stella Bidermanã€Leo Gaoã€Phil Wangå’ŒConnor Leahyåˆä½œå‘å¸ƒã€‚'
- en: '**[GPT NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)**
    (from EleutherAI) released with the paper [GPT-NeoX-20B: An Open-Source Autoregressive
    Language Model](https://arxiv.org/abs/2204.06745) by Sid Black, Stella Biderman,
    Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy,
    Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit,
    Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)**ï¼ˆæ¥è‡ªEleutherAIï¼‰ä¸Sid
    Blackã€Stella Bidermanã€Eric Hallahanã€Quentin Anthonyã€Leo Gaoã€Laurence Goldingã€Horace
    Heã€Connor Leahyã€Kyle McDonellã€Jason Phangã€Michael Pielerã€USVSN Sai Prashanthã€Shivanshu
    Purohitã€Laria Reynoldsã€Jonathan Towã€Ben Wangã€Samuel Weinbachåˆè‘—çš„è®ºæ–‡[GPT-NeoX-20Bï¼šä¸€ä¸ªå¼€æºçš„è‡ªå›å½’è¯­è¨€æ¨¡å‹](https://arxiv.org/abs/2204.06745)ä¸€èµ·å‘å¸ƒã€‚'
- en: '**[GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2)** (from
    OpenAI) released with the paper [Language Models are Unsupervised Multitask Learners](https://blog.openai.com/better-language-models/)
    by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei**and Ilya
    Sutskever**.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2)**ï¼ˆæ¥è‡ªOpenAIï¼‰ä¸Alec
    Radford*ã€Jeffrey Wu*ã€Rewon Childã€David Luanã€Dario Amodei**å’ŒIlya Sutskever**åˆè‘—çš„è®ºæ–‡[ã€ŠLanguage
    Models are Unsupervised Multitask Learnersã€‹](https://blog.openai.com/better-language-models/)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)** (from
    EleutherAI) released in the repository [kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/)
    by Ben Wang and Aran Komatsuzaki.'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)**ï¼ˆæ¥è‡ªEleutherAIï¼‰ç”±Ben
    Wangå’ŒAran Komatsuzakiåœ¨[repository kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/)ä¸­å‘å¸ƒã€‚'
- en: '**[GPTBigCode](https://huggingface.co/docs/transformers/model_doc/gpt_bigcode)**
    (from BigCode) released with the paper [SantaCoder: donâ€™t reach for the stars!](https://arxiv.org/abs/2301.03988)
    by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki,
    Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey,
    Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier,
    Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert,
    Francesco De Toni, Bernardo GarcÃ­a del RÃ­o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya,
    Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David
    Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine
    Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPTBigCode](https://huggingface.co/docs/transformers/model_doc/gpt_bigcode)**ï¼ˆæ¥è‡ªBigCodeï¼‰ä¸Loubna
    Ben Allalã€Raymond Liã€Denis Kocetkovã€Chenghao Mouã€Christopher Akikiã€Carlos Munoz
    Ferrandisã€Niklas Muennighoffã€Mayank Mishraã€Alex Guã€Manan Deyã€Logesh Kumar Umapathiã€Carolyn
    Jane Andersonã€Yangtian Ziã€Joel Lamy Poirierã€Hailey Schoelkopfã€Sergey Troshinã€Dmitry
    Abulkhanovã€Manuel Romeroã€Michael Lappertã€Francesco De Toniã€Bernardo GarcÃ­a del
    RÃ­oã€Qian Liuã€Shamik Boseã€Urvashi Bhattacharyyaã€Terry Yue Zhuoã€Ian Yuã€Paulo Villegasã€Marco
    Zoccaã€Sourab Mangrulkarã€David Lanskyã€Huu Nguyenã€Danish Contractorã€Luis Villaã€Jia
    Liã€Dzmitry Bahdanauã€Yacine Jerniteã€Sean Hughesã€Daniel Friedã€Arjun Guhaã€Harm de
    Vriesã€Leandro von Werraåˆè‘—çš„è®ºæ–‡[ã€ŠSantaCoder: donâ€™t reach for the stars!ã€‹](https://arxiv.org/abs/2301.03988)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[HerBERT](https://huggingface.co/docs/transformers/model_doc/herbert)** (from
    Allegro.pl, AGH University of Science and Technology) released with the paper
    [KLEJ: Comprehensive Benchmark for Polish Language Understanding](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)
    by Piotr Rybak, Robert Mroczkowski, Janusz Tracz, Ireneusz Gawlik.'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[HerBERT](https://huggingface.co/docs/transformers/model_doc/herbert)**ï¼ˆæ¥è‡ªAllegro.pl,
    AGHç§‘æŠ€å¤§å­¦ï¼‰ä¸Piotr Rybakã€Robert Mroczkowskiã€Janusz Traczã€Ireneusz Gawlikåˆè‘—çš„è®ºæ–‡[ã€ŠKLEJ:
    Comprehensive Benchmark for Polish Language Understandingã€‹](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[Hubert](https://huggingface.co/docs/transformers/model_doc/hubert)** (from
    Facebook) released with the paper [HuBERT: Self-Supervised Speech Representation
    Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447)
    by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan
    Salakhutdinov, Abdelrahman Mohamed.'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Hubert](https://huggingface.co/docs/transformers/model_doc/hubert)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸Wei-Ning
    Hsuã€Benjamin Bolteã€Yao-Hung Hubert Tsaiã€Kushal Lakhotiaã€Ruslan Salakhutdinovã€Abdelrahman
    Mohamedåˆè‘—çš„è®ºæ–‡[ã€ŠHuBERT: Self-Supervised Speech Representation Learning by Masked
    Prediction of Hidden Unitsã€‹](https://arxiv.org/abs/2106.07447)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[LongT5](https://huggingface.co/docs/transformers/model_doc/longt5)** (from
    Google AI) released with the paper [LongT5: Efficient Text-To-Text Transformer
    for Long Sequences](https://arxiv.org/abs/2112.07916) by Mandy Guo, Joshua Ainslie,
    David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[LongT5](https://huggingface.co/docs/transformers/model_doc/longt5)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰ä¸Mandy Guoã€Joshua Ainslieã€David Uthusã€Santiago Ontanonã€Jianmo Niã€Yun-Hsuan
    Sungã€Yinfei Yangåˆè‘—çš„è®ºæ–‡[ã€ŠLongT5: Efficient Text-To-Text Transformer for Long Sequencesã€‹](https://arxiv.org/abs/2112.07916)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[LLaMA](https://huggingface.co/docs/transformers/model_doc/llama)** (from
    The FAIR team of Meta AI) released with the paper [LLaMA: Open and Efficient Foundation
    Language Models](https://arxiv.org/abs/2302.13971) by Hugo Touvron, Thibaut Lavril,
    Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste
    RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin,
    Edouard Grave, Guillaume Lample.'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[LLaMA](https://huggingface.co/docs/transformers/model_doc/llama)**ï¼ˆæ¥è‡ªMeta
    AIçš„FAIRå›¢é˜Ÿï¼‰ä¸Hugo Touvronã€Thibaut Lavrilã€Gautier Izacardã€Xavier Martinetã€Marie-Anne
    Lachauxã€TimothÃ©e Lacroixã€Baptiste RoziÃ¨reã€Naman Goyalã€Eric Hambroã€Faisal Azharã€Aurelien
    Rodriguezã€Armand Joulinã€Edouard Graveã€Guillaume Lampleåˆè‘—çš„è®ºæ–‡[ã€ŠLLaMA: Open and Efficient
    Foundation Language Modelsã€‹](https://arxiv.org/abs/2302.13971)ä¸€åŒå‘å¸ƒã€‚'
- en: '**[Llama2](https://huggingface.co/docs/transformers/model_doc/llama2)** (from
    The FAIR team of Meta AI) released with the paper [Llama2: Open Foundation and
    Fine-Tuned Chat Models](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/XXX)
    by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
    Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan
    Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David
    Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj
    Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan,
    Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit
    Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai
    Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog,
    Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan
    Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan,
    Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan,
    Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien
    Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Llama2](https://huggingface.co/docs/transformers/model_doc/llama2)**ï¼ˆæ¥è‡ªMeta
    AIçš„FAIRå›¢é˜Ÿï¼‰ä¸è®ºæ–‡[Llama2ï¼šå¼€æ”¾åŸºç¡€å’Œç²¾ç»†è°ƒæ•´çš„èŠå¤©æ¨¡å‹](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/XXX)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…æ˜¯Hugo
    Touvronï¼ŒLouis Martinï¼ŒKevin Stoneï¼ŒPeter Albertï¼ŒAmjad Almahairiï¼ŒYasmine Babaeiï¼ŒNikolay
    Bashlykovï¼ŒSoumya Batraï¼ŒPrajjwal Bhargavaï¼ŒShruti Bhosaleï¼ŒDan Bikelï¼ŒLukas Blecherï¼ŒCristian
    Canton Ferrerï¼ŒMoya Chenï¼ŒGuillem Cucurullï¼ŒDavid Esiobuï¼ŒJude Fernandesï¼ŒJeremy Fuï¼ŒWenyin
    Fuï¼ŒBrian Fullerï¼ŒCynthia Gaoï¼ŒVedanuj Goswamiï¼ŒNaman Goyalï¼ŒAnthony Hartshornï¼ŒSaghar
    Hosseiniï¼ŒRui Houï¼ŒHakan Inanï¼ŒMarcin Kardasï¼ŒViktor Kerkez Madian Khabsaï¼ŒIsabel Kloumannï¼ŒArtem
    Korenevï¼ŒPunit Singh Kouraï¼ŒMarie-Anne Lachauxï¼ŒThibaut Lavrilï¼ŒJenya Leeï¼ŒDiana Liskovichï¼ŒYinghai
    Luï¼ŒYuning Maoï¼ŒXavier Martinetï¼ŒTodor Mihaylovï¼ŒPushka rMishraï¼ŒIgor Molybogï¼ŒYixin
    Nieï¼ŒAndrew Poultonï¼ŒJeremy Reizensteinï¼ŒRashi Rungtaï¼ŒKalyan Saladiï¼ŒAlan Scheltenï¼ŒRuan
    Silvaï¼ŒEric Michael Smithï¼ŒRanjan Subramanianï¼ŒXiaoqing EllenTanï¼ŒBinh Tangï¼ŒRoss Taylorï¼ŒAdina
    Williamsï¼ŒJian Xiang Kuanï¼ŒPuxin Xuï¼ŒZheng Yanï¼ŒIliyan Zarovï¼ŒYuchen Zhangï¼ŒAngela Fanï¼ŒMelanie
    Kambadurï¼ŒSharan Narangï¼ŒAurelien Rodriguezï¼ŒRobert Stojnicï¼ŒSergey Edunovï¼ŒThomas
    Scialomã€‚'
- en: '**[M2M100](https://huggingface.co/docs/transformers/model_doc/m2m_100)** (from
    Facebook) released with the paper [Beyond English-Centric Multilingual Machine
    Translation](https://arxiv.org/abs/2010.11125) by Angela Fan, Shruti Bhosale,
    Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur
    Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky,
    Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[M2M100](https://huggingface.co/docs/transformers/model_doc/m2m_100)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸è®ºæ–‡[è¶…è¶Šä»¥è‹±è¯­ä¸ºä¸­å¿ƒçš„å¤šè¯­è¨€æœºå™¨ç¿»è¯‘](https://arxiv.org/abs/2010.11125)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…æ˜¯Angela
    Fanï¼ŒShruti Bhosaleï¼ŒHolger Schwenkï¼ŒZhiyi Maï¼ŒAhmed El-Kishkyï¼ŒSiddharth Goyalï¼ŒMandeep
    Bainesï¼ŒOnur Celebiï¼ŒGuillaume Wenzekï¼ŒVishrav Chaudharyï¼ŒNaman Goyalï¼ŒTom Birchï¼ŒVitaliy
    Liptchinskyï¼ŒSergey Edunovï¼ŒEdouard Graveï¼ŒMichael Auliï¼ŒArmand Joulinã€‚'
- en: '**[MarianMT](https://huggingface.co/docs/transformers/model_doc/marian)** Machine
    translation models trained using [OPUS](http://opus.nlpl.eu/) data by JÃ¶rg Tiedemann.
    The [Marian Framework](https://marian-nmt.github.io/) is being developed by the
    Microsoft Translator Team.'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MarianMT](https://huggingface.co/docs/transformers/model_doc/marian)**ä½¿ç”¨JÃ¶rg
    Tiedemannçš„[OPUS](http://opus.nlpl.eu/)æ•°æ®è®­ç»ƒçš„æœºå™¨ç¿»è¯‘æ¨¡å‹ã€‚[Marian Framework](https://marian-nmt.github.io/)ç”±Microsoft
    Translatorå›¢é˜Ÿå¼€å‘ã€‚'
- en: '**[mBART](https://huggingface.co/docs/transformers/model_doc/mbart)** (from
    Facebook) released with the paper [Multilingual Denoising Pre-training for Neural
    Machine Translation](https://arxiv.org/abs/2001.08210) by Yinhan Liu, Jiatao Gu,
    Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[mBART](https://huggingface.co/docs/transformers/model_doc/mbart)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸è®ºæ–‡[ç¥ç»æœºå™¨ç¿»è¯‘çš„å¤šè¯­è¨€å»å™ªé¢„è®­ç»ƒ](https://arxiv.org/abs/2001.08210)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…æ˜¯Yinhan
    Liuï¼ŒJiatao Guï¼ŒNaman Goyalï¼ŒXian Liï¼ŒSergey Edunovï¼ŒMarjan Ghazvininejadï¼ŒMike Lewisï¼ŒLuke
    Zettlemoyerã€‚'
- en: '**[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)** (from
    Facebook) released with the paper [Multilingual Translation with Extensible Multilingual
    Pretraining and Finetuning](https://arxiv.org/abs/2008.00401) by Yuqing Tang,
    Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu,
    Angela Fan.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸è®ºæ–‡[å…·æœ‰å¯æ‰©å±•å¤šè¯­è¨€é¢„è®­ç»ƒå’Œå¾®è°ƒçš„å¤šè¯­è¨€ç¿»è¯‘](https://arxiv.org/abs/2008.00401)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…æ˜¯Yuqing
    Tangï¼ŒChau Tranï¼ŒXian Liï¼ŒPeng-Jen Chenï¼ŒNaman Goyalï¼ŒVishrav Chaudharyï¼ŒJiatao Guï¼ŒAngela
    Fanã€‚'
- en: '**[Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)** (from
    Mistral AI) by The [Mistral AI](https://mistral.ai) team: Albert Jiang, Alexandre
    Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las
    Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, LÃ©lio Renard Lavaud,
    Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril,
    Thomas Wang, TimothÃ©e Lacroix, William El Sayed.'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)**ï¼ˆæ¥è‡ªMistral
    AIï¼‰ç”±[Mistral AI](https://mistral.ai)å›¢é˜Ÿå‘å¸ƒï¼šAlbert Jiangï¼ŒAlexandre Sablayrollesï¼ŒArthur
    Menschï¼ŒChris Bamfordï¼ŒDevendra Singh Chaplotï¼ŒDiego de las Casasï¼ŒFlorian Bressandï¼ŒGianna
    Lengyelï¼ŒGuillaume Lampleï¼ŒLÃ©lio Renard Lavaudï¼ŒLucile Saulnierï¼ŒMarie-Anne Lachauxï¼ŒPierre
    Stockï¼ŒTeven Le Scaoï¼ŒThibaut Lavrilï¼ŒThomas Wangï¼ŒTimothÃ©e Lacroixï¼ŒWilliam El Sayedã€‚'
- en: '**[MMS](https://huggingface.co/docs/transformers/model_doc/mms)** (from Facebook)
    released with the paper [Scaling Speech Technology to 1,000+ Languages](https://arxiv.org/abs/2305.13516)
    by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani
    Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski,
    Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MMS](https://huggingface.co/docs/transformers/model_doc/mms)**ï¼ˆæ¥è‡ªFacebookï¼‰ä¸è®ºæ–‡[å°†è¯­éŸ³æŠ€æœ¯æ‰©å±•åˆ°1000å¤šç§è¯­è¨€](https://arxiv.org/abs/2305.13516)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…æ˜¯Vineel
    Pratapï¼ŒAndros Tjandraï¼ŒBowen Shiï¼ŒPaden Tomaselloï¼ŒArun Babuï¼ŒSayani Kunduï¼ŒAli Elkahkyï¼ŒZhaoheng
    Niï¼ŒApoorv Vyasï¼ŒMaryam Fazel-Zarandiï¼ŒAlexei Baevskiï¼ŒYossi Adiï¼ŒXiaohui Zhangï¼ŒWei-Ning
    Hsuï¼ŒAlexis Conneauï¼ŒMichael Auliã€‚'
- en: '**[MobileBERT](https://huggingface.co/docs/transformers/model_doc/mobilebert)**
    (from CMU/Google Brain) released with the paper [MobileBERT: a Compact Task-Agnostic
    BERT for Resource-Limited Devices](https://arxiv.org/abs/2004.02984) by Zhiqing
    Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MobileBERT](https://huggingface.co/docs/transformers/model_doc/mobilebert)**ï¼ˆæ¥è‡ªCMU/Google
    Brainï¼‰ä¸è®ºæ–‡[MobileBERTï¼šé€‚ç”¨äºèµ„æºå—é™è®¾å¤‡çš„ç´§å‡‘é€šç”¨BERT](https://arxiv.org/abs/2004.02984)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…æ˜¯Zhiqing
    Sunï¼ŒHongkun Yuï¼ŒXiaodan Songï¼ŒRenjie Liuï¼ŒYiming Yangå’ŒDenny Zhouã€‚'
- en: '**[MobileViT](https://huggingface.co/docs/transformers/model_doc/mobilevit)**
    (from Apple) released with the paper [MobileViT: Light-weight, General-purpose,
    and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) by Sachin
    Mehta and Mohammad Rastegari.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MobileViT](https://huggingface.co/docs/transformers/model_doc/mobilevit)**ï¼ˆæ¥è‡ªè‹¹æœï¼‰ç”±Sachin
    Mehtaå’ŒMohammad Rastegariåœ¨è®ºæ–‡[MobileViT: Light-weight, General-purpose, and Mobile-friendly
    Vision Transformer](https://arxiv.org/abs/2110.02178)ä¸­å‘å¸ƒã€‚'
- en: '**[MPNet](https://huggingface.co/docs/transformers/model_doc/mpnet)** (from
    Microsoft Research) released with the paper [MPNet: Masked and Permuted Pre-training
    for Language Understanding](https://arxiv.org/abs/2004.09297) by Kaitao Song,
    Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MPNet](https://huggingface.co/docs/transformers/model_doc/mpnet)**ï¼ˆæ¥è‡ªå¾®è½¯ç ”ç©¶ï¼‰ç”±Kaitao
    Songã€Xu Tanã€Tao Qinã€Jianfeng Luã€åˆ˜é“å½¦åœ¨è®ºæ–‡[MPNet: Masked and Permuted Pre-training
    for Language Understanding](https://arxiv.org/abs/2004.09297)ä¸­å‘å¸ƒã€‚'
- en: '**[MPT](https://huggingface.co/docs/transformers/model_doc/mpt)** (from MosaiML)
    released with the repository [llm-foundry](https://github.com/mosaicml/llm-foundry/)
    by the MosaicML NLP Team.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MPT](https://huggingface.co/docs/transformers/model_doc/mpt)**ï¼ˆæ¥è‡ªMosaiMLï¼‰ç”±MosaicML
    NLPå›¢é˜Ÿåœ¨[llm-foundry](https://github.com/mosaicml/llm-foundry/)å­˜å‚¨åº“ä¸­å‘å¸ƒã€‚'
- en: '**[MT5](https://huggingface.co/docs/transformers/model_doc/mt5)** (from Google
    AI) released with the paper [mT5: A massively multilingual pre-trained text-to-text
    transformer](https://arxiv.org/abs/2010.11934) by Linting Xue, Noah Constant,
    Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MT5](https://huggingface.co/docs/transformers/model_doc/mt5)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰ç”±Linting Xueã€Noah Constantã€Adam Robertsã€Mihir Kaleã€Rami Al-Rfouã€Aditya Siddhantã€Aditya
    Baruaã€Colin Raffelåœ¨è®ºæ–‡[mT5: A massively multilingual pre-trained text-to-text transformer](https://arxiv.org/abs/2010.11934)ä¸­å‘å¸ƒã€‚'
- en: '**[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)** (from Meta)
    released with the paper [No Language Left Behind: Scaling Human-Centered Machine
    Translation](https://arxiv.org/abs/2207.04672) by the NLLB team.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)**ï¼ˆæ¥è‡ªMetaï¼‰ç”±NLLBå›¢é˜Ÿåœ¨è®ºæ–‡[No
    Language Left Behind: Scaling Human-Centered Machine Translation](https://arxiv.org/abs/2207.04672)ä¸­å‘å¸ƒã€‚'
- en: '**[Nougat](https://huggingface.co/docs/transformers/model_doc/nougat)** (from
    Meta AI) released with the paper [Nougat: Neural Optical Understanding for Academic
    Documents](https://arxiv.org/abs/2308.13418) by Lukas Blecher, Guillem Cucurull,
    Thomas Scialom, Robert Stojnic.'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Nougat](https://huggingface.co/docs/transformers/model_doc/nougat)**ï¼ˆæ¥è‡ªMeta
    AIï¼‰ç”±Lukas Blecherã€Guillem Cucurullã€Thomas Scialomã€Robert Stojnicåœ¨è®ºæ–‡[Nougat: Neural
    Optical Understanding for Academic Documents](https://arxiv.org/abs/2308.13418)ä¸­å‘å¸ƒã€‚'
- en: '**[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)** (from
    Meta AI) released with the paper [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068)
    by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
    Chen et al.'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)**ï¼ˆæ¥è‡ªMeta
    AIï¼‰ç”±Susan Zhangã€Stephen Rollerã€Naman Goyalã€Mikel Artetxeã€Moya Chenã€Shuohui Chenç­‰äººåœ¨è®ºæ–‡[OPT:
    Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068)ä¸­å‘å¸ƒã€‚'
- en: '**[OWL-ViT](https://huggingface.co/docs/transformers/model_doc/owlvit)** (from
    Google AI) released with the paper [Simple Open-Vocabulary Object Detection with
    Vision Transformers](https://arxiv.org/abs/2205.06230) by Matthias Minderer, Alexey
    Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy,
    Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua
    Zhai, Thomas Kipf, and Neil Houlsby.'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[OWL-ViT](https://huggingface.co/docs/transformers/model_doc/owlvit)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰ç”±Matthias Mindererã€Alexey Gritsenkoã€Austin Stoneã€Maxim Neumannã€Dirk Weissenbornã€Alexey
    Dosovitskiyã€Aravindh Mahendranã€Anurag Arnabã€Mostafa Dehghaniã€Zhuoran Shenã€Xiao
    Wangã€Xiaohua Zhaiã€Thomas Kipfå’ŒNeil Houlsbyåœ¨è®ºæ–‡[Simple Open-Vocabulary Object Detection
    with Vision Transformers](https://arxiv.org/abs/2205.06230)ä¸­å‘å¸ƒã€‚'
- en: '**[Phi](https://huggingface.co/docs/transformers/main/model_doc/phi)** (from
    Microsoft) released with the papers - [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)
    by Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio CÃ©sar Teodoro Mendes, Allie Del
    Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli
    Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, SÃ©bastien Bubeck,
    Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee and Yuanzhi Li, [Textbooks Are All
    You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463) by Yuanzhi
    Li, SÃ©bastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar and Yin
    Tat Lee.'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Phi](https://huggingface.co/docs/transformers/main/model_doc/phi)**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰ç”±Suriya
    Gunasekarã€Yi Zhangã€Jyoti Anejaã€Caio CÃ©sar Teodoro Mendesã€Allie Del Giornoã€Sivakanth
    Gopiã€Mojan Javaheripiã€Piero Kauffmannã€Gustavo de Rosaã€Olli Saarikiviã€Adil Salimã€Shital
    Shahã€Harkirat Singh Behlã€Xin Wangã€SÃ©bastien Bubeckã€Ronen Eldanã€Adam Tauman Kalaiã€Yin
    Tat Leeå’ŒYuanzhi Liåœ¨è®ºæ–‡[Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)å’Œ[Yuanzhi
    Liã€SÃ©bastien Bubeckã€Ronen Eldanã€Allie Del Giornoã€Suriya Gunasekarå’ŒYin Tat Leeåœ¨è®ºæ–‡Textbooks
    Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463)ä¸­å‘å¸ƒã€‚'
- en: '**[Qwen2](https://huggingface.co/docs/transformers/model_doc/qwen2)** (from
    the Qwen team, Alibaba Group) released with the paper [Qwen Technical Report](https://arxiv.org/abs/2309.16609)
    by Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan,
    Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji
    Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang
    Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang,
    Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng
    Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang,
    Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou and Tianhang
    Zhu.'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Qwen2](https://huggingface.co/docs/transformers/model_doc/qwen2)**ï¼ˆæ¥è‡ªé˜¿é‡Œå·´å·´é›†å›¢çš„Qwenå›¢é˜Ÿï¼‰ç”±Jinze
    Baiã€Shuai Baiã€Yunfei Chuã€Zeyu Cuiã€Kai Dangã€Xiaodong Dengã€Yang Fanã€Wenbin Geã€Yu
    Hanã€Fei Huangã€Binyuan Huiã€Luo Jiã€Mei Liã€Junyang Linã€Runji Linã€Dayiheng Liuã€Gao
    Liuã€Chengqiang Luã€Keming Luã€Jianxin Maã€Rui Menã€Xingzhang Renã€Xuancheng Renã€Chuanqi
    Tanã€Sinan Tanã€Jianhong Tuã€Peng Wangã€Shijie Wangã€Wei Wangã€Shengguang Wuã€Benfeng
    Xuã€Jin Xuã€An Yangã€Hao Yangã€Jian Yangã€Shusheng Yangã€Yang Yaoã€Bowen Yuã€Hongyi Yuanã€Zheng
    Yuanã€Jianwei Zhangã€Xingxuan Zhangã€Yichang Zhangã€Zhenru Zhangã€Chang Zhouã€Jingren
    Zhouã€Xiaohuan Zhouå’ŒTianhang Zhuåœ¨è®ºæ–‡[Qwen Technical Report](https://arxiv.org/abs/2309.16609)ä¸­å‘å¸ƒã€‚'
- en: '**[ResNet](https://huggingface.co/docs/transformers/model_doc/resnet)** (from
    Microsoft Research) released with the paper [Deep Residual Learning for Image
    Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He, Xiangyu Zhang, Shaoqing
    Ren, Jian Sun.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ResNet](https://huggingface.co/docs/transformers/model_doc/resnet)**ï¼ˆæ¥è‡ªå¾®è½¯ç ”ç©¶ï¼‰ä¸è®ºæ–‡[Deep
    Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºKaiming
    Heã€Xiangyu Zhangã€Shaoqing Renã€Jian Sunã€‚'
- en: '**[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)** (from
    Facebook), released together with the paper [RoBERTa: A Robustly Optimized BERT
    Pretraining Approach](https://arxiv.org/abs/1907.11692) by Yinhan Liu, Myle Ott,
    Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke
    Zettlemoyer, Veselin Stoyanov.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)**ï¼ˆæ¥è‡ªFacebookï¼‰ï¼Œä¸è®ºæ–‡[RoBERTa:
    A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºåˆ˜é“¶æ¶µã€Myle
    Ottã€Naman Goyalã€Jingfei Duã€Mandar Joshiã€Danqi Chenã€Omer Levyã€Mike Lewisã€Luke Zettlemoyerã€Veselin
    Stoyanovã€‚'
- en: '**[RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer)**
    (from ZhuiyiTechnology), released together with the paper [RoFormer: Enhanced
    Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864)
    by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer)**ï¼ˆæ¥è‡ªè¿½ä¸€ç§‘æŠ€ï¼‰ï¼Œä¸è®ºæ–‡[RoFormer:
    Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºè‹å»ºæ—ã€é™†å®‡ã€æ½˜èƒœé”‹ã€æ–‡æ³¢ã€åˆ˜äº‘å³°ã€‚'
- en: '**[SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer)**
    (from NVIDIA) released with the paper [SegFormer: Simple and Efficient Design
    for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)
    by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping
    Luo.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer)**ï¼ˆæ¥è‡ªNVIDIAï¼‰ä¸è®ºæ–‡[SegFormer:
    Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºEnze
    Xieã€Wenhai Wangã€Zhiding Yuã€Anima Anandkumarã€Jose M. Alvarezã€Ping Luoã€‚'
- en: '**[Segment Anything](https://huggingface.co/docs/transformers/model_doc/sam)**
    (from Meta AI) released with the paper [Segment Anything](https://arxiv.org/pdf/2304.02643v1.pdf)
    by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
    Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar,
    Ross Girshick.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Segment Anything](https://huggingface.co/docs/transformers/model_doc/sam)**ï¼ˆæ¥è‡ªMeta
    AIï¼‰ä¸è®ºæ–‡[Segment Anything](https://arxiv.org/pdf/2304.02643v1.pdf)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºAlexander
    Kirillovã€Eric Mintunã€Nikhila Raviã€Hanzi Maoã€Chloe Rollandã€Laura Gustafsonã€Tete
    Xiaoã€Spencer Whiteheadã€Alex Bergã€Wan-Yen Loã€Piotr Dollarã€Ross Girshickã€‚'
- en: '**[SigLIP](https://huggingface.co/docs/transformers/main/model_doc/siglip)**
    (from Google AI) released with the paper [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)
    by Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, Lucas Beyer.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SigLIP](https://huggingface.co/docs/transformers/main/model_doc/siglip)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰ä¸è®ºæ–‡[Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºXiaohua
    Zhaiã€Basil Mustafaã€Alexander Kolesnikovã€Lucas Beyerã€‚'
- en: '**[SpeechT5](https://huggingface.co/docs/transformers/model_doc/speecht5)**
    (from Microsoft Research) released with the paper [SpeechT5: Unified-Modal Encoder-Decoder
    Pre-Training for Spoken Language Processing](https://arxiv.org/abs/2110.07205)
    by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom
    Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SpeechT5](https://huggingface.co/docs/transformers/model_doc/speecht5)**ï¼ˆæ¥è‡ªå¾®è½¯ç ”ç©¶ï¼‰ä¸è®ºæ–‡[SpeechT5:
    Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing](https://arxiv.org/abs/2110.07205)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºJunyi
    Aoã€Rui Wangã€Long Zhouã€Chengyi Wangã€Shuo Renã€Yu Wuã€Shujie Liuã€Tom Koã€Qing Liã€Yu
    Zhangã€Zhihua Weiã€Yao Qianã€Jinyu Liã€Furu Weiã€‚'
- en: '**[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)**
    (from Berkeley) released with the paper [SqueezeBERT: What can computer vision
    teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316)
    by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)**ï¼ˆæ¥è‡ªä¼¯å…‹åˆ©ï¼‰ä¸è®ºæ–‡[SqueezeBERT:
    What can computer vision teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºForrest
    N. Iandolaã€Albert E. Shawã€Ravi Krishnaã€Kurt W. Keutzerã€‚'
- en: '**[Swin Transformer](https://huggingface.co/docs/transformers/model_doc/swin)**
    (from Microsoft) released with the paper [Swin Transformer: Hierarchical Vision
    Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) by Ze Liu,
    Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Swin Transformer](https://huggingface.co/docs/transformers/model_doc/swin)**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰ä¸è®ºæ–‡[Swin
    Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºZe
    Liuã€Yutong Linã€Yue Caoã€Han Huã€Yixuan Weiã€Zheng Zhangã€Stephen Linã€Baining Guoã€‚'
- en: '**[Swin2SR](https://huggingface.co/docs/transformers/model_doc/swin2sr)** (from
    University of WÃ¼rzburg) released with the paper [Swin2SR: SwinV2 Transformer for
    Compressed Image Super-Resolution and Restoration](https://arxiv.org/abs/2209.11345)
    by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Swin2SR](https://huggingface.co/docs/transformers/model_doc/swin2sr)**ï¼ˆæ¥è‡ªWÃ¼rzburgå¤§å­¦ï¼‰ä¸è®ºæ–‡[Swin2SR:
    SwinV2 Transformer for Compressed Image Super-Resolution and Restoration](https://arxiv.org/abs/2209.11345)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºMarcos
    V. Condeã€Ui-Jin Choiã€Maxime Burchiã€Radu Timofteã€‚'
- en: '**[T5](https://huggingface.co/docs/transformers/model_doc/t5)** (from Google
    AI) released with the paper [Exploring the Limits of Transfer Learning with a
    Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin Raffel
    and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael
    Matena and Yanqi Zhou and Wei Li and Peter J. Liu.'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[T5](https://huggingface.co/docs/transformers/model_doc/t5)**ï¼ˆæ¥è‡ªGoogle AIï¼‰ä¸è®ºæ–‡[Exploring
    the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)ä¸€èµ·å‘å¸ƒï¼Œä½œè€…ä¸ºColin
    Raffelã€Noam Shazeerã€Adam Robertsã€Katherine Leeã€Sharan Narangã€Michael Matenaã€Yanqi
    Zhouã€Wei Liã€Peter J. Liuã€‚'
- en: '**[T5v1.1](https://huggingface.co/docs/transformers/model_doc/t5v1.1)** (from
    Google AI) released in the repository [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511)
    by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan
    Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[T5v1.1](https://huggingface.co/docs/transformers/model_doc/t5v1.1)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰åœ¨[google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511)ä»“åº“ä¸­å‘å¸ƒï¼Œä½œè€…ä¸ºColin
    Raffelã€Noam Shazeerã€Adam Robertsã€Katherine Leeã€Sharan Narangã€Michael Matenaã€Yanqi
    Zhouã€Wei Liã€Peter J. Liuã€‚'
- en: '**[Table Transformer](https://huggingface.co/docs/transformers/model_doc/table-transformer)**
    (from Microsoft Research) released with the paper [PubTables-1M: Towards Comprehensive
    Table Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061)
    by Brandon Smock, Rohith Pesala, Robin Abraham.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Table Transformer](https://huggingface.co/docs/transformers/model_doc/table-transformer)**ï¼ˆæ¥è‡ªå¾®è½¯ç ”ç©¶é™¢ï¼‰ï¼Œä¸Brandon
    Smockã€Rohith Pesalaã€Robin Abrahamåˆä½œå‘å¸ƒäº†è®ºæ–‡[PubTables-1M: Towards Comprehensive Table
    Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061)ã€‚'
- en: '**[TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)** (from
    Microsoft), released together with the paper [TrOCR: Transformer-based Optical
    Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282)
    by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun
    Li, Furu Wei.'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰ï¼Œä¸Minghao
    Liã€Tengchao Lvã€Lei Cuiã€Yijuan Luã€Dinei Florencioã€Cha Zhangã€Zhoujun Liã€Furu Weiåˆä½œå‘å¸ƒäº†è®ºæ–‡[TrOCR:
    Transformer-based Optical Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282)ã€‚'
- en: '**[Vision Transformer (ViT)](https://huggingface.co/docs/transformers/model_doc/vit)**
    (from Google AI) released with the paper [An Image is Worth 16x16 Words: Transformers
    for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) by Alexey Dosovitskiy,
    Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
    Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,
    Neil Houlsby.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Vision Transformer (ViT)](https://huggingface.co/docs/transformers/model_doc/vit)**ï¼ˆæ¥è‡ªGoogle
    AIï¼‰ï¼Œä¸Alexey Dosovitskiyã€Lucas Beyerã€Alexander Kolesnikovã€Dirk Weissenbornã€Xiaohua
    Zhaiã€Thomas Unterthinerã€Mostafa Dehghaniã€Matthias Mindererã€Georg Heigoldã€Sylvain
    Gellyã€Jakob Uszkoreitã€Neil Houlsbyåˆä½œå‘å¸ƒäº†è®ºæ–‡[An Image is Worth 16x16 Words: Transformers
    for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)ã€‚'
- en: '**[ViTMatte](https://huggingface.co/docs/transformers/model_doc/vitmatte)**
    (from HUST-VL) released with the paper [ViTMatte: Boosting Image Matting with
    Pretrained Plain Vision Transformers](https://arxiv.org/abs/2305.15272) by Jingfeng
    Yao, Xinggang Wang, Shusheng Yang, Baoyuan Wang.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ViTMatte](https://huggingface.co/docs/transformers/model_doc/vitmatte)**ï¼ˆæ¥è‡ªHUST-VLï¼‰ï¼Œä¸Jingfeng
    Yaoã€Xinggang Wangã€Shusheng Yangã€Baoyuan Wangåˆä½œå‘å¸ƒäº†è®ºæ–‡[ViTMatte: Boosting Image Matting
    with Pretrained Plain Vision Transformers](https://arxiv.org/abs/2305.15272)ã€‚'
- en: '**[VITS](https://huggingface.co/docs/transformers/model_doc/vits)** (from Kakao
    Enterprise) released with the paper [Conditional Variational Autoencoder with
    Adversarial Learning for End-to-End Text-to-Speech](https://arxiv.org/abs/2106.06103)
    by Jaehyeon Kim, Jungil Kong, Juhee Son.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[VITS](https://huggingface.co/docs/transformers/model_doc/vits)**ï¼ˆæ¥è‡ªKakao
    Enterpriseï¼‰ï¼Œä¸Jaehyeon Kimã€Jungil Kongã€Juhee Sonåˆä½œå‘å¸ƒäº†è®ºæ–‡[Conditional Variational
    Autoencoder with Adversarial Learning for End-to-End Text-to-Speech](https://arxiv.org/abs/2106.06103)ã€‚'
- en: '**[Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)**
    (from Facebook AI) released with the paper [wav2vec 2.0: A Framework for Self-Supervised
    Learning of Speech Representations](https://arxiv.org/abs/2006.11477) by Alexei
    Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)**ï¼ˆæ¥è‡ªFacebook
    AIï¼‰ï¼Œä¸Alexei Baevskiã€Henry Zhouã€Abdelrahman Mohamedã€Michael Auliåˆä½œå‘å¸ƒäº†è®ºæ–‡[wav2vec
    2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477)ã€‚'
- en: '**[Wav2Vec2-BERT](https://huggingface.co/docs/transformers/main/model_doc/wav2vec2-bert)**
    (from Meta AI) released with the paper [Seamless: Multilingual Expressive and
    Streaming Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)
    by the Seamless Communication team.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Wav2Vec2-BERT](https://huggingface.co/docs/transformers/main/model_doc/wav2vec2-bert)**ï¼ˆæ¥è‡ªMeta
    AIï¼‰ï¼Œä¸Seamless Communicationå›¢é˜Ÿåˆä½œå‘å¸ƒäº†è®ºæ–‡[Seamless: Multilingual Expressive and Streaming
    Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)ã€‚'
- en: '**[WavLM](https://huggingface.co/docs/transformers/model_doc/wavlm)** (from
    Microsoft Research) released with the paper [WavLM: Large-Scale Self-Supervised
    Pre-Training for Full Stack Speech Processing](https://arxiv.org/abs/2110.13900)
    by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu
    Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren,
    Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[WavLM](https://huggingface.co/docs/transformers/model_doc/wavlm)**ï¼ˆæ¥è‡ªå¾®è½¯ç ”ç©¶é™¢ï¼‰ï¼Œä¸Sanyuan
    Chenã€Chengyi Wangã€Zhengyang Chenã€Yu Wuã€Shujie Liuã€Zhuo Chenã€Jinyu Liã€Naoyuki Kandaã€Takuya
    Yoshiokaã€Xiong Xiaoã€Jian Wuã€Long Zhouã€Shuo Renã€Yanmin Qianã€Yao Qianã€Jian Wuã€Michael
    Zengã€Furu Weiåˆä½œå‘å¸ƒäº†è®ºæ–‡[WavLM: Large-Scale Self-Supervised Pre-Training for Full
    Stack Speech Processing](https://arxiv.org/abs/2110.13900)ã€‚'
- en: '**[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)** (from
    OpenAI) released with the paper [Robust Speech Recognition via Large-Scale Weak
    Supervision](https://cdn.openai.com/papers/whisper.pdf) by Alec Radford, Jong
    Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)**ï¼ˆæ¥è‡ªOpenAIï¼‰ï¼Œä¸Alec
    Radfordã€Jong Wook Kimã€Tao Xuã€Greg Brockmanã€Christine McLeaveyã€Ilya Sutskeveråˆä½œå‘å¸ƒäº†è®ºæ–‡[Robust
    Speech Recognition via Large-Scale Weak Supervision](https://cdn.openai.com/papers/whisper.pdf)ã€‚'
- en: '**[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (from Facebook)
    released together with the paper [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291)
    by Guillaume Lample and Alexis Conneau.'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)**ï¼ˆæ¥è‡ªFacebookï¼‰ï¼Œä¸Guillaume
    Lampleå’ŒAlexis Conneauåˆä½œå‘å¸ƒäº†è®ºæ–‡[Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291)ã€‚'
- en: '**[XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta)**
    (from Facebook AI), released together with the paper [Unsupervised Cross-lingual
    Representation Learning at Scale](https://arxiv.org/abs/1911.02116) by Alexis
    Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek,
    Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta)**ï¼ˆæ¥è‡ªFacebook
    AIï¼‰ï¼Œä¸Alexis Conneauã€Kartikay Khandelwalã€Naman Goyalã€Vishrav Chaudharyã€Guillaume
    Wenzekã€Francisco GuzmÃ¡nã€Edouard Graveã€Myle Ottã€Luke Zettlemoyerå’ŒVeselin Stoyanovåˆä½œå‘å¸ƒäº†è®ºæ–‡[Unsupervised
    Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116)ã€‚'
- en: '**[YOLOS](https://huggingface.co/docs/transformers/model_doc/yolos)** (from
    Huazhong University of Science & Technology) released with the paper [You Only
    Look at One Sequence: Rethinking Transformer in Vision through Object Detection](https://arxiv.org/abs/2106.00666)
    by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei
    Niu, Wenyu Liu.'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[YOLOS](https://huggingface.co/docs/transformers/model_doc/yolos)**ï¼ˆæ¥è‡ªåä¸­ç§‘æŠ€å¤§å­¦ï¼‰æ˜¯ç”±Yuxin
    Fangã€Bencheng Liaoã€Xinggang Wangã€Jiemin Fangã€Jiyang Qiã€Rui Wuã€Jianwei Niuã€Wenyu
    Liuç­‰äººå‘è¡¨çš„è®ºæ–‡[You Only Look at One Sequence: Rethinking Transformer in Vision through
    Object Detection](https://arxiv.org/abs/2106.00666)å‘å¸ƒçš„ã€‚'
