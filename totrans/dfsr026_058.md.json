["```py\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npip install .\n```", "```py\ncd examples/text_to_image\npip install -r requirements.txt\n```", "```py\naccelerate config\n```", "```py\naccelerate config default\n```", "```py\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config()\n```", "```py\naccelerate launch train_text_to_image.py \\\n  --mixed_precision=\"fp16\"\n```", "```py\naccelerate launch train_text_to_image.py \\\n  --snr_gamma=5.0\n```", "```py\nnoise_scheduler = DDPMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder=\"scheduler\")\ntokenizer = CLIPTokenizer.from_pretrained(\n    args.pretrained_model_name_or_path, subfolder=\"tokenizer\", revision=args.revision\n)\n```", "```py\nload_model = UNet2DConditionModel.from_pretrained(input_dir, subfolder=\"unet\")\nmodel.register_to_config(**load_model.config)\n\nmodel.load_state_dict(load_model.state_dict())\n```", "```py\ndef preprocess_train(examples):\n    images = [image.convert(\"RGB\") for image in examples[image_column]]\n    examples[\"pixel_values\"] = [train_transforms(image) for image in images]\n    examples[\"input_ids\"] = tokenize_captions(examples)\n    return examples\n```", "```py\nexport MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\nexport dataset_name=\"lambdalabs/pokemon-blip-captions\"\n\naccelerate launch --mixed_precision=\"fp16\"  train_text_to_image.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\n  --dataset_name=$dataset_name \\\n  --use_ema \\\n  --resolution=512 --center_crop --random_flip \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=4 \\\n  --gradient_checkpointing \\\n  --max_train_steps=15000 \\\n  --learning_rate=1e-05 \\\n  --max_grad_norm=1 \\\n  --enable_xformers_memory_efficient_attention\n  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n  --output_dir=\"sd-pokemon-model\" \\\n  --push_to_hub\n```", "```py\nfrom diffusers import StableDiffusionPipeline\nimport torch\n\npipeline = StableDiffusionPipeline.from_pretrained(\"path/to/saved_model\", torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n\nimage = pipeline(prompt=\"yoda\").images[0]\nimage.save(\"yoda-pokemon.png\")\n```"]