- en: 'Hands-on: advanced Deep Reinforcement Learning. Using Sample Factory to play
    Doom from pixels'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit8/hands-on-sf](https://huggingface.co/learn/deep-rl-course/unit8/hands-on-sf)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![Ask a Question](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit8/unit8_part2.ipynb)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The colab notebook: [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit8/unit8_part2.ipynb)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'Unit 8 Part 2: Advanced Deep Reinforcement Learning. Using Sample Factory to
    play Doom from pixels'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Thumbnail](../Images/1636e0752d93a1e41c70f4a1147a2563.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: In this notebook, we will learn how to train a Deep Neural Network to collect
    objects in a 3D environment based on the game of Doom, a video of the resulting
    policy is shown below. We train this policy using [Sample Factory](https://www.samplefactory.dev/),
    an asynchronous implementation of the PPO algorithm.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'Please note the following points:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[Sample Factory](https://www.samplefactory.dev/) is an advanced RL framework
    and **only functions on Linux and Mac** (not Windows).'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The framework performs best on a **GPU machine with many CPU cores**, where
    it can achieve speeds of 100k interactions per second. The resources available
    on a standard Colab notebook **limit the performance of this library**. So the
    speed in this setting **does not reflect the real-world performance**.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarks for Sample Factory are available in a number of settings, check out
    the [examples](https://github.com/alex-petrenko/sample-factory/tree/master/sf_examples)
    if you want to find out more.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process),
    you need to push one model:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '`doom_health_gathering_supreme` get a result of >= 5.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To find your result, go to the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)
    and find your model, **the result = mean_reward - std of reward**
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: If you donâ€™t find your model, **go to the bottom of the page and click on the
    refresh button**
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: For more information about the certification process, check this section ğŸ‘‰ [https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Set the GPU ğŸ’ª
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To **accelerate the agentâ€™s training, weâ€™ll use a GPU**. To do that, go to `Runtime
    > Change Runtime type`
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![GPU Step 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: '`Hardware Accelerator > GPU`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![GPU Step 2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: Before starting to train our agent, letâ€™s **study the library and environments
    weâ€™re going to use**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Sample Factory
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Sample Factory](https://www.samplefactory.dev/) is one of the **fastest RL
    libraries focused on very efficient synchronous and asynchronous implementations
    of policy gradients (PPO)**.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Sample Factory is thoroughly **tested, used by many researchers and practitioners**,
    and is actively maintained. Our implementation is known to **reach SOTA performance
    in a variety of domains while minimizing RL experiment training time and hardware
    requirements**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![Sample factory](../Images/cec8dbebc3e783f8e71a5698f72f4450.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Key features
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Highly optimized algorithmÂ [architecture](https://www.samplefactory.dev/06-architecture/overview/)Â for
    maximum learning throughput
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Synchronous and asynchronous](https://www.samplefactory.dev/07-advanced-topics/sync-async/)Â training
    regimes'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Serial (single-process) mode](https://www.samplefactory.dev/07-advanced-topics/serial-mode/)Â for
    easy debugging'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimal performance in both CPU-based andÂ [GPU-accelerated environments](https://www.samplefactory.dev/09-environment-integrations/isaacgym/)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨åŸºäºCPUå’Œ[GPUåŠ é€Ÿç¯å¢ƒ](https://www.samplefactory.dev/09-environment-integrations/isaacgym/)ä¸­å®ç°æœ€ä½³æ€§èƒ½
- en: Single- & multi-agent training, self-play, supportsÂ [training multiple policies](https://www.samplefactory.dev/07-advanced-topics/multi-policy-training/)Â at
    once on one or many GPUs
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä¸€å’Œå¤šä»£ç†è®­ç»ƒï¼Œè‡ªæˆ‘å¯¹å¼ˆï¼Œæ”¯æŒä¸€æ¬¡åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªGPUä¸Š[è®­ç»ƒå¤šä¸ªç­–ç•¥](https://www.samplefactory.dev/07-advanced-topics/multi-policy-training/)
- en: Population-Based Training ([PBT](https://www.samplefactory.dev/07-advanced-topics/pbt/))
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºäººå£çš„è®­ç»ƒï¼ˆ[PBT](https://www.samplefactory.dev/07-advanced-topics/pbt/)ï¼‰
- en: Discrete, continuous, hybrid action spaces
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¦»æ•£ã€è¿ç»­ã€æ··åˆåŠ¨ä½œç©ºé—´
- en: Vector-based, image-based, dictionary observation spaces
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºå‘é‡ã€åŸºäºå›¾åƒã€åŸºäºå­—å…¸çš„è§‚å¯Ÿç©ºé—´
- en: Automatically creates a model architecture by parsing action/observation space
    specification. SupportsÂ [custom model architectures](https://www.samplefactory.dev/03-customization/custom-models/)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡è§£æåŠ¨ä½œ/è§‚å¯Ÿç©ºé—´è§„èŒƒè‡ªåŠ¨åˆ›å»ºæ¨¡å‹æ¶æ„ã€‚æ”¯æŒ[è‡ªå®šä¹‰æ¨¡å‹æ¶æ„](https://www.samplefactory.dev/03-customization/custom-models/)
- en: Designed to be imported into other projects,Â [custom environments](https://www.samplefactory.dev/03-customization/custom-environments/)Â are
    first-class citizens
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¾è®¡ä¸ºå¯å¯¼å…¥å…¶ä»–é¡¹ç›®ï¼Œ[è‡ªå®šä¹‰ç¯å¢ƒ](https://www.samplefactory.dev/03-customization/custom-environments/)æ˜¯ä¸€ç­‰å…¬æ°‘
- en: DetailedÂ [WandB and Tensorboard summaries](https://www.samplefactory.dev/05-monitoring/metrics-reference/),Â [custom
    metrics](https://www.samplefactory.dev/05-monitoring/custom-metrics/)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¦ç»†çš„[WandBå’ŒTensorboardæ‘˜è¦](https://www.samplefactory.dev/05-monitoring/metrics-reference/)ï¼Œ[è‡ªå®šä¹‰æŒ‡æ ‡](https://www.samplefactory.dev/05-monitoring/custom-metrics/)
- en: '[HuggingFace ğŸ¤— integration](https://www.samplefactory.dev/10-huggingface/huggingface/)Â (upload
    trained models and metrics to the Hub)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingFace ğŸ¤— é›†æˆ](https://www.samplefactory.dev/10-huggingface/huggingface/)ï¼ˆä¸Šä¼ è®­ç»ƒæ¨¡å‹å’ŒæŒ‡æ ‡åˆ°Hubï¼‰'
- en: '[Multiple](https://www.samplefactory.dev/09-environment-integrations/mujoco/)Â [example](https://www.samplefactory.dev/09-environment-integrations/atari/)Â [environment](https://www.samplefactory.dev/09-environment-integrations/vizdoom/)Â [integrations](https://www.samplefactory.dev/09-environment-integrations/dmlab/)Â with
    tuned parameters and trained models'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å¤šä¸ª](https://www.samplefactory.dev/09-environment-integrations/mujoco/) [ç¤ºä¾‹](https://www.samplefactory.dev/09-environment-integrations/atari/)
    [ç¯å¢ƒ](https://www.samplefactory.dev/09-environment-integrations/vizdoom/) [é›†æˆ](https://www.samplefactory.dev/09-environment-integrations/dmlab/)ï¼Œå…·æœ‰è°ƒæ•´å‚æ•°å’Œè®­ç»ƒæ¨¡å‹'
- en: All of the above policies are available on the ğŸ¤— hub. Search for the tag [sample-factory](https://huggingface.co/models?library=sample-factory&sort=downloads)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸Šæ‰€æœ‰ç­–ç•¥éƒ½å¯ä»¥åœ¨ğŸ¤— hubä¸Šæ‰¾åˆ°ã€‚æœç´¢æ ‡ç­¾[sample-factory](https://huggingface.co/models?library=sample-factory&sort=downloads)
- en: How sample-factory works
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Sample-factoryçš„å·¥ä½œåŸç†
- en: Sample-factory is one of the **most highly optimized RL implementations available
    to the community**.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Sample-factoryæ˜¯**ç¤¾åŒºä¸­æœ€é«˜åº¦ä¼˜åŒ–çš„RLå®ç°ä¹‹ä¸€**ã€‚
- en: It works by **spawning multiple processes that run rollout workers, inference
    workers and a learner worker**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒé€šè¿‡**ç”Ÿæˆå¤šä¸ªè¿›ç¨‹æ¥è¿è¡Œæ¨å‡ºå·¥ä½œè€…ã€æ¨ç†å·¥ä½œè€…å’Œå­¦ä¹ è€…å·¥ä½œè€…**ã€‚
- en: The *workers* **communicate through shared memory, which lowers the communication
    cost between processes**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*å·¥ä½œè€…* **é€šè¿‡å…±äº«å†…å­˜è¿›è¡Œé€šä¿¡ï¼Œé™ä½äº†è¿›ç¨‹ä¹‹é—´çš„é€šä¿¡æˆæœ¬**ã€‚'
- en: The *rollout workers* interact with the environment and send observations to
    the *inference workers*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ¨å‡ºå·¥ä½œè€…* ä¸ç¯å¢ƒäº¤äº’å¹¶å°†è§‚å¯Ÿå‘é€ç»™*æ¨ç†å·¥ä½œè€…*ã€‚'
- en: The *inferences workers* query a fixed version of the policy and **send actions
    back to the rollout worker**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ¨ç†å·¥ä½œè€…* æŸ¥è¯¢ç­–ç•¥çš„å›ºå®šç‰ˆæœ¬å¹¶**å°†åŠ¨ä½œå‘é€å›æ¨å‡ºå·¥ä½œè€…**ã€‚'
- en: After *k* steps the rollout works send a trajectory of experience to the learner
    worker, **which it uses to update the agentâ€™s policy network**.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*k*æ­¥éª¤ä¹‹åï¼Œæ¨å‡ºå·¥ä½œå‘é€ä¸€æ¡ç»éªŒè½¨è¿¹ç»™å­¦ä¹ è€…å·¥ä½œè€…ï¼Œ**ç”¨äºæ›´æ–°ä»£ç†çš„ç­–ç•¥ç½‘ç»œ**ã€‚
- en: '![Sample factory](../Images/dbf151279f91bb01f87ae6359c6f520f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![Sample factory](../Images/dbf151279f91bb01f87ae6359c6f520f.png)'
- en: Actor Critic models in Sample-factory
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Sample-factoryä¸­çš„Actor Criticæ¨¡å‹
- en: 'Actor Critic models in Sample Factory are composed of three components:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Sample Factoryä¸­çš„Actor Criticæ¨¡å‹ç”±ä¸‰ä¸ªç»„ä»¶ç»„æˆï¼š
- en: '**Encoder** - Process input observations (images, vectors) and map them to
    a vector. This is the part of the model you will most likely want to customize.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¼–ç å™¨** - å¤„ç†è¾“å…¥è§‚å¯Ÿï¼ˆå›¾åƒã€å‘é‡ï¼‰å¹¶å°†å®ƒä»¬æ˜ å°„åˆ°ä¸€ä¸ªå‘é‡ã€‚è¿™æ˜¯æ‚¨æœ€æœ‰å¯èƒ½æƒ³è¦è‡ªå®šä¹‰çš„æ¨¡å‹çš„éƒ¨åˆ†ã€‚'
- en: '**Core** - Intergrate vectors from one or more encoders, can optionally include
    a single- or multi-layer LSTM/GRU in a memory-based agent.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ¸å¿ƒ** - é›†æˆæ¥è‡ªä¸€ä¸ªæˆ–å¤šä¸ªç¼–ç å™¨çš„å‘é‡ï¼Œå¯ä»¥é€‰æ‹©åŒ…æ‹¬ä¸€ä¸ªå•å±‚æˆ–å¤šå±‚LSTM/GRUåœ¨åŸºäºå†…å­˜çš„ä»£ç†ä¸­ã€‚'
- en: '**Decoder** - Apply additional layers to the output of the model core before
    computing the policy and value outputs.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§£ç å™¨** - åœ¨è®¡ç®—ç­–ç•¥å’Œä»·å€¼è¾“å‡ºä¹‹å‰ï¼Œå¯¹æ¨¡å‹æ ¸å¿ƒçš„è¾“å‡ºåº”ç”¨é¢å¤–å±‚ã€‚'
- en: The library has been designed to automatically support any observation and action
    spaces. Users can easily add their custom models. You can find out more in the
    [documentation](https://www.samplefactory.dev/03-customization/custom-models/#actor-critic-models-in-sample-factory).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åº“å·²è¢«è®¾è®¡ä¸ºè‡ªåŠ¨æ”¯æŒä»»ä½•è§‚å¯Ÿå’ŒåŠ¨ä½œç©ºé—´ã€‚ç”¨æˆ·å¯ä»¥è½»æ¾æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹ã€‚æ‚¨å¯ä»¥åœ¨[æ–‡æ¡£](https://www.samplefactory.dev/03-customization/custom-models/#actor-critic-models-in-sample-factory)ä¸­æ‰¾åˆ°æ›´å¤šä¿¡æ¯ã€‚
- en: ViZDoom
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ViZDoom
- en: '[ViZDoom](https://vizdoom.cs.put.edu.pl/) is an **open-source python interface
    for the Doom Engine**.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[ViZDoom](https://vizdoom.cs.put.edu.pl/)æ˜¯ä¸€ä¸ª**Doomå¼•æ“çš„å¼€æºPythonæ¥å£**ã€‚'
- en: The library was created in 2016 by Marek Wydmuch, Michal Kempka at theÂ Institute
    of Computing Science, Poznan University of Technology, Poland.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åº“ç”±æ³¢å…°æ³¢å…¹å—ç†å·¥å¤§å­¦è®¡ç®—ç§‘å­¦ç ”ç©¶æ‰€çš„Marek Wydmuchã€Michal Kempkaäº2016å¹´åˆ›å»ºã€‚
- en: The library enables the **training of agents directly from the screen pixels
    in a number of scenarios**, including team deathmatch, shown in the video below.
    Because the ViZDoom environment is based on a game the was created in the 90s,
    it can be run on modern hardware at accelerated speeds, **allowing us to learn
    complex AI behaviors fairly quickly**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åº“ä½¿å¾—**ç›´æ¥ä»å±å¹•åƒç´ è®­ç»ƒä»£ç†åœ¨è®¸å¤šåœºæ™¯ä¸­æˆä¸ºå¯èƒ½**ï¼ŒåŒ…æ‹¬åœ¨ä¸‹é¢çš„è§†é¢‘ä¸­å±•ç¤ºçš„å›¢é˜Ÿæ­»æ–—ã€‚ç”±äºViZDoomç¯å¢ƒåŸºäº90å¹´ä»£åˆ›å»ºçš„æ¸¸æˆï¼Œå®ƒå¯ä»¥åœ¨ç°ä»£ç¡¬ä»¶ä¸Šä»¥åŠ é€Ÿé€Ÿåº¦è¿è¡Œï¼Œ**ä½¿æˆ‘ä»¬èƒ½å¤Ÿç›¸å½“å¿«é€Ÿåœ°å­¦ä¹ å¤æ‚çš„AIè¡Œä¸º**ã€‚
- en: 'The library includes feature such as:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åº“åŒ…æ‹¬ä»¥ä¸‹åŠŸèƒ½ï¼š
- en: Multi-platform (Linux, macOS, Windows),
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šå¹³å°ï¼ˆLinuxã€macOSã€Windowsï¼‰ï¼Œ
- en: API for Python and C++,
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pythonå’ŒC++çš„APIï¼Œ
- en: '[OpenAI Gym](https://www.gymlibrary.dev/)Â environment wrappers'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy-to-create custom scenarios (visual editors, scripting language, and examples
    available),
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Async and sync single-player and multiplayer modes,
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lightweight (few MBs) and fast (up to 7000 fps in sync mode, single-threaded),
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customizable resolution and rendering parameters,
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to the depth buffer (3D vision),
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic labeling of game objects visible in the frame,
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to the audio buffer
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to the list of actors/objects and map geometry,
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Off-screen rendering and episode recording,
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time scaling in async mode.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We first need to install some dependencies that are required for the ViZDoom
    environment
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that our Colab runtime is set up, we can start by installing the dependencies
    required to run ViZDoom on linux.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: If you are following on your machine on Mac, you will want to follow the installation
    instructions on the [github page](https://github.com/Farama-Foundation/ViZDoom/blob/master/doc/Quickstart.md#-quickstart-for-macos-and-anaconda3-python-36).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then we can install Sample Factory and ViZDoom
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This can take 7min
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Setting up the Doom Environment in sample-factory
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that the setup if complete, we can train the agent. We have chosen here
    to learn a ViZDoom task called `Health Gathering Supreme`.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'The scenario: Health Gathering Supreme'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Health-Gathering-Supreme](../Images/08a1a85695f5485b036e974dd75dc6b6.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
- en: The objective of this scenario is to **teach the agent how to survive without
    knowing what makes it survive**. The Agent know only that **life is precious**
    and death is bad so **it must learn what prolongs its existence and that its health
    is connected with survival**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: The map is a rectangle containing walls and with a green, acidic floor which
    **hurts the player periodically**. Initially there are some medkits spread uniformly
    over the map. A new medkit falls from the skies every now and then. **Medkits
    heal some portions of playerâ€™s health** - to survive, the agent needs to pick
    them up. The episode finishes after the playerâ€™s death or on timeout.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Further configuration:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Living_reward = 1
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3 available buttons: turn left, turn right, move forward'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '1 available game variable: HEALTH'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: death penalty = 100
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find out more about the scenarios available in ViZDoom [here](https://github.com/Farama-Foundation/ViZDoom/tree/master/scenarios).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: There are also a number of more complex scenarios that have been create for
    ViZDoom, such as the ones detailed on [this github page](https://github.com/edbeeching/3d_control_deep_rl).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Training the agent
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Weâ€™re going to train the agent for 4000000 steps. It will take approximately
    20min
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Letâ€™s take a look at the performance of the trained policy and output a video
    of the agent.
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now lets visualize the performance of the agent
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The agent has learned something, but its performance could be better. We would
    clearly need to train for longer. But letâ€™s upload this model to the Hub.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Now lets upload your checkpoint and video to the Hugging Face Hub
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To be able to share your model with the community there are three more steps
    to follow:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 1ï¸âƒ£ (If itâ€™s not already done) create an account to HF â¡ [https://huggingface.co/join](https://huggingface.co/join)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 2ï¸âƒ£ Sign in and get your authentication token from the Hugging Face website.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Create a new token ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
    **with write role**
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Copy the token
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the cell below and paste the token
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you donâ€™t want to use Google Colab or a Jupyter Notebook, you need to use
    this command instead: `huggingface-cli login`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Letâ€™s load another model
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This agentâ€™s performance was good, but we can do better! Letâ€™s download and
    visualize an agent trained for 10B timesteps from the hub.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Some additional challenges ğŸ†: Doom Deathmatch'
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Training an agent to play a Doom deathmatch **takes many hours on a more beefy
    machine than is available in Colab**.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we have have **already trained an agent in this scenario and it
    is available in the ğŸ¤— Hub!** Letâ€™s download the model and visualize the agentâ€™s
    performance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å·²ç»è®­ç»ƒè¿‡ä¸€ä¸ªä»£ç†ï¼Œå¹¶ä¸”å®ƒå¯ä»¥åœ¨ğŸ¤— Hubä¸­ä½¿ç”¨ï¼è®©æˆ‘ä»¬ä¸‹è½½æ¨¡å‹å¹¶å¯è§†åŒ–ä»£ç†çš„è¡¨ç°ã€‚
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Given the agent plays for a long time the video generation can take **10 minutes**.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°ä»£ç†ç©äº†å¾ˆé•¿æ—¶é—´ï¼Œè§†é¢‘ç”Ÿæˆå¯èƒ½éœ€è¦10åˆ†é’Ÿã€‚
- en: '[PRE14]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You **can try to train your agent in this environment** using the code above,
    but not on colab. **Good luck ğŸ¤**
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å°è¯•ä½¿ç”¨ä¸Šé¢çš„ä»£ç åœ¨è¿™ä¸ªç¯å¢ƒä¸­è®­ç»ƒä½ çš„ä»£ç†ï¼Œä½†ä¸è¦åœ¨colabä¸Šã€‚ç¥ä½ å¥½è¿ğŸ¤
- en: If you prefer an easier scenario, **why not try training in another ViZDoom
    scenario such as `doom_deadly_corridor` or `doom_defend_the_center`.**
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ›´å–œæ¬¢ä¸€ä¸ªæ›´ç®€å•çš„æƒ…æ™¯ï¼Œä¸ºä»€ä¹ˆä¸å°è¯•åœ¨å¦ä¸€ä¸ªViZDoomæƒ…æ™¯ä¸­è®­ç»ƒï¼Œæ¯”å¦‚`doom_deadly_corridor`æˆ–`doom_defend_the_center`ã€‚
- en: '* * *'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This concludes the last unit. But we are not finished yet! ğŸ¤— The following **bonus
    section include some of the most interesting, advanced, and cutting edge work
    in Deep Reinforcement Learning**.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»“æŸäº†æœ€åä¸€ä¸ªå•å…ƒã€‚ä½†æˆ‘ä»¬è¿˜æ²¡æœ‰å®Œæˆï¼ğŸ¤— æ¥ä¸‹æ¥çš„**å¥–åŠ±éƒ¨åˆ†åŒ…æ‹¬ä¸€äº›æœ€æœ‰è¶£ã€å…ˆè¿›å’Œå°–ç«¯çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ å·¥ä½œ**ã€‚
- en: Keep learning, stay awesome ğŸ¤—
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»§ç»­å­¦ä¹ ï¼Œä¿æŒå‡ºè‰²ğŸ¤—
