# 处理文本数据

> 原始文本：[https://huggingface.co/docs/datasets/nlp_process](https://huggingface.co/docs/datasets/nlp_process)

本指南展示了处理文本数据集的具体方法。学习如何：

+   使用 [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) 对数据集进行标记化。

+   将数据集标签与 NLI 数据集的标签 id 对齐。

有关如何处理任何类型的数据集的指南，请查看[通用处理指南](./process)。

## 映射

[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) 函数支持一次处理批量示例，从而加快标记化速度。

从 🤗 [Transformers](https://huggingface.co/transformers/) 加载标记器：

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
```

在 [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) 函数中将 `batched` 参数设置为 `True`，以将标记器应用于批量示例：

```py
>>> dataset = dataset.map(lambda examples: tokenizer(examples["text"]), batched=True)
>>> dataset[0]
{'text': 'the rock is destined to be the 21st century\'s new " conan " and that he\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 
 'label': 1, 
 'input_ids': [101, 1996, 2600, 2003, 16036, 2000, 2022, 1996, 7398, 2301, 1005, 1055, 2047, 1000, 16608, 1000, 1998, 2008, 2002, 1005, 1055, 2183, 2000, 2191, 1037, 17624, 2130, 3618, 2084, 7779, 29058, 8625, 13327, 1010, 3744, 1011, 18856, 19513, 3158, 5477, 4168, 2030, 7112, 16562, 2140, 1012, 102], 
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) 函数将返回的值转换为 PyArrow 支持的格式。但是，将张量显式返回为 NumPy 数组更快，因为它是本机支持的 PyArrow 格式。在标记文本时设置 `return_tensors="np"`：

```py
>>> dataset = dataset.map(lambda examples: tokenizer(examples["text"], return_tensors="np"), batched=True)
```

## 对齐

[align_labels_with_mapping()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping) 函数将数据集标签 id 与标签名称对齐。并非所有 🤗 Transformers 模型都遵循原始数据集的规定标签映射，特别是对于 NLI 数据集。例如，[MNLI](https://huggingface.co/datasets/glue) 数据集使用以下标签映射：

```py
>>> label2id = {"entailment": 0, "neutral": 1, "contradiction": 2}
```

为了将数据集标签映射与模型使用的映射对齐，创建一个包含标签名称和 id 的字典进行对齐：

```py
>>> label2id = {"contradiction": 0, "neutral": 1, "entailment": 2}
```

将标签映射的字典传递给 [align_labels_with_mapping()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping) 函数，并指定要对齐的列：

```py
>>> from datasets import load_dataset

>>> mnli = load_dataset("glue", "mnli", split="train")
>>> mnli_aligned = mnli.align_labels_with_mapping(label2id, "label")
```

您还可以使用此函数将标签映射到 id 的自定义映射。
