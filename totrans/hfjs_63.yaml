- en: 🤗 Hugging Face Agents.js
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🤗 Hugging Face Agents.js
- en: 'Original text: [https://huggingface.co/docs/huggingface.js/agents/README](https://huggingface.co/docs/huggingface.js/agents/README)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/huggingface.js/agents/README](https://huggingface.co/docs/huggingface.js/agents/README)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: A way to call Hugging Face models and Inference Endpoints from natural language,
    using an LLM.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一种从自然语言中调用Hugging Face模型和推理端点的方法，使用LLM。
- en: Install
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Deno
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Deno
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Usage
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法
- en: Agents.js leverages LLMs hosted as Inference Endpoints on HF, so you need to
    create an account and generate an [access token](https://huggingface.co/settings/tokens).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Agents.js利用在HF上托管的LLM作为推理端点，因此您需要创建一个帐户并生成一个[访问令牌](https://huggingface.co/settings/tokens)。
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Choose your LLM
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择您的LLM
- en: You can also use your own LLM, by calling one of the `LLMFrom*` functions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过调用`LLMFrom*`函数之一来使用自己的LLM。
- en: From the hub
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 来自hub
- en: You can specify any valid model on the hub as long as they have an API.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 只要它们有API，您可以指定hub上的任何有效模型。
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: From your own endpoints
  id: totrans-16
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从您自己的端点
- en: You can also specify your own endpoint, as long as it implements the same API,
    for exemple using [text generation inference](https://github.com/huggingface/text-generation-inference)
    and [Inference Endpoints](https://huggingface.co/inference-endpoints).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以指定自己的端点，只要它实现相同的API，例如使用[text generation inference](https://github.com/huggingface/text-generation-inference)和[Inference
    Endpoints](https://huggingface.co/inference-endpoints)。
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Custom LLM
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自定义LLM
- en: 'A LLM in this context is defined as any async function that takes a string
    input and returns a string. For example if you wanted to use the OpenAI API you
    could do so like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，LLM被定义为任何异步函数，它接受一个字符串输入并返回一个字符串。 例如，如果您想要使用OpenAI API，您可以这样做：
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Tools
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工具
- en: By default, agents ship with 4 tools. (textToImage, textToSpeech, imageToText,
    speechToText)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，代理程序配备有4种工具。 （textToImage，textToSpeech，imageToText，speechToText）
- en: But you can expand the list of tools easily by creating new tools and passing
    them at initialization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但是您可以通过创建新工具并在初始化时传递它们来轻松扩展工具列表。
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Dependencies
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 依赖
- en: '`@huggingface/inference` : Required to call the inference endpoints themselves.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@huggingface/inference`：需要调用推理端点本身。'
