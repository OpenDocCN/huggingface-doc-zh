- en: ðŸ¤— Hugging Face Agents.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/huggingface.js/agents/README](https://huggingface.co/docs/huggingface.js/agents/README)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/huggingface.js/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/entry/start.66898800.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/chunks/scheduler.0219f8bd.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/chunks/singletons.80ab1bd5.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/chunks/paths.0bae90f7.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/entry/app.fac00ab7.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/chunks/index.f61edf3b.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/nodes/0.9401948a.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/nodes/2.ac7c323e.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/chunks/CodeBlock.38e566ae.js">
    <link rel="modulepreload" href="/docs/huggingface.js/main/en/_app/immutable/chunks/Heading.d33122ca.js">
  prefs: []
  type: TYPE_NORMAL
- en: A way to call Hugging Face models and Inference Endpoints from natural language,
    using an LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Install
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Deno
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agents.js leverages LLMs hosted as Inference Endpoints on HF, so you need to
    create an account and generate an [access token](https://huggingface.co/settings/tokens).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Choose your LLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also use your own LLM, by calling one of the `LLMFrom*` functions.
  prefs: []
  type: TYPE_NORMAL
- en: From the hub
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can specify any valid model on the hub as long as they have an API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: From your own endpoints
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can also specify your own endpoint, as long as it implements the same API,
    for exemple using [text generation inference](https://github.com/huggingface/text-generation-inference)
    and [Inference Endpoints](https://huggingface.co/inference-endpoints).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Custom LLM
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A LLM in this context is defined as any async function that takes a string
    input and returns a string. For example if you wanted to use the OpenAI API you
    could do so like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By default, agents ship with 4 tools. (textToImage, textToSpeech, imageToText,
    speechToText)
  prefs: []
  type: TYPE_NORMAL
- en: But you can expand the list of tools easily by creating new tools and passing
    them at initialization.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`@huggingface/inference` : Required to call the inference endpoints themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
