# 提示加权

> 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/weighted_prompts](https://huggingface.co/docs/diffusers/using-diffusers/weighted_prompts)

提示加权提供了一种强调或减弱提示中某些部分的方法，从而更好地控制生成的图像。提示可以包含多个概念，这些概念会转化为上下文化的文本嵌入。这些嵌入被模型用于调节其交叉注意力层以生成图像（阅读Stable Diffusion的[博文](https://huggingface.co/blog/stable_diffusion)以了解更多工作原理）。

提示加权通过增加或减少与提示中概念对应的文本嵌入向量的比例来工作，因为您可能并不一定希望模型平等关注所有概念。准备提示加权嵌入的最简单方法是使用[Compel](https://github.com/damian0815/compel)，一个文本提示加权和混合库。一旦您有了提示加权的嵌入，您可以将它们传递给任何具有[`prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__.prompt_embeds)（以及可选的[`negative_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__.negative_prompt_embeds)）参数的管道，例如[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)、[StableDiffusionControlNetPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/controlnet#diffusers.StableDiffusionControlNetPipeline)和[StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)。

如果您喜欢的管道没有`prompt_embeds`参数，请打开一个[问题](https://github.com/huggingface/diffusers/issues/new/choose)，以便我们可以添加它！

本指南将向您展示如何在🤗 Diffusers中使用Compel对提示进行加权和混合。

在开始之前，请确保您已安装了最新版本的Compel：

```py
# uncomment to install in Colab
#!pip install compel --upgrade
```

在本指南中，让我们使用[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)生成一个带有提示“一只红色的猫正在玩球”的图像：

```py
from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler
import torch

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", use_safetensors=True)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.to("cuda")

prompt = "a red cat playing with a ball"

generator = torch.Generator(device="cpu").manual_seed(33)

image = pipe(prompt, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/24306b5413fb415e890bea8d0fc47df3.png)

## 加权

您会注意到图像中没有“球”！让我们使用compel来增加提示中“球”的概念。创建一个[`Compel`](https://github.com/damian0815/compel/blob/main/doc/compel.md#compel-objects)对象，并传递一个分词器和文本编码器：

```py
from compel import Compel

compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)
```

compel使用`+`或`-`来增加或减少提示中单词的权重。要增加“球”的权重：

`+` 对应值`1.1`，`++` 对应`1.1^2`，依此类推。同样，`-` 对应`0.9`，`--` 对应`0.9^2`。请随意尝试在您的提示中添加更多的`+`或`-`！

```py
prompt = "a red cat playing with a ball++"
```

将提示传递给`compel_proc`以创建新的提示嵌入，然后传递给管道：

```py
prompt_embeds = compel_proc(prompt)
generator = torch.manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/a6ea0a8316ec0e299ce79bd94f29d7a8.png)

要减少提示的某些部分的权重，请使用`-`后缀：

```py
prompt = "a red------- cat playing with a ball"
prompt_embeds = compel_proc(prompt)

generator = torch.manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/eed909df9ef11a12b97771b8f85ab810.png)

您甚至可以在同一个提示中增加或减少多个概念：

```py
prompt = "a red cat++ playing with a ball----"
prompt_embeds = compel_proc(prompt)

generator = torch.manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/b82d3f52e501e13a58f1b034a7a8f0ad.png)

## 混合

您还可以通过将`.blend()`添加到提示列表并传递一些权重来创建加权的*混合*提示。您的混合可能不总是产生您期望的结果，因为它会打破有关文本编码器功能的一些假设，所以只是玩得开心，尝试一下！

```py
prompt_embeds = compel_proc('("a red cat playing with a ball", "jungle").blend(0.7, 0.8)')
generator = torch.Generator(device="cuda").manual_seed(33)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/103f3c5f3fa90b6e9ec2d9e26bbb49cc.png)

## 连接

一个连词独立地扩散每个提示，并通过它们的加权和连接它们的结果。在提示列表的末尾添加`.and()`以创建一个连词：

```py
prompt_embeds = compel_proc('["a red cat", "playing with a", "ball"].and()')
generator = torch.Generator(device="cuda").manual_seed(55)

image = pipe(prompt_embeds=prompt_embeds, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/82df108b16157d244b56b16b408735a0.png)

## 文本反转

[文本反转](../training/text_inversion)是一种从一些图像中学习特定概念的技术，您可以使用它来生成基于该概念的新图像。

创建一个管道，并使用[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)函数加载文本反转嵌入（随时浏览[稳定扩散概念化器](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer)以获取100多个训练概念）：

```py
import torch
from diffusers import StableDiffusionPipeline
from compel import Compel, DiffusersTextualInversionManager

pipe = StableDiffusionPipeline.from_pretrained(
  "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16,
  use_safetensors=True, variant="fp16").to("cuda")
pipe.load_textual_inversion("sd-concepts-library/midjourney-style")
```

Compel提供了一个`DiffusersTextualInversionManager`类，用于简化文本反转的提示加权。实例化`DiffusersTextualInversionManager`并将其传递给`Compel`类：

```py
textual_inversion_manager = DiffusersTextualInversionManager(pipe)
compel_proc = Compel(
    tokenizer=pipe.tokenizer,
    text_encoder=pipe.text_encoder,
    textual_inversion_manager=textual_inversion_manager)
```

将概念合并到条件提示中，使用`<concept>`语法：

```py
prompt_embeds = compel_proc('("A red cat++ playing with a ball <midjourney-style>")')

image = pipe(prompt_embeds=prompt_embeds).images[0]
image
```

![](../Images/018f9f77083d1e4a4a4c59065acae017.png)

## DreamBooth

[DreamBooth](../training/dreambooth)是一种技术，可以根据对主题的几张图像生成主题化图像，而无需对主题进行训练。它类似于文本反转，但DreamBooth训练完整模型，而文本反转只是微调文本嵌入。这意味着您应该使用[from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)来加载DreamBooth模型（随时浏览[稳定扩散Dreambooth概念库](https://huggingface.co/sd-dreambooth-library)以获取100多个训练模型）：

```py
import torch
from diffusers import DiffusionPipeline, UniPCMultistepScheduler
from compel import Compel

pipe = DiffusionPipeline.from_pretrained("sd-dreambooth-library/dndcoverart-v1", torch_dtype=torch.float16).to("cuda")
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
```

创建一个带有分词器和文本编码器的`Compel`类，并将您的提示传递给它。根据您使用的模型，您需要将模型的唯一标识符合并到您的提示中。例如，`dndcoverart-v1`模型使用标识符`dndcoverart`：

```py
compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)
prompt_embeds = compel_proc('("magazine cover of a dndcoverart dragon, high quality, intricate details, larry elmore art style").and()')
image = pipe(prompt_embeds=prompt_embeds).images[0]
image
```

![](../Images/5b0fd6647d5253e64ddf3beb46283bde.png)

## 稳定扩散XL

稳定扩散XL（SDXL）有两个分词器和文本编码器，因此它的使用方式有点不同。为了解决这个问题，您应该将两个分词器和编码器都传递给`Compel`类：

```py
from compel import Compel, ReturnedEmbeddingsType
from diffusers import DiffusionPipeline
from diffusers.utils import make_image_grid
import torch

pipeline = DiffusionPipeline.from_pretrained(
  "stabilityai/stable-diffusion-xl-base-1.0",
  variant="fp16",
  use_safetensors=True,
  torch_dtype=torch.float16
).to("cuda")

compel = Compel(
  tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2] ,
  text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2],
  returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,
  requires_pooled=[False, True]
)
```

这一次，让我们将第一个提示中的“球”权重提高1.5倍，并将第二个提示中的“球”权重降低0.6倍。[StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)还需要[`pooled_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline.__call__.pooled_prompt_embeds)（以及可选的[`negative_pooled_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline.__call__.negative_pooled_prompt_embeds)），因此您应该将这些传递给管道以及条件张量：

```py
# apply weights
prompt = ["a red cat playing with a (ball)1.5", "a red cat playing with a (ball)0.6"]
conditioning, pooled = compel(prompt)

# generate image
generator = [torch.Generator().manual_seed(33) for _ in range(len(prompt))]
images = pipeline(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, generator=generator, num_inference_steps=30).images
make_image_grid(images, rows=1, cols=2)
```

![](../Images/067abbd7c08a8dee4ee6a6f556c86e97.png)

一只红色的猫正在玩一个（球）1.5

![](../Images/1c14404c57c40fb1d0c84a7c12d4cb5c.png)

一只红色的猫正在玩一个（球）0.6
