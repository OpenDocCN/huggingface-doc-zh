# ç¨³å®šæ‰©æ•£ XL

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/diffusers/training/sdxl`](https://huggingface.co/docs/diffusers/training/sdxl)

è¿™ä¸ªè„šæœ¬æ˜¯å®éªŒæ€§çš„ï¼Œå¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆå¹¶é‡åˆ°åƒç¾éš¾æ€§é—å¿˜è¿™æ ·çš„é—®é¢˜ã€‚å°è¯•æ¢ç´¢ä¸åŒçš„è¶…å‚æ•°ä»¥è·å¾—æ•°æ®é›†ä¸Šçš„æœ€ä½³ç»“æœã€‚

[ç¨³å®šæ‰©æ•£ XLï¼ˆSDXLï¼‰](https://hf.co/papers/2307.01952)æ˜¯ç¨³å®šæ‰©æ•£æ¨¡å‹çš„ä¸€ä¸ªæ›´å¤§æ›´å¼ºå¤§çš„è¿­ä»£ç‰ˆæœ¬ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚

SDXL çš„ UNet æ˜¯ 3 å€å¤§ï¼Œæ¨¡å‹åœ¨æ¶æ„ä¸­æ·»åŠ äº†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚æ ¹æ®æ‚¨å¯ç”¨çš„ç¡¬ä»¶ï¼Œè¿™å¯èƒ½éå¸¸è®¡ç®—å¯†é›†ï¼Œå¯èƒ½æ— æ³•åœ¨åƒ Tesla T4 è¿™æ ·çš„æ¶ˆè´¹è€… GPU ä¸Šè¿è¡Œã€‚ä¸ºäº†å°†è¿™ä¸ªæ›´å¤§çš„æ¨¡å‹é€‚åº”å†…å­˜å¹¶åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œè¯·å°è¯•å¯ç”¨`gradient_checkpointing`ã€`mixed_precision`å’Œ`gradient_accumulation_steps`ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡å¯ç”¨ xFormers çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œä½¿ç”¨[bitsandbytes'](https://github.com/TimDettmers/bitsandbytes) 8 ä½ä¼˜åŒ–å™¨æ¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜ä½¿ç”¨ã€‚

æœ¬æŒ‡å—å°†æ¢è®¨[train_text_to_image_sdxl.py](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_sdxl.py)è®­ç»ƒè„šæœ¬ï¼Œä»¥å¸®åŠ©æ‚¨æ›´ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºæ‚¨è‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»æºä»£ç å®‰è£…åº“ï¼š

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

ç„¶åè½¬åˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶ä¸ºæ‚¨æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬å®‰è£…æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

```py
cd examples/text_to_image
pip install -r requirements_sdxl.txt
```

ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ª GPU/TPU ä¸Šæˆ–ä½¿ç”¨æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒçš„åº“ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤— Accelerate [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šã€‚

åˆå§‹åŒ–ä¸€ä¸ªğŸ¤— Accelerate ç¯å¢ƒï¼š

```py
accelerate config
```

è¦è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„ğŸ¤— Accelerate ç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š

```py
accelerate config default
```

æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼Œå¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚

## è„šæœ¬å‚æ•°

ä»¥ä¸‹å„èŠ‚çªå‡ºäº†è®­ç»ƒè„šæœ¬çš„é‡è¦éƒ¨åˆ†ï¼Œä»¥å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_sdxl.py)ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬æ‚¨æ˜¯å¦æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°ï¼Œä»¥å¸®åŠ©æ‚¨è‡ªå®šä¹‰è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L129)å‡½æ•°ä¸­æ‰¾åˆ°ã€‚è¯¥å‡½æ•°ä¸ºæ¯ä¸ªå‚æ•°æä¾›äº†é»˜è®¤å€¼ï¼Œå¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œä¸ºäº†ä½¿ç”¨ bf16 æ ¼å¼åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œå°†`--mixed_precision`å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```py
accelerate launch train_text_to_image_sdxl.py \
  --mixed_precision="bf16"
```

å¤§å¤šæ•°å‚æ•°ä¸æ–‡æœ¬åˆ°å›¾åƒè®­ç»ƒæŒ‡å—ä¸­çš„å‚æ•°ç›¸åŒï¼Œå› æ­¤æ‚¨å°†ä¸“æ³¨äºæœ¬æŒ‡å—ä¸­ä¸è®­ç»ƒ SDXL ç›¸å…³çš„å‚æ•°ã€‚

+   `--pretrained_vae_model_name_or_path`ï¼šé¢„è®­ç»ƒ VAE çš„è·¯å¾„ï¼›SDXL VAE å·²çŸ¥å­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œå› æ­¤æ­¤å‚æ•°å…è®¸æ‚¨æŒ‡å®šæ›´å¥½çš„[VAE](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)

+   `--proportion_empty_prompts`ï¼šè¦æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²çš„å›¾åƒæç¤ºçš„æ¯”ä¾‹

+   `--timestep_bias_strategy`ï¼šåœ¨æ—¶é—´æ­¥ä¸­åº”ç”¨åå·®çš„ä½ç½®ï¼ˆè¾ƒæ—©è¿˜æ˜¯è¾ƒæ™šï¼‰ï¼Œå¯ä»¥é¼“åŠ±æ¨¡å‹å­¦ä¹ ä½é¢‘æˆ–é«˜é¢‘ç»†èŠ‚

+   `--timestep_bias_multiplier`ï¼šåº”ç”¨äºæ—¶é—´æ­¥çš„åå·®æƒé‡

+   -- timestep_bias_beginï¼šå¼€å§‹åº”ç”¨åå·®çš„æ—¶é—´æ­¥

+   `--timestep_bias_end`ï¼šç»“æŸåº”ç”¨åå·®çš„æ—¶é—´æ­¥

+   `--timestep_bias_portion`ï¼šåº”ç”¨åå·®çš„æ—¶é—´æ­¥æ¯”ä¾‹

### Min-SNR åŠ æƒ

[Min-SNR](https://huggingface.co/papers/2303.09556)åŠ æƒç­–ç•¥å¯ä»¥å¸®åŠ©è®­ç»ƒï¼Œé€šè¿‡é‡æ–°å¹³è¡¡æŸå¤±æ¥å®ç°æ›´å¿«çš„æ”¶æ•›ã€‚è®­ç»ƒè„šæœ¬æ”¯æŒé¢„æµ‹`epsilon`ï¼ˆå™ªå£°ï¼‰æˆ–`v_prediction`ï¼Œä½† Min-SNR ä¸ä¸¤ç§é¢„æµ‹ç±»å‹å…¼å®¹ã€‚è¿™ç§åŠ æƒç­–ç•¥ä»…å— PyTorch æ”¯æŒï¼Œåœ¨ Flax è®­ç»ƒè„šæœ¬ä¸­ä¸å¯ç”¨ã€‚

æ·»åŠ `--snr_gamma`å‚æ•°ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºæ¨èå€¼ 5.0ï¼š

```py
accelerate launch train_text_to_image_sdxl.py \
  --snr_gamma=5.0
```

## è®­ç»ƒè„šæœ¬

è®­ç»ƒè„šæœ¬ä¹Ÿç±»ä¼¼äºæ–‡æœ¬åˆ°å›¾åƒè®­ç»ƒæŒ‡å—ï¼Œä½†å·²ç»ä¿®æ”¹ä¸ºæ”¯æŒ SDXL è®­ç»ƒã€‚æœ¬æŒ‡å—å°†é‡ç‚¹æ”¾åœ¨ SDXL è®­ç»ƒè„šæœ¬ä¸­ç‹¬ç‰¹çš„ä»£ç ä¸Šã€‚

é¦–å…ˆåˆ›å»ºå‡½æ•°æ¥[å¯¹æç¤ºè¿›è¡Œæ ‡è®°åŒ–](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L478)ä»¥è®¡ç®—æç¤ºåµŒå…¥ï¼Œå¹¶ä½¿ç”¨[VAE](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L519)è®¡ç®—å›¾åƒåµŒå…¥ã€‚æ¥ä¸‹æ¥ï¼Œæ‚¨å°†åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥[ç”Ÿæˆæ—¶é—´æ­¥æƒé‡](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L531)ï¼Œå…·ä½“å–å†³äºæ—¶é—´æ­¥æ•°å’Œè¦åº”ç”¨çš„æ—¶é—´æ­¥åå·®ç­–ç•¥ã€‚

åœ¨[`main()`](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L572)å‡½æ•°ä¸­ï¼Œé™¤äº†åŠ è½½ä¸€ä¸ªåˆ†è¯å™¨å¤–ï¼Œè„šæœ¬è¿˜åŠ è½½äº†ç¬¬äºŒä¸ªåˆ†è¯å™¨å’Œæ–‡æœ¬ç¼–ç å™¨ï¼Œå› ä¸º SDXL æ¶æ„ä½¿ç”¨äº†ä¸¤ä¸ªï¼š 

```py
tokenizer_one = AutoTokenizer.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="tokenizer", revision=args.revision, use_fast=False
)
tokenizer_two = AutoTokenizer.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="tokenizer_2", revision=args.revision, use_fast=False
)

text_encoder_cls_one = import_model_class_from_model_name_or_path(
    args.pretrained_model_name_or_path, args.revision
)
text_encoder_cls_two = import_model_class_from_model_name_or_path(
    args.pretrained_model_name_or_path, args.revision, subfolder="text_encoder_2"
)
```

é¦–å…ˆè®¡ç®—å¹¶ä¿å­˜[æç¤ºå’Œå›¾åƒåµŒå…¥](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L857)ï¼Œè¿™é€šå¸¸å¯¹äºè¾ƒå°çš„æ•°æ®é›†ä¸æ˜¯é—®é¢˜ï¼Œä½†å¯¹äºè¾ƒå¤§çš„æ•°æ®é›†å¯èƒ½ä¼šå¯¼è‡´å†…å­˜é—®é¢˜ã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œæ‚¨åº”è¯¥å°†é¢„å…ˆè®¡ç®—çš„åµŒå…¥å•ç‹¬ä¿å­˜åˆ°ç£ç›˜ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†å…¶åŠ è½½åˆ°å†…å­˜ä¸­ï¼ˆè¯·å‚é˜…æ­¤[PR](https://github.com/huggingface/diffusers/pull/4505)ä»¥è·å–æœ‰å…³æ­¤ä¸»é¢˜çš„æ›´å¤šè®¨è®ºï¼‰ã€‚

```py
text_encoders = [text_encoder_one, text_encoder_two]
tokenizers = [tokenizer_one, tokenizer_two]
compute_embeddings_fn = functools.partial(
    encode_prompt,
    text_encoders=text_encoders,
    tokenizers=tokenizers,
    proportion_empty_prompts=args.proportion_empty_prompts,
    caption_column=args.caption_column,
)

train_dataset = train_dataset.map(compute_embeddings_fn, batched=True, new_fingerprint=new_fingerprint)
train_dataset = train_dataset.map(
    compute_vae_encodings_fn,
    batched=True,
    batch_size=args.train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps,
    new_fingerprint=new_fingerprint_for_vae,
)
```

è®¡ç®—åµŒå…¥åï¼Œæ–‡æœ¬ç¼–ç å™¨ã€VAE å’Œåˆ†è¯å™¨å°†è¢«åˆ é™¤ä»¥é‡Šæ”¾ä¸€äº›å†…å­˜ï¼š

```py
del text_encoders, tokenizers, vae
gc.collect()
torch.cuda.empty_cache()
```

æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/text_to_image/train_text_to_image_sdxl.py#L943)ä¼šå¤„ç†å‰©ä¸‹çš„äº‹æƒ…ã€‚å¦‚æœé€‰æ‹©åº”ç”¨æ—¶é—´æ­¥åå·®ç­–ç•¥ï¼Œæ‚¨å°†çœ‹åˆ°æ—¶é—´æ­¥æƒé‡è¢«è®¡ç®—å¹¶æ·»åŠ ä¸ºå™ªå£°ï¼š

```py
weights = generate_timestep_weights(args, noise_scheduler.config.num_train_timesteps).to(
        model_input.device
    )
    timesteps = torch.multinomial(weights, bsz, replacement=True).long()

noisy_model_input = noise_scheduler.add_noise(model_input, noise, timesteps)
```

å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹ç†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è§£æäº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## å¯åŠ¨è„šæœ¬

ä¸€æ—¦æ‚¨å®Œæˆæ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€

è®©æˆ‘ä»¬åœ¨[PokÃ©mon BLIP æ ‡é¢˜](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œç”Ÿæˆæ‚¨è‡ªå·±çš„ PokÃ©monã€‚å°†ç¯å¢ƒå˜é‡`MODEL_NAME`å’Œ`DATASET_NAME`è®¾ç½®ä¸ºæ¨¡å‹å’Œæ•°æ®é›†ï¼ˆå¯ä»¥æ¥è‡ª Hub æˆ–æœ¬åœ°è·¯å¾„ï¼‰ã€‚æ‚¨è¿˜åº”è¯¥æŒ‡å®šä¸€ä¸ªé™¤ SDXL VAE ä¹‹å¤–çš„ VAEï¼ˆå¯ä»¥æ¥è‡ª Hub æˆ–æœ¬åœ°è·¯å¾„ï¼‰ï¼Œå¹¶ä½¿ç”¨`VAE_NAME`é¿å…æ•°å€¼ä¸ç¨³å®šã€‚

ä½¿ç”¨ Weightsï¼†Biases ç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œå°†`--report_to=wandb`å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ã€‚æ‚¨è¿˜éœ€è¦å°†`--validation_prompt`å’Œ`--validation_epochs`æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ä»¥è·Ÿè¸ªç»“æœã€‚è¿™å¯¹äºè°ƒè¯•æ¨¡å‹å’ŒæŸ¥çœ‹ä¸­é—´ç»“æœéå¸¸æœ‰ç”¨ã€‚

```py
export MODEL_NAME="stabilityai/stable-diffusion-xl-base-1.0"
export VAE_NAME="madebyollin/sdxl-vae-fp16-fix"
export DATASET_NAME="lambdalabs/pokemon-blip-captions"

accelerate launch train_text_to_image_sdxl.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --pretrained_vae_model_name_or_path=$VAE_NAME \
  --dataset_name=$DATASET_NAME \
  --enable_xformers_memory_efficient_attention \
  --resolution=512 \
  --center_crop \
  --random_flip \
  --proportion_empty_prompts=0.2 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --max_train_steps=10000 \
  --use_8bit_adam \
  --learning_rate=1e-06 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --mixed_precision="fp16" \
  --report_to="wandb" \
  --validation_prompt="a cute Sundar Pichai creature" \
  --validation_epochs 5 \
  --checkpointing_steps=5000 \
  --output_dir="sdxl-pokemon-model" \
  --push_to_hub
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„ SDXL æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼

PyTorchPyTorch XLA

```py
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained("path/to/your/model", torch_dtype=torch.float16).to("cuda")

prompt = "A pokemon with green eyes and red legs."
image = pipeline(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
image.save("pokemon.png")
```

## ä¸‹ä¸€æ­¥

ç¥è´ºæ‚¨è®­ç»ƒäº†ä¸€ä¸ª SDXL æ¨¡å‹ï¼è¦äº†è§£å¦‚ä½•ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ï¼Œä»¥ä¸‹æŒ‡å—å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š

+   é˜…è¯» Stable Diffusion XL æŒ‡å—ï¼Œäº†è§£å¦‚ä½•å°†å…¶ç”¨äºå„ç§ä¸åŒä»»åŠ¡ï¼ˆæ–‡æœ¬åˆ°å›¾åƒï¼Œå›¾åƒåˆ°å›¾åƒï¼Œä¿®å¤ï¼‰ï¼Œå¦‚ä½•ä½¿ç”¨å…¶ç»†åŒ–å™¨æ¨¡å‹ä»¥åŠä¸åŒç±»å‹çš„å¾®è°ƒã€‚

+   æŸ¥çœ‹ DreamBooth å’Œ LoRA åŸ¹è®­æŒ‡å—ï¼Œäº†è§£å¦‚ä½•ä»…ä½¿ç”¨å‡ ä¸ªç¤ºä¾‹å›¾åƒè®­ç»ƒä¸ªæ€§åŒ–çš„ SDXL æ¨¡å‹ã€‚è¿™ä¸¤ç§è®­ç»ƒæŠ€æœ¯ç”šè‡³å¯ä»¥ç»“åˆä½¿ç”¨ï¼
