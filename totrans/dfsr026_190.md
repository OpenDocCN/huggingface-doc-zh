# DEISMultistepScheduler

> 原始文本：[https://huggingface.co/docs/diffusers/api/schedulers/deis](https://huggingface.co/docs/diffusers/api/schedulers/deis)

扩散指数积分器采样器（DEIS）由Qinsheng Zhang和Yongxin Chen在[使用指数积分器快速采样扩散模型](https://huggingface.co/papers/2204.13902)中提出。`DEISMultistepScheduler`是扩散常微分方程（ODEs）的快速高阶求解器。

这个实现修改了DEIS论文中原始线性`t`空间的多项式拟合公式，改为在log-rho空间中。这种修改享有指数多步更新的封闭形式系数，而不是依赖于数值求解器。

论文摘要如下：

*过去几年见证了扩散模型（DMs）在生成生成建模任务中高保真样本方面取得的巨大成功。 DM的一个主要限制是其臭名昭著的缓慢采样过程，通常需要数百到数千个时间离散化步骤来达到所需的精度。我们的目标是为DMs开发一种快速采样方法，步数要少得多，同时保持高样本质量。为此，我们系统地分析了DMs中的采样过程，并确定了影响样本质量的关键因素，其中离散化方法最为关键。通过仔细检查学习到的扩散过程，我们提出了扩散指数积分器采样器（DEIS）。它基于为离散化常微分方程（ODEs）设计的指数积分器，并利用学习到的扩散过程的半线性结构来减少离散化误差。该方法可以应用于任何DMs，并且可以在仅10步的情况下生成高保真样本。在我们的实验中，使用一个A6000 GPU从CIFAR10生成50k图像大约需要3分钟。此外，通过直接使用预训练的DMs，我们在评分函数评估次数有限的情况下实现了最先进的采样性能，例如，在CIFAR10上仅使用15个评分函数评估次数时，FID为4.17，FID为3.37，IS为9.74。代码可在[this https URL](https://github.com/qsh-zh/deis)上找到。*

## 提示

建议将`solver_order`设置为2或3，而`solver_order=1`等同于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)。

支持来自[Imagen](https://huggingface.co/papers/2205.11487)的动态阈值，对于像素空间扩散模型，您可以设置`thresholding=True`来使用动态阈值。

## DEISMultistepScheduler

### `class diffusers.DEISMultistepScheduler`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L74)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Optional = None solver_order: int = 2 prediction_type: str = 'epsilon' thresholding: bool = False dynamic_thresholding_ratio: float = 0.995 sample_max_value: float = 1.0 algorithm_type: str = 'deis' solver_type: str = 'logrho' lower_order_final: bool = True use_karras_sigmas: Optional = False timestep_spacing: str = 'linspace' steps_offset: int = 0 )
```

参数

+   `num_train_timesteps` (`int`, 默认为1000) — 训练模型的扩散步数。

+   `beta_start` (`float`, 默认为0.0001) — 推断的起始`beta`值。

+   `beta_end` (`float`, 默认为0.02) — 最终的`beta`值。

+   `beta_schedule` (`str`, 默认为`"linear"`) — beta调度，从beta范围到用于步进模型的一系列beta的映射。选择`linear`、`scaled_linear`或`squaredcos_cap_v2`。

+   `trained_betas` (`np.ndarray`, *optional*) — 传递一个beta数组直接给构造函数，以绕过`beta_start`和`beta_end`。

+   `solver_order` (`int`, 默认为2) — DEIS阶数，可以是`1`或`2`或`3`。建议对于引导采样使用`solver_order=2`，对于无条件采样使用`solver_order=3`。

+   `prediction_type` (`str`, 默认为`epsilon`) — 调度函数的预测类型；可以是`epsilon`（预测扩散过程的噪声），`sample`（直接预测有噪声的样本）或`v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文第2.4节）。

+   `thresholding` (`bool`, 默认为`False`) — 是否使用“动态阈值”方法。这不适用于Latent-space扩散模型，如Stable Diffusion。

+   `dynamic_thresholding_ratio` (`float`, 默认为0.995) — 动态阈值方法的比率。仅在`thresholding=True`时有效。

+   `sample_max_value` (`float`, 默认为1.0) — 动态阈值的阈值值。仅在`thresholding=True`时有效。

+   `algorithm_type` (`str`, 默认为`deis`) — 求解器的算法类型。

+   `lower_order_final` (`bool`, 默认为`True`) — 是否在最后步骤中使用低阶求解器。仅对<15个推断步骤有效。

+   `use_karras_sigmas` (`bool`, *可选*, 默认为`False`) — 在采样过程中是否使用Karras sigmas作为噪声计划中的步长。如果为`True`，则根据噪声级别序列{σi}确定sigmas。

+   `timestep_spacing` (`str`, 默认为`"linspace"`) — 时间步长应如何缩放。有关更多信息，请参考[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表2。

+   `steps_offset` (`int`, 默认为0) — 添加到推断步骤的偏移量。您可以使用`offset=1`和`set_alpha_to_one=False`的组合，使最后一步使用步骤0来计算先前alpha乘积，就像在Stable Diffusion中一样。

`DEISMultistepScheduler`是扩散常微分方程（ODEs）的快速高阶求解器。

此模型继承自[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)和[ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。查看超类文档以了解库为所有调度程序实现的通用方法，如加载和保存。

#### `convert_model_output`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L351)

```py
( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`int`) — 扩散链中的当前离散时间步。

+   `sample` (`torch.FloatTensor`) — 扩散过程创建的样本的当前实例。

返回

`torch.FloatTensor`

转换后的模型输出。

将模型输出转换为DEIS算法所需的相应类型。

#### `deis_first_order_update`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L408)

```py
( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`int`) — 扩散链中的当前离散时间步。

+   `prev_timestep` (`int`) — 扩散链中的上一个离散时间步。

+   `sample` (`torch.FloatTensor`) — 扩散过程创建的样本的当前实例。

返回

`torch.FloatTensor`

上一个时间步的样本张量。

第一阶DEIS的一步（相当于DDIM）。

#### `multistep_deis_second_order_update`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L466)

```py
( model_output_list: List *args sample: FloatTensor = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `model_output_list` (`List[torch.FloatTensor]`) — 当前和后续时间步的学习扩散模型的直接输出。

+   `sample` (`torch.FloatTensor`) — 扩散过程创建的样本的当前实例。

返回

`torch.FloatTensor`

上一个时间步的样本张量。

第二阶多步DEIS的一步。

#### `multistep_deis_third_order_update`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L535)

```py
( model_output_list: List *args sample: FloatTensor = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `model_output_list` (`List[torch.FloatTensor]`) — 当前和后续时间步的学习扩散模型的直接输出。

+   `sample` (`torch.FloatTensor`) — 扩散过程创建的样本的当前实例。

返回

`torch.FloatTensor`

前一个时间步的样本张量。

第三阶多步DEIS的一步。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L707)

```py
( sample: FloatTensor *args **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

返回值

`torch.FloatTensor`

一个经过缩放的输入样本。

确保与需要根据当前时间步长缩放去噪模型输入的调度器可互换。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L199)

```py
( num_inference_steps: int device: Union = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步骤数。

+   `device` (`str` 或 `torch.device`，*可选*) — 时间步应移动到的设备。如果为`None`，则不移动时间步。

设置用于扩散链的离散时间步骤（在推断之前运行）。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_deis_multistep.py#L642)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`float`) — 扩散链中的当前离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `return_dict` (`bool`) — 是否返回[SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)或`tuple`。

返回值

[SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput) 或 `tuple`

如果`return_dict`为`True`，则返回[SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)，否则返回一个元组，其中第一个元素是样本张量。

通过反转SDE从前一个时间步预测样本。此函数使用多步DEIS传播样本。

## SchedulerOutput

### `class diffusers.schedulers.scheduling_utils.SchedulerOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_utils.py#L50)

```py
( prev_sample: FloatTensor )
```

参数

+   `prev_sample` (`torch.FloatTensor`，对于图像为形状为`(batch_size, num_channels, height, width)`的张量) — 前一个时间步的计算样本`(x_{t-1})`。`prev_sample`应在去噪循环中作为下一个模型输入使用。

调度器`step`函数的输出的基类。
