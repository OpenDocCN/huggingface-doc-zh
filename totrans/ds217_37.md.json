["```py\npip install -U albumentations \n```", "```py\n>>> from datasets import load_dataset\n\n>>> train_dataset = load_dataset(\"sayakpaul/nyu_depth_v2\", split=\"train\")\n>>> index = 17\n>>> example = train_dataset[index]\n>>> example\n{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=640x480>,\n 'depth_map': <PIL.TiffImagePlugin.TiffImageFile image mode=F size=640x480>}\n```", "```py\n>>> example[\"image\"]\n```", "```py\n>>> example[\"depth_map\"].convert(\"RGB\")\n```", "```py\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n\n>>> cmap = plt.cm.viridis\n\n>>> def colored_depthmap(depth, d_min=None, d_max=None):\n...     if d_min is None:\n...         d_min = np.min(depth)\n...     if d_max is None:\n...         d_max = np.max(depth)\n...     depth_relative = (depth - d_min) / (d_max - d_min)\n...     return 255 * cmap(depth_relative)[:,:,:3]\n\n>>> def show_depthmap(depth_map):\n...    if not isinstance(depth_map, np.ndarray):\n...        depth_map = np.array(depth_map)\n...    if depth_map.ndim == 3:\n...        depth_map = depth_map.squeeze()\n\n...    d_min = np.min(depth_map)\n...    d_max = np.max(depth_map)\n...    depth_map = colored_depthmap(depth_map, d_min, d_max)\n\n...    plt.imshow(depth_map.astype(\"uint8\"))\n...    plt.axis(\"off\")\n...    plt.show()\n\n>>> show_depthmap(example[\"depth_map\"])\n```", "```py\n>>> def merge_into_row(input_image, depth_target):\n...     if not isinstance(input_image, np.ndarray):\n...         input_image = np.array(input_image)\n...\n...     d_min = np.min(depth_target)\n...     d_max = np.max(depth_target)\n...     depth_target_col = colored_depthmap(depth_target, d_min, d_max)\n...     img_merge = np.hstack([input_image, depth_target_col])\n...\n...     return img_merge\n\n>>> random_indices = np.random.choice(len(train_dataset), 9).tolist()\n>>> plt.figure(figsize=(15, 6))\n>>> for i, idx in enumerate(random_indices):\n...     example = train_dataset[idx]\n...     ax = plt.subplot(3, 3, i + 1)\n...     image_viz = merge_into_row(\n...         example[\"image\"], example[\"depth_map\"]\n...     )\n...     plt.imshow(image_viz.astype(\"uint8\"))\n...     plt.axis(\"off\")\n```", "```py\n>>> import albumentations as A\n\n>>> crop_size = (448, 576)\n>>> transforms = [\n...     A.HorizontalFlip(p=0.5),\n...     A.RandomCrop(crop_size[0], crop_size[1]),\n...     A.RandomBrightnessContrast(),\n...     A.RandomGamma(),\n...     A.HueSaturationValue()\n... ]\n```", "```py\n>>> additional_targets = {\"depth\": \"mask\"}\n>>> aug = A.Compose(transforms=transforms, additional_targets=additional_targets)\n```", "```py\n>>> def apply_transforms(examples):\n...     transformed_images, transformed_maps = [], []\n...     for image, depth_map in zip(examples[\"image\"], examples[\"depth_map\"]):\n...         image, depth_map = np.array(image), np.array(depth_map)\n...         transformed = aug(image=image, depth=depth_map)\n...         transformed_images.append(transformed[\"image\"])\n...         transformed_maps.append(transformed[\"depth\"])\n...\n...     examples[\"pixel_values\"] = transformed_images\n...     examples[\"labels\"] = transformed_maps\n...     return examples\n```", "```py\n>>> train_dataset.set_transform(apply_transforms)\n```", "```py\n>>> example = train_dataset[index]\n\n>>> plt.imshow(example[\"pixel_values\"])\n>>> plt.axis(\"off\")\n>>> plt.show()\n```", "```py\n>>> show_depthmap(example[\"labels\"])\n```", "```py\n>>> plt.figure(figsize=(15, 6))\n\n>>> for i, idx in enumerate(random_indices):\n...     ax = plt.subplot(3, 3, i + 1)\n...     example = train_dataset[idx]\n...     image_viz = merge_into_row(\n...         example[\"pixel_values\"], example[\"labels\"]\n...     )\n...     plt.imshow(image_viz.astype(\"uint8\"))\n...     plt.axis(\"off\")\n```"]