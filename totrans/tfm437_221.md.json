["```py\n0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n| first sequence    | second sequence |\n```", "```py\n>>> from transformers import AutoTokenizer, ProphetNetModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> model = ProphetNetModel.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n\n>>> input_ids = tokenizer(\n...     \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n... ).input_ids  # Batch size 1\n>>> decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n>>> outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n\n>>> last_hidden_states = outputs.last_hidden_state  # main stream hidden states\n>>> last_hidden_states_ngram = outputs.last_hidden_state_ngram  # predict hidden states\n```", "```py\n>>> from transformers import AutoTokenizer, ProphetNetEncoder\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> model = ProphetNetEncoder.from_pretrained(\"patrickvonplaten/prophetnet-large-uncased-standalone\")\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, ProphetNetDecoder\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> model = ProphetNetDecoder.from_pretrained(\"microsoft/prophetnet-large-uncased\", add_cross_attention=False)\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, ProphetNetForConditionalGeneration\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> model = ProphetNetForConditionalGeneration.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n\n>>> input_ids = tokenizer(\n...     \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n... ).input_ids  # Batch size 1\n>>> decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n>>> outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n\n>>> logits_next_token = outputs.logits  # logits to predict next token as usual\n>>> logits_ngram_next_tokens = outputs.logits_ngram  # logits to predict 2nd, 3rd, ... next tokens\n```", "```py\n>>> from transformers import AutoTokenizer, ProphetNetForCausalLM\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> model = ProphetNetForCausalLM.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> assert model.config.is_decoder, f\"{model.__class__} has to be configured as a decoder.\"\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n\n>>> # Model can also be used with EncoderDecoder framework\n>>> from transformers import BertTokenizer, EncoderDecoderModel, AutoTokenizer\n>>> import torch\n\n>>> tokenizer_enc = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n>>> tokenizer_dec = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n>>> model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n...     \"bert-large-uncased\", \"microsoft/prophetnet-large-uncased\"\n... )\n\n>>> ARTICLE = (\n...     \"the us state department said wednesday it had received no \"\n...     \"formal word from bolivia that it was expelling the us ambassador there \"\n...     \"but said the charges made against him are `` baseless .\"\n... )\n>>> input_ids = tokenizer_enc(ARTICLE, return_tensors=\"pt\").input_ids\n>>> labels = tokenizer_dec(\n...     \"us rejects charges against its ambassador in bolivia\", return_tensors=\"pt\"\n... ).input_ids\n>>> outputs = model(input_ids=input_ids, decoder_input_ids=labels[:, :-1], labels=labels[:, 1:])\n\n>>> loss = outputs.loss\n```"]