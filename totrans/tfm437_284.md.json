["```py\n( num_channels = 3 num_encoder_blocks = 4 depths = [2, 2, 2, 2] sr_ratios = [8, 4, 2, 1] hidden_sizes = [32, 64, 160, 256] patch_sizes = [7, 3, 3, 3] strides = [4, 2, 2, 2] num_attention_heads = [1, 2, 5, 8] mlp_ratios = [4, 4, 4, 4] hidden_act = 'gelu' hidden_dropout_prob = 0.0 attention_probs_dropout_prob = 0.0 classifier_dropout_prob = 0.1 initializer_range = 0.02 drop_path_rate = 0.1 layer_norm_eps = 1e-06 decoder_hidden_size = 256 semantic_loss_ignore_index = 255 **kwargs )\n```", "```py\n>>> from transformers import SegformerModel, SegformerConfig\n\n>>> # Initializing a SegFormer nvidia/segformer-b0-finetuned-ade-512-512 style configuration\n>>> configuration = SegformerConfig()\n\n>>> # Initializing a model from the nvidia/segformer-b0-finetuned-ade-512-512 style configuration\n>>> model = SegformerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( *args **kwargs )\n```", "```py\n( images segmentation_maps = None **kwargs )\n```", "```py\n( outputs target_sizes: List = None ) \u2192 export const metadata = 'undefined';semantic_segmentation\n```", "```py\n( do_resize: bool = True size: Dict = None resample: Resampling = <Resampling.BILINEAR: 2> do_rescale: bool = True rescale_factor: Union = 0.00392156862745098 do_normalize: bool = True image_mean: Union = None image_std: Union = None do_reduce_labels: bool = False **kwargs )\n```", "```py\n( images: Union segmentation_maps: Union = None do_resize: Optional = None size: Optional = None resample: Resampling = None do_rescale: Optional = None rescale_factor: Optional = None do_normalize: Optional = None image_mean: Union = None image_std: Union = None do_reduce_labels: Optional = None return_tensors: Union = None data_format: ChannelDimension = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )\n```", "```py\n( outputs target_sizes: List = None ) \u2192 export const metadata = 'undefined';semantic_segmentation\n```", "```py\n( config )\n```", "```py\n( pixel_values: FloatTensor output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, SegformerModel\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"nvidia/mit-b0\")\n>>> model = SegformerModel.from_pretrained(\"nvidia/mit-b0\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 256, 16, 16]\n```", "```py\n( config )\n```", "```py\n( encoder_hidden_states: FloatTensor )\n```", "```py\n( config )\n```", "```py\n( pixel_values: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.segformer.modeling_segformer.SegFormerImageClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, SegformerForImageClassification\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"nvidia/mit-b0\")\n>>> model = SegformerForImageClassification.from_pretrained(\"nvidia/mit-b0\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = logits.argmax(-1).item()\n>>> print(model.config.id2label[predicted_label])\ntabby, tabby cat\n```", "```py\n( config )\n```", "```py\n( pixel_values: FloatTensor labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.SemanticSegmenterOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, SegformerForSemanticSegmentation\n>>> from PIL import Image\n>>> import requests\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n>>> model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> inputs = image_processor(images=image, return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n>>> list(logits.shape)\n[1, 150, 128, 128]\n```", "```py\n( config: SegformerConfig **kwargs )\n```", "```py\n( encoder_hidden_states: tf.Tensor training: bool = False )\n```", "```py\n( config: SegformerConfig *inputs **kwargs )\n```", "```py\n( pixel_values: tf.Tensor output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFBaseModelOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, TFSegformerModel\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"nvidia/mit-b0\")\n>>> model = TFSegformerModel.from_pretrained(\"nvidia/mit-b0\")\n\n>>> inputs = image_processor(image, return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 256, 16, 16]\n```", "```py\n( config: SegformerConfig *inputs **kwargs )\n```", "```py\n( pixel_values: tf.Tensor | None = None labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSequenceClassifierOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, TFSegformerForImageClassification\n>>> import tensorflow as tf\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"nvidia/mit-b0\")\n>>> model = TFSegformerForImageClassification.from_pretrained(\"nvidia/mit-b0\")\n\n>>> inputs = image_processor(image, return_tensors=\"tf\")\n>>> logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = int(tf.math.argmax(logits, axis=-1))\n>>> print(model.config.id2label[predicted_label])\ntabby, tabby cat\n```", "```py\n( config: SegformerConfig **kwargs )\n```", "```py\n( pixel_values: tf.Tensor labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSemanticSegmenterOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, TFSegformerForSemanticSegmentation\n>>> from PIL import Image\n>>> import requests\n\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n>>> model = TFSegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n\n>>> inputs = image_processor(images=image, return_tensors=\"tf\")\n>>> outputs = model(**inputs, training=False)\n>>> # logits are of shape (batch_size, num_labels, height/4, width/4)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 150, 128, 128]\n```"]