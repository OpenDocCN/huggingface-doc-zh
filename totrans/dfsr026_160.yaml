- en: Stable Diffusion pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion is a text-to-image latent diffusion model created by the researchers
    and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/)
    and [LAION](https://laion.ai/). Latent diffusion applies the diffusion process
    over a lower dimensional latent space to reduce memory and compute complexity.
    This specific type of diffusion model was proposed in [High-Resolution Image Synthesis
    with Latent Diffusion Models](https://huggingface.co/papers/2112.10752) by Robin
    Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion is trained on 512x512 images from a subset of the LAION-5B
    dataset. This model uses a frozen CLIP ViT-L/14 text encoder to condition the
    model on text prompts. With its 860M UNet and 123M text encoder, the model is
    relatively lightweight and can run on consumer GPUs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: For more details about how Stable Diffusion works and how it differs from the
    base latent diffusion model, take a look at the Stability AI [announcement](https://stability.ai/blog/stable-diffusion-announcement)
    and our own [blog post](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work)
    for more technical details.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: You can find the original codebase for Stable Diffusion v1.0 at [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)
    and Stable Diffusion v2.0 at [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)
    as well as their original scripts for various tasks. Additional official checkpoints
    for the different Stable Diffusion versions and tasks can be found on the [CompVis](https://huggingface.co/CompVis),
    [Runway](https://huggingface.co/runwayml), and [Stability AI](https://huggingface.co/stabilityai)
    Hub organizations. Explore these organizations to find the best checkpoint for
    your use-case!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'The table below summarizes the available Stable Diffusion pipelines, their
    supported tasks, and an interactive demo:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '| Pipeline | Supported tasks | 🤗 Space |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusion](./text2img) | text-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionImg2Img](./img2img) | image-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface/diffuse-the-rest)
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionInpaint](./inpaint) | inpainting | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/runwayml/stable-diffusion-inpainting)
    |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionDepth2Img](./depth2img) | depth-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/radames/stable-diffusion-depth2img)
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionImageVariation](./image_variation) | image variation | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations)
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionPipelineSafe](./stable_diffusion_safe) | filtered text-to-image
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/AIML-TUDA/unsafe-vs-safe-stable-diffusion)
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusion2](./stable_diffusion_2) | text-to-image, inpainting, depth-to-image,
    super-resolution | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionXL](./stable_diffusion_xl) | text-to-image, image-to-image
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/RamAnanth1/stable-diffusion-xl)
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionLatentUpscale](./latent_upscale) | super-resolution | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface-projects/stable-diffusion-latent-upscaler)
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionUpscale](./upscale) | super-resolution |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionUpscale](./upscale) | 超分辨率 |'
- en: '| [StableDiffusionLDM3D](./ldm3d_diffusion) | text-to-rgb, text-to-depth, text-to-pano
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/r23/ldm3d-space)
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionLDM3D](./ldm3d_diffusion) | 文本到RGB，文本到深度，文本到全景 | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/r23/ldm3d-space)
    |'
- en: '| [StableDiffusionUpscaleLDM3D](./ldm3d_diffusion) | ldm3d super-resolution
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionUpscaleLDM3D](./ldm3d_diffusion) | ldm3d超分辨率 |'
- en: Tips
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示
- en: To help you get the most out of the Stable Diffusion pipelines, here are a few
    tips for improving performance and usability. These tips are applicable to all
    Stable Diffusion pipelines.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您充分利用稳定扩散管道，这里有一些改善性能和可用性的提示。这些提示适用于所有稳定扩散管道。
- en: Explore tradeoff between speed and quality
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在速度和质量之间进行权衡
- en: '[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    uses the [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    by default, but 🤗 Diffusers provides many other schedulers (some of which are
    faster or output better quality) that are compatible. For example, if you want
    to use the [EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
    instead of the default:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    默认使用[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)，但🤗
    Diffusers提供许多其他调度器（其中一些更快或输出质量更好），这些调度器是兼容的。例如，如果您想使用[EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)而不是默认值：'
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Reuse pipeline components to save memory
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重复使用管道组件以节省内存
- en: To save memory and use the same components across multiple pipelines, use the
    `.components` method to avoid loading weights into RAM more than once.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省内存并在多个管道中使用相同的组件，请使用`.components`方法，以避免将权重加载到RAM中超过一次。
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
