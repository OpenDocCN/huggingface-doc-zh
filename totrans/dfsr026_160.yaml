- en: Stable Diffusion pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/73.3e684628.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion is a text-to-image latent diffusion model created by the researchers
    and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/)
    and [LAION](https://laion.ai/). Latent diffusion applies the diffusion process
    over a lower dimensional latent space to reduce memory and compute complexity.
    This specific type of diffusion model was proposed in [High-Resolution Image Synthesis
    with Latent Diffusion Models](https://huggingface.co/papers/2112.10752) by Robin
    Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion is trained on 512x512 images from a subset of the LAION-5B
    dataset. This model uses a frozen CLIP ViT-L/14 text encoder to condition the
    model on text prompts. With its 860M UNet and 123M text encoder, the model is
    relatively lightweight and can run on consumer GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: For more details about how Stable Diffusion works and how it differs from the
    base latent diffusion model, take a look at the Stability AI [announcement](https://stability.ai/blog/stable-diffusion-announcement)
    and our own [blog post](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work)
    for more technical details.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the original codebase for Stable Diffusion v1.0 at [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)
    and Stable Diffusion v2.0 at [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)
    as well as their original scripts for various tasks. Additional official checkpoints
    for the different Stable Diffusion versions and tasks can be found on the [CompVis](https://huggingface.co/CompVis),
    [Runway](https://huggingface.co/runwayml), and [Stability AI](https://huggingface.co/stabilityai)
    Hub organizations. Explore these organizations to find the best checkpoint for
    your use-case!
  prefs: []
  type: TYPE_NORMAL
- en: 'The table below summarizes the available Stable Diffusion pipelines, their
    supported tasks, and an interactive demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Pipeline | Supported tasks | ðŸ¤— Space |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusion](./text2img) | text-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionImg2Img](./img2img) | image-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface/diffuse-the-rest)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionInpaint](./inpaint) | inpainting | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/runwayml/stable-diffusion-inpainting)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionDepth2Img](./depth2img) | depth-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/radames/stable-diffusion-depth2img)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionImageVariation](./image_variation) | image variation | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionPipelineSafe](./stable_diffusion_safe) | filtered text-to-image
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/AIML-TUDA/unsafe-vs-safe-stable-diffusion)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusion2](./stable_diffusion_2) | text-to-image, inpainting, depth-to-image,
    super-resolution | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionXL](./stable_diffusion_xl) | text-to-image, image-to-image
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/RamAnanth1/stable-diffusion-xl)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionLatentUpscale](./latent_upscale) | super-resolution | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface-projects/stable-diffusion-latent-upscaler)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionUpscale](./upscale) | super-resolution |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionLDM3D](./ldm3d_diffusion) | text-to-rgb, text-to-depth, text-to-pano
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/r23/ldm3d-space)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [StableDiffusionUpscaleLDM3D](./ldm3d_diffusion) | ldm3d super-resolution
    |'
  prefs: []
  type: TYPE_TB
- en: Tips
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To help you get the most out of the Stable Diffusion pipelines, here are a few
    tips for improving performance and usability. These tips are applicable to all
    Stable Diffusion pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Explore tradeoff between speed and quality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    uses the [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    by default, but ðŸ¤— Diffusers provides many other schedulers (some of which are
    faster or output better quality) that are compatible. For example, if you want
    to use the [EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
    instead of the default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Reuse pipeline components to save memory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To save memory and use the same components across multiple pipelines, use the
    `.components` method to avoid loading weights into RAM more than once.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
