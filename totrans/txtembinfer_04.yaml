- en: Supported models and hardware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/text-embeddings-inference/supported_models](https://huggingface.co/docs/text-embeddings-inference/supported_models)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/text-embeddings-inference/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/entry/start.f5781b4e.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/scheduler.b108d059.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/singletons.26f524d0.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/paths.e8cea87f.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/entry/app.ca5804ae.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/index.008de539.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/nodes/0.a44871a2.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/nodes/10.38e38c08.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/Heading.88bfeb84.js">
  prefs: []
  type: TYPE_NORMAL
- en: We are continually expanding our support for other model types and plan to include
    them in future updates.
  prefs: []
  type: TYPE_NORMAL
- en: Supported embeddings models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text Embeddings Inference currently supports BERT, CamemBERT, XLM-RoBERTa models
    with absolute positions and JinaBERT model with Alibi positions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below are some examples of the currently supported models:'
  prefs: []
  type: TYPE_NORMAL
- en: '| MTEB Rank | Model Type | Model ID |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Bert | [BAAI/bge-large-en-v1.5](https://hf.co/BAAI/bge-large-en-v1.5)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2 |  | [BAAI/bge-base-en-v1.5](https://hf.co/BAAI/bge-base-en-v1.5) |'
  prefs: []
  type: TYPE_TB
- en: '| 3 |  | [llmrails/ember-v1](https://hf.co/llmrails/ember-v1) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 |  | [thenlper/gte-large](https://hf.co/thenlper/gte-large) |'
  prefs: []
  type: TYPE_TB
- en: '| 5 |  | [thenlper/gte-base](https://hf.co/thenlper/gte-base) |'
  prefs: []
  type: TYPE_TB
- en: '| 6 |  | [intfloat/e5-large-v2](https://hf.co/intfloat/e5-large-v2) |'
  prefs: []
  type: TYPE_TB
- en: '| 7 |  | [BAAI/bge-small-en-v1.5](https://hf.co/BAAI/bge-small-en-v1.5) |'
  prefs: []
  type: TYPE_TB
- en: '| 10 |  | [intfloat/e5-base-v2](https://hf.co/intfloat/e5-base-v2) |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | XLM-RoBERTa | [intfloat/multilingual-e5-large](https://hf.co/intfloat/multilingual-e5-large)
    |'
  prefs: []
  type: TYPE_TB
- en: '| N/A | JinaBERT | [jinaai/jina-embeddings-v2-base-en](https://hf.co/jinaai/jina-embeddings-v2-base-en)
    |'
  prefs: []
  type: TYPE_TB
- en: '| N/A | JinaBERT | [jinaai/jina-embeddings-v2-small-en](https://hf.co/jinaai/jina-embeddings-v2-small-en)
    |'
  prefs: []
  type: TYPE_TB
- en: To explore the list of best performing text embeddings models, visit the [Massive
    Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).
  prefs: []
  type: TYPE_NORMAL
- en: Supported re-rankers and sequence classification models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text Embeddings Inference currently supports CamemBERT, and XLM-RoBERTa Sequence
    Classification models with absolute positions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below are some examples of the currently supported models:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Task | Model Type | Model ID | Revision |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Re-Ranking | XLM-RoBERTa | [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large)
    | `refs/pr/4` |'
  prefs: []
  type: TYPE_TB
- en: '| Re-Ranking | XLM-RoBERTa | [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)
    | `refs/pr/5` |'
  prefs: []
  type: TYPE_TB
- en: '| Sentiment Analysis | RoBERTa | [SamLowe/roberta-base-go_emotions](https://huggingface.co/SamLowe/roberta-base-go_emotions)
    |  |'
  prefs: []
  type: TYPE_TB
- en: Supported hardware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text Embeddings Inference supports can be used on CPU, Turing (T4, RTX 2000
    series, …), Ampere 80 (A100, A30), Ampere 86 (A10, A40, …), Ada Lovelace (RTX
    4000 series, …), and Hopper (H100) architectures.
  prefs: []
  type: TYPE_NORMAL
- en: The library does **not** support CUDA compute capabilities < 7.5, which means
    V100, Titan V, GTX 1000 series, etc. are not supported. To leverage your GPUs,
    make sure to install the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html),
    and use NVIDIA drivers with CUDA version 12.2 or higher.
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the appropriate Docker image for your hardware in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Architecture | Image |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CPU | ghcr.io/huggingface/text-embeddings-inference:cpu-0.6 |'
  prefs: []
  type: TYPE_TB
- en: '| Volta | NOT SUPPORTED |'
  prefs: []
  type: TYPE_TB
- en: '| Turing (T4, RTX 2000 series, …) | ghcr.io/huggingface/text-embeddings-inference:turing-0.6
    (experimental) |'
  prefs: []
  type: TYPE_TB
- en: '| Ampere 80 (A100, A30) | ghcr.io/huggingface/text-embeddings-inference:0.6
    |'
  prefs: []
  type: TYPE_TB
- en: '| Ampere 86 (A10, A40, …) | ghcr.io/huggingface/text-embeddings-inference:86-0.6
    |'
  prefs: []
  type: TYPE_TB
- en: '| Ada Lovelace (RTX 4000 series, …) | ghcr.io/huggingface/text-embeddings-inference:89-0.6
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hopper (H100) | ghcr.io/huggingface/text-embeddings-inference:hopper-0.4.0
    (experimental) |'
  prefs: []
  type: TYPE_TB
- en: '**Warning**: Flash Attention is turned off by default for the Turing image
    as it suffers from precision issues. You can turn Flash Attention v1 ON by using
    the `USE_FLASH_ATTENTION=True` environment variable.'
  prefs: []
  type: TYPE_NORMAL
