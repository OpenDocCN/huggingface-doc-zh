- en: The Exploration/Exploitation trade-off
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/learn/deep-rl-course/unit1/exp-exp-tradeoff](https://huggingface.co/learn/deep-rl-course/unit1/exp-exp-tradeoff)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/11.8a89fd3a.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: Finally, before looking at the different methods to solve Reinforcement Learning
    problems, we must cover one more very important topic: *the exploration/exploitation
    trade-off.*
  prefs: []
  type: TYPE_NORMAL
- en: '*Exploration* is exploring the environment by trying random actions in order
    to **find more information about the environment.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exploitation* is **exploiting known information to maximize the reward.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, the goal of our RL agent is to maximize the expected cumulative reward.
    However, **we can fall into a common trap**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploration](../Images/8ddcbca3ac19aa9439085910c70097b2.png)'
  prefs: []
  type: TYPE_IMG
- en: In this game, our mouse can have an **infinite amount of small cheese** (+1
    each). But at the top of the maze, there is a gigantic sum of cheese (+1000).
  prefs: []
  type: TYPE_NORMAL
- en: However, if we only focus on exploitation, our agent will never reach the gigantic
    sum of cheese. Instead, it will only exploit **the nearest source of rewards,** even
    if this source is small (exploitation).
  prefs: []
  type: TYPE_NORMAL
- en: But if our agent does a little bit of exploration, it can **discover the big
    reward** (the pile of big cheese).
  prefs: []
  type: TYPE_NORMAL
- en: This is what we call the exploration/exploitation trade-off. We need to balance
    how much we **explore the environment** and how much we **exploit what we know
    about the environment.**
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we must **define a rule that helps to handle this trade-off**. We’ll
    see the different ways to handle it in the future units.
  prefs: []
  type: TYPE_NORMAL
- en: 'If it’s still confusing, **think of a real problem: the choice of picking a
    restaurant:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploration](../Images/cbeb3861abcad7c84550ec8710867e1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Berkley AI Course](https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec15_6up.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Exploitation*: You go to the same one that you know is good every day and
    **take the risk to miss another better restaurant.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exploration*: Try restaurants you never went to before, with the risk of having
    a bad experience **but the probable opportunity of a fantastic experience.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To recap:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploration Exploitation Tradeoff](../Images/3a59b593e994b9d356515c58b0fa6a24.png)'
  prefs: []
  type: TYPE_IMG
