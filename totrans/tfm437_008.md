# é¢„å¤„ç†

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/preprocessing`](https://huggingface.co/docs/transformers/v4.37.2/en/preprocessing)

åœ¨æ‚¨å¯ä»¥åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œéœ€è¦å°†å…¶é¢„å¤„ç†ä¸ºé¢„æœŸçš„æ¨¡å‹è¾“å…¥æ ¼å¼ã€‚æ— è®ºæ‚¨çš„æ•°æ®æ˜¯æ–‡æœ¬ã€å›¾åƒè¿˜æ˜¯éŸ³é¢‘ï¼Œéƒ½éœ€è¦å°†å…¶è½¬æ¢å¹¶ç»„è£…æˆå¼ é‡æ‰¹æ¬¡ã€‚ğŸ¤— Transformers æä¾›äº†ä¸€ç»„é¢„å¤„ç†ç±»æ¥å¸®åŠ©å‡†å¤‡æ•°æ®ä¾›æ¨¡å‹ä½¿ç”¨ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†äº†è§£åˆ°ï¼š

+   æ–‡æœ¬ï¼Œä½¿ç”¨ Tokenizer å°†æ–‡æœ¬è½¬æ¢ä¸ºä¸€ç³»åˆ—æ ‡è®°ï¼Œåˆ›å»ºæ ‡è®°çš„æ•°å€¼è¡¨ç¤ºï¼Œå¹¶å°†å®ƒä»¬ç»„è£…æˆå¼ é‡ã€‚

+   è¯­éŸ³å’ŒéŸ³é¢‘ï¼Œä½¿ç”¨ Feature extractor ä»éŸ³é¢‘æ³¢å½¢ä¸­æå–åºåˆ—ç‰¹å¾å¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡ã€‚

+   å›¾åƒè¾“å…¥ä½¿ç”¨ ImageProcessor å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚

+   å¤šæ¨¡æ€è¾“å…¥ï¼Œä½¿ç”¨ Processor æ¥ç»“åˆä¸€ä¸ªåˆ†è¯å™¨å’Œä¸€ä¸ªç‰¹å¾æå–å™¨æˆ–å›¾åƒå¤„ç†å™¨ã€‚

`AutoProcessor` **æ€»æ˜¯**æœ‰æ•ˆï¼Œå¹¶è‡ªåŠ¨é€‰æ‹©æ‚¨æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹çš„æ­£ç¡®ç±»åˆ«ï¼Œæ— è®ºæ‚¨æ˜¯ä½¿ç”¨åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨è¿˜æ˜¯å¤„ç†å™¨ã€‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·å®‰è£…ğŸ¤—æ•°æ®é›†ï¼Œä»¥ä¾¿åŠ è½½ä¸€äº›æ•°æ®é›†è¿›è¡Œå®éªŒï¼š

```py
pip install datasets
```

## è‡ªç„¶è¯­è¨€å¤„ç†

[`www.youtube-nocookie.com/embed/Yffk5aydLzg`](https://www.youtube-nocookie.com/embed/Yffk5aydLzg)

é¢„å¤„ç†æ–‡æœ¬æ•°æ®çš„ä¸»è¦å·¥å…·æ˜¯ tokenizerã€‚åˆ†è¯å™¨æ ¹æ®ä¸€ç»„è§„åˆ™å°†æ–‡æœ¬åˆ†å‰²ä¸º*æ ‡è®°*ã€‚è¿™äº›æ ‡è®°è¢«è½¬æ¢ä¸ºæ•°å­—ï¼Œç„¶åæˆä¸ºæ¨¡å‹è¾“å…¥çš„å¼ é‡ã€‚åˆ†è¯å™¨ä¼šæ·»åŠ æ¨¡å‹æ‰€éœ€çš„ä»»ä½•é¢å¤–è¾“å…¥ã€‚

å¦‚æœæ‚¨æ‰“ç®—ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œé‡è¦çš„æ˜¯ä½¿ç”¨ç›¸å…³çš„é¢„è®­ç»ƒåˆ†è¯å™¨ã€‚è¿™ç¡®ä¿æ–‡æœ¬è¢«åˆ†å‰²çš„æ–¹å¼ä¸é¢„è®­ç»ƒè¯­æ–™åº“ç›¸åŒï¼Œå¹¶ä¸”åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨ç›¸åŒçš„å¯¹åº”æ ‡è®°ç´¢å¼•ï¼ˆé€šå¸¸ç§°ä¸º*è¯æ±‡è¡¨*ï¼‰ã€‚

é€šè¿‡ AutoTokenizer.from_pretrained()æ–¹æ³•åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨æ¥å¼€å§‹ã€‚è¿™ä¼šä¸‹è½½æ¨¡å‹é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„*è¯æ±‡è¡¨*ï¼š

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
```

ç„¶åå°†æ‚¨çš„æ–‡æœ¬ä¼ é€’ç»™åˆ†è¯å™¨ï¼š

```py
>>> encoded_input = tokenizer("Do not meddle in the affairs of wizards, for they are subtle and quick to anger.")
>>> print(encoded_input)
{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

åˆ†è¯å™¨è¿”å›ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé‡è¦é¡¹ç›®çš„å­—å…¸ï¼š

+   input_ids æ˜¯å¥å­ä¸­æ¯ä¸ªæ ‡è®°å¯¹åº”çš„ç´¢å¼•ã€‚

+   attention_mask æŒ‡ç¤ºä¸€ä¸ªæ ‡è®°æ˜¯å¦åº”è¯¥è¢«å…³æ³¨ã€‚

+   token_type_ids æ ‡è¯†ä¸€ä¸ªæ ‡è®°å±äºå“ªä¸ªåºåˆ—ï¼Œå½“æœ‰å¤šä¸ªåºåˆ—æ—¶ã€‚

é€šè¿‡è§£ç `input_ids`è¿”å›æ‚¨çš„è¾“å…¥ï¼š

```py
>>> tokenizer.decode(encoded_input["input_ids"])
'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'
```

æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œåˆ†è¯å™¨æ·»åŠ äº†ä¸¤ä¸ªç‰¹æ®Šæ ‡è®° - `CLS`å’Œ`SEP`ï¼ˆåˆ†ç±»å™¨å’Œåˆ†éš”ç¬¦ï¼‰- åˆ°å¥å­ä¸­ã€‚å¹¶éæ‰€æœ‰æ¨¡å‹éƒ½éœ€è¦ç‰¹æ®Šæ ‡è®°ï¼Œä½†å¦‚æœéœ€è¦ï¼Œåˆ†è¯å™¨ä¼šè‡ªåŠ¨ä¸ºæ‚¨æ·»åŠ å®ƒä»¬ã€‚

å¦‚æœæœ‰å‡ ä¸ªå¥å­éœ€è¦é¢„å¤„ç†ï¼Œå°†å®ƒä»¬ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™åˆ†è¯å™¨ï¼š

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_inputs = tokenizer(batch_sentences)
>>> print(encoded_inputs)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1]]}
```

### å¡«å……

å¥å­é•¿åº¦ä¸æ€»æ˜¯ç›¸åŒï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºå¼ é‡ï¼Œå³æ¨¡å‹è¾“å…¥ï¼Œéœ€è¦å…·æœ‰ç»Ÿä¸€çš„å½¢çŠ¶ã€‚å¡«å……æ˜¯ä¸€ç§ç¡®ä¿å¼ é‡æ˜¯çŸ©å½¢çš„ç­–ç•¥ï¼Œé€šè¿‡å‘è¾ƒçŸ­çš„å¥å­æ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„*å¡«å……æ ‡è®°*ã€‚

å°†`padding`å‚æ•°è®¾ç½®ä¸º`True`ï¼Œä»¥å°†æ‰¹æ¬¡ä¸­è¾ƒçŸ­çš„åºåˆ—å¡«å……åˆ°ä¸æœ€é•¿åºåˆ—ç›¸åŒ¹é…çš„é•¿åº¦ï¼š

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}
```

ç¬¬ä¸€å¥å’Œç¬¬ä¸‰å¥ç°åœ¨ç”¨`0`å¡«å……ï¼Œå› ä¸ºå®ƒä»¬è¾ƒçŸ­ã€‚

### æˆªæ–­

å¦ä¸€æ–¹é¢ï¼Œæœ‰æ—¶ä¸€ä¸ªåºåˆ—å¯èƒ½å¤ªé•¿ï¼Œæ¨¡å‹æ— æ³•å¤„ç†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦å°†åºåˆ—æˆªæ–­ä¸ºè¾ƒçŸ­çš„é•¿åº¦ã€‚

å°†`truncation`å‚æ•°è®¾ç½®ä¸º`True`ï¼Œå°†åºåˆ—æˆªæ–­ä¸ºæ¨¡å‹æ¥å—çš„æœ€å¤§é•¿åº¦ï¼š

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}
```

æŸ¥çœ‹å¡«å……å’Œæˆªæ–­æ¦‚å¿µæŒ‡å—ï¼Œäº†è§£æ›´å¤šä¸åŒçš„å¡«å……å’Œæˆªæ–­å‚æ•°ã€‚

### æ„å»ºå¼ é‡

æœ€åï¼Œæ‚¨å¸Œæœ›åˆ†è¯å™¨è¿”å›å®é™…é¦ˆé€åˆ°æ¨¡å‹çš„å¼ é‡ã€‚

å°†`return_tensors`å‚æ•°è®¾ç½®ä¸º`pt`ä»¥ä¾› PyTorch ä½¿ç”¨ï¼Œæˆ–è®¾ç½®ä¸º`tf`ä»¥ä¾› TensorFlow ä½¿ç”¨ï¼š

Pytorch éšè— Pytorch å†…å®¹

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="pt")
>>> print(encoded_input)
{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]),
 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),
 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}
```

TensorFlow éšè— TensorFlow å†…å®¹

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="tf")
>>> print(encoded_input)
{'input_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=
array([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
       [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
       [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
      dtype=int32)>,
 'token_type_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,
 'attention_mask': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=
array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}
```

ä¸åŒçš„ç®¡é“ä»¥ä¸åŒçš„æ–¹å¼åœ¨å…¶`__call__()`ä¸­æ”¯æŒåˆ†è¯å™¨å‚æ•°ã€‚`text-2-text-generation`ç®¡é“ä»…æ”¯æŒï¼ˆå³ä¼ é€’ï¼‰`truncation`ã€‚`text-generation`ç®¡é“æ”¯æŒ`max_length`ã€`truncation`ã€`padding`å’Œ`add_special_tokens`ã€‚åœ¨`fill-mask`ç®¡é“ä¸­ï¼Œåˆ†è¯å™¨å‚æ•°å¯ä»¥åœ¨`tokenizer_kwargs`å‚æ•°ï¼ˆå­—å…¸ï¼‰ä¸­ä¼ é€’ã€‚

## éŸ³é¢‘

å¯¹äºéŸ³é¢‘ä»»åŠ¡ï¼Œæ‚¨å°†éœ€è¦ä¸€ä¸ªç‰¹å¾æå–å™¨æ¥å‡†å¤‡æ‚¨çš„æ•°æ®é›†ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚ç‰¹å¾æå–å™¨æ—¨åœ¨ä»åŸå§‹éŸ³é¢‘æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡ã€‚

åŠ è½½[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)æ•°æ®é›†ï¼ˆæŸ¥çœ‹ğŸ¤—[Datasets æ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼‰ä»¥æŸ¥çœ‹å¦‚ä½•åœ¨éŸ³é¢‘æ•°æ®é›†ä¸­ä½¿ç”¨ç‰¹å¾æå–å™¨ï¼š

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
```

è®¿é—®`audio`åˆ—çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä»¥æŸ¥çœ‹è¾“å…¥ã€‚è°ƒç”¨`audio`åˆ—ä¼šè‡ªåŠ¨åŠ è½½å’Œé‡æ–°é‡‡æ ·éŸ³é¢‘æ–‡ä»¶ï¼š

```py
>>> dataset[0]["audio"]
{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,
         0.        ,  0.        ], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 8000}
```

è¿™å°†è¿”å›ä¸‰ä¸ªé¡¹ç›®ï¼š

+   `array`æ˜¯åŠ è½½çš„è¯­éŸ³ä¿¡å· - å¯èƒ½å·²é‡æ–°é‡‡æ · - ä½œä¸º 1D æ•°ç»„ã€‚

+   `path`æŒ‡å‘éŸ³é¢‘æ–‡ä»¶çš„ä½ç½®ã€‚

+   `sampling_rate`æŒ‡çš„æ˜¯æ¯ç§’æµ‹é‡çš„è¯­éŸ³ä¿¡å·ä¸­æœ‰å¤šå°‘æ•°æ®ç‚¹ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨[Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)æ¨¡å‹ã€‚æŸ¥çœ‹æ¨¡å‹å¡ç‰‡ï¼Œæ‚¨å°†äº†è§£åˆ° Wav2Vec2 æ˜¯åœ¨ 16kHz é‡‡æ ·çš„è¯­éŸ³éŸ³é¢‘ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„ã€‚é‡è¦çš„æ˜¯ï¼Œæ‚¨çš„éŸ³é¢‘æ•°æ®çš„é‡‡æ ·ç‡è¦ä¸ç”¨äºé¢„è®­ç»ƒæ¨¡å‹çš„æ•°æ®é›†çš„é‡‡æ ·ç‡åŒ¹é…ã€‚å¦‚æœæ‚¨çš„æ•°æ®é‡‡æ ·ç‡ä¸åŒï¼Œåˆ™éœ€è¦å¯¹æ•°æ®è¿›è¡Œé‡æ–°é‡‡æ ·ã€‚

1.  ä½¿ç”¨ğŸ¤— Datasets çš„[cast_column](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.cast_column)æ–¹æ³•å°†é‡‡æ ·ç‡ä¸Šé‡‡æ ·è‡³ 16kHzï¼š

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16_000))
```

1.  å†æ¬¡è°ƒç”¨`audio`åˆ—ä»¥é‡æ–°é‡‡æ ·éŸ³é¢‘æ–‡ä»¶ï¼š

```py
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 16000}
```

æ¥ä¸‹æ¥ï¼ŒåŠ è½½ä¸€ä¸ªç‰¹å¾æå–å™¨æ¥å¯¹è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–å’Œå¡«å……ã€‚åœ¨å¡«å……æ–‡æœ¬æ•°æ®æ—¶ï¼Œä¼šä¸ºè¾ƒçŸ­çš„åºåˆ—æ·»åŠ `0`ã€‚ç›¸åŒçš„æ€æƒ³ä¹Ÿé€‚ç”¨äºéŸ³é¢‘æ•°æ®ã€‚ç‰¹å¾æå–å™¨ä¼šå‘`array`ä¸­æ·»åŠ ä¸€ä¸ª`0` - è¢«è§£é‡Šä¸ºé™éŸ³ã€‚

ä½¿ç”¨ AutoFeatureExtractor.from_pretrained()åŠ è½½ç‰¹å¾æå–å™¨ï¼š

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

å°†éŸ³é¢‘`array`ä¼ é€’ç»™ç‰¹å¾æå–å™¨ã€‚æˆ‘ä»¬è¿˜å»ºè®®åœ¨ç‰¹å¾æå–å™¨ä¸­æ·»åŠ `sampling_rate`å‚æ•°ï¼Œä»¥æ›´å¥½åœ°è°ƒè¯•å¯èƒ½å‘ç”Ÿçš„ä»»ä½•é™é»˜é”™è¯¯ã€‚

```py
>>> audio_input = [dataset[0]["audio"]["array"]]
>>> feature_extractor(audio_input, sampling_rate=16000)
{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,
        5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}
```

ä¸åˆ†è¯å™¨ä¸€æ ·ï¼Œæ‚¨å¯ä»¥åº”ç”¨å¡«å……æˆ–æˆªæ–­æ¥å¤„ç†æ‰¹å¤„ç†ä¸­çš„å¯å˜åºåˆ—ã€‚æŸ¥çœ‹è¿™ä¸¤ä¸ªéŸ³é¢‘æ ·æœ¬çš„åºåˆ—é•¿åº¦ï¼š

```py
>>> dataset[0]["audio"]["array"].shape
(173398,)

>>> dataset[1]["audio"]["array"].shape
(106496,)
```

åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥é¢„å¤„ç†æ•°æ®é›†ï¼Œä½¿éŸ³é¢‘æ ·æœ¬å…·æœ‰ç›¸åŒçš„é•¿åº¦ã€‚æŒ‡å®šæœ€å¤§æ ·æœ¬é•¿åº¦ï¼Œç‰¹å¾æå–å™¨å°†å¡«å……æˆ–æˆªæ–­åºåˆ—ä»¥åŒ¹é…å®ƒï¼š

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays,
...         sampling_rate=16000,
...         padding=True,
...         max_length=100000,
...         truncation=True,
...     )
...     return inputs
```

å¯¹æ•°æ®é›†ä¸­çš„å‰å‡ ä¸ªç¤ºä¾‹åº”ç”¨`preprocess_function`ï¼š

```py
>>> processed_dataset = preprocess_function(dataset[:5])
```

ç°åœ¨æ ·æœ¬é•¿åº¦ç›¸åŒå¹¶ä¸æŒ‡å®šçš„æœ€å¤§é•¿åº¦åŒ¹é…ã€‚ç°åœ¨å¯ä»¥å°†å¤„ç†è¿‡çš„æ•°æ®é›†ä¼ é€’ç»™æ¨¡å‹äº†ï¼

```py
>>> processed_dataset["input_values"][0].shape
(100000,)

>>> processed_dataset["input_values"][1].shape
(100000,)
```

## è®¡ç®—æœºè§†è§‰

å¯¹äºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œæ‚¨å°†éœ€è¦ä¸€ä¸ªå›¾åƒå¤„ç†å™¨æ¥å‡†å¤‡æ‚¨çš„æ•°æ®é›†ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚å›¾åƒé¢„å¤„ç†åŒ…æ‹¬å‡ ä¸ªæ­¥éª¤ï¼Œå°†å›¾åƒè½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„è¾“å…¥ã€‚è¿™äº›æ­¥éª¤åŒ…æ‹¬ä½†ä¸é™äºè°ƒæ•´å¤§å°ã€å½’ä¸€åŒ–ã€é¢œè‰²é€šé“æ ¡æ­£ä»¥åŠå°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚

å›¾åƒé¢„å¤„ç†é€šå¸¸éµå¾ªæŸç§å½¢å¼çš„å›¾åƒå¢å¼ºã€‚å›¾åƒé¢„å¤„ç†å’Œå›¾åƒå¢å¼ºéƒ½ä¼šè½¬æ¢å›¾åƒæ•°æ®ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„ç›®çš„ï¼š

+   å›¾åƒå¢å¼ºä»¥ä¸€ç§å¯ä»¥å¸®åŠ©é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶å¢åŠ æ¨¡å‹é²æ£’æ€§çš„æ–¹å¼æ”¹å˜å›¾åƒã€‚æ‚¨å¯ä»¥åœ¨æ•°æ®å¢å¼ºä¸­å‘æŒ¥åˆ›é€ åŠ› - è°ƒæ•´äº®åº¦å’Œé¢œè‰²ï¼Œè£å‰ªï¼Œæ—‹è½¬ï¼Œè°ƒæ•´å¤§å°ï¼Œç¼©æ”¾ç­‰ã€‚ä½†æ˜¯ï¼Œè¯·æ³¨æ„ä¸è¦é€šè¿‡å¢å¼ºæ”¹å˜å›¾åƒçš„å«ä¹‰ã€‚

+   å›¾åƒé¢„å¤„ç†ç¡®ä¿å›¾åƒä¸æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ ¼å¼åŒ¹é…ã€‚åœ¨å¾®è°ƒè®¡ç®—æœºè§†è§‰æ¨¡å‹æ—¶ï¼Œå›¾åƒå¿…é¡»ä¸æ¨¡å‹æœ€åˆè®­ç»ƒæ—¶çš„é¢„å¤„ç†æ–¹å¼å®Œå…¨ç›¸åŒã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ‚¨å–œæ¬¢çš„åº“è¿›è¡Œå›¾åƒå¢å¼ºã€‚å¯¹äºå›¾åƒé¢„å¤„ç†ï¼Œè¯·ä½¿ç”¨ä¸æ¨¡å‹å…³è”çš„`ImageProcessor`ã€‚

åŠ è½½[food101](https://huggingface.co/datasets/food101)æ•°æ®é›†ï¼ˆè¯·å‚é˜…ğŸ¤—[æ•°æ®é›†æ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼‰ï¼Œä»¥æŸ¥çœ‹å¦‚ä½•åœ¨è®¡ç®—æœºè§†è§‰æ•°æ®é›†ä¸­ä½¿ç”¨å›¾åƒå¤„ç†å™¨ï¼š

ä½¿ç”¨ğŸ¤—æ•°æ®é›†`split`å‚æ•°ä»…åŠ è½½è®­ç»ƒé›†ä¸­çš„ä¸€å°éƒ¨åˆ†æ ·æœ¬ï¼Œå› ä¸ºæ•°æ®é›†éå¸¸å¤§ï¼

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("food101", split="train[:100]")
```

æ¥ä¸‹æ¥ï¼Œçœ‹ä¸€ä¸‹å¸¦æœ‰ğŸ¤—æ•°æ®é›†[`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image)ç‰¹å¾çš„å›¾åƒï¼š

```py
>>> dataset[0]["image"]
```

![](img/63a998c1115de762652ef3c59b938a3f.png)

ä½¿ç”¨ AutoImageProcessor.from_pretrained()åŠ è½½å›¾åƒå¤„ç†å™¨ï¼š

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€äº›å›¾åƒå¢å¼ºã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ‚¨å–œæ¬¢çš„åº“ï¼Œä½†åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ torchvision çš„[`transforms`](https://pytorch.org/vision/stable/transforms.html)æ¨¡å—ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£ä½¿ç”¨å…¶ä»–æ•°æ®å¢å¼ºåº“ï¼Œè¯·åœ¨[Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)æˆ–[Kornia notebooks](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)ä¸­å­¦ä¹ å¦‚ä½•ä½¿ç”¨ã€‚

1.  åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨[`Compose`](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)æ¥é“¾æ¥ä¸€äº›è½¬æ¢ - [`RandomResizedCrop`](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html)å’Œ[`ColorJitter`](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html)ã€‚è¯·æ³¨æ„ï¼Œå¯¹äºè°ƒæ•´å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥ä»`image_processor`è·å–å›¾åƒå¤§å°è¦æ±‚ã€‚å¯¹äºæŸäº›æ¨¡å‹ï¼ŒæœŸæœ›ç²¾ç¡®çš„é«˜åº¦å’Œå®½åº¦ï¼Œå¯¹äºå…¶ä»–æ¨¡å‹åªå®šä¹‰äº†`shortest_edge`ã€‚

```py
>>> from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose

>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )

>>> _transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])
```

1.  æ¨¡å‹æ¥å—`pixel_values`ä½œä¸ºå…¶è¾“å…¥ã€‚`ImageProcessor`å¯ä»¥è´Ÿè´£å½’ä¸€åŒ–å›¾åƒï¼Œå¹¶ç”Ÿæˆé€‚å½“çš„å¼ é‡ã€‚åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†å›¾åƒå¢å¼ºå’Œå›¾åƒé¢„å¤„ç†ç»„åˆä¸ºä¸€æ‰¹å›¾åƒï¼Œå¹¶ç”Ÿæˆ`pixel_values`ï¼š

```py
>>> def transforms(examples):
...     images = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     examples["pixel_values"] = image_processor(images, do_resize=False, return_tensors="pt")["pixel_values"]
...     return examples
```

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†`do_resize=False`ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨å›¾åƒå¢å¼ºè½¬æ¢ä¸­è°ƒæ•´äº†å›¾åƒçš„å¤§å°ï¼Œå¹¶åˆ©ç”¨äº†é€‚å½“çš„`image_processor`çš„`size`å±æ€§ã€‚å¦‚æœæ‚¨åœ¨å›¾åƒå¢å¼ºæœŸé—´ä¸è°ƒæ•´å›¾åƒå¤§å°ï¼Œè¯·çœç•¥æ­¤å‚æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ`ImageProcessor`å°†å¤„ç†è°ƒæ•´å¤§å°ã€‚

å¦‚æœå¸Œæœ›å°†å›¾åƒå½’ä¸€åŒ–ä½œä¸ºå¢å¼ºè½¬æ¢çš„ä¸€éƒ¨åˆ†ï¼Œè¯·ä½¿ç”¨`image_processor.image_mean`å’Œ`image_processor.image_std`å€¼ã€‚

1.  ç„¶åä½¿ç”¨ğŸ¤—æ•°æ®é›†[set_transform](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.set_transform)æ¥åŠ¨æ€åº”ç”¨è½¬æ¢ï¼š

```py
>>> dataset.set_transform(transforms)
```

1.  ç°åœ¨å½“æ‚¨è®¿é—®å›¾åƒæ—¶ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°å›¾åƒå¤„ç†å™¨å·²æ·»åŠ äº†`pixel_values`ã€‚ç°åœ¨æ‚¨å¯ä»¥å°†å¤„ç†è¿‡çš„æ•°æ®é›†ä¼ é€’ç»™æ¨¡å‹äº†ï¼

```py
>>> dataset[0].keys()
```

è¿™æ˜¯åº”ç”¨è½¬æ¢åçš„å›¾åƒæ ·å­ã€‚å›¾åƒå·²è¢«éšæœºè£å‰ªï¼Œå…¶é¢œè‰²å±æ€§ä¸åŒã€‚

```py
>>> import numpy as np
>>> import matplotlib.pyplot as plt

>>> img = dataset[0]["pixel_values"]
>>> plt.imshow(img.permute(1, 2, 0))
```

![](img/eee368b92fc814b0667081ba147249f4.png)

å¯¹äºç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€å®ä¾‹åˆ†å‰²å’Œå…¨æ™¯åˆ†å‰²ç­‰ä»»åŠ¡ï¼Œ`ImageProcessor`æä¾›åå¤„ç†æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å°†æ¨¡å‹çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„é¢„æµ‹ï¼Œå¦‚è¾¹ç•Œæ¡†æˆ–åˆ†å‰²åœ°å›¾ã€‚

### å¡«å……

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¾‹å¦‚åœ¨å¾®è°ƒ DETR æ—¶ï¼Œæ¨¡å‹ä¼šåœ¨è®­ç»ƒæ—¶åº”ç”¨å°ºåº¦å¢å¼ºã€‚è¿™å¯èƒ½å¯¼è‡´æ‰¹å¤„ç†ä¸­çš„å›¾åƒå¤§å°ä¸åŒã€‚æ‚¨å¯ä»¥ä½¿ç”¨æ¥è‡ª DetrImageProcessor çš„`DetrImageProcessor.pad()`ï¼Œå¹¶å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„`collate_fn`æ¥å°†å›¾åƒæ‰¹å¤„ç†åœ¨ä¸€èµ·ã€‚

```py
>>> def collate_fn(batch):
...     pixel_values = [item["pixel_values"] for item in batch]
...     encoding = image_processor.pad(pixel_values, return_tensors="pt")
...     labels = [item["labels"] for item in batch]
...     batch = {}
...     batch["pixel_values"] = encoding["pixel_values"]
...     batch["pixel_mask"] = encoding["pixel_mask"]
...     batch["labels"] = labels
...     return batch
```

## å¤šæ¨¡æ€

å¯¹äºæ¶‰åŠå¤šæ¨¡æ€è¾“å…¥çš„ä»»åŠ¡ï¼Œæ‚¨å°†éœ€è¦ä¸€ä¸ªå¤„ç†å™¨æ¥ä¸ºæ¨¡å‹å‡†å¤‡æ‚¨çš„æ•°æ®é›†ã€‚å¤„ç†å™¨å°†ä¸¤ä¸ªå¤„ç†å¯¹è±¡ï¼ˆå¦‚æ ‡è®°å™¨å’Œç‰¹å¾æå–å™¨ï¼‰è€¦åˆåœ¨ä¸€èµ·ã€‚

åŠ è½½[LJ Speech](https://huggingface.co/datasets/lj_speech)æ•°æ®é›†ï¼ˆæŸ¥çœ‹ğŸ¤—[æ•°æ®é›†æ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼‰ï¼Œä»¥æŸ¥çœ‹å¦‚ä½•ä½¿ç”¨å¤„ç†å™¨è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ï¼š

```py
>>> from datasets import load_dataset

>>> lj_speech = load_dataset("lj_speech", split="train")
```

å¯¹äº ASRï¼Œæ‚¨ä¸»è¦å…³æ³¨`éŸ³é¢‘`å’Œ`æ–‡æœ¬`ï¼Œå› æ­¤å¯ä»¥åˆ é™¤å…¶ä»–åˆ—ï¼š

```py
>>> lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])
```

ç°åœ¨çœ‹ä¸€ä¸‹`éŸ³é¢‘`å’Œ`æ–‡æœ¬`åˆ—ï¼š

```py
>>> lj_speech[0]["audio"]
{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,
         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',
 'sampling_rate': 22050}

>>> lj_speech[0]["text"]
'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'
```

è®°ä½ï¼Œä½ åº”è¯¥å§‹ç»ˆé‡æ–°é‡‡æ ·ä½ çš„éŸ³é¢‘æ•°æ®é›†çš„é‡‡æ ·ç‡ï¼Œä»¥åŒ¹é…ç”¨äºé¢„è®­ç»ƒæ¨¡å‹çš„æ•°æ®é›†çš„é‡‡æ ·ç‡ï¼

```py
>>> lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))
```

ä½¿ç”¨ AutoProcessor.from_pretrained()åŠ è½½ä¸€ä¸ªå¤„ç†å™¨ï¼š

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")
```

1.  åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¤„ç†`array`ä¸­åŒ…å«çš„éŸ³é¢‘æ•°æ®ä¸º`input_values`ï¼Œå¹¶å°†`æ–‡æœ¬`æ ‡è®°åŒ–ä¸º`æ ‡ç­¾`ã€‚è¿™äº›æ˜¯æ¨¡å‹çš„è¾“å…¥ï¼š

```py
>>> def prepare_dataset(example):
...     audio = example["audio"]

...     example.update(processor(audio=audio["array"], text=example["text"], sampling_rate=16000))

...     return example
```

1.  å°†`prepare_dataset`å‡½æ•°åº”ç”¨åˆ°ä¸€ä¸ªæ ·æœ¬ä¸­ï¼š

```py
>>> prepare_dataset(lj_speech[0])
```

å¤„ç†å™¨ç°åœ¨å·²ç»æ·»åŠ äº†`input_values`å’Œ`labels`ï¼Œé‡‡æ ·ç‡ä¹Ÿå·²ç»æ­£ç¡®é™é‡‡æ ·åˆ° 16kHzã€‚ç°åœ¨æ‚¨å¯ä»¥å°†å¤„ç†è¿‡çš„æ•°æ®é›†ä¼ é€’ç»™æ¨¡å‹äº†ï¼
