- en: Load safetensors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors](https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[safetensors](https://github.com/huggingface/safetensors) is a safe and fast
    file format for storing and loading tensors. Typically, PyTorch model weights
    are saved or *pickled* into a `.bin` file with Python’s [`pickle`](https://docs.python.org/3/library/pickle.html)
    utility. However, `pickle` is not secure and pickled files may contain malicious
    code that can be executed. safetensors is a secure alternative to `pickle`, making
    it ideal for sharing model weights.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'This guide will show you how you load `.safetensor` files, and how to convert
    Stable Diffusion model weights stored in other formats to `.safetensor`. Before
    you start, make sure you have safetensors installed:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you look at the [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)
    repository, you’ll see weights inside the `text_encoder`, `unet` and `vae` subfolders
    are stored in the `.safetensors` format. By default, 🤗 Diffusers automatically
    loads these `.safetensors` files from their subfolders if they’re available in
    the model repository.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'For more explicit control, you can optionally set `use_safetensors=True` (if
    `safetensors` is not installed, you’ll get an error message asking you to install
    it):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'However, model weights are not necessarily stored in separate subfolders like
    in the example above. Sometimes, all the weights are stored in a single `.safetensors`
    file. In this case, if the weights are Stable Diffusion weights, you can load
    the file directly with the [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    method:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Convert to safetensors
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not all weights on the Hub are available in the `.safetensors` format, and you
    may encounter weights stored as `.bin`. In this case, use the [Convert Space](https://huggingface.co/spaces/diffusers/convert)
    to convert the weights to `.safetensors`. The Convert Space downloads the pickled
    weights, converts them, and opens a Pull Request to upload the newly converted
    `.safetensors` file on the Hub. This way, if there is any malicious code contained
    in the pickled files, they’re uploaded to the Hub - which has a [security scanner](https://huggingface.co/docs/hub/security-pickle#hubs-security-scanner)
    to detect unsafe files and suspicious pickle imports - instead of your computer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the model with the new `.safetensors` weights by specifying the
    reference to the Pull Request in the `revision` parameter (you can also test it
    in this [Check PR](https://huggingface.co/spaces/diffusers/check_pr) Space on
    the Hub), for example `refs/pr/22`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Why use safetensors?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several reasons for using safetensors:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Safety is the number one reason for using safetensors. As open-source and model
    distribution grows, it is important to be able to trust the model weights you
    downloaded don’t contain any malicious code. The current size of the header in
    safetensors prevents parsing extremely large JSON files.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading speed between switching models is another reason to use safetensors,
    which performs zero-copy of the tensors. It is especially fast compared to `pickle`
    if you’re loading the weights to CPU (the default case), and just as fast if not
    faster when directly loading the weights to GPU. You’ll only notice the performance
    difference if the model is already loaded, and not if you’re downloading the weights
    or loading the model for the first time.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The time it takes to load the entire pipeline:'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'But the actual time it takes to load 500MB of the model weights is only:'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Lazy loading is also supported in safetensors, which is useful in distributed
    settings to only load some of the tensors. This format allowed the [BLOOM](https://huggingface.co/bigscience/bloom)
    model to be loaded in 45 seconds on 8 GPUs instead of 10 minutes with regular
    PyTorch weights.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在safetensors中也支持延迟加载，这在分布式环境中非常有用，可以只加载部分张量。这种格式使得[BLOOM](https://huggingface.co/bigscience/bloom)模型在8个GPU上仅用45秒加载完成，而使用常规的PyTorch权重则需要10分钟。
