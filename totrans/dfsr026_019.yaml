- en: Load safetensors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors](https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[safetensors](https://github.com/huggingface/safetensors) is a safe and fast
    file format for storing and loading tensors. Typically, PyTorch model weights
    are saved or *pickled* into a `.bin` file with Pythonâ€™s [`pickle`](https://docs.python.org/3/library/pickle.html)
    utility. However, `pickle` is not secure and pickled files may contain malicious
    code that can be executed. safetensors is a secure alternative to `pickle`, making
    it ideal for sharing model weights.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'This guide will show you how you load `.safetensor` files, and how to convert
    Stable Diffusion model weights stored in other formats to `.safetensor`. Before
    you start, make sure you have safetensors installed:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you look at the [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)
    repository, youâ€™ll see weights inside the `text_encoder`, `unet` and `vae` subfolders
    are stored in the `.safetensors` format. By default, ğŸ¤— Diffusers automatically
    loads these `.safetensors` files from their subfolders if theyâ€™re available in
    the model repository.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'For more explicit control, you can optionally set `use_safetensors=True` (if
    `safetensors` is not installed, youâ€™ll get an error message asking you to install
    it):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'However, model weights are not necessarily stored in separate subfolders like
    in the example above. Sometimes, all the weights are stored in a single `.safetensors`
    file. In this case, if the weights are Stable Diffusion weights, you can load
    the file directly with the [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    method:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Convert to safetensors
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not all weights on the Hub are available in the `.safetensors` format, and you
    may encounter weights stored as `.bin`. In this case, use the [Convert Space](https://huggingface.co/spaces/diffusers/convert)
    to convert the weights to `.safetensors`. The Convert Space downloads the pickled
    weights, converts them, and opens a Pull Request to upload the newly converted
    `.safetensors` file on the Hub. This way, if there is any malicious code contained
    in the pickled files, theyâ€™re uploaded to the Hub - which has a [security scanner](https://huggingface.co/docs/hub/security-pickle#hubs-security-scanner)
    to detect unsafe files and suspicious pickle imports - instead of your computer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the model with the new `.safetensors` weights by specifying the
    reference to the Pull Request in the `revision` parameter (you can also test it
    in this [Check PR](https://huggingface.co/spaces/diffusers/check_pr) Space on
    the Hub), for example `refs/pr/22`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Why use safetensors?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several reasons for using safetensors:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Safety is the number one reason for using safetensors. As open-source and model
    distribution grows, it is important to be able to trust the model weights you
    downloaded donâ€™t contain any malicious code. The current size of the header in
    safetensors prevents parsing extremely large JSON files.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading speed between switching models is another reason to use safetensors,
    which performs zero-copy of the tensors. It is especially fast compared to `pickle`
    if youâ€™re loading the weights to CPU (the default case), and just as fast if not
    faster when directly loading the weights to GPU. Youâ€™ll only notice the performance
    difference if the model is already loaded, and not if youâ€™re downloading the weights
    or loading the model for the first time.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The time it takes to load the entire pipeline:'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'But the actual time it takes to load 500MB of the model weights is only:'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Lazy loading is also supported in safetensors, which is useful in distributed
    settings to only load some of the tensors. This format allowed the [BLOOM](https://huggingface.co/bigscience/bloom)
    model to be loaded in 45 seconds on 8 GPUs instead of 10 minutes with regular
    PyTorch weights.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨safetensorsä¸­ä¹Ÿæ”¯æŒå»¶è¿ŸåŠ è½½ï¼Œè¿™åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥åªåŠ è½½éƒ¨åˆ†å¼ é‡ã€‚è¿™ç§æ ¼å¼ä½¿å¾—[BLOOM](https://huggingface.co/bigscience/bloom)æ¨¡å‹åœ¨8ä¸ªGPUä¸Šä»…ç”¨45ç§’åŠ è½½å®Œæˆï¼Œè€Œä½¿ç”¨å¸¸è§„çš„PyTorchæƒé‡åˆ™éœ€è¦10åˆ†é’Ÿã€‚
