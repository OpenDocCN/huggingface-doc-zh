# è®­ç»ƒå™¨

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/trainer](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/trainer)

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ç±»æä¾›äº†ä¸€ä¸ªç”¨äºåœ¨PyTorchä¸­è¿›è¡Œå®Œæ•´ç‰¹å¾è®­ç»ƒçš„APIï¼Œå¹¶æ”¯æŒåœ¨å¤šä¸ªGPU/TPUä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ”¯æŒ[NVIDIA GPUs](https://nvidia.github.io/apex/)çš„æ··åˆç²¾åº¦ï¼Œ[AMD GPUs](https://rocm.docs.amd.com/en/latest/rocm.html)ï¼Œä»¥åŠPyTorchçš„[`torch.amp`](https://pytorch.org/docs/stable/amp.html)ã€‚[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä¸[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ç±»ç›¸è¾…ç›¸æˆï¼Œåè€…æä¾›äº†å¹¿æ³›çš„é€‰é¡¹æ¥è‡ªå®šä¹‰æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ã€‚è¿™ä¸¤ä¸ªç±»ä¸€èµ·æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒAPIã€‚

[Seq2SeqTrainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Seq2SeqTrainer) å’Œ [Seq2SeqTrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments) ç»§æ‰¿è‡ª[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å’Œ`TrainingArgument`ç±»ï¼Œå®ƒä»¬é€‚ç”¨äºç”¨äºåºåˆ—åˆ°åºåˆ—ä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦æˆ–ç¿»è¯‘ï¼‰çš„æ¨¡å‹è®­ç»ƒã€‚

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ç±»é’ˆå¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå½“ä¸å…¶ä»–æ¨¡å‹ä¸€èµ·ä½¿ç”¨æ—¶å¯èƒ½ä¼šæœ‰ä¸€äº›æ„å¤–è¡Œä¸ºã€‚åœ¨ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹æ—¶ï¼Œè¯·ç¡®ä¿ï¼š

+   æ‚¨çš„æ¨¡å‹å§‹ç»ˆè¿”å›å…ƒç»„æˆ–[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)çš„å­ç±»

+   å¦‚æœæä¾›äº†`labels`å‚æ•°å¹¶ä¸”è¯¥æŸå¤±ä½œä¸ºå…ƒç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ è¿”å›ï¼ˆå¦‚æœæ‚¨çš„æ¨¡å‹è¿”å›å…ƒç»„ï¼‰ï¼Œåˆ™æ‚¨çš„æ¨¡å‹å¯ä»¥è®¡ç®—æŸå¤±

+   æ‚¨çš„æ¨¡å‹å¯ä»¥æ¥å—å¤šä¸ªæ ‡ç­¾å‚æ•°ï¼ˆåœ¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­ä½¿ç”¨`label_names`æŒ‡ç¤ºå®ƒä»¬çš„åç§°ç»™[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ï¼Œä½†å®ƒä»¬ä¸­æ²¡æœ‰ä¸€ä¸ªåº”è¯¥è¢«å‘½åä¸º`"label"`

## è®­ç»ƒå™¨

### `class transformers.Trainer`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L236)

```py
( model: Union = None args: TrainingArguments = None data_collator: Optional = None train_dataset: Optional = None eval_dataset: Union = None tokenizer: Optional = None model_init: Optional = None compute_metrics: Optional = None callbacks: Optional = None optimizers: Tuple = (None, None) preprocess_logits_for_metrics: Optional = None )
```

å‚æ•°

+   `model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel) æˆ– `torch.nn.Module`, *å¯é€‰*) â€” ç”¨äºè®­ç»ƒã€è¯„ä¼°æˆ–ç”¨äºé¢„æµ‹çš„æ¨¡å‹ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™å¿…é¡»ä¼ é€’ä¸€ä¸ª`model_init`ã€‚

    [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) è¢«ä¼˜åŒ–ä¸ºä¸åº“æä¾›çš„[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ä¸€èµ·ä½¿ç”¨ã€‚åªè¦æ‚¨çš„æ¨¡å‹ä¸ğŸ¤— Transformersæ¨¡å‹çš„å·¥ä½œæ–¹å¼ç›¸åŒï¼Œæ‚¨ä»ç„¶å¯ä»¥ä½¿ç”¨è‡ªå·±å®šä¹‰çš„`torch.nn.Module`æ¨¡å‹ã€‚

+   `args` ([TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments), *å¯é€‰*) â€” ç”¨äºè°ƒæ•´è®­ç»ƒçš„å‚æ•°ã€‚å¦‚æœæœªæä¾›ï¼Œå°†é»˜è®¤ä¸ºä¸€ä¸ªåŸºæœ¬çš„[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å®ä¾‹ï¼Œå…¶ä¸­`output_dir`è®¾ç½®ä¸ºå½“å‰ç›®å½•ä¸­åä¸º*tmp_trainer*çš„ç›®å½•ã€‚

+   `data_collator` (`DataCollator`, *å¯é€‰*) â€” ç”¨äºä»`train_dataset`æˆ–`eval_dataset`çš„å…ƒç´ åˆ—è¡¨ä¸­å½¢æˆæ‰¹æ¬¡çš„å‡½æ•°ã€‚å¦‚æœæœªæä¾›`tokenizer`ï¼Œå°†é»˜è®¤ä¸º[default_data_collator()](/docs/transformers/v4.37.2/en/main_classes/data_collator#transformers.default_data_collator)ï¼Œå¦åˆ™å°†é»˜è®¤ä¸º[DataCollatorWithPadding](/docs/transformers/v4.37.2/en/main_classes/data_collator#transformers.DataCollatorWithPadding)çš„å®ä¾‹ã€‚

+   `train_dataset`ï¼ˆ`torch.utils.data.Dataset`æˆ–`torch.utils.data.IterableDataset`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®­ç»ƒçš„æ•°æ®é›†ã€‚å¦‚æœæ˜¯[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œåˆ™ä¸è¢«`model.forward()`æ–¹æ³•æ¥å—çš„åˆ—å°†è‡ªåŠ¨åˆ é™¤ã€‚

    è¯·æ³¨æ„ï¼Œå¦‚æœæ˜¯å¸¦æœ‰ä¸€äº›éšæœºåŒ–çš„`torch.utils.data.IterableDataset`ï¼Œå¹¶ä¸”æ‚¨æ­£åœ¨ä»¥åˆ†å¸ƒå¼æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œæ‚¨çš„å¯è¿­ä»£æ•°æ®é›†åº”è¯¥ä½¿ç”¨ä¸€ä¸ªå†…éƒ¨å±æ€§`generator`ï¼Œè¯¥å±æ€§æ˜¯ä¸€ä¸ª`torch.Generator`ï¼Œç”¨äºåœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šä¿æŒç›¸åŒçš„éšæœºåŒ–ï¼ˆå¹¶ä¸”Trainerå°†åœ¨æ¯ä¸ªepochæ‰‹åŠ¨è®¾ç½®æ­¤`generator`çš„ç§å­ï¼‰ï¼Œæˆ–è€…å…·æœ‰ä¸€ä¸ªåœ¨å†…éƒ¨è®¾ç½®ç”¨äºéšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­çš„`set_epoch()`æ–¹æ³•ã€‚

+   `eval_dataset`ï¼ˆUnion[`torch.utils.data.Dataset`ï¼ŒDict[strï¼Œ`torch.utils.data.Dataset`]ï¼‰ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè¯„ä¼°çš„æ•°æ®é›†ã€‚å¦‚æœæ˜¯[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œåˆ™ä¸è¢«`model.forward()`æ–¹æ³•æ¥å—çš„åˆ—å°†è‡ªåŠ¨åˆ é™¤ã€‚å¦‚æœæ˜¯å­—å…¸ï¼Œåˆ™å°†åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œå¹¶åœ¨åº¦é‡åç§°ä¹‹å‰æ·»åŠ å­—å…¸é”®ã€‚

+   `tokenizer`ï¼ˆ[PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase)ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¢„å¤„ç†æ•°æ®çš„åˆ†è¯å™¨ã€‚å¦‚æœæä¾›ï¼Œå°†ç”¨äºåœ¨æ‰¹å¤„ç†è¾“å…¥æ—¶è‡ªåŠ¨å¡«å……è¾“å…¥åˆ°æœ€å¤§é•¿åº¦ï¼Œå¹¶å°†ä¿å­˜åœ¨æ¨¡å‹ä¸­ï¼Œä»¥ä¾¿æ›´å®¹æ˜“é‡æ–°è¿è¡Œä¸­æ–­çš„è®­ç»ƒæˆ–é‡ç”¨å¾®è°ƒçš„æ¨¡å‹ã€‚

+   `model_init`ï¼ˆ`Callable[[], PreTrainedModel]`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå®ä¾‹åŒ–è¦ä½¿ç”¨çš„æ¨¡å‹çš„å‡½æ•°ã€‚å¦‚æœæä¾›ï¼Œæ¯æ¬¡è°ƒç”¨[train()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.train)éƒ½å°†ä»æ­¤å‡½æ•°ç»™å‡ºçš„æ¨¡å‹çš„æ–°å®ä¾‹å¼€å§‹ã€‚

    è¯¥å‡½æ•°å¯èƒ½æ²¡æœ‰å‚æ•°ï¼Œæˆ–è€…åŒ…å«ä¸€ä¸ªå‚æ•°ï¼Œå…¶ä¸­åŒ…å«optuna/Ray Tune/SigOptè¯•éªŒå¯¹è±¡ï¼Œä»¥ä¾¿æ ¹æ®è¶…å‚æ•°ï¼ˆä¾‹å¦‚å±‚è®¡æ•°ã€å†…éƒ¨å±‚å¤§å°ã€ä¸¢å¤±æ¦‚ç‡ç­‰ï¼‰é€‰æ‹©ä¸åŒçš„æ¶æ„ã€‚

+   `compute_metrics`ï¼ˆ`Callable[[EvalPrediction], Dict]`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºåœ¨è¯„ä¼°æ—¶è®¡ç®—æŒ‡æ ‡çš„å‡½æ•°ã€‚å¿…é¡»æ¥å—[EvalPrediction](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.EvalPrediction)å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²å­—å…¸ä»¥è¡¨ç¤ºæŒ‡æ ‡å€¼ã€‚

+   `callbacks`ï¼ˆ[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)åˆ—è¡¨ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè‡ªå®šä¹‰è®­ç»ƒå¾ªç¯çš„å›è°ƒåˆ—è¡¨ã€‚å°†æ·»åŠ åˆ°[æ­¤å¤„](callback)è¯¦ç»†è¯´æ˜çš„é»˜è®¤å›è°ƒåˆ—è¡¨ä¸­ã€‚

    å¦‚æœè¦åˆ é™¤ä½¿ç”¨çš„é»˜è®¤å›è°ƒä¹‹ä¸€ï¼Œè¯·ä½¿ç”¨[Trainer.remove_callback()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.remove_callback)æ–¹æ³•ã€‚

+   `optimizers`ï¼ˆ`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`(None, None)`ï¼‰â€” åŒ…å«è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨çš„å…ƒç»„ã€‚å°†é»˜è®¤ä¸ºæ‚¨çš„æ¨¡å‹ä¸Šçš„[AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW)å®ä¾‹å’Œç”±[get_linear_schedule_with_warmup()](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)æ§åˆ¶çš„è°ƒåº¦å™¨ï¼Œç”±`args`æŒ‡å®šã€‚

+   `preprocess_logits_for_metrics`ï¼ˆ`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºåœ¨æ¯ä¸ªè¯„ä¼°æ­¥éª¤ä¹‹å‰é¢„å¤„ç†logitsçš„å‡½æ•°ã€‚å¿…é¡»æ¥å—ä¸¤ä¸ªå¼ é‡ï¼Œlogitså’Œæ ‡ç­¾ï¼Œå¹¶æ ¹æ®éœ€è¦è¿”å›å¤„ç†åçš„logitsã€‚æ­¤å‡½æ•°æ‰€åšçš„ä¿®æ”¹å°†åæ˜ åœ¨`compute_metrics`æ¥æ”¶åˆ°çš„é¢„æµ‹ä¸­ã€‚

    è¯·æ³¨æ„ï¼Œå¦‚æœæ•°æ®é›†æ²¡æœ‰æ ‡ç­¾ï¼Œæ ‡ç­¾ï¼ˆç¬¬äºŒä¸ªå‚æ•°ï¼‰å°†ä¸º`None`ã€‚

Traineræ˜¯ä¸€ä¸ªç®€å•ä½†åŠŸèƒ½å®Œå¤‡çš„PyTorchè®­ç»ƒå’Œè¯„ä¼°å¾ªç¯ï¼Œä¸“ä¸ºğŸ¤— Transformersä¼˜åŒ–ã€‚

é‡è¦å±æ€§ï¼š

+   `model` - å§‹ç»ˆæŒ‡å‘æ ¸å¿ƒæ¨¡å‹ã€‚å¦‚æœä½¿ç”¨transformersæ¨¡å‹ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)å­ç±»ã€‚

+   `model_wrapped` - å§‹ç»ˆæŒ‡å‘æœ€å¤–éƒ¨çš„æ¨¡å‹ï¼Œä»¥é˜²ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–æ¨¡å—åŒ…è£…åŸå§‹æ¨¡å‹ã€‚è¿™æ˜¯åº”è¯¥ç”¨äºå‰å‘ä¼ é€’çš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œåœ¨`DeepSpeed`ä¸‹ï¼Œå†…éƒ¨æ¨¡å‹è¢«åŒ…è£…åœ¨`DeepSpeed`ä¸­ï¼Œç„¶åå†æ¬¡åŒ…è£…åœ¨`torch.nn.DistributedDataParallel`ä¸­ã€‚å¦‚æœå†…éƒ¨æ¨¡å‹æ²¡æœ‰è¢«åŒ…è£…ï¼Œé‚£ä¹ˆ`self.model_wrapped`ä¸`self.model`ç›¸åŒã€‚

+   `is_model_parallel` - æ¨¡å‹æ˜¯å¦å·²åˆ‡æ¢åˆ°æ¨¡å‹å¹¶è¡Œæ¨¡å¼ï¼ˆä¸æ•°æ®å¹¶è¡Œä¸åŒï¼Œè¿™æ„å‘³ç€ä¸€äº›æ¨¡å‹å±‚åœ¨ä¸åŒçš„GPUä¸Šåˆ†å‰²ï¼‰ã€‚ 

+   `place_model_on_device` - æ˜¯å¦è‡ªåŠ¨å°†æ¨¡å‹æ”¾ç½®åœ¨è®¾å¤‡ä¸Š - å¦‚æœä½¿ç”¨æ¨¡å‹å¹¶è¡Œæˆ–deepspeedï¼Œæˆ–è€…å¦‚æœé»˜è®¤çš„`TrainingArguments.place_model_on_device`è¢«è¦†ç›–ä¸ºè¿”å›`False`ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸º`False`ã€‚

+   `is_in_train` - æ¨¡å‹å½“å‰æ˜¯å¦åœ¨è¿è¡Œ`train`ï¼ˆä¾‹å¦‚ï¼Œåœ¨`train`ä¸­è°ƒç”¨`evaluate`æ—¶ï¼‰

#### `add_callback`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L654)

```py
( callback )
```

å‚æ•°

+   `callback`ï¼ˆ`type`æˆ–[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)ï¼‰- ä¸€ä¸ª[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)ç±»æˆ–[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)çš„å®ä¾‹ã€‚åœ¨ç¬¬ä¸€ç§æƒ…å†µä¸‹ï¼Œå°†å®ä¾‹åŒ–è¯¥ç±»çš„æˆå‘˜ã€‚

å‘å½“å‰çš„[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)åˆ—è¡¨ä¸­æ·»åŠ ä¸€ä¸ªå›è°ƒã€‚

#### `autocast_smart_context_manager`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2734)

```py
( cache_enabled: Optional = True )
```

ä¸€ä¸ªå¸®åŠ©å™¨åŒ…è£…å™¨ï¼Œä¸º`autocast`åˆ›å»ºé€‚å½“çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¹¶æ ¹æ®æƒ…å†µæä¾›æ‰€éœ€çš„å‚æ•°ã€‚

#### `compute_loss`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2785)

```py
( model inputs return_outputs = False )
```

Trainerå¦‚ä½•è®¡ç®—æŸå¤±ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½åœ¨ç¬¬ä¸€ä¸ªå…ƒç´ ä¸­è¿”å›æŸå¤±ã€‚

å­ç±»å’Œè¦†ç›–ä»¥è¿›è¡Œè‡ªå®šä¹‰è¡Œä¸ºã€‚

#### `compute_loss_context_manager`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2728)

```py
( )
```

ä¸€ä¸ªå¸®åŠ©å™¨åŒ…è£…å™¨ï¼Œç”¨äºå°†ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç»„åˆåœ¨ä¸€èµ·ã€‚

#### `create_model_card`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3564)

```py
( language: Optional = None license: Optional = None tags: Union = None model_name: Optional = None finetuned_from: Optional = None tasks: Union = None dataset_tags: Union = None dataset: Union = None dataset_args: Union = None )
```

å‚æ•°

+   `language`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹çš„è¯­è¨€ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

+   `license`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹çš„è®¸å¯è¯ã€‚å¦‚æœåŸå§‹æ¨¡å‹ç»™å®šç»™`Trainer`æ¥è‡ªHubä¸Šçš„repoï¼Œåˆ™å°†é»˜è®¤ä¸ºä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹çš„è®¸å¯è¯ã€‚

+   `tags`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- è¦åŒ…å«åœ¨æ¨¡å‹å¡å…ƒæ•°æ®ä¸­çš„ä¸€äº›æ ‡ç­¾ã€‚

+   `model_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹çš„åç§°ã€‚

+   `finetuned_from`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºå¾®è°ƒæ­¤æ¨¡å‹çš„æ¨¡å‹çš„åç§°ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚å¦‚æœåŸå§‹æ¨¡å‹ç»™å®šç»™`Trainer`æ¥è‡ªHubï¼Œåˆ™å°†é»˜è®¤ä¸ºåŸå§‹æ¨¡å‹çš„repoçš„åç§°ã€‚

+   `tasks`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- ä¸€ä¸ªæˆ–å¤šä¸ªä»»åŠ¡æ ‡è¯†ç¬¦ï¼Œå°†åŒ…å«åœ¨æ¨¡å‹å¡çš„å…ƒæ•°æ®ä¸­ã€‚

+   `dataset_tags`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†æ ‡ç­¾ï¼Œå°†åŒ…å«åœ¨æ¨¡å‹å¡çš„å…ƒæ•°æ®ä¸­ã€‚

+   `dataset`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†æ ‡è¯†ç¬¦ï¼Œå°†åŒ…å«åœ¨æ¨¡å‹å¡çš„å…ƒæ•°æ®ä¸­ã€‚

+   `dataset_args` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†å‚æ•°ï¼Œå°†åŒ…å«åœ¨æ¨¡å‹å¡çš„å…ƒæ•°æ®ä¸­ã€‚

ä½¿ç”¨`Trainer`å¯ç”¨çš„ä¿¡æ¯åˆ›å»ºä¸€ä¸ªæ¨¡å‹å¡çš„è‰ç¨¿ã€‚

#### `create_optimizer`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L929)

```py
( )
```

è®¾ç½®ä¼˜åŒ–å™¨ã€‚

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåˆç†çš„é»˜è®¤å€¼ï¼Œæ•ˆæœå¾ˆå¥½ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨å…¶ä»–å†…å®¹ï¼Œå¯ä»¥é€šè¿‡`optimizers`åœ¨Trainerçš„initä¸­ä¼ é€’ä¸€ä¸ªå…ƒç»„ï¼Œæˆ–è€…åœ¨å­ç±»ä¸­é‡å†™æ­¤æ–¹æ³•ã€‚

åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L902)

```py
( num_training_steps: int )
```

è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåˆç†çš„é»˜è®¤å€¼ï¼Œæ•ˆæœå¾ˆå¥½ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨å…¶ä»–å†…å®¹ï¼Œå¯ä»¥é€šè¿‡`optimizers`åœ¨Trainerçš„initä¸­ä¼ é€’ä¸€ä¸ªå…ƒç»„ï¼Œæˆ–è€…åœ¨å­ç±»ä¸­é‡å†™æ­¤æ–¹æ³•ï¼ˆæˆ–`create_optimizer`å’Œ/æˆ–`create_scheduler`ï¼‰ã€‚

#### `create_scheduler`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L1109)

```py
( num_training_steps: int optimizer: Optimizer = None )
```

å‚æ•°

+   `num_training_steps` (int) â€” è¦æ‰§è¡Œçš„è®­ç»ƒæ­¥éª¤æ•°ã€‚

è®¾ç½®è°ƒåº¦å™¨ã€‚è®­ç»ƒå™¨çš„ä¼˜åŒ–å™¨å¿…é¡»åœ¨è°ƒç”¨æ­¤æ–¹æ³•ä¹‹å‰è®¾ç½®å¥½ï¼Œæˆ–è€…ä½œä¸ºå‚æ•°ä¼ é€’ã€‚

#### `evaluate`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3031)

```py
( eval_dataset: Union = None ignore_keys: Optional = None metric_key_prefix: str = 'eval' )
```

å‚æ•°

+   `eval_dataset` (Union[`Dataset`, Dict[str, `Dataset`]), *å¯é€‰*) â€” å¦‚æœè¦è¦†ç›–`self.eval_dataset`ï¼Œè¯·ä¼ é€’ä¸€ä¸ªæ•°æ®é›†ã€‚å¦‚æœæ˜¯ä¸€ä¸ª[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œåˆ™`model.forward()`æ–¹æ³•ä¸æ¥å—çš„åˆ—å°†è‡ªåŠ¨åˆ é™¤ã€‚å¦‚æœæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå®ƒå°†å¯¹æ¯ä¸ªæ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œå¹¶åœ¨åº¦é‡åç§°å‰åŠ ä¸Šå­—å…¸é”®ã€‚æ•°æ®é›†å¿…é¡»å®ç°`__len__`æ–¹æ³•ã€‚

    å¦‚æœæ‚¨ä¼ é€’ä¸€ä¸ªä»¥æ•°æ®é›†åç§°ä¸ºé”®ã€æ•°æ®é›†ä¸ºå€¼çš„å­—å…¸ï¼Œè¯„ä¼°å°†åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šå•ç‹¬è¿è¡Œã€‚è¿™å¯¹äºç›‘è§†è®­ç»ƒå¦‚ä½•å½±å“å…¶ä»–æ•°æ®é›†æˆ–ä»…ä»…è·å¾—æ›´ç²¾ç»†çš„è¯„ä¼°å¾ˆæœ‰ç”¨ã€‚å½“ä¸`load_best_model_at_end`ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œè¯·ç¡®ä¿`metric_for_best_model`å¼•ç”¨ç¡®åˆ‡åœ°ä¸€ä¸ªæ•°æ®é›†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸ºä¸¤ä¸ªæ•°æ®é›†`data1`å’Œ`data2`ä¼ é€’`{"data1": data1, "data2": data2}`ï¼Œåˆ™å¯ä»¥æŒ‡å®š`metric_for_best_model="eval_data1_loss"`æ¥ä½¿ç”¨`data1`ä¸Šçš„æŸå¤±ï¼Œä»¥åŠ`metric_for_best_model="eval_data1_loss"`æ¥ä½¿ç”¨`data2`ä¸Šçš„æŸå¤±ã€‚

+   `ignore_keys` (`List[str]`, *å¯é€‰*) â€” åœ¨æ¨¡å‹è¾“å‡ºä¸­åº”è¯¥è¢«å¿½ç•¥çš„é”®çš„åˆ—è¡¨ï¼ˆå¦‚æœå®ƒæ˜¯ä¸€ä¸ªå­—å…¸ï¼‰ã€‚

+   `metric_key_prefix` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"eval"`) â€” ç”¨ä½œæŒ‡æ ‡é”®å‰ç¼€çš„å¯é€‰å‰ç¼€ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå‰ç¼€æ˜¯`"eval"`ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™æŒ‡æ ‡â€œbleuâ€å°†è¢«å‘½åä¸ºâ€œeval_bleuâ€ã€‚

è¿è¡Œè¯„ä¼°å¹¶è¿”å›æŒ‡æ ‡ã€‚

è°ƒç”¨è„šæœ¬å°†è´Ÿè´£æä¾›è®¡ç®—æŒ‡æ ‡çš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ä»»åŠ¡ç›¸å…³çš„ï¼ˆå°†å…¶ä¼ é€’ç»™`compute_metrics`å‚æ•°è¿›è¡Œåˆå§‹åŒ–ï¼‰ã€‚

æ‚¨ä¹Ÿå¯ä»¥å­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ä»¥æ³¨å…¥è‡ªå®šä¹‰è¡Œä¸ºã€‚

#### `evaluation_loop`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3191)

```py
( dataloader: DataLoader description: str prediction_loss_only: Optional = None ignore_keys: Optional = None metric_key_prefix: str = 'eval' )
```

é¢„æµ‹/è¯„ä¼°å¾ªç¯ï¼Œç”±`Trainer.evaluate()`å’Œ`Trainer.predict()`å…±äº«ã€‚

å¯ä»¥ä½¿ç”¨å¸¦æœ‰æˆ–ä¸å¸¦æœ‰æ ‡ç­¾çš„å·¥ä½œã€‚

#### `floating_point_ops`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3529)

```py
( inputs: Dict ) â†’ export const metadata = 'undefined';int
```

å‚æ•°

+   `inputs` (`Dict[str, Union[torch.Tensor, Any]]`) â€” æ¨¡å‹çš„è¾“å…¥å’Œç›®æ ‡ã€‚

è¿”å›

`int`

æµ®ç‚¹è¿ç®—çš„æ•°é‡ã€‚

å¯¹äºç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)çš„æ¨¡å‹ï¼Œä½¿ç”¨è¯¥æ–¹æ³•è®¡ç®—æ¯æ¬¡åå‘+å‰å‘ä¼ é€’çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚å¦‚æœä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹ï¼Œè¦ä¹ˆåœ¨æ¨¡å‹ä¸­å®ç°è¿™æ ·çš„æ–¹æ³•ï¼Œè¦ä¹ˆå­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ã€‚

#### `get_decay_parameter_names`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L918)

```py
( model )
```

è·å–å°†åº”ç”¨æƒé‡è¡°å‡çš„æ‰€æœ‰å‚æ•°åç§°

è¯·æ³¨æ„ï¼Œä¸€äº›æ¨¡å‹å®ç°äº†è‡ªå·±çš„layernormè€Œä¸æ˜¯è°ƒç”¨nn.LayerNormï¼Œå› æ­¤è¿™ä¸ªå‡½æ•°åªè¿‡æ»¤å‡ºnn.LayerNormçš„å®ä¾‹

#### `get_eval_dataloader`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L834)

```py
( eval_dataset: Optional = None )
```

å‚æ•°

+   `eval_dataset` (`torch.utils.data.Dataset`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼Œå°†è¦†ç›–`self.eval_dataset`ã€‚å¦‚æœå®ƒæ˜¯ä¸€ä¸ª[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œé‚£äº›`model.forward()`æ–¹æ³•ä¸æ¥å—çš„åˆ—å°†è¢«è‡ªåŠ¨ç§»é™¤ã€‚å®ƒå¿…é¡»å®ç°`__len__`ã€‚

è¿”å›è¯„ä¼°`~torch.utils.data.DataLoader`ã€‚

å¦‚æœæ‚¨æƒ³è¦æ³¨å…¥ä¸€äº›è‡ªå®šä¹‰è¡Œä¸ºï¼Œè¯·å­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ã€‚

#### `get_optimizer_cls_and_kwargs`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L977)

```py
( args: TrainingArguments )
```

å‚æ•°

+   `args` (`transformers.training_args.TrainingArguments`) â€” è®­ç»ƒä¼šè¯çš„è®­ç»ƒå‚æ•°ã€‚

æ ¹æ®è®­ç»ƒå‚æ•°è¿”å›ä¼˜åŒ–å™¨ç±»å’Œä¼˜åŒ–å™¨å‚æ•°ã€‚

#### `get_test_dataloader`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L869)

```py
( test_dataset: Dataset )
```

å‚æ•°

+   `test_dataset` (`torch.utils.data.Dataset`, *å¯é€‰*) â€” è¦ä½¿ç”¨çš„æµ‹è¯•æ•°æ®é›†ã€‚å¦‚æœå®ƒæ˜¯ä¸€ä¸ª[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œé‚£äº›`model.forward()`æ–¹æ³•ä¸æ¥å—çš„åˆ—å°†è¢«è‡ªåŠ¨ç§»é™¤ã€‚å®ƒå¿…é¡»å®ç°`__len__`ã€‚

è¿”å›æµ‹è¯•`~torch.utils.data.DataLoader`ã€‚

å¦‚æœæ‚¨æƒ³è¦æ³¨å…¥ä¸€äº›è‡ªå®šä¹‰è¡Œä¸ºï¼Œè¯·å­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ã€‚

#### `get_train_dataloader`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L778)

```py
( )
```

è¿”å›è®­ç»ƒ`~torch.utils.data.DataLoader`ã€‚

å¦‚æœ`train_dataset`ä¸å®ç°`__len__`ï¼Œåˆ™ä¸ä½¿ç”¨é‡‡æ ·å™¨ï¼Œå¦åˆ™ä½¿ç”¨éšæœºé‡‡æ ·å™¨ï¼ˆå¿…è¦æ—¶é€‚åº”åˆ†å¸ƒå¼è®­ç»ƒï¼‰ã€‚

å¦‚æœæ‚¨æƒ³è¦æ³¨å…¥ä¸€äº›è‡ªå®šä¹‰è¡Œä¸ºï¼Œè¯·å­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ã€‚

#### `hyperparameter_search`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2596)

```py
( hp_space: Optional = None compute_objective: Optional = None n_trials: int = 20 direction: Union = 'minimize' backend: Union = None hp_name: Optional = None **kwargs ) â†’ export const metadata = 'undefined';[trainer_utils.BestRun or List[trainer_utils.BestRun]]
```

å‚æ•°

+   `hp_space` (`Callable[["optuna.Trial"], Dict[str, float]]`, *å¯é€‰*) â€” å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´çš„å‡½æ•°ã€‚å°†æ ¹æ®æ‚¨çš„åç«¯é»˜è®¤ä¸º`default_hp_space_optuna()`æˆ–`default_hp_space_ray()`æˆ–`default_hp_space_sigopt()`ã€‚

+   `compute_objective` (`Callable[[Dict[str, float]], float]`, *å¯é€‰*) â€” ä¸€ä¸ªè®¡ç®—è¦æœ€å°åŒ–æˆ–æœ€å¤§åŒ–çš„ç›®æ ‡çš„å‡½æ•°ï¼Œä»`evaluate`æ–¹æ³•è¿”å›çš„æŒ‡æ ‡ä¸­è®¡ç®—ã€‚å°†é»˜è®¤ä¸º`default_compute_objective()`ã€‚

+   `n_trials` (`int`, *å¯é€‰*, é»˜è®¤ä¸º100) â€” æµ‹è¯•è¿è¡Œçš„æ¬¡æ•°ã€‚

+   `direction` (`str` æˆ– `List[str]`, *å¯é€‰*, é»˜è®¤ä¸º`"minimize"`) â€” å¦‚æœæ˜¯å•ç›®æ ‡ä¼˜åŒ–ï¼Œæ–¹å‘æ˜¯`str`ï¼Œå¯ä»¥æ˜¯`"minimize"`æˆ–`"maximize"`ï¼Œå½“ä¼˜åŒ–éªŒè¯æŸå¤±æ—¶åº”é€‰æ‹©`"minimize"`ï¼Œå½“ä¼˜åŒ–ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‡æ ‡æ—¶åº”é€‰æ‹©`"maximize"`ã€‚å¦‚æœæ˜¯å¤šç›®æ ‡ä¼˜åŒ–ï¼Œæ–¹å‘æ˜¯`List[str]`ï¼Œå¯ä»¥æ˜¯`"minimize"`å’Œ`"maximize"`çš„åˆ—è¡¨ï¼Œå½“ä¼˜åŒ–éªŒè¯æŸå¤±æ—¶åº”é€‰æ‹©`"minimize"`ï¼Œå½“ä¼˜åŒ–ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‡æ ‡æ—¶åº”é€‰æ‹©`"maximize"`ã€‚

+   `backend`ï¼ˆ`str`æˆ–`~training_utils.HPSearchBackend`ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨äºè¶…å‚æ•°æœç´¢çš„åç«¯ã€‚å°†é»˜è®¤ä¸ºoptunaã€Ray Tuneæˆ–SigOptï¼Œå–å†³äºå®‰è£…äº†å“ªä¸ªã€‚å¦‚æœæ‰€æœ‰éƒ½å®‰è£…äº†ï¼Œå°†é»˜è®¤ä¸ºoptunaã€‚

+   `hp_name`ï¼ˆ`Callable[["optuna.Trial"], str]`ï¼Œ*å¯é€‰*ï¼‰â€”å®šä¹‰è¯•éªŒ/è¿è¡Œåç§°çš„å‡½æ•°ã€‚é»˜è®¤ä¸ºNoneã€‚

+   `kwargs`ï¼ˆ`Dict[str, Any]`ï¼Œ*å¯é€‰*ï¼‰â€”ä¼ é€’ç»™`optuna.create_study`æˆ–`ray.tune.run`çš„å…¶ä»–å…³é”®å­—å‚æ•°ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§ï¼š

    +   [optuna.create_studyçš„æ–‡æ¡£](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.create_study.html)

    +   [tune.runçš„æ–‡æ¡£](https://docs.ray.io/en/latest/tune/api_docs/execution.html#tune-run)

    +   [sigoptçš„æ–‡æ¡£](https://app.sigopt.com/docs/endpoints/experiments/create)

è¿”å›

[`trainer_utils.BestRun`æˆ–`List[trainer_utils.BestRun]`]

æœ‰å…³å¤šç›®æ ‡ä¼˜åŒ–çš„æœ€ä½³è¿è¡Œæˆ–æœ€ä½³è¿è¡Œçš„æ‰€æœ‰ä¿¡æ¯ã€‚å®éªŒæ‘˜è¦å¯ä»¥åœ¨Rayåç«¯çš„`run_summary`å±æ€§ä¸­æ‰¾åˆ°ã€‚

ä½¿ç”¨`optuna`ã€`Ray Tune`æˆ–`SigOpt`å¯åŠ¨è¶…å‚æ•°æœç´¢ã€‚ä¼˜åŒ–çš„æ•°é‡ç”±`compute_objective`ç¡®å®šï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œå½“æ²¡æœ‰æä¾›æŒ‡æ ‡æ—¶è¿”å›è¯„ä¼°æŸå¤±çš„å‡½æ•°ï¼Œå¦åˆ™è¿”å›æ‰€æœ‰æŒ‡æ ‡çš„æ€»å’Œã€‚

è¦ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œæ‚¨éœ€è¦åœ¨åˆå§‹åŒ–[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)æ—¶æä¾›ä¸€ä¸ª`model_init`ï¼šæˆ‘ä»¬éœ€è¦åœ¨æ¯æ¬¡æ–°è¿è¡Œæ—¶é‡æ–°åˆå§‹åŒ–æ¨¡å‹ã€‚è¿™ä¸`optimizers`å‚æ•°ä¸å…¼å®¹ï¼Œå› æ­¤æ‚¨éœ€è¦å­ç±»åŒ–[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å¹¶é‡å†™æ–¹æ³•[create_optimizer_and_scheduler()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.create_optimizer_and_scheduler)ä»¥è·å¾—è‡ªå®šä¹‰ä¼˜åŒ–å™¨/è°ƒåº¦å™¨ã€‚

#### `init_hf_repo`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3547)

```py
( )
```

åœ¨`self.args.hub_model_id`ä¸­åˆå§‹åŒ–gitå­˜å‚¨åº“ã€‚

#### `is_local_process_zero`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2822)

```py
( )
```

æ­¤è¿›ç¨‹æ˜¯å¦ä¸ºæœ¬åœ°ï¼ˆä¾‹å¦‚ï¼Œåœ¨å¤šå°æœºå™¨ä¸Šä»¥åˆ†å¸ƒå¼æ–¹å¼è¿›è¡Œè®­ç»ƒæ—¶ï¼Œå¦‚æœæ˜¯ä¸»è¦è¿›ç¨‹ï¼Œåˆ™ä¸ºä¸€å°æœºå™¨ä¸Šçš„è¿›ç¨‹ï¼‰ã€‚

#### `is_world_process_zero`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2829)

```py
( )
```

æ­¤è¿›ç¨‹æ˜¯å¦ä¸ºå…¨å±€ä¸»è¿›ç¨‹ï¼ˆåœ¨å¤šå°æœºå™¨ä¸Šä»¥åˆ†å¸ƒå¼æ–¹å¼è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåªæœ‰ä¸€ä¸ªè¿›ç¨‹ä¼šæ˜¯`True`ï¼‰ã€‚

#### `log`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2675)

```py
( logs: Dict )
```

å‚æ•°

+   `logs`ï¼ˆ`Dict[str, float]`ï¼‰â€”è¦è®°å½•çš„å€¼ã€‚

è®°å½•`logs`åœ¨è§‚å¯Ÿè®­ç»ƒçš„å„ç§å¯¹è±¡ã€‚

å­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ä»¥æ³¨å…¥è‡ªå®šä¹‰è¡Œä¸ºã€‚

#### `log_metrics`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_pt_utils.py#L905)

```py
( split metrics )
```

å‚æ•°

+   `split`ï¼ˆ`str`ï¼‰â€”æ¨¡å¼/åˆ†å‰²åç§°ï¼š`train`ã€`eval`ã€`test`ä¹‹ä¸€

+   `metrics`ï¼ˆ`Dict[str, float]`ï¼‰â€”æ¥è‡ªtrain/evaluate/predictmetricsçš„æŒ‡æ ‡ï¼šæŒ‡æ ‡å­—å…¸

ä»¥ç‰¹æ®Šæ ¼å¼è®°å½•æŒ‡æ ‡

åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ï¼Œè¿™ä»…é’ˆå¯¹æ’åä¸º0çš„è¿›ç¨‹æ‰§è¡Œã€‚

å…³äºå†…å­˜æŠ¥å‘Šçš„æ³¨æ„äº‹é¡¹ï¼š

ä¸ºäº†è·å¾—å†…å­˜ä½¿ç”¨æŠ¥å‘Šï¼Œæ‚¨éœ€è¦å®‰è£…`psutil`ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`pip install psutil`æ¥å®‰è£…ã€‚

ç°åœ¨å½“è¿è¡Œæ­¤æ–¹æ³•æ—¶ï¼Œæ‚¨å°†çœ‹åˆ°ä¸€ä¸ªåŒ…å«çš„æŠ¥å‘Šï¼šï¼š

```py
init_mem_cpu_alloc_delta   =     1301MB
init_mem_cpu_peaked_delta  =      154MB
init_mem_gpu_alloc_delta   =      230MB
init_mem_gpu_peaked_delta  =        0MB
train_mem_cpu_alloc_delta  =     1345MB
train_mem_cpu_peaked_delta =        0MB
train_mem_gpu_alloc_delta  =      693MB
train_mem_gpu_peaked_delta =        7MB
```

**ç†è§£æŠ¥å‘Šï¼š**

+   ä¾‹å¦‚ï¼Œç¬¬ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚`train__`ï¼Œå‘Šè¯‰æ‚¨æŒ‡æ ‡æ‰€å±çš„é˜¶æ®µã€‚ä»¥`init_`å¼€å¤´çš„æŠ¥å‘Šå°†æ·»åŠ åˆ°è¿è¡Œçš„ç¬¬ä¸€ä¸ªé˜¶æ®µã€‚å› æ­¤ï¼Œå¦‚æœåªè¿è¡Œè¯„ä¼°ï¼Œåˆ™å°†æŠ¥å‘Š`__init__`çš„å†…å­˜ä½¿ç”¨æƒ…å†µä»¥åŠ`eval_`æŒ‡æ ‡ã€‚

+   ç¬¬ä¸‰éƒ¨åˆ†ï¼Œæ˜¯`cpu`æˆ–`gpu`ï¼Œå‘Šè¯‰æ‚¨å®ƒæ˜¯é€šç”¨RAMè¿˜æ˜¯gpu0å†…å­˜æŒ‡æ ‡ã€‚

+   `*_alloc_delta` - æ˜¯é˜¶æ®µç»“æŸå’Œå¼€å§‹æ—¶ä½¿ç”¨/åˆ†é…å†…å­˜è®¡æ•°å™¨ä¹‹é—´çš„å·®å¼‚ - å¦‚æœå‡½æ•°é‡Šæ”¾çš„å†…å­˜å¤šäºåˆ†é…çš„å†…å­˜ï¼Œåˆ™å¯èƒ½ä¸ºè´Ÿæ•°ã€‚

+   `*_peaked_delta` - æ˜¯ä»»ä½•é¢å¤–æ¶ˆè€—ç„¶åé‡Šæ”¾çš„å†…å­˜ - ç›¸å¯¹äºå½“å‰åˆ†é…çš„å†…å­˜è®¡æ•°å™¨ - å®ƒæ°¸è¿œä¸ä¼šæ˜¯è´Ÿæ•°ã€‚å½“æ‚¨æŸ¥çœ‹ä»»ä½•é˜¶æ®µçš„æŒ‡æ ‡æ—¶ï¼Œæ‚¨å°†`alloc_delta` + `peaked_delta`ç›¸åŠ ï¼Œå°±çŸ¥é“å®Œæˆè¯¥é˜¶æ®µéœ€è¦å¤šå°‘å†…å­˜ã€‚

ä»…å¯¹rank 0å’Œgpu 0çš„è¿›ç¨‹è¿›è¡ŒæŠ¥å‘Šï¼ˆå¦‚æœæœ‰gpuï¼‰ã€‚é€šå¸¸è¿™å·²ç»è¶³å¤Ÿäº†ï¼Œå› ä¸ºä¸»è¿›ç¨‹å®Œæˆå¤§éƒ¨åˆ†å·¥ä½œï¼Œä½†å¦‚æœä½¿ç”¨æ¨¡å‹å¹¶è¡Œï¼Œæƒ…å†µå¯èƒ½ä¸å¤ªä¸€æ ·ï¼Œå…¶ä»–GPUå¯èƒ½ä½¿ç”¨ä¸åŒæ•°é‡çš„gpuå†…å­˜ã€‚åœ¨DataParallelä¸‹ä¹Ÿä¸åŒï¼Œå› ä¸ºgpu0å¯èƒ½éœ€è¦æ¯”å…¶ä»–GPUæ›´å¤šçš„å†…å­˜ï¼Œå› ä¸ºå®ƒå­˜å‚¨äº†æ‰€æœ‰å‚ä¸GPUçš„æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚ä¹Ÿè®¸åœ¨æœªæ¥ï¼Œè¿™äº›æŠ¥å‘Šå°†å‘å±•åˆ°æµ‹é‡è¿™äº›å†…å®¹ã€‚

CPU RAMæŒ‡æ ‡æµ‹é‡RSSï¼ˆResident Set Sizeï¼‰ï¼ŒåŒ…æ‹¬è¿›ç¨‹ç‹¬æœ‰çš„å†…å­˜å’Œä¸å…¶ä»–è¿›ç¨‹å…±äº«çš„å†…å­˜ã€‚é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œå®ƒä¸åŒ…æ‹¬è¢«äº¤æ¢å‡ºçš„å†…å­˜ï¼Œå› æ­¤æŠ¥å‘Šå¯èƒ½ä¸å¤Ÿç²¾ç¡®ã€‚

CPUå³°å€¼å†…å­˜æ˜¯ä½¿ç”¨é‡‡æ ·çº¿ç¨‹æµ‹é‡çš„ã€‚ç”±äºpythonçš„GILï¼Œå¦‚æœè¯¥çº¿ç¨‹åœ¨ä½¿ç”¨æœ€é«˜å†…å­˜æ—¶æ²¡æœ‰è¿è¡Œçš„æœºä¼šï¼Œå®ƒå¯èƒ½ä¼šé”™è¿‡ä¸€äº›å³°å€¼å†…å­˜ã€‚å› æ­¤ï¼Œè¿™ä»½æŠ¥å‘Šå¯èƒ½å°äºå®é™…æƒ…å†µã€‚ä½¿ç”¨`tracemalloc`å°†æŠ¥å‘Šå‡†ç¡®çš„å³°å€¼å†…å­˜ï¼Œä½†å®ƒä¸ä¼šæŠ¥å‘Špythonä¹‹å¤–çš„å†…å­˜åˆ†é…ã€‚å› æ­¤ï¼Œå¦‚æœæŸä¸ªC++ CUDAæ‰©å±•åˆ†é…äº†è‡ªå·±çš„å†…å­˜ï¼Œå®ƒå°†ä¸ä¼šè¢«æŠ¥å‘Šã€‚å› æ­¤ï¼Œå®ƒè¢«æ”¾å¼ƒï¼Œä»¥æ”¯æŒå†…å­˜é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è¯»å–å½“å‰è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µã€‚

GPUåˆ†é…å’Œå³°å€¼å†…å­˜æŠ¥å‘Šæ˜¯é€šè¿‡`torch.cuda.memory_allocated()`å’Œ`torch.cuda.max_memory_allocated()`å®Œæˆçš„ã€‚è¿™ä¸ªæŒ‡æ ‡ä»…æŠ¥å‘Špytorchç‰¹å®šåˆ†é…çš„â€œå¢é‡â€ï¼Œå› ä¸º`torch.cuda`å†…å­˜ç®¡ç†ç³»ç»Ÿä¸è·Ÿè¸ªpytorchä¹‹å¤–åˆ†é…çš„ä»»ä½•å†…å­˜ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªcudaè°ƒç”¨é€šå¸¸åŠ è½½CUDAå†…æ ¸ï¼Œå¯èƒ½å ç”¨0.5åˆ°2GBçš„GPUå†…å­˜ã€‚

è¯·æ³¨æ„ï¼Œæ­¤è·Ÿè¸ªå™¨ä¸è€ƒè™‘[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)çš„`__init__`ã€`train`ã€`evaluate`å’Œ`predict`è°ƒç”¨ä¹‹å¤–çš„å†…å­˜åˆ†é…ã€‚

å› ä¸º`evaluation`è°ƒç”¨å¯èƒ½å‘ç”Ÿåœ¨`train`æœŸé—´ï¼Œæˆ‘ä»¬æ— æ³•å¤„ç†åµŒå¥—è°ƒç”¨ï¼Œå› ä¸º`torch.cuda.max_memory_allocated`æ˜¯ä¸€ä¸ªè®¡æ•°å™¨ï¼Œæ‰€ä»¥å¦‚æœå®ƒè¢«åµŒå¥—çš„evalè°ƒç”¨é‡ç½®ï¼Œ`train`çš„è·Ÿè¸ªå™¨å°†æŠ¥å‘Šä¸æ­£ç¡®çš„ä¿¡æ¯ã€‚å¦‚æœè¿™ä¸ª[pytorché—®é¢˜](https://github.com/pytorch/pytorch/issues/16266)å¾—åˆ°è§£å†³ï¼Œå°†æœ‰å¯èƒ½å°†è¿™ä¸ªç±»æ”¹ä¸ºå¯é‡å…¥ã€‚åœ¨é‚£ä¹‹å‰ï¼Œæˆ‘ä»¬åªä¼šè·Ÿè¸ª`train`ã€`evaluate`å’Œ`predict`æ–¹æ³•çš„å¤–å±‚çº§åˆ«ã€‚è¿™æ„å‘³ç€å¦‚æœåœ¨`train`æœŸé—´è°ƒç”¨`eval`ï¼Œåè€…å°†è®°å½•å…¶å†…å­˜ä½¿ç”¨æƒ…å†µä»¥åŠå‰è€…çš„å†…å­˜ä½¿ç”¨æƒ…å†µã€‚

è¿™ä¹Ÿæ„å‘³ç€å¦‚æœåœ¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)è°ƒç”¨æœŸé—´ä½¿ç”¨ä»»ä½•å…¶ä»–å·¥å…·`torch.cuda.reset_peak_memory_stats`ï¼Œåˆ™gpuå³°å€¼å†…å­˜ç»Ÿè®¡æ•°æ®å¯èƒ½æ— æ•ˆã€‚è€Œä¸”[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å°†ç ´åä»»ä½•ä¾èµ–äºè‡ªå·±è°ƒç”¨`torch.cuda.reset_peak_memory_stats`çš„å·¥å…·çš„æ­£å¸¸è¡Œä¸ºã€‚

ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œæ‚¨å¯èƒ½å¸Œæœ›åœ¨ç”Ÿäº§è¿è¡Œä¸­å…³é—­å†…å­˜åˆ†æã€‚

#### `metrics_format`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_pt_utils.py#L879)

```py
( metrics: Dict ) â†’ export const metadata = 'undefined';metrics (Dict[str, float])
```

å‚æ•°

+   `metrics` (`Dict[str, float]`) â€” è®­ç»ƒ/è¯„ä¼°/é¢„æµ‹è¿”å›çš„æŒ‡æ ‡

è¿”å›

metrics (`Dict[str, float]`)

é‡æ ¼å¼åŒ–çš„æŒ‡æ ‡

å°†TraineræŒ‡æ ‡å€¼é‡æ–°æ ¼å¼åŒ–ä¸ºäººç±»å¯è¯»çš„æ ¼å¼

#### `num_examples`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L1128)

```py
( dataloader: DataLoader )
```

é€šè¿‡è®¿é—®å…¶æ•°æ®é›†æ¥è·å–`~torch.utils.data.DataLoader`ä¸­æ ·æœ¬æ•°çš„å¸®åŠ©ç¨‹åºã€‚å½“æ•°æ®åŠ è½½å™¨æ•°æ®é›†ä¸å­˜åœ¨æˆ–æ²¡æœ‰é•¿åº¦æ—¶ï¼Œå°½å¯èƒ½ä¼°è®¡

#### `num_tokens`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L1142)

```py
( train_dl: DataLoader max_steps: Optional = None )
```

é€šè¿‡æšä¸¾æ•°æ®åŠ è½½å™¨æ¥è·å–`~torch.utils.data.DataLoader`ä¸­çš„æ ‡è®°æ•°çš„å¸®åŠ©ç¨‹åºã€‚

#### `pop_callback`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L665)

```py
( callback ) â†’ export const metadata = 'undefined';TrainerCallback
```

å‚æ•°

+   `callback`ï¼ˆ`type`æˆ–[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)ï¼‰- [TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)ç±»æˆ–[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)çš„å®ä¾‹ã€‚åœ¨ç¬¬ä¸€ç§æƒ…å†µä¸‹ï¼Œå°†å¼¹å‡ºåœ¨å›è°ƒåˆ—è¡¨ä¸­æ‰¾åˆ°çš„è¯¥ç±»çš„ç¬¬ä¸€ä¸ªæˆå‘˜ã€‚

è¿”å›

[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)

å¦‚æœæ‰¾åˆ°ï¼Œå°†åˆ é™¤å›è°ƒã€‚

ä»å½“å‰çš„[TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)åˆ—è¡¨ä¸­åˆ é™¤å›è°ƒå¹¶è¿”å›å®ƒã€‚

å¦‚æœæœªæ‰¾åˆ°å›è°ƒï¼Œåˆ™è¿”å›`None`ï¼ˆä¸ä¼šå¼•å‘é”™è¯¯ï¼‰ã€‚

#### `predict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3129)

```py
( test_dataset: Dataset ignore_keys: Optional = None metric_key_prefix: str = 'test' )
```

å‚æ•°

+   `test_dataset`ï¼ˆ`Dataset`ï¼‰- è¦åœ¨å…¶ä¸Šè¿è¡Œé¢„æµ‹çš„æ•°æ®é›†ã€‚å¦‚æœå®ƒæ˜¯`datasets.Dataset`ï¼Œåˆ™ä¸è¢«`model.forward()`æ–¹æ³•æ¥å—çš„åˆ—å°†è‡ªåŠ¨åˆ é™¤ã€‚å¿…é¡»å®ç°æ–¹æ³•`__len__`

+   `ignore_keys`ï¼ˆ`List[str]`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹è¾“å‡ºä¸­åº”å¿½ç•¥çš„é”®åˆ—è¡¨ï¼ˆå¦‚æœå®ƒæ˜¯å­—å…¸ï¼‰ã€‚

+   `metric_key_prefix`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"test"`ï¼‰- ç”¨ä½œæŒ‡æ ‡é”®å‰ç¼€çš„å¯é€‰å‰ç¼€ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå‰ç¼€æ˜¯`"test"`ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™æŒ‡æ ‡â€œbleuâ€å°†è¢«å‘½åä¸ºâ€œtest_bleuâ€ã€‚

è¿è¡Œé¢„æµ‹å¹¶è¿”å›é¢„æµ‹å’Œæ½œåœ¨æŒ‡æ ‡ã€‚

æ ¹æ®æ•°æ®é›†å’Œç”¨ä¾‹ï¼Œæ‚¨çš„æµ‹è¯•æ•°æ®é›†å¯èƒ½åŒ…å«æ ‡ç­¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ­¤æ–¹æ³•è¿˜å°†è¿”å›æŒ‡æ ‡ï¼Œå°±åƒåœ¨`evaluate()`ä¸­ä¸€æ ·ã€‚

å¦‚æœæ‚¨çš„é¢„æµ‹æˆ–æ ‡ç­¾å…·æœ‰ä¸åŒçš„åºåˆ—é•¿åº¦ï¼ˆä¾‹å¦‚ï¼Œå› ä¸ºæ‚¨åœ¨æ ‡è®°åˆ†ç±»ä»»åŠ¡ä¸­è¿›è¡ŒåŠ¨æ€å¡«å……ï¼‰ï¼Œåˆ™é¢„æµ‹å°†è¢«å¡«å……ï¼ˆåœ¨å³ä¾§ï¼‰ï¼Œä»¥å…è®¸è¿æ¥åˆ°ä¸€ä¸ªæ•°ç»„ä¸­ã€‚å¡«å……ç´¢å¼•ä¸º-100ã€‚

è¿”å›ï¼š*NamedTuple* å…·æœ‰ä»¥ä¸‹é”®çš„å‘½åå…ƒç»„ï¼š

+   é¢„æµ‹ï¼ˆ`np.ndarray`ï¼‰ï¼šåœ¨`test_dataset`ä¸Šçš„é¢„æµ‹ã€‚

+   label_idsï¼ˆ`np.ndarray`ï¼Œ*å¯é€‰*ï¼‰ï¼šæ ‡ç­¾ï¼ˆå¦‚æœæ•°æ®é›†åŒ…å«ï¼‰ã€‚

+   æŒ‡æ ‡ï¼ˆ`Dict[str, float]`ï¼Œ*å¯é€‰*ï¼‰ï¼šæ½œåœ¨çš„æŒ‡æ ‡å­—å…¸ï¼ˆå¦‚æœæ•°æ®é›†åŒ…å«æ ‡ç­¾ï¼‰ã€‚

#### `prediction_loop`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3766)

```py
( dataloader: DataLoader description: str prediction_loss_only: Optional = None ignore_keys: Optional = None metric_key_prefix: str = 'eval' )
```

é¢„æµ‹/è¯„ä¼°å¾ªç¯ï¼Œç”±`Trainer.evaluate()`å’Œ`Trainer.predict()`å…±äº«ã€‚

æ— è®ºæ˜¯å¦æœ‰æ ‡ç­¾ï¼Œéƒ½å¯ä»¥ä½¿ç”¨ã€‚

#### `prediction_step`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3424)

```py
( model: Module inputs: Dict prediction_loss_only: bool ignore_keys: Optional = None ) â†’ export const metadata = 'undefined';Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]
```

å‚æ•°

+   `model`ï¼ˆ`nn.Module`ï¼‰- è¦è¯„ä¼°çš„æ¨¡å‹ã€‚

+   `inputs`ï¼ˆ`Dict[str, Union[torch.Tensor, Any]]`ï¼‰- æ¨¡å‹çš„è¾“å…¥å’Œç›®æ ‡ã€‚

    åœ¨é¦ˆé€æ¨¡å‹ä¹‹å‰ï¼Œå­—å…¸å°†è¢«è§£åŒ…ã€‚å¤§å¤šæ•°æ¨¡å‹å¸Œæœ›ç›®æ ‡åœ¨å‚æ•°`labels`ä¸‹ã€‚æ£€æŸ¥æ‚¨æ¨¡å‹çš„æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æ¥å—çš„å‚æ•°ã€‚

+   `prediction_loss_only`ï¼ˆ`bool`ï¼‰- æ˜¯å¦ä»…è¿”å›æŸå¤±ã€‚

+   `ignore_keys`ï¼ˆ`List[str]`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹è¾“å‡ºä¸­åº”å¿½ç•¥çš„é”®åˆ—è¡¨ï¼ˆå¦‚æœå®ƒæ˜¯å­—å…¸ï¼‰ã€‚

è¿”å›

Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]

ä¸€ä¸ªåŒ…å«æŸå¤±ã€logits å’Œæ ‡ç­¾çš„å…ƒç»„ï¼ˆæ¯ä¸ªéƒ½æ˜¯å¯é€‰çš„ï¼‰ã€‚

ä½¿ç”¨ `inputs` åœ¨ `model` ä¸Šæ‰§è¡Œè¯„ä¼°æ­¥éª¤ã€‚

å­ç±»å’Œè¦†ç›–ä»¥æ³¨å…¥è‡ªå®šä¹‰è¡Œä¸ºã€‚

#### `propagate_args_to_deepspeed`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L4012)

```py
( auto_find_batch_size = False )
```

æ ¹æ® Trainer å‚æ•°åœ¨ deepspeed æ’ä»¶ä¸­è®¾ç½®å€¼

#### `push_to_hub`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L3702)

```py
( commit_message: Optional = 'End of training' blocking: bool = True **kwargs )
```

å‚æ•°

+   `commit_message` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"End of training"`) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚

+   `blocking` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” å‡½æ•°æ˜¯å¦åº”è¯¥åœ¨ `git push` å®Œæˆåæ‰è¿”å›ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ [create_model_card()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.create_model_card) çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°† `self.model` å’Œ `self.tokenizer` ä¸Šä¼ åˆ° ğŸ¤— æ¨¡å‹ä¸­å¿ƒï¼Œå­˜å‚¨åº“ä¸º `self.args.hub_model_id`ã€‚

#### `remove_callback`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L681)

```py
( callback )
```

å‚æ•°

+   `å›è°ƒ` (`ç±»å‹` æˆ– [TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback)) â€” ä¸€ä¸ª [TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback) ç±»æˆ–ä¸€ä¸ª [TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback) çš„å®ä¾‹ã€‚åœ¨ç¬¬ä¸€ç§æƒ…å†µä¸‹ï¼Œå°†åˆ é™¤åœ¨å›è°ƒåˆ—è¡¨ä¸­æ‰¾åˆ°çš„è¯¥ç±»çš„ç¬¬ä¸€ä¸ªæˆå‘˜ã€‚

ä»å½“å‰çš„ [TrainerCallback](/docs/transformers/v4.37.2/en/main_classes/callback#transformers.TrainerCallback) åˆ—è¡¨ä¸­åˆ é™¤ä¸€ä¸ªå›è°ƒã€‚

#### `save_metrics`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_pt_utils.py#L995)

```py
( split metrics combined = True )
```

å‚æ•°

+   `split` (`str`) â€” æ¨¡å¼/æ‹†åˆ†åç§°ï¼š`train`, `eval`, `test`, `all` ä¸­çš„ä¸€ä¸ª

+   `metrics` (`Dict[str, float]`) â€” ä»è®­ç»ƒ/è¯„ä¼°/é¢„æµ‹è¿”å›çš„æŒ‡æ ‡

+   `combined` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” é€šè¿‡æ›´æ–° `all_results.json` åˆ›å»ºç»„åˆæŒ‡æ ‡ï¼Œå…¶ä¸­åŒ…æ‹¬æ­¤è°ƒç”¨çš„æŒ‡æ ‡ã€‚

å°†æŒ‡æ ‡ä¿å­˜åˆ°ä¸€ä¸ª json æ–‡ä»¶ä¸­ï¼Œä¾‹å¦‚ `train_results.json`ã€‚

åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ï¼Œè¿™ä»…é€‚ç”¨äºç§©ä¸º0çš„è¿›ç¨‹ã€‚

è¦äº†è§£æŒ‡æ ‡ï¼Œè¯·é˜…è¯» [log_metrics()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.log_metrics) çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯åŸå§‹æœªæ ¼å¼åŒ–çš„æ•°å­—ä¿å­˜åœ¨å½“å‰æ–¹æ³•ä¸­ã€‚

#### `save_model`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2841)

```py
( output_dir: Optional = None _internal_call: bool = False )
```

å°†ä¿å­˜æ¨¡å‹ï¼Œå› æ­¤æ‚¨å¯ä»¥ä½¿ç”¨ `from_pretrained()` é‡æ–°åŠ è½½å®ƒã€‚

ä»…ä»ä¸»è¿›ç¨‹ä¿å­˜ã€‚

#### `save_state`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_pt_utils.py#L1033)

```py
( )
```

ä¿å­˜ Trainer çŠ¶æ€ï¼Œå› ä¸º Trainer.save_model ä»…ä¿å­˜äº†æ¨¡å‹çš„ tokenizer

åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ï¼Œè¿™ä»…é€‚ç”¨äºç§©ä¸º0çš„è¿›ç¨‹ã€‚

#### `train`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L1438)

```py
( resume_from_checkpoint: Union = None trial: Union = None ignore_keys_for_eval: Optional = None **kwargs )
```

å‚æ•°

+   `resume_from_checkpoint` (`str` æˆ– `bool`, *å¯é€‰*) â€” å¦‚æœæ˜¯ `str`ï¼Œåˆ™æ˜¯ç”±ä¹‹å‰çš„ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) å®ä¾‹ä¿å­˜çš„æœ¬åœ°è·¯å¾„çš„æ£€æŸ¥ç‚¹ã€‚å¦‚æœæ˜¯ `bool` å¹¶ä¸”ç­‰äº `True`ï¼Œåˆ™åŠ è½½ç”±ä¹‹å‰çš„ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) å®ä¾‹ä¿å­˜åœ¨ *args.output_dir* ä¸­çš„æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚å¦‚æœå­˜åœ¨ï¼Œè®­ç»ƒå°†ä»æ­¤å¤„åŠ è½½çš„æ¨¡å‹/ä¼˜åŒ–å™¨/è°ƒåº¦å™¨çŠ¶æ€æ¢å¤ã€‚

+   `trial` (`optuna.Trial` æˆ– `Dict[str, Any]`, *å¯é€‰*) â€” è¿è¡Œè¯•éªŒæˆ–ç”¨äºè¶…å‚æ•°æœç´¢çš„è¶…å‚æ•°å­—å…¸ã€‚

+   `ignore_keys_for_eval` (`List[str]`, *å¯é€‰*) â€” æ‚¨çš„æ¨¡å‹è¾“å‡ºä¸­åº”åœ¨è¯„ä¼°æœŸé—´å¿½ç•¥çš„é”®çš„åˆ—è¡¨ï¼ˆå¦‚æœå®ƒæ˜¯ä¸€ä¸ªå­—å…¸ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ç”¨äºéšè—å·²å¼ƒç”¨å‚æ•°çš„é™„åŠ å…³é”®å­—å‚æ•°

ä¸»è¦è®­ç»ƒå…¥å£ã€‚

#### `training_step`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer.py#L2746)

```py
( model: Module inputs: Dict ) â†’ export const metadata = 'undefined';torch.Tensor
```

å‚æ•°

+   `model` (`nn.Module`) â€” è¦è®­ç»ƒçš„æ¨¡å‹ã€‚

+   `inputs` (`Dict[str, Union[torch.Tensor, Any]]`) â€” æ¨¡å‹çš„è¾“å…¥å’Œç›®æ ‡ã€‚

    å­—å…¸å°†åœ¨é¦ˆé€åˆ°æ¨¡å‹ä¹‹å‰è§£åŒ…ã€‚å¤§å¤šæ•°æ¨¡å‹æœŸæœ›ç›®æ ‡åœ¨å‚æ•°`labels`ä¸‹ã€‚æ£€æŸ¥æ‚¨æ¨¡å‹çš„æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æ¥å—çš„å‚æ•°ã€‚

è¿”å›

`torch.Tensor`

è¿™æ‰¹æ¬¡çš„è®­ç»ƒæŸå¤±çš„å¼ é‡ã€‚

å¯¹ä¸€æ‰¹è¾“å…¥æ‰§è¡Œè®­ç»ƒæ­¥éª¤ã€‚

å­ç±»å’Œè¦†ç›–ä»¥æ³¨å…¥è‡ªå®šä¹‰è¡Œä¸ºã€‚

## Seq2SeqTrainer

### `class transformers.Seq2SeqTrainer`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_seq2seq.py#L41)

```py
( model: Union = None args: TrainingArguments = None data_collator: Optional = None train_dataset: Optional = None eval_dataset: Union = None tokenizer: Optional = None model_init: Optional = None compute_metrics: Optional = None callbacks: Optional = None optimizers: Tuple = (None, None) preprocess_logits_for_metrics: Optional = None )
```

#### `evaluate`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_seq2seq.py#L112)

```py
( eval_dataset: Optional = None ignore_keys: Optional = None metric_key_prefix: str = 'eval' **gen_kwargs )
```

å‚æ•°

+   `eval_dataset` (`Dataset`, *å¯é€‰*) â€” å¦‚æœè¦è¦†ç›–`self.eval_dataset`ï¼Œè¯·ä¼ é€’ä¸€ä¸ªæ•°æ®é›†ã€‚å¦‚æœå®ƒæ˜¯ä¸€ä¸ª[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œåˆ™ä¸è¢«`model.forward()`æ–¹æ³•æ¥å—çš„åˆ—å°†è‡ªåŠ¨åˆ é™¤ã€‚å®ƒå¿…é¡»å®ç°`__len__`æ–¹æ³•ã€‚

+   `ignore_keys` (`List[str]`, *å¯é€‰*) â€” æ‚¨çš„æ¨¡å‹è¾“å‡ºä¸­åº”åœ¨æ”¶é›†é¢„æµ‹æ—¶å¿½ç•¥çš„é”®çš„åˆ—è¡¨ã€‚

+   `metric_key_prefix` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"eval"`) â€” ç”¨ä½œæŒ‡æ ‡é”®å‰ç¼€çš„å¯é€‰å‰ç¼€ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå‰ç¼€æ˜¯`"eval"`ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™æŒ‡æ ‡â€œbleuâ€å°†è¢«å‘½åä¸ºâ€œeval_bleuâ€ã€‚

+   `max_length` (`int`, *å¯é€‰*) â€” åœ¨ä½¿ç”¨`generate`æ–¹æ³•è¿›è¡Œé¢„æµ‹æ—¶ä½¿ç”¨çš„æœ€å¤§ç›®æ ‡é•¿åº¦ã€‚

+   `num_beams` (`int`, *å¯é€‰*) â€” åœ¨ä½¿ç”¨`generate`æ–¹æ³•è¿›è¡Œé¢„æµ‹æ—¶å°†ç”¨äºæŸæœç´¢çš„æŸæ•°ã€‚1è¡¨ç¤ºæ²¡æœ‰æŸæœç´¢ã€‚gen_kwargs â€” é™„åŠ çš„`generate`ç‰¹å®škwargsã€‚

è¿è¡Œè¯„ä¼°å¹¶è¿”å›æŒ‡æ ‡ã€‚

è°ƒç”¨è„šæœ¬å°†è´Ÿè´£æä¾›è®¡ç®—æŒ‡æ ‡çš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ä»»åŠ¡ç›¸å…³çš„ï¼ˆå°†å…¶ä¼ é€’ç»™init `compute_metrics`å‚æ•°ï¼‰ã€‚

æ‚¨è¿˜å¯ä»¥å­ç±»åŒ–å¹¶è¦†ç›–æ­¤æ–¹æ³•ä»¥æ³¨å…¥è‡ªå®šä¹‰è¡Œä¸ºã€‚

#### `predict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/trainer_seq2seq.py#L168)

```py
( test_dataset: Dataset ignore_keys: Optional = None metric_key_prefix: str = 'test' **gen_kwargs )
```

å‚æ•°

+   `test_dataset` (`Dataset`) â€” è¦åœ¨å…¶ä¸Šè¿è¡Œé¢„æµ‹çš„æ•°æ®é›†ã€‚å¦‚æœå®ƒæ˜¯ä¸€ä¸ª[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)ï¼Œåˆ™ä¸è¢«`model.forward()`æ–¹æ³•æ¥å—çš„åˆ—å°†è‡ªåŠ¨åˆ é™¤ã€‚å¿…é¡»å®ç°`__len__`æ–¹æ³•

+   `ignore_keys` (`List[str]`, *å¯é€‰*) â€” æ‚¨çš„æ¨¡å‹è¾“å‡ºä¸­åº”åœ¨æ”¶é›†é¢„æµ‹æ—¶å¿½ç•¥çš„é”®çš„åˆ—è¡¨ã€‚

+   `metric_key_prefix` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"eval"`) â€” ç”¨ä½œæŒ‡æ ‡é”®å‰ç¼€çš„å¯é€‰å‰ç¼€ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå‰ç¼€æ˜¯`"eval"`ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™æŒ‡æ ‡â€œbleuâ€å°†è¢«å‘½åä¸ºâ€œeval_bleuâ€ã€‚

+   `max_length` (`int`, *å¯é€‰*) â€” åœ¨ä½¿ç”¨`generate`æ–¹æ³•è¿›è¡Œé¢„æµ‹æ—¶ä½¿ç”¨çš„æœ€å¤§ç›®æ ‡é•¿åº¦ã€‚

+   `num_beams` (`int`, *å¯é€‰*) â€” åœ¨ä½¿ç”¨`generate`æ–¹æ³•è¿›è¡Œé¢„æµ‹æ—¶å°†ç”¨äºæŸæœç´¢çš„æŸæ•°ã€‚1è¡¨ç¤ºæ²¡æœ‰æŸæœç´¢ã€‚gen_kwargs â€” é™„åŠ çš„`generate`ç‰¹å®škwargsã€‚

è¿è¡Œé¢„æµ‹å¹¶è¿”å›é¢„æµ‹å’Œæ½œåœ¨æŒ‡æ ‡ã€‚

æ ¹æ®æ•°æ®é›†å’Œæ‚¨çš„ç”¨ä¾‹ï¼Œæ‚¨çš„æµ‹è¯•æ•°æ®é›†å¯èƒ½åŒ…å«æ ‡ç­¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ­¤æ–¹æ³•è¿˜å°†è¿”å›æŒ‡æ ‡ï¼Œå°±åƒåœ¨`evaluate()`ä¸­ä¸€æ ·ã€‚

å¦‚æœæ‚¨çš„é¢„æµ‹æˆ–æ ‡ç­¾å…·æœ‰ä¸åŒçš„åºåˆ—é•¿åº¦ï¼ˆä¾‹å¦‚ï¼Œå› ä¸ºæ‚¨åœ¨æ ‡è®°åˆ†ç±»ä»»åŠ¡ä¸­è¿›è¡ŒåŠ¨æ€å¡«å……ï¼‰ï¼Œåˆ™é¢„æµ‹å°†è¢«å¡«å……ï¼ˆåœ¨å³ä¾§ï¼‰ä»¥å…è®¸è¿æ¥æˆä¸€ä¸ªæ•°ç»„ã€‚å¡«å……ç´¢å¼•ä¸º -100ã€‚

è¿”å›: *NamedTuple* å…·æœ‰ä»¥ä¸‹é”®çš„å‘½åå…ƒç»„:

+   predictions (`np.ndarray`): åœ¨ `test_dataset` ä¸Šçš„é¢„æµ‹ã€‚

+   label_ids (`np.ndarray`, *optional*): æ ‡ç­¾ï¼ˆå¦‚æœæ•°æ®é›†åŒ…å«æ ‡ç­¾ï¼‰ã€‚

+   metrics (`Dict[str, float]`, *optional*): æ½œåœ¨çš„æŒ‡æ ‡å­—å…¸ï¼ˆå¦‚æœæ•°æ®é›†åŒ…å«æ ‡ç­¾ï¼‰ã€‚

## TrainingArguments

### `class transformers.TrainingArguments`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L161)

```py
( output_dir: str overwrite_output_dir: bool = False do_train: bool = False do_eval: bool = False do_predict: bool = False evaluation_strategy: Union = 'no' prediction_loss_only: bool = False per_device_train_batch_size: int = 8 per_device_eval_batch_size: int = 8 per_gpu_train_batch_size: Optional = None per_gpu_eval_batch_size: Optional = None gradient_accumulation_steps: int = 1 eval_accumulation_steps: Optional = None eval_delay: Optional = 0 learning_rate: float = 5e-05 weight_decay: float = 0.0 adam_beta1: float = 0.9 adam_beta2: float = 0.999 adam_epsilon: float = 1e-08 max_grad_norm: float = 1.0 num_train_epochs: float = 3.0 max_steps: int = -1 lr_scheduler_type: Union = 'linear' lr_scheduler_kwargs: Optional = <factory> warmup_ratio: float = 0.0 warmup_steps: int = 0 log_level: Optional = 'passive' log_level_replica: Optional = 'warning' log_on_each_node: bool = True logging_dir: Optional = None logging_strategy: Union = 'steps' logging_first_step: bool = False logging_steps: float = 500 logging_nan_inf_filter: bool = True save_strategy: Union = 'steps' save_steps: float = 500 save_total_limit: Optional = None save_safetensors: Optional = True save_on_each_node: bool = False save_only_model: bool = False no_cuda: bool = False use_cpu: bool = False use_mps_device: bool = False seed: int = 42 data_seed: Optional = None jit_mode_eval: bool = False use_ipex: bool = False bf16: bool = False fp16: bool = False fp16_opt_level: str = 'O1' half_precision_backend: str = 'auto' bf16_full_eval: bool = False fp16_full_eval: bool = False tf32: Optional = None local_rank: int = -1 ddp_backend: Optional = None tpu_num_cores: Optional = None tpu_metrics_debug: bool = False debug: Union = '' dataloader_drop_last: bool = False eval_steps: Optional = None dataloader_num_workers: int = 0 past_index: int = -1 run_name: Optional = None disable_tqdm: Optional = None remove_unused_columns: Optional = True label_names: Optional = None load_best_model_at_end: Optional = False metric_for_best_model: Optional = None greater_is_better: Optional = None ignore_data_skip: bool = False fsdp: Union = '' fsdp_min_num_params: int = 0 fsdp_config: Optional = None fsdp_transformer_layer_cls_to_wrap: Optional = None deepspeed: Optional = None label_smoothing_factor: float = 0.0 optim: Union = 'adamw_torch' optim_args: Optional = None adafactor: bool = False group_by_length: bool = False length_column_name: Optional = 'length' report_to: Optional = None ddp_find_unused_parameters: Optional = None ddp_bucket_cap_mb: Optional = None ddp_broadcast_buffers: Optional = None dataloader_pin_memory: bool = True dataloader_persistent_workers: bool = False skip_memory_metrics: bool = True use_legacy_prediction_loop: bool = False push_to_hub: bool = False resume_from_checkpoint: Optional = None hub_model_id: Optional = None hub_strategy: Union = 'every_save' hub_token: Optional = None hub_private_repo: bool = False hub_always_push: bool = False gradient_checkpointing: bool = False gradient_checkpointing_kwargs: Optional = None include_inputs_for_metrics: bool = False fp16_backend: str = 'auto' push_to_hub_model_id: Optional = None push_to_hub_organization: Optional = None push_to_hub_token: Optional = None mp_parameters: str = '' auto_find_batch_size: bool = False full_determinism: bool = False torchdynamo: Optional = None ray_scope: Optional = 'last' ddp_timeout: Optional = 1800 torch_compile: bool = False torch_compile_backend: Optional = None torch_compile_mode: Optional = None dispatch_batches: Optional = None split_batches: Optional = False include_tokens_per_second: Optional = False include_num_input_tokens_seen: Optional = False neftune_noise_alpha: float = None )
```

å‚æ•°

+   `output_dir` (`str`) â€” æ¨¡å‹é¢„æµ‹å’Œæ£€æŸ¥ç‚¹å°†è¢«å†™å…¥çš„è¾“å‡ºç›®å½•ã€‚

+   `overwrite_output_dir` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `True`ï¼Œåˆ™è¦†ç›–è¾“å‡ºç›®å½•çš„å†…å®¹ã€‚ä½¿ç”¨æ­¤é€‰é¡¹ç»§ç»­è®­ç»ƒï¼Œå¦‚æœ `output_dir` æŒ‡å‘æ£€æŸ¥ç‚¹ç›®å½•ã€‚

+   `do_train` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿è¡Œè®­ç»ƒã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯ç”¨äºæ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ã€‚æŸ¥çœ‹ [ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples) è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `do_eval` (`bool`, *optional*) â€” æ˜¯å¦åœ¨éªŒè¯é›†ä¸Šè¿è¡Œè¯„ä¼°ã€‚å¦‚æœ `evaluation_strategy` ä¸ `"no"` ä¸åŒï¼Œåˆ™å°†è®¾ç½®ä¸º `True`ã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯ç”¨äºæ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ã€‚æŸ¥çœ‹ [ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples) è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `do_predict` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œé¢„æµ‹ã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯ç”¨äºæ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ã€‚æŸ¥çœ‹ [ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples) è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `evaluation_strategy` (`str` æˆ– [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy), *optional*, é»˜è®¤ä¸º `"no"`) â€” è®­ç»ƒæœŸé—´é‡‡ç”¨çš„è¯„ä¼°ç­–ç•¥ã€‚å¯èƒ½çš„å€¼ä¸º:

    +   `"no"`: è®­ç»ƒæœŸé—´ä¸è¿›è¡Œè¯„ä¼°ã€‚

    +   `"steps"`: æ¯ `eval_steps` æ¬¡è¿›è¡Œè¯„ä¼°ï¼ˆå¹¶è®°å½•æ—¥å¿—ï¼‰ã€‚

    +   `"epoch"`: æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶è¿›è¡Œè¯„ä¼°ã€‚

+   `prediction_loss_only` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” åœ¨è¿›è¡Œè¯„ä¼°å’Œç”Ÿæˆé¢„æµ‹æ—¶ï¼Œä»…è¿”å›æŸå¤±ã€‚

+   `per_device_train_batch_size` (`int`, *optional*, é»˜è®¤ä¸º 8) â€” ç”¨äºè®­ç»ƒçš„æ¯ä¸ª GPU/XPU/TPU/MPS/NPU æ ¸å¿ƒ/CPU çš„æ‰¹å¤„ç†å¤§å°ã€‚

+   `per_device_eval_batch_size` (`int`, *optional*, é»˜è®¤ä¸º 8) â€” ç”¨äºè¯„ä¼°çš„æ¯ä¸ª GPU/XPU/TPU/MPS/NPU æ ¸å¿ƒ/CPU çš„æ‰¹å¤„ç†å¤§å°ã€‚

+   `gradient_accumulation_steps` (`int`, *optional*, é»˜è®¤ä¸º 1) â€” ç´¯ç§¯æ¢¯åº¦çš„æ›´æ–°æ­¥æ•°ï¼Œç„¶åæ‰§è¡Œåå‘/æ›´æ–°ä¼ é€’ã€‚

    ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ—¶ï¼Œä¸€ä¸ªæ­¥éª¤è¢«è®¡ä¸ºä¸€ä¸ªå¸¦æœ‰åå‘ä¼ é€’çš„æ­¥éª¤ã€‚å› æ­¤ï¼Œæ¯ `gradient_accumulation_steps * xxx_step` è®­ç»ƒç¤ºä¾‹å°†è¿›è¡Œæ—¥å¿—è®°å½•ã€è¯„ä¼°å’Œä¿å­˜ã€‚

+   `eval_accumulation_steps` (`int`, *optional*) â€” åœ¨å°†ç»“æœç§»åŠ¨åˆ° CPU ä¹‹å‰ï¼Œç´¯ç§¯è¾“å‡ºå¼ é‡çš„é¢„æµ‹æ­¥æ•°ã€‚å¦‚æœæœªè®¾ç½®ï¼Œæ•´ä¸ªé¢„æµ‹å°†åœ¨ GPU/NPU/TPU ä¸Šç´¯ç§¯åå†ç§»åŠ¨åˆ° CPUï¼ˆé€Ÿåº¦æ›´å¿«ä½†éœ€è¦æ›´å¤šå†…å­˜ï¼‰ã€‚

+   `eval_delay` (`float`, *optional*) â€” åœ¨è¿›è¡Œç¬¬ä¸€æ¬¡è¯„ä¼°ä¹‹å‰ç­‰å¾…çš„æ—¶æœŸæˆ–æ­¥æ•°ï¼Œå–å†³äº `evaluation_strategy`ã€‚

+   `learning_rate` (`float`, *optional*, defaults to 5e-5) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ã€‚

+   `weight_decay` (`float`, *optional*, defaults to 0) â€” åº”ç”¨çš„æƒé‡è¡°å‡ï¼ˆå¦‚æœä¸ä¸ºé›¶ï¼‰åˆ° [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨ä¸­çš„æ‰€æœ‰å±‚ï¼Œé™¤äº†æ‰€æœ‰åç½®å’Œ LayerNorm æƒé‡ã€‚

+   `adam_beta1` (`float`, *optional*, defaults to 0.9) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„ beta1 è¶…å‚æ•°ã€‚

+   `adam_beta2` (`float`, *optional*, defaults to 0.999) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„ beta2 è¶…å‚æ•°ã€‚

+   `adam_epsilon` (`float`, *optional*, defaults to 1e-8) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„ epsilon è¶…å‚æ•°ã€‚

+   `max_grad_norm` (`float`, *optional*, defaults to 1.0) â€” æœ€å¤§æ¢¯åº¦èŒƒæ•°ï¼ˆç”¨äºæ¢¯åº¦è£å‰ªï¼‰ã€‚

+   `num_train_epochs(float,` *optional*, defaults to 3.0) â€” æ‰§è¡Œçš„æ€»è®­ç»ƒæ—¶ä»£æ•°ï¼ˆå¦‚æœä¸æ˜¯æ•´æ•°ï¼Œåˆ™åœ¨åœæ­¢è®­ç»ƒä¹‹å‰æ‰§è¡Œæœ€åä¸€ä¸ªæ—¶ä»£çš„å°æ•°éƒ¨åˆ†ç™¾åˆ†æ¯”ï¼‰ã€‚

+   `max_steps` (`int`, *optional*, defaults to -1) â€” å¦‚æœè®¾ç½®ä¸ºæ­£æ•°ï¼Œåˆ™æ‰§è¡Œçš„æ€»è®­ç»ƒæ­¥æ•°ã€‚è¦†ç›– `num_train_epochs`ã€‚å¯¹äºæœ‰é™çš„æ•°æ®é›†ï¼Œè®­ç»ƒé€šè¿‡æ•°æ®é›†ï¼ˆå¦‚æœæ‰€æœ‰æ•°æ®éƒ½ç”¨å®Œï¼‰é‡å¤è¿›è¡Œï¼Œç›´åˆ°è¾¾åˆ° `max_steps`ã€‚

+   `lr_scheduler_type` (`str` or [SchedulerType](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.SchedulerType), *optional*, defaults to `"linear"`) â€” è¦ä½¿ç”¨çš„è°ƒåº¦å™¨ç±»å‹ã€‚æŸ¥çœ‹ [SchedulerType](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.SchedulerType) çš„æ–‡æ¡£ä»¥è·å–æ‰€æœ‰å¯èƒ½çš„å€¼ã€‚

+   `lr_scheduler_kwargs` (â€˜dictâ€™, *optional*, defaults to {}) â€” lr_scheduler çš„é¢å¤–å‚æ•°ã€‚æŸ¥çœ‹æ¯ä¸ªè°ƒåº¦å™¨çš„æ–‡æ¡£ä»¥è·å–å¯èƒ½çš„å€¼ã€‚

+   `warmup_ratio` (`float`, *optional*, defaults to 0.0) â€” ç”¨äºä» 0 çº¿æ€§é¢„çƒ­åˆ° `learning_rate` çš„æ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡ã€‚

+   `warmup_steps` (`int`, *optional*, defaults to 0) â€” ç”¨äºä» 0 çº¿æ€§é¢„çƒ­åˆ° `learning_rate` çš„æ­¥éª¤æ•°ã€‚è¦†ç›– `warmup_ratio` çš„ä»»ä½•æ•ˆæœã€‚

+   `log_level` (`str`, *optional*, defaults to `passive`) â€” ä¸»è¿›ç¨‹ä½¿ç”¨çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ã€‚å¯èƒ½çš„é€‰æ‹©æ˜¯å­—ç¬¦ä¸²å½¢å¼çš„æ—¥å¿—çº§åˆ«ï¼š'debug'ã€'info'ã€'warning'ã€'error'å’Œ'critical'ï¼Œä»¥åŠä¸€ä¸ª'passive'çº§åˆ«ï¼Œå®ƒä¸è®¾ç½®ä»»ä½•å†…å®¹ï¼Œå¹¶ä¿æŒTransformersåº“çš„å½“å‰æ—¥å¿—çº§åˆ«ï¼ˆé»˜è®¤ä¸º`"warning"`ï¼‰ã€‚

+   `log_level_replica` (`str`, *optional*, defaults to `"warning"`) â€” å‰¯æœ¬ä½¿ç”¨çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ã€‚ä¸ `log_level` ç›¸åŒçš„é€‰æ‹©ã€‚

+   `log_on_each_node` (`bool`, *optional*, defaults to `True`) â€” åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ˜¯å¦æ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨ `log_level` è¿›è¡Œæ—¥å¿—è®°å½•ï¼Œè¿˜æ˜¯ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿›è¡Œã€‚

+   `logging_dir` (`str`, *optional*) â€” [TensorBoard](https://www.tensorflow.org/tensorboard) æ—¥å¿—ç›®å½•ã€‚é»˜è®¤ä¸º *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***ã€‚

+   `logging_strategy` (`str` or [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy), *optional*, defaults to `"steps"`) â€” è®­ç»ƒæœŸé—´é‡‡ç”¨çš„æ—¥å¿—è®°å½•ç­–ç•¥ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š

    +   `"no"`: è®­ç»ƒæœŸé—´ä¸è¿›è¡Œæ—¥å¿—è®°å½•ã€‚

    +   `"epoch"`: æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶è¿›è¡Œæ—¥å¿—è®°å½•ã€‚

    +   `"steps"`: æ¯ `logging_steps` è¿›è¡Œæ—¥å¿—è®°å½•ã€‚

+   `logging_first_step` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦è®°å½•å’Œè¯„ä¼°ç¬¬ä¸€ä¸ª `global_step`ã€‚

+   `logging_steps` (`int` or `float`, *optional*, defaults to 500) â€” å¦‚æœ `logging_strategy="steps"`ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ—¥å¿—ä¹‹é—´çš„æ›´æ–°æ­¥éª¤æ•°ã€‚åº”ä¸ºæ•´æ•°æˆ–èŒƒå›´ä¸º `[0,1)` çš„æµ®ç‚¹æ•°ã€‚å¦‚æœå°äº 1ï¼Œå°†è¢«è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥éª¤çš„æ¯”ç‡ã€‚

+   `logging_nan_inf_filter` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¿‡æ»¤ç”¨äºè®°å½•çš„ `nan` å’Œ `inf` æŸå¤±ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™ä¼šè¿‡æ»¤æ¯ä¸ªæ­¥éª¤çš„æŸå¤±ï¼Œå¦‚æœä¸º `nan` æˆ– `inf`ï¼Œåˆ™å–å½“å‰æ—¥å¿—çª—å£çš„å¹³å‡æŸå¤±ã€‚ 

    `logging_nan_inf_filter` ä»…å½±å“æŸå¤±å€¼çš„è®°å½•ï¼Œä¸ä¼šæ”¹å˜æ¢¯åº¦çš„è®¡ç®—æˆ–åº”ç”¨äºæ¨¡å‹çš„è¡Œä¸ºã€‚

+   `save_strategy` (`str` or [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy), *optional*, defaults to `"steps"`) â€” è®­ç»ƒæœŸé—´é‡‡ç”¨çš„æ£€æŸ¥ç‚¹ä¿å­˜ç­–ç•¥ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š

    +   `"no"`: è®­ç»ƒæœŸé—´ä¸è¿›è¡Œä¿å­˜ã€‚

    +   `"epoch"`: åœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶ä¿å­˜ã€‚

    +   `"steps"`: æ¯ `save_steps` ä¿å­˜ä¸€æ¬¡ã€‚

+   `save_steps` (`int` or `float`, *optional*, defaults to 500) â€” å¦‚æœ `save_strategy="steps"`ï¼Œåœ¨ä¸¤æ¬¡æ£€æŸ¥ç‚¹ä¿å­˜ä¹‹å‰çš„æ›´æ–°æ­¥éª¤æ•°ã€‚åº”ä¸ºæ•´æ•°æˆ–èŒƒå›´ä¸º `[0,1)` çš„æµ®ç‚¹æ•°ã€‚å¦‚æœå°äº 1ï¼Œå°†è¢«è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥éª¤çš„æ¯”ç‡ã€‚

+   `save_total_limit` (`int`, *optional*) â€” å¦‚æœä¼ é€’äº†ä¸€ä¸ªå€¼ï¼Œå°†é™åˆ¶æ£€æŸ¥ç‚¹çš„æ€»é‡ã€‚åˆ é™¤ `output_dir` ä¸­çš„æ—§æ£€æŸ¥ç‚¹ã€‚å½“å¯ç”¨ `load_best_model_at_end` æ—¶ï¼Œæ ¹æ® `metric_for_best_model` çš„â€œæœ€ä½³â€æ£€æŸ¥ç‚¹å°†å§‹ç»ˆä¿ç•™åœ¨æœ€è¿‘çš„æ£€æŸ¥ç‚¹ä¹‹å¤–ã€‚ä¾‹å¦‚ï¼Œå¯¹äº `save_total_limit=5` å’Œ `load_best_model_at_end`ï¼Œæœ€åå››ä¸ªæ£€æŸ¥ç‚¹å°†å§‹ç»ˆä¸æœ€ä½³æ¨¡å‹ä¸€èµ·ä¿ç•™ã€‚å½“ `save_total_limit=1` å’Œ `load_best_model_at_end` æ—¶ï¼Œå¯èƒ½ä¿å­˜ä¸¤ä¸ªæ£€æŸ¥ç‚¹ï¼šæœ€åä¸€ä¸ªå’Œæœ€ä½³ä¸€ä¸ªï¼ˆå¦‚æœå®ƒä»¬ä¸åŒï¼‰ã€‚

+   `save_safetensors` (`bool`, *optional*, defaults to `True`) â€” ä½¿ç”¨ [safetensors](https://huggingface.co/docs/safetensors) ä¿å­˜å’ŒåŠ è½½çŠ¶æ€å­—å…¸ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„ `torch.load` å’Œ `torch.save`ã€‚

+   `save_on_each_node` (`bool`, *optional*, defaults to `False`) â€” åœ¨è¿›è¡Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹å’Œæ£€æŸ¥ç‚¹ï¼Œè¿˜æ˜¯åªåœ¨ä¸»èŠ‚ç‚¹ä¸Šä¿å­˜ã€‚

    å½“ä¸åŒèŠ‚ç‚¹ä½¿ç”¨ç›¸åŒå­˜å‚¨æ—¶ï¼Œä¸åº”æ¿€æ´»æ­¤é€‰é¡¹ï¼Œå› ä¸ºæ–‡ä»¶å°†ä»¥ç›¸åŒåç§°ä¿å­˜åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šã€‚

+   `save_only_model` (`bool`, *optional*, defaults to `False`) â€” åœ¨è¿›è¡Œæ£€æŸ¥ç‚¹æ—¶ï¼Œæ˜¯å¦ä»…ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯åŒæ—¶ä¿å­˜ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨å’Œ rng çŠ¶æ€ã€‚è¯·æ³¨æ„ï¼Œå½“æ­¤é€‰é¡¹ä¸º true æ—¶ï¼Œæ‚¨å°†æ— æ³•ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è¿™æ ·å¯ä»¥é€šè¿‡ä¸å­˜å‚¨ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨å’Œ rng çŠ¶æ€æ¥èŠ‚çœå­˜å‚¨ç©ºé—´ã€‚æ‚¨åªèƒ½ä½¿ç”¨ `from_pretrained` åŠ è½½æ¨¡å‹ï¼Œå¹¶å°†æ­¤é€‰é¡¹è®¾ç½®ä¸º `True`ã€‚

+   `use_cpu` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨ cpuã€‚å¦‚æœè®¾ç½®ä¸º Falseï¼Œå°†ä½¿ç”¨ cuda æˆ– mps è®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

+   `seed` (`int`, *optional*, defaults to 42) â€” åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾ç½®çš„éšæœºç§å­ã€‚ä¸ºäº†ç¡®ä¿å¤šæ¬¡è¿è¡Œçš„å¯é‡ç°æ€§ï¼Œè¯·ä½¿ç”¨ `~Trainer.model_init` å‡½æ•°æ¥å®ä¾‹åŒ–æ¨¡å‹ï¼Œå¦‚æœæ¨¡å‹å…·æœ‰ä¸€äº›éšæœºåˆå§‹åŒ–çš„å‚æ•°ã€‚

+   `data_seed` (`int`, *optional*) â€” ç”¨äºæ•°æ®é‡‡æ ·å™¨çš„éšæœºç§å­ã€‚å¦‚æœæœªè®¾ç½®ï¼Œç”¨äºæ•°æ®é‡‡æ ·çš„éšæœºç”Ÿæˆå™¨å°†ä½¿ç”¨ä¸ `seed` ç›¸åŒçš„ç§å­ã€‚è¿™å¯ç”¨äºç¡®ä¿æ•°æ®é‡‡æ ·çš„å¯é‡ç°æ€§ï¼Œç‹¬ç«‹äºæ¨¡å‹ç§å­ã€‚

+   `jit_mode_eval` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨ PyTorch jit trace è¿›è¡Œæ¨æ–­ã€‚

+   `use_ipex` (`bool`, *optional*, defaults to `False`) â€” åœ¨å¯ç”¨æ—¶ä½¿ç”¨ PyTorch çš„ Intel æ‰©å±•ã€‚[IPEX å®‰è£…](https://github.com/intel/intel-extension-for-pytorch)ã€‚

+   `bf16` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨bf16 16ä½ï¼ˆæ··åˆï¼‰ç²¾åº¦è®­ç»ƒï¼Œè€Œä¸æ˜¯32ä½è®­ç»ƒã€‚éœ€è¦å®‰åŸ¹æˆ–æ›´é«˜çš„NVIDIAæ¶æ„ï¼Œæˆ–è€…ä½¿ç”¨CPUï¼ˆuse_cpuï¼‰æˆ–Ascend NPUã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§APIï¼Œå¯èƒ½ä¼šæ›´æ”¹ã€‚

+   `fp16` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨fp16 16ä½ï¼ˆæ··åˆï¼‰ç²¾åº¦è®­ç»ƒï¼Œè€Œä¸æ˜¯32ä½è®­ç»ƒã€‚

+   `fp16_opt_level` (`str`, *optional*, defaults to â€˜O1â€™) â€” å¯¹äº`fp16`è®­ç»ƒï¼Œé€‰æ‹©åœ¨[â€˜O0â€™, â€˜O1â€™, â€˜O2â€™, å’Œ â€˜O3â€™]ä¸­çš„Apex AMPä¼˜åŒ–çº§åˆ«ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[Apexæ–‡æ¡£](https://nvidia.github.io/apex/amp)ã€‚

+   `fp16_backend` (`str`, *optional*, defaults to `"auto"`) â€” æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚è¯·æ”¹ç”¨`half_precision_backend`ã€‚

+   `half_precision_backend` (`str`, *optional*, defaults to `"auto"`) â€” ç”¨äºæ··åˆç²¾åº¦è®­ç»ƒçš„åç«¯ã€‚å¿…é¡»æ˜¯`"auto", "apex", "cpu_amp"`ä¹‹ä¸€ã€‚`"auto"`å°†æ ¹æ®æ£€æµ‹åˆ°çš„PyTorchç‰ˆæœ¬ä½¿ç”¨CPU/CUDA AMPæˆ–APEXï¼Œè€Œå…¶ä»–é€‰æ‹©å°†å¼ºåˆ¶ä½¿ç”¨è¯·æ±‚çš„åç«¯ã€‚

+   `bf16_full_eval` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„bfloat16è¯„ä¼°ï¼Œè€Œä¸æ˜¯32ä½ã€‚è¿™å°†æ›´å¿«ï¼ŒèŠ‚çœå†…å­˜ï¼Œä½†å¯èƒ½ä¼šæŸå®³æŒ‡æ ‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§APIï¼Œå¯èƒ½ä¼šæ›´æ”¹ã€‚

+   `fp16_full_eval` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„float16è¯„ä¼°ï¼Œè€Œä¸æ˜¯32ä½ã€‚è¿™å°†æ›´å¿«ï¼ŒèŠ‚çœå†…å­˜ï¼Œä½†å¯èƒ½ä¼šæŸå®³æŒ‡æ ‡å€¼ã€‚

+   `tf32` (`bool`, *optional*) â€” æ˜¯å¦å¯ç”¨TF32æ¨¡å¼ï¼Œé€‚ç”¨äºå®‰åŸ¹å’Œæ›´æ–°çš„GPUæ¶æ„ã€‚é»˜è®¤å€¼å–å†³äºPyTorchç‰ˆæœ¬çš„`torch.backends.cuda.matmul.allow_tf32`é»˜è®¤å€¼ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[TF32](https://huggingface.co/docs/transformers/performance#tf32)æ–‡æ¡£ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§APIï¼Œå¯èƒ½ä¼šæ›´æ”¹ã€‚

+   `local_rank` (`int`, *optional*, defaults to -1`) â€” åˆ†å¸ƒå¼è®­ç»ƒè¿‡ç¨‹ä¸­è¿›ç¨‹çš„æ’åã€‚

+   `ddp_backend` (`str`, *optional*) â€” ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒçš„åç«¯ã€‚å¿…é¡»æ˜¯`"nccl"`, `"mpi"`, `"ccl"`, `"gloo"`, `"hccl"`ä¹‹ä¸€ã€‚

+   `tpu_num_cores` (`int`, *optional*) â€” åœ¨TPUä¸Šè®­ç»ƒæ—¶ï¼ŒTPUæ ¸å¿ƒçš„æ•°é‡ï¼ˆç”±å¯åŠ¨è„šæœ¬è‡ªåŠ¨ä¼ é€’ï¼‰ã€‚

+   `dataloader_drop_last` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡ï¼ˆå¦‚æœæ•°æ®é›†çš„é•¿åº¦ä¸æ˜¯æ‰¹æ¬¡å¤§å°çš„æ•´æ•°å€ï¼‰ã€‚

+   `eval_steps` (`int` or `float`, *optional*) â€” å¦‚æœ`evaluation_strategy="steps"`ï¼Œåˆ™ä¸¤æ¬¡è¯„ä¼°ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºä¸`logging_steps`ç›¸åŒçš„å€¼ã€‚åº”ä¸ºèŒƒå›´ä¸º`[0,1)`çš„æ•´æ•°æˆ–æµ®ç‚¹æ•°ã€‚å¦‚æœå°äº1ï¼Œåˆ™å°†è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡ã€‚

+   `dataloader_num_workers` (`int`, *optional*, defaults to 0) â€” ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°ï¼ˆä»…é€‚ç”¨äºPyTorchï¼‰ã€‚0è¡¨ç¤ºæ•°æ®å°†åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½ã€‚

+   `past_index` (`int`, *optional*, defaults to -1`) â€” ä¸€äº›æ¨¡å‹ï¼ˆå¦‚[TransformerXL](../model_doc/transformerxl)æˆ–[XLNet](../model_doc/xlnet)ï¼‰å¯ä»¥åˆ©ç”¨è¿‡å»çš„éšè—çŠ¶æ€è¿›è¡Œé¢„æµ‹ã€‚å¦‚æœå°†æ­¤å‚æ•°è®¾ç½®ä¸ºæ­£æ•´æ•°ï¼Œåˆ™`Trainer`å°†ä½¿ç”¨ç›¸åº”çš„è¾“å‡ºï¼ˆé€šå¸¸ä¸ºç´¢å¼•2ï¼‰ä½œä¸ºè¿‡å»çŠ¶æ€ï¼Œå¹¶åœ¨ä¸‹ä¸€ä¸ªè®­ç»ƒæ­¥éª¤ä¸­å°†å…¶ä½œä¸ºå…³é”®å­—å‚æ•°`mems`æä¾›ç»™æ¨¡å‹ã€‚

+   `run_name` (`str`, *optional*) â€” è¿è¡Œçš„æè¿°ç¬¦ã€‚é€šå¸¸ç”¨äº[wandb](https://www.wandb.com/)å’Œ[mlflow](https://www.mlflow.org/)æ—¥å¿—è®°å½•ã€‚

+   `disable_tqdm` (`bool`, *optional*) â€” æ˜¯å¦ç¦ç”¨Jupyterç¬”è®°æœ¬ä¸­ç”±`~notebook.NotebookTrainingTracker`ç”Ÿæˆçš„tqdmè¿›åº¦æ¡å’ŒæŒ‡æ ‡è¡¨ã€‚å¦‚æœæ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºwarnæˆ–æ›´ä½ï¼ˆé»˜è®¤å€¼ï¼‰ï¼Œåˆ™é»˜è®¤ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚

+   `remove_unused_columns` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è‡ªåŠ¨åˆ é™¤æ¨¡å‹å‰å‘æ–¹æ³•æœªä½¿ç”¨çš„åˆ—ã€‚

+   `label_names` (`List[str]`, *å¯é€‰*) â€” æ‚¨çš„è¾“å…¥å­—å…¸ä¸­ä¸æ ‡ç­¾å¯¹åº”çš„é”®åˆ—è¡¨ã€‚

    æœ€ç»ˆå°†é»˜è®¤ä¸ºæ¨¡å‹æ¥å—çš„å‚æ•°åç§°åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«å•è¯â€œlabelâ€ï¼Œé™¤éä½¿ç”¨çš„æ¨¡å‹æ˜¯ `XxxForQuestionAnswering` ä¹‹ä¸€ï¼Œé‚£ä¹ˆè¿˜å°†åŒ…æ‹¬ `["start_positions", "end_positions"]` é”®ã€‚

+   `load_best_model_at_end` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨è®­ç»ƒç»“æŸæ—¶åŠ è½½æ‰¾åˆ°çš„æœ€ä½³æ¨¡å‹ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œå°†å§‹ç»ˆä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [`save_total_limit`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.save_total_limit)ã€‚

    å½“è®¾ç½®ä¸º `True` æ—¶ï¼Œå‚æ•° `save_strategy` éœ€è¦ä¸ `evaluation_strategy` ç›¸åŒï¼Œå¹¶ä¸”åœ¨å…¶ä¸º â€œstepsâ€ çš„æƒ…å†µä¸‹ï¼Œ`save_steps` å¿…é¡»æ˜¯ `eval_steps` çš„æ•´æ•°å€ã€‚

+   `metric_for_best_model` (`str`, *å¯é€‰*) â€” ä¸ `load_best_model_at_end` ç»“åˆä½¿ç”¨ï¼ŒæŒ‡å®šç”¨äºæ¯”è¾ƒä¸¤ä¸ªä¸åŒæ¨¡å‹çš„æŒ‡æ ‡ã€‚å¿…é¡»æ˜¯è¯„ä¼°è¿”å›çš„æŒ‡æ ‡çš„åç§°ï¼Œå¸¦æœ‰æˆ–ä¸å¸¦æœ‰å‰ç¼€ `"eval_"`ã€‚å¦‚æœæœªæŒ‡å®šä¸” `load_best_model_at_end=True`ï¼Œå°†é»˜è®¤ä¸º `"loss"`ï¼ˆä½¿ç”¨è¯„ä¼°æŸå¤±ï¼‰ã€‚

    å¦‚æœè®¾ç½®äº†æ­¤å€¼ï¼Œ`greater_is_better` å°†é»˜è®¤ä¸º `True`ã€‚ä¸è¦å¿˜è®°ï¼Œå¦‚æœæ‚¨çš„æŒ‡æ ‡åœ¨è¾ƒä½æ—¶æ›´å¥½ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸º `False`ã€‚

+   `greater_is_better` (`bool`, *å¯é€‰*) â€” ä¸ `load_best_model_at_end` å’Œ `metric_for_best_model` ç»“åˆä½¿ç”¨ï¼ŒæŒ‡å®šæ›´å¥½çš„æ¨¡å‹æ˜¯å¦åº”å…·æœ‰æ›´å¤§çš„æŒ‡æ ‡ã€‚é»˜è®¤ä¸ºï¼š

    +   å¦‚æœ `metric_for_best_model` è®¾ç½®ä¸ºä¸æ˜¯ `"loss"` æˆ– `"eval_loss"` çš„å€¼ï¼Œåˆ™ä¸º `True`ã€‚

    +   å¦‚æœæœªè®¾ç½® `metric_for_best_model`ï¼Œæˆ–è®¾ç½®ä¸º `"loss"` æˆ– `"eval_loss"`ï¼Œåˆ™ä¸º `False`ã€‚

+   `ignore_data_skip` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” åœ¨æ¢å¤è®­ç»ƒæ—¶ï¼Œæ˜¯å¦è·³è¿‡æ‰¹æ¬¡ä»¥ä½¿æ•°æ®åŠ è½½ä¸å…ˆå‰è®­ç»ƒä¸­çš„é˜¶æ®µç›¸åŒã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œè®­ç»ƒå°†æ›´å¿«å¼€å§‹ï¼ˆå› ä¸ºè·³è¿‡æ­¥éª¤å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼‰ï¼Œä½†ä¸ä¼šäº§ç”Ÿä¸ä¸­æ–­è®­ç»ƒç›¸åŒçš„ç»“æœã€‚

+   `fsdp` (`bool`, `str` æˆ– `FSDPOption` åˆ—è¡¨, *å¯é€‰*, é»˜è®¤ä¸º `''`) â€” ä½¿ç”¨ PyTorch åˆ†å¸ƒå¼å¹¶è¡Œè®­ç»ƒï¼ˆä»…åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼‰ã€‚

    ä»¥ä¸‹æ˜¯ä¸€ç³»åˆ—é€‰é¡¹ï¼š

    +   `"full_shard"`: åˆ†ç‰‡å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚

    +   `"shard_grad_op"`: åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦ã€‚

    +   `"hybrid_shard"`: åœ¨èŠ‚ç‚¹å†…åº”ç”¨ `FULL_SHARD`ï¼Œå¹¶åœ¨èŠ‚ç‚¹ä¹‹é—´å¤åˆ¶å‚æ•°ã€‚

    +   `"hybrid_shard_zero2"`: åœ¨èŠ‚ç‚¹å†…åº”ç”¨ `SHARD_GRAD_OP`ï¼Œå¹¶åœ¨èŠ‚ç‚¹ä¹‹é—´å¤åˆ¶å‚æ•°ã€‚

    +   `"offload"`: å°†å‚æ•°å’Œæ¢¯åº¦å¸è½½åˆ° CPUï¼ˆä»…ä¸ `"full_shard"` å’Œ `"shard_grad_op"` å…¼å®¹ï¼‰ã€‚

    +   `"auto_wrap"`: ä½¿ç”¨ `default_auto_wrap_policy` è‡ªåŠ¨é€’å½’åŒ…è£…å±‚ä¸ FSDPã€‚

+   `fsdp_config` (`str` æˆ– `dict`, *å¯é€‰*) â€” ç”¨äº fsdpï¼ˆPytorch åˆ†å¸ƒå¼å¹¶è¡Œè®­ç»ƒï¼‰çš„é…ç½®ã€‚è¯¥å€¼å¯ä»¥æ˜¯ fsdp json é…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œ`fsdp_config.json`ï¼‰æˆ–å·²åŠ è½½çš„ json æ–‡ä»¶ä½œä¸º `dict`ã€‚

    é…ç½®åŠå…¶é€‰é¡¹åˆ—è¡¨ï¼š

    +   min_num_params (`int`, *å¯é€‰*, é»˜è®¤ä¸º `0`): FSDP é»˜è®¤è‡ªåŠ¨åŒ…è£…çš„å‚æ•°æœ€å°æ•°é‡ã€‚ ï¼ˆä»…åœ¨ä¼ é€’ `fsdp` å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚

    +   transformer_layer_cls_to_wrap (`List[str]`, *å¯é€‰*): è¦åŒ…è£…çš„ transformer å±‚ç±»åç§°åˆ—è¡¨ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ï¼Œ`BertLayer`ã€`GPTJBlock`ã€`T5Block` â€¦ï¼ˆä»…åœ¨ä¼ é€’ `fsdp` æ ‡å¿—æ—¶æœ‰ç”¨ï¼‰ã€‚

    +   backward_prefetch (`str`, *å¯é€‰*) FSDP çš„åå‘é¢„å–æ¨¡å¼ã€‚æ§åˆ¶ä½•æ—¶é¢„å–ä¸‹ä¸€ç»„å‚æ•°ï¼ˆä»…åœ¨ä¼ é€’ `fsdp` å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚

        ä»¥ä¸‹æ˜¯ä¸€ç³»åˆ—é€‰é¡¹ï¼š

        +   `"backward_pre"` : åœ¨å½“å‰å‚æ•°çš„æ¢¯åº¦è®¡ç®—ä¹‹å‰ï¼Œé¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚

        +   `"backward_post"` : åœ¨å½“å‰å‚æ•°çš„æ¢¯åº¦è®¡ç®—ä¹‹åï¼Œé¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚

    +   forward_prefetchï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰FSDPçš„å‰å‘é¢„å–æ¨¡å¼ï¼ˆä»…åœ¨ä¼ é€’`fsdp`å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚å¦‚æœä¸º`"True"`ï¼Œåˆ™FSDPåœ¨æ‰§è¡Œå‰å‘ä¼ é€’æ—¶æ˜ç¡®é¢„å–ä¸‹ä¸€ä¸ªå³å°†åˆ°æ¥çš„å…¨èšé›†ã€‚

    +   limit_all_gathersï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰FSDPçš„limit_all_gathersï¼ˆä»…åœ¨ä¼ é€’`fsdp`å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚å¦‚æœä¸º`"True"`ï¼ŒFSDPæ˜ç¡®åŒæ­¥CPUçº¿ç¨‹ï¼Œä»¥é˜²æ­¢å¤ªå¤šçš„in-flight all-gathersã€‚

    +   use_orig_paramsï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰å¦‚æœä¸º`"True"`ï¼Œå…è®¸åœ¨åˆå§‹åŒ–æœŸé—´ä½¿ç”¨éå‡åŒ€çš„`requires_grad`ï¼Œè¿™æ„å‘³ç€æ”¯æŒäº¤æ›¿å†»ç»“å’Œå¯è®­ç»ƒçš„å‚æ•°ã€‚åœ¨å‚æ•°é«˜æ•ˆå¾®è°ƒç­‰æƒ…å†µä¸‹å¾ˆæœ‰ç”¨ã€‚è¯·å‚è€ƒè¿™ä¸ª[åšå®¢]([https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019](https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019)

    +   sync_module_statesï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰å¦‚æœä¸º`"True"`ï¼Œæ¯ä¸ªå•ç‹¬åŒ…è£…çš„FSDPå•å…ƒå°†ä»rank 0å¹¿æ’­æ¨¡å—å‚æ•°ï¼Œä»¥ç¡®ä¿å®ƒä»¬åœ¨åˆå§‹åŒ–ååœ¨æ‰€æœ‰rankä¸­æ˜¯ç›¸åŒçš„

    +   activation_checkpointingï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ï¼šå¦‚æœä¸º`"True"`ï¼Œæ¿€æ´»æ£€æŸ¥ç‚¹æ˜¯ä¸€ç§é€šè¿‡æ¸…é™¤æŸäº›å±‚çš„æ¿€æ´»å¹¶åœ¨å‘åä¼ é€’æœŸé—´é‡æ–°è®¡ç®—å®ƒä»¬æ¥å‡å°‘å†…å­˜ä½¿ç”¨çš„æŠ€æœ¯ã€‚å®é™…ä¸Šï¼Œè¿™æ˜¯ä»¥é¢å¤–çš„è®¡ç®—æ—¶é—´æ¢å–å‡å°‘å†…å­˜ä½¿ç”¨ã€‚

    +   xlaï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ï¼šæ˜¯å¦ä½¿ç”¨PyTorch/XLAå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œè®­ç»ƒã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œå…¶APIå¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿå˜åŒ–ã€‚

    +   xla_fsdp_settingsï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰è¯¥å€¼æ˜¯ä¸€ä¸ªå­˜å‚¨XLA FSDPåŒ…è£…å‚æ•°çš„å­—å…¸ã€‚

        æœ‰å…³å®Œæ•´çš„é€‰é¡¹åˆ—è¡¨ï¼Œè¯·å‚è§[è¿™é‡Œ](https://github.com/pytorch/xla/blob/master/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py)ã€‚

    +   xla_fsdp_grad_ckptï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ï¼šå°†åœ¨æ¯ä¸ªåµŒå¥—çš„XLA FSDPåŒ…è£…å±‚ä¸Šä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€‚æ­¤è®¾ç½®ä»…åœ¨å°†xlaæ ‡å¿—è®¾ç½®ä¸ºtrueå¹¶é€šè¿‡fsdp_min_num_paramsæˆ–fsdp_transformer_layer_cls_to_wrapæŒ‡å®šè‡ªåŠ¨åŒ…è£…ç­–ç•¥æ—¶æ‰èƒ½ä½¿ç”¨ã€‚

+   `deepspeed`ï¼ˆ`str`æˆ–`dict`ï¼Œ*å¯é€‰*ï¼‰â€” ä½¿ç”¨[Deepspeed](https://github.com/microsoft/deepspeed)ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œå…¶APIå¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿå˜åŒ–ã€‚è¯¥å€¼å¯ä»¥æ˜¯DeepSpeed jsoné…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œ`ds_config.json`ï¼‰æˆ–å·²åŠ è½½çš„jsonæ–‡ä»¶ä½œä¸º`dict`â€

+   `label_smoothing_factor`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.0ï¼‰â€” è¦ä½¿ç”¨çš„æ ‡ç­¾å¹³æ»‘å› å­ã€‚é›¶è¡¨ç¤ºä¸è¿›è¡Œæ ‡ç­¾å¹³æ»‘ï¼Œå¦åˆ™åº•å±‚çš„onehotç¼–ç æ ‡ç­¾å°†ä»0å’Œ1æ›´æ”¹ä¸º`label_smoothing_factor/num_labels`å’Œ`1 - label_smoothing_factor + label_smoothing_factor/num_labels`ã€‚

+   `debug`ï¼ˆ`str`æˆ–`DebugOption`åˆ—è¡¨ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`""`ï¼‰â€” å¯ç”¨ä¸€ä¸ªæˆ–å¤šä¸ªè°ƒè¯•åŠŸèƒ½ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ã€‚

    å¯èƒ½çš„é€‰é¡¹åŒ…æ‹¬ï¼š

    +   `"underflow_overflow"`ï¼šæ£€æµ‹æ¨¡å‹è¾“å…¥/è¾“å‡ºä¸­çš„æº¢å‡ºå¹¶æŠ¥å‘Šå¯¼è‡´äº‹ä»¶çš„æœ€åå¸§

    +   `"tpu_metrics_debug"`ï¼šåœ¨TPUä¸Šæ‰“å°è°ƒè¯•æŒ‡æ ‡

    é€‰é¡¹åº”è¯¥ç”¨ç©ºæ ¼åˆ†éš”ã€‚

+   `optim`ï¼ˆ`str`æˆ–`training_args.OptimizerNames`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"adamw_torch"`ï¼‰â€” è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼šadamw_hfã€adamw_torchã€adamw_torch_fusedã€adamw_apex_fusedã€adamw_anyprecisionæˆ–adafactorã€‚

+   `optim_args`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” ä¾›AnyPrecisionAdamWæä¾›çš„å¯é€‰å‚æ•°ã€‚

+   `group_by_length`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å°†å¤§è‡´ç›¸åŒé•¿åº¦çš„æ ·æœ¬åˆ†ç»„åœ¨ä¸€èµ·ï¼ˆä»¥æœ€å°åŒ–åº”ç”¨çš„å¡«å……å¹¶æé«˜æ•ˆç‡ï¼‰ã€‚ä»…åœ¨åº”ç”¨åŠ¨æ€å¡«å……æ—¶æœ‰ç”¨ã€‚

+   `length_column_name` (`str`, *optional*, defaults to `"length"`) â€” é¢„å…ˆè®¡ç®—é•¿åº¦çš„åˆ—åã€‚å¦‚æœè¯¥åˆ—å­˜åœ¨ï¼ŒæŒ‰é•¿åº¦åˆ†ç»„å°†ä½¿ç”¨è¿™äº›å€¼è€Œä¸æ˜¯åœ¨è®­ç»ƒå¯åŠ¨æ—¶è®¡ç®—å®ƒä»¬ã€‚ä»…åœ¨ `group_by_length` ä¸º `True` ä¸”æ•°æ®é›†æ˜¯ `Dataset` çš„å®ä¾‹æ—¶æ‰ä¼šè¢«å¿½ç•¥ã€‚

+   `report_to` (`str` or `List[str]`, *optional*, defaults to `"all"`) â€” æŠ¥å‘Šç»“æœå’Œæ—¥å¿—çš„é›†æˆåˆ—è¡¨ã€‚æ”¯æŒçš„å¹³å°æœ‰ `"azure_ml"`ã€`"clearml"`ã€`"codecarbon"`ã€`"comet_ml"`ã€`"dagshub"`ã€`"dvclive"`ã€`"flyte"`ã€`"mlflow"`ã€`"neptune"`ã€`"tensorboard"` å’Œ `"wandb"`ã€‚ä½¿ç”¨ `"all"` æŠ¥å‘Šåˆ°æ‰€æœ‰å·²å®‰è£…çš„é›†æˆï¼Œä½¿ç”¨ `"none"` ä¸æŠ¥å‘Šåˆ°ä»»ä½•é›†æˆã€‚

+   `ddp_find_unused_parameters` (`bool`, *optional*) â€” åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ `DistributedDataParallel` çš„ `find_unused_parameters` æ ‡å¿—çš„å€¼ã€‚å¦‚æœä½¿ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œåˆ™é»˜è®¤ä¸º `False`ï¼Œå¦åˆ™ä¸º `True`ã€‚

+   `ddp_bucket_cap_mb` (`int`, *optional*) â€” åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ `DistributedDataParallel` çš„ `bucket_cap_mb` æ ‡å¿—çš„å€¼ã€‚

+   `ddp_broadcast_buffers` (`bool`, *optional*) â€” åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ `DistributedDataParallel` çš„ `broadcast_buffers` æ ‡å¿—çš„å€¼ã€‚å¦‚æœä½¿ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œåˆ™é»˜è®¤ä¸º `False`ï¼Œå¦åˆ™ä¸º `True`ã€‚

+   `dataloader_pin_memory` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¦åœ¨æ•°æ®åŠ è½½å™¨ä¸­å›ºå®šå†…å­˜ã€‚é»˜è®¤ä¸º `True`ã€‚

+   `dataloader_persistent_workers` (`bool`, *optional*, defaults to `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™æ•°æ®åŠ è½½å™¨åœ¨æ•°æ®é›†è¢«æ¶ˆè€—ä¸€æ¬¡åä¸ä¼šå…³é—­å·¥ä½œè¿›ç¨‹ã€‚è¿™å…è®¸ä¿æŒå·¥ä½œè¿›ç¨‹çš„æ•°æ®é›†å®ä¾‹å¤„äºæ´»åŠ¨çŠ¶æ€ã€‚å¯èƒ½ä¼šåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¼šå¢åŠ å†…å­˜ä½¿ç”¨é‡ã€‚é»˜è®¤ä¸º `False`ã€‚

+   `skip_memory_metrics` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è·³è¿‡å°†å†…å­˜åˆ†æå™¨æŠ¥å‘Šæ·»åŠ åˆ°æŒ‡æ ‡ä¸­ã€‚é»˜è®¤æƒ…å†µä¸‹ä¼šè·³è¿‡è¿™ä¸€æ­¥ï¼Œå› ä¸ºå®ƒä¼šå‡æ…¢è®­ç»ƒå’Œè¯„ä¼°é€Ÿåº¦ã€‚

+   `push_to_hub` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨æ¯æ¬¡ä¿å­˜æ¨¡å‹æ—¶å°†æ¨¡å‹æ¨é€åˆ° Hubã€‚å¦‚æœæ¿€æ´»äº†æ­¤é€‰é¡¹ï¼Œ`output_dir` å°†å¼€å§‹ä¸€ä¸ªä¸ä»“åº“åŒæ­¥çš„ git ç›®å½•ï¼ˆç”± `hub_model_id` ç¡®å®šï¼‰ï¼Œå¹¶ä¸”æ¯æ¬¡è§¦å‘ä¿å­˜æ—¶éƒ½ä¼šæ¨é€å†…å®¹ï¼ˆå–å†³äºæ‚¨çš„ `save_strategy`ï¼‰ã€‚è°ƒç”¨ [save_model()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.save_model) ä¹Ÿä¼šè§¦å‘æ¨é€ã€‚

    å¦‚æœ `output_dir` å­˜åœ¨ï¼Œåˆ™å®ƒéœ€è¦æ˜¯å°† [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) å°†è¦æ¨é€åˆ°çš„ä»“åº“çš„æœ¬åœ°å…‹éš†ã€‚

+   `resume_from_checkpoint` (`str`, *optional*) â€” æ‚¨çš„æ¨¡å‹çš„æœ‰æ•ˆæ£€æŸ¥ç‚¹æ‰€åœ¨æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚è¿™ä¸ªå‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯æ‰“ç®—ç”±æ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ä½¿ç”¨ã€‚æŸ¥çœ‹ [ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples) ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `hub_model_id` (`str`, *optional*) â€” è¦ä¸æœ¬åœ° *output_dir* ä¿æŒåŒæ­¥çš„ä»“åº“åç§°ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡å‹ IDï¼Œæ­¤æ—¶æ¨¡å‹å°†è¢«æ¨é€åˆ°æ‚¨çš„å‘½åç©ºé—´ã€‚å¦åˆ™ï¼Œå®ƒåº”è¯¥æ˜¯æ•´ä¸ªä»“åº“åç§°ï¼Œä¾‹å¦‚ `"user_name/model"`ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥æ¨é€åˆ°æ‚¨æ‰€å±çš„ç»„ç»‡ï¼Œå¦‚ `"organization_name/model"`ã€‚é»˜è®¤ä¸º `user_name/output_dir_name`ï¼Œå…¶ä¸­ *output_dir_name* æ˜¯ `output_dir` çš„åç§°ã€‚

    é»˜è®¤ä¸º `output_dir` çš„åç§°ã€‚

+   `hub_strategy` (`str` or `HubStrategy`, *optional*, defaults to `"every_save"`) â€” å®šä¹‰æ¨é€åˆ° Hub çš„èŒƒå›´å’Œæ—¶é—´ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š

    +   `"end"`: å½“è°ƒç”¨ [save_model()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.save_model) æ–¹æ³•æ—¶ï¼Œä¼šæ¨é€æ¨¡å‹ã€å…¶é…ç½®ã€åˆ†è¯å™¨ï¼ˆå¦‚æœä¼ é€’ç»™ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ä»¥åŠæ¨¡å‹å¡çš„è‰ç¨¿ã€‚

    +   `"every_save"`: æ¯æ¬¡ä¿å­˜æ¨¡å‹æ—¶ï¼Œéƒ½ä¼šæ¨é€æ¨¡å‹ã€å…¶é…ç½®ã€åˆ†è¯å™¨ï¼ˆå¦‚æœä¼ é€’ç»™ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ä»¥åŠæ¨¡å‹å¡çš„è‰ç¨¿ã€‚æ¨é€æ˜¯å¼‚æ­¥çš„ï¼Œä»¥é¿å…é˜»å¡è®­ç»ƒï¼Œå¦‚æœä¿å­˜éå¸¸é¢‘ç¹ï¼Œåˆ™åªæœ‰åœ¨ä¸Šä¸€ä¸ªæ¨é€å®Œæˆåæ‰ä¼šå°è¯•æ–°çš„æ¨é€ã€‚åœ¨è®­ç»ƒç»“æŸæ—¶ï¼Œä¼šä½¿ç”¨æœ€ç»ˆæ¨¡å‹è¿›è¡Œæœ€åä¸€æ¬¡æ¨é€ã€‚

    +   `"checkpoint"`: ç±»ä¼¼äº `"every_save"`ï¼Œä½†æœ€æ–°çš„æ£€æŸ¥ç‚¹ä¹Ÿä¼šè¢«æ¨é€åˆ°åä¸º last-checkpoint çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œä½¿æ‚¨å¯ä»¥é€šè¿‡ `trainer.train(resume_from_checkpoint="last-checkpoint")` è½»æ¾æ¢å¤è®­ç»ƒã€‚

    +   `"all_checkpoints"`: ç±»ä¼¼äº `"checkpoint"`ï¼Œä½†æ‰€æœ‰æ£€æŸ¥ç‚¹éƒ½åƒå®ƒä»¬å‡ºç°åœ¨è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ä¸€æ ·è¢«æ¨é€ï¼ˆå› æ­¤æ‚¨å°†åœ¨æœ€ç»ˆå­˜å‚¨åº“ä¸­è·å¾—ä¸€ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ï¼‰ã€‚

+   `hub_token` (`str`, *optional*) â€” ç”¨äºå°†æ¨¡å‹æ¨é€åˆ° Hub çš„ä»¤ç‰Œã€‚å°†é»˜è®¤ä½¿ç”¨é€šè¿‡ `huggingface-cli login` è·å–çš„ç¼“å­˜æ–‡ä»¶å¤¹ä¸­çš„ä»¤ç‰Œã€‚

+   `hub_private_repo` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™ Hub å­˜å‚¨åº“å°†è®¾ç½®ä¸ºç§æœ‰ã€‚

+   `hub_always_push` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” é™¤éä¸º `True`ï¼Œå¦åˆ™å½“ä¸Šä¸€ä¸ªæ¨é€æœªå®Œæˆæ—¶ï¼Œ`Trainer` å°†è·³è¿‡æ¨é€æ£€æŸ¥ç‚¹ã€‚

+   `gradient_checkpointing` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æ¥èŠ‚çœå†…å­˜ï¼Œä½†ä¼šå¯¼è‡´åå‘ä¼ æ’­é€Ÿåº¦å˜æ…¢ã€‚

+   `gradient_checkpointing_kwargs` (`dict`, *optional*, é»˜è®¤ä¸º `None`) â€” è¦ä¼ é€’ç»™ `gradient_checkpointing_enable` æ–¹æ³•çš„å…³é”®å­—å‚æ•°ã€‚

+   `include_inputs_for_metrics` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å°†è¾“å…¥ä¼ é€’ç»™ `compute_metrics` å‡½æ•°ã€‚è¿™é€‚ç”¨äºéœ€è¦è¾“å…¥ã€é¢„æµ‹å’Œå‚è€ƒå€¼è¿›è¡Œè¯„åˆ†è®¡ç®—çš„æŒ‡æ ‡ç±»ã€‚

+   `auto_find_batch_size` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦é€šè¿‡æŒ‡æ•°è¡°å‡è‡ªåŠ¨æ‰¾åˆ°é€‚åˆå†…å­˜çš„æ‰¹å¤„ç†å¤§å°ï¼Œé¿å… CUDA å†…å­˜ä¸è¶³é”™è¯¯ã€‚éœ€è¦å®‰è£… accelerate (`pip install accelerate`)ã€‚

+   `full_determinism` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `True`ï¼Œå°†è°ƒç”¨ [enable_full_determinism()](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.enable_full_determinism) è€Œä¸æ˜¯ [set_seed()](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.set_seed) ä»¥ç¡®ä¿åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­è·å¾—å¯é‡ç°çš„ç»“æœã€‚é‡è¦æç¤ºï¼šè¿™å°†å¯¹æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œå› æ­¤ä»…ç”¨äºè°ƒè¯•ç›®çš„ã€‚

+   `torchdynamo` (`str`, *optional*) â€” å¦‚æœè®¾ç½®ï¼ŒTorchDynamo çš„åç«¯ç¼–è¯‘å™¨ã€‚å¯èƒ½çš„é€‰æ‹©åŒ…æ‹¬ `"eager"`, `"aot_eager"`, `"inductor"`, `"nvfuser"`, `"aot_nvfuser"`, `"aot_cudagraphs"`, `"ofi"`, `"fx2trt"`, `"onnxrt"` å’Œ `"ipex"`ã€‚

+   `ray_scope` (`str`, *optional*, é»˜è®¤ä¸º `"last"`) â€” åœ¨ä½¿ç”¨ Ray è¿›è¡Œè¶…å‚æ•°æœç´¢æ—¶è¦ä½¿ç”¨çš„èŒƒå›´ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä½¿ç”¨ `"last"`ã€‚ç„¶åï¼ŒRay å°†ä½¿ç”¨æ‰€æœ‰è¯•éªŒçš„æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œæ¯”è¾ƒå®ƒä»¬ï¼Œå¹¶é€‰æ‹©æœ€ä½³çš„ä¸€ä¸ªã€‚ä½†æ˜¯ï¼Œä¹Ÿæœ‰å…¶ä»–é€‰é¡¹å¯ç”¨ã€‚æœ‰å…³æ›´å¤šé€‰é¡¹ï¼Œè¯·å‚é˜… [Ray æ–‡æ¡£](https://docs.ray.io/en/latest/tune/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial)ã€‚

+   `ddp_timeout` (`int`, *å¯é€‰*, é»˜è®¤ä¸º1800) â€” `torch.distributed.init_process_group`è°ƒç”¨çš„è¶…æ—¶æ—¶é—´ï¼Œç”¨äºé¿å…åœ¨åˆ†å¸ƒå¼è¿è¡Œä¸­æ‰§è¡Œç¼“æ…¢æ“ä½œæ—¶å‡ºç°GPUå¥—æ¥å­—è¶…æ—¶ã€‚è¯·å‚è€ƒ[PyTorchæ–‡æ¡£] ([https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group)) è·å–æ›´å¤šä¿¡æ¯ã€‚

+   `use_mps_device` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚å¦‚æœå¯ç”¨ï¼Œå°†ä½¿ç”¨`mps`è®¾å¤‡ï¼Œç±»ä¼¼äº`cuda`è®¾å¤‡ã€‚

+   `torch_compile` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä½¿ç”¨ PyTorch 2.0 [`torch.compile`](https://pytorch.org/get-started/pytorch-2.0/) ç¼–è¯‘æ¨¡å‹ã€‚

    è¿™å°†ä½¿ç”¨[`torch.compile` API](https://pytorch.org/docs/stable/generated/torch.compile.html?highlight=torch+compile#torch.compile)çš„æœ€ä½³é»˜è®¤å€¼ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å‚æ•°`torch_compile_backend`å’Œ`torch_compile_mode`è‡ªå®šä¹‰é»˜è®¤å€¼ï¼Œä½†æˆ‘ä»¬ä¸èƒ½ä¿è¯å®ƒä»¬ä¸­çš„ä»»ä½•ä¸€ä¸ªä¼šèµ·ä½œç”¨ï¼Œå› ä¸ºæ”¯æŒé€æ¸åœ¨PyTorchä¸­æ¨å‡ºã€‚

    è¿™ä¸ªæ ‡å¿—å’Œæ•´ä¸ªç¼–è¯‘APIæ˜¯å®éªŒæ€§çš„ï¼Œå¹¶å¯èƒ½åœ¨æœªæ¥ç‰ˆæœ¬ä¸­å‘ç”Ÿå˜åŒ–ã€‚

+   `torch_compile_backend` (`str`, *å¯é€‰*) â€” åœ¨`torch.compile`ä¸­ä½¿ç”¨çš„åç«¯ã€‚å¦‚æœè®¾ç½®ä¸ºä»»ä½•å€¼ï¼Œ`torch_compile`å°†è®¾ç½®ä¸º`True`ã€‚

    è¯·å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–å¯èƒ½çš„å€¼ï¼Œå¹¶æ³¨æ„å®ƒä»¬å¯èƒ½ä¼šéšç€PyTorchç‰ˆæœ¬çš„å˜åŒ–è€Œæ”¹å˜ã€‚

    è¿™ä¸ªæ ‡å¿—æ˜¯å®éªŒæ€§çš„ï¼Œå¹¶å¯èƒ½åœ¨æœªæ¥ç‰ˆæœ¬ä¸­å‘ç”Ÿå˜åŒ–ã€‚

+   `torch_compile_mode` (`str`, *å¯é€‰*) â€” åœ¨`torch.compile`ä¸­ä½¿ç”¨çš„æ¨¡å¼ã€‚å¦‚æœè®¾ç½®ä¸ºä»»ä½•å€¼ï¼Œ`torch_compile`å°†è®¾ç½®ä¸º`True`ã€‚

    è¯·å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–å¯èƒ½çš„å€¼ï¼Œå¹¶æ³¨æ„å®ƒä»¬å¯èƒ½ä¼šéšç€PyTorchç‰ˆæœ¬çš„å˜åŒ–è€Œæ”¹å˜ã€‚

    è¿™ä¸ªæ ‡å¿—æ˜¯å®éªŒæ€§çš„ï¼Œå¹¶å¯èƒ½åœ¨æœªæ¥ç‰ˆæœ¬ä¸­å‘ç”Ÿå˜åŒ–ã€‚

+   `split_batches` (`bool`, *å¯é€‰*) â€” æ˜¯å¦åŠ é€Ÿå™¨åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´åº”è¯¥å°†æ•°æ®åŠ è½½å™¨äº§ç”Ÿçš„æ‰¹æ¬¡åˆ†é…åˆ°è®¾å¤‡ä¸Šã€‚å¦‚æœ

    è®¾ç½®ä¸º`True`ï¼Œå®é™…ä½¿ç”¨çš„æ‰¹é‡å¤§å°å°†åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è¿›ç¨‹ä¸Šç›¸åŒï¼Œä½†å¿…é¡»æ˜¯

    å°†ä½¿ç”¨æ‚¨æ­£åœ¨ä½¿ç”¨çš„è¿›ç¨‹æ•°é‡çš„å€æ•°ï¼ˆä¾‹å¦‚GPUï¼‰è¿›è¡Œå››èˆäº”å…¥ã€‚

+   `include_tokens_per_second` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è®¡ç®—æ¯ä¸ªè®¾å¤‡æ¯ç§’çš„æ ‡è®°æ•°ä»¥è·å–è®­ç»ƒé€Ÿåº¦æŒ‡æ ‡ã€‚

    è¿™å°†åœ¨äº‹å…ˆè¿­ä»£æ•´ä¸ªè®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸€æ¬¡ï¼Œ

    å¹¶ä¸”ä¼šå‡æ…¢æ•´ä¸ªè¿‡ç¨‹ã€‚

+   `include_num_input_tokens_seen` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è·Ÿè¸ªæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°çš„è¾“å…¥æ ‡è®°æ•°ã€‚

    åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­å¯èƒ½ä¼šè¾ƒæ…¢ï¼Œå› ä¸ºå¿…é¡»è°ƒç”¨gatheræ“ä½œã€‚

+   `neftune_noise_alpha` (`Optional[float]`) â€” å¦‚æœä¸æ˜¯`None`ï¼Œè¿™å°†æ¿€æ´»NEFTuneå™ªå£°åµŒå…¥ã€‚è¿™å¯ä»¥æå¤§åœ°æé«˜æŒ‡ä»¤å¾®è°ƒçš„æ¨¡å‹æ€§èƒ½ã€‚æŸ¥çœ‹[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2310.05914)å’Œ[åŸå§‹ä»£ç ](https://github.com/neelsjain/NEFTune)ã€‚æ”¯æŒtransformers `PreTrainedModel`å’Œ`PeftModel`ã€‚

TrainingArgumentsæ˜¯æˆ‘ä»¬åœ¨ç¤ºä¾‹è„šæœ¬ä¸­ä½¿ç”¨çš„ä¸è®­ç»ƒå¾ªç¯æœ¬èº«ç›¸å…³çš„å‚æ•°çš„å­é›†ã€‚

ä½¿ç”¨[HfArgumentParser](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.HfArgumentParser)ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªç±»è½¬æ¢ä¸ºå¯ä»¥åœ¨å‘½ä»¤è¡Œä¸ŠæŒ‡å®šçš„[argparse](https://docs.python.org/3/library/argparse#module-argparse)å‚æ•°ã€‚

#### `get_process_log_level`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2028)

```py
( )
```

æ ¹æ®è¿™ä¸ªè¿›ç¨‹æ˜¯èŠ‚ç‚¹0çš„ä¸»è¿›ç¨‹ã€é0èŠ‚ç‚¹çš„ä¸»è¿›ç¨‹è¿˜æ˜¯éä¸»è¿›ç¨‹ï¼Œè¿”å›è¦ä½¿ç”¨çš„æ—¥å¿—çº§åˆ«ã€‚

å¯¹äºä¸»è¿›ç¨‹ï¼Œæ—¥å¿—çº§åˆ«é»˜è®¤ä¸ºè®¾ç½®çš„æ—¥å¿—çº§åˆ«ï¼ˆå¦‚æœæ‚¨æ²¡æœ‰åšä»»ä½•æ“ä½œï¼Œåˆ™ä¸º`logging.WARNING`ï¼‰ï¼Œé™¤éè¢«`log_level`å‚æ•°è¦†ç›–ã€‚

å¯¹äºå‰¯æœ¬è¿›ç¨‹ï¼Œé»˜è®¤çš„æ—¥å¿—çº§åˆ«ä¸º`logging.WARNING`ï¼Œé™¤éè¢«`log_level_replica`å‚æ•°è¦†ç›–ã€‚

æ ¹æ®`should_log`çš„è¿”å›å€¼æ¥é€‰æ‹©ä¸»è¿›ç¨‹å’Œå‰¯æœ¬è¿›ç¨‹çš„è®¾ç½®ã€‚

#### `get_warmup_steps`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2117)

```py
( num_training_steps: int )
```

è·å–ç”¨äºçº¿æ€§é¢„çƒ­çš„æ­¥æ•°ã€‚

#### `main_process_first`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2066)

```py
( local = True desc = 'work' )
```

å‚æ•°

+   `local` (`bool`, *optional*, defaults to `True`) â€” å¦‚æœä¸º`True`ï¼Œåˆ™é¦–å…ˆå¤„ç†æ¯ä¸ªèŠ‚ç‚¹çš„æ’åä¸º0çš„è¿›ç¨‹ï¼Œå¦‚æœä¸º`False`ï¼Œåˆ™é¦–å…ˆå¤„ç†æ’åä¸º0çš„èŠ‚ç‚¹0çš„è¿›ç¨‹ã€‚åœ¨å…·æœ‰å…±äº«æ–‡ä»¶ç³»ç»Ÿçš„å¤šèŠ‚ç‚¹ç¯å¢ƒä¸­ï¼Œæ‚¨å¾ˆå¯èƒ½ä¼šæƒ³è¦ä½¿ç”¨`local=False`ï¼Œä»¥ä¾¿åªæœ‰ç¬¬ä¸€ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹ä¼šè¿›è¡Œå¤„ç†ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ–‡ä»¶ç³»ç»Ÿä¸å…±äº«ï¼Œåˆ™æ¯ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹å°†éœ€è¦è¿›è¡Œå¤„ç†ï¼Œè¿™æ˜¯é»˜è®¤è¡Œä¸ºã€‚

+   `desc` (`str`, *optional*, defaults to `"work"`) â€” ç”¨äºè°ƒè¯•æ—¥å¿—ä¸­çš„å·¥ä½œæè¿°

ç”¨äºtorchåˆ†å¸ƒå¼ç¯å¢ƒçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œåœ¨ä¸»è¿›ç¨‹ä¸Šéœ€è¦æ‰§è¡ŒæŸäº›æ“ä½œï¼ŒåŒæ—¶é˜»å¡å‰¯æœ¬ï¼Œå®Œæˆåé‡Šæ”¾å‰¯æœ¬ã€‚

å…¶ä¸­ä¸€ç§ç”¨æ³•æ˜¯ç”¨äº`datasets`çš„`map`åŠŸèƒ½ï¼Œä¸ºäº†æœ‰æ•ˆç‡ï¼Œåº”è¯¥åœ¨ä¸»è¿›ç¨‹ä¸Šè¿è¡Œä¸€æ¬¡ï¼Œå®Œæˆåä¿å­˜ç»“æœçš„ç¼“å­˜ç‰ˆæœ¬ï¼Œç„¶åå‰¯æœ¬ä¼šè‡ªåŠ¨åŠ è½½ã€‚

#### `set_dataloader`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2629)

```py
( train_batch_size: int = 8 eval_batch_size: int = 8 drop_last: bool = False num_workers: int = 0 pin_memory: bool = True persistent_workers: bool = False auto_find_batch_size: bool = False ignore_data_skip: bool = False sampler_seed: Optional = None )
```

å‚æ•°

+   `drop_last` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡ï¼ˆå¦‚æœæ•°æ®é›†çš„é•¿åº¦ä¸å¯è¢«æ‰¹æ¬¡å¤§å°æ•´é™¤ï¼‰ã€‚

+   `num_workers` (`int`, *optional*, defaults to 0) â€” ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°é‡ï¼ˆä»…é€‚ç”¨äºPyTorchï¼‰ã€‚0è¡¨ç¤ºæ•°æ®å°†åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½ã€‚

+   `pin_memory` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¦åœ¨æ•°æ®åŠ è½½å™¨ä¸­å›ºå®šå†…å­˜ã€‚é»˜è®¤ä¸º`True`ã€‚

+   `persistent_workers` (`bool`, *optional*, defaults to `False`) â€” å¦‚æœä¸ºTrueï¼Œåˆ™æ•°æ®åŠ è½½å™¨åœ¨æ•°æ®é›†è¢«æ¶ˆè€—ä¸€æ¬¡åä¸ä¼šå…³é—­å·¥ä½œè¿›ç¨‹ã€‚è¿™å…è®¸ä¿æŒå·¥ä½œè¿›ç¨‹çš„æ•°æ®é›†å®ä¾‹ä¿æŒæ´»åŠ¨çŠ¶æ€ã€‚å¯èƒ½ä¼šåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¼šå¢åŠ å†…å­˜ä½¿ç”¨é‡ã€‚é»˜è®¤ä¸º`False`ã€‚

+   `auto_find_batch_size` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦é€šè¿‡æŒ‡æ•°è¡°å‡è‡ªåŠ¨æ‰¾åˆ°é€‚åˆå†…å­˜çš„æ‰¹æ¬¡å¤§å°ï¼Œé¿å…CUDAå†…å­˜ä¸è¶³é”™è¯¯ã€‚éœ€è¦å®‰è£…accelerateï¼ˆ`pip install accelerate`ï¼‰

+   `ignore_data_skip` (`bool`, *optional*, defaults to `False`) â€” åœ¨æ¢å¤è®­ç»ƒæ—¶ï¼Œæ˜¯å¦è·³è¿‡æ‰¹æ¬¡å’Œè½®æ¬¡ä»¥ä½¿æ•°æ®åŠ è½½å¤„äºä¸å…ˆå‰è®­ç»ƒç›¸åŒé˜¶æ®µã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œè®­ç»ƒå°†æ›´å¿«å¼€å§‹ï¼ˆå› ä¸ºè·³è¿‡æ­¥éª¤å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼‰ï¼Œä½†ä¸ä¼šäº§ç”Ÿä¸ä¸­æ–­è®­ç»ƒç›¸åŒçš„ç»“æœã€‚

+   `sampler_seed` (`int`, *optional*) â€” ç”¨äºæ•°æ®é‡‡æ ·å™¨çš„éšæœºç§å­ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™æ•°æ®é‡‡æ ·çš„éšæœºç”Ÿæˆå™¨å°†ä½¿ç”¨ä¸`self.seed`ç›¸åŒçš„ç§å­ã€‚è¿™å¯ç”¨äºç¡®ä¿æ•°æ®é‡‡æ ·çš„å¯é‡å¤æ€§ï¼Œç‹¬ç«‹äºæ¨¡å‹ç§å­ã€‚

å°†æ‰€æœ‰ä¸æ•°æ®åŠ è½½å™¨åˆ›å»ºç›¸å…³çš„å‚æ•°é‡æ–°ç»„åˆçš„æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_dataloader(train_batch_size=16, eval_batch_size=64)
>>> args.per_device_train_batch_size
16
```

#### `set_evaluate`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2238)

```py
( strategy: Union = 'no' steps: int = 500 batch_size: int = 8 accumulation_steps: Optional = None delay: Optional = None loss_only: bool = False jit_mode: bool = False )
```

å‚æ•°

+   `strategy` (`str`æˆ–[IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy), *optional*, defaults to `"no"`) â€” è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨çš„è¯„ä¼°ç­–ç•¥ã€‚å¯èƒ½çš„å€¼ä¸ºï¼š

    +   `"no"`: è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è¿›è¡Œè¯„ä¼°ã€‚

    +   `"steps"`: æ¯`steps`è¿›è¡Œè¯„ä¼°ï¼ˆå¹¶è®°å½•æ—¥å¿—ï¼‰ã€‚

    +   `"epoch"`: æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶è¿›è¡Œè¯„ä¼°ã€‚

    è®¾ç½®ä¸`"no"`ä¸åŒçš„`strategy`å°†`self.do_eval`è®¾ç½®ä¸º`True`ã€‚

+   `steps` (`int`, *optional*, é»˜è®¤ä¸º500) â€” å¦‚æœ`strategy="steps"`ï¼Œä¸¤æ¬¡è¯„ä¼°ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ã€‚

+   `batch_size` (`int` *optional*, é»˜è®¤ä¸º8) â€” ç”¨äºè¯„ä¼°çš„æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/TPUæ ¸å¿ƒ/CPU...ï¼‰çš„æ‰¹é‡å¤§å°ã€‚

+   `accumulation_steps` (`int`, *optional*) â€” åœ¨å°†ç»“æœç§»åŠ¨åˆ°CPUä¹‹å‰ï¼Œç´¯ç§¯è¾“å‡ºå¼ é‡çš„é¢„æµ‹æ­¥æ•°ã€‚å¦‚æœæœªè®¾ç½®ï¼Œæ•´ä¸ªé¢„æµ‹å°†åœ¨GPU/TPUä¸Šç´¯ç§¯åç§»è‡³CPUï¼ˆé€Ÿåº¦æ›´å¿«ä½†éœ€è¦æ›´å¤šå†…å­˜ï¼‰ã€‚

+   `delay` (`float`, *optional*) â€” ç­‰å¾…è¿›è¡Œç¬¬ä¸€æ¬¡è¯„ä¼°çš„å‘¨æœŸæ•°æˆ–æ­¥æ•°ï¼Œå–å†³äºè¯„ä¼°ç­–ç•¥ã€‚

+   `loss_only` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” ä»…å¿½ç•¥æŸå¤±ä»¥å¤–çš„æ‰€æœ‰è¾“å‡ºã€‚

+   `jit_mode` (`bool`, *optional*) â€” æ˜¯å¦ä½¿ç”¨PyTorch jitè·Ÿè¸ªè¿›è¡Œæ¨æ–­ã€‚

å°†æ‰€æœ‰ä¸è¯„ä¼°ç›¸å…³çš„å‚æ•°åˆ†ç»„çš„æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_evaluate(strategy="steps", steps=100)
>>> args.eval_steps
100
```

#### `set_logging`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2388)

```py
( strategy: Union = 'steps' steps: int = 500 report_to: Union = 'none' level: str = 'passive' first_step: bool = False nan_inf_filter: bool = False on_each_node: bool = False replica_level: str = 'passive' )
```

å‚æ•°

+   `strategy` (`str` æˆ– [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy), *optional*, é»˜è®¤ä¸º`"steps"`) â€” è®­ç»ƒæœŸé—´é‡‡ç”¨çš„æ—¥å¿—è®°å½•ç­–ç•¥ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š

    +   `"no"`: è®­ç»ƒæœŸé—´ä¸ä¿å­˜ã€‚

    +   `"epoch"`: åœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶ä¿å­˜ã€‚

    +   `"steps"`: æ¯`save_steps`ä¿å­˜ä¸€æ¬¡ã€‚

+   `steps` (`int`, *optional*, é»˜è®¤ä¸º500) â€” å¦‚æœ`strategy="steps"`ï¼Œä¸¤æ¬¡æ—¥å¿—è®°å½•ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ã€‚

+   `level` (`str`, *optional*, é»˜è®¤ä¸º`"passive"`) â€” ç”¨äºä¸»è¿›ç¨‹çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ã€‚å¯èƒ½çš„é€‰æ‹©æ˜¯å­—ç¬¦ä¸²å½¢å¼çš„æ—¥å¿—çº§åˆ«ï¼š`"debug"`ã€`"info"`ã€`"warning"`ã€`"error"`å’Œ`"critical"`ï¼Œä»¥åŠä¸€ä¸ªä¸è®¾ç½®ä»»ä½•å†…å®¹å¹¶è®©åº”ç”¨ç¨‹åºè®¾ç½®çº§åˆ«çš„`"passive"`çº§åˆ«ã€‚

+   `report_to` (`str` æˆ– `List[str]`, *optional*, é»˜è®¤ä¸º`"all"`) â€” æŠ¥å‘Šç»“æœå’Œæ—¥å¿—çš„é›†æˆåˆ—è¡¨ã€‚æ”¯æŒçš„å¹³å°æœ‰`"azure_ml"`ã€`"clearml"`ã€`"codecarbon"`ã€`"comet_ml"`ã€`"dagshub"`ã€`"dvclive"`ã€`"flyte"`ã€`"mlflow"`ã€`"neptune"`ã€`"tensorboard"`å’Œ`"wandb"`ã€‚ä½¿ç”¨`"all"`æŠ¥å‘Šæ‰€æœ‰å·²å®‰è£…çš„é›†æˆï¼Œä½¿ç”¨`"none"`ä¸æŠ¥å‘Šä»»ä½•é›†æˆã€‚

+   `first_step` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦è®°å½•å’Œè¯„ä¼°ç¬¬ä¸€ä¸ª`global_step`ã€‚

+   `nan_inf_filter` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦è¿‡æ»¤ç”¨äºæ—¥å¿—è®°å½•çš„`nan`å’Œ`inf`æŸå¤±ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿‡æ»¤æ¯ä¸ªæ­¥éª¤çš„`nan`æˆ–`inf`æŸå¤±ï¼Œå¹¶å–ä»£å½“å‰æ—¥å¿—çª—å£çš„å¹³å‡æŸå¤±ã€‚

    `nan_inf_filter`ä»…å½±å“æŸå¤±å€¼çš„æ—¥å¿—è®°å½•ï¼Œä¸ä¼šæ”¹å˜è®¡ç®—æ¢¯åº¦æˆ–å°†æ¢¯åº¦åº”ç”¨äºæ¨¡å‹çš„è¡Œä¸ºã€‚

+   `on_each_node` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ˜¯å¦æ¯ä¸ªèŠ‚ç‚¹ä»…ä½¿ç”¨`log_level`ä¸€æ¬¡è¿›è¡Œæ—¥å¿—è®°å½•ï¼Œæˆ–ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿›è¡Œæ—¥å¿—è®°å½•ã€‚

+   `replica_level` (`str`, *optional*, é»˜è®¤ä¸º`"passive"`) â€” ç”¨äºå‰¯æœ¬çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ã€‚ä¸`log_level`ç›¸åŒçš„é€‰æ‹©ã€‚

å°†æ‰€æœ‰ä¸æ—¥å¿—è®°å½•ç›¸å…³çš„å‚æ•°åˆ†ç»„çš„æ–¹æ³•ã€‚

ç¤ºä¾‹:

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_logging(strategy="steps", steps=100)
>>> args.logging_steps
100
```

#### `set_lr_scheduler`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2584)

```py
( name: Union = 'linear' num_epochs: float = 3.0 max_steps: int = -1 warmup_ratio: float = 0 warmup_steps: int = 0 )
```

å‚æ•°

+   `name` (`str` æˆ– [SchedulerType](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.SchedulerType), *optional*, é»˜è®¤ä¸º`"linear"`) â€” è¦ä½¿ç”¨çš„è°ƒåº¦ç¨‹åºç±»å‹ã€‚æŸ¥çœ‹[SchedulerType](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.SchedulerType)çš„æ–‡æ¡£ä»¥è·å–æ‰€æœ‰å¯èƒ½çš„å€¼ã€‚

+   `num_epochs(float,` *optional*, é»˜è®¤ä¸º3.0) â€” è¦æ‰§è¡Œçš„æ€»è®­ç»ƒå‘¨æœŸæ•°ï¼ˆå¦‚æœä¸æ˜¯æ•´æ•°ï¼Œåˆ™åœ¨åœæ­¢è®­ç»ƒä¹‹å‰æ‰§è¡Œæœ€åä¸€ä¸ªå‘¨æœŸçš„å°æ•°éƒ¨åˆ†ç™¾åˆ†æ¯”ï¼‰ã€‚

+   `max_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º -1) â€” å¦‚æœè®¾ç½®ä¸ºæ­£æ•°ï¼Œåˆ™æ‰§è¡Œçš„æ€»è®­ç»ƒæ­¥æ•°ã€‚è¦†ç›–`num_train_epochs`ã€‚å¯¹äºæœ‰é™çš„æ•°æ®é›†ï¼Œå¦‚æœæ‰€æœ‰æ•°æ®éƒ½ç”¨å®Œï¼Œåˆ™é€šè¿‡æ•°æ®é›†é‡å¤è®­ç»ƒï¼Œç›´åˆ°è¾¾åˆ°`max_steps`ã€‚

+   `warmup_ratio` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” ç”¨äºä»0åˆ°`learning_rate`è¿›è¡Œçº¿æ€§é¢„çƒ­çš„æ€»è®­ç»ƒæ­¥éª¤çš„æ¯”ç‡ã€‚

+   `warmup_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” ç”¨äºä»0åˆ°`learning_rate`è¿›è¡Œçº¿æ€§é¢„çƒ­çš„æ­¥éª¤æ•°ã€‚è¦†ç›–`warmup_ratio`çš„ä»»ä½•æ•ˆæœã€‚

ä¸€ä¸ªå°†æ‰€æœ‰ä¸å­¦ä¹ ç‡è°ƒåº¦å™¨åŠå…¶è¶…å‚æ•°ç›¸å…³è”çš„å‚æ•°é‡æ–°åˆ†ç»„çš„æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_lr_scheduler(name="cosine", warmup_ratio=0.05)
>>> args.warmup_ratio
0.05
```

#### `set_optimizer`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2533)

```py
( name: Union = 'adamw_torch' learning_rate: float = 5e-05 weight_decay: float = 0 beta1: float = 0.9 beta2: float = 0.999 epsilon: float = 1e-08 args: Optional = None )
```

å‚æ•°

+   `name` (`str` æˆ– `training_args.OptimizerNames`, *å¯é€‰*, é»˜è®¤ä¸º `"adamw_torch"`) â€” è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼š"adamw_hf"ã€"adamw_torch"ã€"adamw_torch_fused"ã€"adamw_apex_fused"ã€"adamw_anyprecision"æˆ–"adafactor"ã€‚

+   `learning_rate` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 5e-5) â€” åˆå§‹å­¦ä¹ ç‡ã€‚

+   `weight_decay` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” åº”ç”¨çš„æƒé‡è¡°å‡ï¼ˆå¦‚æœä¸ä¸ºé›¶ï¼‰åˆ°æ‰€æœ‰å±‚ï¼Œé™¤äº†æ‰€æœ‰åç½®å’ŒLayerNormæƒé‡ã€‚

+   `beta1` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.9) â€” Adamä¼˜åŒ–å™¨æˆ–å…¶å˜ç§çš„beta1è¶…å‚æ•°ã€‚

+   `beta2` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.999) â€” Adamä¼˜åŒ–å™¨æˆ–å…¶å˜ç§çš„beta2è¶…å‚æ•°ã€‚

+   `epsilon` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 1e-8) â€” Adamä¼˜åŒ–å™¨æˆ–å…¶å˜ç§çš„epsilonè¶…å‚æ•°ã€‚

+   `args` (`str`, *å¯é€‰*) â€” æä¾›ç»™AnyPrecisionAdamWçš„å¯é€‰å‚æ•°ï¼ˆä»…åœ¨`optim="adamw_anyprecision"`æ—¶æœ‰ç”¨ï¼‰ã€‚

ä¸€ä¸ªå°†æ‰€æœ‰ä¸ä¼˜åŒ–å™¨åŠå…¶è¶…å‚æ•°ç›¸å…³è”çš„å‚æ•°é‡æ–°åˆ†ç»„çš„æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_optimizer(name="adamw_torch", beta1=0.8)
>>> args.optim
'adamw_torch'
```

#### `set_push_to_hub`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2463)

```py
( model_id: str strategy: Union = 'every_save' token: Optional = None private_repo: bool = False always_push: bool = False )
```

å‚æ•°

+   `model_id` (`str`) â€” ä¸æœ¬åœ°*output_dir*åŒæ­¥çš„å­˜å‚¨åº“çš„åç§°ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡å‹IDï¼Œæ­¤æ—¶æ¨¡å‹å°†è¢«æ¨é€åˆ°æ‚¨çš„å‘½åç©ºé—´ã€‚å¦åˆ™ï¼Œå®ƒåº”è¯¥æ˜¯æ•´ä¸ªå­˜å‚¨åº“åç§°ï¼Œä¾‹å¦‚`"user_name/model"`ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥å°†å…¶æ¨é€åˆ°æ‚¨æ˜¯æˆå‘˜çš„ç»„ç»‡ä¸­ï¼Œä¾‹å¦‚`"organization_name/model"`ã€‚

+   `strategy` (`str` æˆ– `HubStrategy`, *å¯é€‰*, é»˜è®¤ä¸º `"every_save"`) â€” å®šä¹‰æ¨é€åˆ°Hubçš„èŒƒå›´å’Œæ—¶é—´ã€‚å¯èƒ½çš„å€¼ä¸ºï¼š

    +   `"end"`: å½“è°ƒç”¨[save_model()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.save_model)æ–¹æ³•æ—¶ï¼Œæ¨é€æ¨¡å‹ã€å…¶é…ç½®ã€åˆ†è¯å™¨ï¼ˆå¦‚æœä¼ é€’ç»™[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ä»¥åŠæ¨¡å‹å¡çš„è‰ç¨¿ã€‚

    +   `"every_save"`: æ¯æ¬¡ä¿å­˜æ¨¡å‹æ—¶ï¼Œæ¨é€æ¨¡å‹ã€å…¶é…ç½®ã€åˆ†è¯å™¨ï¼ˆå¦‚æœä¼ é€’ç»™[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ä»¥åŠæ¨¡å‹å¡çš„è‰ç¨¿ã€‚æ¨é€æ˜¯å¼‚æ­¥çš„ï¼Œä»¥é¿å…é˜»å¡è®­ç»ƒï¼Œå¦‚æœä¿å­˜éå¸¸é¢‘ç¹ï¼Œåˆ™åªæœ‰åœ¨ä¸Šä¸€ä¸ªæ¨é€å®Œæˆåæ‰ä¼šå°è¯•æ–°çš„æ¨é€ã€‚åœ¨è®­ç»ƒç»“æŸæ—¶ï¼Œä½¿ç”¨æœ€ç»ˆæ¨¡å‹è¿›è¡Œæœ€åä¸€æ¬¡æ¨é€ã€‚

    +   `"checkpoint"`: ç±»ä¼¼äº`"every_save"`ï¼Œä½†æœ€æ–°çš„æ£€æŸ¥ç‚¹ä¹Ÿè¢«æ¨é€åˆ°åä¸ºlast-checkpointçš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™æ ·æ‚¨å¯ä»¥è½»æ¾åœ°ä½¿ç”¨`trainer.train(resume_from_checkpoint="last-checkpoint")`æ¢å¤è®­ç»ƒã€‚

    +   `"all_checkpoints"`: ç±»ä¼¼äº`"checkpoint"`ï¼Œä½†æ‰€æœ‰æ£€æŸ¥ç‚¹éƒ½åƒå®ƒä»¬å‡ºç°åœ¨è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ä¸€æ ·è¢«æ¨é€ï¼ˆå› æ­¤æ‚¨å°†åœ¨æœ€ç»ˆå­˜å‚¨åº“ä¸­çš„æ¯ä¸ªæ–‡ä»¶å¤¹ä¸­è·å¾—ä¸€ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ï¼‰ã€‚

+   `token` (`str`, *å¯é€‰*) â€” ç”¨äºå°†æ¨¡å‹æ¨é€åˆ°Hubçš„ä»¤ç‰Œã€‚å°†é»˜è®¤ä½¿ç”¨é€šè¿‡`huggingface-cli login`è·å¾—çš„ç¼“å­˜æ–‡ä»¶å¤¹ä¸­çš„ä»¤ç‰Œã€‚

+   `private_repo` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸ºTrueï¼Œåˆ™Hubå­˜å‚¨åº“å°†è®¾ç½®ä¸ºç§æœ‰ã€‚

+   always_pushï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” é™¤éä¸º`True`ï¼Œå¦åˆ™å½“ä¸Šä¸€æ¬¡æ¨é€æœªå®Œæˆæ—¶ï¼Œ`Trainer`å°†è·³è¿‡æ¨é€æ£€æŸ¥ç‚¹ã€‚

å°†æ‰€æœ‰ä¸ä¸HubåŒæ­¥æ£€æŸ¥ç‚¹ç›¸å…³çš„å‚æ•°è¿›è¡Œåˆ†ç»„çš„æ–¹æ³•ã€‚

è°ƒç”¨æ­¤æ–¹æ³•å°†è®¾ç½®`self.push_to_hub`ä¸º`True`ï¼Œè¿™æ„å‘³ç€`output_dir`å°†å¼€å§‹ä¸€ä¸ªä¸å­˜å‚¨åº“åŒæ­¥çš„gitç›®å½•ï¼ˆç”±`model_id`ç¡®å®šï¼‰ï¼Œå¹¶ä¸”æ¯æ¬¡è§¦å‘ä¿å­˜æ—¶å°†æ¨é€å†…å®¹ï¼ˆå–å†³äº`self.save_strategy`ï¼‰ã€‚è°ƒç”¨[save_model()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.save_model)ä¹Ÿå°†è§¦å‘æ¨é€ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_push_to_hub("me/awesome-model")
>>> args.hub_model_id
'me/awesome-model'
```

#### `set_save`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2339)

```py
( strategy: Union = 'steps' steps: int = 500 total_limit: Optional = None on_each_node: bool = False )
```

å‚æ•°

+   strategyï¼ˆ`str`æˆ–[IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"steps"`ï¼‰â€” è®­ç»ƒæœŸé—´é‡‡ç”¨çš„æ£€æŸ¥ç‚¹ä¿å­˜ç­–ç•¥ã€‚å¯èƒ½çš„å€¼ä¸ºï¼š

    +   `"no"`ï¼šåœ¨è®­ç»ƒæœŸé—´ä¸è¿›è¡Œä¿å­˜ã€‚

    +   `"epoch"`ï¼šåœ¨æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶ä¿å­˜ã€‚

    +   `"steps"`ï¼šæ¯`save_steps`ä¿å­˜ä¸€æ¬¡ã€‚

+   `steps`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º500ï¼‰â€” å¦‚æœ`strategy="steps"`ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ£€æŸ¥ç‚¹ä¿å­˜ä¹‹å‰çš„æ›´æ–°æ­¥éª¤æ•°ã€‚

+   total_limitï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœä¼ é€’äº†ä¸€ä¸ªå€¼ï¼Œå°†é™åˆ¶æ£€æŸ¥ç‚¹çš„æ€»é‡ã€‚åˆ é™¤`output_dir`ä¸­çš„æ—§æ£€æŸ¥ç‚¹ã€‚

+   on_each_nodeï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” åœ¨è¿›è¡Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹å’Œæ£€æŸ¥ç‚¹ï¼Œè¿˜æ˜¯ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šä¿å­˜ã€‚

    å½“ä¸åŒèŠ‚ç‚¹ä½¿ç”¨ç›¸åŒå­˜å‚¨æ—¶ï¼Œä¸åº”æ¿€æ´»æ­¤é€‰é¡¹ï¼Œå› ä¸ºæ–‡ä»¶å°†ä»¥æ¯ä¸ªèŠ‚ç‚¹ç›¸åŒçš„åç§°ä¿å­˜ã€‚

å°†æ‰€æœ‰ä¸æ£€æŸ¥ç‚¹ä¿å­˜ç›¸å…³çš„å‚æ•°è¿›è¡Œåˆ†ç»„çš„æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_save(strategy="steps", steps=100)
>>> args.save_steps
100
```

#### `set_testing`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2299)

```py
( batch_size: int = 8 loss_only: bool = False jit_mode: bool = False )
```

å‚æ•°

+   batch_sizeï¼ˆ`int` *å¯é€‰*ï¼Œé»˜è®¤ä¸º8ï¼‰â€” ç”¨äºæµ‹è¯•çš„æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/TPUæ ¸å¿ƒ/CPUâ€¦ï¼‰çš„æ‰¹é‡å¤§å°ã€‚

+   loss_onlyï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” é™¤äº†æŸå¤±ä¹‹å¤–ï¼Œå¿½ç•¥æ‰€æœ‰è¾“å‡ºã€‚

+   jit_modeï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦ä½¿ç”¨PyTorch jitè·Ÿè¸ªè¿›è¡Œæ¨æ–­ã€‚

å°†æ‰€æœ‰ä¸åœ¨ä¿ç•™æ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ç›¸å…³çš„åŸºæœ¬å‚æ•°è¿›è¡Œåˆ†ç»„çš„æ–¹æ³•ã€‚

è°ƒç”¨æ­¤æ–¹æ³•å°†è‡ªåŠ¨å°†`self.do_predict`è®¾ç½®ä¸º`True`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_testing(batch_size=32)
>>> args.per_device_eval_batch_size
32
```

#### `set_training`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2163)

```py
( learning_rate: float = 5e-05 batch_size: int = 8 weight_decay: float = 0 num_epochs: float = 3 max_steps: int = -1 gradient_accumulation_steps: int = 1 seed: int = 42 gradient_checkpointing: bool = False )
```

å‚æ•°

+   learning_rateï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º5e-5ï¼‰â€” ä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ã€‚

+   batch_sizeï¼ˆ`int` *å¯é€‰*ï¼Œé»˜è®¤ä¸º8ï¼‰â€” ç”¨äºè®­ç»ƒçš„æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/TPUæ ¸å¿ƒ/CPUâ€¦ï¼‰çš„æ‰¹é‡å¤§å°ã€‚

+   weight_decayï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0ï¼‰â€” åº”ç”¨çš„æƒé‡è¡°å‡ï¼ˆå¦‚æœä¸ä¸ºé›¶ï¼‰åˆ°ä¼˜åŒ–å™¨ä¸­é™¤æ‰€æœ‰åç½®å’ŒLayerNormæƒé‡ä¹‹å¤–çš„æ‰€æœ‰å±‚ã€‚

+   num_train_epochsï¼ˆfloatï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º3.0ï¼‰â€” è¦æ‰§è¡Œçš„æ€»è®­ç»ƒæ—¶æœŸæ•°ï¼ˆå¦‚æœä¸æ˜¯æ•´æ•°ï¼Œåˆ™åœ¨åœæ­¢è®­ç»ƒä¹‹å‰æ‰§è¡Œæœ€åä¸€ä¸ªæ—¶æœŸçš„å°æ•°éƒ¨åˆ†ç™¾åˆ†æ¯”ï¼‰ã€‚

+   max_stepsï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º-1ï¼‰â€” å¦‚æœè®¾ç½®ä¸ºæ­£æ•°ï¼Œåˆ™æ‰§è¡Œçš„æ€»è®­ç»ƒæ­¥æ•°ã€‚è¦†ç›–`num_train_epochs`ã€‚å¯¹äºæœ‰é™çš„æ•°æ®é›†ï¼Œå¦‚æœæ‰€æœ‰æ•°æ®éƒ½ç”¨å®Œï¼Œåˆ™é€šè¿‡æ•°æ®é›†é‡å¤è®­ç»ƒï¼Œç›´åˆ°è¾¾åˆ°`max_steps`ã€‚

+   gradient_accumulation_stepsï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º1ï¼‰â€” åœ¨æ‰§è¡Œå‘å/æ›´æ–°ä¼ é€’ä¹‹å‰ï¼Œç´¯ç§¯æ¢¯åº¦çš„æ›´æ–°æ­¥éª¤æ•°ã€‚

    åœ¨ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ—¶ï¼Œä¸€ä¸ªæ­¥éª¤è¢«è®¡ä¸ºä¸€ä¸ªå¸¦æœ‰å‘åä¼ é€’çš„æ­¥éª¤ã€‚å› æ­¤ï¼Œæ¯`gradient_accumulation_steps * xxx_step`ä¸ªè®­ç»ƒç¤ºä¾‹å°†è¿›è¡Œæ—¥å¿—è®°å½•ã€è¯„ä¼°å’Œä¿å­˜ã€‚

+   `seed` (`int`, *optional*, é»˜è®¤ä¸º 42) â€” å°†åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾ç½®çš„éšæœºç§å­ã€‚ä¸ºäº†ç¡®ä¿åœ¨ä¸åŒè¿è¡Œä¹‹é—´çš„å¯é‡ç°æ€§ï¼Œè¯·ä½¿ç”¨ `~Trainer.model_init` å‡½æ•°æ¥å®ä¾‹åŒ–æ¨¡å‹ï¼Œå¦‚æœæ¨¡å‹æœ‰ä¸€äº›éšæœºåˆå§‹åŒ–çš„å‚æ•°ã€‚

+   `gradient_checkpointing` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æ¥èŠ‚çœå†…å­˜ï¼Œä½†ä¼šé™ä½å‘åä¼ é€’çš„é€Ÿåº¦ã€‚

å°†æ‰€æœ‰ä¸è®­ç»ƒç›¸å…³çš„åŸºæœ¬å‚æ•°é‡æ–°ç»„åˆçš„æ–¹æ³•ã€‚

è°ƒç”¨æ­¤æ–¹æ³•å°†è‡ªåŠ¨å°† `self.do_train` è®¾ç½®ä¸º `True`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import TrainingArguments

>>> args = TrainingArguments("working_dir")
>>> args = args.set_training(learning_rate=1e-4, batch_size=32)
>>> args.learning_rate
1e-4
```

#### `to_dict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2126)

```py
( )
```

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ï¼ŒåŒæ—¶ç”¨å®ƒä»¬çš„å€¼æ›¿æ¢ `Enum`ï¼ˆç”¨äº JSON åºåˆ—åŒ–æ”¯æŒï¼‰ã€‚é€šè¿‡åˆ é™¤å®ƒä»¬çš„å€¼æ¥æ··æ·†ä»¤ç‰Œå€¼ã€‚

#### `to_json_string`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2143)

```py
( )
```

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ã€‚

#### `to_sanitized_dict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args.py#L2149)

```py
( )
```

ç»è¿‡æ¸…ç†çš„åºåˆ—åŒ–ï¼Œå¯ä¸ TensorBoard çš„ hparams ä¸€èµ·ä½¿ç”¨

## Seq2SeqTrainingArguments

### `class transformers.Seq2SeqTrainingArguments`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args_seq2seq.py#L28)

```py
( output_dir: str overwrite_output_dir: bool = False do_train: bool = False do_eval: bool = False do_predict: bool = False evaluation_strategy: Union = 'no' prediction_loss_only: bool = False per_device_train_batch_size: int = 8 per_device_eval_batch_size: int = 8 per_gpu_train_batch_size: Optional = None per_gpu_eval_batch_size: Optional = None gradient_accumulation_steps: int = 1 eval_accumulation_steps: Optional = None eval_delay: Optional = 0 learning_rate: float = 5e-05 weight_decay: float = 0.0 adam_beta1: float = 0.9 adam_beta2: float = 0.999 adam_epsilon: float = 1e-08 max_grad_norm: float = 1.0 num_train_epochs: float = 3.0 max_steps: int = -1 lr_scheduler_type: Union = 'linear' lr_scheduler_kwargs: Optional = <factory> warmup_ratio: float = 0.0 warmup_steps: int = 0 log_level: Optional = 'passive' log_level_replica: Optional = 'warning' log_on_each_node: bool = True logging_dir: Optional = None logging_strategy: Union = 'steps' logging_first_step: bool = False logging_steps: float = 500 logging_nan_inf_filter: bool = True save_strategy: Union = 'steps' save_steps: float = 500 save_total_limit: Optional = None save_safetensors: Optional = True save_on_each_node: bool = False save_only_model: bool = False no_cuda: bool = False use_cpu: bool = False use_mps_device: bool = False seed: int = 42 data_seed: Optional = None jit_mode_eval: bool = False use_ipex: bool = False bf16: bool = False fp16: bool = False fp16_opt_level: str = 'O1' half_precision_backend: str = 'auto' bf16_full_eval: bool = False fp16_full_eval: bool = False tf32: Optional = None local_rank: int = -1 ddp_backend: Optional = None tpu_num_cores: Optional = None tpu_metrics_debug: bool = False debug: Union = '' dataloader_drop_last: bool = False eval_steps: Optional = None dataloader_num_workers: int = 0 past_index: int = -1 run_name: Optional = None disable_tqdm: Optional = None remove_unused_columns: Optional = True label_names: Optional = None load_best_model_at_end: Optional = False metric_for_best_model: Optional = None greater_is_better: Optional = None ignore_data_skip: bool = False fsdp: Union = '' fsdp_min_num_params: int = 0 fsdp_config: Optional = None fsdp_transformer_layer_cls_to_wrap: Optional = None deepspeed: Optional = None label_smoothing_factor: float = 0.0 optim: Union = 'adamw_torch' optim_args: Optional = None adafactor: bool = False group_by_length: bool = False length_column_name: Optional = 'length' report_to: Optional = None ddp_find_unused_parameters: Optional = None ddp_bucket_cap_mb: Optional = None ddp_broadcast_buffers: Optional = None dataloader_pin_memory: bool = True dataloader_persistent_workers: bool = False skip_memory_metrics: bool = True use_legacy_prediction_loop: bool = False push_to_hub: bool = False resume_from_checkpoint: Optional = None hub_model_id: Optional = None hub_strategy: Union = 'every_save' hub_token: Optional = None hub_private_repo: bool = False hub_always_push: bool = False gradient_checkpointing: bool = False gradient_checkpointing_kwargs: Optional = None include_inputs_for_metrics: bool = False fp16_backend: str = 'auto' push_to_hub_model_id: Optional = None push_to_hub_organization: Optional = None push_to_hub_token: Optional = None mp_parameters: str = '' auto_find_batch_size: bool = False full_determinism: bool = False torchdynamo: Optional = None ray_scope: Optional = 'last' ddp_timeout: Optional = 1800 torch_compile: bool = False torch_compile_backend: Optional = None torch_compile_mode: Optional = None dispatch_batches: Optional = None split_batches: Optional = False include_tokens_per_second: Optional = False include_num_input_tokens_seen: Optional = False neftune_noise_alpha: float = None sortish_sampler: bool = False predict_with_generate: bool = False generation_max_length: Optional = None generation_num_beams: Optional = None generation_config: Union = None )
```

å‚æ•°

+   `output_dir` (`str`) â€” æ¨¡å‹é¢„æµ‹å’Œæ£€æŸ¥ç‚¹å°†è¢«å†™å…¥çš„è¾“å‡ºç›®å½•ã€‚

+   `overwrite_output_dir` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `True`ï¼Œåˆ™è¦†ç›–è¾“å‡ºç›®å½•çš„å†…å®¹ã€‚å¦‚æœ `output_dir` æŒ‡å‘ä¸€ä¸ªæ£€æŸ¥ç‚¹ç›®å½•ï¼Œåˆ™ä½¿ç”¨æ­¤é€‰é¡¹ç»§ç»­è®­ç»ƒã€‚

+   `do_train` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿è¡Œè®­ç»ƒã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯æ‰“ç®—ç”±æ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ä½¿ç”¨ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples)ã€‚

+   `do_eval` (`bool`, *optional*) â€” æ˜¯å¦åœ¨éªŒè¯é›†ä¸Šè¿è¡Œè¯„ä¼°ã€‚å¦‚æœ `evaluation_strategy` ä¸ `"no"` ä¸åŒï¼Œåˆ™å°†è®¾ç½®ä¸º `True`ã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯æ‰“ç®—ç”±æ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ä½¿ç”¨ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples)ã€‚

+   `do_predict` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œé¢„æµ‹ã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯æ‰“ç®—ç”±æ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ä½¿ç”¨ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples)ã€‚

+   `evaluation_strategy` (`str` æˆ– [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy), *optional*, é»˜è®¤ä¸º `"no"`) â€” è®­ç»ƒæœŸé—´é‡‡ç”¨çš„è¯„ä¼°ç­–ç•¥ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š

    +   `"no"`: åœ¨è®­ç»ƒæœŸé—´ä¸è¿›è¡Œè¯„ä¼°ã€‚

    +   `"steps"`: æ¯ `eval_steps` è¿›è¡Œä¸€æ¬¡è¯„ä¼°ï¼ˆå¹¶è®°å½•ï¼‰ã€‚

    +   `"epoch"`: åœ¨æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶è¿›è¡Œè¯„ä¼°ã€‚

+   `prediction_loss_only` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” åœ¨è¿›è¡Œè¯„ä¼°å’Œç”Ÿæˆé¢„æµ‹æ—¶ï¼Œä»…è¿”å›æŸå¤±ã€‚

+   `per_device_train_batch_size` (`int`, *optional*, é»˜è®¤ä¸º 8) â€” è®­ç»ƒæ—¶æ¯ä¸ª GPU/XPU/TPU/MPS/NPU æ ¸å¿ƒ/CPU çš„æ‰¹é‡å¤§å°ã€‚

+   `per_device_eval_batch_size` (`int`, *optional*, é»˜è®¤ä¸º 8) â€” è¯„ä¼°æ—¶æ¯ä¸ª GPU/XPU/TPU/MPS/NPU æ ¸å¿ƒ/CPU çš„æ‰¹é‡å¤§å°ã€‚

+   `gradient_accumulation_steps` (`int`, *optional*, é»˜è®¤ä¸º 1) â€” åœ¨æ‰§è¡Œå‘å/æ›´æ–°ä¼ é€’ä¹‹å‰ï¼Œç´¯ç§¯æ¢¯åº¦çš„æ›´æ–°æ­¥éª¤æ•°ã€‚

    åœ¨ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ—¶ï¼Œä¸€ä¸ªæ­¥éª¤è¢«è®¡ä¸ºä¸€ä¸ªå¸¦æœ‰åå‘ä¼ æ’­çš„æ­¥éª¤ã€‚å› æ­¤ï¼Œæ¯ `gradient_accumulation_steps * xxx_step` è®­ç»ƒç¤ºä¾‹å°†è¿›è¡Œè®°å½•ã€è¯„ä¼°ã€ä¿å­˜ã€‚

+   `eval_accumulation_steps` (`int`, *å¯é€‰*) â€” åœ¨å°†ç»“æœç§»åŠ¨åˆ° CPU ä¹‹å‰ï¼Œç´¯ç§¯è¾“å‡ºå¼ é‡çš„é¢„æµ‹æ­¥æ•°ã€‚å¦‚æœæœªè®¾ç½®ï¼Œæ•´ä¸ªé¢„æµ‹å°†åœ¨ GPU/NPU/TPU ä¸Šç´¯ç§¯åå†ç§»åŠ¨åˆ° CPUï¼ˆæ›´å¿«ä½†éœ€è¦æ›´å¤šå†…å­˜ï¼‰ã€‚

+   `eval_delay` (`float`, *å¯é€‰*) â€” åœ¨è¿›è¡Œç¬¬ä¸€æ¬¡è¯„ä¼°ä¹‹å‰ç­‰å¾…çš„å‘¨æœŸæ•°æˆ–æ­¥æ•°ï¼Œå…·ä½“å–å†³äº evaluation_strategyã€‚

+   `learning_rate` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 5e-5) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ã€‚

+   `weight_decay` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” è¦åº”ç”¨çš„æƒé‡è¡°å‡ï¼ˆå¦‚æœä¸ä¸ºé›¶ï¼‰åˆ°æ‰€æœ‰å±‚ï¼Œé™¤äº† [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨ä¸­çš„æ‰€æœ‰åç½®å’Œ LayerNorm æƒé‡ã€‚

+   `adam_beta1` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.9) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„ beta1 è¶…å‚æ•°ã€‚

+   `adam_beta2` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.999) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„ beta2 è¶…å‚æ•°ã€‚

+   `adam_epsilon` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 1e-8) â€” [AdamW](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.AdamW) ä¼˜åŒ–å™¨çš„ epsilon è¶…å‚æ•°ã€‚

+   `max_grad_norm` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 1.0) â€” æœ€å¤§æ¢¯åº¦èŒƒæ•°ï¼ˆç”¨äºæ¢¯åº¦è£å‰ªï¼‰ã€‚

+   `num_train_epochs(float,` *å¯é€‰*, é»˜è®¤ä¸º 3.0) â€” è¦æ‰§è¡Œçš„æ€»è®­ç»ƒå‘¨æœŸæ•°ï¼ˆå¦‚æœä¸æ˜¯æ•´æ•°ï¼Œåˆ™åœ¨åœæ­¢è®­ç»ƒä¹‹å‰æ‰§è¡Œæœ€åä¸€ä¸ªå‘¨æœŸçš„å°æ•°éƒ¨åˆ†ç™¾åˆ†æ¯”ï¼‰ã€‚

+   `max_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º -1) â€” å¦‚æœè®¾ç½®ä¸ºæ­£æ•°ï¼Œåˆ™æ‰§è¡Œçš„æ€»è®­ç»ƒæ­¥æ•°ã€‚è¦†ç›– `num_train_epochs`ã€‚å¯¹äºæœ‰é™çš„æ•°æ®é›†ï¼Œå¦‚æœæ‰€æœ‰æ•°æ®éƒ½ç”¨å®Œï¼Œåˆ™é€šè¿‡æ•°æ®é›†é‡æ–°è¿›è¡Œè®­ç»ƒï¼Œç›´åˆ°è¾¾åˆ° `max_steps`ã€‚

+   `lr_scheduler_type` (`str` æˆ– [SchedulerType](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.SchedulerType), *å¯é€‰*, é»˜è®¤ä¸º `"linear"`) â€” è¦ä½¿ç”¨çš„è°ƒåº¦å™¨ç±»å‹ã€‚æŸ¥çœ‹ [SchedulerType](/docs/transformers/v4.37.2/en/main_classes/optimizer_schedules#transformers.SchedulerType) çš„æ–‡æ¡£ä»¥è·å–æ‰€æœ‰å¯èƒ½çš„å€¼ã€‚

+   `lr_scheduler_kwargs`ï¼ˆâ€˜dictâ€™, *å¯é€‰*, é»˜è®¤ä¸º {}ï¼‰ â€” lr_scheduler çš„é¢å¤–å‚æ•°ã€‚æŸ¥çœ‹æ¯ä¸ªè°ƒåº¦å™¨çš„æ–‡æ¡£ä»¥è·å–å¯èƒ½çš„å€¼ã€‚

+   `warmup_ratio` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” ç”¨äºä» 0 åˆ° `learning_rate` è¿›è¡Œçº¿æ€§é¢„çƒ­çš„æ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡ã€‚

+   `warmup_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” ç”¨äºä» 0 åˆ° `learning_rate` è¿›è¡Œçº¿æ€§é¢„çƒ­çš„æ­¥æ•°ã€‚è¦†ç›–ä»»ä½• `warmup_ratio` çš„æ•ˆæœã€‚

+   `log_level` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `passive`) â€” è¦åœ¨ä¸»è¿›ç¨‹ä¸Šä½¿ç”¨çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ã€‚å¯èƒ½çš„é€‰æ‹©æ˜¯å­—ç¬¦ä¸²å½¢å¼çš„æ—¥å¿—çº§åˆ«ï¼šâ€˜debugâ€™ã€â€˜infoâ€™ã€`"warning"`ã€â€˜errorâ€™ å’Œ â€˜criticalâ€™ï¼Œä»¥åŠä¸€ä¸ª`passive`çº§åˆ«ï¼Œå®ƒä¸è®¾ç½®ä»»ä½•å†…å®¹å¹¶ä¿æŒ Transformers åº“çš„å½“å‰æ—¥å¿—çº§åˆ«ï¼ˆé»˜è®¤ä¸º `"warning"`ï¼‰ã€‚

+   `log_level_replica` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"warning"`) â€” ç”¨äºå‰¯æœ¬çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ã€‚ä¸ `log_level` ç›¸åŒçš„é€‰æ‹©â€

+   `log_on_each_node` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ˜¯å¦æ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨ `log_level` è¿›è¡Œè®°å½•ï¼Œæˆ–ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿›è¡Œè®°å½•ã€‚

+   `logging_dir` (`str`, *å¯é€‰*) â€” [TensorBoard](https://www.tensorflow.org/tensorboard) æ—¥å¿—ç›®å½•ã€‚å°†é»˜è®¤ä¸º *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***ã€‚

+   `logging_strategy` (`str` æˆ– [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"steps"`) â€” è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨çš„æ—¥å¿—è®°å½•ç­–ç•¥ã€‚å¯èƒ½çš„å–å€¼æœ‰ï¼š

    +   `"no"`: è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è¿›è¡Œæ—¥å¿—è®°å½•ã€‚

    +   `"epoch"`: æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶è¿›è¡Œæ—¥å¿—è®°å½•ã€‚

    +   `"steps"`: æ¯ `logging_steps` æ­¥è¿›è¡Œæ—¥å¿—è®°å½•ã€‚

+   `logging_first_step` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” æ˜¯å¦è®°å½•å’Œè¯„ä¼°ç¬¬ä¸€ä¸ª `global_step`ã€‚

+   `logging_steps` (`int` æˆ– `float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 500) â€” å¦‚æœ `logging_strategy="steps"`ï¼Œåˆ™åœ¨ä¸¤æ¬¡æ—¥å¿—ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ã€‚åº”ä¸ºæ•´æ•°æˆ–èŒƒå›´ä¸º `[0,1)` çš„æµ®ç‚¹æ•°ã€‚å¦‚æœå°äº 1ï¼Œåˆ™å°†è¢«è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡ã€‚

+   `logging_nan_inf_filter` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿‡æ»¤ç”¨äºè®°å½•çš„ `nan` å’Œ `inf` æŸå¤±ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™ä¼šè¿‡æ»¤æ¯ä¸ªæ­¥éª¤çš„æŸå¤±å€¼ä¸º `nan` æˆ– `inf`ï¼Œå¹¶å–å½“å‰æ—¥å¿—çª—å£çš„å¹³å‡æŸå¤±å€¼ã€‚ 

    `logging_nan_inf_filter` ä»…å½±å“æŸå¤±å€¼çš„è®°å½•ï¼Œä¸ä¼šæ”¹å˜æ¢¯åº¦çš„è®¡ç®—æˆ–åº”ç”¨äºæ¨¡å‹çš„è¡Œä¸ºã€‚

+   `save_strategy` (`str` æˆ– [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy)ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"steps"`) â€” è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨çš„æ£€æŸ¥ç‚¹ä¿å­˜ç­–ç•¥ã€‚å¯èƒ½çš„å–å€¼æœ‰ï¼š

    +   `"no"`: è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è¿›è¡Œä¿å­˜ã€‚

    +   `"epoch"`: æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶ä¿å­˜ã€‚

    +   `"steps"`: æ¯ `save_steps` æ­¥ä¿å­˜ä¸€æ¬¡ã€‚

+   `save_steps` (`int` æˆ– `float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 500) â€” å¦‚æœ `save_strategy="steps"`ï¼Œåˆ™åœ¨ä¸¤æ¬¡æ£€æŸ¥ç‚¹ä¿å­˜ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ã€‚åº”ä¸ºæ•´æ•°æˆ–èŒƒå›´ä¸º `[0,1)` çš„æµ®ç‚¹æ•°ã€‚å¦‚æœå°äº 1ï¼Œåˆ™å°†è¢«è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡ã€‚

+   `save_total_limit` (`int`ï¼Œ*å¯é€‰*) â€” å¦‚æœä¼ é€’äº†ä¸€ä¸ªå€¼ï¼Œå°†é™åˆ¶æ£€æŸ¥ç‚¹çš„æ€»é‡ã€‚åˆ é™¤ `output_dir` ä¸­çš„æ—§æ£€æŸ¥ç‚¹ã€‚å½“å¯ç”¨ `load_best_model_at_end` æ—¶ï¼Œâ€œæœ€ä½³â€æ£€æŸ¥ç‚¹å§‹ç»ˆä¼šä¿ç•™ï¼Œè€Œä¸”è¿˜ä¼šä¿ç•™æœ€è¿‘çš„æ£€æŸ¥ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¯¹äº `save_total_limit=5` å’Œ `load_best_model_at_end`ï¼Œæœ€åå››ä¸ªæ£€æŸ¥ç‚¹å°†å§‹ç»ˆä¸æœ€ä½³æ¨¡å‹ä¸€èµ·ä¿ç•™ã€‚å½“ `save_total_limit=1` å’Œ `load_best_model_at_end` æ—¶ï¼Œå¯èƒ½ä¿å­˜ä¸¤ä¸ªæ£€æŸ¥ç‚¹ï¼šæœ€åä¸€ä¸ªå’Œæœ€ä½³ä¸€ä¸ªï¼ˆå¦‚æœå®ƒä»¬ä¸åŒï¼‰ã€‚

+   `save_safetensors` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” ä½¿ç”¨ [safetensors](https://huggingface.co/docs/safetensors) ä¿å­˜å’ŒåŠ è½½çŠ¶æ€å­—å…¸ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„ `torch.load` å’Œ `torch.save`ã€‚

+   `save_on_each_node` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” åœ¨è¿›è¡Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹å’Œæ£€æŸ¥ç‚¹ï¼Œè¿˜æ˜¯ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šä¿å­˜ã€‚

    å½“ä¸åŒèŠ‚ç‚¹ä½¿ç”¨ç›¸åŒå­˜å‚¨æ—¶ï¼Œä¸åº”æ¿€æ´»æ­¤é€‰é¡¹ï¼Œå› ä¸ºæ–‡ä»¶å°†ä»¥ç›¸åŒåç§°ä¿å­˜åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šã€‚

+   `save_only_model` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” åœ¨æ£€æŸ¥ç‚¹æ—¶ï¼Œæ˜¯å¦ä»…ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯åŒæ—¶ä¿å­˜ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨å’Œ RNG çŠ¶æ€ã€‚è¯·æ³¨æ„ï¼Œå½“æ­¤é€‰é¡¹ä¸ºçœŸæ—¶ï¼Œæ‚¨å°†æ— æ³•ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è¿™æ ·å¯ä»¥é€šè¿‡ä¸å­˜å‚¨ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨å’Œ RNG çŠ¶æ€æ¥èŠ‚çœå­˜å‚¨ç©ºé—´ã€‚æ‚¨åªèƒ½ä½¿ç”¨ `from_pretrained` åŠ è½½æ¨¡å‹ï¼Œå¹¶å°†æ­¤é€‰é¡¹è®¾ç½®ä¸º `True`ã€‚

+   `use_cpu` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä½¿ç”¨ CPUã€‚å¦‚æœè®¾ç½®ä¸º Falseï¼Œå°†ä½¿ç”¨ cuda æˆ– mps è®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

+   `seed` (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 42) â€” åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾ç½®çš„éšæœºç§å­ã€‚ä¸ºäº†ç¡®ä¿è·¨è¿è¡Œçš„å¯é‡ç°æ€§ï¼Œè¯·ä½¿ç”¨ `~Trainer.model_init` å‡½æ•°æ¥å®ä¾‹åŒ–æ¨¡å‹ï¼Œå¦‚æœæ¨¡å‹å…·æœ‰ä¸€äº›éšæœºåˆå§‹åŒ–çš„å‚æ•°ã€‚

+   `data_seed` (`int`, *optional*) â€” ç”¨äºæ•°æ®é‡‡æ ·çš„éšæœºç§å­ã€‚å¦‚æœæœªè®¾ç½®ï¼Œæ•°æ®é‡‡æ ·çš„éšæœºç”Ÿæˆå™¨å°†ä½¿ç”¨ä¸`seed`ç›¸åŒçš„ç§å­ã€‚è¿™å¯ç”¨äºç¡®ä¿æ•°æ®é‡‡æ ·çš„å¯é‡ç°æ€§ï¼Œä¸æ¨¡å‹ç§å­æ— å…³ã€‚

+   `jit_mode_eval` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨PyTorch jitè·Ÿè¸ªè¿›è¡Œæ¨æ–­ã€‚

+   `use_ipex` (`bool`, *optional*, defaults to `False`) â€” åœ¨PyTorchå¯ç”¨æ—¶ä½¿ç”¨Intelæ‰©å±•ã€‚[IPEXå®‰è£…](https://github.com/intel/intel-extension-for-pytorch)ã€‚

+   `bf16` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨bf16 16ä½ï¼ˆæ··åˆï¼‰ç²¾åº¦è®­ç»ƒï¼Œè€Œä¸æ˜¯32ä½è®­ç»ƒã€‚éœ€è¦å®‰æ™®å°”æˆ–æ›´é«˜çš„NVIDIAæ¶æ„æˆ–ä½¿ç”¨CPUï¼ˆuse_cpuï¼‰æˆ–Ascend NPUã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„APIï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚

+   `fp16` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨fp16 16ä½ï¼ˆæ··åˆï¼‰ç²¾åº¦è®­ç»ƒï¼Œè€Œä¸æ˜¯32ä½è®­ç»ƒã€‚

+   `fp16_opt_level` (`str`, *optional*, defaults to â€˜O1â€™) â€” å¯¹äº`fp16`è®­ç»ƒï¼Œé€‰æ‹©åœ¨[â€˜O0â€™, â€˜O1â€™, â€˜O2â€™, å’Œ â€˜O3â€™]ä¸­çš„Apex AMPä¼˜åŒ–çº§åˆ«ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[Apexæ–‡æ¡£](https://nvidia.github.io/apex/amp)ã€‚

+   `fp16_backend` (`str`, *optional*, defaults to `"auto"`) â€” æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚è¯·æ”¹ç”¨`half_precision_backend`ã€‚

+   `half_precision_backend` (`str`, *optional*, defaults to `"auto"`) â€” ç”¨äºæ··åˆç²¾åº¦è®­ç»ƒçš„åç«¯ã€‚å¿…é¡»æ˜¯`"auto", "apex", "cpu_amp"`ä¹‹ä¸€ã€‚`"auto"`å°†æ ¹æ®æ£€æµ‹åˆ°çš„PyTorchç‰ˆæœ¬ä½¿ç”¨CPU/CUDA AMPæˆ–APEXï¼Œè€Œå…¶ä»–é€‰æ‹©å°†å¼ºåˆ¶ä½¿ç”¨è¯·æ±‚çš„åç«¯ã€‚

+   `bf16_full_eval` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„bfloat16è¯„ä¼°ï¼Œè€Œä¸æ˜¯32ä½ã€‚è¿™å°†æ›´å¿«ï¼ŒèŠ‚çœå†…å­˜ï¼Œä½†å¯èƒ½ä¼šæŸå®³æŒ‡æ ‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„APIï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚

+   `fp16_full_eval` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„float16è¯„ä¼°ï¼Œè€Œä¸æ˜¯32ä½ã€‚è¿™å°†æ›´å¿«ï¼ŒèŠ‚çœå†…å­˜ï¼Œä½†å¯èƒ½ä¼šæŸå®³æŒ‡æ ‡å€¼ã€‚

+   `tf32` (`bool`, *optional*) â€” æ˜¯å¦å¯ç”¨TF32æ¨¡å¼ï¼Œé€‚ç”¨äºAmpereå’Œæ›´æ–°çš„GPUæ¶æ„ã€‚é»˜è®¤å€¼å–å†³äºPyTorchçš„ç‰ˆæœ¬é»˜è®¤å€¼`torch.backends.cuda.matmul.allow_tf32`ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[TF32](https://huggingface.co/docs/transformers/performance#tf32)æ–‡æ¡£ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„APIï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚

+   `local_rank` (`int`, *optional*, defaults to -1) â€” åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´è¿›ç¨‹çš„æ’åã€‚

+   `ddp_backend` (`str`, *optional*) â€” ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒçš„åç«¯ã€‚å¿…é¡»æ˜¯`"nccl"`, `"mpi"`, `"ccl"`, `"gloo"`, `"hccl"`ä¹‹ä¸€ã€‚

+   `tpu_num_cores` (`int`, *optional*) â€” åœ¨TPUä¸Šè®­ç»ƒæ—¶ï¼ŒTPUæ ¸å¿ƒçš„æ•°é‡ï¼ˆç”±å¯åŠ¨è„šæœ¬è‡ªåŠ¨ä¼ é€’ï¼‰ã€‚

+   `dataloader_drop_last` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡ï¼ˆå¦‚æœæ•°æ®é›†çš„é•¿åº¦ä¸èƒ½è¢«æ‰¹æ¬¡å¤§å°æ•´é™¤ï¼‰ã€‚

+   `eval_steps` (`int` or `float`, *optional*) â€” å¦‚æœ`evaluation_strategy="steps"`ï¼Œåˆ™ä¸¤æ¬¡è¯„ä¼°ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºä¸`logging_steps`ç›¸åŒçš„å€¼ã€‚åº”ä¸ºèŒƒå›´åœ¨`[0,1)`çš„æ•´æ•°æˆ–æµ®ç‚¹æ•°ã€‚å¦‚æœå°äº1ï¼Œå°†è¢«è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡ã€‚

+   `dataloader_num_workers` (`int`, *optional*, defaults to 0) â€” ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°ï¼ˆä»…é€‚ç”¨äºPyTorchï¼‰ã€‚0è¡¨ç¤ºæ•°æ®å°†åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½ã€‚

+   `past_index` (`int`, *optional*, defaults to -1) â€” ä¸€äº›æ¨¡å‹ï¼ˆå¦‚[TransformerXL](../model_doc/transformerxl)æˆ–[XLNet](../model_doc/xlnet)ï¼‰å¯ä»¥åˆ©ç”¨è¿‡å»çš„éšè—çŠ¶æ€è¿›è¡Œé¢„æµ‹ã€‚å¦‚æœå°†æ­¤å‚æ•°è®¾ç½®ä¸ºæ­£æ•´æ•°ï¼Œåˆ™`Trainer`å°†ä½¿ç”¨ç›¸åº”çš„è¾“å‡ºï¼ˆé€šå¸¸ä¸ºç´¢å¼•2ï¼‰ä½œä¸ºè¿‡å»çŠ¶æ€ï¼Œå¹¶åœ¨ä¸‹ä¸€ä¸ªè®­ç»ƒæ­¥éª¤ä¸­å°†å…¶ä½œä¸ºå…³é”®å­—å‚æ•°`mems`æä¾›ç»™æ¨¡å‹ã€‚

+   `run_name` (`str`, *optional*) â€” è¿è¡Œçš„æè¿°ç¬¦ã€‚é€šå¸¸ç”¨äº[wandb](https://www.wandb.com/)å’Œ[mlflow](https://www.mlflow.org/)æ—¥å¿—è®°å½•ã€‚

+   `disable_tqdm` (`bool`, *optional*) â€” æ˜¯å¦ç¦ç”¨Jupyterç¬”è®°æœ¬ä¸­`~notebook.NotebookTrainingTracker`ç”Ÿæˆçš„tqdmè¿›åº¦æ¡å’ŒæŒ‡æ ‡è¡¨ã€‚å¦‚æœæ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºwarnæˆ–æ›´ä½ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™é»˜è®¤ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚

+   `remove_unused_columns` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è‡ªåŠ¨åˆ é™¤æ¨¡å‹å‰å‘æ–¹æ³•æœªä½¿ç”¨çš„åˆ—ã€‚

+   `label_names` (`List[str]`, *optional*) â€” æ‚¨çš„è¾“å…¥å­—å…¸ä¸­å¯¹åº”äºæ ‡ç­¾çš„é”®åˆ—è¡¨ã€‚

    æœ€ç»ˆå°†é»˜è®¤ä¸ºæ¨¡å‹æ¥å—çš„å‚æ•°åç§°åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«å•è¯â€œlabelâ€ï¼Œé™¤éä½¿ç”¨çš„æ¨¡å‹æ˜¯`XxxForQuestionAnswering`ä¹‹ä¸€ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹è¿˜å°†åŒ…æ‹¬`["start_positions", "end_positions"]`é”®ã€‚

+   `load_best_model_at_end` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨è®­ç»ƒç»“æŸæ—¶åŠ è½½è®­ç»ƒè¿‡ç¨‹ä¸­æ‰¾åˆ°çš„æœ€ä½³æ¨¡å‹ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæœ€ä½³æ£€æŸ¥ç‚¹å°†å§‹ç»ˆè¢«ä¿å­˜ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§[`save_total_limit`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.save_total_limit)ã€‚

    è®¾ç½®ä¸º`True`æ—¶ï¼Œå‚æ•°`save_strategy`éœ€è¦ä¸`evaluation_strategy`ç›¸åŒï¼Œå¦‚æœæ˜¯â€œstepsâ€ï¼Œåˆ™`save_steps`å¿…é¡»æ˜¯`eval_steps`çš„æ•´æ•°å€ã€‚

+   `metric_for_best_model` (`str`, *optional*) â€” ä¸`load_best_model_at_end`ä¸€èµ·ä½¿ç”¨ï¼ŒæŒ‡å®šç”¨äºæ¯”è¾ƒä¸¤ä¸ªä¸åŒæ¨¡å‹çš„åº¦é‡æ ‡å‡†ã€‚å¿…é¡»æ˜¯è¯„ä¼°è¿”å›çš„åº¦é‡çš„åç§°ï¼Œå¸¦æœ‰æˆ–ä¸å¸¦æœ‰å‰ç¼€`"eval_"`ã€‚å¦‚æœæœªæŒ‡å®šä¸”`load_best_model_at_end=True`ï¼ˆä½¿ç”¨è¯„ä¼°æŸå¤±ï¼‰ï¼Œå°†é»˜è®¤ä¸º`"loss"`ã€‚

    å¦‚æœè®¾ç½®äº†æ­¤å€¼ï¼Œ`greater_is_better`å°†é»˜è®¤ä¸º`True`ã€‚å¦‚æœæ‚¨çš„åº¦é‡æ ‡å‡†è¾ƒä½æ—¶æ›´å¥½ï¼Œè¯·ä¸è¦å¿˜è®°å°†å…¶è®¾ç½®ä¸º`False`ã€‚

+   `greater_is_better` (`bool`, *optional*) â€” ä¸`load_best_model_at_end`å’Œ`metric_for_best_model`ä¸€èµ·ä½¿ç”¨ï¼ŒæŒ‡å®šæ›´å¥½çš„æ¨¡å‹æ˜¯å¦åº”å…·æœ‰æ›´å¤§çš„åº¦é‡æ ‡å‡†ã€‚é»˜è®¤ä¸ºï¼š

    +   å¦‚æœ`metric_for_best_model`è®¾ç½®ä¸ºä¸æ˜¯`"loss"`æˆ–`"eval_loss"`çš„å€¼ï¼Œåˆ™ä¸º`True`ã€‚

    +   å¦‚æœæœªè®¾ç½®`metric_for_best_model`ï¼Œæˆ–è®¾ç½®ä¸º`"loss"`æˆ–`"eval_loss"`ï¼Œåˆ™ä¸º`False`ã€‚

+   `ignore_data_skip` (`bool`, *optional*, defaults to `False`) â€” æ¢å¤è®­ç»ƒæ—¶ï¼Œæ˜¯å¦è·³è¿‡æ‰¹æ¬¡å’Œè½®æ¬¡ä»¥ä½¿æ•°æ®åŠ è½½ä¸å…ˆå‰è®­ç»ƒçš„é˜¶æ®µç›¸åŒã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œè®­ç»ƒå°†æ›´å¿«å¼€å§‹ï¼ˆå› ä¸ºè·³è¿‡æ­¥éª¤å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼‰ï¼Œä½†ä¸ä¼šäº§ç”Ÿä¸ä¸­æ–­è®­ç»ƒç›¸åŒçš„ç»“æœã€‚

+   `fsdp` (`bool`, `str` or list of `FSDPOption`, *optional*, defaults to `''`) â€” ä½¿ç”¨PyTorchåˆ†å¸ƒå¼å¹¶è¡Œè®­ç»ƒï¼ˆä»…åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼‰ã€‚

    ä»¥ä¸‹é€‰é¡¹åˆ—è¡¨ï¼š

    +   `"full_shard"`: åˆ†ç‰‡å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚

    +   `"shard_grad_op"`: åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦ã€‚

    +   `"hybrid_shard"`: åœ¨èŠ‚ç‚¹å†…åº”ç”¨`FULL_SHARD`ï¼Œå¹¶åœ¨èŠ‚ç‚¹ä¹‹é—´å¤åˆ¶å‚æ•°ã€‚

    +   `"hybrid_shard_zero2"`: åœ¨èŠ‚ç‚¹å†…åº”ç”¨`SHARD_GRAD_OP`ï¼Œå¹¶åœ¨èŠ‚ç‚¹ä¹‹é—´å¤åˆ¶å‚æ•°ã€‚

    +   `"offload"`: å°†å‚æ•°å’Œæ¢¯åº¦å¸è½½åˆ°CPUï¼ˆä»…ä¸`"full_shard"`å’Œ`"shard_grad_op"`å…¼å®¹ï¼‰ã€‚

    +   `"auto_wrap"`: ä½¿ç”¨`default_auto_wrap_policy`è‡ªåŠ¨é€’å½’åŒ…è£…å±‚ä¸FSDPã€‚

+   `fsdp_config` (`str` or `dict`, *optional*) â€” ç”¨äºfsdpï¼ˆPytorchåˆ†å¸ƒå¼å¹¶è¡Œè®­ç»ƒï¼‰çš„é…ç½®ã€‚è¯¥å€¼å¯ä»¥æ˜¯fsdp jsoné…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œ`fsdp_config.json`ï¼‰æˆ–å·²åŠ è½½çš„jsonæ–‡ä»¶ä½œä¸º`dict`ã€‚

    é…ç½®åŠå…¶é€‰é¡¹åˆ—è¡¨ï¼š

    +   min_num_params (`int`, *optional*, defaults to `0`): FSDPçš„é»˜è®¤è‡ªåŠ¨åŒ…è£…çš„å‚æ•°æœ€å°æ•°é‡ã€‚ï¼ˆä»…åœ¨ä¼ é€’`fsdp`å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚

    +   transformer_layer_cls_to_wrapï¼ˆ`List[str]`ï¼Œ*å¯é€‰*ï¼‰ï¼šè¦åŒ…è£…çš„transformerå±‚ç±»åç§°åˆ—è¡¨ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ï¼Œ`BertLayer`ï¼Œ`GPTJBlock`ï¼Œ`T5Block` â€¦ï¼ˆä»…åœ¨ä¼ é€’`fsdp`æ ‡å¿—æ—¶æœ‰ç”¨ï¼‰ã€‚

    +   backward_prefetchï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰FSDPçš„åå‘é¢„å–æ¨¡å¼ã€‚æ§åˆ¶ä½•æ—¶é¢„å–ä¸‹ä¸€ç»„å‚æ•°ï¼ˆä»…åœ¨ä¼ é€’`fsdp`å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚

        ä»¥ä¸‹æ˜¯ä¸€ç³»åˆ—é€‰é¡¹ï¼š

        +   `"backward_pre"`ï¼šåœ¨å½“å‰å‚æ•°æ¢¯åº¦è®¡ç®—ä¹‹å‰é¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚

        +   `"backward_post"`ï¼šåœ¨å½“å‰å‚æ•°æ¢¯åº¦è®¡ç®—ä¹‹åé¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚

    +   forward_prefetchï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰FSDPçš„å‰å‘é¢„å–æ¨¡å¼ï¼ˆä»…åœ¨ä¼ é€’`fsdp`å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚å¦‚æœä¸º`"True"`ï¼Œåˆ™FSDPä¼šåœ¨å‰å‘ä¼ é€’ä¸­æ˜¾å¼é¢„å–ä¸‹ä¸€ä¸ªå³å°†åˆ°æ¥çš„all-gatherã€‚

    +   limit_all_gathersï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰FSDPçš„limit_all_gathersï¼ˆä»…åœ¨ä¼ é€’`fsdp`å­—æ®µæ—¶æœ‰ç”¨ï¼‰ã€‚å¦‚æœä¸º`"True"`ï¼ŒFSDPä¼šæ˜¾å¼åŒæ­¥CPUçº¿ç¨‹ï¼Œä»¥é˜²æ­¢å¤ªå¤šçš„in-flight all-gathersã€‚

    +   use_orig_paramsï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰å¦‚æœä¸º`"True"`ï¼Œå…è®¸åœ¨åˆå§‹åŒ–æœŸé—´ä½¿ç”¨éå‡åŒ€çš„`requires_grad`ï¼Œè¿™æ„å‘³ç€æ”¯æŒäº¤æ›¿å†»ç»“å’Œå¯è®­ç»ƒå‚æ•°ã€‚åœ¨å‚æ•°é«˜æ•ˆå¾®è°ƒç­‰æƒ…å†µä¸‹éå¸¸æœ‰ç”¨ã€‚è¯·å‚è€ƒæ­¤[åšå®¢]ï¼ˆ[https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019](https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019)

    +   sync_module_statesï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰å¦‚æœä¸º`"True"`ï¼Œæ¯ä¸ªå•ç‹¬åŒ…è£…çš„FSDPå•å…ƒå°†ä»rank 0å¹¿æ’­æ¨¡å—å‚æ•°ï¼Œä»¥ç¡®ä¿åœ¨åˆå§‹åŒ–åæ‰€æœ‰rankä¸­çš„å‚æ•°ç›¸åŒ

    +   activation_checkpointingï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ï¼šå¦‚æœä¸º`"True"`ï¼Œæ¿€æ´»æ£€æŸ¥ç‚¹æ˜¯ä¸€ç§é€šè¿‡æ¸…é™¤æŸäº›å±‚çš„æ¿€æ´»å¹¶åœ¨åå‘ä¼ é€’æœŸé—´é‡æ–°è®¡ç®—å®ƒä»¬æ¥å‡å°‘å†…å­˜ä½¿ç”¨çš„æŠ€æœ¯ã€‚å®é™…ä¸Šï¼Œè¿™æ˜¯ä»¥é¢å¤–çš„è®¡ç®—æ—¶é—´æ¢å–å‡å°‘å†…å­˜ä½¿ç”¨ã€‚

    +   xlaï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ï¼šæ˜¯å¦ä½¿ç”¨PyTorch/XLAå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œè®­ç»ƒã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œå…¶APIå¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿå˜åŒ–ã€‚

    +   xla_fsdp_settingsï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰è¯¥å€¼æ˜¯ä¸€ä¸ªå­˜å‚¨XLA FSDPåŒ…è£…å‚æ•°çš„å­—å…¸ã€‚

        æœ‰å…³æ‰€æœ‰é€‰é¡¹çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚è§[æ­¤å¤„](https://github.com/pytorch/xla/blob/master/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py)ã€‚

    +   xla_fsdp_grad_ckptï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰ï¼šå°†åœ¨æ¯ä¸ªåµŒå¥—çš„XLA FSDPåŒ…è£…å±‚ä¸Šä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€‚åªæœ‰åœ¨å°†xlaæ ‡å¿—è®¾ç½®ä¸ºtrueï¼Œå¹¶é€šè¿‡fsdp_min_num_paramsæˆ–fsdp_transformer_layer_cls_to_wrapæŒ‡å®šäº†è‡ªåŠ¨åŒ…è£…ç­–ç•¥æ—¶æ‰èƒ½ä½¿ç”¨æ­¤è®¾ç½®ã€‚

+   `deepspeed`ï¼ˆ`str`æˆ–`dict`ï¼Œ*å¯é€‰*ï¼‰â€”ä½¿ç”¨[Deepspeed](https://github.com/microsoft/deepspeed)ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œå…¶APIå¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿå˜åŒ–ã€‚è¯¥å€¼å¯ä»¥æ˜¯DeepSpeed jsoné…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œ`ds_config.json`ï¼‰æˆ–å·²åŠ è½½çš„jsonæ–‡ä»¶ä½œä¸º`dict`â€

+   `label_smoothing_factor`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.0ï¼‰â€”è¦ä½¿ç”¨çš„æ ‡ç­¾å¹³æ»‘å› å­ã€‚é›¶è¡¨ç¤ºä¸è¿›è¡Œæ ‡ç­¾å¹³æ»‘ï¼Œå¦åˆ™åŸºç¡€çš„onehotç¼–ç æ ‡ç­¾å°†ä»0å’Œ1æ›´æ”¹ä¸º`label_smoothing_factor/num_labels`å’Œ`1 - label_smoothing_factor + label_smoothing_factor/num_labels`ã€‚

+   `debug`ï¼ˆ`str`æˆ–`DebugOption`åˆ—è¡¨ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`""`ï¼‰â€”å¯ç”¨ä¸€ä¸ªæˆ–å¤šä¸ªè°ƒè¯•åŠŸèƒ½ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ã€‚

    å¯èƒ½çš„é€‰é¡¹æœ‰ï¼š

    +   `"underflow_overflow"`ï¼šæ£€æµ‹æ¨¡å‹è¾“å…¥/è¾“å‡ºä¸­çš„æº¢å‡ºå¹¶æŠ¥å‘Šå¯¼è‡´äº‹ä»¶çš„æœ€åå¸§

    +   `"tpu_metrics_debug"`ï¼šåœ¨TPUä¸Šæ‰“å°è°ƒè¯•æŒ‡æ ‡

    é€‰é¡¹åº”è¯¥ç”¨ç©ºæ ¼åˆ†éš”ã€‚

+   `optim` (`str` or `training_args.OptimizerNames`, *optional*, defaults to `"adamw_torch"`) â€” è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼šadamw_hfã€adamw_torchã€adamw_torch_fusedã€adamw_apex_fusedã€adamw_anyprecision æˆ– adafactorã€‚

+   `optim_args` (`str`, *optional*) â€” æä¾›ç»™ AnyPrecisionAdamW çš„å¯é€‰å‚æ•°ã€‚

+   `group_by_length` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å°†å¤§è‡´ç›¸åŒé•¿åº¦çš„æ ·æœ¬åˆ†ç»„åœ¨ä¸€èµ·ï¼ˆä»¥æœ€å°åŒ–å¡«å……å¹¶æé«˜æ•ˆç‡ï¼‰ã€‚ä»…åœ¨åº”ç”¨åŠ¨æ€å¡«å……æ—¶æœ‰ç”¨ã€‚

+   `length_column_name` (`str`, *optional*, defaults to `"length"`) â€” é¢„å…ˆè®¡ç®—é•¿åº¦çš„åˆ—åã€‚å¦‚æœè¯¥åˆ—å­˜åœ¨ï¼Œåˆ™æŒ‰é•¿åº¦åˆ†ç»„å°†ä½¿ç”¨è¿™äº›å€¼è€Œä¸æ˜¯åœ¨è®­ç»ƒå¯åŠ¨æ—¶è®¡ç®—å®ƒä»¬ã€‚ä»…åœ¨ `group_by_length` ä¸º `True` ä¸”æ•°æ®é›†æ˜¯ `Dataset` çš„å®ä¾‹æ—¶æ‰ä¼šè¢«å¿½ç•¥ã€‚

+   `report_to` (`str` or `List[str]`, *optional*, defaults to `"all"`) â€” æŠ¥å‘Šç»“æœå’Œæ—¥å¿—çš„é›†æˆåˆ—è¡¨ã€‚æ”¯æŒçš„å¹³å°æœ‰ `"azure_ml"`ã€`"clearml"`ã€`"codecarbon"`ã€`"comet_ml"`ã€`"dagshub"`ã€`"dvclive"`ã€`"flyte"`ã€`"mlflow"`ã€`"neptune"`ã€`"tensorboard"` å’Œ `"wandb"`ã€‚ä½¿ç”¨ `"all"` æŠ¥å‘Šåˆ°æ‰€æœ‰å·²å®‰è£…çš„é›†æˆï¼Œä½¿ç”¨ `"none"` ä¸æŠ¥å‘Šåˆ°ä»»ä½•é›†æˆã€‚

+   `ddp_find_unused_parameters` (`bool`, *optional*) â€” åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ `DistributedDataParallel` çš„æ ‡å¿— `find_unused_parameters` çš„å€¼ã€‚å¦‚æœä½¿ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œåˆ™é»˜è®¤ä¸º `False`ï¼Œå¦åˆ™ä¸º `True`ã€‚

+   `ddp_bucket_cap_mb` (`int`, *optional*) â€” åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ `DistributedDataParallel` çš„æ ‡å¿— `bucket_cap_mb` çš„å€¼ã€‚

+   `ddp_broadcast_buffers` (`bool`, *optional*) â€” åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ `DistributedDataParallel` çš„æ ‡å¿— `broadcast_buffers` çš„å€¼ã€‚å¦‚æœä½¿ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œåˆ™é»˜è®¤ä¸º `False`ï¼Œå¦åˆ™ä¸º `True`ã€‚

+   `dataloader_pin_memory` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¦åœ¨æ•°æ®åŠ è½½å™¨ä¸­å›ºå®šå†…å­˜ã€‚é»˜è®¤ä¸º `True`ã€‚

+   `dataloader_persistent_workers` (`bool`, *optional*, defaults to `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™æ•°æ®åŠ è½½å™¨åœ¨æ•°æ®é›†è¢«æ¶ˆè€—ä¸€æ¬¡åä¸ä¼šå…³é—­å·¥ä½œè¿›ç¨‹ã€‚è¿™å…è®¸ä¿æŒå·¥ä½œäººå‘˜æ•°æ®é›†å®ä¾‹çš„æ´»åŠ¨çŠ¶æ€ã€‚å¯èƒ½ä¼šåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¼šå¢åŠ  RAM ä½¿ç”¨é‡ã€‚é»˜è®¤ä¸º `False`ã€‚

+   `skip_memory_metrics` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è·³è¿‡å°†å†…å­˜åˆ†ææŠ¥å‘Šæ·»åŠ åˆ°æŒ‡æ ‡ä¸­ã€‚é»˜è®¤è·³è¿‡æ­¤æ­¥éª¤ï¼Œå› ä¸ºå®ƒä¼šå‡æ…¢è®­ç»ƒå’Œè¯„ä¼°é€Ÿåº¦ã€‚

+   `push_to_hub` (`bool`, *optional*, defaults to `False`) â€” æ¯æ¬¡ä¿å­˜æ¨¡å‹æ—¶æ˜¯å¦å°†æ¨¡å‹æ¨é€åˆ° Hubã€‚å¦‚æœæ¿€æ´»äº†æ­¤é€‰é¡¹ï¼Œ`output_dir` å°†å¼€å§‹ä¸€ä¸ªä¸å­˜å‚¨åº“åŒæ­¥çš„ git ç›®å½•ï¼ˆç”± `hub_model_id` ç¡®å®šï¼‰ï¼Œå¹¶ä¸”æ¯æ¬¡è§¦å‘ä¿å­˜æ—¶éƒ½ä¼šæ¨é€å†…å®¹ï¼ˆå–å†³äºæ‚¨çš„ `save_strategy`ï¼‰ã€‚è°ƒç”¨ [save_model()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.save_model) ä¹Ÿä¼šè§¦å‘æ¨é€ã€‚

    å¦‚æœ `output_dir` å­˜åœ¨ï¼Œåˆ™éœ€è¦æ˜¯å°† [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) æ¨é€åˆ°çš„å­˜å‚¨åº“çš„æœ¬åœ°å…‹éš†ã€‚

+   `resume_from_checkpoint` (`str`, *optional*) â€” æ‚¨çš„æ¨¡å‹çš„æœ‰æ•ˆæ£€æŸ¥ç‚¹æ‰€åœ¨æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚æ­¤å‚æ•°ä¸ä¼šç›´æ¥è¢« [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä½¿ç”¨ï¼Œè€Œæ˜¯æ‰“ç®—ç”±æ‚¨çš„è®­ç»ƒ/è¯„ä¼°è„šæœ¬ä½¿ç”¨ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples)ã€‚

+   `hub_model_id` (`str`, *optional*) â€” ä¸æœ¬åœ° *output_dir* åŒæ­¥çš„å­˜å‚¨åº“çš„åç§°ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡å‹ IDï¼Œæ­¤æ—¶æ¨¡å‹å°†è¢«æ¨é€åˆ°æ‚¨çš„å‘½åç©ºé—´ã€‚å¦åˆ™ï¼Œå®ƒåº”è¯¥æ˜¯æ•´ä¸ªå­˜å‚¨åº“åç§°ï¼Œä¾‹å¦‚ `"user_name/model"`ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥æ¨é€åˆ°æ‚¨æ‰€å±çš„ç»„ç»‡ï¼Œä¾‹å¦‚ `"organization_name/model"`ã€‚å°†é»˜è®¤ä¸º `user_name/output_dir_name`ï¼Œå…¶ä¸­ *output_dir_name* æ˜¯ `output_dir` çš„åç§°ã€‚

    å°†é»˜è®¤ä¸º `output_dir` çš„åç§°ã€‚

+   `hub_strategy` (`str` æˆ– `HubStrategy`, *optional*, é»˜è®¤ä¸º `"every_save"`) â€” å®šä¹‰æ¨é€åˆ° Hub çš„èŒƒå›´å’Œæ—¶é—´ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š

    +   `"end"`: å½“è°ƒç”¨ [save_model()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.save_model) æ–¹æ³•æ—¶ï¼Œæ¨é€æ¨¡å‹ã€å…¶é…ç½®ã€åˆ†è¯å™¨ï¼ˆå¦‚æœä¼ é€’ç»™ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ä»¥åŠæ¨¡å‹å¡ç‰‡çš„è‰ç¨¿ã€‚

    +   `"every_save"`: æ¯æ¬¡ä¿å­˜æ¨¡å‹æ—¶ï¼Œæ¨é€æ¨¡å‹ã€å…¶é…ç½®ã€åˆ†è¯å™¨ï¼ˆå¦‚æœä¼ é€’ç»™ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼‰ä»¥åŠæ¨¡å‹å¡ç‰‡çš„è‰ç¨¿ã€‚æ¨é€æ˜¯å¼‚æ­¥çš„ï¼Œä»¥é¿å…é˜»å¡è®­ç»ƒï¼Œå¦‚æœä¿å­˜éå¸¸é¢‘ç¹ï¼Œåˆ™åªæœ‰åœ¨ä¸Šä¸€ä¸ªæ¨é€å®Œæˆåæ‰ä¼šå°è¯•æ–°çš„æ¨é€ã€‚åœ¨è®­ç»ƒç»“æŸæ—¶ï¼Œä½¿ç”¨æœ€ç»ˆæ¨¡å‹è¿›è¡Œæœ€åä¸€æ¬¡æ¨é€ã€‚

    +   `"checkpoint"`: ç±»ä¼¼äº `"every_save"`ï¼Œä½†æœ€æ–°çš„æ£€æŸ¥ç‚¹ä¹Ÿä¼šè¢«æ¨é€åˆ°åä¸º last-checkpoint çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™æ ·æ‚¨å¯ä»¥è½»æ¾åœ°ä½¿ç”¨ `trainer.train(resume_from_checkpoint="last-checkpoint")` æ¢å¤è®­ç»ƒã€‚

    +   `"all_checkpoints"`: ç±»ä¼¼äº `"checkpoint"`ï¼Œä½†æ‰€æœ‰æ£€æŸ¥ç‚¹éƒ½åƒå®ƒä»¬å‡ºç°åœ¨è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ä¸€æ ·è¢«æ¨é€ï¼ˆå› æ­¤æ‚¨å°†åœ¨æœ€ç»ˆå­˜å‚¨åº“ä¸­è·å¾—ä¸€ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ï¼‰ã€‚

+   `hub_token` (`str`, *optional*) â€” ç”¨äºå°†æ¨¡å‹æ¨é€åˆ° Hub çš„ä»¤ç‰Œã€‚å°†é»˜è®¤ä¸ºä½¿ç”¨ `huggingface-cli login` è·å–çš„ç¼“å­˜æ–‡ä»¶å¤¹ä¸­çš„ä»¤ç‰Œã€‚

+   `hub_private_repo` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™ Hub å­˜å‚¨åº“å°†è®¾ç½®ä¸ºç§æœ‰ã€‚

+   `hub_always_push` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” é™¤éä¸º `True`ï¼Œå¦åˆ™ `Trainer` åœ¨ä¸Šä¸€ä¸ªæ¨é€æœªå®Œæˆæ—¶å°†è·³è¿‡æ¨é€æ£€æŸ¥ç‚¹ã€‚

+   `gradient_checkpointing` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æ¥èŠ‚çœå†…å­˜ï¼Œä½†ä¼šå¯¼è‡´åå‘ä¼ æ’­é€Ÿåº¦å˜æ…¢ã€‚

+   `gradient_checkpointing_kwargs` (`dict`, *optional*, é»˜è®¤ä¸º `None`) â€” è¦ä¼ é€’ç»™ `gradient_checkpointing_enable` æ–¹æ³•çš„å…³é”®å­—å‚æ•°ã€‚

+   `include_inputs_for_metrics` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å°†è¾“å…¥ä¼ é€’ç»™ `compute_metrics` å‡½æ•°ã€‚è¿™é€‚ç”¨äºéœ€è¦è¾“å…¥ã€é¢„æµ‹å’Œå‚è€ƒå€¼è¿›è¡Œè¯„åˆ†è®¡ç®—çš„æŒ‡æ ‡ç±»ã€‚

+   `auto_find_batch_size` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦é€šè¿‡æŒ‡æ•°è¡°å‡è‡ªåŠ¨æ‰¾åˆ°é€‚åˆå†…å­˜çš„æ‰¹é‡å¤§å°ï¼Œé¿å… CUDA å†…å­˜ä¸è¶³é”™è¯¯ã€‚éœ€è¦å®‰è£… accelerate (`pip install accelerate`)ã€‚

+   `full_determinism` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `True`ï¼Œå°†è°ƒç”¨ [enable_full_determinism()](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.enable_full_determinism) è€Œä¸æ˜¯ [set_seed()](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.set_seed) æ¥ç¡®ä¿åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­è·å¾—å¯é‡ç°çš„ç»“æœã€‚é‡è¦æç¤ºï¼šè¿™ä¼šå¯¹æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œå› æ­¤åªèƒ½ç”¨äºè°ƒè¯•ç›®çš„ã€‚

+   `torchdynamo` (`str`, *optional*) â€” å¦‚æœè®¾ç½®ï¼ŒTorchDynamo çš„åç«¯ç¼–è¯‘å™¨ã€‚å¯èƒ½çš„é€‰æ‹©æ˜¯ `"eager"`, `"aot_eager"`, `"inductor"`, `"nvfuser"`, `"aot_nvfuser"`, `"aot_cudagraphs"`, `"ofi"`, `"fx2trt"`, `"onnxrt"` å’Œ `"ipex"`ã€‚

+   `ray_scope`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"last"`ï¼‰â€” åœ¨ä½¿ç”¨Rayè¿›è¡Œè¶…å‚æ•°æœç´¢æ—¶è¦ä½¿ç”¨çš„èŒƒå›´ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä½¿ç”¨`"last"`ã€‚ç„¶åï¼ŒRayå°†ä½¿ç”¨æ‰€æœ‰è¯•éªŒçš„æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œè¿›è¡Œæ¯”è¾ƒå¹¶é€‰æ‹©æœ€ä½³çš„ä¸€ä¸ªã€‚ä½†ä¹Ÿæœ‰å…¶ä»–é€‰é¡¹å¯ç”¨ã€‚æŸ¥çœ‹[Rayæ–‡æ¡£](https://docs.ray.io/en/latest/tune/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial)ä»¥è·å–æ›´å¤šé€‰é¡¹ã€‚

+   `ddp_timeout`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º1800ï¼‰â€” `torch.distributed.init_process_group`è°ƒç”¨çš„è¶…æ—¶æ—¶é—´ï¼Œç”¨äºé¿å…åœ¨åˆ†å¸ƒå¼è¿è¡Œä¸­æ‰§è¡Œç¼“æ…¢æ“ä½œæ—¶å‘ç”ŸGPUå¥—æ¥å­—è¶…æ—¶ã€‚è¯·å‚è€ƒ[PyTorchæ–‡æ¡£]([https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group))ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

+   `use_mps_device`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚å¦‚æœå¯ç”¨ï¼Œå°†ä½¿ç”¨`mps`è®¾å¤‡ï¼Œç±»ä¼¼äº`cuda`è®¾å¤‡ã€‚

+   `torch_compile`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä½¿ç”¨PyTorch 2.0 [`torch.compile`](https://pytorch.org/get-started/pytorch-2.0/)ç¼–è¯‘æ¨¡å‹ã€‚

    è¿™å°†ä½¿ç”¨[`torch.compile` API](https://pytorch.org/docs/stable/generated/torch.compile.html?highlight=torch+compile#torch.compile)çš„æœ€ä½³é»˜è®¤å€¼ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å‚æ•°`torch_compile_backend`å’Œ`torch_compile_mode`è‡ªå®šä¹‰é»˜è®¤å€¼ï¼Œä½†æˆ‘ä»¬ä¸èƒ½ä¿è¯å®ƒä»¬ä¸­çš„ä»»ä½•ä¸€ä¸ªä¼šèµ·ä½œç”¨ï¼Œå› ä¸ºæ”¯æŒé€æ­¥åœ¨PyTorchä¸­æ¨å‡ºã€‚

    æ­¤æ ‡å¿—å’Œæ•´ä¸ªç¼–è¯‘APIæ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½ä¼šåœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­å‘ç”Ÿå˜åŒ–ã€‚

+   `torch_compile_backend`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” åœ¨`torch.compile`ä¸­è¦ä½¿ç”¨çš„åç«¯ã€‚å¦‚æœè®¾ç½®ä¸ºä»»ä½•å€¼ï¼Œ`torch_compile`å°†è¢«è®¾ç½®ä¸º`True`ã€‚

    è¯·å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–å¯èƒ½çš„å€¼ï¼Œå¹¶æ³¨æ„å®ƒä»¬å¯èƒ½ä¼šéšç€PyTorchç‰ˆæœ¬çš„å˜åŒ–è€Œæ”¹å˜ã€‚

    æ­¤æ ‡å¿—æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½ä¼šåœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­å‘ç”Ÿå˜åŒ–ã€‚

+   `torch_compile_mode`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” åœ¨`torch.compile`ä¸­è¦ä½¿ç”¨çš„æ¨¡å¼ã€‚å¦‚æœè®¾ç½®ä¸ºä»»ä½•å€¼ï¼Œ`torch_compile`å°†è¢«è®¾ç½®ä¸º`True`ã€‚

    è¯·å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–å¯èƒ½çš„å€¼ï¼Œå¹¶æ³¨æ„å®ƒä»¬å¯èƒ½ä¼šéšç€PyTorchç‰ˆæœ¬çš„å˜åŒ–è€Œæ”¹å˜ã€‚

    æ­¤æ ‡å¿—æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½ä¼šåœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­å‘ç”Ÿå˜åŒ–ã€‚

+   `split_batches`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼ŒåŠ é€Ÿå™¨æ˜¯å¦åº”è¯¥åœ¨è®¾å¤‡ä¹‹é—´åˆ†å‰²æ•°æ®åŠ è½½å™¨äº§ç”Ÿçš„æ‰¹æ¬¡ã€‚å¦‚æœ

    è®¾ç½®ä¸º`True`ï¼Œå®é™…ä½¿ç”¨çš„æ‰¹é‡å¤§å°å°†åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è¿›ç¨‹ä¸Šç›¸åŒï¼Œä½†å¿…é¡»æ˜¯

    å°†å¤šä¸ªè¿›ç¨‹çš„æ•°é‡ï¼ˆä¾‹å¦‚GPUï¼‰çš„å€æ•°å››èˆäº”å…¥ã€‚

+   `include_tokens_per_second`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è®¡ç®—æ¯ä¸ªè®¾å¤‡æ¯ç§’çš„æ ‡è®°æ•°ï¼Œç”¨äºè®­ç»ƒé€Ÿåº¦æŒ‡æ ‡ã€‚

    è¿™å°†åœ¨è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¹‹å‰è¿­ä»£æ•´ä¸ªè®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸€æ¬¡ï¼Œ

    å¹¶ä¸”ä¼šå‡æ…¢æ•´ä¸ªè¿‡ç¨‹ã€‚

+   `include_num_input_tokens_seen`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¦è·Ÿè¸ªæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°çš„è¾“å…¥æ ‡è®°æ•°é‡ã€‚

    åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­å¯èƒ½ä¼šè¾ƒæ…¢ï¼Œå› ä¸ºå¿…é¡»è°ƒç”¨gatheræ“ä½œã€‚

+   `neftune_noise_alpha`ï¼ˆ`Optional[float]`ï¼‰â€” å¦‚æœä¸æ˜¯`None`ï¼Œå°†æ¿€æ´»NEFTuneå™ªå£°åµŒå…¥ã€‚è¿™å¯ä»¥æå¤§åœ°æé«˜æŒ‡å¯¼å¾®è°ƒçš„æ¨¡å‹æ€§èƒ½ã€‚æŸ¥çœ‹[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2310.05914)å’Œ[åŸå§‹ä»£ç ](https://github.com/neelsjain/NEFTune)ã€‚æ”¯æŒtransformersçš„`PreTrainedModel`å’Œpeftçš„`PeftModel`ã€‚

+   `sortish_sampler`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä½¿ç”¨*sortish sampler*ã€‚ç›®å‰ä»…åœ¨åº•å±‚æ•°æ®é›†ä¸º*Seq2SeqDataset*æ—¶æ‰å¯èƒ½ï¼Œä½†å°†åœ¨ä¸ä¹…çš„å°†æ¥æ™®éå¯ç”¨ã€‚

    æ ¹æ®é•¿åº¦å¯¹è¾“å…¥è¿›è¡Œæ’åºï¼Œä»¥æœ€å°åŒ–å¡«å……å¤§å°ï¼Œå¹¶åœ¨è®­ç»ƒé›†ä¸­åŠ å…¥ä¸€äº›éšæœºæ€§ã€‚

+   `predict_with_generate`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä½¿ç”¨ç”Ÿæˆæ¥è®¡ç®—ç”ŸæˆæŒ‡æ ‡ï¼ˆROUGEï¼ŒBLEUï¼‰ã€‚

+   `generation_max_length` (`int`, *optional*) â€” åœ¨`predict_with_generate=True`æ—¶ï¼Œåœ¨æ¯ä¸ªè¯„ä¼°å¾ªç¯ä¸­ä½¿ç”¨çš„`max_length`ã€‚å°†é»˜è®¤ä¸ºæ¨¡å‹é…ç½®çš„`max_length`å€¼ã€‚

+   `generation_num_beams` (`int`, *optional*) â€” åœ¨`predict_with_generate=True`æ—¶ï¼Œåœ¨æ¯ä¸ªè¯„ä¼°å¾ªç¯ä¸­ä½¿ç”¨çš„`num_beams`ã€‚å°†é»˜è®¤ä¸ºæ¨¡å‹é…ç½®çš„`num_beams`å€¼ã€‚

+   `generation_config` (`str`æˆ–`Path`æˆ–[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig), *optional*) â€” å…è®¸ä»`from_pretrained`æ–¹æ³•åŠ è½½ä¸€ä¸ª[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)ã€‚è¿™å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹é…ç½®çš„*æ¨¡å‹id*ï¼Œæ‰˜ç®¡åœ¨huggingface.coä¸Šçš„æ¨¡å‹å­˜å‚¨åº“å†…ã€‚æœ‰æ•ˆçš„æ¨¡å‹idå¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚

    +   ä¸€ä¸ª*ç›®å½•*çš„è·¯å¾„ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.save_pretrained)æ–¹æ³•ä¿å­˜çš„é…ç½®æ–‡ä»¶ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

    +   ä¸€ä¸ª[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)å¯¹è±¡ã€‚

TrainingArgumentsæ˜¯æˆ‘ä»¬åœ¨ç¤ºä¾‹è„šæœ¬ä¸­ä½¿ç”¨çš„ä¸è®­ç»ƒå¾ªç¯æœ¬èº«ç›¸å…³çš„å‚æ•°çš„å­é›†ã€‚

ä½¿ç”¨[HfArgumentParser](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.HfArgumentParser)ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªç±»è½¬æ¢ä¸ºå¯ä»¥åœ¨å‘½ä»¤è¡Œä¸ŠæŒ‡å®šçš„[argparse](https://docs.python.org/3/library/argparse#module-argparse)å‚æ•°ã€‚

#### `to_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/training_args_seq2seq.py#L87)

```py
( )
```

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ï¼Œå°†`Enum`æ›¿æ¢ä¸ºå®ƒä»¬çš„å€¼ï¼Œå°†`GenerationConfig`æ›¿æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºJSONåºåˆ—åŒ–æ”¯æŒï¼‰ã€‚é€šè¿‡åˆ é™¤å…¶å€¼æ¥æ··æ·†æ ‡è®°å€¼ã€‚
