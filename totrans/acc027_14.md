# å¤„ç†æ¨æ–­çš„å¤§æ¨¡å‹

> åŸæ–‡ï¼š[https://huggingface.co/docs/accelerate/usage_guides/big_modeling](https://huggingface.co/docs/accelerate/usage_guides/big_modeling)

ğŸ¤— Accelerateæä¾›çš„æœ€å¤§çš„è¿›æ­¥ä¹‹ä¸€æ˜¯[å¤§å‹æ¨¡å‹æ¨æ–­](../concept_guides/big_model_inference)çš„æ¦‚å¿µï¼Œæ‚¨å¯ä»¥åœ¨æ— æ³•å®Œå…¨é€‚åº”æ‚¨çš„æ˜¾å¡çš„æ¨¡å‹ä¸Šæ‰§è¡Œ*æ¨æ–­*ã€‚

æœ¬æ•™ç¨‹å°†åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œå±•ç¤ºå¦‚ä½•åŒæ—¶ä½¿ç”¨ğŸ¤— Accelerateå’ŒğŸ¤— Transformersï¼ˆæ›´é«˜çº§åˆ«çš„APIï¼‰æ¥åˆ©ç”¨è¿™ä¸ªæƒ³æ³•ã€‚

## ä½¿ç”¨ğŸ¤— Accelerate

å¯¹äºè¿™äº›æ•™ç¨‹ï¼Œæˆ‘ä»¬å°†å‡è®¾ä¸€ä¸ªå…¸å‹çš„å·¥ä½œæµç¨‹ï¼Œç”¨äºåŠ è½½æ‚¨çš„æ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
import torch

my_model = ModelClass(...)
state_dict = torch.load(checkpoint_file)
my_model.load_state_dict(state_dict)
```

è¯·æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬å‡è®¾`ModelClass`æ˜¯ä¸€ä¸ªå ç”¨æ¯”è®¾å¤‡ï¼ˆæ— è®ºæ˜¯`mps`è¿˜æ˜¯`cuda`ï¼‰ä¸Šå¯å®¹çº³çš„è§†é¢‘å†…å­˜æ›´å¤šçš„æ¨¡å‹ã€‚

ç¬¬ä¸€æ­¥æ˜¯åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹çš„ç©ºéª¨æ¶ï¼Œä½¿ç”¨[init_empty_weights()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.init_empty_weights)ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè¿™æ ·ä¸ä¼šå ç”¨ä»»ä½•RAMï¼š

```py
from accelerate import init_empty_weights
with init_empty_weights():
    my_model = ModelClass(...)
```

ç›®å‰è¿™ä¸ª`my_model`æ˜¯â€œæ— å‚æ•°â€çš„ï¼Œå› æ­¤æ¯”ç›´æ¥åŠ è½½åˆ°CPUä¸Šç•™ä¸‹äº†æ›´å°çš„å°è®°ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦åŠ è½½æƒé‡åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œä»¥ä¾¿è¿›è¡Œæ¨æ–­ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[load_checkpoint_and_dispatch()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.load_checkpoint_and_dispatch)ï¼Œå¦‚å…¶åç§°æ‰€ç¤ºï¼Œå°†åœ¨æ‚¨çš„ç©ºæ¨¡å‹å†…åŠ è½½ä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œå¹¶å°†æ¯ä¸ªå±‚çš„æƒé‡åˆ†é…åˆ°æ‚¨å¯ç”¨çš„æ‰€æœ‰è®¾å¤‡ï¼ˆGPU/MPSå’ŒCPU RAMï¼‰ä¸Šã€‚

è¦ç¡®å®šå¦‚ä½•æ‰§è¡Œè¿™ä¸ª`dispatch`ï¼Œé€šå¸¸æŒ‡å®š`device_map="auto"`å°±è¶³å¤Ÿäº†ï¼Œå› ä¸ºğŸ¤— Accelerateä¼šå°è¯•å¡«æ»¡GPU(s)ä¸Šçš„æ‰€æœ‰ç©ºé—´ï¼Œç„¶ååŠ è½½åˆ°CPUï¼Œæœ€åå¦‚æœå†…å­˜ä¸å¤Ÿï¼Œå®ƒå°†è¢«åŠ è½½åˆ°ç£ç›˜ï¼ˆç»å¯¹æœ€æ…¢çš„é€‰é¡¹ï¼‰ã€‚

æœ‰å…³è®¾è®¡è‡ªå·±çš„è®¾å¤‡æ˜ å°„çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æ¦‚å¿µæŒ‡å—](../concept_guide/big_model_inference#designing-a-device-map)çš„æœ¬èŠ‚

çœ‹ä¸‹é¢çš„ç¤ºä¾‹ï¼š

```py
from accelerate import load_checkpoint_and_dispatch

model = load_checkpoint_and_dispatch(
    model, checkpoint=checkpoint_file, device_map="auto"
)
```

å¦‚æœæœ‰æŸäº›â€œå—â€å±‚ä¸åº”è¯¥è¢«åˆ†å‰²ï¼Œæ‚¨å¯ä»¥å°†å®ƒä»¬ä½œä¸º`no_split_module_classes`ä¼ é€’ã€‚äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](../concept_guides/big_model_inference#loading-weights)

æ­¤å¤–ï¼Œä¸ºäº†èŠ‚çœå†…å­˜ï¼ˆä¾‹å¦‚å¦‚æœ`state_dict`æ— æ³•é€‚åº”RAMï¼‰ï¼Œæ¨¡å‹çš„æƒé‡å¯ä»¥åˆ†å‰²å¹¶æ‹†åˆ†ä¸ºå¤šä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶ã€‚äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](../concept_guides/big_model_inference#sharded-checkpoints)

ç°åœ¨æ¨¡å‹å·²ç»å®Œå…¨åˆ†å‘ï¼Œæ‚¨å¯ä»¥åƒæ­£å¸¸æƒ…å†µä¸‹ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼š

```py
input = torch.randn(2,3)
input = input.to("cuda")
output = model(input)
```

ç°åœ¨æ¯æ¬¡è¾“å…¥é€šè¿‡ä¸€ä¸ªå±‚æ—¶ï¼Œå®ƒå°†ä»CPUå‘é€åˆ°GPUï¼ˆæˆ–ä»ç£ç›˜åˆ°CPUåˆ°GPUï¼‰ï¼Œè®¡ç®—è¾“å‡ºï¼Œç„¶åå°†è¯¥å±‚ä»GPUæ‹‰å›åˆ°çº¿è·¯ä¸‹æ–¹ã€‚è™½ç„¶è¿™ä¼šå¢åŠ æ‰§è¡Œæ¨æ–­çš„å¼€é”€ï¼Œä½†é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œå¯ä»¥åœ¨æ‚¨çš„ç³»ç»Ÿä¸Šè¿è¡Œ**ä»»ä½•å¤§å°çš„æ¨¡å‹**ï¼Œåªè¦æœ€å¤§çš„å±‚èƒ½å¤Ÿé€‚åˆåœ¨æ‚¨çš„GPUä¸Šã€‚

å¤šä¸ªGPUå¯ä»¥è¢«åˆ©ç”¨ï¼Œä½†è¿™è¢«è®¤ä¸ºæ˜¯â€œæ¨¡å‹å¹¶è¡Œâ€ï¼Œå› æ­¤åœ¨ä»»ä½•ç»™å®šæ—¶åˆ»åªæœ‰ä¸€ä¸ªGPUä¼šå¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œç­‰å¾…å‰ä¸€ä¸ªGPUå‘é€è¾“å‡ºã€‚æ‚¨åº”è¯¥æ­£å¸¸å¯åŠ¨æ‚¨çš„è„šæœ¬ä½¿ç”¨`python`ï¼Œè€Œä¸éœ€è¦`torchrun`ï¼Œ`accelerate launch`ç­‰ã€‚

è¦æŸ¥çœ‹æ­¤å†…å®¹çš„å¯è§†åŒ–è¡¨ç¤ºï¼Œè¯·æŸ¥çœ‹ä¸‹é¢çš„åŠ¨ç”»ï¼š

[https://www.youtube-nocookie.com/embed/MWCSGj9jEAo](https://www.youtube-nocookie.com/embed/MWCSGj9jEAo)

### å®Œæ•´ç¤ºä¾‹

ä»¥ä¸‹æ˜¯å®Œæ•´ç¤ºä¾‹ï¼Œå±•ç¤ºæˆ‘ä»¬ä¸Šé¢æ‰§è¡Œçš„æ“ä½œï¼š

```py
import torch
from accelerate import init_empty_weights, load_checkpoint_and_dispatch

with init_empty_weights():
    model = MyModel(...)

model = load_checkpoint_and_dispatch(
    model, checkpoint=checkpoint_file, device_map="auto"
)

input = torch.randn(2,3)
input = input.to("cuda")
output = model(input)
```

## ä½¿ç”¨ğŸ¤— Transformersï¼ŒğŸ¤— Diffuserså’Œå…¶ä»–ğŸ¤—å¼€æºåº“

æ”¯æŒğŸ¤— Accelerateå¤§å‹æ¨¡å‹æ¨æ–­çš„åº“åŒ…æ‹¬å®ƒä»¬çš„`from_pretrained`æ„é€ å‡½æ•°ä¸­çš„æ‰€æœ‰å…ˆå‰é€»è¾‘ã€‚

é€šè¿‡æŒ‡å®šä¸€ä¸ªè¡¨ç¤ºè¦ä»[ğŸ¤— Hub](https://hf.co/models)ä¸‹è½½çš„æ¨¡å‹çš„å­—ç¬¦ä¸²ï¼Œç„¶åä½¿ç”¨`device_map="auto"`ä»¥åŠä¸€äº›é¢å¤–çš„å‚æ•°æ¥æ“ä½œã€‚

ä½œä¸ºä¸€ä¸ªç®€çŸ­çš„ä¾‹å­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä½¿ç”¨`transformers`åŠ è½½Big Scienceçš„T0ppæ¨¡å‹ã€‚

```py
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0pp", device_map="auto")
```

åŠ è½½æ¨¡å‹åï¼Œä¹‹å‰å‡†å¤‡æ¨¡å‹çš„åˆå§‹æ­¥éª¤éƒ½å·²å®Œæˆï¼Œæ¨¡å‹å·²å®Œå…¨å‡†å¤‡å¥½åˆ©ç”¨æœºå™¨ä¸­çš„æ‰€æœ‰èµ„æºã€‚é€šè¿‡è¿™äº›æ„é€ å‡½æ•°ï¼Œæ‚¨è¿˜å¯ä»¥é€šè¿‡æŒ‡å®šæ¨¡å‹åŠ è½½çš„ç²¾åº¦æ¥èŠ‚çœ*æ›´å¤š*å†…å­˜ï¼Œé€šè¿‡`torch_dtype`å‚æ•°ï¼Œä¾‹å¦‚ï¼š

```py
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0pp", device_map="auto", torch_dtype=torch.float16)
```

è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[è¿™é‡Œæä¾›çš„ğŸ¤— Transformersæ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/main_classes/model#large-model-loading)ã€‚

## æ¥ä¸‹æ¥è¯¥å»å“ªé‡Œ

å¯¹äºæ›´è¯¦ç»†çš„å¤§æ¨¡å‹æ¨æ–­ï¼Œè¯·åŠ¡å¿…æŸ¥çœ‹[å…³äºå®ƒçš„æ¦‚å¿µæŒ‡å—](../concept_guides/big_model_inference)
