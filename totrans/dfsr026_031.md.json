["```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\nfrom diffusers.utils import make_image_grid\n```", "```py\npretrained_model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\nrepo_id_embeds = \"sd-concepts-library/cat-toy\"\n```", "```py\npipeline = StableDiffusionPipeline.from_pretrained(\n    pretrained_model_name_or_path, torch_dtype=torch.float16, use_safetensors=True\n).to(\"cuda\")\n\npipeline.load_textual_inversion(repo_id_embeds)\n```", "```py\nprompt = \"a grafitti in a favela wall with a <cat-toy> on it\"\n\nnum_samples_per_row = 2\nnum_rows = 2\n```", "```py\nall_images = []\nfor _ in range(num_rows):\n    images = pipeline(prompt, num_images_per_prompt=num_samples_per_row, num_inference_steps=50, guidance_scale=7.5).images\n    all_images.extend(images)\n\ngrid = make_image_grid(all_images, num_rows, num_samples_per_row)\ngrid\n```", "```py\nfrom huggingface_hub import hf_hub_download\nfrom safetensors.torch import load_file\n\nfile = hf_hub_download(\"dn118/unaestheticXL\", filename=\"unaestheticXLv31.safetensors\")\nstate_dict = load_file(file)\nstate_dict\n```", "```py\n{'clip_g': tensor([[ 0.0077, -0.0112,  0.0065,  ...,  0.0195,  0.0159,  0.0275],\n         ...,\n         [-0.0170,  0.0213,  0.0143,  ..., -0.0302, -0.0240, -0.0362]],\n 'clip_l': tensor([[ 0.0023,  0.0192,  0.0213,  ..., -0.0385,  0.0048, -0.0011],\n         ...,\n         [ 0.0475, -0.0508, -0.0145,  ...,  0.0070, -0.0089, -0.0163]],\n```", "```py\nfrom diffusers import AutoPipelineForText2Image\nimport torch\n\npipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", variant=\"fp16\", torch_dtype=torch.float16)\npipe.to(\"cuda\")\n\npipe.load_textual_inversion(state_dict[\"clip_g\"], token=\"unaestheticXLv31\", text_encoder=pipe.text_encoder_2, tokenizer=pipe.tokenizer_2)\npipe.load_textual_inversion(state_dict[\"clip_l\"], token=\"unaestheticXLv31\", text_encoder=pipe.text_encoder, tokenizer=pipe.tokenizer)\n\n# the embedding should be used as a negative embedding, so we pass it as a negative prompt\ngenerator = torch.Generator().manual_seed(33)\nimage = pipe(\"a woman standing in front of a mountain\", negative_prompt=\"unaestheticXLv31\", generator=generator).images[0]\nimage\n```"]