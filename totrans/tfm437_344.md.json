["```py\n>>> import re\n\n>>> from transformers import DonutProcessor, VisionEncoderDecoderModel\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-rvlcdip\")\n>>> model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-rvlcdip\")\n\n>>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n>>> model.to(device)\n>>> # load document image\n>>> dataset = load_dataset(\"hf-internal-testing/example-documents\", split=\"test\")\n>>> image = dataset[1][\"image\"]\n\n>>> # prepare decoder inputs\n>>> task_prompt = \"<s_rvlcdip>\"\n>>> decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n\n>>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n\n>>> outputs = model.generate(\n...     pixel_values.to(device),\n...     decoder_input_ids=decoder_input_ids.to(device),\n...     max_length=model.decoder.config.max_position_embeddings,\n...     pad_token_id=processor.tokenizer.pad_token_id,\n...     eos_token_id=processor.tokenizer.eos_token_id,\n...     use_cache=True,\n...     bad_words_ids=[[processor.tokenizer.unk_token_id]],\n...     return_dict_in_generate=True,\n... )\n\n>>> sequence = processor.batch_decode(outputs.sequences)[0]\n>>> sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n>>> sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n>>> print(processor.token2json(sequence))\n{'class': 'advertisement'}\n```", "```py\n>>> import re\n\n>>> from transformers import DonutProcessor, VisionEncoderDecoderModel\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n>>> model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n\n>>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n>>> model.to(device)\n>>> # load document image\n>>> dataset = load_dataset(\"hf-internal-testing/example-documents\", split=\"test\")\n>>> image = dataset[2][\"image\"]\n\n>>> # prepare decoder inputs\n>>> task_prompt = \"<s_cord-v2>\"\n>>> decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n\n>>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n\n>>> outputs = model.generate(\n...     pixel_values.to(device),\n...     decoder_input_ids=decoder_input_ids.to(device),\n...     max_length=model.decoder.config.max_position_embeddings,\n...     pad_token_id=processor.tokenizer.pad_token_id,\n...     eos_token_id=processor.tokenizer.eos_token_id,\n...     use_cache=True,\n...     bad_words_ids=[[processor.tokenizer.unk_token_id]],\n...     return_dict_in_generate=True,\n... )\n\n>>> sequence = processor.batch_decode(outputs.sequences)[0]\n>>> sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n>>> sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n>>> print(processor.token2json(sequence))\n{'menu': {'nm': 'CINNAMON SUGAR', 'unitprice': '17,000', 'cnt': '1 x', 'price': '17,000'}, 'sub_total': {'subtotal_price': '17,000'}, 'total': {'total_price': '17,000', 'cashprice': '20,000', 'changeprice': '3,000'}}\n```", "```py\n>>> import re\n\n>>> from transformers import DonutProcessor, VisionEncoderDecoderModel\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-docvqa\")\n>>> model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-docvqa\")\n\n>>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n>>> model.to(device)\n>>> # load document image from the DocVQA dataset\n>>> dataset = load_dataset(\"hf-internal-testing/example-documents\", split=\"test\")\n>>> image = dataset[0][\"image\"]\n\n>>> # prepare decoder inputs\n>>> task_prompt = \"<s_docvqa><s_question>{user_input}</s_question><s_answer>\"\n>>> question = \"When is the coffee break?\"\n>>> prompt = task_prompt.replace(\"{user_input}\", question)\n>>> decoder_input_ids = processor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n\n>>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n\n>>> outputs = model.generate(\n...     pixel_values.to(device),\n...     decoder_input_ids=decoder_input_ids.to(device),\n...     max_length=model.decoder.config.max_position_embeddings,\n...     pad_token_id=processor.tokenizer.pad_token_id,\n...     eos_token_id=processor.tokenizer.eos_token_id,\n...     use_cache=True,\n...     bad_words_ids=[[processor.tokenizer.unk_token_id]],\n...     return_dict_in_generate=True,\n... )\n\n>>> sequence = processor.batch_decode(outputs.sequences)[0]\n>>> sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n>>> sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n>>> print(processor.token2json(sequence))\n{'question': 'When is the coffee break?', 'answer': '11-14 to 11:39 a.m.'}\n```", "```py\n>>> from transformers import DonutSwinConfig, DonutSwinModel\n\n>>> # Initializing a Donut naver-clova-ix/donut-base style configuration\n>>> configuration = DonutSwinConfig()\n\n>>> # Randomly initializing a model from the naver-clova-ix/donut-base style configuration\n>>> model = DonutSwinModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoImageProcessor, DonutSwinModel\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"https://huggingface.co/naver-clova-ix/donut-base\")\n>>> model = DonutSwinModel.from_pretrained(\"https://huggingface.co/naver-clova-ix/donut-base\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 49, 768]\n```"]