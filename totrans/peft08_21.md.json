["```py\naccelerate config --config_file ds_zero3_cpu.yaml\n```", "```py\n`zero_stage`: [0] Disabled, [1] optimizer state partitioning, [2] optimizer+gradient state partitioning and [3] optimizer+gradient+parameter partitioning\n`gradient_accumulation_steps`: Number of training steps to accumulate gradients before averaging and applying them.\n`gradient_clipping`: Enable gradient clipping with value.\n`offload_optimizer_device`: [none] Disable optimizer offloading, [cpu] offload optimizer to CPU, [nvme] offload optimizer to NVMe SSD. Only applicable with ZeRO >= Stage-2.\n`offload_param_device`: [none] Disable parameter offloading, [cpu] offload parameters to CPU, [nvme] offload parameters to NVMe SSD. Only applicable with ZeRO Stage-3.\n`zero3_init_flag`: Decides whether to enable `deepspeed.zero.Init` for constructing massive models. Only applicable with ZeRO Stage-3.\n`zero3_save_16bit_model`: Decides whether to save 16-bit model weights when using ZeRO Stage-3.\n`mixed_precision`: `no` for FP32 training, `fp16` for FP16 mixed-precision training and `bf16` for BF16 mixed-precision training. \n```", "```py\ncompute_environment: LOCAL_MACHINE\ndeepspeed_config:\n  gradient_accumulation_steps: 1\n  gradient_clipping: 1.0\n  offload_optimizer_device: cpu\n  offload_param_device: cpu\n  zero3_init_flag: true\n  zero3_save_16bit_model: true\n  zero_stage: 3\ndistributed_type: DEEPSPEED\ndowncast_bf16: 'no'\ndynamo_backend: 'NO'\nfsdp_config: {}\nmachine_rank: 0\nmain_training_function: main\nmegatron_lm_config: {}\nmixed_precision: 'no'\nnum_machines: 1\nnum_processes: 1\nrdzv_backend: static\nsame_network: true\nuse_cpu: false\n```", "```py\n def main():\n+    accelerator = Accelerator()\n     model_name_or_path = \"facebook/bart-large\"\n     dataset_name = \"twitter_complaints\"\n+    peft_config = LoraConfig(\n         task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n     )\n```", "```py\n  model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n+ model = get_peft_model(model, peft_config)\n```", "```py\nmodel, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler = accelerator.prepare(\n    model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler\n)\n```", "```py\nis_ds_zero_3 = False\nif getattr(accelerator.state, \"deepspeed_plugin\", None):\n    is_ds_zero_3 = accelerator.state.deepspeed_plugin.zero_stage == 3\n```", "```py\n  for epoch in range(num_epochs):\n      with TorchTracemalloc() as tracemalloc:\n          model.train()\n          total_loss = 0\n          for step, batch in enumerate(tqdm(train_dataloader)):\n              outputs = model(**batch)\n              loss = outputs.loss\n              total_loss += loss.detach().float()\n+             accelerator.backward(loss)\n              optimizer.step()\n              lr_scheduler.step()\n              optimizer.zero_grad()\n```", "```py\naccelerate launch --config_file ds_zero3_cpu.yaml examples/peft_lora_seq2seq_accelerate_ds_zero3_offload.py\n```", "```py\nGPU Memory before entering the train : 1916\nGPU Memory consumed at the end of the train (end-begin): 66\nGPU Peak Memory consumed during the train (max-begin): 7488\nGPU Total Peak Memory consumed during the train (max): 9404\nCPU Memory before entering the train : 19411\nCPU Memory consumed at the end of the train (end-begin): 0\nCPU Peak Memory consumed during the train (max-begin): 0\nCPU Total Peak Memory consumed during the train (max): 19411\nepoch=4: train_ppl=tensor(1.0705, device='cuda:0') train_epoch_loss=tensor(0.0681, device='cuda:0')\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:27<00:00,  3.92s/it]\nGPU Memory before entering the eval : 1982\nGPU Memory consumed at the end of the eval (end-begin): -66\nGPU Peak Memory consumed during the eval (max-begin): 672\nGPU Total Peak Memory consumed during the eval (max): 2654\nCPU Memory before entering the eval : 19411\nCPU Memory consumed at the end of the eval (end-begin): 0\nCPU Peak Memory consumed during the eval (max-begin): 0\nCPU Total Peak Memory consumed during the eval (max): 19411\naccuracy=100.0\neval_preds[:10]=['no complaint', 'no complaint', 'complaint', 'complaint', 'no complaint', 'no complaint', 'no complaint', 'complaint', 'complaint', 'no complaint']\ndataset['train'][label_column][:10]=['no complaint', 'no complaint', 'complaint', 'complaint', 'no complaint', 'no complaint', 'no complaint', 'complaint', 'complaint', 'no complaint']\n```"]