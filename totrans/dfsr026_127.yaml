- en: Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/overview](https://huggingface.co/docs/diffusers/api/pipelines/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines provide a simple way to run state-of-the-art diffusion models in inference
    by bundling all of the necessary components (multiple independently-trained models,
    schedulers, and processors) into a single end-to-end class. Pipelines are flexible
    and they can be adapted to use different schedulers or even model components.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: All pipelines are built from the base [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    class which provides basic functionality for loading, downloading, and saving
    all the components. Specific pipeline types (for example [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline))
    loaded with [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    are automatically detected and the pipeline components are loaded and passed to
    the `__init__` function of the pipeline.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: You shouldnâ€™t use the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    class for training. Individual components (for example, [UNet2DModel](/docs/diffusers/v0.26.3/en/api/models/unet2d#diffusers.UNet2DModel)
    and [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    of diffusion pipelines are usually trained individually, so we suggest directly
    working with them instead.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines do not offer any training functionality. Youâ€™ll notice PyTorchâ€™s autograd
    is disabled by decorating the `__call__()` method with a [`torch.no_grad`](https://pytorch.org/docs/stable/generated/torch.no_grad.html)
    decorator because pipelines should not be used for training. If youâ€™re interested
    in training, please take a look at the [Training](../../training/overview) guides
    instead!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: The table below lists all the pipelines currently available in ğŸ¤— Diffusers and
    the tasks they support. Click on a pipeline to view its abstract and published
    paper.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '| Pipeline | Tasks |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| [AltDiffusion](alt_diffusion) | image2image |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| [AnimateDiff](animatediff) | text2video |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| [Attend-and-Excite](attend_and_excite) | text2image |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: '| [Audio Diffusion](audio_diffusion) | image2audio |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| [AudioLDM](audioldm) | text2audio |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: '| [AudioLDM2](audioldm2) | text2audio |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
- en: '| [BLIP Diffusion](blip_diffusion) | text2image |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| [Consistency Models](consistency_models) | unconditional image generation
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet](controlnet) | text2image, image2image, inpainting |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet with Stable Diffusion XL](controlnet_sdxl) | text2image |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet-XS](controlnetxs) | text2image |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet-XS with Stable Diffusion XL](controlnetxs_sdxl) | text2image
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
- en: '| [Cycle Diffusion](cycle_diffusion) | image2image |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| [Dance Diffusion](dance_diffusion) | unconditional audio generation |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| [DDIM](ddim) | unconditional image generation |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| [DDPM](ddpm) | unconditional image generation |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| [DeepFloyd IF](deepfloyd_if) | text2image, image2image, inpainting, super-resolution
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| [DiffEdit](diffedit) | inpainting |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| [DiT](dit) | text2image |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| [GLIGEN](stable_diffusion/gligen) | text2image |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| [InstructPix2Pix](pix2pix) | image editing |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 2.1](kandinsky) | text2image, image2image, inpainting, interpolation
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 2.2](kandinsky_v22) | text2image, image2image, inpainting |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 3](kandinsky3) | text2image, image2image |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| [Latent Consistency Models](latent_consistency_models) | text2image |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: '| [Latent Diffusion](latent_diffusion) | text2image, super-resolution |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: '| [LDM3D](stable_diffusion/ldm3d_diffusion) | text2image, text-to-3D, text-to-pano,
    upscaling |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
- en: '| [MultiDiffusion](panorama) | text2image |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| [MusicLDM](musicldm) | text2audio |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| [Paint by Example](paint_by_example) | inpainting |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| [ParaDiGMS](paradigms) | text2image |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| [Pix2Pix Zero](pix2pix_zero) | image editing |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| [PixArt-Î±](pixart) | text2image |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| [PNDM](pndm) | unconditional image generation |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| [RePaint](repaint) | inpainting |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| [Score SDE VE](score_sde_ve) | unconditional image generation |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| [Self-Attention Guidance](self_attention_guidance) | text2image |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| [Semantic Guidance](semantic_stable_diffusion) | text2image |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| [Shap-E](shap_e) | text-to-3D, image-to-3D |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| [Spectrogram Diffusion](spectrogram_diffusion) |  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion](stable_diffusion/overview) | text2image, image2image,
    depth2image, inpainting, image variation, latent upscaler, super-resolution |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion Model Editing](model_editing) | model editing |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion XL](stable_diffusion/stable_diffusion_xl) | text2image,
    image2image, inpainting |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion XL Turbo](stable_diffusion/sdxl_turbo) | text2image, image2image,
    inpainting |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| [Stable unCLIP](stable_unclip) | text2image, image variation |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| [Stochastic Karras VE](stochastic_karras_ve) | unconditional image generation
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| [T2I-Adapter](stable_diffusion/adapter) | text2image |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| [Text2Video](text_to_video) | text2video, video2video |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| [Text2Video-Zero](text_to_video_zero) | text2video |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| [unCLIP](unclip) | text2image, image variation |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| [Unconditional Latent Diffusion](latent_diffusion_uncond) | unconditional
    image generation |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| [UniDiffuser](unidiffuser) | text2image, image2text, image variation, text
    variation, unconditional image generation, unconditional audio generation |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| [Value-guided planning](value_guided_sampling) | value guided sampling |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| [Versatile Diffusion](versatile_diffusion) | text2image, image variation
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| [VQ Diffusion](vq_diffusion) | text2image |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| [Wuerstchen](wuerstchen) | text2image |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: DiffusionPipeline
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.DiffusionPipeline`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L569)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Base class for all pipelines.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    stores all components (models, schedulers, and processors) for diffusion pipelines
    and provides methods for loading, downloading and saving models. It also includes
    methods to:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: move all PyTorch modules to the device of your choice
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: enable/disable the progress bar for the denoising iteration
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class attributes:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '`config_name` (`str`) â€” The configuration filename that stores the class and
    module names of all the diffusion pipelineâ€™s components.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_optional_components` (`List[str]`) â€” List of all optional components that
    donâ€™t have to be passed to the pipeline to function (should be overridden by subclasses).'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Call self as a function.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '#### `device`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L901)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Returns
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.device`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The torch device on which the pipeline is located.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '#### `to`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L742)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '`dtype` (`torch.dtype`, *optional*) â€” Returns a pipeline with the specified
    [`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`torch.Device`, *optional*) â€” Returns a pipeline with the specified
    [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`silence_dtype_warnings` (`str`, *optional*, defaults to `False`) â€” Whether
    to omit warnings if the target `dtype` is not compatible with the target `device`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline converted to specified `dtype` and/or `dtype`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Performs Pipeline dtype and/or device conversion. A torch.dtype and torch.device
    are inferred from the arguments of `self.to(*args, **kwargs).`
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: If the pipeline already has the correct torch.dtype and torch.device, then it
    is returned as is. Otherwise, the returned pipeline is a copy of self with the
    desired torch.dtype and torch.device.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœç®¡é“å·²ç»å…·æœ‰æ­£ç¡®çš„torch.dtypeå’Œtorch.deviceï¼Œåˆ™è¿”å›åŸæ ·ã€‚å¦åˆ™ï¼Œè¿”å›çš„ç®¡é“æ˜¯å…·æœ‰æ‰€éœ€torch.dtypeå’Œtorch.deviceçš„selfçš„å‰¯æœ¬ã€‚
- en: 'Here are the ways to call `to`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯è°ƒç”¨`to`çš„æ–¹æ³•ï¼š
- en: '`to(dtype, silence_dtype_warnings=False) â†’ DiffusionPipeline` to return a pipeline
    with the specified [`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to(dtype, silence_dtype_warnings=False) â†’ DiffusionPipeline` è¿”å›å…·æœ‰æŒ‡å®š[`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)çš„ç®¡é“ã€‚'
- en: '`to(device, silence_dtype_warnings=False) â†’ DiffusionPipeline` to return a
    pipeline with the specified [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to(device, silence_dtype_warnings=False) â†’ DiffusionPipeline` è¿”å›å…·æœ‰æŒ‡å®š[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)çš„ç®¡é“ã€‚'
- en: '`to(device=None, dtype=None, silence_dtype_warnings=False) â†’ DiffusionPipeline`
    to return a pipeline with the specified [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)
    and [`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to(device=None, dtype=None, silence_dtype_warnings=False) â†’ DiffusionPipeline`
    è¿”å›å…·æœ‰æŒ‡å®š[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)å’Œ[`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)çš„ç®¡é“ã€‚'
- en: '#### `components`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `components`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1941)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1941)'
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `self.components` property can be useful to run different pipelines with
    the same weights and configurations without reallocating additional memory.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.components`å±æ€§å¯ç”¨äºä½¿ç”¨ç›¸åŒçš„æƒé‡å’Œé…ç½®è¿è¡Œä¸åŒçš„ç®¡é“ï¼Œè€Œæ— éœ€é‡æ–°åˆ†é…é¢å¤–çš„å†…å­˜ã€‚'
- en: 'Returns (`dict`): A dictionary containing all the modules needed to initialize
    the pipeline.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¿”å› (`dict`): åŒ…å«åˆå§‹åŒ–ç®¡é“æ‰€éœ€çš„æ‰€æœ‰æ¨¡å—çš„å­—å…¸ã€‚'
- en: 'Examples:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `disable_attention_slicing`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Disable sliced attention computation. If `enable_attention_slicing` was previously
    called, attention is computed in one step.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚
- en: '#### `download`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1552)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1552)'
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name` (`str` or `os.PathLike`, *optional*) â€” A string, the
    *repository id* (for example `CompVis/ldm-text2im-large-256`) of a pretrained
    pipeline hosted on the Hub.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name` (`str` æˆ– `os.PathLike`, *optional*) â€” ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç®¡é“çš„*å­˜å‚¨åº“id*ï¼ˆä¾‹å¦‚
    `CompVis/ldm-text2im-large-256`ï¼‰ï¼Œæ‰˜ç®¡åœ¨Hubä¸Šã€‚'
- en: '`custom_pipeline` (`str`, *optional*) â€” Can be either:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_pipeline` (`str`, *optional*) â€” å¯ä»¥æ˜¯ï¼š'
- en: A string, the *repository id* (for example `CompVis/ldm-text2im-large-256`)
    of a pretrained pipeline hosted on the Hub. The repository must contain a file
    called `pipeline.py` that defines the custom pipeline.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç®¡é“çš„*å­˜å‚¨åº“id*ï¼ˆä¾‹å¦‚ `CompVis/ldm-text2im-large-256`ï¼‰ï¼Œæ‰˜ç®¡åœ¨Hubä¸Šã€‚å­˜å‚¨åº“å¿…é¡»åŒ…å«ä¸€ä¸ªåä¸º`pipeline.py`çš„æ–‡ä»¶ï¼Œå®šä¹‰äº†è‡ªå®šä¹‰ç®¡é“ã€‚
- en: A string, the *file name* of a community pipeline hosted on GitHub under [Community](https://github.com/huggingface/diffusers/tree/main/examples/community).
    Valid file names must match the file name and not the pipeline script (`clip_guided_stable_diffusion`
    instead of `clip_guided_stable_diffusion.py`). Community pipelines are always
    loaded from the current `main` branch of GitHub.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨GitHubçš„[Community](https://github.com/huggingface/diffusers/tree/main/examples/community)ä¸‹çš„ç¤¾åŒºç®¡é“çš„*æ–‡ä»¶å*ã€‚æœ‰æ•ˆçš„æ–‡ä»¶åå¿…é¡»åŒ¹é…æ–‡ä»¶åè€Œä¸æ˜¯ç®¡é“è„šæœ¬ï¼ˆ`clip_guided_stable_diffusion`è€Œä¸æ˜¯`clip_guided_stable_diffusion.py`ï¼‰ã€‚ç¤¾åŒºç®¡é“å§‹ç»ˆä»GitHubçš„å½“å‰`main`åˆ†æ”¯åŠ è½½ã€‚
- en: A path to a *directory* (`./my_pipeline_directory/`) containing a custom pipeline.
    The directory must contain a file called `pipeline.py` that defines the custom
    pipeline.
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘åŒ…å«è‡ªå®šä¹‰ç®¡é“çš„*ç›®å½•*ï¼ˆ`./my_pipeline_directory/`ï¼‰çš„è·¯å¾„ã€‚è¯¥ç›®å½•å¿…é¡»åŒ…å«ä¸€ä¸ªåä¸º`pipeline.py`çš„æ–‡ä»¶ï¼Œå®šä¹‰äº†è‡ªå®šä¹‰ç®¡é“ã€‚
- en: ğŸ§ª This is an experimental feature and may change in the future.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ§ª è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œå¯èƒ½ä¼šåœ¨æœªæ¥æ›´æ”¹ã€‚
- en: For more information on how to load and create custom pipelines, take a look
    at [How to contribute a community pipeline](https://huggingface.co/docs/diffusers/main/en/using-diffusers/contribute_pipeline).
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³å¦‚ä½•åŠ è½½å’Œåˆ›å»ºè‡ªå®šä¹‰ç®¡é“çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[å¦‚ä½•è´¡çŒ®ç¤¾åŒºç®¡é“](https://huggingface.co/docs/diffusers/main/en/using-diffusers/contribute_pipeline)ã€‚
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™åˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼Œ`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†æœåŠ¡å™¨åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) â€” Whether or not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`custom_revision` (`str`, *optional*, defaults to `"main"`) â€” The specific
    model version to use. It can be a branch name, a tag name, or a commit id similar
    to `revision` when loading a custom pipeline from the Hub. It can be a ğŸ¤— Diffusers
    version when loading a custom pipeline from GitHub, otherwise it defaults to `"main"`
    when loading from the Hub.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variant` (`str`, *optional*) â€” Load weights from a specified variant filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) â€” If set to `None`,
    the safetensors weights are downloaded if theyâ€™re available **and** if the safetensors
    library is installed. If set to `True`, the model is forcibly loaded from safetensors
    weights. If set to `False`, safetensors weights are not loaded.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_onnx` (`bool`, *optional*, defaults to `False`) â€” If set to `True`, ONNX
    weights will always be downloaded if present. If set to `False`, ONNX weights
    will never be downloaded. By default `use_onnx` defaults to the `_is_onnx` class
    attribute which is `False` for non-ONNX pipelines and `True` for ONNX pipelines.
    ONNX weights include both files ending with `.onnx` and `.pb`.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) â€” Whether or
    not to allow for custom pipelines and components defined on the Hub in their own
    files. This option should only be set to `True` for repositories you trust and
    in which you have read the code, as it will execute code present on the Hub on
    your local machine.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '`os.PathLike`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: A path to the downloaded pipeline.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Download and cache a PyTorch diffusion pipeline from pretrained pipeline weights.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_attention_slicing`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '`slice_size` (`str` or `int`, *optional*, defaults to `"auto"`) â€” When `"auto"`,
    halves the input to the attention heads, so attention will be computed in two
    steps. If `"max"`, maximum amount of memory will be saved by running only one
    slice at a time. If a number is provided, uses as many slices as `attention_head_dim
    // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable sliced attention computation. When this option is enabled, the attention
    module splits the input tensor in slices to compute attention in several steps.
    For more than one attention head, the computation is performed sequentially over
    each head. This is useful to save some memory in exchange for a small speed decrease.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: âš ï¸ Donâ€™t enable attention slicing if youâ€™re already using `scaled_dot_product_attention`
    (SDPA) from PyTorch 2.0 or xFormers. These attention computations are already
    very memory efficient so you wonâ€™t need to enable this function. If you enable
    attention slicing with SDPA or xFormers, it can lead to serious slow downs!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `enable_model_cpu_offload`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_model_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
- en: '[PRE11]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`gpu_id` (`int`, *optional*) â€” The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id` (`int`ï¼Œ*å¯é€‰*) â€” ç”¨äºæ¨ç†çš„åŠ é€Ÿå™¨çš„IDã€‚å¦‚æœæœªæŒ‡å®šï¼Œå®ƒå°†é»˜è®¤ä¸º0ã€‚'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to â€œcudaâ€) â€” The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to â€œcudaâ€.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`torch.Device`æˆ–`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºâ€œcudaâ€) â€” ç”¨äºæ¨ç†çš„åŠ é€Ÿå™¨çš„PyTorchè®¾å¤‡ç±»å‹ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå®ƒå°†é»˜è®¤ä¸ºâ€œcudaâ€ã€‚'
- en: Offloads all models to CPU using accelerate, reducing memory usage with a low
    impact on performance. Compared to `enable_sequential_cpu_offload`, this method
    moves one whole model at a time to the GPU when its `forward` method is called,
    and the model remains in GPU until the next model runs. Memory savings are lower
    than with `enable_sequential_cpu_offload`, but performance is much better due
    to the iterative execution of the `unet`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŠ é€Ÿå™¨å°†æ‰€æœ‰æ¨¡å‹è½¬ç§»åˆ°CPUï¼Œå‡å°‘å†…å­˜ä½¿ç”¨é‡å¯¹æ€§èƒ½å½±å“è¾ƒå°ã€‚ä¸`enable_sequential_cpu_offload`ç›¸æ¯”ï¼Œæ­¤æ–¹æ³•åœ¨è°ƒç”¨å…¶`forward`æ–¹æ³•æ—¶ä¸€æ¬¡å°†æ•´ä¸ªæ¨¡å‹ç§»åŠ¨åˆ°GPUï¼Œå¹¶ä¸”æ¨¡å‹ä¿æŒåœ¨GPUä¸­ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹è¿è¡Œã€‚ä¸`enable_sequential_cpu_offload`ç›¸æ¯”ï¼Œå†…å­˜èŠ‚çœè¾ƒä½ï¼Œä½†ç”±äº`unet`çš„è¿­ä»£æ‰§è¡Œï¼Œæ€§èƒ½è¦å¥½å¾—å¤šã€‚
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)'
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`gpu_id` (`int`, *optional*) â€” The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id` (`int`ï¼Œ*å¯é€‰*) â€” ç”¨äºæ¨ç†çš„åŠ é€Ÿå™¨çš„IDã€‚å¦‚æœæœªæŒ‡å®šï¼Œå®ƒå°†é»˜è®¤ä¸º0ã€‚'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to â€œcudaâ€) â€” The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to â€œcudaâ€.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`torch.Device`æˆ–`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºâ€œcudaâ€) â€” ç”¨äºæ¨ç†çš„åŠ é€Ÿå™¨çš„PyTorchè®¾å¤‡ç±»å‹ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå®ƒå°†é»˜è®¤ä¸ºâ€œcudaâ€ã€‚'
- en: Offloads all models to CPU using ğŸ¤— Accelerate, significantly reducing memory
    usage. When called, the state dicts of all `torch.nn.Module` components (except
    those in `self._exclude_from_cpu_offload`) are saved to CPU and then moved to
    `torch.device('meta')` and loaded to GPU only when their specific submodule has
    its `forward` method called. Offloading happens on a submodule basis. Memory savings
    are higher than with `enable_model_cpu_offload`, but performance is lower.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ğŸ¤— Accelerateå°†æ‰€æœ‰æ¨¡å‹è½¬ç§»åˆ°CPUï¼Œæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚å½“è°ƒç”¨æ—¶ï¼Œæ‰€æœ‰`torch.nn.Module`ç»„ä»¶çš„çŠ¶æ€å­—å…¸ï¼ˆé™¤äº†`self._exclude_from_cpu_offload`ä¸­çš„ç»„ä»¶ï¼‰å°†ä¿å­˜åˆ°CPUï¼Œç„¶åç§»åŠ¨åˆ°`torch.device('meta')`ï¼Œä»…å½“å…¶ç‰¹å®šå­æ¨¡å—è°ƒç”¨å…¶`forward`æ–¹æ³•æ—¶æ‰åŠ è½½åˆ°GPUã€‚å¸è½½æ˜¯åŸºäºå­æ¨¡å—çš„ã€‚ä¸`enable_model_cpu_offload`ç›¸æ¯”ï¼Œå†…å­˜èŠ‚çœæ›´é«˜ï¼Œä½†æ€§èƒ½è¾ƒä½ã€‚
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`attention_op` (`Callable`, *optional*) â€” Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`ï¼Œ*å¯é€‰*) â€” è¦†ç›–ç”¨ä½œxFormersçš„[`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)å‡½æ•°çš„`op`å‚æ•°çš„é»˜è®¤`None`è¿ç®—ç¬¦ã€‚'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°GPUå†…å­˜ä½¿ç”¨é‡é™ä½ï¼Œå¹¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ½œåœ¨åŠ é€Ÿã€‚è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ é€Ÿä¸è¢«ä¿è¯ã€‚
- en: âš ï¸ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å½“å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›åŒæ—¶å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚
- en: 'Examples:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE14]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `from_pretrained`'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L931)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L931)'
- en: '[PRE15]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) â€” Can
    be either:'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`ï¼Œ*å¯é€‰*) â€” å¯ä»¥æ˜¯ï¼š'
- en: A string, the *repo id* (for example `CompVis/ldm-text2im-large-256`) of a pretrained
    pipeline hosted on the Hub.
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨Hubä¸Šçš„é¢„è®­ç»ƒæµæ°´çº¿çš„*repo id*ï¼ˆä¾‹å¦‚`CompVis/ldm-text2im-large-256`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_pipeline_directory/`) containing
    pipeline weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.save_pretrained).
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘ä½¿ç”¨[save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.save_pretrained)ä¿å­˜çš„æµæ°´çº¿æƒé‡çš„*ç›®å½•*çš„è·¯å¾„ï¼ˆä¾‹å¦‚`./my_pipeline_directory/`ï¼‰ã€‚
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) â€” Override the default `torch.dtype`
    and load the model with another dtype. If â€œautoâ€ is passed, the dtype is automatically
    derived from the modelâ€™s weights.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype` (`str`æˆ–`torch.dtype`ï¼Œ*å¯é€‰*) â€” è¦†ç›–é»˜è®¤çš„`torch.dtype`å¹¶ä½¿ç”¨å¦ä¸€ç§dtypeåŠ è½½æ¨¡å‹ã€‚å¦‚æœä¼ é€’â€œautoâ€ï¼Œåˆ™dtypeå°†è‡ªåŠ¨ä»æ¨¡å‹çš„æƒé‡ä¸­æ´¾ç”Ÿã€‚'
- en: '`custom_pipeline` (`str`, *optional*) â€”'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_pipeline` (`str`, *å¯é€‰*) â€”'
- en: ğŸ§ª This is an experimental feature and may change in the future.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ§ª è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œå¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿå˜åŒ–ã€‚
- en: 'Can be either:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥æ˜¯ï¼š
- en: A string, the *repo id* (for example `hf-internal-testing/diffusers-dummy-pipeline`)
    of a custom pipeline hosted on the Hub. The repository must contain a file called
    pipeline.py that defines the custom pipeline.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨Hubä¸Šçš„è‡ªå®šä¹‰æµæ°´çº¿çš„*repo id*ï¼ˆä¾‹å¦‚`hf-internal-testing/diffusers-dummy-pipeline`ï¼‰ã€‚å­˜å‚¨åº“å¿…é¡»åŒ…å«ä¸€ä¸ªåä¸ºpipeline.pyçš„æ–‡ä»¶ï¼Œå®šä¹‰äº†è‡ªå®šä¹‰æµæ°´çº¿ã€‚
- en: A string, the *file name* of a community pipeline hosted on GitHub under [Community](https://github.com/huggingface/diffusers/tree/main/examples/community).
    Valid file names must match the file name and not the pipeline script (`clip_guided_stable_diffusion`
    instead of `clip_guided_stable_diffusion.py`). Community pipelines are always
    loaded from the current main branch of GitHub.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨GitHubä¸Šçš„ç¤¾åŒºç®¡é“çš„*æ–‡ä»¶å*ï¼Œä½äº[Community](https://github.com/huggingface/diffusers/tree/main/examples/community)ä¸‹ã€‚æœ‰æ•ˆçš„æ–‡ä»¶åå¿…é¡»ä¸æ–‡ä»¶ååŒ¹é…ï¼Œè€Œä¸æ˜¯ç®¡é“è„šæœ¬ï¼ˆ`clip_guided_stable_diffusion`è€Œä¸æ˜¯`clip_guided_stable_diffusion.py`ï¼‰ã€‚ç¤¾åŒºç®¡é“å§‹ç»ˆä»GitHubçš„å½“å‰ä¸»åˆ†æ”¯åŠ è½½ã€‚
- en: A path to a directory (`./my_pipeline_directory/`) containing a custom pipeline.
    The directory must contain a file called `pipeline.py` that defines the custom
    pipeline.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªåŒ…å«è‡ªå®šä¹‰ç®¡é“çš„ç›®å½•çš„è·¯å¾„ï¼ˆ`./my_pipeline_directory/`ï¼‰ã€‚è¯¥ç›®å½•å¿…é¡»åŒ…å«ä¸€ä¸ªåä¸º`pipeline.py`çš„æ–‡ä»¶ï¼Œå®šä¹‰äº†è‡ªå®šä¹‰ç®¡é“ã€‚
- en: For more information on how to load and create custom pipelines, please have
    a look at [Loading and Adding Custom Pipelines](https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview)
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³å¦‚ä½•åŠ è½½å’Œåˆ›å»ºè‡ªå®šä¹‰ç®¡é“çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[åŠ è½½å’Œæ·»åŠ è‡ªå®šä¹‰ç®¡é“](https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview)
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®çš„ç¼“å­˜è·¯å¾„ï¼Œå¦‚æœæœªä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™ä¼šåˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`ã€‚è¿™äº›ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸­ä½¿ç”¨ã€‚'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) â€” Whether or not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦è¿˜è¿”å›ä¸€ä¸ªåŒ…å«ç¼ºå¤±é”®ã€æ„å¤–é”®å’Œé”™è¯¯æ¶ˆæ¯çš„å­—å…¸ã€‚'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™æ¨¡å‹ä¸ä¼šä»Hubä¸‹è½½ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`æˆ–*bool*, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli
    login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, é»˜è®¤ä¸º`"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å®ƒå¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤IDæˆ–Gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`custom_revision` (`str`, *optional*, defaults to `"main"`) â€” The specific
    model version to use. It can be a branch name, a tag name, or a commit id similar
    to `revision` when loading a custom pipeline from the Hub. It can be a ğŸ¤— Diffusers
    version when loading a custom pipeline from GitHub, otherwise it defaults to `"main"`
    when loading from the Hub.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_revision` (`str`, *optional*, é»˜è®¤ä¸º`"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å®ƒå¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°æˆ–ä¸ä»HubåŠ è½½è‡ªå®šä¹‰ç®¡é“æ—¶çš„`revision`ç±»ä¼¼çš„æäº¤IDã€‚ä»GitHubåŠ è½½è‡ªå®šä¹‰ç®¡é“æ—¶å¯ä»¥æ˜¯ğŸ¤—
    Diffusersç‰ˆæœ¬ï¼Œå¦åˆ™åœ¨ä»HubåŠ è½½æ—¶é»˜è®¤ä¸º`"main"`ã€‚'
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *optional*) â€” é•œåƒæºï¼Œç”¨äºè§£å†³åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶çš„å¯è®¿é—®æ€§é—®é¢˜ã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚'
- en: '`device_map` (`str` or `Dict[str, Union[int, str, torch.device]]`, *optional*)
    â€” A map that specifies where each submodule should go. It doesnâ€™t need to be defined
    for each parameter/buffer name; once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`str`æˆ–`Dict[str, Union[int, str, torch.device]]`, *optional*)
    â€” æŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥å»çš„åœ°æ–¹çš„æ˜ å°„ã€‚ä¸éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°å®šä¹‰å®ƒï¼›ä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…éƒ¨ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚'
- en: Set `device_map="auto"` to have ğŸ¤— Accelerate automatically compute the most
    optimized `device_map`. For more information about each option see [designing
    a device map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®¾ç½®`device_map="auto"`ä»¥ä½¿ğŸ¤— Accelerateè‡ªåŠ¨è®¡ç®—æœ€ä¼˜åŒ–çš„`device_map`ã€‚æœ‰å…³æ¯ä¸ªé€‰é¡¹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[è®¾è®¡è®¾å¤‡æ˜ å°„](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)ã€‚
- en: '`max_memory` (`Dict`, *optional*) â€” A dictionary device identifier for the
    maximum memory. Will default to the maximum memory available for each GPU and
    the available CPU RAM if unset.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *optional*) â€” ä¸€ä¸ªå­—å…¸è®¾å¤‡æ ‡è¯†ç¬¦ï¼Œç”¨äºæœ€å¤§å†…å­˜ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºæ¯ä¸ªGPUå’Œå¯ç”¨CPU
    RAMçš„æœ€å¤§å†…å­˜ã€‚'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) â€” The path to offload
    weights if device_map contains the value `"disk"`.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str`æˆ–`os.PathLike`, *optional*) â€” å¦‚æœ`device_map`åŒ…å«å€¼`"disk"`ï¼Œåˆ™æ˜¯å¸è½½æƒé‡çš„è·¯å¾„ã€‚'
- en: '`offload_state_dict` (`bool`, *optional*) â€” If `True`, temporarily offloads
    the CPU state dict to the hard drive to avoid running out of CPU RAM if the weight
    of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults
    to `True` when there is some disk offload.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *optional*) â€” å¦‚æœä¸º `True`ï¼Œæš‚æ—¶å°†CPUçŠ¶æ€å­—å…¸å¸è½½åˆ°ç¡¬ç›˜ï¼Œä»¥é¿å…CPU
    RAMä¸è¶³ï¼Œå¦‚æœCPUçŠ¶æ€å­—å…¸çš„é‡é‡ + æ£€æŸ¥ç‚¹çš„æœ€å¤§åˆ†ç‰‡é‡é‡ä¸é€‚åˆã€‚å½“å­˜åœ¨ä¸€äº›ç£ç›˜å¸è½½æ—¶ï¼Œé»˜è®¤ä¸º `True`ã€‚'
- en: '`low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) â€” Speed up model loading only loading the pretrained weights
    and not initializing the weights. This also tries to not use more than 1x model
    size in CPU memory (including peak memory) while loading the model. Only supported
    for PyTorch >= 1.9.0\. If you are using an older version of PyTorch, setting this
    argument to `True` will raise an error.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) â€” ä»…åŠ è½½é¢„è®­ç»ƒæƒé‡è€Œä¸åˆå§‹åŒ–æƒé‡ï¼ŒåŠ å¿«æ¨¡å‹åŠ è½½é€Ÿåº¦ã€‚åŒæ—¶å°è¯•åœ¨åŠ è½½æ¨¡å‹æ—¶ä¸ä½¿ç”¨è¶…è¿‡1å€æ¨¡å‹å¤§å°çš„CPUå†…å­˜ï¼ˆåŒ…æ‹¬å³°å€¼å†…å­˜ï¼‰ã€‚ä»…æ”¯æŒPyTorch
    >= 1.9.0ã€‚å¦‚æœæ‚¨ä½¿ç”¨è¾ƒæ—§ç‰ˆæœ¬çš„PyTorchï¼Œå°†æ­¤å‚æ•°è®¾ç½®ä¸º `True` å°†å¼•å‘é”™è¯¯ã€‚'
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) â€” If set to `None`,
    the safetensors weights are downloaded if theyâ€™re available **and** if the safetensors
    library is installed. If set to `True`, the model is forcibly loaded from safetensors
    weights. If set to `False`, safetensors weights are not loaded.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_safetensors` (`bool`, *optional*, defaults to `None`) â€” å¦‚æœè®¾ç½®ä¸º `None`ï¼Œåˆ™åœ¨å¯ç”¨æ—¶ä¸‹è½½safetensorsæƒé‡
    **å¹¶ä¸”** å¦‚æœå·²å®‰è£…safetensorsåº“ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™å¼ºåˆ¶ä»safetensorsæƒé‡åŠ è½½æ¨¡å‹ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œåˆ™ä¸åŠ è½½safetensorsæƒé‡ã€‚'
- en: '`use_onnx` (`bool`, *optional*, defaults to `None`) â€” If set to `True`, ONNX
    weights will always be downloaded if present. If set to `False`, ONNX weights
    will never be downloaded. By default `use_onnx` defaults to the `_is_onnx` class
    attribute which is `False` for non-ONNX pipelines and `True` for ONNX pipelines.
    ONNX weights include both files ending with `.onnx` and `.pb`.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_onnx` (`bool`, *optional*, defaults to `None`) â€” å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™å§‹ç»ˆä¸‹è½½ONNXæƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚å¦‚æœè®¾ç½®ä¸º
    `False`ï¼Œåˆ™æ°¸è¿œä¸ä¼šä¸‹è½½ONNXæƒé‡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ`use_onnx` é»˜è®¤ä¸º `_is_onnx` ç±»å±æ€§ï¼Œå¯¹äºéONNXç®¡é“ä¸º `False`ï¼Œå¯¹äºONNXç®¡é“ä¸º
    `True`ã€‚ONNXæƒé‡åŒ…æ‹¬ä»¥ `.onnx` å’Œ `.pb` ç»“å°¾çš„æ–‡ä»¶ã€‚'
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) â€” Can be used
    to overwrite load and saveable variables (the pipeline components of the specific
    pipeline class). The overwritten components are passed directly to the pipelines
    `__init__` method. See example below for more information.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`ï¼ˆå‰©ä½™çš„å…³é”®å­—å‚æ•°å­—å…¸ï¼Œ*optional*ï¼‰ â€” å¯ç”¨äºè¦†ç›–åŠ è½½å’Œå¯ä¿å­˜å˜é‡ï¼ˆç‰¹å®šç®¡é“ç±»çš„ç®¡é“ç»„ä»¶ï¼‰ã€‚è¢«è¦†ç›–çš„ç»„ä»¶ç›´æ¥ä¼ é€’ç»™ç®¡é“çš„
    `__init__` æ–¹æ³•ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ä¸‹é¢çš„ç¤ºä¾‹ã€‚'
- en: '`variant` (`str`, *optional*) â€” Load weights from a specified variant filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) â€” ä»æŒ‡å®šçš„å˜ä½“æ–‡ä»¶åï¼ˆå¦‚ `"fp16"` æˆ– `"ema"`ï¼‰åŠ è½½æƒé‡ã€‚åœ¨åŠ è½½ `from_flax`
    æ—¶ä¼šè¢«å¿½ç•¥ã€‚'
- en: Instantiate a PyTorch diffusion pipeline from pretrained pipeline weights.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é¢„è®­ç»ƒçš„ç®¡é“æƒé‡å®ä¾‹åŒ–ä¸€ä¸ªPyTorchæ‰©æ•£ç®¡é“ã€‚
- en: The pipeline is set in evaluation mode (`model.eval()`) by default.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œç®¡é“è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆ`model.eval()`ï¼‰ã€‚
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ”¶åˆ°ä¸‹é¢çš„é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™éœ€è¦ä¸ºä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæƒé‡ï¼š
- en: '[PRE16]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To use private or [gated](https://huggingface.co/docs/hub/models-gated#gated-models)
    models, log-in with `huggingface-cli login`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨ç§æœ‰æˆ–[é—¨æ§](https://huggingface.co/docs/hub/models-gated#gated-models)æ¨¡å‹ï¼Œè¯·ä½¿ç”¨
    `huggingface-cli login` ç™»å½•ã€‚
- en: 'Examples:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE17]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `maybe_free_model_hooks`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `maybe_free_model_hooks`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1480)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1480)'
- en: '[PRE18]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Function that offloads all components, removes all model hooks that were added
    when using `enable_model_cpu_offload` and then applies them again. In case the
    model has not been offloaded this function is a no-op. Make sure to add this function
    to the end of the `__call__` function of your pipeline so that it functions correctly
    when applying enable_model_cpu_offload.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: å‡½æ•°å°†å¸è½½æ‰€æœ‰ç»„ä»¶ï¼Œåˆ é™¤åœ¨ä½¿ç”¨ `enable_model_cpu_offload` æ—¶æ·»åŠ çš„æ‰€æœ‰æ¨¡å‹é’©å­ï¼Œç„¶åå†æ¬¡åº”ç”¨å®ƒä»¬ã€‚å¦‚æœæ¨¡å‹å°šæœªè¢«å¸è½½ï¼Œåˆ™æ­¤å‡½æ•°ä¸æ‰§è¡Œä»»ä½•æ“ä½œã€‚ç¡®ä¿å°†æ­¤å‡½æ•°æ·»åŠ åˆ°ç®¡é“çš„
    `__call__` å‡½æ•°çš„æœ«å°¾ï¼Œä»¥ä¾¿åœ¨åº”ç”¨ `enable_model_cpu_offload` æ—¶æ­£ç¡®è¿è¡Œã€‚
- en: '#### `numpy_to_pil`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `numpy_to_pil`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1977)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1977)'
- en: '[PRE19]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Convert a NumPy image or a batch of images to a PIL image.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: å°†NumPyå›¾åƒæˆ–ä¸€æ‰¹å›¾åƒè½¬æ¢ä¸ºPILå›¾åƒã€‚
- en: '#### `save_pretrained`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L624)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L624)'
- en: '[PRE20]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to save a pipeline to.
    Will be created if it doesnâ€™t exist.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜ç®¡é“çš„ç›®å½•ã€‚å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œå°†ä¼šåˆ›å»ºã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors`
    æˆ–ä¼ ç»Ÿçš„PyTorchæ–¹å¼ï¼ˆä½¿ç”¨ `pickle`ï¼‰ä¿å­˜æ¨¡å‹ã€‚'
- en: '`variant` (`str`, *optional*) â€” If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥ `pytorch_model.<variant>.bin` æ ¼å¼ä¿å­˜ã€‚'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨ä¿å­˜æ¨¡å‹åå°†å…¶æ¨é€åˆ°Hugging
    Faceæ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°ï¼‰ã€‚'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) â€” Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *optional*) â€” ä¼ é€’ç»™ [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚'
- en: Save all saveable variables of the pipeline to a directory. A pipeline variable
    can be saved and loaded if its class implements both a save and loading method.
    The pipeline is easily reloaded using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    class method.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç®¡é“çš„æ‰€æœ‰å¯ä¿å­˜å˜é‡ä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ä¸­ã€‚å¦‚æœä¸€ä¸ªç®¡é“å˜é‡çš„ç±»å®ç°äº†ä¿å­˜å’ŒåŠ è½½æ–¹æ³•ï¼Œåˆ™å¯ä»¥ä¿å­˜å’ŒåŠ è½½è¯¥å˜é‡ã€‚å¯ä»¥ä½¿ç”¨[from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)ç±»æ–¹æ³•è½»æ¾é‡æ–°åŠ è½½ç®¡é“ã€‚
- en: FlaxDiffusionPipeline
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxDiffusionPipeline
- en: '### `class diffusers.FlaxDiffusionPipeline`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.FlaxDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L101)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L101)'
- en: '[PRE21]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Base class for Flax-based pipelines.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºFlaxçš„ç®¡é“çš„åŸºç±»ã€‚
- en: '[FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline)
    stores all components (models, schedulers, and processors) for diffusion pipelines
    and provides methods for loading, downloading and saving models. It also includes
    methods to:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline)å­˜å‚¨äº†æ‰©æ•£ç®¡é“çš„æ‰€æœ‰ç»„ä»¶ï¼ˆæ¨¡å‹ã€è°ƒåº¦å™¨å’Œå¤„ç†å™¨ï¼‰ï¼Œå¹¶æä¾›äº†åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚å®ƒè¿˜åŒ…æ‹¬ç”¨äºï¼š'
- en: enable/disable the progress bar for the denoising iteration
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ç”¨/ç¦ç”¨å»å™ªè¿­ä»£çš„è¿›åº¦æ¡
- en: 'Class attributes:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»å±æ€§ï¼š
- en: '`config_name` (`str`) â€” The configuration filename that stores the class and
    module names of all the diffusion pipelineâ€™s components.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_name` (`str`) â€” å­˜å‚¨æ‰€æœ‰æ‰©æ•£ç®¡é“ç»„ä»¶çš„ç±»å’Œæ¨¡å—åç§°çš„é…ç½®æ–‡ä»¶åã€‚'
- en: '#### `from_pretrained`'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L229)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L229)'
- en: '[PRE22]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) â€” Can
    be either:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`, *optional*) â€” å¯ä»¥æ˜¯ï¼š'
- en: A string, the *repo id* (for example `runwayml/stable-diffusion-v1-5`) of a
    pretrained pipeline hosted on the Hub.
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç®¡é“åœ¨Hubä¸Šæ‰˜ç®¡çš„*repo id*ï¼ˆä¾‹å¦‚`runwayml/stable-diffusion-v1-5`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline.save_pretrained).
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*ç›®å½•*çš„è·¯å¾„ï¼ˆä¾‹å¦‚`./my_model_directory`ï¼‰ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨[save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline.save_pretrained)ä¿å­˜çš„æ¨¡å‹æƒé‡ã€‚
- en: '`dtype` (`str` or `jnp.dtype`, *optional*) â€” Override the default `jnp.dtype`
    and load the model under this dtype. If `"auto"`, the dtype is automatically derived
    from the modelâ€™s weights.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`str`æˆ–`jnp.dtype`, *optional*) â€” è¦†ç›–é»˜è®¤çš„`jnp.dtype`å¹¶åœ¨æ­¤dtypeä¸‹åŠ è½½æ¨¡å‹ã€‚å¦‚æœæ˜¯`"auto"`ï¼Œåˆ™dtypeä¼šæ ¹æ®æ¨¡å‹çš„æƒé‡è‡ªåŠ¨æ¨å¯¼ã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™ä¼šåˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼Œ`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`ã€‚è¿™äº›ä»£ç†ä¼šåœ¨æ¯ä¸ªè¯·æ±‚ä¸­ä½¿ç”¨ã€‚'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) â€” Whether or not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) â€” æ˜¯å¦è¿”å›åŒ…å«ç¼ºå¤±é”®ã€æ„å¤–é”®å’Œé”™è¯¯æ¶ˆæ¯çš„å­—å…¸ã€‚'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ä¸ä¼šä»Hubä¸‹è½½æ¨¡å‹ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`æˆ–*bool*, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli
    login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤IDæˆ–Gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *optional*) â€” é•œåƒæºä»¥è§£å†³åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶çš„å¯è®¿é—®æ€§é—®é¢˜ã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚'
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) â€” Can be used
    to overwrite load and saveable variables (the pipeline components) of the specific
    pipeline class. The overwritten components are passed directly to the pipelines
    `__init__` method.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`ï¼ˆå‰©ä½™çš„å…³é”®å­—å‚æ•°å­—å…¸ï¼Œ*optional*ï¼‰ â€” å¯ä»¥ç”¨æ¥è¦†ç›–ç‰¹å®šç®¡é“ç±»çš„åŠ è½½å’Œå¯ä¿å­˜å˜é‡ï¼ˆç®¡é“ç»„ä»¶ï¼‰ã€‚è¢«è¦†ç›–çš„ç»„ä»¶ç›´æ¥ä¼ é€’ç»™ç®¡é“çš„`__init__`æ–¹æ³•ã€‚'
- en: Instantiate a Flax-based diffusion pipeline from pretrained pipeline weights.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é¢„è®­ç»ƒçš„ç®¡é“æƒé‡å®ä¾‹åŒ–ä¸€ä¸ªåŸºäºFlaxçš„æ‰©æ•£ç®¡é“ã€‚
- en: The pipeline is set in evaluation mode (`model.eval()) by default and dropout
    modules are deactivated.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œç®¡é“è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆ`model.eval()`ï¼‰ï¼Œå¹¶ä¸”å…³é—­äº†dropoutæ¨¡å—ã€‚
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ”¶åˆ°ä¸‹é¢çš„é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™éœ€è¦ä¸ºä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæƒé‡ï¼š
- en: '[PRE23]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#### `numpy_to_pil`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L588)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Convert a NumPy image or a batch of images to a PIL image.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save_pretrained`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L151)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to which to save. Will
    be created if it doesnâ€™t exist.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (`Dict[str, Any]`, *optional*) â€” Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save all saveable variables of the pipeline to a directory. A pipeline variable
    can be saved and loaded if its class implements both a save and loading method.
    The pipeline is easily reloaded using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline.from_pretrained)
    class method.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: PushToHubMixin
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.utils.PushToHubMixin`'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: A Mixin to push a model, scheduler, or pipeline to the Hugging Face Hub.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '#### `push_to_hub`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '`repo_id` (`str`) â€” The name of the repository you want to push your model,
    scheduler, or pipeline files to. It should contain your organization name when
    pushing to an organization. `repo_id` can also be a path to a local directory.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`commit_message` (`str`, *optional*) â€” Message to commit while pushing. Default
    to `"Upload {object}"`.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`private` (`bool`, *optional*) â€” Whether or not the repository created should
    be private.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`str`, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. The token generated when running `huggingface-cli login` (stored
    in `~/.huggingface`).'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) â€” Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether or
    not to convert the model weights to the `safetensors` format.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variant` (`str`, *optional*) â€” If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upload model, scheduler, or pipeline files to the ğŸ¤— Hugging Face Hub.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
