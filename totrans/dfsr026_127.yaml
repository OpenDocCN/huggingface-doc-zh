- en: Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/overview](https://huggingface.co/docs/diffusers/api/pipelines/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines provide a simple way to run state-of-the-art diffusion models in inference
    by bundling all of the necessary components (multiple independently-trained models,
    schedulers, and processors) into a single end-to-end class. Pipelines are flexible
    and they can be adapted to use different schedulers or even model components.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: All pipelines are built from the base [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    class which provides basic functionality for loading, downloading, and saving
    all the components. Specific pipeline types (for example [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline))
    loaded with [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    are automatically detected and the pipeline components are loaded and passed to
    the `__init__` function of the pipeline.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: You shouldn’t use the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    class for training. Individual components (for example, [UNet2DModel](/docs/diffusers/v0.26.3/en/api/models/unet2d#diffusers.UNet2DModel)
    and [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    of diffusion pipelines are usually trained individually, so we suggest directly
    working with them instead.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines do not offer any training functionality. You’ll notice PyTorch’s autograd
    is disabled by decorating the `__call__()` method with a [`torch.no_grad`](https://pytorch.org/docs/stable/generated/torch.no_grad.html)
    decorator because pipelines should not be used for training. If you’re interested
    in training, please take a look at the [Training](../../training/overview) guides
    instead!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: The table below lists all the pipelines currently available in 🤗 Diffusers and
    the tasks they support. Click on a pipeline to view its abstract and published
    paper.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '| Pipeline | Tasks |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| [AltDiffusion](alt_diffusion) | image2image |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| [AnimateDiff](animatediff) | text2video |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| [Attend-and-Excite](attend_and_excite) | text2image |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: '| [Audio Diffusion](audio_diffusion) | image2audio |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| [AudioLDM](audioldm) | text2audio |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: '| [AudioLDM2](audioldm2) | text2audio |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
- en: '| [BLIP Diffusion](blip_diffusion) | text2image |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| [Consistency Models](consistency_models) | unconditional image generation
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet](controlnet) | text2image, image2image, inpainting |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet with Stable Diffusion XL](controlnet_sdxl) | text2image |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet-XS](controlnetxs) | text2image |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet-XS with Stable Diffusion XL](controlnetxs_sdxl) | text2image
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
- en: '| [Cycle Diffusion](cycle_diffusion) | image2image |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| [Dance Diffusion](dance_diffusion) | unconditional audio generation |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| [DDIM](ddim) | unconditional image generation |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| [DDPM](ddpm) | unconditional image generation |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| [DeepFloyd IF](deepfloyd_if) | text2image, image2image, inpainting, super-resolution
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| [DiffEdit](diffedit) | inpainting |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| [DiT](dit) | text2image |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| [GLIGEN](stable_diffusion/gligen) | text2image |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| [InstructPix2Pix](pix2pix) | image editing |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 2.1](kandinsky) | text2image, image2image, inpainting, interpolation
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 2.2](kandinsky_v22) | text2image, image2image, inpainting |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 3](kandinsky3) | text2image, image2image |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| [Latent Consistency Models](latent_consistency_models) | text2image |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: '| [Latent Diffusion](latent_diffusion) | text2image, super-resolution |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: '| [LDM3D](stable_diffusion/ldm3d_diffusion) | text2image, text-to-3D, text-to-pano,
    upscaling |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
- en: '| [MultiDiffusion](panorama) | text2image |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| [MusicLDM](musicldm) | text2audio |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| [Paint by Example](paint_by_example) | inpainting |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| [ParaDiGMS](paradigms) | text2image |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| [Pix2Pix Zero](pix2pix_zero) | image editing |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| [PixArt-α](pixart) | text2image |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| [PNDM](pndm) | unconditional image generation |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| [RePaint](repaint) | inpainting |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| [Score SDE VE](score_sde_ve) | unconditional image generation |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| [Self-Attention Guidance](self_attention_guidance) | text2image |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| [Semantic Guidance](semantic_stable_diffusion) | text2image |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| [Shap-E](shap_e) | text-to-3D, image-to-3D |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| [Spectrogram Diffusion](spectrogram_diffusion) |  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion](stable_diffusion/overview) | text2image, image2image,
    depth2image, inpainting, image variation, latent upscaler, super-resolution |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion Model Editing](model_editing) | model editing |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion XL](stable_diffusion/stable_diffusion_xl) | text2image,
    image2image, inpainting |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| [Stable Diffusion XL Turbo](stable_diffusion/sdxl_turbo) | text2image, image2image,
    inpainting |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| [Stable unCLIP](stable_unclip) | text2image, image variation |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| [Stochastic Karras VE](stochastic_karras_ve) | unconditional image generation
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| [T2I-Adapter](stable_diffusion/adapter) | text2image |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| [Text2Video](text_to_video) | text2video, video2video |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| [Text2Video-Zero](text_to_video_zero) | text2video |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| [unCLIP](unclip) | text2image, image variation |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| [Unconditional Latent Diffusion](latent_diffusion_uncond) | unconditional
    image generation |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| [UniDiffuser](unidiffuser) | text2image, image2text, image variation, text
    variation, unconditional image generation, unconditional audio generation |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| [Value-guided planning](value_guided_sampling) | value guided sampling |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| [Versatile Diffusion](versatile_diffusion) | text2image, image variation
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| [VQ Diffusion](vq_diffusion) | text2image |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| [Wuerstchen](wuerstchen) | text2image |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: DiffusionPipeline
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.DiffusionPipeline`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L569)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Base class for all pipelines.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    stores all components (models, schedulers, and processors) for diffusion pipelines
    and provides methods for loading, downloading and saving models. It also includes
    methods to:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: move all PyTorch modules to the device of your choice
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: enable/disable the progress bar for the denoising iteration
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class attributes:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '`config_name` (`str`) — The configuration filename that stores the class and
    module names of all the diffusion pipeline’s components.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_optional_components` (`List[str]`) — List of all optional components that
    don’t have to be passed to the pipeline to function (should be overridden by subclasses).'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Call self as a function.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '#### `device`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L901)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Returns
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.device`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The torch device on which the pipeline is located.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '#### `to`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L742)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '`dtype` (`torch.dtype`, *optional*) — Returns a pipeline with the specified
    [`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`torch.Device`, *optional*) — Returns a pipeline with the specified
    [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`silence_dtype_warnings` (`str`, *optional*, defaults to `False`) — Whether
    to omit warnings if the target `dtype` is not compatible with the target `device`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline converted to specified `dtype` and/or `dtype`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Performs Pipeline dtype and/or device conversion. A torch.dtype and torch.device
    are inferred from the arguments of `self.to(*args, **kwargs).`
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: If the pipeline already has the correct torch.dtype and torch.device, then it
    is returned as is. Otherwise, the returned pipeline is a copy of self with the
    desired torch.dtype and torch.device.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果管道已经具有正确的torch.dtype和torch.device，则返回原样。否则，返回的管道是具有所需torch.dtype和torch.device的self的副本。
- en: 'Here are the ways to call `to`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是调用`to`的方法：
- en: '`to(dtype, silence_dtype_warnings=False) → DiffusionPipeline` to return a pipeline
    with the specified [`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to(dtype, silence_dtype_warnings=False) → DiffusionPipeline` 返回具有指定[`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)的管道。'
- en: '`to(device, silence_dtype_warnings=False) → DiffusionPipeline` to return a
    pipeline with the specified [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to(device, silence_dtype_warnings=False) → DiffusionPipeline` 返回具有指定[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)的管道。'
- en: '`to(device=None, dtype=None, silence_dtype_warnings=False) → DiffusionPipeline`
    to return a pipeline with the specified [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)
    and [`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`to(device=None, dtype=None, silence_dtype_warnings=False) → DiffusionPipeline`
    返回具有指定[`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)和[`dtype`](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)的管道。'
- en: '#### `components`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `components`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1941)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1941)'
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `self.components` property can be useful to run different pipelines with
    the same weights and configurations without reallocating additional memory.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.components`属性可用于使用相同的权重和配置运行不同的管道，而无需重新分配额外的内存。'
- en: 'Returns (`dict`): A dictionary containing all the modules needed to initialize
    the pipeline.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '返回 (`dict`): 包含初始化管道所需的所有模块的字典。'
- en: 'Examples:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `disable_attention_slicing`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Disable sliced attention computation. If `enable_attention_slicing` was previously
    called, attention is computed in one step.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片注意力计算。如果之前调用了`enable_attention_slicing`，则注意力在一步中计算。
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。
- en: '#### `download`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1552)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1552)'
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name` (`str` or `os.PathLike`, *optional*) — A string, the
    *repository id* (for example `CompVis/ldm-text2im-large-256`) of a pretrained
    pipeline hosted on the Hub.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name` (`str` 或 `os.PathLike`, *optional*) — 一个字符串，预训练管道的*存储库id*（例如
    `CompVis/ldm-text2im-large-256`），托管在Hub上。'
- en: '`custom_pipeline` (`str`, *optional*) — Can be either:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_pipeline` (`str`, *optional*) — 可以是：'
- en: A string, the *repository id* (for example `CompVis/ldm-text2im-large-256`)
    of a pretrained pipeline hosted on the Hub. The repository must contain a file
    called `pipeline.py` that defines the custom pipeline.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练管道的*存储库id*（例如 `CompVis/ldm-text2im-large-256`），托管在Hub上。存储库必须包含一个名为`pipeline.py`的文件，定义了自定义管道。
- en: A string, the *file name* of a community pipeline hosted on GitHub under [Community](https://github.com/huggingface/diffusers/tree/main/examples/community).
    Valid file names must match the file name and not the pipeline script (`clip_guided_stable_diffusion`
    instead of `clip_guided_stable_diffusion.py`). Community pipelines are always
    loaded from the current `main` branch of GitHub.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在GitHub的[Community](https://github.com/huggingface/diffusers/tree/main/examples/community)下的社区管道的*文件名*。有效的文件名必须匹配文件名而不是管道脚本（`clip_guided_stable_diffusion`而不是`clip_guided_stable_diffusion.py`）。社区管道始终从GitHub的当前`main`分支加载。
- en: A path to a *directory* (`./my_pipeline_directory/`) containing a custom pipeline.
    The directory must contain a file called `pipeline.py` that defines the custom
    pipeline.
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含自定义管道的*目录*（`./my_pipeline_directory/`）的路径。该目录必须包含一个名为`pipeline.py`的文件，定义了自定义管道。
- en: 🧪 This is an experimental feature and may change in the future.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 🧪 这是一个实验性功能，可能会在未来更改。
- en: For more information on how to load and create custom pipelines, take a look
    at [How to contribute a community pipeline](https://huggingface.co/docs/diffusers/main/en/using-diffusers/contribute_pipeline).
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关如何加载和创建自定义管道的更多信息，请查看[如何贡献社区管道](https://huggingface.co/docs/diffusers/main/en/using-diffusers/contribute_pipeline)。
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否恢复下载模型权重和配置文件。如果设置为`False`，则删除任何未完全下载的文件。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理服务器在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether or not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won’t be downloaded from the Hub.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`custom_revision` (`str`, *optional*, defaults to `"main"`) — The specific
    model version to use. It can be a branch name, a tag name, or a commit id similar
    to `revision` when loading a custom pipeline from the Hub. It can be a 🤗 Diffusers
    version when loading a custom pipeline from GitHub, otherwise it defaults to `"main"`
    when loading from the Hub.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mirror` (`str`, *optional*) — Mirror source to resolve accessibility issues
    if you’re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variant` (`str`, *optional*) — Load weights from a specified variant filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) — If set to `None`,
    the safetensors weights are downloaded if they’re available **and** if the safetensors
    library is installed. If set to `True`, the model is forcibly loaded from safetensors
    weights. If set to `False`, safetensors weights are not loaded.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_onnx` (`bool`, *optional*, defaults to `False`) — If set to `True`, ONNX
    weights will always be downloaded if present. If set to `False`, ONNX weights
    will never be downloaded. By default `use_onnx` defaults to the `_is_onnx` class
    attribute which is `False` for non-ONNX pipelines and `True` for ONNX pipelines.
    ONNX weights include both files ending with `.onnx` and `.pb`.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom pipelines and components defined on the Hub in their own
    files. This option should only be set to `True` for repositories you trust and
    in which you have read the code, as it will execute code present on the Hub on
    your local machine.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '`os.PathLike`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: A path to the downloaded pipeline.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Download and cache a PyTorch diffusion pipeline from pretrained pipeline weights.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_attention_slicing`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '`slice_size` (`str` or `int`, *optional*, defaults to `"auto"`) — When `"auto"`,
    halves the input to the attention heads, so attention will be computed in two
    steps. If `"max"`, maximum amount of memory will be saved by running only one
    slice at a time. If a number is provided, uses as many slices as `attention_head_dim
    // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable sliced attention computation. When this option is enabled, the attention
    module splits the input tensor in slices to compute attention in several steps.
    For more than one attention head, the computation is performed sequentially over
    each head. This is useful to save some memory in exchange for a small speed decrease.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: ⚠️ Don’t enable attention slicing if you’re already using `scaled_dot_product_attention`
    (SDPA) from PyTorch 2.0 or xFormers. These attention computations are already
    very memory efficient so you won’t need to enable this function. If you enable
    attention slicing with SDPA or xFormers, it can lead to serious slow downs!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `enable_model_cpu_offload`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_model_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
- en: '[PRE11]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`gpu_id` (`int`, *optional*) — The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id` (`int`，*可选*) — 用于推理的加速器的ID。如果未指定，它将默认为0。'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to “cuda”) — The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to “cuda”.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`torch.Device`或`str`，*可选*，默认为“cuda”) — 用于推理的加速器的PyTorch设备类型。如果未指定，它将默认为“cuda”。'
- en: Offloads all models to CPU using accelerate, reducing memory usage with a low
    impact on performance. Compared to `enable_sequential_cpu_offload`, this method
    moves one whole model at a time to the GPU when its `forward` method is called,
    and the model remains in GPU until the next model runs. Memory savings are lower
    than with `enable_sequential_cpu_offload`, but performance is much better due
    to the iterative execution of the `unet`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有模型转移到CPU，减少内存使用量对性能影响较小。与`enable_sequential_cpu_offload`相比，此方法在调用其`forward`方法时一次将整个模型移动到GPU，并且模型保持在GPU中，直到下一个模型运行。与`enable_sequential_cpu_offload`相比，内存节省较低，但由于`unet`的迭代执行，性能要好得多。
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)'
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`gpu_id` (`int`, *optional*) — The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id` (`int`，*可选*) — 用于推理的加速器的ID。如果未指定，它将默认为0。'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to “cuda”) — The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to “cuda”.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`torch.Device`或`str`，*可选*，默认为“cuda”) — 用于推理的加速器的PyTorch设备类型。如果未指定，它将默认为“cuda”。'
- en: Offloads all models to CPU using 🤗 Accelerate, significantly reducing memory
    usage. When called, the state dicts of all `torch.nn.Module` components (except
    those in `self._exclude_from_cpu_offload`) are saved to CPU and then moved to
    `torch.device('meta')` and loaded to GPU only when their specific submodule has
    its `forward` method called. Offloading happens on a submodule basis. Memory savings
    are higher than with `enable_model_cpu_offload`, but performance is lower.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用🤗 Accelerate将所有模型转移到CPU，显著减少内存使用。当调用时，所有`torch.nn.Module`组件的状态字典（除了`self._exclude_from_cpu_offload`中的组件）将保存到CPU，然后移动到`torch.device('meta')`，仅当其特定子模块调用其`forward`方法时才加载到GPU。卸载是基于子模块的。与`enable_model_cpu_offload`相比，内存节省更高，但性能较低。
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_op` (`Callable`, *optional*) — Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`，*可选*) — 覆盖用作xFormers的[`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)函数的`op`参数的默认`None`运算符。'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 启用[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。启用此选项时，您应该观察到GPU内存使用量降低，并在推理过程中潜在加速。训练过程中的加速不被保证。
- en: ⚠️ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 当内存高效注意力和切片注意力同时启用时，内存高效注意力优先。
- en: 'Examples:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `from_pretrained`'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L931)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L931)'
- en: '[PRE15]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) — Can
    be either:'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`或`os.PathLike`，*可选*) — 可以是：'
- en: A string, the *repo id* (for example `CompVis/ldm-text2im-large-256`) of a pretrained
    pipeline hosted on the Hub.
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在Hub上的预训练流水线的*repo id*（例如`CompVis/ldm-text2im-large-256`）。
- en: A path to a *directory* (for example `./my_pipeline_directory/`) containing
    pipeline weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.save_pretrained).
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向使用[save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.save_pretrained)保存的流水线权重的*目录*的路径（例如`./my_pipeline_directory/`）。
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) — Override the default `torch.dtype`
    and load the model with another dtype. If “auto” is passed, the dtype is automatically
    derived from the model’s weights.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype` (`str`或`torch.dtype`，*可选*) — 覆盖默认的`torch.dtype`并使用另一种dtype加载模型。如果传递“auto”，则dtype将自动从模型的权重中派生。'
- en: '`custom_pipeline` (`str`, *optional*) —'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_pipeline` (`str`, *可选*) —'
- en: 🧪 This is an experimental feature and may change in the future.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 🧪 这是一个实验性功能，可能会在未来发生变化。
- en: 'Can be either:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以是：
- en: A string, the *repo id* (for example `hf-internal-testing/diffusers-dummy-pipeline`)
    of a custom pipeline hosted on the Hub. The repository must contain a file called
    pipeline.py that defines the custom pipeline.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在Hub上的自定义流水线的*repo id*（例如`hf-internal-testing/diffusers-dummy-pipeline`）。存储库必须包含一个名为pipeline.py的文件，定义了自定义流水线。
- en: A string, the *file name* of a community pipeline hosted on GitHub under [Community](https://github.com/huggingface/diffusers/tree/main/examples/community).
    Valid file names must match the file name and not the pipeline script (`clip_guided_stable_diffusion`
    instead of `clip_guided_stable_diffusion.py`). Community pipelines are always
    loaded from the current main branch of GitHub.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在GitHub上的社区管道的*文件名*，位于[Community](https://github.com/huggingface/diffusers/tree/main/examples/community)下。有效的文件名必须与文件名匹配，而不是管道脚本（`clip_guided_stable_diffusion`而不是`clip_guided_stable_diffusion.py`）。社区管道始终从GitHub的当前主分支加载。
- en: A path to a directory (`./my_pipeline_directory/`) containing a custom pipeline.
    The directory must contain a file called `pipeline.py` that defines the custom
    pipeline.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含自定义管道的目录的路径（`./my_pipeline_directory/`）。该目录必须包含一个名为`pipeline.py`的文件，定义了自定义管道。
- en: For more information on how to load and create custom pipelines, please have
    a look at [Loading and Adding Custom Pipelines](https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview)
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关如何加载和创建自定义管道的更多信息，请查看[加载和添加自定义管道](https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview)
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — 下载预训练模型配置的缓存路径，如果未使用标准缓存。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为`False`) — 是否恢复下载模型权重和配置文件。如果设置为`False`，则会删除任何未完全下载的文件。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether or not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won’t be downloaded from the Hub.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, 默认为`False`) — 是否仅加载本地模型权重和配置文件。如果设置为`True`，则模型不会从Hub下载。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`或*bool*, *optional*) — 用作远程文件的HTTP bearer授权的令牌。如果为`True`，则使用从`diffusers-cli
    login`生成的令牌（存储在`~/.huggingface`中）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称、提交ID或Git允许的任何标识符。'
- en: '`custom_revision` (`str`, *optional*, defaults to `"main"`) — The specific
    model version to use. It can be a branch name, a tag name, or a commit id similar
    to `revision` when loading a custom pipeline from the Hub. It can be a 🤗 Diffusers
    version when loading a custom pipeline from GitHub, otherwise it defaults to `"main"`
    when loading from the Hub.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_revision` (`str`, *optional*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或与从Hub加载自定义管道时的`revision`类似的提交ID。从GitHub加载自定义管道时可以是🤗
    Diffusers版本，否则在从Hub加载时默认为`"main"`。'
- en: '`mirror` (`str`, *optional*) — Mirror source to resolve accessibility issues
    if you’re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *optional*) — 镜像源，用于解决在中国下载模型时的可访问性问题。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。'
- en: '`device_map` (`str` or `Dict[str, Union[int, str, torch.device]]`, *optional*)
    — A map that specifies where each submodule should go. It doesn’t need to be defined
    for each parameter/buffer name; once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`str`或`Dict[str, Union[int, str, torch.device]]`, *optional*)
    — 指定每个子模块应该去的地方的映射。不需要为每个参数/缓冲区名称定义它；一旦给定模块名称在内部，它的每个子模块都将被发送到相同的设备。'
- en: Set `device_map="auto"` to have 🤗 Accelerate automatically compute the most
    optimized `device_map`. For more information about each option see [designing
    a device map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设置`device_map="auto"`以使🤗 Accelerate自动计算最优化的`device_map`。有关每个选项的更多信息，请参阅[设计设备映射](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)。
- en: '`max_memory` (`Dict`, *optional*) — A dictionary device identifier for the
    maximum memory. Will default to the maximum memory available for each GPU and
    the available CPU RAM if unset.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *optional*) — 一个字典设备标识符，用于最大内存。如果未设置，将默认为每个GPU和可用CPU
    RAM的最大内存。'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) — The path to offload
    weights if device_map contains the value `"disk"`.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str`或`os.PathLike`, *optional*) — 如果`device_map`包含值`"disk"`，则是卸载权重的路径。'
- en: '`offload_state_dict` (`bool`, *optional*) — If `True`, temporarily offloads
    the CPU state dict to the hard drive to avoid running out of CPU RAM if the weight
    of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults
    to `True` when there is some disk offload.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *optional*) — 如果为 `True`，暂时将CPU状态字典卸载到硬盘，以避免CPU
    RAM不足，如果CPU状态字典的重量 + 检查点的最大分片重量不适合。当存在一些磁盘卸载时，默认为 `True`。'
- en: '`low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) — Speed up model loading only loading the pretrained weights
    and not initializing the weights. This also tries to not use more than 1x model
    size in CPU memory (including peak memory) while loading the model. Only supported
    for PyTorch >= 1.9.0\. If you are using an older version of PyTorch, setting this
    argument to `True` will raise an error.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) — 仅加载预训练权重而不初始化权重，加快模型加载速度。同时尝试在加载模型时不使用超过1倍模型大小的CPU内存（包括峰值内存）。仅支持PyTorch
    >= 1.9.0。如果您使用较旧版本的PyTorch，将此参数设置为 `True` 将引发错误。'
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) — If set to `None`,
    the safetensors weights are downloaded if they’re available **and** if the safetensors
    library is installed. If set to `True`, the model is forcibly loaded from safetensors
    weights. If set to `False`, safetensors weights are not loaded.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_safetensors` (`bool`, *optional*, defaults to `None`) — 如果设置为 `None`，则在可用时下载safetensors权重
    **并且** 如果已安装safetensors库。如果设置为 `True`，则强制从safetensors权重加载模型。如果设置为 `False`，则不加载safetensors权重。'
- en: '`use_onnx` (`bool`, *optional*, defaults to `None`) — If set to `True`, ONNX
    weights will always be downloaded if present. If set to `False`, ONNX weights
    will never be downloaded. By default `use_onnx` defaults to the `_is_onnx` class
    attribute which is `False` for non-ONNX pipelines and `True` for ONNX pipelines.
    ONNX weights include both files ending with `.onnx` and `.pb`.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_onnx` (`bool`, *optional*, defaults to `None`) — 如果设置为 `True`，则始终下载ONNX权重（如果存在）。如果设置为
    `False`，则永远不会下载ONNX权重。默认情况下，`use_onnx` 默认为 `_is_onnx` 类属性，对于非ONNX管道为 `False`，对于ONNX管道为
    `True`。ONNX权重包括以 `.onnx` 和 `.pb` 结尾的文件。'
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) — Can be used
    to overwrite load and saveable variables (the pipeline components of the specific
    pipeline class). The overwritten components are passed directly to the pipelines
    `__init__` method. See example below for more information.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（剩余的关键字参数字典，*optional*） — 可用于覆盖加载和可保存变量（特定管道类的管道组件）。被覆盖的组件直接传递给管道的
    `__init__` 方法。有关更多信息，请参见下面的示例。'
- en: '`variant` (`str`, *optional*) — Load weights from a specified variant filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) — 从指定的变体文件名（如 `"fp16"` 或 `"ema"`）加载权重。在加载 `from_flax`
    时会被忽略。'
- en: Instantiate a PyTorch diffusion pipeline from pretrained pipeline weights.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练的管道权重实例化一个PyTorch扩散管道。
- en: The pipeline is set in evaluation mode (`model.eval()`) by default.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，管道设置为评估模式（`model.eval()`）。
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果收到下面的错误消息，则需要为下游任务微调权重：
- en: '[PRE16]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To use private or [gated](https://huggingface.co/docs/hub/models-gated#gated-models)
    models, log-in with `huggingface-cli login`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用私有或[门控](https://huggingface.co/docs/hub/models-gated#gated-models)模型，请使用
    `huggingface-cli login` 登录。
- en: 'Examples:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `maybe_free_model_hooks`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `maybe_free_model_hooks`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1480)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1480)'
- en: '[PRE18]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Function that offloads all components, removes all model hooks that were added
    when using `enable_model_cpu_offload` and then applies them again. In case the
    model has not been offloaded this function is a no-op. Make sure to add this function
    to the end of the `__call__` function of your pipeline so that it functions correctly
    when applying enable_model_cpu_offload.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 函数将卸载所有组件，删除在使用 `enable_model_cpu_offload` 时添加的所有模型钩子，然后再次应用它们。如果模型尚未被卸载，则此函数不执行任何操作。确保将此函数添加到管道的
    `__call__` 函数的末尾，以便在应用 `enable_model_cpu_offload` 时正确运行。
- en: '#### `numpy_to_pil`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `numpy_to_pil`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1977)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1977)'
- en: '[PRE19]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Convert a NumPy image or a batch of images to a PIL image.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 将NumPy图像或一批图像转换为PIL图像。
- en: '#### `save_pretrained`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L624)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L624)'
- en: '[PRE20]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory to save a pipeline to.
    Will be created if it doesn’t exist.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` 或 `os.PathLike`) — 保存管道的目录。如果目录不存在，将会创建。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — 是否使用 `safetensors`
    或传统的PyTorch方式（使用 `pickle`）保存模型。'
- en: '`variant` (`str`, *optional*) — If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) — 如果指定，权重将以 `pytorch_model.<variant>.bin` 格式保存。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — 是否在保存模型后将其推送到Hugging
    Face模型中心。您可以使用 `repo_id` 指定要推送到的存储库（将默认为您的命名空间中的 `save_directory` 名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *optional*) — 传递给 [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    方法的额外关键字参数。'
- en: Save all saveable variables of the pipeline to a directory. A pipeline variable
    can be saved and loaded if its class implements both a save and loading method.
    The pipeline is easily reloaded using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    class method.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 将管道的所有可保存变量保存到一个目录中。如果一个管道变量的类实现了保存和加载方法，则可以保存和加载该变量。可以使用[from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)类方法轻松重新加载管道。
- en: FlaxDiffusionPipeline
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxDiffusionPipeline
- en: '### `class diffusers.FlaxDiffusionPipeline`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.FlaxDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L101)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L101)'
- en: '[PRE21]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Base class for Flax-based pipelines.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Flax的管道的基类。
- en: '[FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline)
    stores all components (models, schedulers, and processors) for diffusion pipelines
    and provides methods for loading, downloading and saving models. It also includes
    methods to:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline)存储了扩散管道的所有组件（模型、调度器和处理器），并提供了加载、下载和保存模型的方法。它还包括用于：'
- en: enable/disable the progress bar for the denoising iteration
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用/禁用去噪迭代的进度条
- en: 'Class attributes:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 类属性：
- en: '`config_name` (`str`) — The configuration filename that stores the class and
    module names of all the diffusion pipeline’s components.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_name` (`str`) — 存储所有扩散管道组件的类和模块名称的配置文件名。'
- en: '#### `from_pretrained`'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L229)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L229)'
- en: '[PRE22]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) — Can
    be either:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`或`os.PathLike`, *optional*) — 可以是：'
- en: A string, the *repo id* (for example `runwayml/stable-diffusion-v1-5`) of a
    pretrained pipeline hosted on the Hub.
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练管道在Hub上托管的*repo id*（例如`runwayml/stable-diffusion-v1-5`）。
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline.save_pretrained).
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径（例如`./my_model_directory`），其中包含使用[save_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline.save_pretrained)保存的模型权重。
- en: '`dtype` (`str` or `jnp.dtype`, *optional*) — Override the default `jnp.dtype`
    and load the model under this dtype. If `"auto"`, the dtype is automatically derived
    from the model’s weights.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`str`或`jnp.dtype`, *optional*) — 覆盖默认的`jnp.dtype`并在此dtype下加载模型。如果是`"auto"`，则dtype会根据模型的权重自动推导。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否恢复下载模型权重和配置文件。如果设置为`False`，则会删除任何未完全下载的文件。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理会在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether or not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won’t be downloaded from the Hub.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, defaults to `False`) — 是否仅加载本地模型权重和配置文件。如果设置为`True`，则不会从Hub下载模型。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`或*bool*, *optional*) — 用作远程文件的HTTP bearer授权的令牌。如果为`True`，则使用从`diffusers-cli
    login`生成的令牌（存储在`~/.huggingface`）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交ID或Git允许的任何标识符。'
- en: '`mirror` (`str`, *optional*) — Mirror source to resolve accessibility issues
    if you’re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *optional*) — 镜像源以解决在中国下载模型时的可访问性问题。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。'
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) — Can be used
    to overwrite load and saveable variables (the pipeline components) of the specific
    pipeline class. The overwritten components are passed directly to the pipelines
    `__init__` method.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（剩余的关键字参数字典，*optional*） — 可以用来覆盖特定管道类的加载和可保存变量（管道组件）。被覆盖的组件直接传递给管道的`__init__`方法。'
- en: Instantiate a Flax-based diffusion pipeline from pretrained pipeline weights.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练的管道权重实例化一个基于Flax的扩散管道。
- en: The pipeline is set in evaluation mode (`model.eval()) by default and dropout
    modules are deactivated.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，管道设置为评估模式（`model.eval()`），并且关闭了dropout模块。
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如果收到下面的错误消息，则需要为下游任务微调权重：
- en: '[PRE23]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#### `numpy_to_pil`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L588)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Convert a NumPy image or a batch of images to a PIL image.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save_pretrained`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_flax_utils.py#L151)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str` or `os.PathLike`) — Directory to which to save. Will
    be created if it doesn’t exist.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save all saveable variables of the pipeline to a directory. A pipeline variable
    can be saved and loaded if its class implements both a save and loading method.
    The pipeline is easily reloaded using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline.from_pretrained)
    class method.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: PushToHubMixin
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.utils.PushToHubMixin`'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: A Mixin to push a model, scheduler, or pipeline to the Hugging Face Hub.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '#### `push_to_hub`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '`repo_id` (`str`) — The name of the repository you want to push your model,
    scheduler, or pipeline files to. It should contain your organization name when
    pushing to an organization. `repo_id` can also be a path to a local directory.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`commit_message` (`str`, *optional*) — Message to commit while pushing. Default
    to `"Upload {object}"`.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`private` (`bool`, *optional*) — Whether or not the repository created should
    be private.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`str`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. The token generated when running `huggingface-cli login` (stored
    in `~/.huggingface`).'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether or
    not to convert the model weights to the `safetensors` format.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variant` (`str`, *optional*) — If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upload model, scheduler, or pipeline files to the 🤗 Hugging Face Hub.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
