- en: Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The base classes [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel),
    [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel),
    and [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)
    implement the common methods for loading/saving a model either from a local file
    or directory, or from a pretrained model configuration provided by the library
    (downloaded from HuggingFace’s AWS S3 repository).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 基类 [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)、[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    和 [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)
    实现了从本地文件或目录加载/保存模型的常用方法，或从库提供的预训练模型配置（从 HuggingFace 的 AWS S3 存储库下载）加载模型。
- en: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    also implement a few methods which are common among all the models to:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    和 [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    还实现了一些所有模型共有的方法：'
- en: resize the input token embeddings when new tokens are added to the vocabulary
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当新的标记添加到词汇表中时，调整输入标记嵌入大小
- en: prune the attention heads of the model.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修剪模型的注意力头。
- en: The other methods that are common to each model are defined in [ModuleUtilsMixin](/docs/transformers/v4.37.2/en/main_classes/model#transformers.modeling_utils.ModuleUtilsMixin)
    (for the PyTorch models) and `~modeling_tf_utils.TFModuleUtilsMixin` (for the
    TensorFlow models) or for text generation, [GenerationMixin](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin)
    (for the PyTorch models), [TFGenerationMixin](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.TFGenerationMixin)
    (for the TensorFlow models) and [FlaxGenerationMixin](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.FlaxGenerationMixin)
    (for the Flax/JAX models).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型共有的其他方法在 [ModuleUtilsMixin](/docs/transformers/v4.37.2/en/main_classes/model#transformers.modeling_utils.ModuleUtilsMixin)（用于
    PyTorch 模型）和 `~modeling_tf_utils.TFModuleUtilsMixin`（用于 TensorFlow 模型）中定义，或者用于文本生成的
    [GenerationMixin](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin)（用于
    PyTorch 模型）、[TFGenerationMixin](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.TFGenerationMixin)（用于
    TensorFlow 模型）和 [FlaxGenerationMixin](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.FlaxGenerationMixin)（用于
    Flax/JAX 模型）。
- en: PreTrainedModel
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PreTrainedModel
- en: '### `class transformers.PreTrainedModel`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.PreTrainedModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1157)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1157)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Base class for all models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有模型的基类。
- en: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    takes care of storing the configuration of the models and handles methods for
    loading, downloading and saving models as well as a few methods common to all
    models to:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    负责存储模型的配置，并处理加载、下载和保存模型以及一些所有模型共有的方法：'
- en: resize the input embeddings,
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整输入嵌入大小，
- en: prune heads in the self-attention heads.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修剪自注意力头中的头。
- en: 'Class attributes (overridden by derived classes):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 类属性（派生类覆盖）：
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — A subclass of [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    to use as configuration class for this model architecture.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 用作此模型架构的配置类的 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的子类。'
- en: '`load_tf_weights` (`Callable`) — A python *method* for loading a TensorFlow
    checkpoint in a PyTorch model, taking as arguments:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load_tf_weights` (`Callable`) — 用于在 PyTorch 模型中加载 TensorFlow 检查点的 Python *方法*，参数为：'
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — An instance of the model on which to load the TensorFlow checkpoint.'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 要加载 TensorFlow 检查点的模型实例。'
- en: '`config` (`PreTrainedConfig`) — An instance of the configuration associated
    to the model.'
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` (`PreTrainedConfig`) — 与模型关联的配置实例。'
- en: '`path` (`str`) — A path to the TensorFlow checkpoint.'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path` (`str`) — TensorFlow 检查点的路径。'
- en: '`base_model_prefix` (`str`) — A string indicating the attribute associated
    to the base model in derived classes of the same architecture adding modules on
    top of the base model.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_model_prefix` (`str`) — 一个字符串，指示派生类中基础模型关联的属性，该属性在基础模型的顶部添加模块。'
- en: '`is_parallelizable` (`bool`) — A flag indicating whether this model supports
    model parallelization.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_parallelizable` (`bool`) — 一个指示此模型是否支持模型并行化的标志。'
- en: '`main_input_name` (`str`) — The name of the principal input to the model (often
    `input_ids` for NLP models, `pixel_values` for vision models and `input_values`
    for speech models).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main_input_name` (`str`) — 模型的主要输入名称（通常为 NLP 模型的 `input_ids`，视觉模型的 `pixel_values`
    和语音模型的 `input_values`）。'
- en: '#### `push_to_hub`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `push_to_hub`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`repo_id` (`str`) — The name of the repository you want to push your model
    to. It should contain your organization name when pushing to a given organization.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) — 您要推送模型的存储库名称。在推送到特定组织时，应包含您的组织名称。'
- en: '`use_temp_dir` (`bool`, *optional*) — Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_temp_dir`（`bool`，*可选*）— 是否使用临时目录存储保存的文件，然后将它们推送到 Hub。如果没有名为`repo_id`的目录，则默认为`True`，否则为`False`。'
- en: '`commit_message` (`str`, *optional*) — Message to commit while pushing. Will
    default to `"Upload model"`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message`（`str`，*可选*）— 推送时要提交的消息。默认为`"Upload model"`。'
- en: '`private` (`bool`, *optional*) — Whether or not the repository created should
    be private.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private`（`bool`，*可选*）— 是否应该创建私有存储库。'
- en: '`token` (`bool` or `str`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`bool`或`str`，*可选*）— 用作远程文件的HTTP bearer授权的令牌。如果为`True`，将使用运行`huggingface-cli
    login`时生成的令牌（存储在`~/.huggingface`中）。如果未指定`repo_url`，则默认为`True`。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"5GB"`) — Only applicable
    for models. The maximum size for a checkpoint before being sharded. Checkpoints
    shard will then be each of size lower than this size. If expressed as a string,
    needs to be digits followed by a unit (like `"5MB"`). We default it to `"5GB"`
    so that users can easily load models on free-tier Google Colab instances without
    any CPU OOM issues.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size`（`int`或`str`，*可选*，默认为`"5GB"`）— 仅适用于模型。在分片之前的检查点的最大大小。然后，检查点将分片，每个分片的大小都小于此大小。如果表示为字符串，需要是数字后跟一个单位（如`"5MB"`）。我们将其默认设置为`"5GB"`，以便用户可以在免费的
    Google Colab 实例上轻松加载模型，而不会出现任何 CPU OOM 问题。'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr`（`bool`，*可选*，默认为`False`）— 是否创建带有上传文件的PR或直接提交。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether or
    not to convert the model weights in safetensors format for safer serialization.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization`（`bool`，*可选*，默认为`True`）— 是否将模型权重转换为safetensors格式以进行更安全的序列化。'
- en: '`revision` (`str`, *optional*) — Branch to push the uploaded files to.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*）— 要将上传的文件推送到的分支。'
- en: '`commit_description` (`str`, *optional*) — The description of the commit that
    will be created'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_description`（`str`，*可选*）— 将创建的提交的描述'
- en: '`tags` (`List[str]`, *optional*) — List of tags to push on the Hub.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags`（`List[str]`，*可选*）— 要推送到 Hub 上的标签列表。'
- en: Upload the model file to the 🤗 Model Hub.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型文件上传到🤗模型中心。
- en: 'Examples:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `add_model_tags`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_model_tags`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1270)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1270)'
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tags` (`Union[List[str], str]`) — The desired tags to inject in the model'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags`（`Union[List[str], str]`）— 要注入模型中的所需标签。'
- en: Add custom tags into the model that gets pushed to the Hugging Face Hub. Will
    not overwrite existing tags in the model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 将自定义标签添加到推送到 Hugging Face Hub 的模型中。不会覆盖模型中的现有标签。
- en: 'Examples:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `can_generate`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `can_generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1438)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1438)'
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Returns
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`bool`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`bool`'
- en: Whether this model can generate sequences with `.generate()`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是否可以生成序列，使用`.generate()`。
- en: Returns whether this model can generate sequences with `.generate()`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 返回此模型是否可以生成序列，使用`.generate()`。
- en: '#### `disable_input_require_grads`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_input_require_grads`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1582)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1582)'
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Removes the `_require_grads_hook`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 删除`_require_grads_hook`。
- en: '#### `enable_input_require_grads`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_input_require_grads`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1571)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1571)'
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enables the gradients for the input embeddings. This is useful for fine-tuning
    adapter weights while keeping the model weights fixed.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 启用输入嵌入的梯度。这对于微调适配器权重并保持模型权重固定很有用。
- en: '#### `from_pretrained`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2617)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2617)'
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) — Can
    be either:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`，*可选*）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将`from_tf`设置为`True`，并将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。
- en: A path or url to a model folder containing a *flax checkpoint file* in *.msgpack*
    format (e.g, `./flax_model/` containing `flax_model.msgpack`). In this case, `from_flax`
    should be set to `True`.
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含*flax checkpoint file*的模型文件夹的路径或url，格式为*.msgpack*（例如，`./flax_model/`包含`flax_model.msgpack`）。在这种情况下，`from_flax`应设置为`True`。
- en: '`None` if you are both providing the configuration and state dictionary (resp.
    with keyword arguments `config` and `state_dict`).'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您同时提供配置和状态字典（分别使用关键字参数`config`和`state_dict`），则为`None`。
- en: '`model_args` (sequence of positional arguments, *optional*) — All remaining
    positional arguments will be passed to the underlying model’s `__init__` method.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（位置参数序列，*可选*）— 所有剩余的位置参数将传递给底层模型的`__init__`方法。'
- en: '`config` (`Union[PretrainedConfig, str, os.PathLike]`, *optional*) — Can be
    either:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（`Union[PretrainedConfig, str, os.PathLike]`，*可选*）— 可以是：'
- en: an instance of a class derived from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)派生的类的实例，
- en: a string or path valid as input to [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained).
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个作为输入有效的字符串或路径，用于[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)。
- en: 'Configuration for the model to use instead of an automatically loaded configuration.
    Configuration can be automatically loaded when:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代替自动加载的配置使用的模型配置。当：
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (`Dict[str, torch.Tensor]`, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（`Dict[str, torch.Tensor]`，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`Union[str, os.PathLike]`，*可选*）— 下载预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`from_flax` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a Flax checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_flax`（`bool`，*可选*，默认为`False`）— 从Flax检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`ignore_mismatched_sizes` (`bool`, *optional*, defaults to `False`) — Whether
    or not to raise an error if some of the weights from the checkpoint do not have
    the same size as the weights of the model (if for instance, you are instantiating
    a model with 10 labels from a checkpoint with 3 labels).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_mismatched_sizes`（`bool`，*可选*，默认为`False`) — 如果检查点中的某些权重与模型的权重大小不同，是否引发错误（例如，您从具有3个标签的检查点实例化具有10个标签的模型）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (i.e., do not try to download the model).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（即，不尝试下载模型）。'
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`str`或`bool`，*可选*）— 用作远程文件的HTTP bearer授权的令牌。如果为`True`或未指定，将使用运行`huggingface-cli
    login`时生成的令牌（存储在`~/.huggingface`中）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: To test a pull request you made on the Hub, you can pass `revision=“refs/pr/<pr_number>“.</pr_number>
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要测试您在 Hub 上创建的拉取请求，可以传递 `revision=“refs/pr/<pr_number>“。</pr_number>
- en: '`mirror` (`str`, *optional*) — Mirror source to accelerate downloads in China.
    If you are from China and have an accessibility problem, you can set this option
    to resolve it. Note that we do not guarantee the timeliness or safety. Please
    refer to the mirror site for more information.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *可选*) — 镜像源以加速中国的下载。如果您来自中国并且有访问问题，您可以设置此选项来解决。请注意，我们不保证及时性或安全性。请参考镜像站点获取更多信息。'
- en: '`_fast_init(bool,` *optional*, defaults to `True`) — Whether or not to disable
    fast initialization.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_fast_init(bool,` *可选*, 默认为 `True`) — 是否禁用快速初始化。'
- en: One should only disable *_fast_init* to ensure backwards compatibility with
    `transformers.__version__ < 4.6.0` for seeded model initialization. This argument
    will be removed at the next major version. See [pull request 11471](https://github.com/huggingface/transformers/pull/11471)
    for more information.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保与 `transformers.__version__ < 4.6.0` 的种子模型初始化向后兼容，应该只禁用 *_fast_init*。此参数将在下一个主要版本中删除。有关更多信息，请参阅[拉取请求
    11471](https://github.com/huggingface/transformers/pull/11471)。
- en: Parameters for big model inference
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 大型模型推理的参数
- en: '`low_cpu_mem_usage(bool,` *optional*) — Tries to not use more than 1x model
    size in CPU memory (including peak memory) while loading the model. This is an
    experimental feature and a subject to change at any moment.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_cpu_mem_usage(bool,` *可选*) — 尝试在加载模型时不使用超过 CPU 内存中的 1x 模型大小（包括峰值内存）。这是一个实验性功能，随时可能更改。'
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) — Override the default `torch.dtype`
    and load the model under a specific `dtype`. The different options are:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype` (`str` 或 `torch.dtype`, *可选*) — 覆盖默认的 `torch.dtype` 并在特定的 `dtype`
    下加载模型。不同的选项有：'
- en: '`torch.float16` or `torch.bfloat16` or `torch.float`: load in a specified `dtype`,
    ignoring the model’s `config.torch_dtype` if one exists. If not specified'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`torch.float16` 或 `torch.bfloat16` 或 `torch.float`: 以指定的 `dtype` 加载，忽略模型的 `config.torch_dtype`（如果存在）。如果未指定'
- en: the model will get loaded in `torch.float` (fp32).
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型将以 `torch.float` (fp32) 加载。
- en: '`"auto"` - A `torch_dtype` entry in the `config.json` file of the model will
    be attempted to be used. If this entry isn’t found then next check the `dtype`
    of the first weight in the checkpoint that’s of a floating point type and use
    that as `dtype`. This will load the model using the `dtype` it was saved in at
    the end of the training. It can’t be used as an indicator of how the model was
    trained. Since it could be trained in one of half precision dtypes, but saved
    in fp32.'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`"auto"` - 将尝试使用模型的 `config.json` 文件中的 `torch_dtype` 条目。如果找不到此条目，则下一个检查是检查点中第一个浮点类型的权重的
    `dtype` 并将其用作 `dtype`。这将使用模型在训练结束时保存的 `dtype` 加载模型。它不能用作模型训练方式的指示器。因为它可能是在半精度
    `dtype` 中训练，但以 fp32 保存。'
- en: <tip>For some models the `dtype` they were trained in is unknown - you may try
    to check the model’s paper or reach out to the authors and ask them to add this
    information to the model’s card and to insert the `torch_dtype` entry in `config.json`
    on the hub.</tip>
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <tip>对于一些模型，它们训练时使用的 `dtype` 是未知的 - 您可以尝试查看模型的论文或联系作者，并要求他们将此信息添加到模型的卡片中，并在
    Hub 上的 `config.json` 中插入 `torch_dtype` 条目。</tip>
- en: '`device_map` (`str` or `Dict[str, Union[int, str, torch.device]]` or `int`
    or `torch.device`, *optional*) — A map that specifies where each submodule should
    go. It doesn’t need to be refined to each parameter/buffer name, once a given
    module name is inside, every submodule of it will be sent to the same device.
    If we only pass the device (*e.g.*, `"cpu"`, `"cuda:1"`, `"mps"`, or a GPU ordinal
    rank like `1`) on which the model will be allocated, the device map will map the
    entire model to this device. Passing `device_map = 0` means put the whole model
    on GPU 0.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`str` 或 `Dict[str, Union[int, str, torch.device]]` 或 `int` 或
    `torch.device`, *可选*) — 一个指定每个子模块应该放在哪里的映射。它不需要细化到每个参数/缓冲区名称，一旦给定模块名称在内，它的每个子模块都将被发送到同一设备。如果我们只传递模型将被分配的设备（例如，`"cpu"`、`"cuda:1"`、`"mps"`，或者像
    `1` 这样的 GPU 序数等），设备映射将把整个模型映射到这个设备上。传递 `device_map = 0` 意味着将整个模型放在 GPU 0 上。'
- en: To have Accelerate compute the most optimized `device_map` automatically, set
    `device_map="auto"`. For more information about each option see [designing a device
    map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让 Accelerate 自动计算最优化的 `device_map`，请设置 `device_map="auto"`。有关每个选项的更多信息，请参阅[设计设备映射](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)。
- en: '`max_memory` (`Dict`, *optional*) — A dictionary device identifier to maximum
    memory. Will default to the maximum memory available for each GPU and the available
    CPU RAM if unset.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *可选*) — 设备标识符到最大内存的字典。如果未设置，将默认为每个 GPU 可用的最大内存和可用的 CPU
    RAM。'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) — If the `device_map`
    contains any value `"disk"`, the folder where we will offload weights.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str` 或 `os.PathLike`, *可选*) — 如果 `device_map` 包含任何值 `"disk"`，则我们将卸载权重的文件夹。'
- en: '`offload_state_dict` (`bool`, *optional*) — If `True`, will temporarily offload
    the CPU state dict to the hard drive to avoid getting out of CPU RAM if the weight
    of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults
    to `True` when there is some disk offload.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *可选*) — 如果为 `True`，将临时将 CPU 状态字典转移到硬盘，以避免 CPU
    RAM 不足，如果 CPU 状态字典的重量 + 检查点的最大分片不适合。当存在一些磁盘卸载时，默认为 `True`。'
- en: '`load_in_8bit` (`bool`, *optional*, defaults to `False`) — If `True`, will
    convert the loaded model into mixed-8bit quantized model. To use this feature
    please install `bitsandbytes` (`pip install -U bitsandbytes`).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load_in_8bit` (`bool`, *optional*, 默认为 `False`) — 如果为`True`，将加载的模型转换为混合8位量化模型。要使用此功能，请安装`bitsandbytes`（`pip
    install -U bitsandbytes`）。'
- en: '`load_in_4bit` (`bool`, *optional*, defaults to `False`) — If `True`, will
    convert the loaded model into 4bit precision quantized model. To use this feature
    install the latest version of `bitsandbytes` (`pip install -U bitsandbytes`).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load_in_4bit` (`bool`, *optional*, 默认为 `False`) — 如果为`True`，将加载的模型转换为4位精度量化模型。要使用此功能，请安装最新版本的`bitsandbytes`（`pip
    install -U bitsandbytes`）。'
- en: '`quantization_config` (`Union[QuantizationConfigMixin,Dict]`, *optional*) —
    A dictionary of configuration parameters or a QuantizationConfigMixin object for
    quantization (e.g bitsandbytes, gptq)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quantization_config` (`Union[QuantizationConfigMixin,Dict]`, *可选*) — 量化的配置参数字典或QuantizationConfigMixin对象（例如bitsandbytes,
    gptq）'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) — In case the relevant files
    are located inside a subfolder of the model repo on huggingface.co, you can specify
    the folder name here.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *optional*, 默认为 `""`) — 如果相关文件位于huggingface.co模型仓库的子文件夹中，您可以在这里指定文件夹名称。'
- en: '`variant` (`str`, *optional*) — If specified load weights from `variant` filename,
    *e.g.* pytorch_model.<variant>.bin. `variant` is ignored when using `from_tf`
    or `from_flax`.</variant>'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) — 如果指定，将从`variant`文件名加载权重，例如pytorch_model.<variant>.bin。在使用`from_tf`或`from_flax`时忽略`variant`。</variant>'
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) — Whether or not
    to use `safetensors` checkpoints. Defaults to `None`. If not specified and `safetensors`
    is not installed, it will be set to `False`.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_safetensors` (`bool`, *optional*, 默认为 `None`) — 是否使用`safetensors`检查点。默认为`None`。如果未指定并且未安装`safetensors`，则将其设置为`False`。'
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) — Can be used
    to update the configuration object (after it being loaded) and initiate the model
    (e.g., `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（剩余的关键字参数字典，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate a pretrained pytorch model from a pre-trained model configuration.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型配置实例化一个预训练的pytorch模型。
- en: The model is set in evaluation mode by default using `model.eval()` (Dropout
    modules are deactivated). To train the model, you should first set it back in
    training mode with `model.train()`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型以评估模式设置，使用`model.eval()`（Dropout模块被停用）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。
- en: The warning *Weights from XXX not initialized from pretrained model* means that
    the weights of XXX do not come pretrained with the rest of the model. It is up
    to you to train those weights with a downstream fine-tuning task.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 警告*Weights from XXX not initialized from pretrained model*表示XXX的权重不是与模型的其余部分一起预训练的。您需要使用下游微调任务来训练这些权重。
- en: The warning *Weights from XXX not used in YYY* means that the layer XXX is not
    used by YYY, therefore those weights are discarded.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 警告*Weights from XXX not used in YYY*表示层XXX未被YYY使用，因此这些权重将被丢弃。
- en: Activate the special [“offline-mode”](https://huggingface.co/transformers/installation.html#offline-mode)
    to use this method in a firewalled environment.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 激活特殊的[“离线模式”](https://huggingface.co/transformers/installation.html#offline-mode)以在受防火墙保护的环境中使用此方法。
- en: 'Examples:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`low_cpu_mem_usage` algorithm:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_cpu_mem_usage`算法：'
- en: This is an experimental function that loads the model using ~1x model size CPU
    memory
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个使用约1倍模型大小CPU内存加载模型的实验性功能
- en: 'Here is how it works:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是它的工作原理：
- en: save which state_dict keys we have
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存我们拥有的state_dict键
- en: drop state_dict before the model is created, since the latter takes 1x model
    size CPU memory
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建模型之前删除state_dict，因为后者需要1倍模型大小的CPU内存
- en: after the model has been instantiated switch to the meta device all params/buffers
    that are going to be replaced from the loaded state_dict
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实例化模型后，切换到元设备，所有将从加载的state_dict中替换的参数/缓冲区
- en: load state_dict 2nd time
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二次加载state_dict
- en: replace the params/buffers from the state_dict
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从state_dict中替换参数/缓冲区
- en: Currently, it can’t handle deepspeed ZeRO stage 3 and ignores loading errors
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，它无法处理deepspeed ZeRO阶段3并忽略加载错误
- en: '#### `get_input_embeddings`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_input_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1588)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1588)'
- en: '[PRE10]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Returns
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`nn.Module`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Module`'
- en: A torch module mapping vocabulary to hidden states.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 将词汇映射到隐藏状态的torch模块。
- en: Returns the model’s input embeddings.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 返回模型的输入嵌入。
- en: '#### `get_memory_footprint`'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_memory_footprint`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2540)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2540)'
- en: '[PRE11]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`return_buffers` (`bool`, *optional*, defaults to `True`) — Whether to return
    the size of the buffer tensors in the computation of the memory footprint. Buffers
    are tensors that do not require gradients and not registered as parameters. E.g.
    mean and std in batch norm layers. Please see: [https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2](https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_buffers`（`bool`，*可选*，默认为`True`）— 是否在计算内存占用时返回缓冲张量的大小。缓冲区是不需要梯度且未注册为参数的张量。例如，批量归一化层中的均值和标准差。请参见：[https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2](https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2)'
- en: 'Get the memory footprint of a model. This will return the memory footprint
    of the current model in bytes. Useful to benchmark the memory footprint of the
    current model and design some tests. Solution inspired from the PyTorch discussions:
    [https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2](https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 获取模型的内存占用。这将以字节为单位返回当前模型的内存占用。有助于基准测试当前模型的内存占用并设计一些测试。解决方案灵感来自PyTorch讨论：[https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2](https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2)
- en: '#### `get_output_embeddings`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_output_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1614)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1614)'
- en: '[PRE12]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Returns
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`nn.Module`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Module`'
- en: A torch module mapping hidden states to vocabulary.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 将隐藏状态映射到词汇表的torch模块。
- en: Returns the model’s output embeddings.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 返回模型的输出嵌入。
- en: '#### `gradient_checkpointing_disable`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `gradient_checkpointing_disable`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2166)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2166)'
- en: '[PRE13]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Deactivates gradient checkpointing for the current model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为当前模型停用梯度检查点。
- en: Note that in other frameworks this feature can be referred to as “activation
    checkpointing” or “checkpoint activations”.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在其他框架中，此功能可能被称为“激活检查点”或“检查点激活”。
- en: '#### `gradient_checkpointing_enable`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `gradient_checkpointing_enable`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2102)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2102)'
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`gradient_checkpointing_kwargs` (dict, *optional*) — Additional keyword arguments
    passed along to the `torch.utils.checkpoint.checkpoint` function.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradient_checkpointing_kwargs`（字典，*可选*）— 传递给`torch.utils.checkpoint.checkpoint`函数的附加关键字参数。'
- en: Activates gradient checkpointing for the current model.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为当前模型激活梯度检查点。
- en: Note that in other frameworks this feature can be referred to as “activation
    checkpointing” or “checkpoint activations”.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在其他框架中，此功能可能被称为“激活检查点”或“检查点激活”。
- en: We pass the `__call__` method of the modules instead of `forward` because `__call__`
    attaches all the hooks of the module. [https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2](https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递模块的`__call__`方法而不是`forward`，因为`__call__`会附加模块的所有钩子。[https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2](https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2)
- en: '#### `init_weights`'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `init_weights`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2068)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2068)'
- en: '[PRE15]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If needed prunes and maybe initializes weights. If using a custom `PreTrainedModel`,
    you need to implement any initialization logic in `_init_weights`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要修剪并可能初始化权重。如果使用自定义`PreTrainedModel`，则需要在`_init_weights`中实现任何初始化逻辑。
- en: '#### `post_init`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_init`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1256)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1256)'
- en: '[PRE16]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: A method executed at the end of each Transformer model initialization, to execute
    code that needs the model’s modules properly initialized (such as weight initialization).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个Transformer模型初始化结束时执行的方法，用于执行需要模型模块正确初始化的代码（例如权重初始化）。
- en: '#### `prune_heads`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prune_heads`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2085)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2085)'
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`heads_to_prune` (`Dict[int, List[int]]`) — Dictionary with keys being selected
    layer indices (`int`) and associated values being the list of heads to prune in
    said layer (list of `int`). For instance {1: [0, 2], 2: [2, 3]} will prune heads
    0 and 2 on layer 1 and heads 2 and 3 on layer 2.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`heads_to_prune`（`Dict[int, List[int]]`）— 键为选定的层索引（`int`）的字典，相关值为该层中要修剪的头部列表（`int`的列表）。例如{1:
    [0, 2]，2: [2, 3]}将在第1层修剪头部0和2，在第2层修剪头部2和3。'
- en: Prunes heads of the base model.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 修剪基本模型的头部。
- en: '#### `register_for_auto_class`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register_for_auto_class`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4427)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4427)'
- en: '[PRE18]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`auto_class` (`str` or `type`, *optional*, defaults to `"AutoModel"`) — The
    auto class to register this new model with.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_class`（`str`或`type`，*可选*，默认为`"AutoModel"`）— 要注册此新模型的自动类。'
- en: Register this class with a given auto class. This should only be used for custom
    models as the ones in the library are already mapped with an auto class.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 将此类与给定的自动类注册。这仅应用于自定义模型，因为库中的模型已经与自动类映射。
- en: This API is experimental and may have some slight breaking changes in the next
    releases.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 此API是实验性的，可能在下一个版本中有一些轻微的破坏性更改。
- en: '#### `resize_token_embeddings`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `resize_token_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1786)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1786)'
- en: '[PRE19]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`new_num_tokens` (`int`, *optional*) — The new number of tokens in the embedding
    matrix. Increasing the size will add newly initialized vectors at the end. Reducing
    the size will remove vectors from the end. If not provided or `None`, just returns
    a pointer to the input tokens `torch.nn.Embedding` module of the model without
    doing anything.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new_num_tokens` (`int`, *optional*) — 嵌入矩阵中的新标记数。增加大小将在末尾添加新初始化的向量。减小大小将从末尾删除向量。如果未提供或为`None`，则只返回指向模型的输入标记`torch.nn.Embedding`模块的指针，而不执行任何操作。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the embedding matrix
    to a multiple of the provided value.If `new_num_tokens` is set to `None` will
    just pad the embedding to a multiple of `pad_to_multiple_of`.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *optional*) — 如果设置，将填充嵌入矩阵到提供的值的倍数。如果`new_num_tokens`设置为`None`，则只会将嵌入填充到`pad_to_multiple_of`的倍数。'
- en: 'This is especially useful to enable the use of Tensor Cores on NVIDIA hardware
    with compute capability `>= 7.5` (Volta), or on TPUs which benefit from having
    sequence lengths be a multiple of 128\. For more details about this, or help on
    choosing the correct value for resizing, refer to this guide: [https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于启用NVIDIA硬件上的Tensor Cores特别有用，计算能力`>= 7.5`（Volta），或者对于受益于序列长度为128的倍数的TPUs。有关此更多详细信息，或者有关选择调整大小的正确值的帮助，请参阅此指南：[https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc)
- en: Returns
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.nn.Embedding`'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.nn.Embedding`'
- en: Pointer to the input tokens Embeddings Module of the model.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 指向模型的输入标记嵌入模块。
- en: Resizes input token embeddings matrix of the model if `new_num_tokens != config.vocab_size`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`new_num_tokens != config.vocab_size`，则调整模型的输入标记嵌入矩阵的大小。
- en: Takes care of tying weights embeddings afterwards if the model class has a `tie_weights()`
    method.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型类具有`tie_weights()`方法时负责绑定权重嵌入。
- en: '#### `reverse_bettertransformer`'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `reverse_bettertransformer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4481)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4481)'
- en: '[PRE20]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Returns
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)'
- en: The model converted back to the original modeling.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型转换回原始建模。
- en: Reverts the transformation from [to_bettertransformer()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.to_bettertransformer)
    so that the original modeling is used, for example in order to save the model.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 撤消从[to_bettertransformer()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.to_bettertransformer)的转换，以便使用原始建模，例如为了保存模型。
- en: '#### `save_pretrained`'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2199)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2199)'
- en: '[PRE21]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory to which to save. Will
    be created if it doesn’t exist.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory`（`str`或`os.PathLike`） — 要保存到的目录。如果不存在，将创建该目录。'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) — Whether the process
    calling this is the main process or not. Useful when in distributed training like
    TPUs and need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *optional*, 默认为`True`) — 调用此函数的进程是否为主进程。在像TPU这样的分布式训练中很有用，需要在所有进程上调用此函数。在这种情况下，仅在主进程上设置`is_main_process=True`，以避免竞争条件。'
- en: '`state_dict` (nested dictionary of `torch.Tensor`) — The state dictionary of
    the model to save. Will default to `self.state_dict()`, but can be used to only
    save parts of the model or if special precautions need to be taken when recovering
    the state dictionary of a model (like when using model parallelism).'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（`torch.Tensor`的嵌套字典） — 要保存的模型的状态字典。将默认为`self.state_dict()`，但可以用于仅保存模型的部分或者在恢复模型的状态字典时需要采取特殊预防措施的情况（例如在使用模型并行时）。'
- en: '`save_function` (`Callable`) — The function to use to save the state dictionary.
    Useful on distributed training like TPUs when one need to replace `torch.save`
    by another method.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function` (`Callable`) — 用于保存状态字典的函数。在像TPU这样的分布式训练中很有用，当需要用另一种方法替换`torch.save`时。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *optional*, 默认为`False`) — 是否在保存后将模型推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`的名称）。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"5GB"`) — The maximum
    size for a checkpoint before being sharded. Checkpoints shard will then be each
    of size lower than this size. If expressed as a string, needs to be digits followed
    by a unit (like `"5MB"`). We default it to 5GB in order for models to be able
    to run easily on free-tier google colab instances without CPU OOM issues.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int`或`str`，*optional*，默认为`"5GB"`) — 在分片之前的检查点的最大大小。然后，检查点分片的大小将小于此大小。如果表示为字符串，需要是数字后跟一个单位（如`"5MB"`）。我们将其默认为5GB，以便模型能够在免费的Google
    Colab实例上轻松运行，而不会出现CPU OOM问题。'
- en: If a single weight of the model is bigger than `max_shard_size`, it will be
    in its own checkpoint shard which will be bigger than `max_shard_size`.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果模型的单个权重大于`max_shard_size`，则它将在自己的检查点分片中，该分片将大于`max_shard_size`。
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether to
    save the model using `safetensors` or the traditional PyTorch way (that uses `pickle`).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, 默认为`True`) — 是否使用`safetensors`或传统的PyTorch方式（使用`pickle`）保存模型。'
- en: '`variant` (`str`, *optional*) — If specified, weights are saved in the format
    pytorch_model.<variant>.bin.</variant>'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *可选*) — 如果指定，权重将以 pytorch_model.<variant>.bin 的格式保存。'
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 `bool`, *可选*) — 用作远程文件的HTTP bearer授权的令牌。如果为 `True`，或未指定，将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。'
- en: '`save_peft_format` (`bool`, *optional*, defaults to `True`) — For backward
    compatibility with PEFT library, in case adapter weights are attached to the model,
    all keys of the state dict of adapters needs to be pre-pended with `base_model.model`.
    Advanced users can disable this behaviours by setting `save_peft_format` to `False`.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_peft_format` (`bool`, *可选*, 默认为 `True`) — 为了向后兼容PEFT库，如果适配器权重附加到模型上，适配器状态字典的所有键都需要以
    `base_model.model` 为前缀。高级用户可以通过将 `save_peft_format` 设置为 `False` 来禁用此行为。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) — 传递给 [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    方法的额外关键字参数。'
- en: Save a model and its configuration file to a directory, so that it can be re-loaded
    using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    class method.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型及其配置文件保存到目录中，以便可以使用 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    类方法重新加载。
- en: '#### `set_input_embeddings`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_input_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1601)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1601)'
- en: '[PRE22]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`value` (`nn.Module`) — A module mapping vocabulary to hidden states.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value` (`nn.Module`) — 将词汇映射到隐藏状态的模块。'
- en: Set model’s input embeddings.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 设置模型的输入嵌入。
- en: '#### `tie_weights`'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tie_weights`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1641)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1641)'
- en: '[PRE23]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Tie the weights between the input embeddings and the output embeddings.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入嵌入和输出嵌入之间的权重绑定在一起。
- en: If the `torchscript` flag is set in the configuration, can’t handle parameter
    sharing so we are cloning the weights instead.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果配置中设置了 `torchscript` 标志，则无法处理参数共享，因此我们会克隆权重。
- en: '#### `to_bettertransformer`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_bettertransformer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4453)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4453)'
- en: '[PRE24]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Returns
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)'
- en: The model converted to BetterTransformer.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 转换为BetterTransformer的模型。
- en: Converts the model to use [PyTorch’s native attention implementation](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html),
    integrated to Transformers through [Optimum library](https://huggingface.co/docs/optimum/bettertransformer/overview).
    Only a subset of all Transformers models are supported.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型转换为使用[PyTorch的本机注意力实现](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)，通过[Optimum库](https://huggingface.co/docs/optimum/bettertransformer/overview)集成到Transformers中。仅支持所有Transformers模型的子集。
- en: PyTorch’s attention fastpath allows to speed up inference through kernel fusions
    and the use of [nested tensors](https://pytorch.org/docs/stable/nested.html).
    Detailed benchmarks can be found in [this blog post](https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的注意力快速路径允许通过内核融合和使用[嵌套张量](https://pytorch.org/docs/stable/nested.html)加速推理。详细的基准测试可以在[这篇博文](https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2)中找到。
- en: '#### `warn_if_padding_and_no_attention_mask`'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `warn_if_padding_and_no_attention_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4503)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4503)'
- en: '[PRE25]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Shows a one-time warning if the input_ids appear to contain padding and no attention
    mask was given.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输入的 input_ids 看起来包含填充并且没有给出注意力掩码，则显示一次警告。
- en: Large model loading
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型模型加载
- en: In Transformers 4.20.0, the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method has been reworked to accommodate large models using [Accelerate](https://huggingface.co/docs/accelerate/big_modeling).
    This requires Accelerate >= 0.9.0 and PyTorch >= 1.9.0\. Instead of creating the
    full model, then loading the pretrained weights inside it (which takes twice the
    size of the model in RAM, one for the randomly initialized model, one for the
    weights), there is an option to create the model as an empty shell, then only
    materialize its parameters when the pretrained weights are loaded.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在Transformers 4.20.0中，[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法已经重新设计，以适应使用[Accelerate](https://huggingface.co/docs/accelerate/big_modeling)的大型模型。这需要
    Accelerate >= 0.9.0 和 PyTorch >= 1.9.0。与其在内存中创建完整模型，然后加载预训练权重（这需要模型大小的两倍的内存，一个用于随机初始化模型，一个用于权重），现在有一个选项可以创建模型作为空壳，然后只有在加载预训练权重时才实现其参数。
- en: This option can be activated with `low_cpu_mem_usage=True`. The model is first
    created on the Meta device (with empty weights) and the state dict is then loaded
    inside it (shard by shard in the case of a sharded checkpoint). This way the maximum
    RAM used is the full size of the model only.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 `low_cpu_mem_usage=True` 激活此选项。模型首先在 Meta 设备上创建（带有空权重），然后状态字典被加载到其中（在分片检查点的情况下逐个分片）。这样，最大使用的RAM仅为模型的完整大小。
- en: '[PRE26]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Moreover, you can directly place the model on different devices if it doesn’t
    fully fit in RAM (only works for inference for now). With `device_map="auto"`,
    Accelerate will determine where to put each layer to maximize the use of your
    fastest devices (GPUs) and offload the rest on the CPU, or even the hard drive
    if you don’t have enough GPU RAM (or CPU RAM). Even if the model is split across
    several devices, it will run as you would normally expect.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果模型无法完全适应RAM（目前仅适用于推断），则可以直接将模型放置在不同的设备上。使用`device_map="auto"`，Accelerate将确定将每个层放置在哪里以最大化您最快的设备（GPU）的使用，并将其余部分卸载到CPU，甚至硬盘，如果您没有足够的GPU
    RAM（或CPU RAM）。即使模型分布在多个设备上，它也将按照您通常的预期运行。
- en: 'When passing a `device_map`, `low_cpu_mem_usage` is automatically set to `True`,
    so you don’t need to specify it:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在传递`device_map`时，`low_cpu_mem_usage`会自动设置为`True`，因此您无需指定它：
- en: '[PRE27]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You can inspect how the model was split across devices by looking at its `hf_device_map`
    attribute:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看`hf_device_map`属性来查看模型如何分布在设备上：
- en: '[PRE28]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can also write your own device map following the same format (a dictionary
    layer name to device). It should map all parameters of the model to a given device,
    but you don’t have to detail where all the submodules of one layer go if that
    layer is entirely on the same device. For instance, the following device map would
    work properly for T0pp (as long as you have the GPU memory):'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以按照相同格式编写自己的设备映射（将层名称映射到设备的字典）。它应该将模型的所有参数映射到给定设备，但如果该层完全位于同一设备上，则不必详细说明一个层的所有子模块去哪里。例如，以下设备映射对于T0pp将正常工作（只要您有GPU内存）：
- en: '[PRE30]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Another way to minimize the memory impact of your model is to instantiate it
    at a lower precision dtype (like `torch.float16`) or use direct quantization techniques
    as described below.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 减少模型内存影响的另一种方法是以较低精度dtype（如`torch.float16`）实例化模型，或者使用下面描述的直接量化技术。
- en: Model Instantiation dtype
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型实例化dtype
- en: 'Under Pytorch a model normally gets instantiated with `torch.float32` format.
    This can be an issue if one tries to load a model whose weights are in fp16, since
    it’d require twice as much memory. To overcome this limitation, you can either
    explicitly pass the desired `dtype` using `torch_dtype` argument:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pytorch下，模型通常以`torch.float32`格式实例化。如果尝试加载权重为fp16的模型，则可能会出现问题，因为它将需要两倍的内存。为了克服这个限制，您可以使用`torch_dtype`参数显式传递所需的`dtype`：
- en: '[PRE31]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'or, if you want the model to always load in the most optimal memory pattern,
    you can use the special value `"auto"`, and then `dtype` will be automatically
    derived from the model’s weights:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果希望模型始终以最佳内存模式加载，可以使用特殊值`"auto"`，然后`dtype`将自动从模型的权重中派生：
- en: '[PRE32]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Models instantiated from scratch can also be told which `dtype` to use with:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始实例化的模型也可以指定使用的`dtype`：
- en: '[PRE33]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Due to Pytorch design, this functionality is only available for floating dtypes.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Pytorch设计，此功能仅适用于浮点dtype。
- en: ModuleUtilsMixin
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ModuleUtilsMixin
- en: '### `class transformers.modeling_utils.ModuleUtilsMixin`'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.modeling_utils.ModuleUtilsMixin`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L853)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L853)'
- en: '[PRE34]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: A few utilities for `torch.nn.Modules`, to be used as a mixin.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 用作mixin的`torch.nn.Modules`的一些实用程序。
- en: '#### `add_memory_hooks`'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_memory_hooks`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L884)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L884)'
- en: '[PRE35]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Add a memory hook before and after each sub-module forward pass to record increase
    in memory consumption.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个子模块正向传递之前和之后添加内存钩子以记录内存消耗的增加。
- en: Increase in memory consumption is stored in a `mem_rss_diff` attribute for each
    module and can be reset to zero with `model.reset_memory_hooks_state()`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 内存消耗的增加存储在每个模块的`mem_rss_diff`属性中，并可以使用`model.reset_memory_hooks_state()`将其重置为零。
- en: '#### `estimate_tokens`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `estimate_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1109)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1109)'
- en: '[PRE36]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`inputs` (`dict`) — The model inputs.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs`（`dict`）— 模型输入。'
- en: Returns
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The total number of tokens.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌的总数。
- en: Helper function to estimate the total number of tokens from the model inputs.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 用于估计模型输入中总令牌数的辅助函数。
- en: '#### `floating_point_ops`'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `floating_point_ops`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1130)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1130)'
- en: '[PRE37]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`batch_size` (`int`) — The batch size for the forward pass.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`（`int`）— 正向传递的批量大小。'
- en: '`sequence_length` (`int`) — The number of tokens in each line of the batch.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequence_length`（`int`）— 每个批次行中的令牌数。'
- en: '`exclude_embeddings` (`bool`, *optional*, defaults to `True`) — Whether or
    not to count embedding and softmax operations.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exclude_embeddings`（`bool`，*可选*，默认为`True`）— 是否计算嵌入和softmax操作。'
- en: Returns
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The number of floating-point operations.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点运算的数量。
- en: Get number of (optionally, non-embeddings) floating-point operations for the
    forward and backward passes of a batch with this transformer model. Default approximation
    neglects the quadratic dependency on the number of tokens (valid if `12 * d_model
    << sequence_length`) as laid out in [this paper](https://arxiv.org/pdf/2001.08361.pdf)
    section 2.1\. Should be overridden for transformers with parameter re-use e.g.
    Albert or Universal Transformers, or if doing long-range modeling with very high
    sequence lengths.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此转换器模型的批处理的正向和反向传递的浮点操作的数量（可选，非嵌入）。默认近似忽略对令牌数量的二次依赖（如果`12 * d_model << sequence_length`）如[本文](https://arxiv.org/pdf/2001.08361.pdf)第2.1节所述。对于具有参数重用的变压器（例如Albert或通用变压器）或者如果使用非常高的序列长度进行长距离建模，则应该进行覆盖。
- en: '#### `get_extended_attention_mask`'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_extended_attention_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L972)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L972)'
- en: '[PRE38]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_mask` (`torch.Tensor`) — Mask with ones indicating tokens to attend
    to, zeros for tokens to ignore.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`) — 一个掩码，其中的1表示要关注的标记，0表示要忽略的标记。'
- en: '`input_shape` (`Tuple[int]`) — The shape of the input to the model.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_shape` (`Tuple[int]`) — 模型的输入形状。'
- en: Makes broadcastable attention and causal masks so that future and masked tokens
    are ignored.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 使可广播的注意力和因果掩码，以便将来和掩码的标记被忽略。
- en: '#### `get_head_mask`'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_head_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1024)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1024)'
- en: '[PRE39]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Parameters
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`head_mask` (`torch.Tensor` with shape `[num_heads]` or `[num_hidden_layers
    x num_heads]`, *optional*) — The mask indicating if we should keep the heads or
    not (1.0 for keep, 0.0 for discard).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`，形状为`[num_heads]`或`[num_hidden_layers x num_heads]`，*可选*)
    — 指示我们是否应保留头部的掩码（保留为1.0，丢弃为0.0）。'
- en: '`num_hidden_layers` (`int`) — The number of hidden layers in the model.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`) — 模型中的隐藏层数量。'
- en: '`is_attention_chunked` (`bool`, *optional*, defaults to `False`) — Whether
    or not the attentions scores are computed by chunks or not.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_attention_chunked` (`bool`, *可选*, 默认为 `False`) — 注意力分数是否按块计算。'
- en: Prepare the head mask if needed.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，准备头掩码。
- en: '#### `invert_attention_mask`'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `invert_attention_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L920)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L920)'
- en: '[PRE40]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`encoder_attention_mask` (`torch.Tensor`) — An attention mask.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_mask` (`torch.Tensor`) — 一个注意力掩码。'
- en: Returns
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.Tensor`'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.Tensor`'
- en: The inverted attention mask.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 反转的注意力掩码。
- en: Invert an attention mask (e.g., switches 0\. and 1.).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 反转注意力掩码（例如，切换0和1）。
- en: '#### `num_parameters`'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `num_parameters`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1062)'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1062)'
- en: '[PRE41]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parameters
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`only_trainable` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return only the number of trainable parameters'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`only_trainable` (`bool`, *可选*, 默认为 `False`) — 是否只返回可训练参数的数量'
- en: '`exclude_embeddings` (`bool`, *optional*, defaults to `False`) — Whether or
    not to return only the number of non-embeddings parameters'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exclude_embeddings` (`bool`, *可选*, 默认为 `False`) — 是否只返回非嵌入参数的数量'
- en: Returns
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The number of parameters.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 参数的数量。
- en: Get number of (optionally, trainable or non-embeddings) parameters in the module.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 获取模块中（可选地，可训练或非嵌入）参数的数量。
- en: '#### `reset_memory_hooks_state`'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `reset_memory_hooks_state`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L896)'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L896)'
- en: '[PRE42]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Reset the `mem_rss_diff` attribute of each module (see [add_memory_hooks()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.modeling_utils.ModuleUtilsMixin.add_memory_hooks)).
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 重置每个模块的`mem_rss_diff`属性（参见[add_memory_hooks()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.modeling_utils.ModuleUtilsMixin.add_memory_hooks)）。
- en: TFPreTrainedModel
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFPreTrainedModel
- en: '### `class transformers.TFPreTrainedModel`'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFPreTrainedModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1058)'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1058)'
- en: '[PRE43]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Base class for all TF models.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 所有TF模型的基类。
- en: '[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    takes care of storing the configuration of the models and handles methods for
    loading, downloading and saving models as well as a few methods common to all
    models to:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: TFPreTrainedModel类负责存储模型的配置，并处理加载、下载和保存模型的方法，以及一些所有模型通用的方法：
- en: resize the input embeddings,
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整输入嵌入，
- en: prune heads in the self-attention heads.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修剪自注意力头。
- en: 'Class attributes (overridden by derived classes):'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 类属性（由派生类覆盖）：
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — A subclass of [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    to use as configuration class for this model architecture.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 用作此模型架构的配置类的[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的子类。'
- en: '`base_model_prefix` (`str`) — A string indicating the attribute associated
    to the base model in derived classes of the same architecture adding modules on
    top of the base model.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_model_prefix` (`str`) — 一个字符串，指示派生类中基础模型关联的属性，在同一架构的派生类中添加模块到基础模型之上。'
- en: '`main_input_name` (`str`) — The name of the principal input to the model (often
    `input_ids` for NLP models, `pixel_values` for vision models and `input_values`
    for speech models).'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main_input_name` (`str`) — 模型的主要输入的名称（通常为NLP模型的`input_ids`，视觉模型的`pixel_values`和语音模型的`input_values`）。'
- en: '#### `push_to_hub`'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `push_to_hub`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L3067)'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L3067)'
- en: '[PRE44]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Parameters
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`repo_id` (`str`) — The name of the repository you want to push your model
    to. It should contain your organization name when pushing to a given organization.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) — 您要将模型推送到的存储库的名称。在推送到给定组织时，应包含您的组织名称。'
- en: '`use_temp_dir` (`bool`, *optional*) — Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_temp_dir` (`bool`, *可选*) — 是否使用临时目录存储保存的文件，直到它们被推送到Hub。如果没有名为`repo_id`的目录，则默认为`True`，否则为`False`。'
- en: '`commit_message` (`str`, *optional*) — Message to commit while pushing. Will
    default to `"Upload model"`.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message` (`str`, *可选*) — 推送时要提交的消息。默认为`"Upload model"`。'
- en: '`private` (`bool`, *optional*) — Whether or not the repository created should
    be private.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private`（`bool`，*可选*）— 是否应创建私有存储库。'
- en: '`token` (`bool` or `str`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`bool`或`str`，*可选*）— 用作远程文件的HTTP bearer授权的令牌。如果为`True`，将使用运行`huggingface-cli
    login`时生成的令牌（存储在`~/.huggingface`中）。如果未指定`repo_url`，则默认为`True`。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"10GB"`) — Only
    applicable for models. The maximum size for a checkpoint before being sharded.
    Checkpoints shard will then be each of size lower than this size. If expressed
    as a string, needs to be digits followed by a unit (like `"5MB"`).'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size`（`int`或`str`，*可选*，默认为`"10GB"`）— 仅适用于模型。在分片之前的检查点的最大大小。然后，检查点分片将每个大小小于此大小。如果表示为字符串，需要是数字后跟一个单位（如`"5MB"`）。'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr`（`bool`，*可选*，默认为`False`）— 是否创建带有上传文件的PR或直接提交。'
- en: Upload the model files to the 🤗 Model Hub while synchronizing a local clone
    of the repo in `repo_path_or_name`.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型文件上传到🤗模型Hub，同时同步存储库的本地克隆到`repo_path_or_name`中。
- en: 'Examples:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE45]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '#### `can_generate`'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `can_generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1301)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1301)'
- en: '[PRE46]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Returns
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`bool`'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '`bool`'
- en: Whether this model can generate sequences with `.generate()`.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是否可以使用`.generate()`生成序列。
- en: Returns whether this model can generate sequences with `.generate()`.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 返回此模型是否可以使用`.generate()`生成序列。
- en: '#### `compile`'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `compile`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1496)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1496)'
- en: '[PRE47]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This is a thin wrapper that sets the model’s loss output head as the loss if
    the user does not specify a loss function themselves.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个薄包装器，如果用户没有指定自己的损失函数，则将模型的损失输出头设置为损失。
- en: '#### `create_model_card`'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_model_card`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1791)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1791)'
- en: '[PRE48]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Parameters
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`output_dir` (`str` or `os.PathLike`) — The folder in which to create the model
    card.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_dir`（`str`或`os.PathLike`）— 创建模型卡片的文件夹。'
- en: '`model_name` (`str`, *optional*) — The name of the model.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_name`（`str`，*可选*）— 模型的名称。'
- en: '`language` (`str`, *optional*) — The language of the model (if applicable)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`（`str`，*可选*）— 模型的语言（如果适用）'
- en: '`license` (`str`, *optional*) — The license of the model. Will default to the
    license of the pretrained model used, if the original model given to the `Trainer`
    comes from a repo on the Hub.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`license`（`str`，*可选*）— 模型的许可证。如果给定给`Trainer`的原始模型来自Hub上的repo，则默认为使用的预训练模型的许可证。'
- en: '`tags` (`str` or `List[str]`, *optional*) — Some tags to be included in the
    metadata of the model card.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags`（`str`或`List[str]`，*可选*）— 要包含在模型卡片的元数据中的一些标签。'
- en: '`finetuned_from` (`str`, *optional*) — The name of the model used to fine-tune
    this one (if applicable). Will default to the name of the repo of the original
    model given to the `Trainer` (if it comes from the Hub).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`finetuned_from`（`str`，*可选*）— 用于微调此模型的模型的名称（如果适用）。如果来自Hub的原始模型的`Trainer`给出的repo的名称，则默认为原始模型的名称。'
- en: '`tasks` (`str` or `List[str]`, *optional*) — One or several task identifiers,
    to be included in the metadata of the model card.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tasks`（`str`或`List[str]`，*可选*）— 一个或多个任务标识符，要包含在模型卡片的元数据中。'
- en: '`dataset_tags` (`str` or `List[str]`, *optional*) — One or several dataset
    tags, to be included in the metadata of the model card.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_tags`（`str`或`List[str]`，*可选*）— 一个或多个数据集标签，要包含在模型卡片的元数据中。'
- en: '`dataset` (`str` or `List[str]`, *optional*) — One or several dataset identifiers,
    to be included in the metadata of the model card.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset`（`str`或`List[str]`，*可选*）— 一个或多个数据集标识符，要包含在模型卡片的元数据中。'
- en: '`dataset_args` (`str` or `List[str]`, *optional*) — One or several dataset
    arguments, to be included in the metadata of the model card.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_args`（`str`或`List[str]`，*可选*）— 一个或多个数据集参数，要包含在模型卡片的元数据中。'
- en: Creates a draft of a model card using the information available to the `Trainer`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Trainer`可用的信息创建模型卡片的草稿。
- en: '#### `eager_serving`'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `eager_serving`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1213)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1213)'
- en: '[PRE49]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Parameters
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`inputs` (`Dict[str, tf.Tensor]`) — The input of the saved model as a dictionary
    of tensors.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs`（`Dict[str, tf.Tensor]`）— 保存模型的输入，作为张量字典。'
- en: Method used for serving the model. This method is deprecated, and will be removed.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 用于提供模型的方法。此方法已弃用，将被移除。
- en: '#### `from_pretrained`'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2499)'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2499)'
- en: '[PRE50]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Parameters
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str`, *optional*) — Can be either:'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`，*可选*）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-405
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *PyTorch state_dict 保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象作为 `config` 参数提供。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型要慢。
- en: '`None` if you are both providing the configuration and state dictionary (resp.
    with keyword arguments `config` and `state_dict`).'
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您同时提供配置和状态字典（分别使用关键字参数 `config` 和 `state_dict`），则为 `None`。
- en: '`model_args` (sequence of positional arguments, *optional*) — All remaining
    positional arguments will be passed to the underlying model’s `__init__` method.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（位置参数序列，*可选*） — 所有剩余的位置参数将传递给底层模型的 `__init__` 方法。'
- en: '`config` (`Union[PretrainedConfig, str]`, *optional*) — Can be either:'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` (`Union[PretrainedConfig, str]`, *可选*) — 可以是：'
- en: an instance of a class derived from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    派生的类的实例，
- en: a string valid as input to [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained).
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)
    输入有效的字符串。
- en: 'Configuration for the model to use instead of an automatically loaded configuration.
    Configuration can be automatically loaded when:'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于替代自动加载配置的模型配置。当以下情况发生时，配置可以自动加载：
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch state_dict save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch state_dict 保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`ignore_mismatched_sizes` (`bool`, *optional*, defaults to `False`) — Whether
    or not to raise an error if some of the weights from the checkpoint do not have
    the same size as the weights of the model (if for instance, you are instantiating
    a model with 10 labels from a checkpoint with 3 labels).'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_mismatched_sizes` (`bool`, *可选*, 默认为 `False`) — 是否在检查点的某些权重与模型的权重大小不同时引发错误（例如，如果您从具有
    3 个标签的检查点实例化具有 10 个标签的模型）。'
- en: '`cache_dir` (`str`, *optional*) — Path to a directory in which a downloaded
    pretrained model configuration should be cached if the standard cache should not
    be used.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str`, *可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists. proxies — (`Dict[str, str],` optional`): A dictionary of proxy
    servers to use by protocol or endpoint, e.g.,` {‘http’: ‘foo.bar:3128’, ‘http://hostname’:
    ‘foo.bar:4012’}`. The proxies are used on each request. output_loading_info(`bool`,
    *optional*, defaults to` False`): Whether ot not to also return a dictionary containing
    missing keys, unexpected keys and error messages.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。代理
    — (`Dict[str, str],` 可选`): 用于每个请求的协议或端点的代理服务器字典，例如` {‘http’: ‘foo.bar:3128’, ‘http://hostname’:
    ‘foo.bar:4012’}`。代理将用于每个请求。output_loading_info(`bool`, *可选*, 默认为` False`): 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 `bool`, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，或者未指定，则将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们在
    huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型配置实例化预训练的 TF 2.0 模型。
- en: The warning *Weights from XXX not initialized from pretrained model* means that
    the weights of XXX do not come pretrained with the rest of the model. It is up
    to you to train those weights with a downstream fine-tuning task.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 警告 *Weights from XXX not initialized from pretrained model* 意味着 XXX 的权重不是与模型的其余部分一起预训练的。您需要使用下游微调任务来训练这些权重。
- en: The warning *Weights from XXX not used in YYY* means that the layer XXX is not
    used by YYY, therefore those weights are discarded.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 警告*来自 XXX 的权重在 YYY 中未使用*表示层 XXX 未被 YYY 使用，因此这些权重被丢弃。
- en: 'Examples:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE51]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '#### `get_bias`'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_bias`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1931)'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1931)'
- en: '[PRE52]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Returns
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tf.Variable`'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.Variable`'
- en: The weights representing the bias, None if not an LM model.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 表示偏置的权重，如果不是 LM 模型则为 None。
- en: Dict of bias attached to an LM head. The key represents the name of the bias
    attribute.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 附加到 LM head 的偏置的字典。键表示偏置属性的名称。
- en: '#### `get_head_mask`'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_head_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1168)'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1168)'
- en: '[PRE53]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Parameters
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`head_mask` (`tf.Tensor` with shape `[num_heads]` or `[num_hidden_layers x
    num_heads]`, *optional*) — The mask indicating if we should keep the heads or
    not (1.0 for keep, 0.0 for discard).'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`tf.Tensor`，形状为 `[num_heads]` 或 `[num_hidden_layers x num_heads]`，*可选*)
    — 指示我们是否应保留头部的掩码（保留为 1.0，丢弃为 0.0）。'
- en: '`num_hidden_layers` (`int`) — The number of hidden layers in the model.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`) — 模型中的隐藏层数量。'
- en: Prepare the head mask if needed.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，准备头部掩码。
- en: '#### `get_input_embeddings`'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_input_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1315)'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1315)'
- en: '[PRE54]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Returns
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tf.Variable`'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.Variable`'
- en: The embeddings layer mapping vocabulary to hidden states.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 将词汇映射到隐藏状态的嵌入层。
- en: Returns the model’s input embeddings layer.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 返回模型的输入嵌入层。
- en: '#### `get_lm_head`'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_lm_head`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1964)'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1964)'
- en: '[PRE55]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Returns
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tf.keras.layers.Layer`'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.keras.layers.Layer`'
- en: The LM head layer if the model has one, None if not.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型有 LM head 层，则为 LM head 层，否则为 None。
- en: The LM Head layer. This method must be overwritten by all the models that have
    a lm head.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: LM Head 层。该方法必须被所有具有 lm head 的模型覆盖。
- en: '#### `get_output_embeddings`'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_output_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1871)'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1871)'
- en: '[PRE56]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Returns
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tf.Variable`'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.Variable`'
- en: The new weights mapping vocabulary to hidden states.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 将词汇映射到隐藏状态的新权重。
- en: Returns the model’s output embeddings
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 返回模型的输出嵌入
- en: '#### `get_output_layer_with_bias`'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_output_layer_with_bias`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1908)'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1908)'
- en: '[PRE57]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Returns
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tf.keras.layers.Layer`'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.keras.layers.Layer`'
- en: The layer that handles the bias, None if not an LM model.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 处理偏置的层，如果不是 LM 模型则为 None。
- en: Get the layer that handles a bias attribute in case the model has an LM head
    with weights tied to the embeddings
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 获取处理偏置属性的层，如果模型具有将权重绑定到嵌入的 LM head
- en: '#### `get_prefix_bias_name`'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_prefix_bias_name`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1921)'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1921)'
- en: '[PRE58]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Returns
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The _prefix name of the bias.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置的连接前缀名称。
- en: Get the concatenated _prefix name of the bias from the model name to the parent
    layer
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型名称到父层的偏置的连接前缀名称
- en: '#### `load_repo_checkpoint`'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_repo_checkpoint`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1342)'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1342)'
- en: '[PRE59]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Parameters
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`repo_path_or_name` (`str`) — Can either be a repository name for your {object}
    in the Hub or a path to a local folder (in which case the repository will have
    the name of that local folder).'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_path_or_name` (`str`) — 可以是 Hub 中您的 {object} 的存储库名称，也可以是本地文件夹的路径（在这种情况下，存储库将使用该本地文件夹的名称）。'
- en: Returns
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`dict`'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '`dict`'
- en: A dictionary of extra metadata from the checkpoint, most commonly an “epoch”
    count.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 来自检查点的额外元数据字典，通常是“时代”计数。
- en: Loads a saved checkpoint (model weights and optimizer state) from a repo. Returns
    the current epoch count when the checkpoint was made.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 从存储库加载已保存的检查点（模型权重和优化器状态）。返回检查点生成时的当前时代计数。
- en: '#### `prepare_tf_dataset`'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prepare_tf_dataset`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1391)'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1391)'
- en: '[PRE60]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Parameters
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`dataset` (`Any`) — A [~`datasets.Dataset`] to be wrapped as a `tf.data.Dataset`.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset` (`Any`) — 要包装为 `tf.data.Dataset` 的 [~`datasets.Dataset`]。'
- en: '`batch_size` (`int`, defaults to 8) — The size of batches to return.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` (`int`，默认为 8) — 要返回的批次大小。'
- en: '`shuffle` (`bool`, defaults to `True`) — Whether to return samples from the
    dataset in random order. Usually `True` for training datasets and `False` for
    validation/test datasets.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shuffle` (`bool`，默认为 `True`) — 是否以随机顺序返回数据集中的样本。通常对于训练数据集为 `True`，对于验证/测试数据集为
    `False`。'
- en: '`tokenizer` ([PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase),
    *optional*) — A `PreTrainedTokenizer` that will be used to pad samples to create
    batches. Has no effect if a specific `collate_fn` is passed instead.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase)，*可选*）
    — 用于填充样本以创建批次的 `PreTrainedTokenizer`。如果传递了特定的 `collate_fn`，则不会产生影响。'
- en: '`collate_fn` (`Callable`, *optional*) — A function that collates samples from
    the dataset into a single batch. Defaults to `DefaultDataCollator` if no `tokenizer`
    is supplied or `DataCollatorWithPadding` if a `tokenizer` is passed.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collate_fn` (`Callable`，*可选*) — 一个将数据集中的样本整理成单个批次的函数。如果未提供 `tokenizer`，则默认为
    `DefaultDataCollator`，如果传递了 `tokenizer`，则为 `DataCollatorWithPadding`。'
- en: '`collate_fn_args` (`Dict[str, Any]`, *optional*) — A dict of arguments to pass
    to the `collate_fn` alongside the list of samples.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collate_fn_args` (`Dict[str, Any]`, *可选*) — 传递给`collate_fn`的参数字典，以及样本列表。'
- en: '`drop_remainder` (`bool`, *optional*) — Whether to drop the final batch, if
    the batch_size does not evenly divide the dataset length. Defaults to the same
    setting as `shuffle`.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop_remainder` (`bool`, *可选*) — 是否丢弃最后一个批次，如果批次大小不能整除数据集长度。默认设置与`shuffle`相同。'
- en: '`prefetch` (`bool`, defaults to `True`) — Whether to add prefetching to the
    end of the `tf.data` pipeline. This is almost always beneficial for performance,
    but can be disabled in edge cases.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefetch` (`bool`, 默认为 `True`) — 是否在`tf.data`管道的末尾添加预取。这几乎总是有利于性能，但在边缘情况下可以禁用。'
- en: Returns
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dataset`'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dataset`'
- en: A `tf.data.Dataset` which is ready to pass to the Keras API.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 一个准备传递给Keras API的`tf.data.Dataset`。
- en: Wraps a HuggingFace [Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)
    as a `tf.data.Dataset` with collation and batching. This method is designed to
    create a “ready-to-use” dataset that can be passed directly to Keras methods like
    `fit()` without further modification. The method will drop columns from the dataset
    if they don’t match input names for the model. If you want to specify the column
    names to return rather than using the names that match this model, we recommend
    using `Dataset.to_tf_dataset()` instead.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 将HuggingFace [Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)包装为带有整理和批处理的`tf.data.Dataset`。此方法旨在创建一个“即插即用”的数据集，可以直接传递给Keras方法，如`fit()`，而无需进一步修改。如果数据集中的列与模型的输入名称不匹配，该方法将删除这些列。如果您想指定要返回的列名，而不是使用与此模型匹配的名称，我们建议使用`Dataset.to_tf_dataset()`。
- en: '#### `prune_heads`'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prune_heads`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2311)'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2311)'
- en: '[PRE61]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Parameters
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`heads_to_prune` (`Dict[int, List[int]]`) — Dictionary with keys being selected
    layer indices (`int`) and associated values being the list of heads to prune in
    said layer (list of `int`). For instance {1: [0, 2], 2: [2, 3]} will prune heads
    0 and 2 on layer 1 and heads 2 and 3 on layer 2.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`heads_to_prune` (`Dict[int, List[int]]`) — 键为选定的层索引（`int`）的字典，相关值为要在该层中修剪的头部列表（`int`列表）。例如，{1:
    [0, 2], 2: [2, 3]}将在第1层修剪头部0和2，在第2层修剪头部2和3。'
- en: Prunes heads of the base model.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 修剪基础模型的头部。
- en: '#### `register_for_auto_class`'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register_for_auto_class`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L3176)'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L3176)'
- en: '[PRE62]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Parameters
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`auto_class` (`str` or `type`, *optional*, defaults to `"TFAutoModel"`) — The
    auto class to register this new model with.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_class` (`str` 或 `type`, *可选*, 默认为 `"TFAutoModel"`) — 要注册此新模型的自动类。'
- en: Register this class with a given auto class. This should only be used for custom
    models as the ones in the library are already mapped with an auto class.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定的自动类注册此类。这应仅用于自定义模型，因为库中的模型已经与自动类映射。
- en: This API is experimental and may have some slight breaking changes in the next
    releases.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 此API是实验性的，可能在下一个版本中有一些轻微的破坏性更改。
- en: '#### `resize_token_embeddings`'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `resize_token_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1973)'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1973)'
- en: '[PRE63]'
  id: totrans-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Parameters
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`new_num_tokens` (`int`, *optional*) — The number of new tokens in the embedding
    matrix. Increasing the size will add newly initialized vectors at the end. Reducing
    the size will remove vectors from the end. If not provided or `None`, just returns
    a pointer to the input tokens without doing anything.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new_num_tokens` (`int`, *可选*) — 嵌入矩阵中的新标记数量。增加大小将在末尾添加新初始化的向量。减小大小将从末尾删除向量。如果未提供或为`None`，则只返回指向输入标记的指针，而不执行任何操作。'
- en: Returns
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tf.Variable` or `tf.keras.layers.Embedding`'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.Variable` 或 `tf.keras.layers.Embedding`'
- en: Pointer to the input tokens of the model.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输入标记的指针。
- en: Resizes input token embeddings matrix of the model if `new_num_tokens != config.vocab_size`.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`new_num_tokens != config.vocab_size`，则调整模型的输入标记嵌入矩阵大小。
- en: Takes care of tying weights embeddings afterwards if the model class has a `tie_weights()`
    method.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型类具有`tie_weights()`方法，则在之后处理权重嵌入。
- en: '#### `save_pretrained`'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2323)'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2323)'
- en: '[PRE64]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Parameters
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str`) — Directory to which to save. Will be created if it
    doesn’t exist.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str`) — 要保存到的目录。如果不存在，将创建该目录。'
- en: '`saved_model` (`bool`, *optional*, defaults to `False`) — If the model has
    to be saved in saved model format as well or not.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`saved_model` (`bool`, *可选*, 默认为 `False`) — 是否还要将模型保存为saved model格式。'
- en: '`version` (`int`, *optional*, defaults to 1) — The version of the saved model.
    A saved model needs to be versioned in order to be properly loaded by TensorFlow
    Serving as detailed in the official documentation [https://www.tensorflow.org/tfx/serving/serving_basic](https://www.tensorflow.org/tfx/serving/serving_basic)'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version` (`int`, *可选*, 默认为 1) — 已保存模型的版本。为了能够被TensorFlow Serving正确加载，保存的模型需要进行版本化，详细信息请参阅官方文档[https://www.tensorflow.org/tfx/serving/serving_basic](https://www.tensorflow.org/tfx/serving/serving_basic)'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为 `False`) — 是否在保存后将模型推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`名称）。'
- en: '`signatures` (`dict` or `tf.function`, *optional*) — Model’s signature used
    for serving. This will be passed to the `signatures` argument of model.save().'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`signatures` (`dict` 或 `tf.function`, *可选*) — 用于serving的模型签名。这将传递给model.save()的`signatures`参数。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"10GB"`) — The maximum
    size for a checkpoint before being sharded. Checkpoints shard will then be each
    of size lower than this size. If expressed as a string, needs to be digits followed
    by a unit (like `"5MB"`).'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int` 或 `str`, *可选*, 默认为 `"10GB"`) - 在分片之前的检查点的最大大小。然后，检查点分片将小于此大小。如果表示为字符串，需要是数字后跟一个单位（如
    `"5MB"`）。'
- en: If a single weight of the model is bigger than `max_shard_size`, it will be
    in its own checkpoint shard which will be bigger than `max_shard_size`.
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果模型的单个权重大于 `max_shard_size`，它将在自己的检查点分片中，该分片将大于 `max_shard_size`。
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr` (`bool`, *可选*, 默认为 `False`) - 是否创建带有上传文件的 PR 或直接提交。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `False`) — Whether to
    save the model using `safetensors` or the traditional TensorFlow way (that uses
    `h5`).'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *可选*, 默认为 `False`) - 是否使用 `safetensors` 或传统的
    TensorFlow 方式（使用 `h5`）保存模型。'
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 `bool`, *可选*) - 用作远程文件的HTTP bearer授权的令牌。如果为 `True`，或未指定，将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) - 传递给 [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    方法的额外关键字参数。'
- en: Save a model and its configuration file to a directory, so that it can be re-loaded
    using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    class method.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型及其配置文件保存到目录中，以便可以使用 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    类方法重新加载。
- en: '#### `serving`'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `serving`'
- en: '[PRE65]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Parameters
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`Method` used for serving the model. Does not have a specific signature, but
    will be specialized as concrete —'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于提供模型的方法。没有特定的签名，但将作为具体的专业化 -
- en: '`functions` when saving with `save_pretrained`. — inputs (`Dict[str, tf.Tensor]`):
    The input of the saved model as a dictionary of tensors.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `save_pretrained` 保存时的 `functions`。 - 输入（`Dict[str, tf.Tensor]`）：保存模型的输入，作为张量字典。
- en: '#### `serving_output`'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `serving_output`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1277)'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1277)'
- en: '[PRE66]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Prepare the output of the saved model. Can be overridden if specific serving
    modifications are required.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 准备保存模型的输出。如果需要特定的服务修改，可以进行覆盖。
- en: '#### `set_bias`'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_bias`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1948)'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1948)'
- en: '[PRE67]'
  id: totrans-552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Parameters
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`value` (`Dict[tf.Variable]`) — All the new bias attached to an LM head.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value` (`Dict[tf.Variable]`) - 附加到 LM 头部的所有新偏置。'
- en: Set all the bias in the LM head.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 LM 头部中的所有偏置。
- en: '#### `set_input_embeddings`'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_input_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1851)'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1851)'
- en: '[PRE68]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Parameters
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`value` (`tf.Variable`) — The new weights mapping hidden states to vocabulary.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value` (`tf.Variable`) - 将隐藏状态映射到词汇表的新权重。'
- en: Set model’s input embeddings
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 设置模型的输入嵌入
- en: '#### `set_output_embeddings`'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_output_embeddings`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1891)'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1891)'
- en: '[PRE69]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Parameters
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`value` (`tf.Variable`) — The new weights mapping hidden states to vocabulary.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value` (`tf.Variable`) - 将隐藏状态映射到词汇表的新权重。'
- en: Set model’s output embeddings
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 设置模型的输出嵌入
- en: '#### `test_step`'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `test_step`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1687)'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1687)'
- en: '[PRE70]'
  id: totrans-570
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: A modification of Keras’s default `train_step` that correctly handles matching
    outputs to labels for our models and supports directly training on the loss output
    head. In addition, it ensures input keys are copied to the labels where appropriate.
    It will also copy label keys into the input dict when using the dummy loss, to
    ensure that they are available to the model during the forward pass.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 对 Keras 默认的 `train_step` 进行修改，正确处理模型输出与标签的匹配，并支持直接在损失输出头上进行训练。此外，它确保适当时将输入键复制到标签中。当使用虚拟损失时，它还会将标签键复制到输入字典中，以确保它们在前向传递期间对模型可用。
- en: '#### `train_step`'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `train_step`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1579)'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1579)'
- en: '[PRE71]'
  id: totrans-574
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: A modification of Keras’s default `train_step` that correctly handles matching
    outputs to labels for our models and supports directly training on the loss output
    head. In addition, it ensures input keys are copied to the labels where appropriate.
    It will also copy label keys into the input dict when using the dummy loss, to
    ensure that they are available to the model during the forward pass.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 对 Keras 默认的 `train_step` 进行修改，正确处理模型输出与标签的匹配，并支持直接在损失输出头上进行训练。此外，它确保适当时将输入键复制到标签中。当使用虚拟损失时，它还会将标签键复制到输入字典中，以确保它们在前向传递期间对模型可用。
- en: TFModelUtilsMixin
  id: totrans-576
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFModelUtilsMixin
- en: '### `class transformers.modeling_tf_utils.TFModelUtilsMixin`'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.modeling_tf_utils.TFModelUtilsMixin`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L104)'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L104)'
- en: '[PRE72]'
  id: totrans-579
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: A few utilities for `tf.keras.Model`, to be used as a mixin.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 用于 `tf.keras.Model` 的一些实用程序，可用作混合。
- en: '#### `num_parameters`'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `num_parameters`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L109)'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L109)'
- en: '[PRE73]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Parameters
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`only_trainable` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return only the number of trainable parameters'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`only_trainable` (`bool`, *optional*, 默认为 `False`) — 是否仅返回可训练参数的数量'
- en: Returns
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The number of parameters.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 参数数量。
- en: Get the number of (optionally, trainable) parameters in the model.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 获取模型中的（可选的可训练）参数数量。
- en: FlaxPreTrainedModel
  id: totrans-590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxPreTrainedModel
- en: '### `class transformers.FlaxPreTrainedModel`'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxPreTrainedModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L166)'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L166)'
- en: '[PRE74]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Base class for all models.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 所有模型的基类。
- en: '[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)
    takes care of storing the configuration of the models and handles methods for
    loading, downloading and saving models.'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)
    负责存储模型的配置，并处理加载、下载和保存模型的方法。'
- en: 'Class attributes (overridden by derived classes):'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 类属性（由派生类覆盖）：
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — A subclass of [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    to use as configuration class for this model architecture.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 用作此模型架构的配置类的 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的子类。'
- en: '`base_model_prefix` (`str`) — A string indicating the attribute associated
    to the base model in derived classes of the same architecture adding modules on
    top of the base model.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_model_prefix` (`str`) — 一个字符串，指示派生类中基础模型关联的属性，该派生类在基础模型之上添加模块。'
- en: '`main_input_name` (`str`) — The name of the principal input to the model (often
    `input_ids` for NLP models, `pixel_values` for vision models and `input_values`
    for speech models).'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main_input_name` (`str`) — 模型的主要输入的名称（通常为 NLP 模型的 `input_ids`，视觉模型的 `pixel_values`
    和语音模型的 `input_values`）。'
- en: '#### `push_to_hub`'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `push_to_hub`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
- en: '[PRE75]'
  id: totrans-602
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Parameters
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`repo_id` (`str`) — The name of the repository you want to push your model
    to. It should contain your organization name when pushing to a given organization.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) — 您要将模型推送到的存储库的名称。在推送到给定组织时，应包含您的组织名称。'
- en: '`use_temp_dir` (`bool`, *optional*) — Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_temp_dir` (`bool`, *optional*) — 是否使用临时目录存储在推送到 Hub 之前保存的文件。如果没有名为 `repo_id`
    的目录，则默认为 `True`，否则为 `False`。'
- en: '`commit_message` (`str`, *optional*) — Message to commit while pushing. Will
    default to `"Upload model"`.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message` (`str`, *optional*) — 推送时要提交的消息。默认为 `"Upload model"`。'
- en: '`private` (`bool`, *optional*) — Whether or not the repository created should
    be private.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private` (`bool`, *optional*) — 是否创建的存储库应为私有。'
- en: '`token` (`bool` or `str`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`bool` 或 `str`, *optional*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。如果未指定 `repo_url`，则默认为 `True`。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"5GB"`) — Only applicable
    for models. The maximum size for a checkpoint before being sharded. Checkpoints
    shard will then be each of size lower than this size. If expressed as a string,
    needs to be digits followed by a unit (like `"5MB"`). We default it to `"5GB"`
    so that users can easily load models on free-tier Google Colab instances without
    any CPU OOM issues.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int` 或 `str`, *optional*, 默认为 `"5GB"`) — 仅适用于模型。在被分片之前的检查点的最大大小。然后检查点将被分成小于此大小的每个部分。如果表示为字符串，需要是数字后跟一个单位（如
    `"5MB"`）。我们将其默认为 `"5GB"`，以便用户可以在免费的 Google Colab 实例上轻松加载模型，而不会出现任何 CPU OOM 问题。'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr` (`bool`, *optional*, 默认为 `False`) — 是否创建一个带有上传文件的 PR 或直接提交。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether or
    not to convert the model weights in safetensors format for safer serialization.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, 默认为 `True`) — 是否将模型权重转换为 safetensors
    格式以进行更安全的序列化。'
- en: '`revision` (`str`, *optional*) — Branch to push the uploaded files to.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*) — 要将上传的文件推送到的分支。'
- en: '`commit_description` (`str`, *optional*) — The description of the commit that
    will be created'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_description` (`str`, *optional*) — 将要创建的提交的描述'
- en: '`tags` (`List[str]`, *optional*) — List of tags to push on the Hub.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags` (`List[str]`, *optional*) — 要推送到 Hub 上的标签列表。'
- en: Upload the model checkpoint to the 🤗 Model Hub.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 上传模型检查点到 🤗 Model Hub。
- en: 'Examples:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE76]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '#### `can_generate`'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `can_generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L506)'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L506)'
- en: '[PRE77]'
  id: totrans-620
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Returns whether this model can generate sequences with `.generate()`. Returns:
    `bool`: Whether this model can generate sequences with `.generate()`.'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '返回此模型是否可以使用 `.generate()` 生成序列。返回：`bool`: 此模型是否可以使用 `.generate()` 生成序列。'
- en: '#### `from_pretrained`'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L518)'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L518)'
- en: '[PRE78]'
  id: totrans-624
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Parameters
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`或`os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-627
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-628
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *pt index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_pt` should be set to `True`.
  id: totrans-629
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*pt索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_pt`应设置为`True`。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *optional*, 默认为 `jax.numpy.float32`) — 计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）之一。'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-631
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定了`dtype`，则所有计算将使用给定的`dtype`执行。
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`请注意，这仅指定计算的数据类型，不影响模型参数的数据类型。`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-633
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改模型参数的数据类型，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。
- en: '`model_args` (sequence of positional arguments, *optional*) — All remaining
    positional arguments will be passed to the underlying model’s `__init__` method.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（位置参数序列，*optional*） — 所有剩余的位置参数将传递给底层模型的`__init__`方法。'
- en: '`config` (`Union[PretrainedConfig, str, os.PathLike]`, *optional*) — Can be
    either:'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` (`Union[PretrainedConfig, str, os.PathLike]`, *optional*) — 可以是：'
- en: an instance of a class derived from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
  id: totrans-636
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)派生的类的实例，
- en: a string or path valid as input to [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained).
  id: totrans-637
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个作为[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)输入有效的字符串或路径。
- en: 'Configuration for the model to use instead of an automatically loaded configuration.
    Configuration can be automatically loaded when:'
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要使用的模型配置，而不是自动加载的配置。当以下情况自动加载配置时：
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-639
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-640
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-641
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — 如果不应使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, 默认为 `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`ignore_mismatched_sizes` (`bool`, *optional*, defaults to `False`) — Whether
    or not to raise an error if some of the weights from the checkpoint do not have
    the same size as the weights of the model (if for instance, you are instantiating
    a model with 10 labels from a checkpoint with 3 labels).'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_mismatched_sizes` (`bool`, *optional*, 默认为 `False`) — 如果检查点中的某些权重与模型的权重大小不同，是否引发错误（例如，如果您从具有3个标签的检查点实例化具有10个标签的模型）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (i.e., do not try to download the model).'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（即，不尝试下载模型）。'
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 `bool`, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，或未指定，将使用运行
    `huggingface-cli login` 时生成的令牌 (存储在 `~/.huggingface` 中)。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: Instantiate a pretrained flax model from a pre-trained model configuration.
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型配置实例化一个预训练的 flax 模型。
- en: The warning *Weights from XXX not initialized from pretrained model* means that
    the weights of XXX do not come pretrained with the rest of the model. It is up
    to you to train those weights with a downstream fine-tuning task.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 警告 *来自 XXX 的权重未从预训练模型初始化* 意味着 XXX 的权重不是与模型的其余部分一起预训练的。您需要使用下游微调任务来训练这些权重。
- en: The warning *Weights from XXX not used in YYY* means that the layer XXX is not
    used by YYY, therefore those weights are discarded.
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 警告 *来自 XXX 的权重在 YYY 中未使用* 意味着层 XXX 在 YYY 中未被使用，因此这些权重被丢弃。
- en: 'Examples:'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE79]'
  id: totrans-655
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '#### `load_flax_sharded_weights`'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_flax_sharded_weights`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L459)'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L459)'
- en: '[PRE80]'
  id: totrans-658
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Parameters
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`shard_files` (`List[str]` — The list of shard files to load.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shard_files` (`List[str]` — 要加载的分片文件列表。'
- en: Returns
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict`'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict`'
- en: 'A nested dictionary of the model parameters, in the expected format for flax
    models : `{''model'': {''params'': {''...''}}}`.'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: '模型参数的嵌套字典，符合 flax 模型的预期格式：`{''model'': {''params'': {''...''}}}`。'
- en: This is the same as `flax.serialization.from_bytes` (https:lax.readthedocs.io/en/latest/_modules/flax/serialization.html#from_bytes)
    but for a sharded checkpoint.
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 这与 `flax.serialization.from_bytes` 相同 (https:lax.readthedocs.io/en/latest/_modules/flax/serialization.html#from_bytes)，但适用于分片检查点。
- en: 'This load is performed efficiently: each checkpoint shard is loaded one by
    one in RAM and deleted after being loaded in the model.'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 这种加载效率很高：每个检查点分片都会逐个加载到 RAM 中，并在加载到模型后删除。
- en: '#### `register_for_auto_class`'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register_for_auto_class`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L1226)'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L1226)'
- en: '[PRE81]'
  id: totrans-668
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Parameters
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`auto_class` (`str` or `type`, *optional*, defaults to `"FlaxAutoModel"`) —
    The auto class to register this new model with.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_class` (`str` 或 `type`, *可选*, 默认为 `"FlaxAutoModel"`) — 用于注册这个新模型的自动类。'
- en: Register this class with a given auto class. This should only be used for custom
    models as the ones in the library are already mapped with an auto class.
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定的自动类注册此类。这应该仅用于自定义模型，因为库中的模型已经与自动类映射。
- en: This API is experimental and may have some slight breaking changes in the next
    releases.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 此 API 是实验性的，可能在下一个版本中有一些轻微的破坏性更改。
- en: '#### `save_pretrained`'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L1088)'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L1088)'
- en: '[PRE82]'
  id: totrans-675
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Parameters
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory to which to save. Will
    be created if it doesn’t exist.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` 或 `os.PathLike`) — 要保存到的目录。如果不存在，将创建。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为 `False`) — 保存模型后是否将其推送到 Hugging Face 模型中心。您可以使用
    `repo_id` 指定要推送到的存储库 (将默认为您的命名空间中的 `save_directory` 名称)。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"10GB"`) — The maximum
    size for a checkpoint before being sharded. Checkpoints shard will then be each
    of size lower than this size. If expressed as a string, needs to be digits followed
    by a unit (like `"5MB"`).'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int` 或 `str`, *可选*, 默认为 `"10GB"`) — 在分片之前检查点的最大大小。检查点分片将小于此大小。如果表示为字符串，需要是数字后跟一个单位
    (如 `"5MB"`)。'
- en: If a single weight of the model is bigger than `max_shard_size`, it will be
    in its own checkpoint shard which will be bigger than `max_shard_size`.
  id: totrans-680
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果模型的单个权重大于 `max_shard_size`，它将在自己的检查点分片中，该分片将大于 `max_shard_size`。
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 `bool`, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，或未指定，将使用运行
    `huggingface-cli login` 时生成的令牌 (存储在 `~/.huggingface` 中)。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) — 传递给 [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    方法的额外关键字参数。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `False`) — Whether to
    save the model using `safetensors` or through msgpack.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *可选*, 默认为 `False`) — 是否使用 `safetensors` 或通过 msgpack
    保存模型。'
- en: Save a model and its configuration file to a directory, so that it can be re-loaded
    using the `[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)`
    class method
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型及其配置文件保存到目录中，以便可以使用 `[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)`
    类方法重新加载。
- en: '#### `to_bf16`'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_bf16`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L329)'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L329)'
- en: '[PRE83]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Parameters
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`params` (`Union[Dict, FrozenDict]`) — A `PyTree` of model parameters.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) — 模型参数的 `PyTree`。'
- en: '`mask` (`Union[Dict, FrozenDict]`) — A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans, `True` for params you want to cast,
    and should be `False` for those you want to skip.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask` (`Union[Dict, FrozenDict]`) — 与 `params` 树具有相同结构的 `PyTree`。叶子应为布尔值，对于要转换的参数应为
    `True`，对于要跳过的参数应为 `False`。'
- en: Cast the floating-point `params` to `jax.numpy.bfloat16`. This returns a new
    `params` tree and does not cast the `params` in place.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 将浮点 `params` 转换为 `jax.numpy.bfloat16`。这将返回一个新的 `params` 树，不会直接在原地转换 `params`。
- en: This method can be used on TPU to explicitly convert the model parameters to
    bfloat16 precision to do full half-precision training or to save weights in bfloat16
    for inference in order to save memory and improve speed.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法可在 TPU 上使用，显式将模型参数转换为 bfloat16 精度，以进行完全的半精度训练或以 bfloat16 保存权重以用于推理，以节省内存并提高速度。
- en: 'Examples:'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE84]'
  id: totrans-694
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '#### `to_fp16`'
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_fp16`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L395)'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L395)'
- en: '[PRE85]'
  id: totrans-697
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Parameters
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`params` (`Union[Dict, FrozenDict]`) — A `PyTree` of model parameters.'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) — 模型参数的 `PyTree`。'
- en: '`mask` (`Union[Dict, FrozenDict]`) — A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans, `True` for params you want to cast,
    and should be `False` for those you want to skip'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask` (`Union[Dict, FrozenDict]`) — 与 `params` 树具有相同结构的 `PyTree`。叶子应为布尔值，对于要转换的参数应为
    `True`，对于要跳过的参数应为 `False`。'
- en: Cast the floating-point `parmas` to `jax.numpy.float16`. This returns a new
    `params` tree and does not cast the `params` in place.
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 将浮点 `params` 转换为 `jax.numpy.float16`。这将返回一个新的 `params` 树，不会直接在原地转换 `params`。
- en: This method can be used on GPU to explicitly convert the model parameters to
    float16 precision to do full half-precision training or to save weights in float16
    for inference in order to save memory and improve speed.
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法可在 GPU 上使用，显式将模型参数转换为 float16 精度，以进行完全的半精度训练或以 float16 保存权重以用于推理，以节省内存并提高速度。
- en: 'Examples:'
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE86]'
  id: totrans-704
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '#### `to_fp32`'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_fp32`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L368)'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L368)'
- en: '[PRE87]'
  id: totrans-707
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Parameters
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`params` (`Union[Dict, FrozenDict]`) — A `PyTree` of model parameters.'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) — 模型参数的 `PyTree`。'
- en: '`mask` (`Union[Dict, FrozenDict]`) — A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans, `True` for params you want to cast,
    and should be `False` for those you want to skip'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask` (`Union[Dict, FrozenDict]`) — 与 `params` 树具有相同结构的 `PyTree`。叶子应为布尔值，对于要转换的参数应为
    `True`，对于要跳过的参数应为 `False`。'
- en: Cast the floating-point `parmas` to `jax.numpy.float32`. This method can be
    used to explicitly convert the model parameters to fp32 precision. This returns
    a new `params` tree and does not cast the `params` in place.
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: 将浮点 `params` 转换为 `jax.numpy.float32`。此方法可用于显式将模型参数转换为 fp32 精度。这将返回一个新的 `params`
    树，不会直接在原地转换 `params`。
- en: 'Examples:'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE88]'
  id: totrans-713
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Pushing to the Hub
  id: totrans-714
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推送到 Hub
- en: '### `class transformers.utils.PushToHubMixin`'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.utils.PushToHubMixin`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L639)'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L639)'
- en: '[PRE89]'
  id: totrans-717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: A Mixin containing the functionality to push a model or tokenizer to the hub.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含将模型或分词器推送到 Hub 的功能的 Mixin。
- en: '#### `push_to_hub`'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `push_to_hub`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
- en: '[PRE90]'
  id: totrans-721
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Parameters
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`repo_id` (`str`) — The name of the repository you want to push your {object}
    to. It should contain your organization name when pushing to a given organization.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) — 您要将 {object} 推送到的存储库的名称。在推送到给定组织时，应包含您的组织名称。'
- en: '`use_temp_dir` (`bool`, *optional*) — Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_temp_dir` (`bool`，*可选*) — 是否使用临时目录存储在推送到 Hub 之前保存的文件。如果没有名为 `repo_id`
    的目录，则默认为 `True`，否则为 `False`。'
- en: '`commit_message` (`str`, *optional*) — Message to commit while pushing. Will
    default to `"Upload {object}"`.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message` (`str`，*可选*) — 推送时要提交的消息。默认为 `"Upload {object}"`。'
- en: '`private` (`bool`, *optional*) — Whether or not the repository created should
    be private.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private` (`bool`，*可选*) — 创建的存储库是否应为私有。'
- en: '`token` (`bool` or `str`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`bool` 或 `str`，*可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface`）。如果未指定 `repo_url`，则默认为 `True`。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"5GB"`) — Only applicable
    for models. The maximum size for a checkpoint before being sharded. Checkpoints
    shard will then be each of size lower than this size. If expressed as a string,
    needs to be digits followed by a unit (like `"5MB"`). We default it to `"5GB"`
    so that users can easily load models on free-tier Google Colab instances without
    any CPU OOM issues.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int` 或 `str`，*可选*，默认为 `"5GB"`) — 仅适用于模型。在被分片之前的检查点的最大大小。然后检查点将被分成小于此大小的每个分片。如果表示为字符串，需要是数字后跟一个单位（如
    `"5MB"`）。我们将其默认为 `"5GB"`，以便用户可以在免费的 Google Colab 实例上轻松加载模型，而不会出现任何 CPU OOM 问题。'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr` (`bool`，*可选*，默认为 `False`) — 是否创建一个带有上传文件的 PR 或直接提交。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether or
    not to convert the model weights in safetensors format for safer serialization.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *可选*，默认为`True`) — 是否将模型权重转换为safetensors格式以进行更安全的序列化。'
- en: '`revision` (`str`, *optional*) — Branch to push the uploaded files to.'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*) — 要将上传的文件推送到的分支。'
- en: '`commit_description` (`str`, *optional*) — The description of the commit that
    will be created'
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_description` (`str`, *可选*) — 将创建的提交描述'
- en: '`tags` (`List[str]`, *optional*) — List of tags to push on the Hub.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags` (`List[str]`, *可选*) — 要推送到中心的标签列表。'
- en: Upload the {object_files} to the 🤗 Model Hub.
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 将{object_files}上传到🤗模型中心。
- en: 'Examples:'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE91]'
  id: totrans-736
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Sharded checkpoints
  id: totrans-737
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分片检查点
- en: '#### `transformers.modeling_utils.load_sharded_checkpoint`'
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `transformers.modeling_utils.load_sharded_checkpoint`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L415)'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L415)'
- en: '[PRE92]'
  id: totrans-740
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Parameters
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model in which to load the checkpoint.'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要加载检查点的模型。'
- en: '`folder` (`str` or `os.PathLike`) — A path to a folder containing the sharded
    checkpoint.'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`folder` (`str`或`os.PathLike`) — 包含分片检查点的文件夹路径。'
- en: '`strict` (`bool`, *optional`, defaults to` True`) — Whether to strictly enforce
    that the keys in the model state dict match the keys in the sharded checkpoint.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strict` (`bool`, *可选*，默认为`True`) — 是否严格执行模型状态字典中的键与分片检查点中的键匹配。'
- en: '`prefer_safe` (`bool`, *optional*, defaults to `False`) — If both safetensors
    and PyTorch save files are present in checkpoint and `prefer_safe` is True, the
    safetensors files will be loaded. Otherwise, PyTorch files are always loaded when
    possible.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefer_safe` (`bool`, *可选*，默认为`False`) — 如果检查点中同时存在safetensors和PyTorch保存文件，并且`prefer_safe`为True，则将加载safetensors文件。否则，尽可能加载PyTorch文件。'
- en: Returns
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`NamedTuple`'
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: '`NamedTuple`'
- en: A named tuple with `missing_keys` and `unexpected_keys` fields
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 一个带有`missing_keys`和`unexpected_keys`字段的命名元组
- en: '`missing_keys` is a list of str containing the missing keys'
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`missing_keys`是一个包含缺失键的字符串列表'
- en: '`unexpected_keys` is a list of str containing the unexpected keys'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unexpected_keys`是一个包含意外键的字符串列表'
- en: This is the same as [`torch.nn.Module.load_state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict)
    but for a sharded checkpoint.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 这与[`torch.nn.Module.load_state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict)相同，但适用于分片检查点。
- en: 'This load is performed efficiently: each checkpoint shard is loaded one by
    one in RAM and deleted after being loaded in the model.'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 这种加载效率很高：每个检查点分片都会逐个在RAM中加载，加载到模型后会被删除。
