- en: Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '原文链接: [https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The pipelines are a great and easy way to use models for inference. These pipelines
    are objects that abstract most of the complex code from the library, offering
    a simple API dedicated to several tasks, including Named Entity Recognition, Masked
    Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering.
    See the [task summary](../task_summary) for examples of use.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 管道是使用模型进行推断的一种很好且简单的方式。这些管道是抽象出库中大部分复杂代码的对象，提供了专门用于多个任务的简单 API，包括命名实体识别、掩码语言建模、情感分析、特征提取和问答。查看[任务摘要](../task_summary)以获取使用示例。
- en: 'There are two categories of pipeline abstractions to be aware about:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种要注意的管道抽象类别：
- en: The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    which is the most powerful object encapsulating all other pipelines.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    是封装所有其他管道的最强大对象。'
- en: Task-specific pipelines are available for [audio](#audio), [computer vision](#computer-vision),
    [natural language processing](#natural-language-processing), and [multimodal](#multimodal)
    tasks.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对[音频](#audio)、[计算机视觉](#computer-vision)、[自然语言处理](#natural-language-processing)和[多模态](#multimodal)任务提供了特定任务的管道。
- en: The pipeline abstraction
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道抽象
- en: The *pipeline* abstraction is a wrapper around all the other available pipelines.
    It is instantiated as any other pipeline but can provide additional quality of
    life.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*pipeline* 抽象是围绕所有其他可用管道的包装器。它像任何其他管道一样实例化，但可以提供额外的生活质量。'
- en: 'Simple call on one item:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 简单调用一个项目：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you want to use a specific model from the [hub](https://huggingface.co)
    you can ignore the task if the model on the hub already defines it:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要使用来自[hub](https://huggingface.co)的特定模型，可以忽略任务，如果 hub 上的模型已经定义了它：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To call a pipeline on many items, you can call it with a *list*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要在多个项目上调用管道，可以使用*列表*调用它。
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To iterate over full datasets it is recommended to use a `dataset` directly.
    This means you don’t need to allocate the whole dataset at once, nor do you need
    to do batching yourself. This should work just as fast as custom loops on GPU.
    If it doesn’t don’t hesitate to create an issue.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要遍历完整数据集，建议直接使用`dataset`。这意味着您不需要一次性分配整个数据集，也不需要自己进行批处理。这应该与 GPU 上的自定义循环一样快。如果不是，请不要犹豫创建一个问题。
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For ease of use, a generator is also possible:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便使用，也可以使用生成器：
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `transformers.pipeline`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `transformers.pipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/__init__.py#L531)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/__init__.py#L531)'
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`task` (`str`) — The task defining which pipeline will be returned. Currently
    accepted tasks are:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`) — 定义将返回哪个管道的任务。当前接受的任务有：'
- en: '`"audio-classification"`: will return a [AudioClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AudioClassificationPipeline).'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"audio-classification"`: 将返回一个[AudioClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AudioClassificationPipeline)。'
- en: '`"automatic-speech-recognition"`: will return a [AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline).'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"automatic-speech-recognition"`: 将返回一个[AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)。'
- en: '`"conversational"`: will return a [ConversationalPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ConversationalPipeline).'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"conversational"`: 将返回一个[ConversationalPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ConversationalPipeline)。'
- en: '`"depth-estimation"`: will return a [DepthEstimationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.DepthEstimationPipeline).'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"depth-estimation"`: 将返回一个[DepthEstimationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.DepthEstimationPipeline)。'
- en: '`"document-question-answering"`: will return a [DocumentQuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.DocumentQuestionAnsweringPipeline).'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"document-question-answering"`: 将返回一个[DocumentQuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.DocumentQuestionAnsweringPipeline)。'
- en: '`"feature-extraction"`: will return a [FeatureExtractionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.FeatureExtractionPipeline).'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"feature-extraction"`: 将返回一个[FeatureExtractionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.FeatureExtractionPipeline)。'
- en: '`"fill-mask"`: will return a [FillMaskPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.FillMaskPipeline):.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"fill-mask"`: 将返回一个[FillMaskPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.FillMaskPipeline)。'
- en: '`"image-classification"`: will return a [ImageClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageClassificationPipeline).'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"image-classification"`: 将返回一个[ImageClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageClassificationPipeline)。'
- en: '`"image-segmentation"`: will return a [ImageSegmentationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageSegmentationPipeline).'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"image-segmentation"`: 将返回一个[ImageSegmentationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageSegmentationPipeline)。'
- en: '`"image-to-image"`: will return a [ImageToImagePipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageToImagePipeline).'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"image-to-image"`: 将返回一个[ImageToImagePipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageToImagePipeline)。'
- en: '`"image-to-text"`: will return a [ImageToTextPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageToTextPipeline).'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"image-to-text"`: 将返回一个[ImageToTextPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ImageToTextPipeline)。'
- en: '`"mask-generation"`: will return a [MaskGenerationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.MaskGenerationPipeline).'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"mask-generation"`: 将返回一个[MaskGenerationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.MaskGenerationPipeline)。'
- en: '`"object-detection"`: will return a [ObjectDetectionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ObjectDetectionPipeline).'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"object-detection"`：将返回一个[ObjectDetectionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ObjectDetectionPipeline)。'
- en: '`"question-answering"`: will return a [QuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline).'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"question-answering"`：将返回一个[QuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline)。'
- en: '`"summarization"`: will return a [SummarizationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.SummarizationPipeline).'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"summarization"`：将返回一个[SummarizationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.SummarizationPipeline)。'
- en: '`"table-question-answering"`: will return a [TableQuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TableQuestionAnsweringPipeline).'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"table-question-answering"`：将返回一个[TableQuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TableQuestionAnsweringPipeline)。'
- en: '`"text2text-generation"`: will return a [Text2TextGenerationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline).'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"text2text-generation"`：将返回一个[Text2TextGenerationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline)。'
- en: '`"text-classification"` (alias `"sentiment-analysis"` available): will return
    a [TextClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextClassificationPipeline).'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"text-classification"`（别名`"sentiment-analysis"`可用）：将返回一个[TextClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextClassificationPipeline)。'
- en: '`"text-generation"`: will return a [TextGenerationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextGenerationPipeline):.'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"text-generation"`：将返回一个[TextGenerationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextGenerationPipeline)。'
- en: '`"text-to-audio"` (alias `"text-to-speech"` available): will return a [TextToAudioPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextToAudioPipeline):.'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"text-to-audio"`（别名`"text-to-speech"`可用）：将返回一个[TextToAudioPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextToAudioPipeline)。'
- en: '`"token-classification"` (alias `"ner"` available): will return a [TokenClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TokenClassificationPipeline).'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"token-classification"`（别名`"ner"`可用）：将返回一个[TokenClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TokenClassificationPipeline)。'
- en: '`"translation"`: will return a [TranslationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TranslationPipeline).'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"translation"`：将返回一个[TranslationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TranslationPipeline)。'
- en: '`"translation_xx_to_yy"`: will return a [TranslationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TranslationPipeline).'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"translation_xx_to_yy"`：将返回一个[TranslationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TranslationPipeline)。'
- en: '`"video-classification"`: will return a [VideoClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.VideoClassificationPipeline).'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"video-classification"`：将返回一个[VideoClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.VideoClassificationPipeline)。'
- en: '`"visual-question-answering"`: will return a [VisualQuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.VisualQuestionAnsweringPipeline).'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"visual-question-answering"`：将返回一个[VisualQuestionAnsweringPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.VisualQuestionAnsweringPipeline)。'
- en: '`"zero-shot-classification"`: will return a [ZeroShotClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline).'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"zero-shot-classification"`：将返回一个[ZeroShotClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline)。'
- en: '`"zero-shot-image-classification"`: will return a [ZeroShotImageClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotImageClassificationPipeline).'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"zero-shot-image-classification"`：将返回一个[ZeroShotImageClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotImageClassificationPipeline)。'
- en: '`"zero-shot-audio-classification"`: will return a [ZeroShotAudioClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotAudioClassificationPipeline).'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"zero-shot-audio-classification"`：将返回一个[ZeroShotAudioClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotAudioClassificationPipeline)。'
- en: '`"zero-shot-object-detection"`: will return a [ZeroShotObjectDetectionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotObjectDetectionPipeline).'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"zero-shot-object-detection"`：将返回一个[ZeroShotObjectDetectionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotObjectDetectionPipeline)。'
- en: '`model` (`str` or [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel),
    *optional*) — The model that will be used by the pipeline to make predictions.
    This can be a model identifier or an actual instance of a pretrained model inheriting
    from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    (for PyTorch) or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    (for TensorFlow).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`str`或[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)或[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)，*可选*）—
    该模型将被管道用于进行预测。这可以是一个模型标识符或一个实际的继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)（对于PyTorch）或[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)（对于TensorFlow）的预训练模型实例。'
- en: If not provided, the default for the `task` will be loaded.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未提供，`task`的默认值将被加载。
- en: '`config` (`str` or [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — The configuration that will be used by the pipeline to instantiate
    the model. This can be a model identifier or an actual pretrained model configuration
    inheriting from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If not provided, the default configuration file for the requested model will
    be used. That means that if `model` is given, its default configuration will be
    used. However, if `model` is not supplied, this `task`’s default model’s config
    is used instead.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`tokenizer` (`str` or [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer),
    *optional*) — The tokenizer that will be used by the pipeline to encode data for
    the model. This can be a model identifier or an actual pretrained tokenizer inheriting
    from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If not provided, the default tokenizer for the given `model` will be loaded
    (if it is a string). If `model` is not specified or not a string, then the default
    tokenizer for `config` is loaded (if it is a string). However, if `config` is
    also not given or not a string, then the default tokenizer for the given `task`
    will be loaded.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`feature_extractor` (`str` or `PreTrainedFeatureExtractor`, *optional*) — The
    feature extractor that will be used by the pipeline to encode data for the model.
    This can be a model identifier or an actual pretrained feature extractor inheriting
    from `PreTrainedFeatureExtractor`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature extractors are used for non-NLP models, such as Speech or Vision models
    as well as multi-modal models. Multi-modal models will also require a tokenizer
    to be passed.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If not provided, the default feature extractor for the given `model` will be
    loaded (if it is a string). If `model` is not specified or not a string, then
    the default feature extractor for `config` is loaded (if it is a string). However,
    if `config` is also not given or not a string, then the default feature extractor
    for the given `task` will be loaded.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — When passing a task
    name or a string model identifier: The specific model version to use. It can be
    a branch name, a tag name, or a commit id, since we use a git-based system for
    storing models and other artifacts on huggingface.co, so `revision` can be any
    identifier allowed by git.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_fast` (`bool`, *optional*, defaults to `True`) — Whether or not to use
    a Fast tokenizer if possible (a [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_auth_token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer
    authorization for remote files. If `True`, will use the token generated when running
    `huggingface-cli login` (stored in `~/.huggingface`).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int` or `str` or `torch.device`) — Defines the device (*e.g.*, `"cpu"`,
    `"cuda:1"`, `"mps"`, or a GPU ordinal rank like `1`) on which this pipeline will
    be allocated.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device_map` (`str` or `Dict[str, Union[int, str, torch.device]`, *optional*)
    — Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate`
    library is present, set `device_map="auto"` to compute the most optimized `device_map`
    automatically (see [here](https://huggingface.co/docs/accelerate/main/en/package_reference/big_modeling#accelerate.cpu_offload)
    for more information).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not use `device_map` AND `device` at the same time as they will conflict
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要同时使用`device_map`和`device`，因为它们会发生冲突
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) — Sent directly as `model_kwargs`
    (just a simpler shortcut) to use the available precision for this model (`torch.float16`,
    `torch.bfloat16`, … or `"auto"`).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype`（`str`或`torch.dtype`，*可选*）- 直接发送为`model_kwargs`（只是一个更简单的快捷方式）以使用此模型的可用精度（`torch.float16`，`torch.bfloat16`，...或`"auto"`）。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom code defined on the Hub in their own modeling, configuration,
    tokenization or even pipeline files. This option should only be set to `True`
    for repositories you trust and in which you have read the code, as it will execute
    code present on the Hub on your local machine.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义的自定义代码在其自己的建模、配置、标记化甚至管道文件中执行。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`model_kwargs` (`Dict[str, Any]`, *optional*) — Additional dictionary of keyword
    arguments passed along to the model’s `from_pretrained(..., **model_kwargs)` function.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_kwargs`（`Dict[str, Any]`，*可选*）- 传递给模型的`from_pretrained(..., **model_kwargs)`函数的其他关键字参数字典。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional keyword arguments passed
    along to the specific pipeline init (see the documentation for the corresponding
    pipeline class for possible values).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*）- 传递给特定管道初始化的其他关键字参数（请参阅相应管道类的文档以获取可能的值）。'
- en: Returns
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Pipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)'
- en: A suitable pipeline for the task.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 适合任务的管道。
- en: Utility factory method to build a [Pipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 构建[Pipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)的实用工厂方法。
- en: 'Pipelines are made of:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 管道由以下组成：
- en: A [tokenizer](tokenizer) in charge of mapping raw textual input to token.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负责将原始文本输入映射到标记的[分词器](tokenizer)。
- en: A [model](model) to make predictions from the inputs.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输入中进行预测的[模型](model)。
- en: Some (optional) post processing for enhancing model’s output.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些（可选的）后处理以增强模型的输出。
- en: 'Examples:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Pipeline batching
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道批处理
- en: All pipelines can use batching. This will work whenever the pipeline uses its
    streaming ability (so when passing lists or `Dataset` or `generator`).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 所有管道都可以使用批处理。每当管道使用其流式处理能力时（因此当传递列表或`Dataset`或`generator`时），它将起作用。
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: However, this is not automatically a win for performance. It can be either a
    10x speedup or 5x slowdown depending on hardware, data and the actual model being
    used.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不自动意味着性能提升。它可能是10倍的加速或5倍的减速，取决于硬件、数据和实际使用的模型。
- en: 'Example where it’s mostly a speedup:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 主要是加速的示例：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Example where it’s most a slowdown:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 主要是减速的示例：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is a occasional very long sentence compared to the other. In that case,
    the **whole** batch will need to be 400 tokens long, so the whole batch will be
    [64, 400] instead of [64, 4], leading to the high slowdown. Even worse, on bigger
    batches, the program simply crashes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他句子相比，这是一个偶尔非常长的句子。在这种情况下，整个批次将需要400个标记长，因此整个批次将是[64, 400]而不是[64, 4]，导致严重减速。更糟糕的是，在更大的批次上，程序会直接崩溃。
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'There are no good (general) solutions for this problem, and your mileage may
    vary depending on your use cases. Rule of thumb:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题没有好的（通用）解决方案，您的使用情况可能会有所不同。经验法则：
- en: 'For users, a rule of thumb is:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于用户，一个经验法则是：
- en: '**Measure performance on your load, with your hardware. Measure, measure, and
    keep measuring. Real numbers are the only way to go.**'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在您的负载上测量性能，使用您的硬件。测量，测量，继续测量。真实数字是唯一的方法。**'
- en: If you are latency constrained (live product doing inference), don’t batch.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您受到延迟约束（进行推断的实时产品），则不要批处理。
- en: If you are using CPU, don’t batch.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您正在使用CPU，则不要批处理。
- en: 'If you are using throughput (you want to run your model on a bunch of static
    data), on GPU, then:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您正在使用吞吐量（希望在一堆静态数据上运行模型），在GPU上，则：
- en: If you have no clue about the size of the sequence_length (“natural” data),
    by default don’t batch, measure and try tentatively to add it, add OOM checks
    to recover when it will fail (and it will at some point if you don’t control the
    sequence_length.)
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您对序列长度的大小一无所知（“自然”数据），默认情况下不要批处理，测量并尝试试探性地添加它，添加OOM检查以在失败时恢复（如果您不控制序列长度，它将在某个时候失败）。
- en: If your sequence_length is super regular, then batching is more likely to be
    VERY interesting, measure and push it until you get OOMs.
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的序列长度非常规则，则批处理更有可能非常有趣，测量并推动它直到出现OOM。
- en: The larger the GPU the more likely batching is going to be more interesting
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU越大，批处理就越有可能更有趣
- en: As soon as you enable batching, make sure you can handle OOMs nicely.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦启用批处理，请确保您可以很好地处理OOM。
- en: Pipeline chunk batching
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道块批处理
- en: '`zero-shot-classification` and `question-answering` are slightly specific in
    the sense, that a single input might yield multiple forward pass of a model. Under
    normal circumstances, this would yield issues with `batch_size` argument.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`zero-shot-classification`和`question-answering`在某种意义上略有特殊，因为单个输入可能会导致模型的多次前向传递。在正常情况下，这将导致`batch_size`参数出现问题。'
- en: 'In order to circumvent this issue, both of these pipelines are a bit specific,
    they are `ChunkPipeline` instead of regular `Pipeline`. In short:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了规避这个问题，这两个管道都有点特殊，它们是`ChunkPipeline`而不是常规的`Pipeline`。简而言之：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now becomes:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在变成了：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This should be very transparent to your code because the pipelines are used
    in the same way.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这对您的代码应该非常透明，因为管道的使用方式相同。
- en: This is a simplified view, since the pipeline can handle automatically the batch
    to ! Meaning you don’t have to care about how many forward passes you inputs are
    actually going to trigger, you can optimize the `batch_size` independently of
    the inputs. The caveats from the previous section still apply.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简化的视图，因为管道可以自动处理批处理！这意味着您无需关心实际将触发多少前向传递，您可以独立于输入优化`batch_size`。前一节中的注意事项仍然适用。
- en: Pipeline custom code
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道自定义代码
- en: If you want to override a specific pipeline.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要覆盖特定管道。
- en: Don’t hesitate to create an issue for your task at hand, the goal of the pipeline
    is to be easy to use and support most cases, so `transformers` could maybe support
    your use case.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 不要犹豫为您手头的任务创建一个问题，管道的目标是易于使用并支持大多数情况，因此`transformers`可能支持您的用例。
- en: 'If you want to try simply you can:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只想简单尝试，可以：
- en: Subclass your pipeline of choice
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子类化您选择的管道
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: That should enable you to do all the custom code you want.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该使您能够执行所有您想要的自定义代码。
- en: Implementing a pipeline
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现管道
- en: '[Implementing a new pipeline](../add_new_pipeline)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[实现新管道](../add_new_pipeline)'
- en: Audio
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频
- en: Pipelines available for audio tasks include the following.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 音频任务可用的管道包括以下内容。
- en: AudioClassificationPipeline
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 音频分类管道
- en: '### `class transformers.AudioClassificationPipeline`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AudioClassificationPipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/audio_classification.py#L66)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/audio_classification.py#L66)'
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    或 [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — 该模型将由管道用于进行预测。这需要是继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)（对于PyTorch）和[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)（对于TensorFlow）的模型。'
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — 该tokenizer将被管道用于为模型编码数据。此对象继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)。'
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelcard` (`str` 或 `ModelCard`, *可选*) — 为此管道的模型指定的模型卡。'
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework` (`str`, *可选*) — 要使用的框架，可以是`"pt"`表示PyTorch或`"tf"`表示TensorFlow。指定的框架必须已安装。'
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未指定框架，将默认使用当前安装的框架。如果未指定框架并且两个框架都已安装，则将默认使用`model`的框架，或者如果未提供模型，则将默认使用PyTorch。
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`, 默认为 `""`) — 管道的任务标识符。'
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers` (`int`, *可选*, 默认为 8) — 当管道将使用*DataLoader*（在传递数据集时，在Pytorch模型的GPU上），要使用的工作程序数量。'
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` (`int`, *可选*, 默认为 1) — 当管道将使用*DataLoader*（在传递数据集时，在Pytorch模型的GPU上），要使用的批次大小，对于推断，这并不总是有益的，请阅读[使用管道进行批处理](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)。'
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *可选*) — 负责解析提供的管道参数的对象的引用。'
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`int`, *可选*, 默认为 -1) — CPU/GPU支持的设备序数。将其设置为 -1 将利用CPU，正数将在关联的CUDA设备ID上运行模型。您也可以传递本机`torch.device`或`str`。'
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`binary_output` (`bool`, *可选*, 默认为 `False`) — 指示管道输出是否应以二进制格式（即pickle）或原始文本格式发生的标志。'
- en: Audio classification pipeline using any `AutoModelForAudioClassification`. This
    pipeline predicts the class of a raw waveform or an audio file. In case of an
    audio file, ffmpeg should be installed to support multiple audio formats.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用任何`AutoModelForAudioClassification`的音频分类管道。该管道预测原始波形或音频文件的类别。在音频文件的情况下，应安装ffmpeg以支持多种音频格式。
- en: 'Example:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 了解有关在[pipeline教程](../pipeline_tutorial)中使用管道的基础知识
- en: 'This pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"audio-classification"`.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 目前可以使用以下任务标识符从[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)加载此管道："audio-classification"。
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=audio-classification).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在[huggingface.co/models](https://huggingface.co/models?filter=audio-classification)上查看可用模型的列表。
- en: '#### `__call__`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/audio_classification.py#L103)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/audio_classification.py#L103)'
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`inputs` (`np.ndarray` or `bytes` or `str` or `dict`) — The inputs is either
    :'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs` (`np.ndarray` 或 `bytes` 或 `str` 或 `dict`) — 输入可以是：'
- en: '`str` that is the filename of the audio file, the file will be read at the
    correct sampling rate to get the waveform using *ffmpeg*. This requires *ffmpeg*
    to be installed on the system.'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`str` — 音频文件的文件名，文件将以正确的采样率读取以获取波形，使用*ffmpeg*。这需要在系统上安装*ffmpeg*。'
- en: '`bytes` it is supposed to be the content of an audio file and is interpreted
    by *ffmpeg* in the same way.'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bytes` 应该是音频文件的内容，并由*ffmpeg*以相同方式解释。'
- en: (`np.ndarray` of shape (n, ) of type `np.float32` or `np.float64`) Raw audio
    at the correct sampling rate (no further check will be done)
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: (`np.ndarray`，形状为(n, )，类型为`np.float32`或`np.float64`) — 在正确的采样率下的原始音频（不会进行进一步检查）
- en: '`dict` form can be used to pass raw audio sampled at arbitrary `sampling_rate`
    and let this pipeline do the resampling. The dict must be either be in the format
    `{"sampling_rate": int, "raw": np.array}`, or `{"sampling_rate": int, "array":
    np.array}`, where the key `"raw"` or `"array"` is used to denote the raw audio
    waveform.'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dict` — 可以用于传递以任意`sampling_rate`采样的原始音频，并让此管道进行重新采样。字典必须是以下格式之一：`{"sampling_rate":
    int, "raw": np.array}`或`{"sampling_rate": int, "array": np.array}`，其中键`"raw"`或`"array"`用于表示原始音频波形。'
- en: '`top_k` (`int`, *optional*, defaults to None) — The number of top labels that
    will be returned by the pipeline. If the provided number is `None` or higher than
    the number of labels available in the model configuration, it will default to
    the number of labels.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k` (`int`，*可选*，默认为None) — 管道将返回的顶部标签数。如果提供的数字为`None`或高于模型配置中可用标签的数量，则默认为标签数。'
- en: Returns
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A list of `dict` with the following keys
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一个带有以下键的`dict`列表
- en: '`label` (`str`) — The label predicted.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label` (`str`) — 预测的标签。'
- en: '`score` (`float`) — The corresponding probability.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score` (`float`) — 相应的概率。'
- en: Classify the sequence(s) given as inputs. See the [AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)
    documentation for more information.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定的输入序列进行分类。有关更多信息，请参阅[AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)文档。
- en: AutomaticSpeechRecognitionPipeline
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutomaticSpeechRecognitionPipeline
- en: '### `class transformers.AutomaticSpeechRecognitionPipeline`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutomaticSpeechRecognitionPipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/automatic_speech_recognition.py#L134)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/automatic_speech_recognition.py#L134)'
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    或 [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — 该模型将被管道用于进行预测。这需要是一个继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)（对于PyTorch）或[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)（对于TensorFlow）的模型。'
- en: '`feature_extractor` ([SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor))
    — The feature extractor that will be used by the pipeline to encode waveform for
    the model.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor))
    — 该特征提取器将被管道用于为模型编码波形。'
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — 该分词器将被管道用于为模型编码数据。该对象继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)。'
- en: '`decoder` (`pyctcdecode.BeamSearchDecoderCTC`, *optional*) — [PyCTCDecode’s
    BeamSearchDecoderCTC](https://github.com/kensho-technologies/pyctcdecode/blob/2fd33dc37c4111417e08d89ccd23d28e9b308d19/pyctcdecode/decoder.py#L180)
    can be passed for language model boosted decoding. See [Wav2Vec2ProcessorWithLM](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ProcessorWithLM)
    for more information.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder` (`pyctcdecode.BeamSearchDecoderCTC`, *可选*) — 可以传递[PyCTCDecode的BeamSearchDecoderCTC](https://github.com/kensho-technologies/pyctcdecode/blob/2fd33dc37c4111417e08d89ccd23d28e9b308d19/pyctcdecode/decoder.py#L180)以进行语言模型增强解码。有关更多信息，请参阅[Wav2Vec2ProcessorWithLM](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ProcessorWithLM)。'
- en: '`chunk_length_s` (`float`, *optional*, defaults to 0) — The input length for
    in each chunk. If `chunk_length_s = 0` then chunking is disabled (default).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk_length_s` (`float`，*可选*，默认为0) — 每个块中的输入长度。如果`chunk_length_s = 0`，则禁用分块（默认）。'
- en: For more information on how to effectively use `chunk_length_s`, please have
    a look at the [ASR chunking blog post](https://huggingface.co/blog/asr-chunking).
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关如何有效使用 `chunk_length_s` 的更多信息，请查看[ASR分块博文](https://huggingface.co/blog/asr-chunking)。
- en: '`stride_length_s` (`float`, *optional*, defaults to `chunk_length_s / 6`) —
    The length of stride on the left and right of each chunk. Used only with `chunk_length_s
    > 0`. This enables the model to *see* more context and infer letters better than
    without this context but the pipeline discards the stride bits at the end to make
    the final reconstitution as perfect as possible.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride_length_s` (`float`, *可选*, 默认为 `chunk_length_s / 6`) — 每个块左右两侧的步幅长度。仅在
    `chunk_length_s > 0` 时使用。这使得模型能够*看到*更多的上下文，并比没有上下文更好地推断字母，但管道会丢弃末尾的步幅位，以使最终重构尽可能完美。'
- en: For more information on how to effectively use `stride_length_s`, please have
    a look at the [ASR chunking blog post](https://huggingface.co/blog/asr-chunking).
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关如何有效使用 `stride_length_s` 的更多信息，请查看[ASR分块博文](https://huggingface.co/blog/asr-chunking)。
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed. If no framework
    is specified, will default to the one currently installed. If no framework is
    specified and both frameworks are installed, will default to the framework of
    the `model`, or to PyTorch if no model is provided.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework` (`str`, *可选*) — 要使用的框架，可以是 `"pt"` 代表PyTorch或 `"tf"` 代表TensorFlow。指定的框架必须已安装。如果未指定框架，将默认使用当前安装的框架。如果未指定框架且两个框架都已安装，则默认使用
    `model` 的框架，或者如果未提供模型，则默认使用PyTorch。'
- en: '`device` (Union[`int`, `torch.device`], *optional*) — Device ordinal for CPU/GPU
    supports. Setting this to `None` will leverage CPU, a positive will run the model
    on the associated CUDA device id.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (Union[`int`, `torch.device`], *可选*) — CPU/GPU支持的设备序数。将其设置为 `None`
    将使用CPU，将其设置为正数将在关联的CUDA设备上运行模型。'
- en: '`torch_dtype` (Union[`int`, `torch.dtype`], *optional*) — The data-type (dtype)
    of the computation. Setting this to `None` will use float32 precision. Set to
    `torch.float16` or `torch.bfloat16` to use half-precision in the respective dtypes.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype` (Union[`int`, `torch.dtype`], *可选*) — 计算的数据类型（dtype）。将其设置为 `None`
    将使用float32精度。设置为 `torch.float16` 或 `torch.bfloat16` 将使用相应dtype的半精度。'
- en: Pipeline that aims at extracting spoken text contained within some audio.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在从某些音频中提取包含的口语文本的管道。
- en: The input can be either a raw waveform or a audio file. In case of the audio
    file, ffmpeg should be installed for to support multiple audio formats
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 输入可以是原始波形或音频文件。在音频文件的情况下，需要安装ffmpeg以支持多种音频格式
- en: 'Example:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 了解有关在[pipeline教程](../pipeline_tutorial)中使用管道的基础知识
- en: '#### `__call__`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/automatic_speech_recognition.py#L229)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/automatic_speech_recognition.py#L229)'
- en: '[PRE20]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`inputs` (`np.ndarray` or `bytes` or `str` or `dict`) — The inputs is either
    :'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs` (`np.ndarray` 或 `bytes` 或 `str` 或 `dict`) — 输入可以是：'
- en: '`str` that is either the filename of a local audio file, or a public URL address
    to download the audio file. The file will be read at the correct sampling rate
    to get the waveform using *ffmpeg*. This requires *ffmpeg* to be installed on
    the system.'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`str`，可以是本地音频文件的文件名，也可以是下载音频文件的公共URL地址。文件将以正确的采样率读取，以使用*ffmpeg*获取波形。这需要系统上安装*ffmpeg*。'
- en: '`bytes` it is supposed to be the content of an audio file and is interpreted
    by *ffmpeg* in the same way.'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bytes` 应该是音频文件内容，并由*ffmpeg*以相同方式解释。'
- en: (`np.ndarray` of shape (n, ) of type `np.float32` or `np.float64`) Raw audio
    at the correct sampling rate (no further check will be done)
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: (`np.ndarray` 的形状为 (n, )，类型为 `np.float32` 或 `np.float64`) — 以正确采样率的原始音频（不会进行进一步检查）
- en: '`dict` form can be used to pass raw audio sampled at arbitrary `sampling_rate`
    and let this pipeline do the resampling. The dict must be in the format `{"sampling_rate":
    int, "raw": np.array}` with optionally a `"stride": (left: int, right: int)` than
    can ask the pipeline to treat the first `left` samples and last `right` samples
    to be ignored in decoding (but used at inference to provide more context to the
    model). Only use `stride` with CTC models.'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '可以使用`dict`形式传递以任意`sampling_rate`采样的原始音频，并让此管道进行重新采样。字典必须采用格式 `{"sampling_rate":
    int, "raw": np.array}`，可选地包含一个 `"stride": (left: int, right: int)`，可以要求管道在解码时忽略前
    `left` 个样本和最后 `right` 个样本（但在推理中使用以向模型提供更多上下文）。仅在CTC模型中使用 `stride`。'
- en: '`return_timestamps` (*optional*, `str` or `bool`) — Only available for pure
    CTC models (Wav2Vec2, HuBERT, etc) and the Whisper model. Not available for other
    sequence-to-sequence models.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_timestamps` (*可选*, `str` 或 `bool`) — 仅适用于纯CTC模型（Wav2Vec2、HuBERT等）和Whisper模型。不适用于其他序列到序列模型。'
- en: 'For CTC models, timestamps can take one of two formats:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于CTC模型，时间戳可以采用以下两种格式之一：
- en: '`"char"`: the pipeline will return timestamps along the text for every character
    in the text. For instance, if you get `[{"text": "h", "timestamp": (0.5, 0.6)},
    {"text": "i", "timestamp": (0.7, 0.9)}]`, then it means the model predicts that
    the letter “h” was spoken after `0.5` and before `0.6` seconds.'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"char"`: 管道将为文本中的每个字符返回时间戳。例如，如果您得到 `[{"text": "h", "timestamp": (0.5, 0.6)},
    {"text": "i", "timestamp": (0.7, 0.9)}]`，则表示模型预测字母“h”在 `0.5` 秒后和 `0.6` 秒前被发音。'
- en: '`"word"`: the pipeline will return timestamps along the text for every word
    in the text. For instance, if you get `[{"text": "hi ", "timestamp": (0.5, 0.9)},
    {"text": "there", "timestamp": (1.0, 1.5)}]`, then it means the model predicts
    that the word “hi” was spoken after `0.5` and before `0.9` seconds.'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"word"`: 管道将为文本中的每个单词返回时间戳。例如，如果您得到 `[{"text": "hi ", "timestamp": (0.5, 0.9)},
    {"text": "there", "timestamp": (1.0, 1.5)}]`，则表示模型预测单词“hi”在 `0.5` 秒后和 `0.9` 秒前被发音。'
- en: 'For the Whisper model, timestamps can take one of two formats:'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于Whisper模型，时间戳可以采用以下两种格式之一：
- en: '`"word"`: same as above for word-level CTC timestamps. Word-level timestamps
    are predicted through the *dynamic-time warping (DTW)* algorithm, an approximation
    to word-level timestamps by inspecting the cross-attention weights.'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"word"`: 与单词级CTC时间戳相同。单词级时间戳通过*动态时间规整（DTW）*算法预测，通过检查交叉注意力权重来近似单词级时间戳。'
- en: '`True`: the pipeline will return timestamps along the text for *segments* of
    words in the text. For instance, if you get `[{"text": " Hi there!", "timestamp":
    (0.5, 1.5)}]`, then it means the model predicts that the segment “Hi there!” was
    spoken after `0.5` and before `1.5` seconds. Note that a segment of text refers
    to a sequence of one or more words, rather than individual words as with word-level
    timestamps.'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`：管道将在文本中为*单词段*返回时间戳。例如，如果您获得`[{"text": " Hi there!", "timestamp": (0.5,
    1.5)}]`，则表示模型预测段“Hi there!”在`0.5`秒后和`1.5`秒前被说出。请注意，文本段指的是一个或多个单词的序列，而不是单词级时间戳。'
- en: '`generate_kwargs` (`dict`, *optional*) — The dictionary of ad-hoc parametrization
    of `generate_config` to be used for the generation call. For a complete overview
    of generate, check the [following guide](https://huggingface.co/docs/transformers/en/main_classes/text_generation).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_kwargs` (`dict`, *可选*) — 用于生成调用的`generate_config`的自定义参数字典。有关generate的完整概述，请查看[以下指南](https://huggingface.co/docs/transformers/en/main_classes/text_generation)。'
- en: '`max_new_tokens` (`int`, *optional*) — The maximum numbers of tokens to generate,
    ignoring the number of tokens in the prompt.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens` (`int`, *可选*) — 要生成的最大标记数，忽略提示中的标记数。'
- en: Returns
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict`'
- en: 'A dictionary with the following keys:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下键的字典：
- en: '`text` (`str`): The recognized text.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`): 识别的文本。'
- en: '`chunks` (*optional(, `List[Dict]`) When using `return_timestamps`, the `chunks`
    will become a list containing all the various text chunks identified by the model,*
    e.g.* `[{"text": "hi ", "timestamp": (0.5, 0.9)}, {"text": "there", "timestamp":
    (1.0, 1.5)}]`. The original full text can roughly be recovered by doing `"".join(chunk["text"]
    for chunk in output["chunks"])`.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunks` (*可选(, `List[Dict]`) 当使用`return_timestamps`时，`chunks`将变成一个包含模型识别的各种文本块的列表，例如`[{"text":
    "hi ", "timestamp": (0.5, 0.9)}, {"text": "there", "timestamp": (1.0, 1.5)}]`。原始完整文本可以通过`"".join(chunk["text"]
    for chunk in output["chunks"])`来粗略恢复。'
- en: Transcribe the audio sequence(s) given as inputs to text. See the [AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)
    documentation for more information.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 将给定的音频序列转录为文本。有关更多信息，请参阅[AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)文档。
- en: TextToAudioPipeline
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本到音频管道
- en: '### `class transformers.TextToAudioPipeline`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TextToAudioPipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_to_audio.py#L27)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_to_audio.py#L27)'
- en: '[PRE21]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Text-to-audio generation pipeline using any `AutoModelForTextToWaveform` or
    `AutoModelForTextToSpectrogram`. This pipeline generates an audio file from an
    input text and optional other conditional inputs.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用任何`AutoModelForTextToWaveform`或`AutoModelForTextToSpectrogram`的文本到音频生成管道。此管道从输入文本和可选的其他条件输入生成音频文件。
- en: 'Example:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE22]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 了解有关在[pipeline tutorial](../pipeline_tutorial)中使用管道的基础知识
- en: You can specify parameters passed to the model by using `TextToAudioPipeline.__call__.forward_params`
    or `TextToAudioPipeline.__call__.generate_kwargs`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用`TextToAudioPipeline.__call__.forward_params`或`TextToAudioPipeline.__call__.generate_kwargs`来指定传递给模型的参数。
- en: 'Example:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE23]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifiers: `"text-to-speech"` or `"text-to-audio"`.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 此管道目前可以使用以下任务标识符从[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)加载：`"text-to-speech"`或`"text-to-audio"`。
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=text-to-speech).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在[huggingface.co/models](https://huggingface.co/models?filter=text-to-speech)上查看可用模型列表。
- en: '#### `__call__`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_to_audio.py#L160)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_to_audio.py#L160)'
- en: '[PRE24]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_inputs` (`str` or `List[str]`) — The text(s) to generate.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_inputs` (`str`或`List[str]`) — 要生成的文本。'
- en: '`forward_params` (`dict`, *optional*) — Parameters passed to the model generation/forward
    method. `forward_params` are always passed to the underlying model.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forward_params` (`dict`, *可选*) — 传递给模型生成/前向方法的参数。`forward_params`始终传递给底层模型。'
- en: '`generate_kwargs` (`dict`, *optional*) — The dictionary of ad-hoc parametrization
    of `generate_config` to be used for the generation call. For a complete overview
    of generate, check the [following guide](https://huggingface.co/docs/transformers/en/main_classes/text_generation).
    `generate_kwargs` are only passed to the underlying model if the latter is a generative
    model.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_kwargs` (`dict`, *可选*) — 用于生成调用的`generate_config`的自定义参数字典。有关generate的完整概述，请查看[以下指南](https://huggingface.co/docs/transformers/en/main_classes/text_generation)。`generate_kwargs`仅在底层模型是生成模型时才传递给底层模型。'
- en: Returns
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A `dict` or a list of `dict`
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`dict`或`dict`的列表
- en: 'The dictionaries have two keys:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 字典有两个键：
- en: '`audio` (`np.ndarray` of shape `(nb_channels, audio_length)`) — The generated
    audio waveform.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio` (`np.ndarray`，形状为`(nb_channels, audio_length)`) — 生成的音频波形。'
- en: '`sampling_rate` (`int`) — The sampling rate of the generated audio waveform.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`) — 生成的音频波形的采样率。'
- en: Generates speech/audio from the inputs. See the [TextToAudioPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextToAudioPipeline)
    documentation for more information.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 从输入生成语音/音频。有关更多信息，请参阅[TextToAudioPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.TextToAudioPipeline)文档。
- en: ZeroShotAudioClassificationPipeline
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ZeroShotAudioClassificationPipeline
- en: '### `class transformers.ZeroShotAudioClassificationPipeline`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ZeroShotAudioClassificationPipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_audio_classification.py#L32)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_audio_classification.py#L32)'
- en: '[PRE25]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)或[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — 管道将用于进行预测的模型。这需要是继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)的模型，用于PyTorch，以及继承自[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)的模型，用于TensorFlow。'
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — 管道将用于为模型编码数据的分词器。此对象继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)。'
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelcard` (`str`或`ModelCard`, *可选*) — 为此管道的模型指定的模型卡。'
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework` (`str`, *可选*) — 要使用的框架，可以是 `"pt"` 代表PyTorch 或 `"tf"` 代表TensorFlow。指定的框架必须已安装。'
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未指定框架，将默认使用当前安装的框架。如果未指定框架并且两个框架都已安装，将默认使用`model`的框架，或者如果未提供模型，则默认使用PyTorch。
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`, 默认为 `""`) — 用于管道的任务标识符。'
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers` (`int`, *可选*, 默认为8) — 当管道将使用 *DataLoader*（传递数据集时，在Pytorch模型的GPU上），要使用的工作人员数量。'
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` (`int`, *可选*, 默认为1) — 当管道将使用 *DataLoader*（传递数据集时，在Pytorch模型的GPU上），要使用的批次大小，对于推断来说，这并不总是有益的，请阅读[使用管道进行批处理](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)。'
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *可选*) — 负责解析提供的管道参数的对象的引用。'
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`int`, *可选*, 默认为-1) — CPU/GPU支持的设备序数。将其设置为-1将利用CPU，正数将在关联的CUDA设备ID上运行模型。您也可以传递本机`torch.device`或`str`。'
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`binary_output` (`bool`, *可选*, 默认为 `False`) — 指示管道输出是否应以二进制格式（即pickle）或原始文本格式发生的标志。'
- en: Zero shot audio classification pipeline using `ClapModel`. This pipeline predicts
    the class of an audio when you provide an audio and a set of `candidate_labels`.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ClapModel`进行零射击音频分类管道。此管道在提供音频和一组`candidate_labels`时预测音频的类。
- en: 'Example:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE26]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
    This audio classification pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"zero-shot-audio-classification"`. See the
    list of available models on [huggingface.co/models](https://huggingface.co/models?filter=zero-shot-audio-classification).'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在[pipeline教程](../pipeline_tutorial)中了解如何使用管道的基础知识。此音频分类管道目前可以通过以下任务标识符从[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)加载："zero-shot-audio-classification"。在[huggingface.co/models](https://huggingface.co/models?filter=zero-shot-audio-classification)上查看可用模型的列表。
- en: '#### `__call__`'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_audio_classification.py#L64)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_audio_classification.py#L64)'
- en: '[PRE27]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audios` (`str`, `List[str]`, `np.array` or `List[np.array]`) — The pipeline
    handles three types of inputs:'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audios` (`str`, `List[str]`, `np.array`或`List[np.array]`) — 管道处理三种类型的输入：'
- en: A string containing a http link pointing to an audio
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含指向音频的http链接的字符串
- en: A string containing a local path to an audio
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含音频本地路径的字符串
- en: An audio loaded in numpy
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载在numpy中的音频
- en: '`candidate_labels` (`List[str]`) — The candidate labels for this audio'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`candidate_labels` (`List[str]`) — 此音频的候选标签'
- en: '`hypothesis_template` (`str`, *optional*, defaults to `"This is a sound of
    {}"`) — The sentence used in cunjunction with *candidate_labels* to attempt the
    audio classification by replacing the placeholder with the candidate_labels. Then
    likelihood is estimated by using logits_per_audio'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hypothesis_template`（`str`，*可选*，默认为`"This is a sound of {}"`）- 与*candidate_labels*一起使用的句子，通过将占位符替换为candidate_labels尝试音频分类。然后通过使用logits_per_audio来估计可能性。'
- en: Assign labels to the audio(s) passed as inputs.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 为传入的音频分配标签。
- en: Computer vision
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: Pipelines available for computer vision tasks include the following.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉任务可用的管道包括以下内容。
- en: DepthEstimationPipeline
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DepthEstimationPipeline
- en: '### `class transformers.DepthEstimationPipeline`'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DepthEstimationPipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/depth_estimation.py#L22)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/depth_estimation.py#L22)'
- en: '[PRE28]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)或[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)）-
    该模型将被管道用于进行预测。这需要是一个继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)（对于PyTorch）和[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)（对于TensorFlow）的模型。'
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)）-
    该tokenizer将被管道用于对数据进行编码以供模型使用。该对象继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)。'
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelcard`（`str`或`ModelCard`，*可选*）- 为此管道的模型分配的模型卡。'
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework`（`str`，*可选*）- 要使用的框架，可以是`"pt"`表示PyTorch或`"tf"`表示TensorFlow。指定的框架必须已安装。'
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未指定框架，将默认使用当前安装的框架。如果未指定框架并且两个框架都已安装，则将默认使用`model`的框架，或者如果未提供模型，则将默认使用PyTorch。
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task`（`str`，默认为`""`）- 管道的任务标识符。'
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers`（`int`，*可选*，默认为8）- 当管道将使用*DataLoader*（在传递数据集时，在PyTorch模型的GPU上）时，要使用的工作人员数量。'
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`（`int`，*可选*，默认为1）- 当管道将使用*DataLoader*（在传递数据集时，在PyTorch模型的GPU上）时，要使用的批次大小，对于推断，这并不总是有益的，请阅读[使用管道进行批处理](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)。'
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args_parser`（[ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler)，*可选*）-
    负责解析提供的管道参数的对象的引用。'
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`（`int`，*可选*，默认为-1）- CPU/GPU支持的设备序数。将其设置为-1将利用CPU，正数将在关联的CUDA设备ID上运行模型。您也可以传递本机`torch.device`或`str`。'
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`binary_output`（`bool`，*可选*，默认为`False`）- 指示管道输出是否应以二进制格式（即pickle）或原始文本格式发生的标志。'
- en: Depth estimation pipeline using any `AutoModelForDepthEstimation`. This pipeline
    predicts the depth of an image.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用任何`AutoModelForDepthEstimation`的深度估计管道。该管道预测图像的深度。
- en: 'Example:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 了解有关在[pipeline教程](../pipeline_tutorial)中使用管道的基础知识。
- en: 'This depth estimation pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"depth-estimation"`.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 此深度估计管道目前可以使用以下任务标识符从[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)中加载："depth-estimation"。
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=depth-estimation).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在[huggingface.co/models](https://huggingface.co/models?filter=depth-estimation)上查看可用模型的列表。
- en: '#### `__call__`'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/depth_estimation.py#L53)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/depth_estimation.py#L53)'
- en: '[PRE30]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`str`, `List[str]`, `PIL.Image` 或 `List[PIL.Image]`) — 管道处理三种类型的图像：'
- en: A string containing a http link pointing to an image
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含指向图像的http链接的字符串
- en: A string containing a local path to an image
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含指向图像的本地路径的字符串
- en: An image loaded in PIL directly
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接加载的PIL图像
- en: 'The pipeline accepts either a single image or a batch of images, which must
    then be passed as a string. Images in a batch must all be in the same format:
    all as http links, all as local paths, or all as PIL images.'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该管道接受单个图像或一批图像，然后必须将它们作为字符串传递。批处理中的图像必须全部采用相同的格式：全部作为http链接，全部作为本地路径，或全部作为PIL图像。
- en: '`top_k` (`int`, *optional*, defaults to 5) — The number of top labels that
    will be returned by the pipeline. If the provided number is higher than the number
    of labels available in the model configuration, it will default to the number
    of labels.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k` (`int`, *可选*, 默认为5) — 管道将返回的前几个标签的数量。如果提供的数字高于模型配置中可用的标签数量，则将默认为标签数量。'
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeout` (`float`, *可选*, 默认为None) — 从网络获取图像的最长等待时间（以秒为单位）。如果为None，则不设置超时，调用可能会永远阻塞。'
- en: Assign labels to the image(s) passed as inputs.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 为传递的图像分配标签。
- en: ImageClassificationPipeline
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ImageClassificationPipeline
- en: '### `class transformers.ImageClassificationPipeline`'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ImageClassificationPipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_classification.py#L50)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_classification.py#L50)'
- en: '[PRE31]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    或 [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — 管道将用于进行预测的模型。这需要是继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)的模型，对于PyTorch和继承自[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)的模型。'
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — 管道将用于为模型编码数据的分词器。该对象继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)。'
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelcard` (`str` 或 `ModelCard`, *可选*) — 为此管道的模型指定的模型卡。'
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework` (`str`, *可选*) — 要使用的框架，可以是`"pt"`表示PyTorch，也可以是`"tf"`表示TensorFlow。指定的框架必须已安装。'
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未指定框架，将默认使用当前安装的框架。如果未指定框架并且两个框架都已安装，则将默认使用`model`的框架，或者如果未提供模型，则将默认使用PyTorch框架。
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`, 默认为`""`) — 管道的任务标识符。'
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers` (`int`, *可选*, 默认为8) — 当管道将使用*DataLoader*（在传递数据集时，在Pytorch模型的GPU上），要使用的工作程序数量。'
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` (`int`, *可选*, 默认为1) — 当管道将使用*DataLoader*（在传递数据集时，在Pytorch模型的GPU上），要使用的批次大小，对于推断，这并不总是有益，请阅读[使用管道进行批处理](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)。'
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *可选*) — 负责解析提供的管道参数的对象的引用。'
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`int`, *可选*, 默认为-1) — CPU/GPU支持的设备序数。将其设置为-1将利用CPU，正数将在关联的CUDA设备ID上运行模型。您也可以传递本机`torch.device`或`str`。'
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`binary_output` (`bool`, *可选*, 默认为`False`) — 指示管道输出是否应以二进制格式（即pickle）或原始文本格式发生的标志。'
- en: '`function_to_apply` (`str`, *optional*, defaults to `"default"`) — The function
    to apply to the model outputs in order to retrieve the scores. Accepts four different
    values:'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`function_to_apply` (`str`, *可选*, 默认为`"default"`) — 用于从模型输出中提取分数的函数。接受四个不同的值：'
- en: '`"default"`: if the model has a single label, will apply the sigmoid function
    on the output. If the model has several labels, will apply the softmax function
    on the output.'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"sigmoid"`: Applies the sigmoid function on the output.'
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"softmax"`: Applies the softmax function on the output.'
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"none"`: Does not apply any function on the output.'
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification pipeline using any `AutoModelForImageClassification`. This
    pipeline predicts the class of an image.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'This image classification pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"image-classification"`.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=image-classification).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_classification.py#L111)'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a http link pointing to an image
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pipeline accepts either a single image or a batch of images, which must
    then be passed as a string. Images in a batch must all be in the same format:
    all as http links, all as local paths, or all as PIL images.'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`function_to_apply` (`str`, *optional*, defaults to `"default"`) — The function
    to apply to the model outputs in order to retrieve the scores. Accepts four different
    values:'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If this argument is not specified, then it will apply the following functions
    according to the number of labels:'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If the model has a single label, will apply the sigmoid function on the output.
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If the model has several labels, will apply the softmax function on the output.
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Possible values are:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`"sigmoid"`: Applies the sigmoid function on the output.'
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"softmax"`: Applies the softmax function on the output.'
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"none"`: Does not apply any function on the output.'
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`, *optional*, defaults to 5) — The number of top labels that
    will be returned by the pipeline. If the provided number is higher than the number
    of labels available in the model configuration, it will default to the number
    of labels.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign labels to the image(s) passed as inputs.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: ImageSegmentationPipeline
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.ImageSegmentationPipeline`'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_segmentation.py#L30)'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未指定框架，将默认使用当前安装的框架。如果未指定框架并且两个框架都已安装，则将默认使用`model`的框架，或者如果未提供模型，则将默认使用PyTorch。
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`, defaults to `""`) — 管道的任务标识符。'
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers` (`int`, *optional*, defaults to 8) — 当管道将使用*DataLoader*（在传递数据集时，对于Pytorch模型在GPU上），要使用的工作程序数量。'
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` (`int`, *optional*, defaults to 1) — 当管道将使用*DataLoader*（在传递数据集时，对于Pytorch模型在GPU上），要使用的批处理大小，对于推断，这并不总是有益的，请阅读[使用管道进行批处理](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)。'
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — 负责解析提供的管道参数的对象的引用。'
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`int`, *optional*, defaults to -1) — CPU/GPU支持的设备序数。将其设置为-1将利用CPU，将其设置为正数将在关联的CUDA设备ID上运行模型。您也可以传递本机`torch.device`或`str`。'
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`binary_output` (`bool`, *optional*, defaults to `False`) — 指示管道输出应以二进制格式（即pickle）还是原始文本格式发生的标志。'
- en: Image segmentation pipeline using any `AutoModelForXXXSegmentation`. This pipeline
    predicts masks of objects and their classes.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 使用任何`AutoModelForXXXSegmentation`的图像分割管道。该管道预测对象及其类别的掩模。
- en: 'Example:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE35]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This image segmentation pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"image-segmentation"`.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 此图像分割管道目前可以使用以下任务标识符从[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)加载："image-segmentation"。
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=image-segmentation).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在[huggingface.co/models](https://huggingface.co/models?filter=image-segmentation)上查看可用模型的列表。
- en: '#### `__call__`'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_segmentation.py#L97)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_segmentation.py#L97)'
- en: '[PRE36]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`str`, `List[str]`, `PIL.Image`或`List[PIL.Image]`) — 该管道处理三种类型的图像：'
- en: A string containing an HTTP(S) link pointing to an image
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含指向图像的HTTP(S)链接的字符串
- en: A string containing a local path to an image
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含图像本地路径的字符串
- en: An image loaded in PIL directly
  id: totrans-374
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接在PIL中加载的图像
- en: 'The pipeline accepts either a single image or a batch of images. Images in
    a batch must all be in the same format: all as HTTP(S) links, all as local paths,
    or all as PIL images.'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该管道接受单个图像或一批图像。批处理中的图像必须全部采用相同的格式：全部作为HTTP(S)链接，全部作为本地路径，或全部作为PIL图像。
- en: '`subtask` (`str`, *optional*) — Segmentation task to be performed, choose [`semantic`,
    `instance` and `panoptic`] depending on model capabilities. If not set, the pipeline
    will attempt tp resolve in the following order: `panoptic`, `instance`, `semantic`.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subtask` (`str`, *optional*) — 要执行的分割任务，根据模型的能力选择[`semantic`、`instance`和`panoptic`]。如果未设置，管道将尝试按以下顺序解析：`panoptic`、`instance`、`semantic`。'
- en: '`threshold` (`float`, *optional*, defaults to 0.9) — Probability threshold
    to filter out predicted masks.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`, *optional*, defaults to 0.9) — 用于过滤预测掩模的概率阈值。'
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — 在将预测掩模转换为二进制值时使用的阈值。'
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.5) — Mask
    overlap threshold to eliminate small, disconnected segments.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.5) — 用于消除小的、不连续段的掩模重叠阈值。'
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeout` (`float`, *optional*, defaults to None) — 从网络获取图像的最长等待时间（以秒为单位）。如果为None，则不设置超时，并且调用可能会永远阻塞。'
- en: Perform segmentation (detect masks & classes) in the image(s) passed as inputs.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在作为输入传递的图像中执行分割（检测掩模和类别）。
- en: ImageToImagePipeline
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ImageToImagePipeline
- en: '### `class transformers.ImageToImagePipeline`'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ImageToImagePipeline`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_to_image.py#L39)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_to_image.py#L39)'
- en: '[PRE37]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image to Image pipeline using any `AutoModelForImageToImage`. This pipeline
    generates an image based on a previous image input.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This image to image pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"image-to-image"`.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=image-to-image).
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_to_image.py#L87)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Parameters
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a http link pointing to an image
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pipeline accepts either a single image or a batch of images, which must
    then be passed as a string. Images in a batch must all be in the same format:
    all as http links, all as local paths, or all as PIL images.'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is used and the
    call may block forever.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transform the image(s) passed as inputs.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: ObjectDetectionPipeline
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.ObjectDetectionPipeline`'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/object_detection.py#L26)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object detection pipeline using any `AutoModelForObjectDetection`. This pipeline
    predicts bounding boxes of objects and their classes.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: 'This object detection pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"object-detection"`.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=object-detection).
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/object_detection.py#L72)'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing an HTTP(S) link pointing to an image
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pipeline accepts either a single image or a batch of images. Images in
    a batch must all be in the same format: all as HTTP(S) links, all as local paths,
    or all as PIL images.'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`threshold` (`float`, *optional*, defaults to 0.9) — The probability necessary
    to make a prediction.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect objects (bounding boxes & classes) in the image(s) passed as inputs.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: VideoClassificationPipeline
  id: totrans-448
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.VideoClassificationPipeline`'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/video_classification.py#L21)'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Parameters
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video classification pipeline using any `AutoModelForVideoClassification`. This
    pipeline predicts the class of a video.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: 'This video classification pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"video-classification"`.'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=video-classification).
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/video_classification.py#L51)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Parameters
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: '`videos` (`str`, `List[str]`) — The pipeline handles three types of videos:'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a http link pointing to a video
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to a video
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pipeline accepts either a single video or a batch of videos, which must
    then be passed as a string. Videos in a batch must all be in the same format:
    all as http links or all as local paths.'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`top_k` (`int`, *optional*, defaults to 5) — The number of top labels that
    will be returned by the pipeline. If the provided number is higher than the number
    of labels available in the model configuration, it will default to the number
    of labels.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_frames` (`int`, *optional*, defaults to `self.model.config.num_frames`)
    — The number of frames sampled from the video to run the classification on. If
    not provided, will default to the number of frames specified in the model configuration.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`frame_sampling_rate` (`int`, *optional*, defaults to 1) — The sampling rate
    used to select frames from the video. If not provided, will default to 1, i.e.
    every frame will be used.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign labels to the video(s) passed as inputs.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: ZeroShotImageClassificationPipeline
  id: totrans-479
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.ZeroShotImageClassificationPipeline`'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_image_classification.py#L32)'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero shot image classification pipeline using `CLIPModel`. This pipeline predicts
    the class of an image when you provide an image and a set of `candidate_labels`.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: 'This image classification pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"zero-shot-image-classification"`.'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=zero-shot-image-classification).
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_image_classification.py#L76)'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Parameters
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a http link pointing to an image
  id: totrans-506
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-507
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`candidate_labels` (`List[str]`) — The candidate labels for this image'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hypothesis_template` (`str`, *optional*, defaults to `"This is a photo of
    {}"`) — The sentence used in cunjunction with *candidate_labels* to attempt the
    image classification by replacing the placeholder with the candidate_labels. Then
    likelihood is estimated by using logits_per_image'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign labels to the image(s) passed as inputs.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: ZeroShotObjectDetectionPipeline
  id: totrans-513
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.ZeroShotObjectDetectionPipeline`'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_object_detection.py#L22)'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Parameters
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero shot object detection pipeline using `OwlViTForObjectDetection`. This pipeline
    predicts bounding boxes of objects when you provide an image and a set of `candidate_labels`.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-531
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: 'This object detection pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"zero-shot-object-detection"`.'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=zero-shot-object-detection).
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_object_detection.py#L65)'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Parameters
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`str`, `PIL.Image` or `List[Dict[str, Any]]`) — The pipeline handles
    three types of images:'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing an http url pointing to an image
  id: totrans-540
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-541
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-542
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can use this parameter to send directly a list of images, or a dataset
    or a generator like so:'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Detect objects (bounding boxes & classes) in the image(s) passed as inputs.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Processing
  id: totrans-545
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pipelines available for natural language processing tasks include the following.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: ConversationalPipeline
  id: totrans-547
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.Conversation`'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/conversational.py#L18)'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Parameters
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: '`messages` (Union[str, List[Dict[str, str]]], *optional*) — The initial messages
    to start the conversation, either a string, or a list of dicts containing “role”
    and “content” keys. If a string is passed, it is interpreted as a single message
    with the “user” role.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`conversation_id` (`uuid.UUID`, *optional*) — Unique identifier for the conversation.
    If not provided, a random UUID4 id will be assigned to the conversation.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utility class containing a conversation and its history. This class is meant
    to be used as an input to the [ConversationalPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ConversationalPipeline).
    The conversation contains several utility functions to manage the addition of
    new user inputs and generated model responses.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: 'Usage:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '#### `add_user_input`'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/conversational.py#L89)'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Add a user input to the conversation for the next round. This is a legacy method
    that assumes that inputs must alternate user/assistant/user/assistant, and so
    will not add multiple user messages in succession. We recommend just using `add_message`
    with role “user” instead.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: '#### `append_response`'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/conversational.py#L110)'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This is a legacy method. We recommend just using `add_message` with an appropriate
    role instead.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
- en: '#### `mark_processed`'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/conversational.py#L116)'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-567
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: This is a legacy method, as the Conversation no longer distinguishes between
    processed and unprocessed user input. We set a counter here to keep behaviour
    mostly backward-compatible, but in general you should just read the messages directly
    when writing new code.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: '### `class transformers.ConversationalPipeline`'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/conversational.py#L194)'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Parameters
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-577
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_length_for_response` (`int`, *optional*, defaults to 32) — The minimum
    length (in number of tokens) for a response.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`minimum_tokens` (`int`, *optional*, defaults to 10) — The minimum length of
    tokens to leave for a response.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-turn conversational pipeline.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: 'This conversational pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"conversational"`.'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: This pipeline can be used with any model that has a [chat template](https://huggingface.co/docs/transformers/chat_templating)
    set.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/conversational.py#L262)'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-594
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Parameters
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: '`conversations` (a [Conversation](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Conversation)
    or a list of [Conversation](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Conversation))
    — Conversation to generate responses for. Inputs can also be passed as a list
    of dictionaries with `role` and `content` keys - in this case, they will be converted
    to `Conversation` objects automatically. Multiple conversations in either format
    may be passed as a list.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `False`) —
    Whether or not to clean up the potential extra spaces in the text output. generate_kwargs
    — Additional keyword arguments to pass along to the generate method of the model
    (see the generate method corresponding to your framework [here](./model#generative-models)).'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: '[Conversation](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Conversation)
    or a list of [Conversation](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Conversation)'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: Conversation(s) with updated generated responses for those containing a new
    user input.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: Generate responses for the conversation(s) given as inputs.
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
- en: FillMaskPipeline
  id: totrans-602
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.FillMaskPipeline`'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/fill_mask.py#L22)'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-605
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Parameters
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`, defaults to 5) — The number of predictions to return.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`targets` (`str` or `List[str]`, *optional*) — When passed, the model will
    limit the scores to the passed targets instead of looking up in the whole vocab.
    If the provided targets are not in the model vocab, they will be tokenized and
    the first resulting token will be used (with a warning, and that might be slower).'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Masked language modeling prediction pipeline using any `ModelWithLMHead`. See
    the [masked language modeling examples](../task_summary#masked-language-modeling)
    for more information.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
- en: 'This mask filling pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"fill-mask"`.'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been trained with
    a masked language modeling objective, which includes the bi-directional models
    in the library. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models?filter=fill-mask).
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
- en: 'This pipeline only works for inputs with exactly one token masked. Experimental:
    We added support for multiple masks. The returned values are raw model output,
    and correspond to disjoint probabilities where one might expect joint probabilities
    (See [discussion](https://github.com/huggingface/transformers/pull/10222)).'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
- en: 'This pipeline now supports tokenizer_kwargs. For example try:'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-628
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '#### `__call__`'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/fill_mask.py#L248)'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-631
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Parameters
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`str` or `List[str]`) — One or several texts (or one list of prompts)
    with masked tokens.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`targets` (`str` or `List[str]`, *optional*) — When passed, the model will
    limit the scores to the passed targets instead of looking up in the whole vocab.
    If the provided targets are not in the model vocab, they will be tokenized and
    the first resulting token will be used (with a warning, and that might be slower).'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`, *optional*) — When passed, overrides the number of predictions
    to return.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as list of dictionaries with the following keys:'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
- en: '`sequence` (`str`) — The corresponding input with the mask token prediction.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`float`) — The corresponding probability.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`int`) — The predicted token id (to replace the masked one).'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_str` (`str`) — The predicted token (to replace the masked one).'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fill the masked token in the text(s) given as inputs.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
- en: QuestionAnsweringPipeline
  id: totrans-644
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.QuestionAnsweringPipeline`'
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/question_answering.py#L224)'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-647
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Parameters
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question Answering pipeline using any `ModelForQuestionAnswering`. See the [question
    answering examples](../task_summary#question-answering) for more information.
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-662
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: 'This question answering pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"question-answering"`.'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a question answering task. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models?filter=question-answering).
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/question_answering.py#L343)'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-668
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Parameters
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`SquadExample` or a list of `SquadExample`) — One or several `SquadExample`
    containing the question and context.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`X` (`SquadExample` or a list of `SquadExample`, *optional*) — One or several
    `SquadExample` containing the question and context (will be treated the same way
    as if passed as the first positional argument).'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data` (`SquadExample` or a list of `SquadExample`, *optional*) — One or several
    `SquadExample` containing the question and context (will be treated the same way
    as if passed as the first positional argument).'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`question` (`str` or `List[str]`) — One or several question(s) (must be used
    in conjunction with the `context` argument).'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`context` (`str` or `List[str]`) — One or several context(s) associated with
    the question(s) (must be used in conjunction with the `question` argument).'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`topk` (`int`, *optional*, defaults to 1) — The number of answers to return
    (will be chosen by order of likelihood). Note that we return less than topk answers
    if there are not enough options available within the context.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doc_stride` (`int`, *optional*, defaults to 128) — If the context is too long
    to fit with the question for the model, it will be split in several chunks with
    some overlap. This argument controls the size of that overlap.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_answer_len` (`int`, *optional*, defaults to 15) — The maximum length of
    predicted answers (e.g., only answers with a shorter length are considered).'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_seq_len` (`int`, *optional*, defaults to 384) — The maximum length of
    the total sentence (context + question) in tokens of each chunk passed to the
    model. The context will be split in several chunks (using `doc_stride` as overlap)
    if needed.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_question_len` (`int`, *optional*, defaults to 64) — The maximum length
    of the question after tokenization. It will be truncated if needed.'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`handle_impossible_answer` (`bool`, *optional*, defaults to `False`) — Whether
    or not we accept impossible as an answer.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`align_to_words` (`bool`, *optional*, defaults to `True`) — Attempts to align
    the answer to real words. Improves quality on space separated langages. Might
    hurt on non-space-separated languages (like Japanese or Chinese)'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
- en: A `dict` or a list of `dict`
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following keys:'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
- en: '`score` (`float`) — The probability associated to the answer.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start` (`int`) — The character start index of the answer (in the tokenized
    version of the input).'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end` (`int`) — The character end index of the answer (in the tokenized version
    of the input).'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`answer` (`str`) — The answer to the question.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer the question(s) given as inputs by using the context(s).
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
- en: '#### `create_sample`'
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/question_answering.py#L278)'
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-692
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Parameters
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
- en: '`question` (`str` or `List[str]`) — The question(s) asked.'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`context` (`str` or `List[str]`) — The context(s) in which we will look for
    the answer.'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
- en: One or a list of `SquadExample`
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
- en: The corresponding `SquadExample` grouping question and context.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
- en: QuestionAnsweringPipeline leverages the `SquadExample` internally. This helper
    method encapsulate all the logic for converting question(s) and context(s) to
    `SquadExample`.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
- en: We currently support extractive question answering.
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
- en: '#### `span_to_answer`'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/question_answering.py#L630)'
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-703
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Parameters
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — The actual context to extract the answer from.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start` (`int`) — The answer starting token index.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end` (`int`) — The answer end token index.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary like `{‘answer’
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
- en: 'str, ‘start’: int, ‘end’: int}`'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
- en: When decoding from token probabilities, this method maps token indexes to actual
    word in the initial context.
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
- en: SummarizationPipeline
  id: totrans-712
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.SummarizationPipeline`'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L216)'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-715
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Parameters
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-721
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarize news articles and other documents.
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
- en: 'This summarizing pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"summarization"`.'
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a summarization task, which is currently, ’*bart-large-cnn*’, ’*t5-small*’, ’*t5-base*’,
    ’*t5-large*’, ’*t5-3b*’, ’*t5-11b*’. See the up-to-date list of available models
    on [huggingface.co/models](https://huggingface.co/models?filter=summarization).
    For a list of available parameters, see the [following documentation](https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.generation.GenerationMixin.generate)
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
- en: 'Usage:'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-732
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '#### `__call__`'
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L245)'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-735
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Parameters
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
- en: '`documents` (*str* or `List[str]`) — One or several articles (or one list of
    articles) to summarize.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_text` (`bool`, *optional*, defaults to `True`) — Whether or not to
    include the decoded texts in the outputs'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_tensors` (`bool`, *optional*, defaults to `False`) — Whether or not
    to include the tensors of predictions (as token indices) in the outputs.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `False`) —
    Whether or not to clean up the potential extra spaces in the text output. generate_kwargs
    — Additional keyword arguments to pass along to the generate method of the model
    (see the generate method corresponding to your framework [here](./model#generative-models)).'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following keys:'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
- en: '`summary_text` (`str`, present when `return_text=True`) — The summary of the
    corresponding input.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`summary_token_ids` (`torch.Tensor` or `tf.Tensor`, present when `return_tensors=True`)
    — The token ids of the summary.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarize the text(s) given as inputs.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
- en: TableQuestionAnsweringPipeline
  id: totrans-747
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.TableQuestionAnsweringPipeline`'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/table_question_answering.py#L87)'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-750
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Parameters
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-756
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table Question Answering pipeline using a `ModelForTableQuestionAnswering`.
    This pipeline is only available in PyTorch.
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-765
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
- en: 'This tabular question answering pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"table-question-answering"`.'
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a tabular question answering task. See the up-to-date list of available models
    on [huggingface.co/models](https://huggingface.co/models?filter=table-question-answering).
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/table_question_answering.py#L270)'
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-771
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Parameters
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
- en: '`table` (`pd.DataFrame` or `Dict`) — Pandas DataFrame or dictionary that will
    be converted to a DataFrame containing all the table values. See above for an
    example of dictionary.'
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`query` (`str` or `List[str]`) — Query or list of queries that will be sent
    to the model alongside the table.'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequential` (`bool`, *optional*, defaults to `False`) — Whether to do inference
    sequentially or as a batch. Batching is faster, but models like SQA require the
    inference to be done sequentially to extract relations within sequences, given
    their conversational nature.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-777
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-778
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-779
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`truncation` (`bool`, `str` or `TapasTruncationStrategy`, *optional*, defaults
    to `False`) — Activates and controls truncation. Accepts the following values:'
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`True` or `''drop_rows_to_fit''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate row by row, removing rows
    from the table.'
  id: totrans-781
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-782
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
- en: A dictionary or a list of dictionaries containing results
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result is a dictionary with the following keys:'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
- en: '`answer` (`str`) — The answer of the query given the table. If there is an
    aggregator, the answer will be preceded by `AGGREGATOR >`.'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`coordinates` (`List[Tuple[int, int]]`) — Coordinates of the cells of the answers.'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cells` (`List[str]`) — List of strings made up of the answer cell values.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aggregator` (`str`) — If the model has an aggregator, this returns the aggregator.'
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Answers queries according to a table. The pipeline accepts several types of
    inputs which are detailed below:'
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
- en: '`pipeline(table, query)`'
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline(table, [query])`'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline(table=table, query=query)`'
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline(table=table, query=[query])`'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline({"table": table, "query": query})`'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline({"table": table, "query": [query]})`'
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline([{"table": table, "query": query}, {"table": table, "query": query}])`'
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `table` argument should be a dict or a DataFrame built from that dict,
    containing the whole table:'
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-800
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This dictionary can be passed in as such, or can be converted to a pandas DataFrame:'
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-803
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: TextClassificationPipeline
  id: totrans-804
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.TextClassificationPipeline`'
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_classification.py#L34)'
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-807
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Parameters
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-813
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_all_scores` (`bool`, *optional*, defaults to `False`) — Whether to
    return all prediction scores or just the one of the predicted class.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`function_to_apply` (`str`, *optional*, defaults to `"default"`) — The function
    to apply to the model outputs in order to retrieve the scores. Accepts four different
    values:'
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"default"`: if the model has a single label, will apply the sigmoid function
    on the output. If the model has several labels, will apply the softmax function
    on the output.'
  id: totrans-822
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"sigmoid"`: Applies the sigmoid function on the output.'
  id: totrans-823
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"softmax"`: Applies the softmax function on the output.'
  id: totrans-824
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"none"`: Does not apply any function on the output.'
  id: totrans-825
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Text classification pipeline using any `ModelForSequenceClassification`. See
    the [sequence classification examples](../task_summary#sequence-classification)
    for more information.
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-828
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
- en: 'This text classification pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"sentiment-analysis"` (for classifying sequences
    according to positive or negative sentiments).'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
- en: If multiple classification labels are available (`model.config.num_labels >=
    2`), the pipeline will run a softmax over the results. If there is a single label,
    the pipeline will run a sigmoid over the result.
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a sequence classification task. See the up-to-date list of available models on
    [huggingface.co/models](https://huggingface.co/models?filter=text-classification).
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_classification.py#L122)'
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-835
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Parameters
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`str` or `List[str]` or `Dict[str]`, or `List[Dict[str]]`) — One or
    several texts to classify. In order to use text pairs for your classification,
    you can send a dictionary containing `{"text", "text_pair"}` keys, or a list of
    those.'
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`, *optional*, defaults to `1`) — How many results to return.'
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`function_to_apply` (`str`, *optional*, defaults to `"default"`) — The function
    to apply to the model outputs in order to retrieve the scores. Accepts four different
    values:'
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If this argument is not specified, then it will apply the following functions
    according to the number of labels:'
  id: totrans-840
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If the model has a single label, will apply the sigmoid function on the output.
  id: totrans-841
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If the model has several labels, will apply the softmax function on the output.
  id: totrans-842
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Possible values are:'
  id: totrans-843
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`"sigmoid"`: Applies the sigmoid function on the output.'
  id: totrans-844
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"softmax"`: Applies the softmax function on the output.'
  id: totrans-845
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"none"`: Does not apply any function on the output.'
  id: totrans-846
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as list of dictionaries with the following keys:'
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
- en: '`label` (`str`) — The label predicted.'
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`float`) — The corresponding probability.'
  id: totrans-851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `top_k` is used, one such dictionary is returned per label.
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
- en: Classify the text(s) given as inputs.
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
- en: TextGenerationPipeline
  id: totrans-854
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.TextGenerationPipeline`'
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_generation.py#L23)'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  id: totrans-857
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Parameters
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-863
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language generation pipeline using any `ModelWithLMHead`. This pipeline predicts
    the words that will follow a specified text prompt.
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-872
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial).
    You can pass text generation parameters to this pipeline to control stopping criteria,
    decoding strategy, and more. Learn more about text generation parameters in [Text
    generation strategies](../generation_strategies) and [Text generation](text_generation).
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
- en: 'This language generation pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"text-generation"`.'
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been trained with
    an autoregressive language modeling objective, which includes the uni-directional
    models in the library (e.g. gpt2). See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=text-generation).
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text_generation.py#L178)'
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  id: totrans-878
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Parameters
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`str` or `List[str]`) — One or several prompts (or one list of prompts)
    to complete.'
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_tensors` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the tensors of predictions (as token indices) in the outputs. If set
    to `True`, the decoded text is not returned.'
  id: totrans-881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_text` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return the decoded texts in the outputs.'
  id: totrans-882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_full_text` (`bool`, *optional*, defaults to `True`) — If set to `False`
    only added text is returned, otherwise the full text is returned. Only meaningful
    if *return_text* is set to True.'
  id: totrans-883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `False`) —
    Whether or not to clean up the potential extra spaces in the text output.'
  id: totrans-884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prefix` (`str`, *optional*) — Prefix added to prompt.'
  id: totrans-885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`handle_long_generation` (`str`, *optional*) — By default, this pipelines does
    not handle long generation (ones that exceed in one form or the other the model
    maximum length). There is no perfect way to adress this (more info :[https://github.com/huggingface/transformers/issues/14033#issuecomment-948385227](https://github.com/huggingface/transformers/issues/14033#issuecomment-948385227)).
    This provides common strategies to work around that problem depending on your
    use case.'
  id: totrans-886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`None` : default strategy where nothing in particular happens'
  id: totrans-887
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"hole"`: Truncates left of input, and leaves a gap wide enough to let generation
    happen (might truncate a lot of the prompt and not suitable when generation exceed
    the model capacity)'
  id: totrans-888
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: generate_kwargs — Additional keyword arguments to pass along to the generate
    method of the model (see the generate method corresponding to your framework [here](./model#generative-models)).
  id: totrans-889
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Returns
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns one of the following dictionaries (cannot return a combination of both
    `generated_text` and `generated_token_ids`):'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_text` (`str`, present when `return_text=True`) — The generated text.'
  id: totrans-893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_token_ids` (`torch.Tensor` or `tf.Tensor`, present when `return_tensors=True`)
    — The token ids of the generated text.'
  id: totrans-894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete the prompt(s) given as inputs.
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
- en: Text2TextGenerationPipeline
  id: totrans-896
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.Text2TextGenerationPipeline`'
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L25)'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-899
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Parameters
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-905
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text to text generation using seq2seq models.
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-914
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial).
    You can pass text generation parameters to this pipeline to control stopping criteria,
    decoding strategy, and more. Learn more about text generation parameters in [Text
    generation strategies](../generation_strategies) and [Text generation](text_generation).
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
- en: 'This Text2TextGenerationPipeline pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"text2text-generation"`.'
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a translation task. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models?filter=text2text-generation).
    For a list of available parameters, see the [following documentation](https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.generation.GenerationMixin.generate)
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
- en: 'Usage:'
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  id: totrans-919
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '#### `__call__`'
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L138)'
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  id: totrans-922
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Parameters
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`str` or `List[str]`) — Input text for the encoder.'
  id: totrans-924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_tensors` (`bool`, *optional*, defaults to `False`) — Whether or not
    to include the tensors of predictions (as token indices) in the outputs.'
  id: totrans-925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_text` (`bool`, *optional*, defaults to `True`) — Whether or not to
    include the decoded texts in the outputs.'
  id: totrans-926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `False`) —
    Whether or not to clean up the potential extra spaces in the text output.'
  id: totrans-927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`truncation` (`TruncationStrategy`, *optional*, defaults to `TruncationStrategy.DO_NOT_TRUNCATE`)
    — The truncation strategy for the tokenization within the pipeline. `TruncationStrategy.DO_NOT_TRUNCATE`
    (default) will never truncate, but it is sometimes desirable to truncate the input
    to fit the model’s max_length instead of throwing an error down the line. generate_kwargs
    — Additional keyword arguments to pass along to the generate method of the model
    (see the generate method corresponding to your framework [here](./model#generative-models)).'
  id: totrans-928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following keys:'
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_text` (`str`, present when `return_text=True`) — The generated text.'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_token_ids` (`torch.Tensor` or `tf.Tensor`, present when `return_tensors=True`)
    — The token ids of the generated text.'
  id: totrans-933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate the output text(s) using text(s) given as inputs.
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
- en: '#### `check_inputs`'
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L111)'
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  id: totrans-937
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: Checks whether there might be something wrong with given input with regard to
    the model.
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
- en: TokenClassificationPipeline
  id: totrans-939
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.TokenClassificationPipeline`'
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/token_classification.py#L61)'
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  id: totrans-942
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Parameters
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-946
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-947
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-948
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-950
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-951
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-952
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ignore_labels` (`List[str]`, defaults to `["O"]`) — A list of labels to ignore.'
  id: totrans-955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`grouped_entities` (`bool`, *optional*, defaults to `False`) — DEPRECATED,
    use `aggregation_strategy` instead. Whether or not to group the tokens corresponding
    to the same entity together in the predictions or not.'
  id: totrans-956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stride` (`int`, *optional*) — If stride is provided, the pipeline is applied
    on all the text. The text is split into chunks of size model_max_length. Works
    only with fast tokenizers and `aggregation_strategy` different from `NONE`. The
    value of this argument defines the number of overlapping tokens between chunks.
    In other words, the model will shift forward by `tokenizer.model_max_length -
    stride` tokens each step.'
  id: totrans-957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aggregation_strategy` (`str`, *optional*, defaults to `"none"`) — The strategy
    to fuse (or not) tokens based on the model prediction.'
  id: totrans-958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“none” : Will simply not do any aggregation and simply return raw results from
    the model'
  id: totrans-959
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '“simple” : Will attempt to group entities following the default schema. (A,
    B-TAG), (B, I-TAG), (C, I-TAG), (D, B-TAG2) (E, B-TAG2) will end up being [{“word”:
    ABC, “entity”: “TAG”}, {“word”: “D”, “entity”: “TAG2”}, {“word”: “E”, “entity”:
    “TAG2”}] Notice that two consecutive B tags will end up as different entities.
    On word based languages, we might end up splitting words undesirably : Imagine
    Microsoft being tagged as [{“word”: “Micro”, “entity”: “ENTERPRISE”}, {“word”:
    “soft”, “entity”: “NAME”}]. Look for FIRST, MAX, AVERAGE for ways to mitigate
    that and disambiguate words (on languages that support that meaning, which is
    basically tokens separated by a space). These mitigations will only work on real
    words, “New york” might still be tagged with two different entities.'
  id: totrans-960
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '“first” : (works only on word based models) Will use the `SIMPLE` strategy
    except that words, cannot end up with different tags. Words will simply use the
    tag of the first token of the word when there is ambiguity.'
  id: totrans-961
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '“average” : (works only on word based models) Will use the `SIMPLE` strategy
    except that words, cannot end up with different tags. scores will be averaged
    first across tokens, and then the maximum label is applied.'
  id: totrans-962
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '“max” : (works only on word based models) Will use the `SIMPLE` strategy except
    that words, cannot end up with different tags. Word entity will simply be the
    token with the maximum score.'
  id: totrans-963
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Named Entity Recognition pipeline using any `ModelForTokenClassification`. See
    the [named entity recognition examples](../task_summary#named-entity-recognition)
    for more information.
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  id: totrans-966
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
- en: 'This token recognition pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"ner"` (for predicting the classes of tokens
    in a sequence: person, organisation, location or miscellaneous).'
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a token classification task. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models?filter=token-classification).
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/token_classification.py#L219)'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  id: totrans-972
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Parameters
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
- en: '`inputs` (`str` or `List[str]`) — One or several texts (or one list of texts)
    for token classification.'
  id: totrans-974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a list of dictionaries (one for each token in the corresponding
    input, or each entity if this pipeline was instantiated with an aggregation_strategy)
    with the following keys:'
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
- en: '`word` (`str`) — The token/word classified. This is obtained by decoding the
    selected tokens. If you want to have the exact string in the original sentence,
    use `start` and `end`.'
  id: totrans-978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`float`) — The corresponding probability for `entity`.'
  id: totrans-979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`entity` (`str`) — The entity predicted for that token/word (it is named *entity_group*
    when *aggregation_strategy* is not `"none"`.'
  id: totrans-980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`index` (`int`, only present when `aggregation_strategy="none"`) — The index
    of the corresponding token in the sentence.'
  id: totrans-981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start` (`int`, *optional*) — The index of the start of the corresponding entity
    in the sentence. Only exists if the offsets are available within the tokenizer'
  id: totrans-982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end` (`int`, *optional*) — The index of the end of the corresponding entity
    in the sentence. Only exists if the offsets are available within the tokenizer'
  id: totrans-983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classify each token of the text(s) given as inputs.
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
- en: '#### `aggregate_words`'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/token_classification.py#L470)'
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  id: totrans-987
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Override tokens from a given word that disagree to force agreement on word boundaries.
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: micro|soft| com|pany| B-ENT I-NAME I-ENT I-ENT will be rewritten with
    first strategy as microsoft| company| B-ENT I-ENT'
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
- en: '#### `gather_pre_entities`'
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/token_classification.py#L356)'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  id: totrans-992
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Fuse various numpy arrays into dicts with all the information needed for aggregation
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
- en: '#### `group_entities`'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/token_classification.py#L533)'
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  id: totrans-996
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Parameters
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
- en: '`entities` (`dict`) — The entities predicted by the pipeline.'
  id: totrans-998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find and group together the adjacent tokens with the same entity predicted.
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
- en: '#### `group_sub_entities`'
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/token_classification.py#L498)'
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  id: totrans-1002
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Parameters
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
- en: '`entities` (`dict`) — The entities predicted by the pipeline.'
  id: totrans-1004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Group together the adjacent tokens with the same entity predicted.
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
- en: TranslationPipeline
  id: totrans-1006
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.TranslationPipeline`'
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L286)'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  id: totrans-1009
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Parameters
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1015
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translates from one language to another.
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
- en: 'This translation pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"translation_xx_to_yy"`.'
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a translation task. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models?filter=translation).
    For a list of available parameters, see the [following documentation](https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.generation.GenerationMixin.generate)
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
- en: 'Usage:'
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  id: totrans-1026
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '#### `__call__`'
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/text2text_generation.py#L341)'
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  id: totrans-1029
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Parameters
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`str` or `List[str]`) — Texts to be translated.'
  id: totrans-1031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_tensors` (`bool`, *optional*, defaults to `False`) — Whether or not
    to include the tensors of predictions (as token indices) in the outputs.'
  id: totrans-1032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_text` (`bool`, *optional*, defaults to `True`) — Whether or not to
    include the decoded texts in the outputs.'
  id: totrans-1033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `False`) —
    Whether or not to clean up the potential extra spaces in the text output.'
  id: totrans-1034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src_lang` (`str`, *optional*) — The language of the input. Might be required
    for multilingual models. Will not have any effect for single pair translation
    models'
  id: totrans-1035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tgt_lang` (`str`, *optional*) — The language of the desired output. Might
    be required for multilingual models. Will not have any effect for single pair
    translation models generate_kwargs — Additional keyword arguments to pass along
    to the generate method of the model (see the generate method corresponding to
    your framework [here](./model#generative-models)).'
  id: totrans-1036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following keys:'
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
- en: '`translation_text` (`str`, present when `return_text=True`) — The translation.'
  id: totrans-1040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`translation_token_ids` (`torch.Tensor` or `tf.Tensor`, present when `return_tensors=True`)
    — The token ids of the translation.'
  id: totrans-1041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translate the text(s) given as inputs.
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
- en: ZeroShotClassificationPipeline
  id: totrans-1043
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.ZeroShotClassificationPipeline`'
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_classification.py#L46)'
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  id: totrans-1046
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Parameters
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1052
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLI-based zero-shot classification pipeline using a `ModelForSequenceClassification`
    trained on NLI (natural language inference) tasks. Equivalent of `text-classification`
    pipelines, but these models don’t require a hardcoded number of potential classes,
    they can be chosen at runtime. It usually means it’s slower but it is **much**
    more flexible.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
- en: Any combination of sequences and labels can be passed and each combination will
    be posed as a premise/hypothesis pair and passed to the pretrained model. Then,
    the logit for *entailment* is taken as the logit for the candidate label being
    valid. Any NLI model can be used, but the id of the *entailment* label must be
    included in the model config’s :attr:*~transformers.PretrainedConfig.label2id*.
  id: totrans-1060
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  id: totrans-1062
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-1063
  prefs: []
  type: TYPE_NORMAL
- en: 'This NLI pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"zero-shot-classification"`.'
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    an NLI task. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models?search=nli).
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/zero_shot_classification.py#L163)'
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  id: totrans-1068
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Parameters
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
- en: '`sequences` (`str` or `List[str]`) — The sequence(s) to classify, will be truncated
    if the model input is too large.'
  id: totrans-1070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`candidate_labels` (`str` or `List[str]`) — The set of possible class labels
    to classify each sequence into. Can be a single label, a string of comma-separated
    labels, or a list of labels.'
  id: totrans-1071
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hypothesis_template` (`str`, *optional*, defaults to `"This example is {}."`)
    — The template used to turn each label into an NLI-style hypothesis. This template
    must include a {} or similar syntax for the candidate label to be inserted into
    the template. For example, the default template is `"This example is {}."` With
    the candidate label `"sports"`, this would be fed into the model like `"<cls>
    sequence to classify <sep> This example is sports . <sep>"`. The default template
    works well in many cases, but it may be worthwhile to experiment with different
    templates depending on the task setting.'
  id: totrans-1072
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multi_label` (`bool`, *optional*, defaults to `False`) — Whether or not multiple
    candidate labels can be true. If `False`, the scores are normalized such that
    the sum of the label likelihoods for each sequence is 1\. If `True`, the labels
    are considered independent and probabilities are normalized for each candidate
    by doing a softmax of the entailment score vs. the contradiction score.'
  id: totrans-1073
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
- en: A `dict` or a list of `dict`
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following keys:'
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
- en: '`sequence` (`str`) — The sequence for which this is the output.'
  id: totrans-1077
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`List[str]`) — The labels sorted by order of likelihood.'
  id: totrans-1078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scores` (`List[float]`) — The probabilities for each of the labels.'
  id: totrans-1079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classify the sequence(s) given as inputs. See the [ZeroShotClassificationPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline)
    documentation for more information.
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal
  id: totrans-1081
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pipelines available for multimodal tasks include the following.
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
- en: DocumentQuestionAnsweringPipeline
  id: totrans-1083
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.DocumentQuestionAnsweringPipeline`'
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/document_question_answering.py#L101)'
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  id: totrans-1086
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Parameters
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1091
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1092
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document Question Answering pipeline using any `AutoModelForDocumentQuestionAnswering`.
    The inputs/outputs are similar to the (extractive) question answering pipeline;
    however, the pipeline takes an image (and optional OCR’d words/boxes) as input
    instead of text context.
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  id: totrans-1101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
- en: 'This document question answering pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"document-question-answering"`.'
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a document question answering task. See the up-to-date list of available models
    on [huggingface.co/models](https://huggingface.co/models?filter=document-question-answering).
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/document_question_answering.py#L194)'
  id: totrans-1106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  id: totrans-1107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Parameters
  id: totrans-1108
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`str` or `PIL.Image`) — The pipeline handles three types of images:'
  id: totrans-1109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a http link pointing to an image
  id: totrans-1110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-1111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-1112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The pipeline accepts either a single image or a batch of images. If given a
    single image, it can be broadcasted to multiple questions.
  id: totrans-1113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`question` (`str`) — A question to ask of the document.'
  id: totrans-1114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`word_boxes` (`List[str, Tuple[float, float, float, float]]`, *optional*) —
    A list of words and bounding boxes (normalized 0->1000). If you provide this optional
    input, then the pipeline will use these words and boxes instead of running OCR
    on the image to derive them for models that need them (e.g. LayoutLM). This allows
    you to reuse OCR’d results across many invocations of the pipeline without having
    to re-run it each time.'
  id: totrans-1115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`, *optional*, defaults to 1) — The number of answers to return
    (will be chosen by order of likelihood). Note that we return less than top_k answers
    if there are not enough options available within the context.'
  id: totrans-1116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doc_stride` (`int`, *optional*, defaults to 128) — If the words in the document
    are too long to fit with the question for the model, it will be split in several
    chunks with some overlap. This argument controls the size of that overlap.'
  id: totrans-1117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_answer_len` (`int`, *optional*, defaults to 15) — The maximum length of
    predicted answers (e.g., only answers with a shorter length are considered).'
  id: totrans-1118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_seq_len` (`int`, *optional*, defaults to 384) — The maximum length of
    the total sentence (context + question) in tokens of each chunk passed to the
    model. The context will be split in several chunks (using `doc_stride` as overlap)
    if needed.'
  id: totrans-1119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_question_len` (`int`, *optional*, defaults to 64) — The maximum length
    of the question after tokenization. It will be truncated if needed.'
  id: totrans-1120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`handle_impossible_answer` (`bool`, *optional*, defaults to `False`) — Whether
    or not we accept impossible as an answer.'
  id: totrans-1121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lang` (`str`, *optional*) — Language to use while running OCR. Defaults to
    english.'
  id: totrans-1122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tesseract_config` (`str`, *optional*) — Additional flags to pass to tesseract
    while running OCR.'
  id: totrans-1123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-1124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
- en: A `dict` or a list of `dict`
  id: totrans-1126
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following keys:'
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
- en: '`score` (`float`) — The probability associated to the answer.'
  id: totrans-1128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start` (`int`) — The start word index of the answer (in the OCR’d version
    of the input or provided `word_boxes`).'
  id: totrans-1129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end` (`int`) — The end word index of the answer (in the OCR’d version of the
    input or provided `word_boxes`).'
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`answer` (`str`) — The answer to the question.'
  id: totrans-1131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`words` (`list[int]`) — The index of each word/box pair that is in the answer'
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer the question(s) given as inputs by using the document(s). A document
    is defined as an image and an optional list of (word, box) tuples which represent
    the text in the document. If the `word_boxes` are not provided, it will use the
    Tesseract OCR engine (if available) to extract the words and boxes automatically
    for LayoutLM-like models which require them as input. For Donut, no OCR is run.
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
- en: 'You can invoke the pipeline several ways:'
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
- en: '`pipeline(image=image, question=question)`'
  id: totrans-1135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline(image=image, question=question, word_boxes=word_boxes)`'
  id: totrans-1136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline([{"image": image, "question": question}])`'
  id: totrans-1137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline([{"image": image, "question": question, "word_boxes": word_boxes}])`'
  id: totrans-1138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FeatureExtractionPipeline
  id: totrans-1139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.FeatureExtractionPipeline`'
  id: totrans-1140
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/feature_extraction.py#L7)'
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  id: totrans-1142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Parameters
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`return_tensors` (`bool`, *optional*) — If `True`, returns a tensor according
    to the specified framework, otherwise returns a list.'
  id: totrans-1149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id.'
  id: totrans-1152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenize_kwargs` (`dict`, *optional*) — Additional dictionary of keyword arguments
    passed along to the tokenizer.'
  id: totrans-1153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature extraction pipeline using no model head. This pipeline extracts the
    hidden states from the base transformer, which can be used as features in downstream
    tasks.
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  id: totrans-1156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-1157
  prefs: []
  type: TYPE_NORMAL
- en: 'This feature extraction pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the task identifier: `"feature-extraction"`.'
  id: totrans-1158
  prefs: []
  type: TYPE_NORMAL
- en: All models may be used for this pipeline. See a list of all models, including
    community-contributed models on [huggingface.co/models](https://huggingface.co/models).
  id: totrans-1159
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1160
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/feature_extraction.py#L96)'
  id: totrans-1161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  id: totrans-1162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Parameters
  id: totrans-1163
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`str` or `List[str]`) — One or several texts (or one list of texts)
    to get the features of.'
  id: totrans-1164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
- en: A nested list of `float`
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
- en: The features computed by the model.
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
- en: Extract the features of the input(s).
  id: totrans-1168
  prefs: []
  type: TYPE_NORMAL
- en: ImageToTextPipeline
  id: totrans-1169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.ImageToTextPipeline`'
  id: totrans-1170
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_to_text.py#L30)'
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  id: totrans-1172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: Parameters
  id: totrans-1173
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image To Text pipeline using a `AutoModelForVision2Seq`. This pipeline predicts
    a caption for a given image.
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  id: totrans-1187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-1188
  prefs: []
  type: TYPE_NORMAL
- en: 'This image to text pipeline can currently be loaded from pipeline() using the
    following task identifier: “image-to-text”.'
  id: totrans-1189
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?pipeline_tag=image-to-text).
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/image_to_text.py#L83)'
  id: totrans-1192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  id: totrans-1193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Parameters
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-1195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a HTTP(s) link pointing to an image
  id: totrans-1196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-1197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-1198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The pipeline accepts either a single image or a batch of images.
  id: totrans-1199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`max_new_tokens` (`int`, *optional*) — The amount of maximum tokens to generate.
    By default it will use `generate` default.'
  id: totrans-1200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generate_kwargs` (`Dict`, *optional*) — Pass it to send all of these arguments
    directly to `generate` allowing full control of this function.'
  id: totrans-1201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-1202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1203
  prefs: []
  type: TYPE_NORMAL
- en: A list or a list of list of `dict`
  id: totrans-1204
  prefs: []
  type: TYPE_NORMAL
- en: 'Each result comes as a dictionary with the following key:'
  id: totrans-1205
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_text` (`str`) — The generated text.'
  id: totrans-1206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign labels to the image(s) passed as inputs.
  id: totrans-1207
  prefs: []
  type: TYPE_NORMAL
- en: MaskGenerationPipeline
  id: totrans-1208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.MaskGenerationPipeline`'
  id: totrans-1209
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/mask_generation.py#L22)'
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  id: totrans-1211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Parameters
  id: totrans-1212
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`feature_extractor` ([SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor))
    — The feature extractor that will be used by the pipeline to encode the input.'
  id: totrans-1215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`points_per_batch` (*optional*, int, default to 64) — Sets the number of points
    run simultaneously by the model. Higher numbers may be faster but use more GPU
    memory.'
  id: totrans-1216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_bboxes_mask` (`bool`, *optional*, default to `False`) — Whether or
    not to output the bounding box predictions.'
  id: totrans-1217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_rle_masks` (`bool`, *optional*, default to `False`) — Whether or not
    to output the masks in `RLE` format'
  id: totrans-1218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic mask generation for images using `SamForMaskGeneration`. This pipeline
    predicts binary masks for an image, given an image. It is a `ChunkPipeline` because
    you can seperate the points in a mini-batch in order to avoid OOM issues. Use
    the `points_per_batch` argument to control the number of points that will be processed
    at the same time. Default is `64`.
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline works in 3 steps:'
  id: totrans-1231
  prefs: []
  type: TYPE_NORMAL
- en: '`preprocess`: A grid of 1024 points evenly separated is generated along with
    bounding boxes and point labels. For more details on how the points and bounding
    boxes are created, check the `_generate_crop_boxes` function. The image is also
    preprocessed using the `image_processor`. This function `yields` a minibatch of
    `points_per_batch`.'
  id: totrans-1232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`forward`: feeds the outputs of `preprocess` to the model. The image embedding
    is computed only once. Calls both `self.model.get_image_embeddings` and makes
    sure that the gradients are not computed, and the tensors and models are on the
    same device.'
  id: totrans-1233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`postprocess`: The most important part of the automatic mask generation happens
    here. Three steps are induced:'
  id: totrans-1234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'image_processor.postprocess_masks (run on each minibatch loop): takes in the
    raw output masks, resizes them according to the image size, and transforms there
    to binary masks.'
  id: totrans-1235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'image_processor.filter_masks (on each minibatch loop): uses both `pred_iou_thresh`
    and `stability_scores`. Also applies a variety of filters based on non maximum
    suppression to remove bad masks.'
  id: totrans-1236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: image_processor.postprocess_masks_for_amg applies the NSM on the mask to only
    keep relevant ones.
  id: totrans-1237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  id: totrans-1239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-1240
  prefs: []
  type: TYPE_NORMAL
- en: 'This segmentation pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifier: `"mask-generation"`.'
  id: totrans-1241
  prefs: []
  type: TYPE_NORMAL
- en: See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=mask-generation).
  id: totrans-1242
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1243
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/mask_generation.py#L135)'
  id: totrans-1244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  id: totrans-1245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Parameters
  id: totrans-1246
  prefs: []
  type: TYPE_NORMAL
- en: '`inputs` (`np.ndarray` or `bytes` or `str` or `dict`) — Image or list of images.'
  id: totrans-1247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.0) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-1248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pred_iou_thresh` (`float`, *optional*, defaults to 0.88) — A filtering threshold
    in `[0,1]` applied on the model’s predicted mask quality.'
  id: totrans-1249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stability_score_thresh` (`float`, *optional*, defaults to 0.95) — A filtering
    threshold in `[0,1]`, using the stability of the mask under changes to the cutoff
    used to binarize the model’s mask predictions.'
  id: totrans-1250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stability_score_offset` (`int`, *optional*, defaults to 1) — The amount to
    shift the cutoff when calculated the stability score.'
  id: totrans-1251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_nms_thresh` (`float`, *optional*, defaults to 0.7) — The box IoU cutoff
    used by non-maximal suppression to filter duplicate masks.'
  id: totrans-1252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_n_layers` (`int`, *optional*, defaults to 0) — If `crops_n_layers>0`,
    mask prediction will be run again on crops of the image. Sets the number of layers
    to run, where each layer has 2**i_layer number of image crops.'
  id: totrans-1253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crop_overlap_ratio` (`float`, *optional*, defaults to `512 / 1500`) — Sets
    the degree to which crops overlap. In the first crop layer, crops will overlap
    by this fraction of the image length. Later layers with more crops scale down
    this overlap.'
  id: totrans-1254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crop_n_points_downscale_factor` (`int`, *optional*, defaults to `1`) — The
    number of points-per-side sampled in layer n is scaled down by crop_n_points_downscale_factor**n.'
  id: totrans-1255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-1256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1257
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict`'
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
- en: 'A dictionary with the following keys:'
  id: totrans-1259
  prefs: []
  type: TYPE_NORMAL
- en: '`mask` (`PIL.Image`) — A binary mask of the detected object as a PIL Image
    of shape `(width, height)` of the original image. Returns a mask filled with zeros
    if no object is found.'
  id: totrans-1260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (*optional* `float`) — Optionally, when the model is capable of estimating
    a confidence of the “object” described by the label and the mask.'
  id: totrans-1261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generates binary segmentation masks
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
- en: VisualQuestionAnsweringPipeline
  id: totrans-1263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class transformers.VisualQuestionAnsweringPipeline`'
  id: totrans-1264
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/visual_question_answering.py#L18)'
  id: totrans-1265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  id: totrans-1266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Parameters
  id: totrans-1267
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual Question Answering pipeline using a `AutoModelForVisualQuestionAnswering`.
    This pipeline is currently only available in PyTorch.
  id: totrans-1279
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1280
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  id: totrans-1281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)
  id: totrans-1282
  prefs: []
  type: TYPE_NORMAL
- en: 'This visual question answering pipeline can currently be loaded from [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    using the following task identifiers: `"visual-question-answering", "vqa"`.'
  id: totrans-1283
  prefs: []
  type: TYPE_NORMAL
- en: The models that this pipeline can use are models that have been fine-tuned on
    a visual question answering task. See the up-to-date list of available models
    on [huggingface.co/models](https://huggingface.co/models?filter=visual-question-answering).
  id: totrans-1284
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1285
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/visual_question_answering.py#L70)'
  id: totrans-1286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  id: totrans-1287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: Parameters
  id: totrans-1288
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`str`, `List[str]`, `PIL.Image` or `List[PIL.Image]`) — The pipeline
    handles three types of images:'
  id: totrans-1289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a http link pointing to an image
  id: totrans-1290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A string containing a local path to an image
  id: totrans-1291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An image loaded in PIL directly
  id: totrans-1292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The pipeline accepts either a single image or a batch of images. If given a
    single image, it can be broadcasted to multiple questions.
  id: totrans-1293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`question` (`str`, `List[str]`) — The question(s) asked. If given a single
    question, it can be broadcasted to multiple images.'
  id: totrans-1294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`, *optional*, defaults to 5) — The number of top labels that
    will be returned by the pipeline. If the provided number is higher than the number
    of labels available in the model configuration, it will default to the number
    of labels.'
  id: totrans-1295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout` (`float`, *optional*, defaults to None) — The maximum time in seconds
    to wait for fetching images from the web. If None, no timeout is set and the call
    may block forever.'
  id: totrans-1296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1297
  prefs: []
  type: TYPE_NORMAL
- en: A dictionary or a list of dictionaries containing the result. The dictionaries
    contain the following keys
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
- en: '`label` (`str`) — The label identified by the model.'
  id: totrans-1299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`int`) — The score attributed by the model for that label.'
  id: totrans-1300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Answers open-ended questions about images. The pipeline accepts several types
    of inputs which are detailed below:'
  id: totrans-1301
  prefs: []
  type: TYPE_NORMAL
- en: '`pipeline(image=image, question=question)`'
  id: totrans-1302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline({"image": image, "question": question})`'
  id: totrans-1303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline([{"image": image, "question": question}])`'
  id: totrans-1304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pipeline([{"image": image, "question": question}, {"image": image, "question":
    question}])`'
  id: totrans-1305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parent class: Pipeline'
  id: totrans-1306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.Pipeline`'
  id: totrans-1307
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L749)'
  id: totrans-1308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  id: totrans-1309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Parameters
  id: totrans-1310
  prefs: []
  type: TYPE_NORMAL
- en: '`model` ([PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel))
    — The model that will be used by the pipeline to make predictions. This needs
    to be a model inheriting from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    for PyTorch and [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    for TensorFlow.'
  id: totrans-1311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer that will be used by the pipeline to encode data for the model.
    This object inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-1312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelcard` (`str` or `ModelCard`, *optional*) — Model card attributed to the
    model for this pipeline.'
  id: totrans-1313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`, *optional*) — The framework to use, either `"pt"` for PyTorch
    or `"tf"` for TensorFlow. The specified framework must be installed.'
  id: totrans-1314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no framework is specified, will default to the one currently installed. If
    no framework is specified and both frameworks are installed, will default to the
    framework of the `model`, or to PyTorch if no model is provided.
  id: totrans-1315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`task` (`str`, defaults to `""`) — A task-identifier for the pipeline.'
  id: totrans-1316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers` (`int`, *optional*, defaults to 8) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number
    of workers to be used.'
  id: totrans-1317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` (`int`, *optional*, defaults to 1) — When the pipeline will use
    *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
    the batch to use, for inference this is not always beneficial, please read [Batching
    with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching)
    .'
  id: totrans-1318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args_parser` ([ArgumentHandler](/docs/transformers/v4.37.2/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler),
    *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.'
  id: totrans-1319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports.
    Setting this to -1 will leverage CPU, a positive will run the model on the associated
    CUDA device id. You can pass native `torch.device` or a `str` too.'
  id: totrans-1320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_output` (`bool`, *optional*, defaults to `False`) — Flag indicating
    if the output the pipeline should happen in a binary format (i.e., pickle) or
    as raw text.'
  id: totrans-1321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Pipeline class is the class from which all pipelines inherit. Refer to this
    class for methods shared across different pipelines.
  id: totrans-1322
  prefs: []
  type: TYPE_NORMAL
- en: 'Base class implementing pipelined operations. Pipeline workflow is defined
    as a sequence of the following operations:'
  id: totrans-1323
  prefs: []
  type: TYPE_NORMAL
- en: Input -> Tokenization -> Model Inference -> Post-Processing (task dependent)
    -> Output
  id: totrans-1324
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline supports running on CPU or GPU through the device argument (see below).
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
- en: Some pipeline, like for instance [FeatureExtractionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.FeatureExtractionPipeline)
    (`'feature-extraction'`) output large tensor object as nested-lists. In order
    to avoid dumping such large structure as textual data we provide the `binary_output`
    constructor argument. If set to `True`, the output will be stored in the pickle
    format.
  id: totrans-1326
  prefs: []
  type: TYPE_NORMAL
- en: '#### `check_model_type`'
  id: totrans-1327
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L984)'
  id: totrans-1328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  id: totrans-1329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: Parameters
  id: totrans-1330
  prefs: []
  type: TYPE_NORMAL
- en: '`supported_models` (`List[str]` or `dict`) — The list of models supported by
    the pipeline, or a dictionary with model class values.'
  id: totrans-1331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check if the model class is in supported by the pipeline.
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
- en: '#### `device_placement`'
  id: totrans-1333
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L923)'
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  id: totrans-1335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: Context Manager allowing tensor allocation on the user-specified device in framework
    agnostic way.
  id: totrans-1336
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-1337
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  id: totrans-1338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '#### `ensure_tensor_on_device`'
  id: totrans-1339
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L950)'
  id: totrans-1340
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  id: totrans-1341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: Parameters
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
- en: '`inputs` (keyword arguments that should be `torch.Tensor`, the rest is ignored)
    — The tensors to place on `self.device`.'
  id: totrans-1343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Recursive` on lists **only**. —'
  id: totrans-1344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1345
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, torch.Tensor]`'
  id: totrans-1346
  prefs: []
  type: TYPE_NORMAL
- en: The same as `inputs` but on the proper device.
  id: totrans-1347
  prefs: []
  type: TYPE_NORMAL
- en: Ensure PyTorch tensors are on the specified device.
  id: totrans-1348
  prefs: []
  type: TYPE_NORMAL
- en: '#### `postprocess`'
  id: totrans-1349
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L1047)'
  id: totrans-1350
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  id: totrans-1351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Postprocess will receive the raw outputs of the `_forward` method, generally
    tensors, and reformat them into something more friendly. Generally it will output
    a list or a dict or results (containing just strings and numbers).
  id: totrans-1352
  prefs: []
  type: TYPE_NORMAL
- en: '#### `predict`'
  id: totrans-1353
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L917)'
  id: totrans-1354
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  id: totrans-1355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: Scikit / Keras interface to transformers’ pipelines. This method will forward
    to **call**().
  id: totrans-1356
  prefs: []
  type: TYPE_NORMAL
- en: '#### `preprocess`'
  id: totrans-1357
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L1026)'
  id: totrans-1358
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-1359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: Preprocess will take the `input_` of a specific pipeline and return a dictionary
    of everything necessary for `_forward` to run properly. It should contain at least
    one tensor, but might have arbitrary other items.
  id: totrans-1360
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save_pretrained`'
  id: totrans-1361
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L861)'
  id: totrans-1362
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-1363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: Parameters
  id: totrans-1364
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str`) — A path to the directory where to saved. It will
    be created if it doesn’t exist.'
  id: totrans-1365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safe_serialization` (`str`) — Whether to save the model using `safetensors`
    or the traditional way for PyTorch or Tensorflow.'
  id: totrans-1366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save the pipeline’s model and tokenizer.
  id: totrans-1367
  prefs: []
  type: TYPE_NORMAL
- en: '#### `transform`'
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/pipelines/base.py#L911)'
  id: totrans-1369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  id: totrans-1370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Scikit / Keras interface to transformers’ pipelines. This method will forward
    to **call**().
  id: totrans-1371
  prefs: []
  type: TYPE_NORMAL
