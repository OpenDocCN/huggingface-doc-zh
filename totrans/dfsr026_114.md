# UNet3DConditionModel

> 原始文本：[`huggingface.co/docs/diffusers/api/models/unet3d-cond`](https://huggingface.co/docs/diffusers/api/models/unet3d-cond)

[UNet](https://huggingface.co/papers/1505.04597)模型最初由 Ronneberger 等人提出，用于生物医学图像分割，但它也常用于🤗 Diffusers，因为它输出与输入相同大小的图像。它是扩散系统中最重要的组件之一，因为它促进了实际的扩散过程。在🤗 Diffusers 中有几个 UNet 模型的变体，取决于它的维度数量以及是否是有条件模型。这是一个 3D UNet 有条件模型。

论文摘要为：

*有很大的共识，成功训练深度网络需要成千上万个注释的训练样本。在本文中，我们提出了一种依赖于强大数据增强的网络和训练策略，以更有效地利用可用的注释样本。该架构由一个收缩路径和一个对称扩展路径组成，用于捕获上下文和实现精确定位。我们展示了这样一个网络可以从很少的图像端到端训练，并在 ISBI 挑战中胜过先前最佳方法（滑动窗口卷积网络）用于电子显微镜堆中神经结构的分割。使用相同的网络在透射光显微镜图像（相差和 DIC）上训练，我们在这些类别上以很大的优势赢得了 2015 年 ISBI 细胞跟踪挑战。此外，该网络速度很快。在最新的 GPU 上，对 512x512 图像的分割不到一秒。完整的实现（基于 Caffe）和训练网络可在[`lmb.informatik.uni-freiburg.de/people/ronneber/u-net`](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net)上获得。*

## UNet3DConditionModel

### `class diffusers.UNet3DConditionModel`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L64)

```py
( sample_size: Optional = None in_channels: int = 4 out_channels: int = 4 down_block_types: Tuple = ('CrossAttnDownBlock3D', 'CrossAttnDownBlock3D', 'CrossAttnDownBlock3D', 'DownBlock3D') up_block_types: Tuple = ('UpBlock3D', 'CrossAttnUpBlock3D', 'CrossAttnUpBlock3D', 'CrossAttnUpBlock3D') block_out_channels: Tuple = (320, 640, 1280, 1280) layers_per_block: int = 2 downsample_padding: int = 1 mid_block_scale_factor: float = 1 act_fn: str = 'silu' norm_num_groups: Optional = 32 norm_eps: float = 1e-05 cross_attention_dim: int = 1024 attention_head_dim: Union = 64 num_attention_heads: Union = None )
```

参数

+   `sample_size`（`int`或`Tuple[int, int]`，*可选*，默认为`None`）— 输入/输出样本的高度和宽度。

+   `in_channels`（`int`，*可选*，默认为 4）— 输入样本中的通道数。

+   `out_channels`（`int`，*可选*，默认为 4）— 输出中的通道数。

+   `down_block_types`（`Tuple[str]`，*可选*，默认为`("CrossAttnDownBlock2D", "CrossAttnDownBlock2D", "CrossAttnDownBlock2D", "DownBlock2D")`）— 要使用的下采样块的元组。

+   `up_block_types`（`Tuple[str]`，*可选*，默认为`("UpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D")`）— 要使用的上采样块的元组。

+   `block_out_channels`（`Tuple[int]`，*可选*，默认为`(320, 640, 1280, 1280)`）— 每个块的输出通道的元组。

+   `layers_per_block`（`int`，*可选*，默认为 2）— 每个块的层数。

+   `downsample_padding`（`int`，*可选*，默认为 1）— 用于下采样卷积的填充。

+   `mid_block_scale_factor`（`float`，*可选*，默认为 1.0）— 用于中间块的比例因子。

+   `act_fn`（`str`，*可选*，默认为`"silu"`) — 要使用的激活函数。

+   `norm_num_groups`（`int`，*可选*，默认为 32）— 用于规范化的组数。如果为`None`，则在后处理中跳过规范化和激活层。

+   `norm_eps`（`float`，*可选*，默认为 1e-5）— 用于规范化的ε。

+   `cross_attention_dim`（`int`，*可选*，默认为 1280）— 交叉注意力特征的维度。

+   `attention_head_dim`（`int`，*可选*，默认为 8）— 注意力头的维度。

+   `num_attention_heads`（`int`，*可选*）— 注意力头的数量。

一个有条件的 3D UNet 模型，接受一个嘈杂的样本、条件状态和一个时间步，并返回一个形状为样本的输出。

此模型继承自 ModelMixin。查看超类文档，了解为所有模型实现的通用方法（如下载或保存）。

#### `disable_freeu`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L498)

```py
( )
```

禁用 FreeU 机制。

#### `enable_forward_chunking`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L412)

```py
( chunk_size: Optional = None dim: int = 0 )
```

参数

+   `chunk_size`（`int`，*可选*）—前馈层的分块大小。如果未指定，将在 dim=`dim`的每个张量上单独运行前馈层。

+   `dim`（`int`，*可选*，默认为`0`）—应该对其进行分块的前馈计算的维度。在 dim=0（批处理）或 dim=1（序列长度）之间进行选择。

将注意力处理器设置为使用[前馈分块](https://huggingface.co/blog/reformer#2-chunked-feed-forward-layers)。

#### `enable_freeu`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L473)

```py
( s1 s2 b1 b2 )
```

参数

+   `s1`（`float`）—阶段 1 的缩放因子，用于减弱跳过特征的贡献。这样做是为了减轻增强去噪过程中的“过度平滑效应”。

+   `s2`（`float`）—阶段 2 的缩放因子，用于减弱跳过特征的贡献。这样做是为了减轻增强去噪过程中的“过度平滑效应”。

+   `b1`（`float`）—阶段 1 的缩放因子，用于放大骨干特征的贡献。

+   `b2`（`float`）—阶段 2 的缩放因子，用于放大骨干特征的贡献。

从[`arxiv.org/abs/2309.11497`](https://arxiv.org/abs/2309.11497)启用 FreeU 机制。

缩放因子后的后缀表示它们被应用的阶段块。

请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同流水线（如 Stable Diffusion v1、v2 和 Stable Diffusion XL）的值组合。

#### `forward`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L518)

```py
( sample: FloatTensor timestep: Union encoder_hidden_states: Tensor class_labels: Optional = None timestep_cond: Optional = None attention_mask: Optional = None cross_attention_kwargs: Optional = None down_block_additional_residuals: Optional = None mid_block_additional_residual: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';~models.unet_3d_condition.UNet3DConditionOutput or tuple
```

参数

+   `sample`（`torch.FloatTensor`）—带有以下形状的嘈杂输入张量`(batch, num_frames, channel, height, width)`。

+   `timestep`（`torch.FloatTensor`或`float`或`int`）—去噪输入的时间步数。

+   `encoder_hidden_states`（`torch.FloatTensor`）—形状为`(batch, sequence_length, feature_dim)`的编码器隐藏状态。

+   `class_labels`（`torch.Tensor`，*可选*，默认为`None`）—用于条件化的可选类标签。它们的嵌入将与时间步嵌入相加。timestep_cond—（`torch.Tensor`，*可选*，默认为`None`）：时间步的条件嵌入。如果提供，嵌入将与通过`self.time_embedding`层传递的样本相加，以获得时间步嵌入。

+   `attention_mask`（`torch.Tensor`，*可选*，默认为`None`）—形状为`(batch, key_tokens)`的注意力掩码应用于`encoder_hidden_states`。如果为`1`，则保留掩码，否则如果为`0`，则丢弃。掩码将被转换为偏置，将大的负值添加到与“丢弃”标记对应的注意力分数中。

+   `cross_attention_kwargs`（`dict`，*可选*）- 如果指定，则传递给`AttentionProcessor`的 kwargs 字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`下定义的。down_block_additional_residuals — (`torch.Tensor`的`tuple`，*可选*）：如果指定，则添加到下行 unet 块的残差中的张量的元组。mid_block_additional_residual — (`torch.Tensor`，*可选*）：如果指定，则添加到中间 unet 块的残差中的张量。

+   `return_dict`（`bool`，*可选*，默认为`True`）- 是否返回一个`~models.unet_3d_condition.UNet3DConditionOutput`而不是一个普通的元组。

+   `cross_attention_kwargs`（`dict`，*可选*）- 如果指定，则传递给`AttnProcessor`的 kwargs 字典。

返回

`~models.unet_3d_condition.UNet3DConditionOutput`或`tuple`

如果`return_dict`为 True，则返回一个`~models.unet_3d_condition.UNet3DConditionOutput`，否则返回一个元组，其中第一个元素是样本张量。

UNet3DConditionModel 的前向方法。

#### `set_attention_slice`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L312)

```py
( slice_size: Union )
```

参数

+   `slice_size`（`str`或`int`或`list(int)`，*可选*，默认为`"auto"`）- 当为`"auto"`时，注意力头的输入减半，因此注意力在两个步骤中计算。如果为`"max"`，通过一次只运行一个切片来节省最大内存。如果提供了一个数字，则使用`attention_head_dim // slice_size`个切片。在这种情况下，`attention_head_dim`必须是`slice_size`的倍数。

启用切片注意力计算。

当启用此选项时，注意力模块将输入张量分割成片段，以便在多个步骤中计算注意力。这对于在节省一些内存的同时换取一点速度下降是有用的。

#### `set_attn_processor`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L378)

```py
( processor: Union )
```

参数

+   `processor`（`dict`，包含`AttentionProcessor`或仅`AttentionProcessor`）- 实例化的处理器类或将设置为**所有**`Attention`层的处理器的处理器类字典。

    如果`processor`是一个字典，则键需要定义到相应交叉注意力处理器的路径。在设置可训练的注意力处理器时，强烈建议这样做。

设置用于计算注意力的注意力处理器。

#### `set_default_attn_processor`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L453)

```py
( )
```

禁用自定义注意力处理器并设置默认的注意力实现。

#### `unload_lora`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L507)

```py
( )
```

卸载 LoRA 权重。

## UNet3DConditionOutput

### `class diffusers.models.unets.unet_3d_condition.UNet3DConditionOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/unets/unet_3d_condition.py#L51)

```py
( sample: FloatTensor )
```

参数

+   `sample`（形状为`(batch_size, num_frames, num_channels, height, width)`的`torch.FloatTensor`）- 在`encoder_hidden_states`输入条件下的隐藏状态输出。模型的最后一层的输出。

UNet3DConditionModel 的输出。
