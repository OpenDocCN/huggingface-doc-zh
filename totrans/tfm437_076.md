# 用于训练的定制硬件

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/perf_hardware`](https://huggingface.co/docs/transformers/v4.37.2/en/perf_hardware)

您用于运行模型训练和推理的硬件可能会对性能产生重大影响。要深入了解 GPU，请务必查看 Tim Dettmer 的优秀[博客文章](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/)。

让我们看看一些关于 GPU 设置的实用建议。

## GPU

当您训练更大的模型时，您基本上有三个选择：

+   更大的 GPU

+   更多的 GPU

+   更多的 CPU 和 NVMe（由 DeepSpeed-Infinity 卸载）

让我们从只有一个 GPU 的情况开始。

### 电源和冷却

如果您购买了昂贵的高端 GPU，请确保为其提供正确的电源和足够的冷却。

**电源**：

一些高端消费级 GPU 卡有 2 个甚至 3 个 PCI-E 8 针电源插座。确保您有与插座数量相同的独立 12V PCI-E 8 针电缆插入卡中。不要使用同一电缆末端的 2 个分裂（也称为猪尾电缆）。也就是说，如果 GPU 上有 2 个插座，您希望从 PSU 到卡的有 2 个 PCI-E 8 针电缆，而不是一个末端有 2 个 PCI-E 8 针连接器的电缆！否则，您将无法充分发挥卡的性能。

每个 PCI-E 8 针电源电缆需要插入 PSU 侧的 12V 电源线，可以提供高达 150W 的功率。

一些其他卡可能使用 PCI-E 12 针连接器，这些连接器可以提供高达 500-600W 的功率。

低端卡可能使用 6 针连接器，提供高达 75W 的功率。

此外，您需要具有稳定电压的高端 PSU。一些质量较低的 PSU 可能无法为卡提供所需的稳定电压以使其在峰值状态下运行。

当然，PSU 需要有足够的未使用瓦特数来为卡供电。

**冷却**：

当 GPU 过热时，它将开始降频，并且不会提供完整的性能，甚至在温度过高时可能会关闭。

很难确定 GPU 在负载严重时应该追求的确切最佳温度，但可能在+80C 以下是好的，但更低更好 - 也许 70-75C 是一个很好的范围。降频很可能会在 84-90C 左右开始。但除了降低性能外，长时间处于非常高的温度下可能会缩短 GPU 的寿命。

接下来让我们看看拥有多个 GPU 时最重要的一个方面：连接性。

### 多 GPU 连接

如果您使用多个 GPU，卡的互连方式对总训练时间有很大影响。如果 GPU 在同一物理节点上，您可以运行：

```py
nvidia-smi topo -m
```

它将告诉您 GPU 是如何互连的。在具有双 GPU 且通过 NVLink 连接的机器上，您很可能会看到类似以下的内容：

```py
        GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      NV2     0-23            N/A
GPU1    NV2      X      0-23            N/A
```

在没有 NVLink 的不同机器上，我们可能会看到：

```py
        GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      PHB     0-11            N/A
GPU1    PHB      X      0-11            N/A
```

该报告包括此图例：

```py
  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks
```

因此，第一个报告`NV2`告诉我们 GPU 是通过 2 个 NVLink 互连的，而第二个报告`PHB`则是典型的消费级 PCIe+Bridge 设置。

检查您的设置上有什么类型的连接性。其中一些将使卡之间的通信更快（例如 NVLink），而其他一些则更慢（例如 PHB）。

根据所使用的可扩展性解决方案的类型，连接速度可能会产生重大或轻微影响。如果 GPU 需要很少同步，如 DDP，较慢连接的影响将不那么显著。如果 GPU 需要经常互发消息，如 ZeRO-DP，则更快的连接变得非常重要以实现更快的训练。

#### NVlink

[NVLink](https://en.wikipedia.org/wiki/NVLink)是由 Nvidia 开发的基于线的串行多通道近距离通信链路。

每一代新产品都提供更快的带宽，例如，这里是来自[Nvidia Ampere GA102 GPU Architecture](https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf)的一句话：

> 第三代 NVLink® GA102 GPU 利用了 NVIDIA 的第三代 NVLink 接口，其中包括四个 x4 链接，每个链接在两个 GPU 之间的每个方向提供 14.0625 GB/sec 的带宽。四个链接在每个方向提供 56.25 GB/sec 的带宽，两个 GPU 之间总共提供 112.5 GB/sec 的带宽。两个 RTX 3090 GPU 可以使用 NVLink 连接在一起进行 SLI。（请注意，不支持 3 路和 4 路 SLI 配置。）

所以在`nvidia-smi topo -m`的输出中，`NVX`报告中的`X`值越高越好。这取决于您的 GPU 架构。

让我们比较在 wikitext 的小样本上训练 gpt2 语言模型的执行。

结果是：

| NVlink | 时间 |
| --- | --: |
| Y | 101 秒 |
| N | 131 秒 |

您可以看到，NVLink 完成训练速度比快约 23%。在第二个基准测试中，我们使用`NCCL_P2P_DISABLE=1`告诉 GPU 不要使用 NVLink。

以下是完整的基准测试代码和输出：

```py
# DDP w/ NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 torchrun \
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train \
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 101.9003, 'train_samples_per_second': 1.963, 'epoch': 0.69}

# DDP w/o NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 NCCL_P2P_DISABLE=1 torchrun \
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 131.4367, 'train_samples_per_second': 1.522, 'epoch': 0.69}
```

硬件：每个 2x TITAN RTX 24GB + 2 个 NVLink 的 NVlink（在`nvidia-smi topo -m`中为`NV2`） 软件：`pytorch-1.8-to-be` + `cuda-11.0` / `transformers==4.3.0.dev0`
