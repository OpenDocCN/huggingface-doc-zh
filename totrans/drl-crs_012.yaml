- en: The “Deep” in Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/learn/deep-rl-course/unit1/deep-rl](https://huggingface.co/learn/deep-rl-course/unit1/deep-rl)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/10.4feeac1f.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Tip.d10b3fc9.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">What
    we've talked about so far is Reinforcement Learning. But where does the "Deep"
    come into play?
  prefs: []
  type: TYPE_NORMAL
- en: Deep Reinforcement Learning introduces **deep neural networks to solve Reinforcement
    Learning problems** — hence the name “deep”.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in the next unit, we’ll learn about two value-based algorithms: Q-Learning (classic
    Reinforcement Learning) and then Deep Q-Learning.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll see the difference is that, in the first approach, **we use a traditional
    algorithm** to create a Q table that helps us find what action to take for each
    state.
  prefs: []
  type: TYPE_NORMAL
- en: In the second approach, **we will use a Neural Network** (to approximate the
    Q value).
  prefs: []
  type: TYPE_NORMAL
- en: '![Value based RL](../Images/1e4c6acfdf811be054c82941f53e5853.png)'
  prefs: []
  type: TYPE_IMG
- en: Schema inspired by the Q learning notebook by Udacity
  prefs: []
  type: TYPE_NORMAL
- en: If you are not familiar with Deep Learning you should definitely watch [the
    FastAI Practical Deep Learning for Coders](https://course.fast.ai) (Free).
  prefs: []
  type: TYPE_NORMAL
