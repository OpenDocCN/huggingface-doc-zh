- en: Deep Q-Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度Q-Learning
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit3/introduction](https://huggingface.co/learn/deep-rl-course/unit3/introduction)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/learn/deep-rl-course/unit3/introduction](https://huggingface.co/learn/deep-rl-course/unit3/introduction)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![Unit 3 thumbnail](../Images/e8420d1d9f22aa4095ae8b961c412a91.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![第3单元缩略图](../Images/e8420d1d9f22aa4095ae8b961c412a91.png)'
- en: 'In the last unit, we learned our first reinforcement learning algorithm: Q-Learning, **implemented
    it from scratch**, and trained it in two environments, FrozenLake-v1 ☃️ and Taxi-v3
    🚕.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个单元中，我们学习了我们的第一个强化学习算法：Q-Learning，**从头开始实现**，并在两个环境中进行了训练，FrozenLake-v1 ☃️和Taxi-v3
    🚕。
- en: We got excellent results with this simple algorithm, but these environments
    were relatively simple because the **state space was discrete and small** (16
    different states for FrozenLake-v1 and 500 for Taxi-v3). For comparison, the state
    space in Atari games can **contain<math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9</mn></msup></mrow><annotation
    encoding="application/x-tex">10^{9}</annotation></semantics></math>109 to<math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>11</mn></msup></mrow><annotation
    encoding="application/x-tex">10^{11}</annotation></semantics></math>1011 states**.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用这个简单的算法取得了出色的结果，但这些环境相对简单，因为**状态空间是离散且较小的**（FrozenLake-v1有16个不同的状态，Taxi-v3有500个）。相比之下，Atari游戏中的状态空间可以**包含<math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9</mn></msup></mrow><annotation
    encoding="application/x-tex">10^{9}</annotation></semantics></math>109到<math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>11</mn></msup></mrow><annotation
    encoding="application/x-tex">10^{11}</annotation></semantics></math>1011个状态**。
- en: But as we’ll see, producing and updating a **Q-table can become ineffective
    in large state space environments.**
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 但正如我们将看到的，**在大状态空间环境中生成和更新Q表可能变得无效**。
- en: 'So in this unit, **we’ll study our first Deep Reinforcement Learning agent**:
    Deep Q-Learning. Instead of using a Q-table, Deep Q-Learning uses a Neural Network
    that takes a state and approximates Q-values for each action based on that state.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本单元中，**我们将学习我们的第一个深度强化学习代理**：深度Q-Learning。深度Q-Learning不使用Q表，而是使用一个神经网络，该神经网络接受一个状态，并根据该状态近似计算每个动作的Q值。
- en: And **we’ll train it to play Space Invaders and other Atari environments using
    [RL-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)**, a training framework
    for RL using Stable-Baselines that provides scripts for training, evaluating agents,
    tuning hyperparameters, plotting results, and recording videos.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们将使用[RL-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)**来训练它玩太空侵略者和其他Atari环境，RL-Zoo是一个使用Stable-Baselines的RL训练框架，提供了用于训练、评估代理、调整超参数、绘制结果和录制视频的脚本。'
- en: '![Environments](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![环境](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
- en: So let’s get started! 🚀
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！🚀
