- en: Deep Q-Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/learn/deep-rl-course/unit3/introduction](https://huggingface.co/learn/deep-rl-course/unit3/introduction)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/43.9c6905fe.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: '![Unit 3 thumbnail](../Images/e8420d1d9f22aa4095ae8b961c412a91.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the last unit, we learned our first reinforcement learning algorithm: Q-Learning, **implemented
    it from scratch**, and trained it in two environments, FrozenLake-v1 ☃️ and Taxi-v3
    🚕.'
  prefs: []
  type: TYPE_NORMAL
- en: We got excellent results with this simple algorithm, but these environments
    were relatively simple because the **state space was discrete and small** (16
    different states for FrozenLake-v1 and 500 for Taxi-v3). For comparison, the state
    space in Atari games can **contain<math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9</mn></msup></mrow><annotation
    encoding="application/x-tex">10^{9}</annotation></semantics></math>109 to<math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>11</mn></msup></mrow><annotation
    encoding="application/x-tex">10^{11}</annotation></semantics></math>1011 states**.
  prefs: []
  type: TYPE_NORMAL
- en: But as we’ll see, producing and updating a **Q-table can become ineffective
    in large state space environments.**
  prefs: []
  type: TYPE_NORMAL
- en: 'So in this unit, **we’ll study our first Deep Reinforcement Learning agent**:
    Deep Q-Learning. Instead of using a Q-table, Deep Q-Learning uses a Neural Network
    that takes a state and approximates Q-values for each action based on that state.'
  prefs: []
  type: TYPE_NORMAL
- en: And **we’ll train it to play Space Invaders and other Atari environments using
    [RL-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)**, a training framework
    for RL using Stable-Baselines that provides scripts for training, evaluating agents,
    tuning hyperparameters, plotting results, and recording videos.
  prefs: []
  type: TYPE_NORMAL
- en: '![Environments](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
  prefs: []
  type: TYPE_IMG
- en: So let’s get started! 🚀
  prefs: []
  type: TYPE_NORMAL
