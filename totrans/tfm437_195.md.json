["```py\nfrom transformers import MarkupLMFeatureExtractor, MarkupLMTokenizerFast, MarkupLMProcessor\n\nfeature_extractor = MarkupLMFeatureExtractor()\ntokenizer = MarkupLMTokenizerFast.from_pretrained(\"microsoft/markuplm-base\")\nprocessor = MarkupLMProcessor(feature_extractor, tokenizer)\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n\n>>> html_string = \"\"\"\n...  <!DOCTYPE html>\n...  <html>\n...  <head>\n...  <title>Hello world</title>\n...  </head>\n...  <body>\n...  <h1>Welcome</h1>\n...  <p>Here is my website.</p>\n...  </body>\n...  </html>\"\"\"\n\n>>> # note that you can also add provide all tokenizer parameters here such as padding, truncation\n>>> encoding = processor(html_string, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n\n>>> nodes = [\"hello\", \"world\", \"how\", \"are\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\", \"html/body\", \"html/body/div\"]\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n\n>>> nodes = [\"hello\", \"world\", \"how\", \"are\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\", \"html/body\", \"html/body/div\"]\n>>> node_labels = [1, 2, 2, 1]\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq', 'labels'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n\n>>> html_string = \"\"\"\n...  <!DOCTYPE html>\n...  <html>\n...  <head>\n...  <title>Hello world</title>\n...  </head>\n...  <body>\n...  <h1>Welcome</h1>\n...  <p>My name is Niels.</p>\n...  </body>\n...  </html>\"\"\"\n\n>>> question = \"What's his name?\"\n>>> encoding = processor(html_string, questions=question, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n\n>>> nodes = [\"hello\", \"world\", \"how\", \"are\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\", \"html/body\", \"html/body/div\"]\n>>> question = \"What's his name?\"\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, questions=question, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n( vocab_size = 30522 hidden_size = 768 num_hidden_layers = 12 num_attention_heads = 12 intermediate_size = 3072 hidden_act = 'gelu' hidden_dropout_prob = 0.1 attention_probs_dropout_prob = 0.1 max_position_embeddings = 512 type_vocab_size = 2 initializer_range = 0.02 layer_norm_eps = 1e-12 pad_token_id = 0 bos_token_id = 0 eos_token_id = 2 max_xpath_tag_unit_embeddings = 256 max_xpath_subs_unit_embeddings = 1024 tag_pad_id = 216 subs_pad_id = 1001 xpath_unit_hidden_size = 32 max_depth = 50 position_embedding_type = 'absolute' use_cache = True classifier_dropout = None **kwargs )\n```", "```py\n>>> from transformers import MarkupLMModel, MarkupLMConfig\n\n>>> # Initializing a MarkupLM microsoft/markuplm-base style configuration\n>>> configuration = MarkupLMConfig()\n\n>>> # Initializing a model from the microsoft/markuplm-base style configuration\n>>> model = MarkupLMModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( **kwargs )\n```", "```py\n( html_strings ) \u2192 export const metadata = 'undefined';BatchFeature\n```", "```py\n>>> from transformers import MarkupLMFeatureExtractor\n\n>>> page_name_1 = \"page1.html\"\n>>> page_name_2 = \"page2.html\"\n>>> page_name_3 = \"page3.html\"\n\n>>> with open(page_name_1) as f:\n...     single_html_string = f.read()\n\n>>> feature_extractor = MarkupLMFeatureExtractor()\n\n>>> # single example\n>>> encoding = feature_extractor(single_html_string)\n>>> print(encoding.keys())\n>>> # dict_keys(['nodes', 'xpaths'])\n\n>>> # batched example\n\n>>> multi_html_strings = []\n\n>>> with open(page_name_2) as f:\n...     multi_html_strings.append(f.read())\n>>> with open(page_name_3) as f:\n...     multi_html_strings.append(f.read())\n\n>>> encoding = feature_extractor(multi_html_strings)\n>>> print(encoding.keys())\n>>> # dict_keys(['nodes', 'xpaths'])\n```", "```py\n( vocab_file merges_file tags_dict errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = False max_depth = 50 max_width = 1000 pad_width = 1001 pad_token_label = -100 only_label_first_subword = True **kwargs )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```", "```py\n( vocab_file merges_file tags_dict tokenizer_file = None errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = False max_depth = 50 max_width = 1000 pad_width = 1001 pad_token_label = -100 only_label_first_subword = True trim_offsets = False **kwargs )\n```", "```py\n( batch_text_or_text_pairs: Union is_pair: bool = None xpaths: Optional = None node_labels: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( text: Union text_pair: Optional = None xpaths: Optional = None node_labels: Optional = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )\n```", "```py\n( xpath )\n```", "```py\n( *args **kwargs )\n```", "```py\n( html_strings = None nodes = None xpaths = None node_labels = None questions = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True return_tensors: Union = None **kwargs )\n```", "```py\n( config add_pooling_layer = True )\n```", "```py\n( input_ids: Optional = None xpath_tags_seq: Optional = None xpath_subs_seq: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, MarkupLMModel\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> model = MarkupLMModel.from_pretrained(\"microsoft/markuplm-base\")\n\n>>> html_string = \"<html> <head> <title>Page Title</title> </head> </html>\"\n\n>>> encoding = processor(html_string, return_tensors=\"pt\")\n\n>>> outputs = model(**encoding)\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 4, 768]\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None xpath_tags_seq: Optional = None xpath_subs_seq: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.SequenceClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForSequenceClassification\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/markuplm-base\", num_labels=7)\n\n>>> html_string = \"<html> <head> <title>Page Title</title> </head> </html>\"\n>>> encoding = processor(html_string, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**encoding)\n\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None xpath_tags_seq: Optional = None xpath_subs_seq: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.MaskedLMOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForTokenClassification\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n>>> model = AutoModelForTokenClassification.from_pretrained(\"microsoft/markuplm-base\", num_labels=7)\n\n>>> nodes = [\"hello\", \"world\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\"]\n>>> node_labels = [1, 2]\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**encoding)\n\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None xpath_tags_seq: Optional = None xpath_subs_seq: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None start_positions: Optional = None end_positions: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.QuestionAnsweringModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoProcessor, MarkupLMForQuestionAnswering\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base-finetuned-websrc\")\n>>> model = MarkupLMForQuestionAnswering.from_pretrained(\"microsoft/markuplm-base-finetuned-websrc\")\n\n>>> html_string = \"<html> <head> <title>My name is Niels</title> </head> </html>\"\n>>> question = \"What's his name?\"\n\n>>> encoding = processor(html_string, questions=question, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**encoding)\n\n>>> answer_start_index = outputs.start_logits.argmax()\n>>> answer_end_index = outputs.end_logits.argmax()\n\n>>> predict_answer_tokens = encoding.input_ids[0, answer_start_index : answer_end_index + 1]\n>>> processor.decode(predict_answer_tokens).strip()\n'Niels'\n```"]