["```py\nfrom transformers import MarkupLMFeatureExtractor, MarkupLMTokenizerFast, MarkupLMProcessor\n\nfeature_extractor = MarkupLMFeatureExtractor()\ntokenizer = MarkupLMTokenizerFast.from_pretrained(\"microsoft/markuplm-base\")\nprocessor = MarkupLMProcessor(feature_extractor, tokenizer)\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n\n>>> html_string = \"\"\"\n...  <!DOCTYPE html>\n...  <html>\n...  <head>\n...  <title>Hello world</title>\n...  </head>\n...  <body>\n...  <h1>Welcome</h1>\n...  <p>Here is my website.</p>\n...  </body>\n...  </html>\"\"\"\n\n>>> # note that you can also add provide all tokenizer parameters here such as padding, truncation\n>>> encoding = processor(html_string, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n\n>>> nodes = [\"hello\", \"world\", \"how\", \"are\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\", \"html/body\", \"html/body/div\"]\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n\n>>> nodes = [\"hello\", \"world\", \"how\", \"are\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\", \"html/body\", \"html/body/div\"]\n>>> node_labels = [1, 2, 2, 1]\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq', 'labels'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n\n>>> html_string = \"\"\"\n...  <!DOCTYPE html>\n...  <html>\n...  <head>\n...  <title>Hello world</title>\n...  </head>\n...  <body>\n...  <h1>Welcome</h1>\n...  <p>My name is Niels.</p>\n...  </body>\n...  </html>\"\"\"\n\n>>> question = \"What's his name?\"\n>>> encoding = processor(html_string, questions=question, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMProcessor\n\n>>> processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n\n>>> nodes = [\"hello\", \"world\", \"how\", \"are\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\", \"html/body\", \"html/body/div\"]\n>>> question = \"What's his name?\"\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, questions=question, return_tensors=\"pt\")\n>>> print(encoding.keys())\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'xpath_tags_seq', 'xpath_subs_seq'])\n```", "```py\n>>> from transformers import MarkupLMModel, MarkupLMConfig\n\n>>> # Initializing a MarkupLM microsoft/markuplm-base style configuration\n>>> configuration = MarkupLMConfig()\n\n>>> # Initializing a model from the microsoft/markuplm-base style configuration\n>>> model = MarkupLMModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import MarkupLMFeatureExtractor\n\n>>> page_name_1 = \"page1.html\"\n>>> page_name_2 = \"page2.html\"\n>>> page_name_3 = \"page3.html\"\n\n>>> with open(page_name_1) as f:\n...     single_html_string = f.read()\n\n>>> feature_extractor = MarkupLMFeatureExtractor()\n\n>>> # single example\n>>> encoding = feature_extractor(single_html_string)\n>>> print(encoding.keys())\n>>> # dict_keys(['nodes', 'xpaths'])\n\n>>> # batched example\n\n>>> multi_html_strings = []\n\n>>> with open(page_name_2) as f:\n...     multi_html_strings.append(f.read())\n>>> with open(page_name_3) as f:\n...     multi_html_strings.append(f.read())\n\n>>> encoding = feature_extractor(multi_html_strings)\n>>> print(encoding.keys())\n>>> # dict_keys(['nodes', 'xpaths'])\n```", "```py\n>>> from transformers import AutoProcessor, MarkupLMModel\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> model = MarkupLMModel.from_pretrained(\"microsoft/markuplm-base\")\n\n>>> html_string = \"<html> <head> <title>Page Title</title> </head> </html>\"\n\n>>> encoding = processor(html_string, return_tensors=\"pt\")\n\n>>> outputs = model(**encoding)\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 4, 768]\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForSequenceClassification\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/markuplm-base\", num_labels=7)\n\n>>> html_string = \"<html> <head> <title>Page Title</title> </head> </html>\"\n>>> encoding = processor(html_string, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**encoding)\n\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForTokenClassification\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n>>> processor.parse_html = False\n>>> model = AutoModelForTokenClassification.from_pretrained(\"microsoft/markuplm-base\", num_labels=7)\n\n>>> nodes = [\"hello\", \"world\"]\n>>> xpaths = [\"/html/body/div/li[1]/div/span\", \"/html/body/div/li[1]/div/span\"]\n>>> node_labels = [1, 2]\n>>> encoding = processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**encoding)\n\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoProcessor, MarkupLMForQuestionAnswering\n>>> import torch\n\n>>> processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base-finetuned-websrc\")\n>>> model = MarkupLMForQuestionAnswering.from_pretrained(\"microsoft/markuplm-base-finetuned-websrc\")\n\n>>> html_string = \"<html> <head> <title>My name is Niels</title> </head> </html>\"\n>>> question = \"What's his name?\"\n\n>>> encoding = processor(html_string, questions=question, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**encoding)\n\n>>> answer_start_index = outputs.start_logits.argmax()\n>>> answer_end_index = outputs.end_logits.argmax()\n\n>>> predict_answer_tokens = encoding.input_ids[0, answer_start_index : answer_end_index + 1]\n>>> processor.decode(predict_answer_tokens).strip()\n'Niels'\n```"]