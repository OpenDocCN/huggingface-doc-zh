- en: Tiny AutoEncoder
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微型自动编码器
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/autoencoder_tiny](https://huggingface.co/docs/diffusers/api/models/autoencoder_tiny)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/diffusers/api/models/autoencoder_tiny](https://huggingface.co/docs/diffusers/api/models/autoencoder_tiny)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Tiny AutoEncoder for Stable Diffusion (TAESD) was introduced in [madebyollin/taesd](https://github.com/madebyollin/taesd)
    by Ollin Boer Bohan. It is a tiny distilled version of Stable Diffusion’s VAE
    that can quickly decode the latents in a [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    or [StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)
    almost instantly.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散的微型自动编码器（TAESD）由 Ollin Boer Bohan 在 [madebyollin/taesd](https://github.com/madebyollin/taesd)
    中引入。它是稳定扩散 VAE 的微型精炼版本，可以快速解码 [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    或 [StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)
    中的潜在表示。
- en: 'To use with Stable Diffusion v-2.1:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 使用稳定扩散 v-2.1 版本：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To use with Stable Diffusion XL 1.0
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 用于稳定扩散 XL 1.0 版本
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: AutoencoderTiny
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoencoderTiny
- en: '### `class diffusers.AutoencoderTiny`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.AutoencoderTiny`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L41)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L41)'
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`in_channels` (`int`, *optional*, defaults to 3) — Number of channels in the
    input image.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_channels`（`int`，*可选*，默认为 3）— 输入图像中的通道数。'
- en: '`out_channels` (`int`, *optional*, defaults to 3) — Number of channels in the
    output.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_channels`（`int`，*可选*，默认为 3）— 输出中的通道数。'
- en: '`encoder_block_out_channels` (`Tuple[int]`, *optional*, defaults to `(64, 64,
    64, 64)`) — Tuple of integers representing the number of output channels for each
    encoder block. The length of the tuple should be equal to the number of encoder
    blocks.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_block_out_channels`（`Tuple[int]`，*可选*，默认为 `(64, 64, 64, 64)`）— 代表每个编码器块的输出通道数的整数元组。元组的长度应等于编码器块的数量。'
- en: '`decoder_block_out_channels` (`Tuple[int]`, *optional*, defaults to `(64, 64,
    64, 64)`) — Tuple of integers representing the number of output channels for each
    decoder block. The length of the tuple should be equal to the number of decoder
    blocks.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_block_out_channels`（`Tuple[int]`，*可选*，默认为 `(64, 64, 64, 64)`）— 代表每个解码器块的输出通道数的整数元组。元组的长度应等于解码器块的数量。'
- en: '`act_fn` (`str`, *optional*, defaults to `"relu"`) — Activation function to
    be used throughout the model.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`act_fn`（`str`，*可选*，默认为 `"relu"`）— 用于整个模型的激活函数。'
- en: '`latent_channels` (`int`, *optional*, defaults to 4) — Number of channels in
    the latent representation. The latent space acts as a compressed representation
    of the input image.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_channels`（`int`，*可选*，默认为 4）— 潜在表示中的通道数。潜在空间充当输入图像的压缩表示。'
- en: '`upsampling_scaling_factor` (`int`, *optional*, defaults to 2) — Scaling factor
    for upsampling in the decoder. It determines the size of the output image during
    the upsampling process.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsampling_scaling_factor`（`int`，*可选*，默认为 2）— 解码器中上采样的缩放因子。它确定上采样过程中输出图像的大小。'
- en: '`num_encoder_blocks` (`Tuple[int]`, *optional*, defaults to `(1, 3, 3, 3)`)
    — Tuple of integers representing the number of encoder blocks at each stage of
    the encoding process. The length of the tuple should be equal to the number of
    stages in the encoder. Each stage has a different number of encoder blocks.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_encoder_blocks`（`Tuple[int]`，*可选*，默认为 `(1, 3, 3, 3)`）— 代表编码过程中每个阶段的编码器块数量的整数元组。元组的长度应等于编码器中的阶段数。每个阶段具有不同数量的编码器块。'
- en: '`num_decoder_blocks` (`Tuple[int]`, *optional*, defaults to `(3, 3, 3, 1)`)
    — Tuple of integers representing the number of decoder blocks at each stage of
    the decoding process. The length of the tuple should be equal to the number of
    stages in the decoder. Each stage has a different number of decoder blocks.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_decoder_blocks`（`Tuple[int]`，*可选*，默认为 `(3, 3, 3, 1)`）— 代表解码过程中每个阶段的解码器块数量的整数元组。元组的长度应等于解码器中的阶段数。每个阶段具有不同数量的解码器块。'
- en: '`latent_magnitude` (`float`, *optional*, defaults to 3.0) — Magnitude of the
    latent representation. This parameter scales the latent representation values
    to control the extent of information preservation.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_magnitude`（`float`，*可选*，默认为 3.0）— 潜在表示的幅度。此参数将潜在表示值缩放以控制信息保留的程度。'
- en: '`latent_shift` (float, *optional*, defaults to 0.5) — Shift applied to the
    latent representation. This parameter controls the center of the latent space.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_shift`（浮点数，*可选*，默认为 0.5）— 应用于潜在表示的偏移。此参数控制潜在空间的中心。'
- en: '`scaling_factor` (`float`, *optional*, defaults to 1.0) — The component-wise
    standard deviation of the trained latent space computed using the first batch
    of the training set. This is used to scale the latent space to have unit variance
    when training the diffusion model. The latents are scaled with the formula `z
    = z * scaling_factor` before being passed to the diffusion model. When decoding,
    the latents are scaled back to the original scale with the formula: `z = 1 / scaling_factor
    * z`. For more details, refer to sections 4.3.2 and D.1 of the [High-Resolution
    Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)
    paper. For this Autoencoder, however, no such scaling factor was used, hence the
    value of 1.0 as the default.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scaling_factor`（`float`，*可选*，默认为 1.0）— 使用训练集的第一批计算的训练潜在空间的分量标准差。在训练扩散模型时，用于将潜在空间缩放为具有单位方差。在传递给扩散模型之前，潜在表示将使用公式
    `z = z * scaling_factor` 进行缩放。在解码时，潜在表示将使用公式缩放回原始比例：`z = 1 / scaling_factor *
    z`。有关更多详细信息，请参阅 [高分辨率图像合成与潜在扩散模型](https://arxiv.org/abs/2112.10752) 论文的 4.3.2
    和 D.1 部分。然而，对于此自动编码器，没有使用此类缩放因子，因此默认值为 1.0。'
- en: '`force_upcast` (`bool`, *optional*, default to `False`) — If enabled it will
    force the VAE to run in float32 for high image resolution pipelines, such as SD-XL.
    VAE can be fine-tuned / trained to a lower range without losing too much precision,
    in which case `force_upcast` can be set to `False` (see this fp16-friendly [AutoEncoder](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_upcast`（`bool`，*可选*，默认为`False`）— 如果启用，它将强制VAE在高图像分辨率管道（如SD-XL）中以float32运行。
    VAE可以在不损失太多精度的情况下被微调/训练到较低范围，此时`force_upcast`可以设置为`False`（请参阅此fp16友好的[AutoEncoder](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)）。'
- en: A tiny distilled VAE model for encoding images into latents and decoding latent
    representations into images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 用于将图像编码为潜变量并将潜变量表示解码为图像的微型精馏VAE模型。
- en: '[AutoencoderTiny](/docs/diffusers/v0.26.3/en/api/models/autoencoder_tiny#diffusers.AutoencoderTiny)
    is a wrapper around the original implementation of `TAESD`.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[AutoencoderTiny](/docs/diffusers/v0.26.3/en/api/models/autoencoder_tiny#diffusers.AutoencoderTiny)是对`TAESD`原始实现的包装。'
- en: This model inherits from [ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin).
    Check the superclass documentation for its generic methods implemented for all
    models (such as downloading or saving).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)。查看超类文档以了解为所有模型实现的通用方法（如下载或保存）。
- en: '#### `disable_slicing`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L173)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L173)'
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disable sliced VAE decoding. If `enable_slicing` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果之前启用了`enable_slicing`，则此方法将返回到一步计算解码。
- en: '#### `disable_tiling`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L188)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L188)'
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable tiled VAE decoding. If `enable_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺VAE解码。如果之前启用了`enable_tiling`，则此方法将返回到一步计算解码。
- en: '#### `enable_slicing`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L166)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L166)'
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。当启用此选项时，VAE将将输入张量分割成片段以在几个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `enable_tiling`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L180)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L180)'
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺VAE解码。当启用此选项时，VAE将将输入张量分割成瓦片，以便在几个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `forward`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L320)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L320)'
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor`) — Input sample.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（`torch.FloatTensor`）— 输入样本。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `DecoderOutput` instead of a plain tuple.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`DecoderOutput`而不是普通元组。'
- en: '#### `scale_latents`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `scale_latents`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L158)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L158)'
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: raw latents -> [0, 1]
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 原始潜变量 -> [0, 1]
- en: '#### `unscale_latents`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unscale_latents`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L162)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L162)'
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[0, 1] -> raw latents'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[0, 1] -> 原始潜变量'
- en: AutoencoderTinyOutput
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoencoderTinyOutput
- en: '### `class diffusers.models.autoencoders.autoencoder_tiny.AutoencoderTinyOutput`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.autoencoders.autoencoder_tiny.AutoencoderTinyOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L28)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L28)'
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`latents` (`torch.Tensor`) — Encoded outputs of the `Encoder`.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents`（`torch.Tensor`）— 编码器的编码输出。'
- en: Output of AutoencoderTiny encoding method.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: AutoencoderTiny编码方法的输出。
