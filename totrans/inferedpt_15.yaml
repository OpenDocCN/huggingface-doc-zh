- en: Advanced Setup (Instance Types, Auto Scaling, Versioning)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级设置（实例类型、自动缩放、版本控制）
- en: 'Original text: [https://huggingface.co/docs/inference-endpoints/guides/advanced](https://huggingface.co/docs/inference-endpoints/guides/advanced)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/inference-endpoints/guides/advanced](https://huggingface.co/docs/inference-endpoints/guides/advanced)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how fast and easy it is to deploy an Endpoint in [Create your first
    Endpoint](/docs/inference-endpoints/guides/create_endpoint), but that’s not all
    you can manage. During the creation process and after selecting your Cloud Provider
    and Region, click on the [Advanced configuration] button to reveal further configuration
    options for your Endpoint.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到在[创建您的第一个端点](/docs/inference-endpoints/guides/create_endpoint)中部署端点是多么快速简便，但这并不是您可以管理的全部。在创建过程中并在选择云提供商和区域后，单击[高级配置]按钮以显示有关端点的进一步配置选项。
- en: '**Instance type**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**实例类型**'
- en: 🤗 Inference Endpoints offers a selection of curated CPU and GPU instances.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 推理端点提供了一系列经过筛选的CPU和GPU实例。
- en: '*Note: Your Hugging Face account comes with a capacity quota for CPU and GPU
    instances. To increase your quota or request new instance types, please check
    with us.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：您的Hugging Face帐户配备了用于CPU和GPU实例的容量配额。要增加配额或请求新的实例类型，请与我们联系。*'
- en: '*Default: CPU-medium*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*默认：CPU-中等*'
- en: '![copy curl](../Images/698d77f5e435ec43634b873963aae15b.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![复制curl](../Images/698d77f5e435ec43634b873963aae15b.png)'
- en: '**Replica autoscaling**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**副本自动缩放**'
- en: Set the range (minimum (>=1) and maximum ) of replicas you want your Endpoint
    to automatically scale within based on utilization.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 设置您希望您的端点根据利用率自动缩放的副本范围（最小（>=1）和最大）。
- en: '*Default: min 1; max 2*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*默认：最小1；最大2*'
- en: '**Task**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**任务**'
- en: Select a [supported Machine Learning Task](/docs/inference-endpoints/supported_tasks),
    or set to [Custom](/docs/inference-endpoints/guides/custom_handler). [Custom](/docs/inference-endpoints/guides/custom_handler)
    can/should be used when you are not using a Transformers-based model or when you
    want to customize the inference pipeline, see [Create your own Inference handler](/docs/inference-endpoints/guides/custom_handler).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个[支持的机器学习任务](/docs/inference-endpoints/supported_tasks)，或设置为[自定义](/docs/inference-endpoints/guides/custom_handler)。当您不使用基于Transformers的模型或想要自定义推理流程时，应该使用[自定义](/docs/inference-endpoints/guides/custom_handler)，请参阅[创建自己的推理处理程序](/docs/inference-endpoints/guides/custom_handler)。
- en: '*Default: derived from the model repository.*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*默认：派生自模型存储库。*'
- en: '**Framework**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**框架**'
- en: For Transformers models, if both PyTorch and TensorFlow weights are both available,
    you can select which model weights to use. This will help reduce the image artifact
    size and accelerate startups/scaling of your endpoints.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Transformers模型，如果PyTorch和TensorFlow权重都可用，您可以选择使用哪个模型权重。这将有助于减少图像伪影大小，并加快启动/扩展您的端点。
- en: '*Default: PyTorch if available.*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*默认：如果可用，则为PyTorch。*'
- en: '**Revision**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**修订**'
- en: Create your Endpoint targeting a specific revision commit for its source Hugging
    Face Model Repository. This allows you to version your endpoint and make sure
    you are always using the same weights even if you are updating the Model Repository.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的端点创建一个针对其源Hugging Face模型存储库的特定修订提交。这允许您对端点进行版本控制，并确保即使更新模型存储库，您始终使用相同的权重。
- en: '*Default: The most recent commit.*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*默认：最近的提交。*'
- en: '**Image**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**图像**'
- en: Allows you to provide a custom container image you want to deploy into an Endpoint.
    Those can be public images, e.g *tensorflow/serving:2.7.3,* or private Images
    hosted on [Docker hub](https://hub.docker.com/), [AWS ECR](https://aws.amazon.com/ecr/?nc1=h_ls),
    [Azure ACR](https://azure.microsoft.com/de-de/services/container-registry/), or
    [Google GCR](https://cloud.google.com/container-registry?hl=de).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 允许您提供要部署到端点的自定义容器映像。这些可以是公共映像，例如*tensorflow/serving:2.7.3*，或托管在[Docker hub](https://hub.docker.com/)、[AWS
    ECR](https://aws.amazon.com/ecr/?nc1=h_ls)、[Azure ACR](https://azure.microsoft.com/de-de/services/container-registry/)或[Google
    GCR](https://cloud.google.com/container-registry?hl=de)上的私有映像。
- en: More on how to [“Use your own custom container”](/docs/inference-endpoints/guides/custom_handler)
    below.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何在下面[“使用您自己的自定义容器”](/docs/inference-endpoints/guides/custom_handler)。
