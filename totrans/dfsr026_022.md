# å°†æ–‡ä»¶æ¨é€åˆ°Hub

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/push_to_hub](https://huggingface.co/docs/diffusers/using-diffusers/push_to_hub)

ğŸ¤— Diffusersä¸ºæ‚¨æä¾›äº†ä¸€ä¸ª[PushToHubMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin)ï¼Œç”¨äºå°†æ‚¨çš„æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–ç®¡é“ä¸Šä¼ åˆ°Hubã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ–¹æ³•æ¥å­˜å‚¨æ‚¨çš„æ–‡ä»¶åœ¨Hubä¸Šï¼Œå¹¶ä¸”è¿˜å…è®¸æ‚¨ä¸ä»–äººåˆ†äº«æ‚¨çš„å·¥ä½œã€‚åœ¨å¹•åï¼Œ[PushToHubMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin)ï¼š

1.  åœ¨Hubä¸Šåˆ›å»ºä¸€ä¸ªå­˜å‚¨åº“

1.  ä¿å­˜æ‚¨çš„æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–ç®¡é“æ–‡ä»¶ï¼Œä»¥ä¾¿ä»¥åé‡æ–°åŠ è½½

1.  å°†åŒ…å«è¿™äº›æ–‡ä»¶çš„uploadsæ–‡ä»¶å¤¹æ¨é€åˆ°Hub

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨[PushToHubMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin)å°†æ‚¨çš„æ–‡ä»¶ä¸Šä¼ åˆ°Hubã€‚

æ‚¨éœ€è¦é¦–å…ˆä½¿ç”¨æ‚¨çš„è®¿é—®[ä»¤ç‰Œ](https://huggingface.co/settings/tokens)ç™»å½•åˆ°æ‚¨çš„Hubå¸æˆ·ï¼š

```py
from huggingface_hub import notebook_login

notebook_login()
```

## æ¨¡å‹

è¦å°†æ¨¡å‹æ¨é€åˆ°Hubï¼Œè¯·è°ƒç”¨[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å¹¶æŒ‡å®šè¦å­˜å‚¨åœ¨Hubä¸Šçš„æ¨¡å‹çš„å­˜å‚¨åº“IDï¼š

```py
from diffusers import ControlNetModel

controlnet = ControlNetModel(
    block_out_channels=(32, 64),
    layers_per_block=2,
    in_channels=4,
    down_block_types=("DownBlock2D", "CrossAttnDownBlock2D"),
    cross_attention_dim=32,
    conditioning_embedding_out_channels=(16, 32),
)
controlnet.push_to_hub("my-controlnet-model")
```

å¯¹äºæ¨¡å‹ï¼Œæ‚¨è¿˜å¯ä»¥æŒ‡å®šè¦æ¨é€åˆ°Hubçš„æƒé‡çš„[*å˜ä½“*]ï¼ˆloading#checkpoint-variantsï¼‰ã€‚ä¾‹å¦‚ï¼Œè¦æ¨é€`fp16`æƒé‡ï¼š

```py
controlnet.push_to_hub("my-controlnet-model", variant="fp16")
```

[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å‡½æ•°ä¿å­˜æ¨¡å‹çš„`config.json`æ–‡ä»¶ï¼Œæƒé‡ä¼šè‡ªåŠ¨ä¿å­˜åœ¨`safetensors`æ ¼å¼ä¸­ã€‚

ç°åœ¨æ‚¨å¯ä»¥ä»Hubä¸Šçš„å­˜å‚¨åº“é‡æ–°åŠ è½½æ¨¡å‹ï¼š

```py
model = ControlNetModel.from_pretrained("your-namespace/my-controlnet-model")
```

## è°ƒåº¦å™¨

è¦å°†è°ƒåº¦å™¨æ¨é€åˆ°Hubï¼Œè¯·è°ƒç”¨[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å¹¶æŒ‡å®šè¦å­˜å‚¨åœ¨Hubä¸Šçš„è°ƒåº¦å™¨çš„å­˜å‚¨åº“IDï¼š

```py
from diffusers import DDIMScheduler

scheduler = DDIMScheduler(
    beta_start=0.00085,
    beta_end=0.012,
    beta_schedule="scaled_linear",
    clip_sample=False,
    set_alpha_to_one=False,
)
scheduler.push_to_hub("my-controlnet-scheduler")
```

[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å‡½æ•°å°†è°ƒåº¦å™¨çš„`scheduler_config.json`æ–‡ä»¶ä¿å­˜åˆ°æŒ‡å®šçš„å­˜å‚¨åº“ä¸­ã€‚

ç°åœ¨æ‚¨å¯ä»¥ä»Hubä¸Šçš„å­˜å‚¨åº“é‡æ–°åŠ è½½è°ƒåº¦å™¨ï¼š

```py
scheduler = DDIMScheduler.from_pretrained("your-namepsace/my-controlnet-scheduler")
```

## ç®¡é“

æ‚¨è¿˜å¯ä»¥å°†æ•´ä¸ªç®¡é“åŠå…¶æ‰€æœ‰ç»„ä»¶æ¨é€åˆ°Hubã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨æ‚¨æƒ³è¦çš„å‚æ•°åˆå§‹åŒ–[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)çš„ç»„ä»¶ï¼š

```py
from diffusers import (
    UNet2DConditionModel,
    AutoencoderKL,
    DDIMScheduler,
    StableDiffusionPipeline,
)
from transformers import CLIPTextModel, CLIPTextConfig, CLIPTokenizer

unet = UNet2DConditionModel(
    block_out_channels=(32, 64),
    layers_per_block=2,
    sample_size=32,
    in_channels=4,
    out_channels=4,
    down_block_types=("DownBlock2D", "CrossAttnDownBlock2D"),
    up_block_types=("CrossAttnUpBlock2D", "UpBlock2D"),
    cross_attention_dim=32,
)

scheduler = DDIMScheduler(
    beta_start=0.00085,
    beta_end=0.012,
    beta_schedule="scaled_linear",
    clip_sample=False,
    set_alpha_to_one=False,
)

vae = AutoencoderKL(
    block_out_channels=[32, 64],
    in_channels=3,
    out_channels=3,
    down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D"],
    up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D"],
    latent_channels=4,
)

text_encoder_config = CLIPTextConfig(
    bos_token_id=0,
    eos_token_id=2,
    hidden_size=32,
    intermediate_size=37,
    layer_norm_eps=1e-05,
    num_attention_heads=4,
    num_hidden_layers=5,
    pad_token_id=1,
    vocab_size=1000,
)
text_encoder = CLIPTextModel(text_encoder_config)
tokenizer = CLIPTokenizer.from_pretrained("hf-internal-testing/tiny-random-clip")
```

å°†æ‰€æœ‰ç»„ä»¶ä¼ é€’ç»™[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)ï¼Œå¹¶è°ƒç”¨[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å°†ç®¡é“æ¨é€åˆ°Hubï¼š

```py
components = {
    "unet": unet,
    "scheduler": scheduler,
    "vae": vae,
    "text_encoder": text_encoder,
    "tokenizer": tokenizer,
    "safety_checker": None,
    "feature_extractor": None,
}

pipeline = StableDiffusionPipeline(**components)
pipeline.push_to_hub("my-pipeline")
```

[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å‡½æ•°å°†æ¯ä¸ªç»„ä»¶ä¿å­˜åˆ°å­˜å‚¨åº“çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚ç°åœ¨æ‚¨å¯ä»¥ä»Hubä¸Šçš„å­˜å‚¨åº“é‡æ–°åŠ è½½ç®¡é“ï¼š

```py
pipeline = StableDiffusionPipeline.from_pretrained("your-namespace/my-pipeline")
```

## éšç§

åœ¨[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)å‡½æ•°ä¸­è®¾ç½®`private=True`ï¼Œä»¥ä¿æŒæ‚¨çš„æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–ç®¡é“æ–‡ä»¶ç§æœ‰ï¼š

```py
controlnet.push_to_hub("my-controlnet-model-private", private=True)
```

ç§æœ‰å­˜å‚¨åº“åªå¯¹æ‚¨å¯è§ï¼Œå…¶ä»–ç”¨æˆ·æ— æ³•å…‹éš†å­˜å‚¨åº“ï¼Œæ‚¨çš„å­˜å‚¨åº“ä¹Ÿä¸ä¼šå‡ºç°åœ¨æœç´¢ç»“æœä¸­ã€‚å³ä½¿ç”¨æˆ·æ‹¥æœ‰æ‚¨ç§æœ‰å­˜å‚¨åº“çš„URLï¼Œä»–ä»¬ä¹Ÿä¼šæ”¶åˆ°`404 - æŠ±æ­‰ï¼Œæˆ‘ä»¬æ‰¾ä¸åˆ°æ‚¨è¦æŸ¥æ‰¾çš„é¡µé¢`ã€‚æ‚¨å¿…é¡»[ç™»å½•](https://huggingface.co/docs/huggingface_hub/quick-start#login)æ‰èƒ½ä»ç§æœ‰å­˜å‚¨åº“åŠ è½½æ¨¡å‹ã€‚
