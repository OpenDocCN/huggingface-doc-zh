# æ½œåœ¨ä¸€è‡´æ€§è’¸é¦

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/lcm_distill](https://huggingface.co/docs/diffusers/training/lcm_distill)

[æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ï¼ˆLCMsï¼‰](https://hf.co/papers/2310.04378)èƒ½å¤Ÿåœ¨å‡ ä¸ªæ­¥éª¤å†…ç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œè¿™æ˜¯ä¸€ä¸ªé‡å¤§è¿›æ­¥ï¼Œå› ä¸ºè®¸å¤šæµç¨‹è‡³å°‘éœ€è¦25æ­¥ä»¥ä¸Šã€‚LCMsæ˜¯é€šè¿‡å°†æ½œåœ¨ä¸€è‡´æ€§è’¸é¦æ–¹æ³•åº”ç”¨äºä»»ä½•ç¨³å®šæ‰©æ•£æ¨¡å‹è€Œäº§ç”Ÿçš„ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†*å•é˜¶æ®µå¼•å¯¼è’¸é¦*åº”ç”¨äºæ½œåœ¨ç©ºé—´ï¼Œå¹¶ç»“åˆ*è·³æ­¥*æ–¹æ³•æ¥ä¸€è‡´åœ°è·³è¿‡æ—¶é—´æ­¥éª¤ä»¥åŠ é€Ÿè’¸é¦è¿‡ç¨‹ï¼ˆæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è®ºæ–‡çš„ç¬¬4.1ã€4.2å’Œ4.3èŠ‚ï¼‰ã€‚

å¦‚æœæ‚¨åœ¨å…·æœ‰æœ‰é™vRAMçš„GPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¯·å°è¯•å¯ç”¨`gradient_checkpointing`ã€`gradient_accumulation_steps`å’Œ`mixed_precision`ä»¥å‡å°‘å†…å­˜ä½¿ç”¨é‡å¹¶åŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡å¯ç”¨[xFormers](../optimization/xformers)å’Œ[bitsandbytes'](https://github.com/TimDettmers/bitsandbytes) 8ä½ä¼˜åŒ–å™¨çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æ¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜ä½¿ç”¨ã€‚

æœ¬æŒ‡å—å°†æ¢è®¨[train_lcm_distill_sd_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)è„šæœ¬ï¼Œå¸®åŠ©æ‚¨æ›´ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºæ‚¨è‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»æºä»£ç å®‰è£…åº“ï¼š

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

ç„¶åå¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ‚¨æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

```py
cd examples/consistency_distillation
pip install -r requirements.txt
```

ğŸ¤—åŠ é€Ÿæ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ªGPU/TPUä¸Šæˆ–ä½¿ç”¨æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒçš„åº“ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤—åŠ é€Ÿ[å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šã€‚

åˆå§‹åŒ–ğŸ¤—åŠ é€Ÿç¯å¢ƒï¼ˆå°è¯•å¯ç”¨`torch.compile`ä»¥æ˜¾è‘—åŠ å¿«è®­ç»ƒï¼‰ï¼š

```py
accelerate config
```

è®¾ç½®é»˜è®¤çš„ğŸ¤—åŠ é€Ÿç¯å¢ƒï¼Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š

```py
accelerate config default
```

æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼shellï¼Œæ¯”å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚

## è„šæœ¬å‚æ•°

ä»¥ä¸‹éƒ¨åˆ†çªå‡ºæ˜¾ç¤ºäº†è®­ç»ƒè„šæœ¬çš„ä¸€äº›é‡è¦éƒ¨åˆ†ï¼Œä»¥å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)ï¼Œå¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ã€‚

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°ï¼Œå¸®åŠ©æ‚¨å®šåˆ¶æ‚¨çš„è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°å‡åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L419)å‡½æ•°ä¸­æ‰¾åˆ°ã€‚è¯¥å‡½æ•°ä¸ºæ¯ä¸ªå‚æ•°æä¾›äº†é»˜è®¤å€¼ï¼Œå¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œä¸ºäº†åŠ å¿«ä½¿ç”¨fp16æ ¼å¼çš„æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒï¼Œå°†`--mixed_precision`å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```py
accelerate launch train_lcm_distill_sd_wds.py \
  --mixed_precision="fp16"
```

å¤§å¤šæ•°å‚æ•°ä¸[æ–‡æœ¬åˆ°å›¾åƒ](text2image#script-parameters)è®­ç»ƒæŒ‡å—ä¸­çš„å‚æ•°ç›¸åŒï¼Œå› æ­¤æ‚¨å°†ä¸“æ³¨äºæœ¬æŒ‡å—ä¸­ä¸æ½œåœ¨ä¸€è‡´æ€§è’¸é¦ç›¸å…³çš„å‚æ•°ã€‚

+   `--pretrained_teacher_model`ï¼šé¢„è®­ç»ƒæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„è·¯å¾„ï¼Œç”¨ä½œæ•™å¸ˆæ¨¡å‹

+   `--pretrained_vae_model_name_or_path`: é¢„è®­ç»ƒVAEçš„è·¯å¾„ï¼›SDXL VAEå·²çŸ¥å­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œå› æ­¤æ­¤å‚æ•°å…è®¸æ‚¨æŒ‡å®šå¦ä¸€ä¸ªVAEï¼ˆæ¯”å¦‚è¿™ä¸ª[VAE]((https://huggingface.co/madebyollin/sdxl-vae-fp16-fix))ï¼Œç”±madebyollinåˆ¶ä½œï¼Œå¯ä»¥åœ¨fp16ä¸­è¿è¡Œï¼‰

+   `--w_min`å’Œ`--w_max`ï¼šæŒ‡å¯¼å°ºåº¦é‡‡æ ·çš„æœ€å°å’Œæœ€å¤§å€¼

+   `--num_ddim_timesteps`: DDIMé‡‡æ ·çš„æ—¶é—´æ­¥æ•°

+   `--loss_type`ï¼šç”¨äºè®¡ç®—æ½œåœ¨ä¸€è‡´æ€§è’¸é¦çš„æŸå¤±ç±»å‹ï¼ˆL2æˆ–Huberï¼‰ï¼›é€šå¸¸æ›´å–œæ¬¢HuberæŸå¤±ï¼Œå› ä¸ºå®ƒå¯¹å¼‚å¸¸å€¼æ›´åŠ ç¨³å¥

+   `--huber_c`ï¼šHuberæŸå¤±å‚æ•°

## è®­ç»ƒè„šæœ¬

è®­ç»ƒè„šæœ¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ•°æ®é›†ç±» - [`Text2ImageDataset`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L141) - ç”¨äºé¢„å¤„ç†å›¾åƒå¹¶åˆ›å»ºè®­ç»ƒæ•°æ®é›†ã€‚

```py
def transform(example):
    image = example["image"]
    image = TF.resize(image, resolution, interpolation=transforms.InterpolationMode.BILINEAR)

    c_top, c_left, _, _ = transforms.RandomCrop.get_params(image, output_size=(resolution, resolution))
    image = TF.crop(image, c_top, c_left, resolution, resolution)
    image = TF.to_tensor(image)
    image = TF.normalize(image, [0.5], [0.5])

    example["image"] = image
    return example
```

ä¸ºäº†æé«˜åœ¨äº‘ä¸­è¯»å–å’Œå†™å…¥å¤§å‹æ•°æ®é›†çš„æ€§èƒ½ï¼Œæ­¤è„šæœ¬ä½¿ç”¨[WebDataset](https://github.com/webdataset/webdataset)æ ¼å¼åˆ›å»ºä¸€ä¸ªé¢„å¤„ç†ç®¡é“ï¼Œåº”ç”¨å˜æ¢å¹¶åˆ›å»ºä¸€ä¸ªæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨ç”¨äºè®­ç»ƒã€‚å›¾åƒè¢«å¤„ç†å¹¶é¦ˆé€åˆ°è®­ç»ƒå¾ªç¯ä¸­ï¼Œè€Œæ— éœ€å…ˆä¸‹è½½å®Œæ•´æ•°æ®é›†ã€‚

```py
processing_pipeline = [
    wds.decode("pil", handler=wds.ignore_and_continue),
    wds.rename(image="jpg;png;jpeg;webp", text="text;txt;caption", handler=wds.warn_and_continue),
    wds.map(filter_keys({"image", "text"})),
    wds.map(transform),
    wds.to_tuple("image", "text"),
]
```

åœ¨[`main()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L768)å‡½æ•°ä¸­ï¼ŒåŠ è½½äº†æ‰€æœ‰å¿…è¦çš„ç»„ä»¶ï¼Œå¦‚å™ªå£°è°ƒåº¦ç¨‹åºã€æ ‡è®°å™¨ã€æ–‡æœ¬ç¼–ç å™¨å’ŒVAEã€‚æ•™å¸ˆUNetä¹Ÿåœ¨è¿™é‡ŒåŠ è½½ï¼Œç„¶åæ‚¨å¯ä»¥ä»æ•™å¸ˆUNetåˆ›å»ºä¸€ä¸ªå­¦ç”ŸUNetã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼˜åŒ–å™¨ä¼šæ›´æ–°å­¦ç”ŸUNetã€‚

```py
teacher_unet = UNet2DConditionModel.from_pretrained(
    args.pretrained_teacher_model, subfolder="unet", revision=args.teacher_revision
)

unet = UNet2DConditionModel(**teacher_unet.config)
unet.load_state_dict(teacher_unet.state_dict(), strict=False)
unet.train()
```

ç°åœ¨æ‚¨å¯ä»¥åˆ›å»º[ä¼˜åŒ–å™¨](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L979)æ¥æ›´æ–°UNetå‚æ•°ï¼š

```py
optimizer = optimizer_class(
    unet.parameters(),
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```

åˆ›å»º[æ•°æ®é›†](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L994)ï¼š

```py
dataset = Text2ImageDataset(
    train_shards_path_or_url=args.train_shards_path_or_url,
    num_train_examples=args.max_train_samples,
    per_gpu_batch_size=args.train_batch_size,
    global_batch_size=args.train_batch_size * accelerator.num_processes,
    num_workers=args.dataloader_num_workers,
    resolution=args.resolution,
    shuffle_buffer_size=1000,
    pin_memory=True,
    persistent_workers=True,
)
train_dataloader = dataset.train_dataloader
```

æ¥ä¸‹æ¥ï¼Œæ‚¨å¯ä»¥è®¾ç½®[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1049)å¹¶å®ç°æ½œåœ¨ä¸€è‡´æ€§è’¸é¦æ–¹æ³•ï¼ˆæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è®ºæ–‡ä¸­çš„ç®—æ³•1ï¼‰ã€‚è„šæœ¬çš„è¿™ä¸€éƒ¨åˆ†è´Ÿè´£å‘æ½œåœ¨å˜é‡æ·»åŠ å™ªå£°ã€é‡‡æ ·å’Œåˆ›å»ºæŒ‡å¯¼å°ºåº¦åµŒå…¥ï¼Œå¹¶ä»å™ªå£°ä¸­é¢„æµ‹åŸå§‹å›¾åƒã€‚

```py
pred_x_0 = predicted_origin(
    noise_pred,
    start_timesteps,
    noisy_model_input,
    noise_scheduler.config.prediction_type,
    alpha_schedule,
    sigma_schedule,
)

model_pred = c_skip_start * noisy_model_input + c_out_start * pred_x_0
```

æ¥ä¸‹æ¥ï¼Œè·å–[æ•™å¸ˆæ¨¡å‹é¢„æµ‹](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1172)å’Œ[LCMé¢„æµ‹](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1209)ï¼Œè®¡ç®—æŸå¤±ï¼Œç„¶åå°†å…¶åå‘ä¼ æ’­åˆ°LCMã€‚

```py
if args.loss_type == "l2":
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
elif args.loss_type == "huber":
    loss = torch.mean(
        torch.sqrt((model_pred.float() - target.float()) ** 2 + args.huber_c**2) - args.huber_c
    )
```

å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[ç†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨æ•™ç¨‹](../using-diffusers/write_own_pipeline)ï¼Œè¯¥æ•™ç¨‹è§£æäº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## å¯åŠ¨è„šæœ¬

ç°åœ¨æ‚¨å·²ç»å‡†å¤‡å¥½å¯åŠ¨è®­ç»ƒè„šæœ¬å¹¶å¼€å§‹è’¸é¦ï¼

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨`--train_shards_path_or_url`æ¥æŒ‡å®šå­˜å‚¨åœ¨Hubä¸Šçš„[Conceptual Captions 12M](https://github.com/google-research-datasets/conceptual-12m)æ•°æ®é›†çš„è·¯å¾„ã€‚å°†`MODEL_DIR`ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºæ•™å¸ˆæ¨¡å‹çš„åç§°ï¼Œå°†`OUTPUT_DIR`è®¾ç½®ä¸ºæ‚¨æƒ³è¦ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚

```py
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path/to/saved/model"

accelerate launch train_lcm_distill_sd_wds.py \
    --pretrained_teacher_model=$MODEL_DIR \
    --output_dir=$OUTPUT_DIR \
    --mixed_precision=fp16 \
    --resolution=512 \
    --learning_rate=1e-6 --loss_type="huber" --ema_decay=0.95 --adam_weight_decay=0.0 \
    --max_train_steps=1000 \
    --max_train_samples=4000000 \
    --dataloader_num_workers=8 \
    --train_shards_path_or_url="pipe:curl -L -s https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset/resolve/main/data/{00000..01099}.tar?download=true" \
    --validation_steps=200 \
    --checkpointing_steps=200 --checkpoints_total_limit=10 \
    --train_batch_size=12 \
    --gradient_checkpointing --enable_xformers_memory_efficient_attention \
    --gradient_accumulation_steps=1 \
    --use_8bit_adam \
    --resume_from_checkpoint=latest \
    --report_to=wandb \
    --seed=453645634 \
    --push_to_hub
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°çš„LCMè¿›è¡Œæ¨æ–­ã€‚

```py
from diffusers import UNet2DConditionModel, DiffusionPipeline, LCMScheduler
import torch

unet = UNet2DConditionModel.from_pretrained("your-username/your-model", torch_dtype=torch.float16, variant="fp16")
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", unet=unet, torch_dtype=torch.float16, variant="fp16")

pipeline.scheduler = LCMScheduler.from_config(pipe.scheduler.config)
pipeline.to("cuda")

prompt = "sushi rolls in the form of panda heads, sushi platter"

image = pipeline(prompt, num_inference_steps=4, guidance_scale=1.0).images[0]
```

## LoRA

LoRAæ˜¯ä¸€ç§æ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°æ•°é‡çš„è®­ç»ƒæŠ€æœ¯ã€‚å› æ­¤ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå­˜å‚¨ç»“æœæƒé‡æ›´å®¹æ˜“ï¼Œå› ä¸ºå®ƒä»¬è¦å°å¾—å¤šï¼ˆ~100MBï¼‰ã€‚ä½¿ç”¨[train_lcm_distill_lora_sd_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sd_wds.py)æˆ–[train_lcm_distill_lora_sdxl.wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sdxl_wds.py)è„šæœ¬æ¥è¿›è¡ŒLoRAè®­ç»ƒã€‚

æœ‰å…³LoRAè®­ç»ƒè„šæœ¬çš„è¯¦ç»†è®¨è®ºï¼Œè¯·å‚é˜…[LoRAè®­ç»ƒ](lora)æŒ‡å—ã€‚

## ç¨³å®šæ‰©æ•£XL

ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¹¶åœ¨å…¶æ¶æ„ä¸­æ·»åŠ äº†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚ä½¿ç”¨[train_lcm_distill_sdxl_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sdxl_wds.py)è„šæœ¬æ¥è®­ç»ƒä¸€ä¸ªå¸¦æœ‰LoRAçš„SDXLæ¨¡å‹ã€‚

æœ‰å…³SDXLè®­ç»ƒè„šæœ¬çš„è¯¦ç»†è®¨è®ºï¼Œè¯·å‚é˜…[SDXLè®­ç»ƒ](sdxl)æŒ‡å—ã€‚

## ä¸‹ä¸€æ­¥

æ­å–œæ‚¨ç²¾ç‚¼LCMæ¨¡å‹ï¼è¦äº†è§£æ›´å¤šå…³äºLCMçš„ä¿¡æ¯ï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š

+   å­¦ä¹ å¦‚ä½•ä½¿ç”¨[LCMsè¿›è¡Œæ¨ç†](../using-diffusers/lcm)ç”¨äºæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒä»¥åŠå¸¦æœ‰LoRAæ£€æŸ¥ç‚¹ã€‚

+   é˜…è¯»[SDXLåœ¨4ä¸ªæ­¥éª¤ä¸­ä½¿ç”¨æ½œåœ¨ä¸€è‡´æ€§LoRAs](https://huggingface.co/blog/lcm_lora)åšå®¢æ–‡ç« ï¼Œäº†è§£æ›´å¤šå…³äºSDXL LCM-LoRAçš„ä¿¡æ¯ï¼Œç”¨äºè¶…å¿«æ¨ç†ã€è´¨é‡æ¯”è¾ƒã€åŸºå‡†æµ‹è¯•ç­‰ã€‚
