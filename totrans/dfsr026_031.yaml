- en: Textual inversion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本反演
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/textual_inversion_inference](https://huggingface.co/docs/diffusers/using-diffusers/textual_inversion_inference)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/textual_inversion_inference](https://huggingface.co/docs/diffusers/using-diffusers/textual_inversion_inference)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    supports textual inversion, a technique that enables a model like Stable Diffusion
    to learn a new concept from just a few sample images. This gives you more control
    over the generated images and allows you to tailor the model towards specific
    concepts. You can get started quickly with a collection of community created concepts
    in the [Stable Diffusion Conceptualizer](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)支持文本反演，这是一种使稳定扩散等模型能够仅从少量示例图像中学习新概念的技术。这使您对生成的图像有更多控制，并允许您将模型定制为特定概念。您可以通过[Stable
    Diffusion Conceptualizer](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer)中的社区创建的概念集快速入门。'
- en: This guide will show you how to run inference with textual inversion using a
    pre-learned concept from the Stable Diffusion Conceptualizer. If you’re interested
    in teaching a model new concepts with textual inversion, take a look at the [Textual
    Inversion](../training/text_inversion) training guide.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将向您展示如何使用稳定扩散概念化器中的预先学习概念来运行文本反演推断。如果您有兴趣使用文本反演教授模型新概念，请查看[文本反演](../training/text_inversion)培训指南。
- en: 'Import the necessary libraries:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 导入必要的库：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Stable Diffusion 1 and 2
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散 1 和 2
- en: 'Pick a Stable Diffusion checkpoint and a pre-learned concept from the [Stable
    Diffusion Conceptualizer](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer):'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个稳定扩散的检查点和一个来自[稳定扩散概念化器](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer)的预先学习的概念：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now you can load a pipeline, and pass the pre-learned concept to it:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以加载一个流水线，并将预先学习的概念传递给它：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a prompt with the pre-learned concept by using the special placeholder
    token `<cat-toy>`, and choose the number of samples and rows of images you’d like
    to generate:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用特殊的占位符标记`<cat-toy>`创建一个包含预先学习概念的提示，并选择要生成的样本数量和图像行数：
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then run the pipeline (feel free to adjust the parameters like `num_inference_steps`
    and `guidance_scale` to see how they affect image quality), save the generated
    images and visualize them with the helper function you created at the beginning:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行流水线（可以随意调整参数，如`num_inference_steps`和`guidance_scale`，以查看它们如何影响图像质量），保存生成的图像，并使用您在开始时创建的辅助函数进行可视化：
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/71bc10f1a2656599ea557d150439d022.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71bc10f1a2656599ea557d150439d022.png)'
- en: Stable Diffusion XL
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散 XL
- en: Stable Diffusion XL (SDXL) can also use textual inversion vectors for inference.
    In contrast to Stable Diffusion 1 and 2, SDXL has two text encoders so you’ll
    need two textual inversion embeddings - one for each text encoder model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散 XL（SDXL）也可以使用文本反演向量进行推断。与稳定扩散 1 和 2 不同，SDXL 有两个文本编码器，因此您将需要两个文本反演嵌入 - 每个文本编码器模型一个。
- en: 'Let’s download the SDXL textual inversion embeddings and have a closer look
    at it’s structure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们下载 SDXL 文本反演嵌入并更仔细地查看它的结构：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There are two tensors, `"clip_g"` and `"clip_l"`. `"clip_g"` corresponds to
    the bigger text encoder in SDXL and refers to `pipe.text_encoder_2` and `"clip_l"`
    refers to `pipe.text_encoder`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个张量，`"clip_g"`和`"clip_l"`。`"clip_g"`对应于 SDXL 中更大的文本编码器，并指的是`pipe.text_encoder_2`，`"clip_l"`指的是`pipe.text_encoder`。
- en: 'Now you can load each tensor separately by passing them along with the correct
    text encoder and tokenizer to [load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以通过将它们与正确的文本编码器和标记器一起传递给[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)来单独加载每个张量：
- en: '[PRE7]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
