- en: Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/tokenizers/api/models](https://huggingface.co/docs/tokenizers/api/models)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 
    
    
    
    
    
    
    
    
    
    PythonRustNode
  prefs: []
  type: TYPE_NORMAL
- en: BPE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class tokenizers.models.BPE`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`Dict[str, int]`, *optional*) — A dictionnary of string keys and their
    ids `{"am": 0,...}`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merges` (`List[Tuple[str, str]]`, *optional*) — A list of pairs of tokens
    (`Tuple[str, str]`) `[("a", "b"),...]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cache_capacity` (`int`, *optional*) — The number of words that the BPE cache
    can contain. The cache allows to speed-up the process by keeping the result of
    the merge operations for a number of words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropout` (`float`, *optional*) — A float between 0 and 1 that represents the
    BPE dropout to use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unk_token` (`str`, *optional*) — The unknown token to be used by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`continuing_subword_prefix` (`str`, *optional*) — The prefix to attach to subword
    units that don’t represent a beginning of word.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_of_word_suffix` (`str`, *optional*) — The suffix to attach to subword
    units that represent an end of word.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fuse_unk` (`bool`, *optional*) — Whether to fuse any subsequent unknown tokens
    into a single one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`byte_fallback` (`bool`, *optional*) — Whether to use spm byte-fallback trick
    (defaults to False)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implementation of the BPE (Byte-Pair Encoding) algorithm
  prefs: []
  type: TYPE_NORMAL
- en: '#### `from_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merges` (`str`) — The path to a `merges.txt` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[BPE](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.BPE)'
  prefs: []
  type: TYPE_NORMAL
- en: An instance of BPE loaded from these files
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate a BPE model from the given files.
  prefs: []
  type: TYPE_NORMAL
- en: 'This method is roughly equivalent to doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you don’t need to keep the `vocab, merges` values lying around, this method
    is more optimized than manually calling `read_file()` to initialize a [BPE](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.BPE)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `read_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merges` (`str`) — The path to a `merges.txt` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A `Tuple` with the vocab and the merges
  prefs: []
  type: TYPE_NORMAL
- en: The vocabulary and merges loaded into memory
  prefs: []
  type: TYPE_NORMAL
- en: Read a `vocab.json` and a `merges.txt` files
  prefs: []
  type: TYPE_NORMAL
- en: This method provides a way to read and parse the content of these files, returning
    the relevant data structures. If you want to instantiate some BPE models from
    memory, this method gives you the expected input from the standard files.
  prefs: []
  type: TYPE_NORMAL
- en: Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class tokenizers.models.Model`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Base class for all models
  prefs: []
  type: TYPE_NORMAL
- en: The model represents the actual tokenization algorithm. This is the part that
    will contain and manage the learned vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be constructed directly. Please use one of the concrete models.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_trainer`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Trainer`'
  prefs: []
  type: TYPE_NORMAL
- en: The Trainer used to train this model
  prefs: []
  type: TYPE_NORMAL
- en: Get the associated `Trainer`
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve the `Trainer` associated to this [Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `id_to_token`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`id` (`int`) — An ID to convert to a token'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  prefs: []
  type: TYPE_NORMAL
- en: The token associated to the ID
  prefs: []
  type: TYPE_NORMAL
- en: Get the token associated to an ID
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`folder` (`str`) — The path to the target folder in which to save the various
    files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prefix` (`str`, *optional*) — An optional prefix, used to prefix each file
    name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`List[str]`'
  prefs: []
  type: TYPE_NORMAL
- en: The list of saved files
  prefs: []
  type: TYPE_NORMAL
- en: Save the current model
  prefs: []
  type: TYPE_NORMAL
- en: Save the current model in the given folder, using the given prefix for the various
    files that will get created. Any file with the same name that already exists in
    this folder will be overwritten.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `token_to_id`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`token` (`str`) — A token to convert to an ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The ID associated to the token
  prefs: []
  type: TYPE_NORMAL
- en: Get the ID associated to a token
  prefs: []
  type: TYPE_NORMAL
- en: '#### `tokenize`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`sequence` (`str`) — A sequence to tokenize'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A `List` of `Token`
  prefs: []
  type: TYPE_NORMAL
- en: The generated tokens
  prefs: []
  type: TYPE_NORMAL
- en: Tokenize a sequence
  prefs: []
  type: TYPE_NORMAL
- en: Unigram
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class tokenizers.models.Unigram`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`List[Tuple[str, float]]`, *optional*, *optional*) — A list of vocabulary
    items and their relative score [(“am”, -0.2442),…]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implementation of the Unigram algorithm
  prefs: []
  type: TYPE_NORMAL
- en: WordLevel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class tokenizers.models.WordLevel`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`, *optional*) — A dictionnary of string keys and their ids `{"am":
    0,...}`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unk_token` (`str`, *optional*) — The unknown token to be used by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implementation of the WordLevel algorithm
  prefs: []
  type: TYPE_NORMAL
- en: Most simple tokenizer model based on mapping tokens to their corresponding id.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `from_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[WordLevel](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordLevel)'
  prefs: []
  type: TYPE_NORMAL
- en: An instance of WordLevel loaded from file
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate a WordLevel model from the given file
  prefs: []
  type: TYPE_NORMAL
- en: 'This method is roughly equivalent to doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If you don’t need to keep the `vocab` values lying around, this method is more
    optimized than manually calling `read_file()` to initialize a [WordLevel](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordLevel)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `read_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The vocabulary as a `dict`
  prefs: []
  type: TYPE_NORMAL
- en: Read a `vocab.json`
  prefs: []
  type: TYPE_NORMAL
- en: This method provides a way to read and parse the content of a vocabulary file,
    returning the relevant data structures. If you want to instantiate some WordLevel
    models from memory, this method gives you the expected input from the standard
    files.
  prefs: []
  type: TYPE_NORMAL
- en: WordPiece
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class tokenizers.models.WordPiece`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`Dict[str, int]`, *optional*) — A dictionnary of string keys and their
    ids `{"am": 0,...}`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unk_token` (`str`, *optional*) — The unknown token to be used by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_input_chars_per_word` (`int`, *optional*) — The maximum number of characters
    to authorize in a single word.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implementation of the WordPiece algorithm
  prefs: []
  type: TYPE_NORMAL
- en: '#### `from_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`) — The path to a `vocab.txt` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[WordPiece](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordPiece)'
  prefs: []
  type: TYPE_NORMAL
- en: An instance of WordPiece loaded from file
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate a WordPiece model from the given file
  prefs: []
  type: TYPE_NORMAL
- en: 'This method is roughly equivalent to doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If you don’t need to keep the `vocab` values lying around, this method is more
    optimized than manually calling `read_file()` to initialize a [WordPiece](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordPiece)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `read_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab` (`str`) — The path to a `vocab.txt` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The vocabulary as a `dict`
  prefs: []
  type: TYPE_NORMAL
- en: Read a `vocab.txt` file
  prefs: []
  type: TYPE_NORMAL
- en: This method provides a way to read and parse the content of a standard *vocab.txt*
    file as used by the WordPiece Model, returning the relevant data structures. If
    you want to instantiate some WordPiece models from memory, this method gives you
    the expected input from the standard files.
  prefs: []
  type: TYPE_NORMAL
