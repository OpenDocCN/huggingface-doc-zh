- en: EnCodec
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EnCodec
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/encodec](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/encodec)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/encodec](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/encodec)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The EnCodec neural codec model was proposed in [High Fidelity Neural Audio Compression](https://arxiv.org/abs/2210.13438)
    by Alexandre Défossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: EnCodec神经编解码器模型由Alexandre Défossez、Jade Copet、Gabriel Synnaeve和Yossi Adi在[High
    Fidelity Neural Audio Compression](https://arxiv.org/abs/2210.13438)中提出。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging
    neural networks. It consists in a streaming encoder-decoder architecture with
    quantized latent space trained in an end-to-end fashion. We simplify and speed-up
    the training by using a single multiscale spectrogram adversary that efficiently
    reduces artifacts and produce high-quality samples. We introduce a novel loss
    balancer mechanism to stabilize training: the weight of a loss now defines the
    fraction of the overall gradient it should represent, thus decoupling the choice
    of this hyper-parameter from the typical scale of the loss. Finally, we study
    how lightweight Transformer models can be used to further compress the obtained
    representation by up to 40%, while staying faster than real time. We provide a
    detailed description of the key design choices of the proposed model including:
    training objective, architectural changes and a study of various perceptual loss
    functions. We present an extensive subjective evaluation (MUSHRA tests) together
    with an ablation study for a range of bandwidths and audio domains, including
    speech, noisy-reverberant speech, and music. Our approach is superior to the baselines
    methods across all evaluated settings, considering both 24 kHz monophonic and
    48 kHz stereophonic audio.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们引入了一种基于神经网络的最先进的实时、高保真音频编解码器。它由一个流式编码器-解码器架构组成，具有量化的潜在空间，以端到端的方式进行训练。我们通过使用一个多尺度频谱对抗器简化和加速训练，有效减少了伪影并产生高质量样本。我们引入了一种新颖的损失平衡机制来稳定训练：损失的权重现在定义了它应该代表整体梯度的比例，从而将这个超参数的选择与典型损失的规模分离。最后，我们研究了轻量级Transformer模型如何进一步压缩获得的表示，最多可减少40%，同时保持快于实时。我们提供了对所提出模型的关键设计选择的详细描述，包括：训练目标、架构变化以及各种感知损失函数的研究。我们进行了广泛的主观评估（MUSHRA测试），并对一系列带宽和音频领域进行了消融研究，包括语音、嘈杂混响语音和音乐。我们的方法在所有评估设置中优于基线方法，考虑到24
    kHz单声道和48 kHz立体声音频。*'
- en: This model was contributed by [Matthijs](https://huggingface.co/Matthijs), [Patrick
    Von Platen](https://huggingface.co/patrickvonplaten) and [Arthur Zucker](https://huggingface.co/ArthurZ).
    The original code can be found [here](https://github.com/facebookresearch/encodec).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[Matthijs](https://huggingface.co/Matthijs)、[Patrick Von Platen](https://huggingface.co/patrickvonplaten)和[Arthur
    Zucker](https://huggingface.co/ArthurZ)贡献。原始代码可在[此处](https://github.com/facebookresearch/encodec)找到。
- en: Usage example
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法示例
- en: 'Here is a quick example of how to encode and decode an audio using this model:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用该模型对音频进行编码和解码的快速示例：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: EncodecConfig
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EncodecConfig
- en: '### `class transformers.EncodecConfig`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.EncodecConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/configuration_encodec.py#L35)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/configuration_encodec.py#L35)'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`target_bandwidths` (`List[float]`, *optional*, defaults to `[1.5, 3.0, 6.0,
    12.0, 24.0]`) — The range of diffent bandwiths the model can encode audio with.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_bandwidths` (`List[float]`, *optional*, defaults to `[1.5, 3.0, 6.0,
    12.0, 24.0]`) — 模型可以对音频进行编码的不同带宽范围。'
- en: '`sampling_rate` (`int`, *optional*, defaults to 24000) — The sampling rate
    at which the audio waveform should be digitalized expressed in hertz (Hz).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *optional*, defaults to 24000) — 音频波形应数字化的采样率，以赫兹（Hz）表示。'
- en: '`audio_channels` (`int`, *optional*, defaults to 1) — Number of channels in
    the audio data. Either 1 for mono or 2 for stereo.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_channels` (`int`, *optional*, defaults to 1) — 音频数据中的通道数。单声道为1，立体声为2。'
- en: '`normalize` (`bool`, *optional*, defaults to `False`) — Whether the audio shall
    be normalized when passed.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize` (`bool`, *optional*, defaults to `False`) — 传递音频时是否应该进行归一化。'
- en: '`chunk_length_s` (`float`, *optional*) — If defined the audio is pre-processed
    into chunks of lengths `chunk_length_s` and then encoded.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk_length_s` (`float`, *optional*) — 如果定义了，音频将被预处理成长度为`chunk_length_s`的块，然后进行编码。'
- en: '`overlap` (`float`, *optional*) — Defines the overlap between each chunk. It
    is used to compute the `chunk_stride` using the following formulae : `int((1.0
    - self.overlap) * self.chunk_length)`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap` (`float`, *optional*) — 定义每个块之间的重叠。用于计算`chunk_stride`的公式为：`int((1.0
    - self.overlap) * self.chunk_length)`。'
- en: '`hidden_size` (`int`, *optional*, defaults to 128) — Intermediate representation
    dimension.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 128) — 中间表示维度。'
- en: '`num_filters` (`int`, *optional*, defaults to 32) — Number of convolution kernels
    of first `EncodecConv1d` down sampling layer.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_filters` (`int`, *optional*, defaults to 32) — 第一个`EncodecConv1d`下采样层的卷积核数量。'
- en: '`num_residual_layers` (`int`, *optional*, defaults to 1) — Number of residual
    layers.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_residual_layers` (`int`, *optional*, defaults to 1) — 残差层的数量。'
- en: '`upsampling_ratios` (`Sequence[int]` , *optional*, defaults to `[8, 5, 4, 2]`)
    — Kernel size and stride ratios. The encoder uses downsampling ratios instead
    of upsampling ratios, hence it will use the ratios in the reverse order to the
    ones specified here that must match the decoder order.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsampling_ratios` (`Sequence[int]` , *optional*, defaults to `[8, 5, 4, 2]`)
    — 核大小和步幅比例。编码器使用下采样比率而不是上采样比率，因此将使用与此处指定的相反顺序的比率，这些比率必须与解码器顺序匹配。'
- en: '`norm_type` (`str`, *optional*, defaults to `"weight_norm"`) — Normalization
    method. Should be in `["weight_norm", "time_group_norm"]`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`norm_type` (`str`, *optional*, defaults to `"weight_norm"`) — 归一化方法。应为`["weight_norm",
    "time_group_norm"]`之一。'
- en: '`kernel_size` (`int`, *optional*, defaults to 7) — Kernel size for the initial
    convolution.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_size` (`int`, *optional*, defaults to 7) — 初始卷积的核大小。'
- en: '`last_kernel_size` (`int`, *optional*, defaults to 7) — Kernel size for the
    last convolution layer.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_kernel_size` (`int`, *可选*, 默认为7) — 最后一个卷积层的核大小。'
- en: '`residual_kernel_size` (`int`, *optional*, defaults to 3) — Kernel size for
    the residual layers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`residual_kernel_size` (`int`, *可选*, 默认为3) — 残差层的核大小。'
- en: '`dilation_growth_rate` (`int`, *optional*, defaults to 2) — How much to increase
    the dilation with each layer.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dilation_growth_rate` (`int`, *可选*, 默认为2) — 每层增加膨胀的量。'
- en: '`use_causal_conv` (`bool`, *optional*, defaults to `True`) — Whether to use
    fully causal convolution.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_causal_conv` (`bool`, *可选*, 默认为`True`) — 是否使用完全因果卷积。'
- en: '`pad_mode` (`str`, *optional*, defaults to `"reflect"`) — Padding mode for
    the convolutions.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_mode` (`str`, *可选*, 默认为`"reflect"`) — 卷积的填充模式。'
- en: '`compress` (`int`, *optional*, defaults to 2) — Reduced dimensionality in residual
    branches (from Demucs v3).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compress` (`int`, *可选*, 默认为2) — 在残差分支中的降维度（来自Demucs v3）。'
- en: '`num_lstm_layers` (`int`, *optional*, defaults to 2) — Number of LSTM layers
    at the end of the encoder.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_lstm_layers` (`int`, *可选*, 默认为2) — 编码器末端的LSTM层数。'
- en: '`trim_right_ratio` (`float`, *optional*, defaults to 1.0) — Ratio for trimming
    at the right of the transposed convolution under the `use_causal_conv = True`
    setup. If equal to 1.0, it means that all the trimming is done at the right.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trim_right_ratio` (`float`, *可选*, 默认为1.0) — 在`use_causal_conv = True`设置下对转置卷积右侧进行修剪的比例。如果等于1.0，则表示所有修剪都在右侧完成。'
- en: '`codebook_size` (`int`, *optional*, defaults to 1024) — Number of discret codes
    that make up VQVAE.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_size` (`int`, *可选*, 默认为1024) — 组成VQVAE的离散代码的数量。'
- en: '`codebook_dim` (`int`, *optional*) — Dimension of the codebook vectors. If
    not defined, uses `hidden_size`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_dim` (`int`, *可选*) — 代码书向量的维度。如果未定义，则使用`hidden_size`。'
- en: '`use_conv_shortcut` (`bool`, *optional*, defaults to `True`) — Whether to use
    a convolutional layer as the ‘skip’ connection in the `EncodecResnetBlock` block.
    If False, an identity function will be used, giving a generic residual connection.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_conv_shortcut` (`bool`, *可选*, 默认为`True`) — 是否在`EncodecResnetBlock`块中使用卷积层作为“跳过”连接。如果为False，将使用一个恒等函数，提供一个通用的残差连接。'
- en: This is the configuration class to store the configuration of an [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel).
    It is used to instantiate a Encodec model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the [facebook/encodec_24khz](https://huggingface.co/facebook/encodec_24khz)
    architecture.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)配置的配置类。它用于根据指定的参数实例化一个Encodec模型，定义模型架构。使用默认值实例化配置将产生类似于[facebook/encodec_24khz](https://huggingface.co/facebook/encodec_24khz)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: EncodecFeatureExtractor
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EncodecFeatureExtractor
- en: '### `class transformers.EncodecFeatureExtractor`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.EncodecFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/feature_extraction_encodec.py#L29)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/feature_extraction_encodec.py#L29)'
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_size` (`int`, *optional*, defaults to 1) — The feature dimension of
    the extracted features. Use 1 for mono, 2 for stereo.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_size` (`int`, *可选*, 默认为1) — 提取特征的特征维度。对于单声道使用1，立体声使用2。'
- en: '`sampling_rate` (`int`, *optional*, defaults to 24000) — The sampling rate
    at which the audio waveform should be digitalized expressed in hertz (Hz).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *可选*, 默认为24000) — 音频波形应数字化的采样率，以赫兹（Hz）表示。'
- en: '`padding_value` (`float`, *optional*, defaults to 0.0) — The value that is
    used to fill the padding values.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value` (`float`, *可选*, 默认为0.0) — 用于填充值的值。'
- en: '`chunk_length_s` (`float`, *optional*) — If defined the audio is pre-processed
    into chunks of lengths `chunk_length_s` and then encoded.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk_length_s` (`float`, *可选*) — 如果定义了，则音频将被预处理成长度为`chunk_length_s`的块，然后进行编码。'
- en: '`overlap` (`float`, *optional*) — Defines the overlap between each chunk. It
    is used to compute the `chunk_stride` using the following formulae : `int((1.0
    - self.overlap) * self.chunk_length)`.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlap` (`float`, *可选*) — 定义每个块之间的重叠。用于计算`chunk_stride`的公式为：`int((1.0 - self.overlap)
    * self.chunk_length)`。'
- en: Constructs an EnCodec feature extractor.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个EnCodec特征提取器。
- en: This feature extractor inherits from [SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特征提取器继承自[SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)，其中包含大部分主要方法。用户应参考这个超类以获取有关这些方法的更多信息。
- en: Instantiating a feature extractor with the defaults will yield a similar configuration
    to that of the [facebook/encodec_24khz](https://huggingface.co/facebook/encodec_24khz)
    architecture.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认值实例化特征提取器将产生类似于[facebook/encodec_24khz](https://huggingface.co/facebook/encodec_24khz)架构的配置。
- en: '#### `__call__`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/feature_extraction_encodec.py#L84)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/feature_extraction_encodec.py#L84)'
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`raw_audio` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`)
    — The sequence or batch of sequences to be processed. Each sequence can be a numpy
    array, a list of float values, a list of numpy arrays or a list of list of float
    values. The numpy array must be of shape `(num_samples,)` for mono audio (`feature_size
    = 1`), or `(2, num_samples)` for stereo audio (`feature_size = 2`).'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`raw_audio` (`np.ndarray`，`List[float]`，`List[np.ndarray]`，`List[List[float]]`)
    — 要处理的序列或序列批次。每个序列可以是一个numpy数组，一个浮点值列表，一个numpy数组列表或一个浮点值列表的列表。对于单声道音频（`feature_size
    = 1`），numpy数组的形状必须为`(num_samples,)`，对于立体声音频（`feature_size = 2`），形状为`(2, num_samples)`。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `True`) — Select a strategy to pad the returned sequences
    (according to the model’s padding side and padding index) among:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`，`str`或[PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为`True`)
    — 选择一种策略来填充返回的序列（根据模型的填充方向和填充索引）：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest''`：填充到批次中最长的序列（如果只提供单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到指定的最大长度（使用参数`max_length`）或模型的最大可接受输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_pad''`（默认）：无填充（即，可以输出长度不同的序列批次）。'
- en: '`truncation` (`bool`, *optional*, defaults to `False`) — Activates truncation
    to cut input sequences longer than `max_length` to `max_length`.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`，*可选*，默认为`False`) — 激活截断，将长于`max_length`的输入序列截断为`max_length`。'
- en: '`max_length` (`int`, *optional*) — Maximum length of the returned list and
    optionally padding length (see above).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 返回列表的最大长度，可选填充长度（见上文）。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*)
    — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回Numpy `np.ndarray`对象。'
- en: '`sampling_rate` (`int`, *optional*) — The sampling rate at which the `audio`
    input was sampled. It is strongly recommended to pass `sampling_rate` at the forward
    call to prevent silent errors.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`，*可选*) — 对`audio`输入进行采样的采样率。强烈建议在前向调用时传递`sampling_rate`以防止潜在错误。'
- en: Main method to featurize and prepare for the model one or several sequence(s).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个或多个序列进行特征化和准备模型的主要方法。
- en: EncodecModel
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EncodecModel
- en: '### `class transformers.EncodecModel`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.EncodecModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L526)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L526)'
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The EnCodec neural audio codec model. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: EnCodec神经音频编解码器模型。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以了解所有与一般用法和行为相关的事项。
- en: '#### `decode`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L707)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L707)'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audio_codes` (`torch.FloatTensor` of shape `(batch_size, nb_chunks, chunk_length)`,
    *optional*) — Discret code embeddings computed using `model.encode`.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_codes` (`torch.FloatTensor`，形状为`(batch_size, nb_chunks, chunk_length)`，*可选*)
    — 使用`model.encode`计算的离散码嵌入。'
- en: '`audio_scales` (`torch.Tensor` of shape `(batch_size, nb_chunks)`, *optional*)
    — Scaling factor for each `audio_codes` input.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_scales` (`torch.Tensor`，形状为`(batch_size, nb_chunks)`，*可选*) — 每个`audio_codes`输入的缩放因子。'
- en: '`padding_mask` (`torch.Tensor` of shape `(batch_size, channels, sequence_length)`)
    — Padding mask used to pad the `input_values`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_mask` (`torch.Tensor`，形状为`(batch_size, channels, sequence_length)`）
    — 用于填充`input_values`的填充蒙版。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Decodes the given frames into an output audio waveform.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 将给定的帧解码为输出音频波形。
- en: Note that the output might be a bit bigger than the input. In that case, any
    extra steps at the end can be trimmed.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，输出可能比输入大一点。在这种情况下，可以裁剪末尾的任何额外步骤。
- en: '#### `encode`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L579)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L579)'
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_values` (`torch.Tensor` of shape `(batch_size, channels, sequence_length)`)
    — Float values of the input audio waveform.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values` (`torch.Tensor` of shape `(batch_size, channels, sequence_length)`)
    — 输入音频波形的浮点值。'
- en: '`padding_mask` (`torch.Tensor` of shape `(batch_size, channels, sequence_length)`)
    — Padding mask used to pad the `input_values`.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_mask` (`torch.Tensor` of shape `(batch_size, channels, sequence_length)`)
    — 用于填充`input_values`的填充掩码。'
- en: '`bandwidth` (`float`, *optional*) — The target bandwidth. Must be one of `config.target_bandwidths`.
    If `None`, uses the smallest possible bandwidth. bandwidth is represented as a
    thousandth of what it is, e.g. 6kbps bandwidth is represented as bandwidth ==
    6.0'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bandwidth` (`float`, *optional*) — 目标带宽。必须是`config.target_bandwidths`之一。如果为`None`，则使用最小可能的带宽。带宽表示为其千分之一，例如6kbps带宽表示为`bandwidth
    == 6.0`'
- en: Encodes the input audio waveform into discrete codes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入音频波形编码为离散代码。
- en: '#### `forward`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L755)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/encodec/modeling_encodec.py#L755)'
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_values` (`torch.FloatTensor` of shape `(batch_size, channels, sequence_length)`,
    *optional*) — Raw audio input converted to Float and padded to the approriate
    length in order to be encoded using chunks of length self.chunk_length and a stride
    of `config.chunk_stride`.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values` (`torch.FloatTensor` of shape `(batch_size, channels, sequence_length)`,
    *optional*) — 将原始音频输入转换为Float并填充到适当的长度，以便使用长度为self.chunk_length的块和`config.chunk_stride`的步长进行编码。'
- en: '`padding_mask` (`torch.BoolTensor` of shape `(batch_size, channels, sequence_length)`,
    *optional*) — Mask to avoid computing scaling factors on padding token indices
    (can we avoid computing conv on these+). Mask values selected in `[0, 1]`:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_mask` (`torch.BoolTensor` of shape `(batch_size, channels, sequence_length)`,
    *optional*) — 用于避免在填充标记索引上计算缩放因子的掩码（我们可以避免在这些上计算卷积+）。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '`padding_mask` should always be passed, unless the input was truncated or not
    padded. This is because in order to process tensors effectively, the input audio
    should be padded so that `input_length % stride = step` with `step = chunk_length-stride`.
    This ensures that all chunks are of the same shape'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应始终传递`padding_mask`，除非输入被截断或未填充。这是因为为了有效处理张量，输入音频应该被填充，以便`input_length % stride
    = step`，其中`step = chunk_length-stride`。这确保所有块具有相同的形状
- en: '`bandwidth` (`float`, *optional*) — The target bandwidth. Must be one of `config.target_bandwidths`.
    If `None`, uses the smallest possible bandwidth. bandwidth is represented as a
    thousandth of what it is, e.g. 6kbps bandwidth is represented as `bandwidth ==
    6.0`'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bandwidth` (`float`, *optional*) — 目标带宽。必须是`config.target_bandwidths`之一。如果为`None`，则使用最小可能的带宽。带宽表示为其千分之一，例如6kbps带宽表示为`bandwidth
    == 6.0`'
- en: '`audio_codes` (`torch.FloatTensor` of shape `(batch_size, nb_chunks, chunk_length)`,
    *optional*) — Discret code embeddings computed using `model.encode`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_codes` (`torch.FloatTensor` of shape `(batch_size, nb_chunks, chunk_length)`,
    *optional*) — 使用`model.encode`计算的离散代码嵌入。'
- en: '`audio_scales` (`torch.Tensor` of shape `(batch_size, nb_chunks)`, *optional*)
    — Scaling factor for each `audio_codes` input.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_scales` (`torch.Tensor` of shape `(batch_size, nb_chunks)`, *optional*)
    — 每个`audio_codes`输入的缩放因子。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.encodec.modeling_encodec.EncodecOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.encodec.modeling_encodec.EncodecOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.encodec.modeling_encodec.EncodecOutput` or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig))
    and inputs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.encodec.modeling_encodec.EncodecOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含根据配置（[EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)）和输入的各种元素。
- en: '`audio_codes` (`torch.FloatTensor` of shape `(batch_size, nb_chunks, chunk_length)`,
    *optional*) — Discret code embeddings computed using `model.encode`.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_codes` (`torch.FloatTensor` of shape `(batch_size, nb_chunks, chunk_length)`,
    *optional*) — 使用`model.encode`计算的离散代码嵌入。'
- en: '`audio_values` (`torch.FlaotTensor` of shape `(batch_size, sequence_length)`,
    *optional*) Decoded audio values, obtained using the decoder part of Encodec.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_values` (`torch.FlaotTensor` of shape `(batch_size, sequence_length)`,
    *optional*) 解码音频值，使用Encodec的解码器部分获得。'
- en: The [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    forward method, overrides the `__call__` special method.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
