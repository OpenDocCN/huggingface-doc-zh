# é…ç½®

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration)

åŸºç±» [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig) å®ç°äº†ä»æœ¬åœ°æ–‡ä»¶æˆ–ç›®å½•åŠ è½½/ä¿å­˜é…ç½®çš„å¸¸ç”¨æ–¹æ³•ï¼Œæˆ–è€…ä»åº“æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ï¼ˆä» HuggingFace çš„ AWS S3 å­˜å‚¨åº“ä¸‹è½½ï¼‰ã€‚

æ¯ä¸ªæ´¾ç”Ÿçš„é…ç½®ç±»éƒ½å®ç°äº†ç‰¹å®šäºæ¨¡å‹çš„å±æ€§ã€‚æ‰€æœ‰é…ç½®ç±»ä¸­å…±æœ‰çš„å±æ€§æ˜¯ï¼š`hidden_size`ã€`num_attention_heads` å’Œ `num_hidden_layers`ã€‚æ–‡æœ¬æ¨¡å‹è¿›ä¸€æ­¥å®ç°äº†ï¼š`vocab_size`ã€‚

## PretrainedConfig

### `class transformers.PretrainedConfig`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L49)

```py
( **kwargs )
```

å‚æ•°

+   `name_or_path` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `""`) â€” å­˜å‚¨ä¼ é€’ç»™ [PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) æˆ– [TFPreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained) ä½œä¸º `pretrained_model_name_or_path` çš„å­—ç¬¦ä¸²ï¼Œå¦‚æœé…ç½®æ˜¯ä½¿ç”¨è¿™ç§æ–¹æ³•åˆ›å»ºçš„ã€‚

+   `output_hidden_states` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æ‰€æœ‰éšè—çŠ¶æ€ã€‚

+   `output_attentions` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æ‰€æœ‰æ³¨æ„åŠ›ã€‚

+   `return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›ä¸€ä¸ª [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šå…ƒç»„ã€‚

+   `is_encoder_decoder` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ¨¡å‹æ˜¯å¦ç”¨ä½œç¼–ç å™¨/è§£ç å™¨ã€‚

+   `is_decoder` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ¨¡å‹æ˜¯å¦ç”¨ä½œè§£ç å™¨æˆ–ä¸ç”¨ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒç”¨ä½œç¼–ç å™¨ï¼‰ã€‚

+   `cross_attention_hidden_size**` (`bool`, *å¯é€‰*) â€” å¦‚æœæ¨¡å‹ç”¨ä½œç¼–ç å™¨-è§£ç å™¨è®¾ç½®ä¸­çš„è§£ç å™¨ï¼Œå¹¶ä¸”äº¤å‰æ³¨æ„åŠ›éšè—ç»´åº¦ä¸ `self.config.hidden_size` ä¸åŒï¼Œåˆ™ä¸ºäº¤å‰æ³¨æ„åŠ›å±‚çš„éšè—å¤§å°ã€‚

+   `add_cross_attention` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åº”å‘æ¨¡å‹æ·»åŠ äº¤å‰æ³¨æ„åŠ›å±‚ã€‚è¯·æ³¨æ„ï¼Œæ­¤é€‰é¡¹ä»…é€‚ç”¨äºå¯ä»¥åœ¨ [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel) ç±»ä¸­ç”¨ä½œè§£ç å™¨æ¨¡å‹çš„æ¨¡å‹ï¼Œå…¶ä¸­åŒ…æ‹¬ `AUTO_MODELS_FOR_CAUSAL_LM` ä¸­çš„æ‰€æœ‰æ¨¡å‹ã€‚

+   `tie_encoder_decoder` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åº”å°†æ‰€æœ‰ç¼–ç å™¨æƒé‡ç»‘å®šåˆ°å®ƒä»¬å¯¹åº”çš„è§£ç å™¨æƒé‡ã€‚è¿™è¦æ±‚ç¼–ç å™¨å’Œè§£ç å™¨æ¨¡å‹å…·æœ‰å®Œå…¨ç›¸åŒçš„å‚æ•°åç§°ã€‚

+   `prune_heads` (`Dict[int, List[int]]`, *å¯é€‰*, é»˜è®¤ä¸º `{}`) â€” æ¨¡å‹çš„å‰ªæå¤´éƒ¨ã€‚é”®æ˜¯æ‰€é€‰å±‚ç´¢å¼•ï¼Œç›¸å…³å€¼æ˜¯è¦åœ¨è¯¥å±‚ä¸­å‰ªæçš„å¤´éƒ¨åˆ—è¡¨ã€‚

    ä¾‹å¦‚ `{1: [0, 2], 2: [2, 3]}` å°†åœ¨ç¬¬ 1 å±‚å‰ªæå¤´éƒ¨ 0 å’Œ 2ï¼Œç¬¬ 2 å±‚å‰ªæå¤´éƒ¨ 2 å’Œ 3ã€‚

+   `chunk_size_feed_forward` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `0`) â€” æ®‹å·®æ³¨æ„åŠ›å—ä¸­æ‰€æœ‰å‰é¦ˆå±‚çš„å—å¤§å°ã€‚å—å¤§å°ä¸º `0` è¡¨ç¤ºå‰é¦ˆå±‚æœªåˆ†å—ã€‚å¤§å°ä¸º n çš„å—è¡¨ç¤ºå‰é¦ˆå±‚ä¸€æ¬¡å¤„ç† `n` ä¸ªåºåˆ—é•¿åº¦çš„åµŒå…¥ã€‚æœ‰å…³å‰é¦ˆåˆ†å—çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [å‰é¦ˆåˆ†å—æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ](../glossary.html#feed-forward-chunking)ã€‚

ç”¨äºåºåˆ—ç”Ÿæˆçš„å‚æ•°

+   `max_length` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 20) â€” é»˜è®¤æƒ…å†µä¸‹åœ¨æ¨¡å‹çš„ `generate` æ–¹æ³•ä¸­å°†ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚

+   `min_length` (`int`, *optional*, é»˜è®¤ä¸º0) â€” åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨çš„æœ€å°é•¿åº¦ã€‚

+   `do_sample` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨çš„æ ‡å¿—ã€‚æ˜¯å¦ä½¿ç”¨é‡‡æ ·ï¼›å¦åˆ™ä½¿ç”¨è´ªå©ªè§£ç ã€‚

+   `early_stopping` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨çš„æ ‡å¿—ã€‚æ˜¯å¦åœ¨æ¯æ‰¹è‡³å°‘å®Œæˆ`num_beams`ä¸ªå¥å­æ—¶åœæ­¢æŸæœç´¢ã€‚

+   `num_beams` (`int`, *optional*, é»˜è®¤ä¸º1) â€” åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨çš„æŸæœç´¢æ•°é‡ã€‚1è¡¨ç¤ºä¸ä½¿ç”¨æŸæœç´¢ã€‚

+   `num_beam_groups` (`int`, *optional*, é»˜è®¤ä¸º1) â€” ä¸ºäº†ç¡®ä¿åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨çš„ä¸åŒæŸç»„ä¹‹é—´çš„å¤šæ ·æ€§ï¼Œå°†`num_beams`åˆ†æˆçš„ç»„æ•°ã€‚1è¡¨ç¤ºä¸ä½¿ç”¨ç»„æŸæœç´¢ã€‚

+   `diversity_penalty` (`float`, *optional*, é»˜è®¤ä¸º0.0) â€” ç”¨äºæ§åˆ¶ç»„æŸæœç´¢å¤šæ ·æ€§çš„å€¼ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨ã€‚0è¡¨ç¤ºæ²¡æœ‰å¤šæ ·æ€§æƒ©ç½šã€‚æƒ©ç½šè¶Šé«˜ï¼Œè¾“å‡ºè¶Šå¤šæ ·åŒ–ã€‚

+   `temperature` (`float`, *optional*, é»˜è®¤ä¸º1.0) â€” ç”¨äºè°ƒèŠ‚ä¸‹ä¸€ä¸ªæ ‡è®°æ¦‚ç‡çš„å€¼ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨ã€‚å¿…é¡»ä¸¥æ ¼ä¸ºæ­£æ•°ã€‚

+   `top_k` (`int`, *optional*, é»˜è®¤ä¸º50) â€” åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨çš„ä¿ç•™æœ€é«˜æ¦‚ç‡è¯æ±‡æ ‡è®°çš„æ•°é‡ï¼Œç”¨äºtop-kè¿‡æ»¤ã€‚

+   `top_p` (`float`, *optional*, é»˜è®¤ä¸º1) â€” ç”¨äº`top_p`çš„é»˜è®¤å€¼ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­ä½¿ç”¨ã€‚å¦‚æœè®¾ç½®ä¸ºfloat < 1ï¼Œåªä¿ç•™æ¦‚ç‡åŠ èµ·æ¥è¾¾åˆ°`top_p`æˆ–æ›´é«˜çš„æœ€æœ‰å¯èƒ½çš„æ ‡è®°ç”¨äºç”Ÿæˆã€‚

+   `typical_p` (`float`, *optional*, é»˜è®¤ä¸º1) â€” æœ¬åœ°å…¸å‹æ€§è¡¡é‡äº†é¢„æµ‹ä¸‹ä¸€ä¸ªç›®æ ‡æ ‡è®°çš„æ¡ä»¶æ¦‚ç‡ä¸é¢„æœŸçš„æ¡ä»¶æ¦‚ç‡æœ‰å¤šç›¸ä¼¼ï¼Œç»™å®šå·²ç”Ÿæˆçš„éƒ¨åˆ†æ–‡æœ¬ã€‚å¦‚æœè®¾ç½®ä¸ºfloat < 1ï¼Œå°†ä¿ç•™æ¦‚ç‡åŠ èµ·æ¥è¾¾åˆ°`typical_p`æˆ–æ›´é«˜çš„æœ€å…·æœ¬åœ°å…¸å‹æ€§çš„æ ‡è®°é›†ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æ­¤è®ºæ–‡](https://arxiv.org/pdf/2202.00666.pdf)ã€‚

+   `repetition_penalty` (`float`, *optional*, é»˜è®¤ä¸º1) â€” ç”¨äºé‡å¤æƒ©ç½šçš„å‚æ•°ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨ã€‚1.0è¡¨ç¤ºæ²¡æœ‰æƒ©ç½šã€‚

+   `length_penalty` (`float`, *optional*, é»˜è®¤ä¸º1) â€” ç”¨äºåŸºäºæŸçš„ç”Ÿæˆçš„é•¿åº¦çš„æŒ‡æ•°æƒ©ç½šã€‚å®ƒä½œä¸ºæŒ‡æ•°åº”ç”¨äºåºåˆ—é•¿åº¦ï¼Œç„¶åç”¨äºåˆ†å‰²åºåˆ—çš„åˆ†æ•°ã€‚ç”±äºåˆ†æ•°æ˜¯åºåˆ—çš„å¯¹æ•°ä¼¼ç„¶ï¼ˆå³è´Ÿæ•°ï¼‰ï¼Œ`length_penalty` > 0.0 ä¿ƒè¿›æ›´é•¿çš„åºåˆ—ï¼Œè€Œ`length_penalty` < 0.0 é¼“åŠ±æ›´çŸ­çš„åºåˆ—ã€‚

+   `no_repeat_ngram_size` (`int`, *optional*, é»˜è®¤ä¸º0) â€” ç”¨äº`no_repeat_ngram_size`çš„é»˜è®¤å€¼ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­ä½¿ç”¨ã€‚å¦‚æœè®¾ç½®ä¸ºint > 0ï¼Œè¯¥å¤§å°çš„æ‰€æœ‰ngramåªèƒ½å‡ºç°ä¸€æ¬¡ã€‚

+   `encoder_no_repeat_ngram_size` (`int`, *optional*, é»˜è®¤ä¸º0) â€” ç”¨äº`encoder_no_repeat_ngram_size`çš„é»˜è®¤å€¼ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­ä½¿ç”¨ã€‚å¦‚æœè®¾ç½®ä¸ºint > 0ï¼Œ`encoder_input_ids`ä¸­å‡ºç°çš„è¯¥å¤§å°çš„æ‰€æœ‰ngramä¸èƒ½å‡ºç°åœ¨`decoder_input_ids`ä¸­ã€‚

+   `bad_words_ids` (`List[int]`, *optional*) â€” ä¸å…è®¸ç”Ÿæˆçš„æ ‡è®°idåˆ—è¡¨ï¼Œå°†åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­é»˜è®¤ä½¿ç”¨ã€‚ä¸ºäº†è·å–ä¸åº”å‡ºç°åœ¨ç”Ÿæˆæ–‡æœ¬ä¸­çš„å•è¯çš„æ ‡è®°ï¼Œè¯·ä½¿ç”¨`tokenizer.encode(bad_word, add_prefix_space=True)`ã€‚

+   `num_return_sequences` (`int`, *optional*, é»˜è®¤ä¸º1) â€” æ¯ä¸ªæ‰¹æ¬¡ä¸­æ¯ä¸ªå…ƒç´ é»˜è®¤åœ¨æ¨¡å‹çš„`generate`æ–¹æ³•ä¸­ä½¿ç”¨çš„ç‹¬ç«‹è®¡ç®—è¿”å›åºåˆ—çš„æ•°é‡ã€‚

+   `output_scores` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” å½“ç”¨äºç”Ÿæˆæ—¶ï¼Œæ¨¡å‹æ˜¯å¦åº”è¿”å›logitsã€‚

+   `return_dict_in_generate` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ¨¡å‹åœ¨ç”Ÿæˆæ—¶æ˜¯å¦åº”è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯`torch.LongTensor`ã€‚

+   `forced_bos_token_id` (`int`, *optional*) â€” åœ¨`decoder_start_token_id`ä¹‹åå¼ºåˆ¶ä½œä¸ºç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°çš„idã€‚å¯¹äºå¤šè¯­è¨€æ¨¡å‹ï¼ˆå¦‚[mBART](../model_doc/mbart)ï¼‰å¾ˆæœ‰ç”¨ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°éœ€è¦æ˜¯ç›®æ ‡è¯­è¨€æ ‡è®°ã€‚

+   `forced_eos_token_id` (`int`, *optional*) â€” å½“è¾¾åˆ°`max_length`æ—¶ï¼Œå¼ºåˆ¶ä½œä¸ºæœ€åç”Ÿæˆçš„æ ‡è®°çš„idã€‚

+   `remove_invalid_values` (`bool`, *optional*) â€” æ˜¯å¦åˆ é™¤æ¨¡å‹å¯èƒ½äº§ç”Ÿçš„*nan*å’Œ*inf*è¾“å‡ºï¼Œä»¥é˜²æ­¢ç”Ÿæˆæ–¹æ³•å´©æºƒã€‚è¯·æ³¨æ„ï¼Œä½¿ç”¨`remove_invalid_values`å¯èƒ½ä¼šå‡æ…¢ç”Ÿæˆé€Ÿåº¦ã€‚

ç”¨äºå¾®è°ƒä»»åŠ¡çš„å‚æ•°

+   `architectures` (`List[str]`, *optional*) â€” å¯ä¸æ¨¡å‹é¢„è®­ç»ƒæƒé‡ä¸€èµ·ä½¿ç”¨çš„æ¨¡å‹æ¶æ„ã€‚

+   `finetuning_task` (`str`, *optional*) â€” ç”¨äºå¾®è°ƒæ¨¡å‹çš„ä»»åŠ¡åç§°ã€‚åœ¨ä»åŸå§‹ï¼ˆTensorFlowæˆ–PyTorchï¼‰æ£€æŸ¥ç‚¹è½¬æ¢æ—¶å¯ä»¥ä½¿ç”¨ã€‚

+   `id2label` (`Dict[int, str]`, *optional*) â€” ä»ç´¢å¼•ï¼ˆä¾‹å¦‚é¢„æµ‹ç´¢å¼•æˆ–ç›®æ ‡ç´¢å¼•ï¼‰åˆ°æ ‡ç­¾çš„æ˜ å°„ã€‚

+   `label2id` (`Dict[str, int]`, *optional*) â€” ä»æ ‡ç­¾åˆ°æ¨¡å‹ç´¢å¼•çš„æ˜ å°„ã€‚

+   `num_labels` (`int`, *optional*) â€” åœ¨æ¨¡å‹ä¸­æ·»åŠ çš„æœ€åä¸€å±‚ä¸­è¦ä½¿ç”¨çš„æ ‡ç­¾æ•°ï¼Œé€šå¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚

+   `task_specific_params` (`Dict[str, Any]`, *optional*) â€” å­˜å‚¨å½“å‰ä»»åŠ¡çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

+   `problem_type` (`str`, *optional*) â€” `XxxForSequenceClassification`æ¨¡å‹çš„é—®é¢˜ç±»å‹ã€‚å¯ä»¥æ˜¯`"regression"`ã€`"single_label_classification"`æˆ–`"multi_label_classification"`ä¸­çš„ä¸€ä¸ªã€‚

ä¸åˆ†è¯å™¨ç›¸å…³çš„å‚æ•°

+   `tokenizer_class` (`str`, *optional*) â€” è¦ä½¿ç”¨çš„å…³è”åˆ†è¯å™¨ç±»çš„åç§°ï¼ˆå¦‚æœæœªè®¾ç½®ï¼Œåˆ™é»˜è®¤ä½¿ç”¨ä¸æ¨¡å‹å…³è”çš„åˆ†è¯å™¨ï¼‰ã€‚

+   `prefix` (`str`, *optional*) â€” æ¯ä¸ªæ–‡æœ¬å‰è°ƒç”¨æ¨¡å‹ä¹‹å‰åº”æ·»åŠ çš„ç‰¹å®šæç¤ºã€‚

+   `bos_token_id` (`int`, *optional*) â€” *æµçš„å¼€å§‹*æ ‡è®°çš„idã€‚

+   `pad_token_id` (`int`, *optional*) â€” *å¡«å……*æ ‡è®°çš„idã€‚

+   `eos_token_id` (`int`, *optional*) â€” *æµçš„ç»“æŸ*æ ‡è®°çš„idã€‚

+   `decoder_start_token_id` (`int`, *optional*) â€” å¦‚æœç¼–ç å™¨-è§£ç å™¨æ¨¡å‹å¼€å§‹è§£ç æ—¶ä½¿ç”¨ä¸*bos*ä¸åŒçš„æ ‡è®°ï¼Œåˆ™è¯¥æ ‡è®°çš„idã€‚

+   `sep_token_id` (`int`, *optional*) â€” *åˆ†éš”*æ ‡è®°çš„idã€‚

PyTorchç‰¹å®šå‚æ•°

+   `torchscript` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ¨¡å‹æ˜¯å¦åº”ä¸Torchscriptä¸€èµ·ä½¿ç”¨ã€‚

+   `tie_word_embeddings` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºè¯åµŒå…¥æ˜¯å¦åº”è¯¥ç»‘å®šã€‚è¯·æ³¨æ„ï¼Œè¿™ä»…åœ¨æ¨¡å‹å…·æœ‰è¾“å‡ºè¯åµŒå…¥å±‚æ—¶æ‰ç›¸å…³ã€‚

+   `torch_dtype` (`str`, *optional*) â€” æƒé‡çš„`dtype`ã€‚æ­¤å±æ€§å¯ç”¨äºå°†æ¨¡å‹åˆå§‹åŒ–ä¸ºéé»˜è®¤çš„`dtype`ï¼ˆé€šå¸¸ä¸º`float32`ï¼‰ï¼Œä»è€Œå…è®¸è¿›è¡Œæœ€ä½³å­˜å‚¨åˆ†é…ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¿å­˜çš„æ¨¡å‹æ˜¯`float16`ï¼Œç†æƒ³æƒ…å†µä¸‹æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨æœ€å°‘çš„å†…å­˜æ¥åŠ è½½`float16`æƒé‡ã€‚ç”±äºé…ç½®å¯¹è±¡ä»¥çº¯æ–‡æœ¬å½¢å¼å­˜å‚¨ï¼Œå› æ­¤æ­¤å±æ€§ä»…åŒ…å«æµ®ç‚¹ç±»å‹å­—ç¬¦ä¸²ï¼Œä¸åŒ…å«`torch.`å‰ç¼€ã€‚ä¾‹å¦‚ï¼Œå¯¹äº`torch.float16`ï¼Œ`torch_dtype`æ˜¯`"float16"`å­—ç¬¦ä¸²ã€‚

    æ­¤å±æ€§å½“å‰åœ¨æ¨¡å‹åŠ è½½æ—¶æœªè¢«ä½¿ç”¨ï¼Œä½†åœ¨å°†æ¥çš„ç‰ˆæœ¬ä¸­å¯èƒ½ä¼šæ›´æ”¹ã€‚ä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ save_pretrained ä¿å­˜ dtype æ¥ä¸ºæœªæ¥åšå¥½å‡†å¤‡ã€‚

+   `attn_implementation` (`str`, *optional*) â€” æ¨¡å‹ä¸­è¦ä½¿ç”¨çš„æ³¨æ„åŠ›å®ç°ã€‚å¯ä»¥æ˜¯ `"eager"`ï¼ˆæ³¨æ„åŠ›çš„æ‰‹åŠ¨å®ç°ï¼‰ï¼Œ`"sdpa"`ï¼ˆä½¿ç”¨ [`torch.nn.functional.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html) çš„æ³¨æ„åŠ›ï¼‰ï¼Œæˆ– `"flash_attention_2"`ï¼ˆä½¿ç”¨ [Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention) çš„æ³¨æ„åŠ›ï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœå¯ç”¨ï¼Œtorch>=2.1.1 ä¼šä½¿ç”¨ SDPAã€‚å¦åˆ™ï¼Œé»˜è®¤ä¸ºæ‰‹åŠ¨çš„ `"eager"` å®ç°ã€‚

TensorFlow ç‰¹å®šå‚æ•°

+   `use_bfloat16` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ¨¡å‹æ˜¯å¦åº”è¯¥ä½¿ç”¨ BFloat16 æ ‡é‡ï¼ˆä»…ç”±æŸäº› TensorFlow æ¨¡å‹ä½¿ç”¨ï¼‰ã€‚

+   `tf_legacy_loss` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ¨¡å‹æ˜¯å¦åº”è¯¥ä½¿ç”¨ä¼ ç»Ÿçš„ TensorFlow æŸå¤±ã€‚ä¼ ç»ŸæŸå¤±å…·æœ‰å¯å˜çš„è¾“å‡ºå½¢çŠ¶ï¼Œå¯èƒ½ä¸å…¼å®¹ XLAã€‚æ­¤é€‰é¡¹ç”¨äºå‘åå…¼å®¹ï¼Œå°†åœ¨ Transformers v5 ä¸­åˆ é™¤ã€‚

æ‰€æœ‰é…ç½®ç±»çš„åŸºç±»ã€‚å¤„ç†ä¸€äº›æ‰€æœ‰æ¨¡å‹é…ç½®å…±æœ‰çš„å‚æ•°ï¼Œä»¥åŠç”¨äºåŠ è½½/ä¸‹è½½/ä¿å­˜é…ç½®çš„æ–¹æ³•ã€‚

å¯ä»¥åŠ è½½å’Œä¿å­˜é…ç½®æ–‡ä»¶åˆ°ç£ç›˜ã€‚åŠ è½½é…ç½®æ–‡ä»¶å¹¶ä½¿ç”¨æ­¤æ–‡ä»¶åˆå§‹åŒ–æ¨¡å‹ **ä¸ä¼š** åŠ è½½æ¨¡å‹æƒé‡ã€‚å®ƒåªå½±å“æ¨¡å‹çš„é…ç½®ã€‚

ç±»å±æ€§ï¼ˆç”±æ´¾ç”Ÿç±»è¦†ç›–ï¼‰ï¼š

+   `model_type` (`str`) â€” æ¨¡å‹ç±»å‹çš„æ ‡è¯†ç¬¦ï¼Œåºåˆ—åŒ–åˆ° JSON æ–‡ä»¶ä¸­ï¼Œå¹¶ç”¨äºåœ¨ [AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig) ä¸­é‡æ–°åˆ›å»ºæ­£ç¡®çš„å¯¹è±¡ã€‚

+   `is_composition` (`bool`) â€” é…ç½®ç±»æ˜¯å¦ç”±å¤šä¸ªå­é…ç½®ç»„æˆã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé…ç½®å¿…é¡»ä»ä¸¤ä¸ªæˆ–æ›´å¤šç±»å‹ä¸º [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig) çš„é…ç½®åˆå§‹åŒ–ï¼Œå¦‚ï¼š[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig) æˆ– [~RagConfig](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagConfig)ã€‚

+   `keys_to_ignore_at_inference` (`List[str]`) â€” æ¨ç†æœŸé—´æŸ¥çœ‹æ¨¡å‹å­—å…¸è¾“å‡ºæ—¶é»˜è®¤è¦å¿½ç•¥çš„é”®åˆ—è¡¨ã€‚

+   `attribute_map` (`Dict[str, str]`) â€” å°†æ¨¡å‹ç‰¹å®šå±æ€§åç§°æ˜ å°„åˆ°å±æ€§çš„æ ‡å‡†åŒ–å‘½åçš„å­—å…¸ã€‚

æ‰€æœ‰å­ç±»ä¸­å­˜åœ¨çš„å…¬å…±å±æ€§ï¼š

+   `vocab_size` (`int`) â€” è¯æ±‡è¡¨ä¸­çš„æ ‡è®°æ•°ï¼Œä¹Ÿæ˜¯åµŒå…¥çŸ©é˜µçš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆå¯¹äºæ²¡æœ‰æ–‡æœ¬æ¨¡æ€çš„æ¨¡å‹ï¼Œæ­¤å±æ€§å¯èƒ½ç¼ºå¤±ï¼‰ã€‚

+   `hidden_size` (`int`) â€” æ¨¡å‹çš„éšè—å¤§å°ã€‚

+   `num_attention_heads` (`int`) â€” æ¨¡å‹ä¸­å¤šå¤´æ³¨æ„åŠ›å±‚ä¸­ä½¿ç”¨çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `num_hidden_layers` (`int`) â€” æ¨¡å‹ä¸­çš„å—æ•°ã€‚

#### `push_to_hub`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)

```py
( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )
```

å‚æ•°

+   `repo_id` (`str`) â€” æ‚¨è¦å°†é…ç½®æ¨é€åˆ°çš„å­˜å‚¨åº“çš„åç§°ã€‚åœ¨æ¨é€åˆ°ç»™å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚

+   `use_temp_dir` (`bool`, *optional*) â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•å­˜å‚¨åœ¨æ¨é€åˆ° Hub ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶ã€‚å¦‚æœæ²¡æœ‰åä¸º `repo_id` çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`ã€‚

+   `commit_message` (`str`, *optional*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º `"Upload config"`ã€‚

+   `private` (`bool`, *optional*) â€” æ˜¯å¦åº”è¯¥åˆ›å»ºç§æœ‰å­˜å‚¨åº“ã€‚

+   `token` (`bool` æˆ– `str`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š`repo_url`ï¼Œåˆ™é»˜è®¤ä¸º`True`ã€‚

+   `max_shard_size` (`int` æˆ– `str`, *å¯é€‰*, é»˜è®¤ä¸º `"5GB"`) â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹å°†åˆ†ç‰‡ä¸ºæ¯ä¸ªå¤§å°ä½äºæ­¤å¤§å°çš„éƒ¨åˆ†ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚`"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤ä¸º`"5GB"`ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨å…è´¹çš„Google Colabå®ä¾‹ä¸Šè½»æ¾åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½•CPU OOMé—®é¢˜ã€‚

+   `create_pr` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„PRæˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸ºsafetensorsæ ¼å¼ä»¥è¿›è¡Œæ›´å®‰å…¨çš„åºåˆ—åŒ–ã€‚

+   `revision` (`str`, *å¯é€‰*) â€” è¦å°†ä¸Šä¼ çš„æ–‡ä»¶æ¨é€åˆ°çš„åˆ†æ”¯ã€‚

+   `commit_description` (`str`, *å¯é€‰*) â€” å°†è¦åˆ›å»ºçš„æäº¤æè¿°

+   `tags` (`List[str]`, *å¯é€‰*) â€” è¦æ¨é€åˆ°Hubä¸Šçš„æ ‡ç­¾åˆ—è¡¨ã€‚

å°†é…ç½®æ–‡ä»¶ä¸Šä¼ åˆ°ğŸ¤—æ¨¡å‹Hubã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import AutoConfig

config = AutoConfig.from_pretrained("bert-base-cased")

# Push the config to your namespace with the name "my-finetuned-bert".
config.push_to_hub("my-finetuned-bert")

# Push the config to an organization with the name "my-finetuned-bert".
config.push_to_hub("huggingface/my-finetuned-bert")
```

#### `dict_torch_dtype_to_str`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L1005)

```py
( d: Dict )
```

æ£€æŸ¥ä¼ é€’çš„å­—å…¸åŠå…¶åµŒå¥—å­—å…¸æ˜¯å¦å…·æœ‰*torch_dtype*é”®ï¼Œå¦‚æœä¸æ˜¯Noneï¼Œåˆ™å°†torch.dtypeè½¬æ¢ä¸ºä»…ç±»å‹çš„å­—ç¬¦ä¸²ã€‚ä¾‹å¦‚ï¼Œ`torch.float32`è¢«è½¬æ¢ä¸º*â€œfloat32â€*å­—ç¬¦ä¸²ï¼Œç„¶åå¯ä»¥å­˜å‚¨åœ¨jsonæ ¼å¼ä¸­ã€‚

#### `from_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L737)

```py
( config_dict: Dict **kwargs ) â†’ export const metadata = 'undefined';PretrainedConfig
```

å‚æ•°

+   `config_dict` (`Dict[str, Any]`) â€” å°†ç”¨äºå®ä¾‹åŒ–é…ç½®å¯¹è±¡çš„å­—å…¸ã€‚å¯ä»¥é€šè¿‡åˆ©ç”¨[get_config_dict()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.get_config_dict)æ–¹æ³•ä»é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ä¸­æ£€ç´¢è¿™æ ·çš„å­—å…¸ã€‚

+   `kwargs` (`Dict[str, Any]`) â€” ç”¨äºåˆå§‹åŒ–é…ç½®å¯¹è±¡çš„å…¶ä»–å‚æ•°ã€‚

è¿”å›

[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)

ä»è¿™äº›å‚æ•°å®ä¾‹åŒ–çš„é…ç½®å¯¹è±¡ã€‚

ä»å‚æ•°å­—å…¸å®ä¾‹åŒ–ä¸€ä¸ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ã€‚

#### `from_json_file`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L798)

```py
( json_file: Union ) â†’ export const metadata = 'undefined';PretrainedConfig
```

å‚æ•°

+   `json_file` (`str` æˆ– `os.PathLike`) â€” åŒ…å«å‚æ•°çš„JSONæ–‡ä»¶çš„è·¯å¾„ã€‚

è¿”å›

[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)

ä»è¯¥JSONæ–‡ä»¶å®ä¾‹åŒ–çš„é…ç½®å¯¹è±¡ã€‚

ä»å‚æ•°æ–‡ä»¶çš„è·¯å¾„å®ä¾‹åŒ–ä¸€ä¸ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ã€‚

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L511)

```py
( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs ) â†’ export const metadata = 'undefined';PretrainedConfig
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str` æˆ– `os.PathLike`) â€” è¿™å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨huggingface.coæ¨¡å‹å­˜å‚¨åº“ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®çš„*æ¨¡å‹ID*ã€‚æœ‰æ•ˆçš„æ¨¡å‹IDå¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚

    +   ä¸€ä¸ª*ç›®å½•*çš„è·¯å¾„ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained)æ–¹æ³•ä¿å­˜çš„é…ç½®æ–‡ä»¶ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

    +   ä¸€ä¸ªä¿å­˜çš„é…ç½®JSON *æ–‡ä»¶*çš„è·¯å¾„æˆ–URLï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/configuration.json`ã€‚

+   `cache_dir` (`str` æˆ– `os.PathLike`, *å¯é€‰*) â€” ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®åº”ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `force_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½é…ç½®æ–‡ä»¶å¹¶è¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ é™¤æ¥æ”¶ä¸å®Œæ•´çš„æ–‡ä»¶ã€‚å¦‚æœå­˜åœ¨è¿™æ ·çš„æ–‡ä»¶ï¼Œå°è¯•æ¢å¤ä¸‹è½½ã€‚

+   `proxies` (`Dict[str, str]`, *å¯é€‰*) â€” è¦ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ï¼‰ã€‚

+   `revision` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å®ƒå¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°æˆ–æäº¤IDï¼Œå› ä¸ºæˆ‘ä»¬åœ¨huggingface.coä¸Šä½¿ç”¨åŸºäºgitçš„ç³»ç»Ÿå­˜å‚¨æ¨¡å‹å’Œå…¶ä»–å·¥ä»¶ï¼Œæ‰€ä»¥`revision`å¯ä»¥æ˜¯gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

    è¦æµ‹è¯•æ‚¨åœ¨Hubä¸Šæäº¤çš„æ‹‰å–è¯·æ±‚ï¼Œå¯ä»¥ä¼ é€’`revision=â€œrefs/pr/<pr_number>â€œã€‚</pr_number>

+   `return_unused_kwargs` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `False`ï¼Œåˆ™æ­¤å‡½æ•°ä»…è¿”å›æœ€ç»ˆé…ç½®å¯¹è±¡ã€‚

    å¦‚æœä¸º `True`ï¼Œåˆ™æ­¤å‡½æ•°è¿”å›ä¸€ä¸ª`Tuple(config, unused_kwargs)`ï¼Œå…¶ä¸­*unused_kwargs*æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œç”±é‚£äº›ä¸æ˜¯é…ç½®å±æ€§çš„é”®/å€¼å¯¹ç»„æˆï¼šå³ï¼Œæœªç”¨äºæ›´æ–°`config`çš„`kwargs`éƒ¨åˆ†ï¼Œå¦åˆ™å°†è¢«å¿½ç•¥ã€‚

+   `subfolder` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `""`) â€” å¦‚æœç›¸å…³æ–‡ä»¶ä½äºhuggingface.coæ¨¡å‹å­˜å‚¨åº“çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤å¤„æŒ‡å®šæ–‡ä»¶å¤¹åç§°ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä»»ä½•é”®çš„kwargså€¼ï¼Œè¿™äº›é”®æ˜¯é…ç½®å±æ€§ï¼Œå°†ç”¨äºè¦†ç›–åŠ è½½çš„å€¼ã€‚å…³äºé”®/å€¼å¯¹ä¸­é”®ä¸æ˜¯é…ç½®å±æ€§çš„è¡Œä¸ºç”±`return_unused_kwargs`å…³é”®å­—å‚æ•°æ§åˆ¶ã€‚

è¿”å›

[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)

ä»æ­¤é¢„è®­ç»ƒæ¨¡å‹å®ä¾‹åŒ–çš„é…ç½®å¯¹è±¡ã€‚

ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–ä¸€ä¸ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼ˆæˆ–æ´¾ç”Ÿç±»ï¼‰ã€‚

ç¤ºä¾‹ï¼š

```py
# We can't instantiate directly the base class *PretrainedConfig* so let's show the examples on a
# derived class: BertConfig
config = BertConfig.from_pretrained(
    "bert-base-uncased"
)  # Download configuration from huggingface.co and cache.
config = BertConfig.from_pretrained(
    "./test/saved_model/"
)  # E.g. config (or model) was saved using *save_pretrained('./test/saved_model/')*
config = BertConfig.from_pretrained("./test/saved_model/my_configuration.json")
config = BertConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
assert config.output_attentions == True
config, unused_kwargs = BertConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
assert config.output_attentions == True
assert unused_kwargs == {"foo": False}
```

#### `get_config_dict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L614)

```py
( pretrained_model_name_or_path: Union **kwargs ) â†’ export const metadata = 'undefined';Tuple[Dict, Dict]
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str` æˆ– `os.PathLike`) â€” æˆ‘ä»¬æƒ³è¦å‚æ•°å­—å…¸çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹çš„æ ‡è¯†ç¬¦ã€‚

è¿”å›

`Tuple[Dict, Dict]`

å°†ç”¨äºå®ä¾‹åŒ–é…ç½®å¯¹è±¡çš„å­—å…¸ã€‚

ä»`pretrained_model_name_or_path`è§£æä¸ºå‚æ•°å­—å…¸ï¼Œç”¨äºä½¿ç”¨`from_dict`å®ä¾‹åŒ–[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ã€‚

#### `register_for_auto_class`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L1017)

```py
( auto_class = 'AutoConfig' )
```

å‚æ•°

+   `auto_class` (`str` æˆ– `type`, *å¯é€‰*, é»˜è®¤ä¸º `"AutoConfig"`) â€” è¦å°†æ­¤æ–°é…ç½®æ³¨å†Œåˆ°çš„è‡ªåŠ¨ç±»ã€‚

ä½¿ç”¨ç»™å®šçš„è‡ªåŠ¨ç±»æ³¨å†Œæ­¤ç±»ã€‚è¿™ä»…åº”ç”¨äºè‡ªå®šä¹‰é…ç½®ï¼Œå› ä¸ºåº“ä¸­çš„é…ç½®å·²ä¸`AutoConfig`æ˜ å°„ã€‚

æ­¤APIæ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½åœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­æœ‰ä¸€äº›è½»å¾®çš„ç ´åæ€§æ›´æ”¹ã€‚

#### `save_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L424)

```py
( save_directory: Union push_to_hub: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str` æˆ– `os.PathLike`) â€” å°†ä¿å­˜é…ç½®JSONæ–‡ä»¶çš„ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨å°†è¢«åˆ›å»ºï¼‰ã€‚

+   `push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ°Hugging Faceæ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` çš„åç§°ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub) æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†é…ç½®å¯¹è±¡ä¿å­˜åˆ°ç›®å½• `save_directory` ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained) ç±»æ–¹æ³•é‡æ–°åŠ è½½ã€‚

#### `to_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L883)

```py
( ) â†’ export const metadata = 'undefined';Dict[str, Any]
```

è¿”å›

`Dict[str, Any]`

è¿™ä¸ªé…ç½®å®ä¾‹çš„æ‰€æœ‰å±æ€§çš„å­—å…¸ã€‚

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸ºPythonå­—å…¸ã€‚

#### `to_diff_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L826)

```py
( ) â†’ export const metadata = 'undefined';Dict[str, Any]
```

è¿”å›

`Dict[str, Any]`

è¿™ä¸ªé…ç½®å®ä¾‹çš„æ‰€æœ‰å±æ€§çš„å­—å…¸ï¼Œ

ä»é…ç½®ä¸­åˆ é™¤æ‰€æœ‰ä¸é»˜è®¤é…ç½®å±æ€§å¯¹åº”çš„å±æ€§ï¼Œä»¥æé«˜å¯è¯»æ€§å¹¶åºåˆ—åŒ–ä¸ºPythonå­—å…¸ã€‚

#### `to_json_file`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L943)

```py
( json_file_path: Union use_diff: bool = True )
```

å‚æ•°

+   `json_file_path` (`str` æˆ– `os.PathLike`) â€” æ­¤é…ç½®å®ä¾‹çš„å‚æ•°å°†è¢«ä¿å­˜åœ¨å…¶ä¸­çš„JSONæ–‡ä»¶çš„è·¯å¾„ã€‚

+   `use_diff` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™åªå°†é…ç½®å®ä¾‹ä¸é»˜è®¤ `PretrainedConfig()` ä¹‹é—´çš„å·®å¼‚åºåˆ—åŒ–ä¸ºJSONæ–‡ä»¶ã€‚

å°†æ­¤å®ä¾‹ä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ã€‚

#### `to_json_string`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L925)

```py
( use_diff: bool = True ) â†’ export const metadata = 'undefined';str
```

å‚æ•°

+   `use_diff` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™åªå°†é…ç½®å®ä¾‹ä¸é»˜è®¤ `PretrainedConfig()` ä¹‹é—´çš„å·®å¼‚åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ã€‚

è¿”å›

`str`

åŒ…å«æ­¤é…ç½®å®ä¾‹ä¸­æ‰€æœ‰å±æ€§çš„å­—ç¬¦ä¸²ï¼Œä»¥JSONæ ¼å¼ã€‚

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ã€‚

#### `update`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L957)

```py
( config_dict: Dict )
```

å‚æ•°

+   `config_dict` (`Dict[str, Any]`) â€” åº”è¯¥æ›´æ–°æ­¤ç±»çš„å±æ€§çš„å­—å…¸ã€‚

ä½¿ç”¨`config_dict`ä¸­çš„å±æ€§æ›´æ–°æ­¤ç±»çš„å±æ€§ã€‚

#### `update_from_string`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/configuration_utils.py#L967)

```py
( update_str: str )
```

å‚æ•°

+   `update_str` (`str`) â€” åº”è¯¥æ›´æ–°æ­¤ç±»çš„å±æ€§çš„å­—ç¬¦ä¸²ã€‚

ä½¿ç”¨`update_str`ä¸­çš„å±æ€§æ›´æ–°æ­¤ç±»çš„å±æ€§ã€‚

é¢„æœŸçš„æ ¼å¼æ˜¯æ•´æ•°ã€æµ®ç‚¹æ•°å’Œå­—ç¬¦ä¸²ï¼Œå¯¹äºå¸ƒå°”å€¼ï¼Œè¯·ä½¿ç”¨ `true` æˆ– `false`ã€‚ä¾‹å¦‚: â€œn_embd=10,resid_pdrop=0.2,scale_attn_weights=false,summary_type=cls_indexâ€

è¦æ›´æ”¹çš„é”®å¿…é¡»å·²ç»å­˜åœ¨äºé…ç½®å¯¹è±¡ä¸­ã€‚
