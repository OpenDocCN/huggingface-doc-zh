- en: Consistency Decoder
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一致性解码器
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/consistency_decoder_vae](https://huggingface.co/docs/diffusers/api/models/consistency_decoder_vae)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/models/consistency_decoder_vae](https://huggingface.co/docs/diffusers/api/models/consistency_decoder_vae)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Consistency decoder can be used to decode the latents from the denoising UNet
    in the [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline).
    This decoder was introduced in the [DALL-E 3 technical report](https://openai.com/dall-e-3).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性解码器可用于从[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)中的去噪UNet解码潜变量。此解码器在[DALL-E
    3技术报告](https://openai.com/dall-e-3)中引入。
- en: The original codebase can be found at [openai/consistencydecoder](https://github.com/openai/consistencydecoder).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可在[openai/consistencydecoder](https://github.com/openai/consistencydecoder)找到。
- en: Inference is only supported for 2 iterations as of now.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 目前仅支持2次迭代的推断。
- en: The pipeline could not have been contributed without the help of [madebyollin](https://github.com/madebyollin)
    and [mrsteyk](https://github.com/mrsteyk) from [this issue](https://github.com/openai/consistencydecoder/issues/1).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有[madebyollin](https://github.com/madebyollin)和[mrsteyk](https://github.com/mrsteyk)在[此问题](https://github.com/openai/consistencydecoder/issues/1)的帮助下，该管道不可能被贡献。
- en: ConsistencyDecoderVAE
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConsistencyDecoderVAE
- en: '### `class diffusers.ConsistencyDecoderVAE`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.ConsistencyDecoderVAE`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L52)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L52)'
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The consistency decoder used with DALL-E 3.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 用于DALL-E 3的一致性解码器。
- en: 'Examples:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#### `wrapper`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `wrapper`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)'
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `disable_slicing`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L182)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L182)'
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disable sliced VAE decoding. If `enable_slicing` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片化VAE解码。如果之前启用了`enable_slicing`，则此方法将回到一步计算解码。
- en: '#### `disable_tiling`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L166)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L166)'
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable tiled VAE decoding. If `enable_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用瓦片化VAE解码。如果之前启用了`enable_tiling`，则此方法将回到一步计算解码。
- en: '#### `enable_slicing`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L174)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L174)'
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片化VAE解码。当启用此选项时，VAE将将输入张量分割成片段，以便在多个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `enable_tiling`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L157)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L157)'
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 启用瓦片化VAE解码。当启用此选项时，VAE将将输入张量分割成瓦片，以便在多个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `forward`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L403)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L403)'
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor`) — Input sample.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（`torch.FloatTensor`）— 输入样本。'
- en: '`sample_posterior` (`bool`, *optional*, defaults to `False`) — Whether to sample
    from the posterior.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_posterior`（`bool`，*可选*，默认为`False`）— 是否从后验中抽样。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `DecoderOutput` instead of a plain tuple.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`DecoderOutput`而不是普通的tuple。'
- en: '`generator` (`torch.Generator`, *optional*, defaults to `None`) — Generator
    to use for sampling.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`，*可选*，默认为`None`）— 用于抽样的生成器。'
- en: Returns
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`DecoderOutput` or `tuple`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`DecoderOutput`或`tuple`'
- en: If return_dict is True, a `DecoderOutput` is returned, otherwise a plain `tuple`
    is returned.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为True，则返回`DecoderOutput`，否则返回普通的`tuple`。
- en: '#### `set_attn_processor`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_attn_processor`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L215)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L215)'
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`processor` (`dict` of `AttentionProcessor` or only `AttentionProcessor`) —
    The instantiated processor class or a dictionary of processor classes that will
    be set as the processor for **all** `Attention` layers.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processor`（`dict` of `AttentionProcessor`或仅`AttentionProcessor`）— 实例化的处理器类或一组处理器类的字典，将被设置为**所有**`Attention`层的处理器。'
- en: If `processor` is a dict, the key needs to define the path to the corresponding
    cross attention processor. This is strongly recommended when setting trainable
    attention processors.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`processor`是一个字典，则键需要定义到相应交叉注意力处理器的路径。在设置可训练的注意力处理器时，强烈建议这样做。
- en: Sets the attention processor to use to compute attention.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于计算注意力的注意力处理器。
- en: '#### `set_default_attn_processor`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_default_attn_processor`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L250)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L250)'
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Disables custom attention processors and sets the default attention implementation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用自定义注意力处理器并设置默认的注意力实现。
- en: '#### `tiled_encode`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tiled_encode`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L348)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/consistency_decoder_vae.py#L348)'
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`x` (`torch.FloatTensor`) — Input batch of images.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`（`torch.FloatTensor`）— 图像的输入批次。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `~models.consistency_decoder_vae.ConsistencyDecoderVAEOutput` instead
    of a plain tuple.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`~models.consistency_decoder_vae.ConsistencyDecoderVAEOutput`而不是普通的tuple。'
- en: Returns
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`~models.consistency_decoder_vae.ConsistencyDecoderVAEOutput` or `tuple`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`~models.consistency_decoder_vae.ConsistencyDecoderVAEOutput`或`tuple`'
- en: If return_dict is True, a `~models.consistency_decoder_vae.ConsistencyDecoderVAEOutput`
    is returned, otherwise a plain `tuple` is returned.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果return_dict为True，则返回`~models.consistency_decoder_vae.ConsistencyDecoderVAEOutput`，否则返回一个普通的`tuple`。
- en: Encode a batch of images using a tiled encoder.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用瓦片编码器对一批图像进行编码。
- en: When this option is enabled, the VAE will split the input tensor into tiles
    to compute encoding in several steps. This is useful to keep memory use constant
    regardless of image size. The end result of tiled encoding is different from non-tiled
    encoding because each tile uses a different encoder. To avoid tiling artifacts,
    the tiles overlap and are blended together to form a smooth output. You may still
    see tile-sized changes in the output, but they should be much less noticeable.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用此选项时，VAE将把输入张量分割成多个瓦片，以几个步骤计算编码。这对于保持内存使用量恒定而不受图像大小影响很有用。瓦片编码的最终结果与非瓦片编码不同，因为每个瓦片使用不同的编码器。为了避免瓦片伪影，瓦片重叠并混合在一起形成平滑的输出。您仍然可能在输出中看到瓦片大小的变化，但它们应该不太明显。
