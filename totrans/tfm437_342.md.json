["```py\n>>> from transformers import Data2VecTextConfig, Data2VecTextModel\n\n>>> # Initializing a Data2VecText facebook/data2vec-text-base style configuration\n>>> configuration = Data2VecTextConfig()\n\n>>> # Initializing a model (with random weights) from the facebook/data2vec-text-base style configuration\n>>> model = Data2VecTextModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import Data2VecAudioConfig, Data2VecAudioModel\n\n>>> # Initializing a Data2VecAudio facebook/data2vec-audio-base-960h style configuration\n>>> configuration = Data2VecAudioConfig()\n\n>>> # Initializing a model (with random weights) from the facebook/data2vec-audio-base-960h style configuration\n>>> model = Data2VecAudioModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import Data2VecVisionConfig, Data2VecVisionModel\n\n>>> # Initializing a Data2VecVision data2vec_vision-base-patch16-224-in22k style configuration\n>>> configuration = Data2VecVisionConfig()\n\n>>> # Initializing a model (with random weights) from the data2vec_vision-base-patch16-224-in22k style configuration\n>>> model = Data2VecVisionModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoProcessor, Data2VecAudioModel\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n>>> dataset = dataset.sort(\"id\")\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n>>> model = Data2VecAudioModel.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n\n>>> # audio file is decoded on the fly\n>>> inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 292, 768]\n```", "```py\n>>> from transformers import AutoFeatureExtractor, Data2VecAudioForAudioFrameClassification\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n>>> dataset = dataset.sort(\"id\")\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n>>> model = Data2VecAudioForAudioFrameClassification.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n\n>>> # audio file is decoded on the fly\n>>> inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=sampling_rate)\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> probabilities = torch.sigmoid(logits[0])\n>>> # labels is a one-hot array of shape (num_frames, num_speakers)\n>>> labels = (probabilities > 0.5).long()\n```", "```py\n>>> from transformers import AutoProcessor, Data2VecAudioForCTC\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n>>> dataset = dataset.sort(\"id\")\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n>>> model = Data2VecAudioForCTC.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n\n>>> # audio file is decoded on the fly\n>>> inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n>>> predicted_ids = torch.argmax(logits, dim=-1)\n\n>>> # transcribe speech\n>>> transcription = processor.batch_decode(predicted_ids)\n>>> transcription[0]\n'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'\n\n>>> inputs[\"labels\"] = processor(text=dataset[0][\"text\"], return_tensors=\"pt\").input_ids\n\n>>> # compute loss\n>>> loss = model(**inputs).loss\n>>> round(loss.item(), 2)\n66.95\n```"]