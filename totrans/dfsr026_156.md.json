["```py\n( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: KarrasDiffusionSchedulers safety_checker: StableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor image_encoder: Optional = None requires_safety_checker: bool = True )\n```", "```py\n( prompt: Union = None height: Optional = None width: Optional = None num_inference_steps: int = 50 guidance_scale: float = 7.5 sag_scale: float = 0.75 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None ip_adapter_image: Union = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: Optional = 1 cross_attention_kwargs: Optional = None clip_skip: Optional = None ) \u2192 export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionSAGPipeline\n\n>>> pipe = StableDiffusionSAGPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> image = pipe(prompt, sag_scale=0.75).images[0]\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( prompt device num_images_per_prompt do_classifier_free_guidance negative_prompt = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None lora_scale: Optional = None clip_skip: Optional = None )\n```", "```py\n( images: Union nsfw_content_detected: Optional )\n```"]