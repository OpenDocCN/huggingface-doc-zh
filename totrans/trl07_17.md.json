["```py\npython ddpo.py --hf_user_access_token <token>\n```", "```py\n[[image, prompt, prompt_metadata, rewards, reward_metadata], ...]\n\n```", "```py\n# for logging these images to wandb\n\ndef image_outputs_hook(image_data, global_step, accelerate_logger):\n    # For the sake of this example, we only care about the last batch\n    # hence we extract the last element of the list\n    result = {}\n    images, prompts, _, rewards, _ = image_data[-1]\n    for i, image in enumerate(images):\n        pil = Image.fromarray(\n            (image.cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n        )\n        pil = pil.resize((256, 256))\n        result[f\"{prompts[i]:.25} | {rewards[i]:.2f}\"] = [pil]\n    accelerate_logger.log_images(\n        result,\n        step=global_step,\n    )\n\n```", "```py\n\nimport torch\nfrom trl import DefaultDDPOStableDiffusionPipeline\n\npipeline = DefaultDDPOStableDiffusionPipeline(\"metric-space/ddpo-finetuned-sd-model\")\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n# memory optimization\npipeline.vae.to(device, torch.float16)\npipeline.text_encoder.to(device, torch.float16)\npipeline.unet.to(device, torch.float16)\n\nprompts = [\"squirrel\", \"crab\", \"starfish\", \"whale\",\"sponge\", \"plankton\"]\nresults = pipeline(prompts)\n\nfor prompt, image in zip(prompts,results.images):\n    image.save(f\"{prompt}.png\")\n\n```"]