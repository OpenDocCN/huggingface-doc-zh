# 自动类

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto)

在许多情况下，您想要使用的架构可以从您提供给`from_pretrained()`方法的预训练模型的名称或路径中猜出。AutoClasses在这里为您执行此操作，以便根据预训练权重/配置/词汇的名称/路径自动检索相关模型。

实例化[AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig)、[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)和[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)中的一个将直接创建相关架构的类。例如

```py
model = AutoModel.from_pretrained("bert-base-cased")
```

将创建一个[BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)的实例模型。

每个任务和每个后端（PyTorch、TensorFlow或Flax）都有一个`AutoModel`类。

## 扩展自动类

每个自动类都有一个方法可以用来扩展您的自定义类。例如，如果您定义了一个名为`NewModel`的自定义模型类，请确保有一个`NewModelConfig`，然后您可以像这样将它们添加到自动类中：

```py
from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)
```

然后您就可以像通常一样使用自动类了！

如果您的`NewModelConfig`是[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的子类，请确保其`model_type`属性设置为注册配置时使用的相同键（这里是`"new-model"`）。

同样，如果您的`NewModel`是[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)的子类，请确保其`config_class`属性设置为注册模型时使用的相同类（这里是`NewModelConfig`）。

## AutoConfig

### `class transformers.AutoConfig`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L975)

```py
( )
```

这是一个通用的配置类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained)类方法创建时，将实例化为库的配置类之一。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L998)

```py
( pretrained_model_name_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型配置的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained)方法保存的配置文件，或者[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)方法，例如 `./my_model_directory/`。

    +   一个保存的配置JSON *文件*的路径或url，例如 `./my_model_directory/configuration.json`。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，并覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求上使用。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `return_unused_kwargs`（`bool`，*可选*，默认为`False`）— 如果为`False`，则此函数仅返回最终配置对象。

    如果为`True`，则此函数返回一个`Tuple(config, unused_kwargs)`，其中*unused_kwargs*是一个字典，由那些键/值对组成，其键不是配置属性：即`kwargs`的一部分，未被用于更新`config`且被忽略的部分。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `kwargs`（附加关键字参数，*可选*）— kwargs中任何键的值，其为配置属性，将用于覆盖加载的值。关于键/值对中键不是配置属性的行为由`return_unused_kwargs`关键字参数控制。

从预训练模型配置中实例化库的配置类之一。

实例化的配置类是根据加载的配置对象的`model_type`属性选择的，或者当它缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `albert` — [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)（ALBERT模型）

+   `align` — [AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)（ALIGN模型）

+   `altclip` — [AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)（AltCLIP模型）

+   `audio-spectrogram-transformer` — [ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)（音频频谱变换器模型）

+   `autoformer` — [AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)（Autoformer模型）

+   `bark` — [BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)（Bark模型）

+   `bart` — [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)（BART模型）

+   `beit` — [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)（BEiT模型）

+   `bert` — [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)（BERT模型）

+   `bert-generation` — [BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)（Bert生成模型）

+   `big_bird` — [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)（BigBird模型）

+   `bigbird_pegasus` — [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)（BigBird-Pegasus模型）

+   `biogpt` — [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)（BioGpt模型）

+   `bit` — [BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)（BiT模型）

+   `blenderbot` — [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)（Blenderbot模型）

+   `blenderbot-small` — [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)（BlenderbotSmall模型）

+   `blip` — [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig) (BLIP 模型)

+   `blip-2` — [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config) (BLIP-2 模型)

+   `bloom` — [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig) (BLOOM 模型)

+   `bridgetower` — [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig) (BridgeTower 模型)

+   `bros` — [BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig) (BROS 模型)

+   `camembert` — [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) (CamemBERT 模型)

+   `canine` — [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig) (CANINE 模型)

+   `chinese_clip` — [ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig) (Chinese-CLIP 模型)

+   `clap` — [ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig) (CLAP 模型)

+   `clip` — [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig) (CLIP 模型)

+   `clip_vision_model` — [CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig) (CLIPVisionModel 模型)

+   `clipseg` — [CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig) (CLIPSeg 模型)

+   `clvp` — [ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig) (CLVP 模型)

+   `code_llama` — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig) (CodeLlama 模型)

+   `codegen` — [CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig) (CodeGen 模型)

+   `conditional_detr` — [ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig) (Conditional DETR 模型)

+   `convbert` — [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) (ConvBERT 模型)

+   `convnext` — [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig) (ConvNeXT 模型)

+   `convnextv2` — [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config) (ConvNeXTV2 模型)

+   `cpmant` — [CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig) (CPM-Ant 模型)

+   `ctrl` — [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig) (CTRL 模型)

+   `cvt` — [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig) (CvT 模型)

+   `data2vec-audio` — [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig) (Data2VecAudio 模型)

+   `data2vec-text` — [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig) (Data2VecText 模型)

+   `data2vec-vision` — [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig) (Data2VecVision 模型)

+   `deberta` — [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) (DeBERTa-v2 模型)

+   `decision_transformer` — [DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig) (Decision Transformer 模型)

+   `deformable_detr` — [DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig) (Deformable DETR 模型)

+   `deit` — [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig) (DeiT 模型)

+   `deta` — [DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig) (DETA 模型)

+   `detr` — [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig) (DETR 模型)

+   `dinat` — [DinatConfig](/docs/transformers/v4.37.2/zh/model_doc/dinat#transformers.DinatConfig) (DiNAT 模型)

+   `dinov2` — [Dinov2Config](/docs/transformers/v4.37.2/zh/model_doc/dinov2#transformers.Dinov2Config) (DINOv2 模型)

+   `distilbert` — [DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig) (DistilBERT 模型)

+   `donut-swin` — [DonutSwinConfig](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutSwinConfig) (DonutSwin 模型)

+   `dpr` — [DPRConfig](/docs/transformers/v4.37.2/zh/model_doc/dpr#transformers.DPRConfig) (DPR 模型)

+   `dpt` — [DPTConfig](/docs/transformers/v4.37.2/zh/model_doc/dpt#transformers.DPTConfig) (DPT 模型)

+   `efficientformer` — [EfficientFormerConfig](/docs/transformers/v4.37.2/zh/model_doc/efficientformer#transformers.EfficientFormerConfig) (EfficientFormer 模型)

+   `efficientnet` — [EfficientNetConfig](/docs/transformers/v4.37.2/zh/model_doc/efficientnet#transformers.EfficientNetConfig) (EfficientNet 模型)

+   `electra` — [ElectraConfig](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraConfig) (ELECTRA 模型)

+   `encodec` — [EncodecConfig](/docs/transformers/v4.37.2/zh/model_doc/encodec#transformers.EncodecConfig) (EnCodec 模型)

+   `encoder-decoder` — [EncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/encoder-decoder#transformers.EncoderDecoderConfig) (编码器解码器模型)

+   `ernie` — [ErnieConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieConfig) (ERNIE 模型)

+   `ernie_m` — [ErnieMConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie_m#transformers.ErnieMConfig) (ErnieM 模型)

+   `esm` — [EsmConfig](/docs/transformers/v4.37.2/zh/model_doc/esm#transformers.EsmConfig) (ESM 模型)

+   `falcon` — [FalconConfig](/docs/transformers/v4.37.2/zh/model_doc/falcon#transformers.FalconConfig) (Falcon 模型)

+   `fastspeech2_conformer` — [FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/zh/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig) (FastSpeech2Conformer 模型)

+   `flaubert` — [FlaubertConfig](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.FlaubertConfig) (FlauBERT 模型)

+   `flava` — [FlavaConfig](/docs/transformers/v4.37.2/zh/model_doc/flava#transformers.FlavaConfig) (FLAVA 模型)

+   `fnet` — [FNetConfig](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetConfig) (FNet 模型)

+   `focalnet` — [FocalNetConfig](/docs/transformers/v4.37.2/zh/model_doc/focalnet#transformers.FocalNetConfig) (FocalNet 模型)

+   `fsmt` — [FSMTConfig](/docs/transformers/v4.37.2/zh/model_doc/fsmt#transformers.FSMTConfig) (FairSeq 机器翻译模型)

+   `funnel` — [FunnelConfig](/docs/transformers/v4.37.2/zh/model_doc/funnel#transformers.FunnelConfig) (Funnel Transformer 模型)

+   `fuyu` — [FuyuConfig](/docs/transformers/v4.37.2/zh/model_doc/fuyu#transformers.FuyuConfig) (Fuyu 模型)

+   `git` — [GitConfig](/docs/transformers/v4.37.2/zh/model_doc/git#transformers.GitConfig) (GIT 模型)

+   `glpn` — [GLPNConfig](/docs/transformers/v4.37.2/zh/model_doc/glpn#transformers.GLPNConfig) (GLPN 模型)

+   `gpt-sw3` — [GPT2Config](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.GPT2Config) (GPT-Sw3 模型)

+   `gpt2` — [GPT2Config](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.GPT2Config) (OpenAI GPT-2 模型)

+   `gpt_bigcode` — [GPTBigCodeConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig) (GPTBigCode 模型)

+   `gpt_neo` — [GPTNeoConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_neo#transformers.GPTNeoConfig) (GPT Neo 模型)

+   `gpt_neox` — [GPTNeoXConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_neox#transformers.GPTNeoXConfig) (GPT NeoX 模型)

+   `gpt_neox_japanese` — [GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig) (GPT NeoX 日语模型)

+   `gptj` — [GPTJConfig](/docs/transformers/v4.37.2/zh/model_doc/gptj#transformers.GPTJConfig) (GPT-J 模型)

+   `gptsan-japanese` — [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)（GPTSAN-japanese 模型）

+   `graphormer` — [GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)（Graphormer 模型）

+   `groupvit` — [GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)（GroupViT 模型）

+   `hubert` — [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)（Hubert 模型）

+   `ibert` — [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)（I-BERT 模型）

+   `idefics` — [IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)（IDEFICS 模型）

+   `imagegpt` — [ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)（ImageGPT 模型）

+   `informer` — [InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)（Informer 模型）

+   `instructblip` — [InstructBlipConfig](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipConfig)（InstructBLIP 模型）

+   `jukebox` — [JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)（Jukebox 模型）

+   `kosmos-2` — [Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)（KOSMOS-2 模型）

+   `layoutlm` — [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)（LayoutLM 模型）

+   `layoutlmv2` — [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)（LayoutLMv2 模型）

+   `layoutlmv3` — [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)（LayoutLMv3 模型）

+   `led` — [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)（LED 模型）

+   `levit` — [LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)（LeViT 模型）

+   `lilt` — [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)（LiLT 模型）

+   `llama` — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)（LLaMA 模型）

+   `llava` — [LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)（LLaVa 模型）

+   `longformer` — [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)（Longformer 模型）

+   `longt5` — [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)（LongT5 模型）

+   `luke` — [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)（LUKE 模型）

+   `lxmert` — [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)（LXMERT 模型）

+   `m2m_100` — [M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)（M2M100 模型）

+   `marian` — [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)（Marian 模型）

+   `markuplm` — [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)（MarkupLM 模型）

+   `mask2former` — [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)（Mask2Former 模型）

+   `maskformer` — [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)（MaskFormer 模型）

+   `maskformer-swin` — `MaskFormerSwinConfig`（MaskFormerSwin 模型）

+   `mbart` — [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)（mBART 模型）

+   `mctct` — [MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)（M-CTC-T 模型）

+   `mega` — [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)（MEGA 模型）

+   `megatron-bert` — [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)（Megatron-BERT 模型）

+   `mgp-str` — [MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig) (MGP-STR 模型)

+   `mistral` — [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig) (Mistral 模型)

+   `mixtral` — [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig) (Mixtral 模型)

+   `mobilebert` — [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) (MobileBERT 模型)

+   `mobilenet_v1` — [MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config) (MobileNetV1 模型)

+   `mobilenet_v2` — [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config) (MobileNetV2 模型)

+   `mobilevit` — [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig) (MobileViT 模型)

+   `mobilevitv2` — [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config) (MobileViTV2 模型)

+   `mpnet` — [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) (MPNet 模型)

+   `mpt` — [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) (MPT 模型)

+   `mra` — [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) (MRA 模型)

+   `mt5` — [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) (MT5 模型)

+   `musicgen` — [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig) (MusicGen 模型)

+   `mvp` — [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) (MVP 模型)

+   `nat` — [NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig) (NAT 模型)

+   `nezha` — [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) (Nezha 模型)

+   `nllb-moe` — [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig) (NLLB-MOE 模型)

+   `nougat` — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig) (Nougat 模型)

+   `nystromformer` — [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) (Nyströmformer 模型)

+   `oneformer` — [OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig) (OneFormer 模型)

+   `open-llama` — [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig) (OpenLlama 模型)

+   `openai-gpt` — [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) (OpenAI GPT 模型)

+   `opt` — [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) (OPT 模型)

+   `owlv2` — [Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config) (OWLv2 模型)

+   `owlvit` — [OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig) (OWL-ViT 模型)

+   `patchtsmixer` — [PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig) (PatchTSMixer 模型)

+   `patchtst` — [PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig) (PatchTST 模型)

+   `pegasus` — [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) (Pegasus 模型)

+   `pegasus_x` — [PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig) (PEGASUS-X 模型)

+   `perceiver` — [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig) (Perceiver 模型)

+   `persimmon` — [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig) (Persimmon 模型)

+   `phi` — [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig) (Phi 模型)

+   `pix2struct` — [Pix2StructConfig](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructConfig) (Pix2Struct 模型)

+   `plbart` — [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig) (PLBart 模型)

+   `poolformer` — [PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig) (PoolFormer 模型)

+   `pop2piano` — [Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig) (Pop2Piano 模型)

+   `prophetnet` — [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig) (ProphetNet 模型)

+   `pvt` — [PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig) (PVT 模型)

+   `qdqbert` — [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) (QDQBert 模型)

+   `qwen2` — [Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config) (Qwen2 模型)

+   `rag` — [RagConfig](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagConfig) (RAG 模型)

+   `realm` — [RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig) (REALM 模型)

+   `reformer` — [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig) (Reformer 模型)

+   `regnet` — [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) (RegNet 模型)

+   `rembert` — [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) (RemBERT 模型)

+   `resnet` — [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) (ResNet 模型)

+   `retribert` — [RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig) (RetriBERT 模型)

+   `roberta` — [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) (RoCBert 模型)

+   `roformer` — [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) (RoFormer 模型)

+   `rwkv` — [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig) (RWKV 模型)

+   `sam` — [SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig) (SAM 模型)

+   `seamless_m4t` — [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig) (SeamlessM4T 模型)

+   `seamless_m4t_v2` — [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config) (SeamlessM4Tv2 模型)

+   `segformer` — [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig) (SegFormer 模型)

+   `sew` — [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig) (SEW 模型)

+   `sew-d` — [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig) (SEW-D 模型)

+   `siglip` — [SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig) (SigLIP 模型)

+   `siglip_vision_model` — [SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig) (SiglipVisionModel 模型)

+   `speech-encoder-decoder` — [SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig) (Speech 编码器解码器模型)

+   `speech_to_text` — [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig) (Speech2Text 模型)

+   `speech_to_text_2` — [Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config) (Speech2Text2 模型)

+   `speecht5` — [SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config) (SpeechT5 模型)

+   `splinter` — [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig) (Splinter 模型)

+   `squeezebert` — [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) (SqueezeBERT 模型)

+   `swiftformer` — [SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig) (SwiftFormer 模型)

+   `swin` — [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig) (Swin Transformer 模型)

+   `swin2sr` — [Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig) (Swin2SR 模型)

+   `swinv2` — [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config) (Swin Transformer V2 模型)

+   `switch_transformers` — [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig) (SwitchTransformers 模型)

+   `t5` — [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) (T5 模型)

+   `table-transformer` — [TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig) (Table Transformer 模型)

+   `tapas` — [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) (TAPAS 模型)

+   `time_series_transformer` — [TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig) (Time Series Transformer 模型)

+   `timesformer` — [TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig) (TimeSformer 模型)

+   `timm_backbone` — `TimmBackboneConfig` (TimmBackbone 模型)

+   `trajectory_transformer` — [TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig) (Trajectory Transformer 模型)

+   `transfo-xl` — [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) (Transformer-XL 模型)

+   `trocr` — [TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig) (TrOCR 模型)

+   `tvlt` — [TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig) (TVLT 模型)

+   `tvp` — [TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig) (TVP 模型)

+   `umt5` — [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config) (UMT5 模型)

+   `unispeech` — [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig) (UniSpeech 模型)

+   `unispeech-sat` — [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) (UniSpeechSat 模型)

+   `univnet` — [UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig) (UnivNet 模型)

+   `upernet` — [UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig) (UPerNet 模型)

+   `van` — [VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig) (VAN 模型)

+   `videomae` — [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig) (VideoMAE 模型)

+   `vilt` — [ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig) (ViLT 模型)

+   `vipllava` — [VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig) (VipLlava 模型)

+   `vision-encoder-decoder` — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig) (Vision Encoder decoder 模型)

+   `vision-text-dual-encoder` — [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig) (VisionTextDualEncoder 模型)

+   `visual_bert` — [VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)（VisualBERT模型）

+   `vit` — [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)（ViT模型）

+   `vit_hybrid` — [ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)（ViT混合模型）

+   `vit_mae` — [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)（ViTMAE模型）

+   `vit_msn` — [ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)（ViTMSN模型）

+   `vitdet` — [VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)（VitDet模型）

+   `vitmatte` — [VitMatteConfig](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteConfig)（ViTMatte模型）

+   `vits` — [VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)（VITS模型）

+   `vivit` — [VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)（ViViT模型）

+   `wav2vec2` — [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)（Wav2Vec2模型）

+   `wav2vec2-bert` — [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)（Wav2Vec2-BERT模型）

+   `wav2vec2-conformer` — [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)（Wav2Vec2-Conformer模型）

+   `wavlm` — [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)（WavLM模型）

+   `whisper` — [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)（Whisper模型）

+   `xclip` — [XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)（X-CLIP模型）

+   `xglm` — [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)（XGLM模型）

+   `xlm` — [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)（XLM模型）

+   `xlm-prophetnet` — [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)（XLM-ProphetNet模型）

+   `xlm-roberta` — [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)（XLM-RoBERTa模型）

+   `xlm-roberta-xl` — [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)（XLM-RoBERTa-XL模型）

+   `xlnet` — [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)（XLNet模型）

+   `xmod` — [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)（X-MOD模型）

+   `yolos` — [YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)（YOLOS模型）

+   `yoso` — [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)（YOSO模型）

示例：

```py
>>> from transformers import AutoConfig

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-uncased")

>>> # Download configuration from huggingface.co (user-uploaded) and cache.
>>> config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

>>> # If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
>>> config = AutoConfig.from_pretrained("./test/bert_saved_model/")

>>> # Load a specific configuration file.
>>> config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

>>> # Change some config attributes when loading a pretrained config.
>>> config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
>>> config.output_attentions
True

>>> config, unused_kwargs = AutoConfig.from_pretrained(
...     "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
... )
>>> config.output_attentions
True

>>> unused_kwargs
{'foo': False}
```

#### `register`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L1138)

```py
( model_type config exist_ok = False )
```

参数

+   `model_type`（`str`）— 模型类型，如“bert”或“gpt”。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 要注册的配置。

为这个类注册一个新的配置。

## AutoTokenizer

### `class transformers.AutoTokenizer`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L616)

```py
( )
```

这是一个通用的分词器类，当使用[AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained)类方法创建时，将实例化为库中的分词器类之一。

这个类不能直接使用`__init__()`实例化（会报错）。

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L630)

```py
( pretrained_model_name_or_path *inputs **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：

    +   一个字符串，预定义的分词器的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   包含分词器所需的词汇文件的*目录*路径，例如使用[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)方法保存的，例如，`./my_model_directory/`。

    +   如果且仅当分词器只需要单个词汇文件（如Bert或XLNet）时，可以是单个保存的词汇文件的路径或url，例如：`./my_model_directory/vocab.txt`。（不适用于所有派生类）

+   `inputs`（额外的位置参数，*可选*）- 将传递给分词器`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 用于确定要实例化的分词器类的配置对象。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不应使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，并覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）- 要按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `subfolder`（`str`，*可选*）- 如果相关文件位于huggingface.co上模型存储库的子文件夹中（例如对于facebook/rag-token-base），请在此处指定。

+   `use_fast`（`bool`，*可选*，默认为`True`）- 如果给定模型支持，使用[快速基于Rust的分词器](https://huggingface.co/docs/tokenizers/index)。如果给定模型不支持快速分词器，则将返回普通的基于Python的分词器。

+   `tokenizer_type`（`str`，*可选*）- 要加载的分词器类型。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地计算机上执行Hub上存在的代码。

+   `kwargs`（额外的关键字参数，*可选*）- 将传递给分词器`__init__()`方法。可用于设置特殊标记，如`bos_token`、`eos_token`、`unk_token`、`sep_token`、`pad_token`、`cls_token`、`mask_token`、`additional_special_tokens`。有关更多详细信息，请参阅`__init__()`中的参数。

从预训练模型词汇实例化库中的一个分词器类。

要实例化的分词器类是根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载）选择的，或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退选择：

+   `albert` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer) 或 [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast) (ALBERT 模型)

+   `align` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (ALIGN 模型)

+   `bark` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (Bark 模型)

+   `bart` — [BartTokenizer](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizer) 或 [BartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizerFast) (BART 模型)

+   `barthez` — [BarthezTokenizer](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizer) 或 [BarthezTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizerFast) (BARThez 模型)

+   `bartpho` — [BartphoTokenizer](/docs/transformers/v4.37.2/en/model_doc/bartpho#transformers.BartphoTokenizer) (BARTpho 模型)

+   `bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (BERT 模型)

+   `bert-generation` — [BertGenerationTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationTokenizer) (Bert Generation 模型)

+   `bert-japanese` — [BertJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer) (BertJapanese 模型)

+   `bertweet` — [BertweetTokenizer](/docs/transformers/v4.37.2/en/model_doc/bertweet#transformers.BertweetTokenizer) (BERTweet 模型)

+   `big_bird` — [BigBirdTokenizer](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizer) 或 [BigBirdTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizerFast) (BigBird 模型)

+   `bigbird_pegasus` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer) 或 [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast) (BigBird-Pegasus 模型)

+   `biogpt` — [BioGptTokenizer](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptTokenizer) (BioGpt 模型)

+   `blenderbot` — [BlenderbotTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizer) 或 [BlenderbotTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast) (Blenderbot 模型)

+   `blenderbot-small` — [BlenderbotSmallTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer) (BlenderbotSmall 模型)

+   `blip` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (BLIP 模型)

+   `blip-2` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (BLIP-2 模型)

+   `bloom` — [BloomTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomTokenizerFast) (BLOOM 模型)

+   `bridgetower` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (BridgeTower 模型)

+   `bros` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (BROS 模型)

+   `byt5` — [ByT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/byt5#transformers.ByT5Tokenizer) (ByT5 模型)

+   `camembert` — [CamembertTokenizer](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizer) 或 [CamembertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizerFast) (CamemBERT 模型)

+   `canine` — [CanineTokenizer](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineTokenizer) (CANINE 模型)

+   `chinese_clip` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (Chinese-CLIP 模型)

+   `clap` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (CLAP 模型)

+   `clip` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast) (CLIP 模型)

+   `clipseg` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast) (CLIPSeg 模型)

+   `clvp` — [ClvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpTokenizer) (CLVP 模型)

+   `code_llama` — [CodeLlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizer) 或 [CodeLlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizerFast) (CodeLlama 模型)

+   `codegen` — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer) 或 [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast) (CodeGen 模型)

+   `convbert` — [ConvBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizer) 或 [ConvBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizerFast) (ConvBERT 模型)

+   `cpm` — [CpmTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizer) 或 [CpmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizerFast) (CPM 模型)

+   `cpmant` — [CpmAntTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntTokenizer) (CPM-Ant 模型)

+   `ctrl` — [CTRLTokenizer](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLTokenizer) (CTRL 模型)

+   `data2vec-audio` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Data2VecAudio 模型)

+   `data2vec-text` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (Data2VecText 模型)

+   `deberta` — [DebertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizer) 或 [DebertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizerFast) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer) 或 [DebertaV2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizer) 或 [DistilBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizerFast) (DistilBERT 模型)

+   `dpr` — [DPRQuestionEncoderTokenizer](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer) 或 [DPRQuestionEncoderTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast) (DPR 模型)

+   `electra` — [ElectraTokenizer](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizer) 或 [ElectraTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizerFast) (ELECTRA 模型)

+   `ernie` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (ERNIE 模型)

+   `ernie_m` — [ErnieMTokenizer](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMTokenizer) (ErnieM 模型)

+   `esm` — [EsmTokenizer](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmTokenizer) (ESM 模型)

+   `falcon` — [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast) (Falcon 模型)

+   `fastspeech2_conformer` — (FastSpeech2Conformer 模型)

+   `flaubert` — [FlaubertTokenizer](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertTokenizer) (FlauBERT 模型)

+   `fnet` — [FNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizer) 或 [FNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizerFast) (FNet 模型)

+   `fsmt` — [FSMTTokenizer](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTTokenizer) (FairSeq 机器翻译模型)

+   `funnel` — [FunnelTokenizer](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizer) 或 [FunnelTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizerFast) (Funnel Transformer 模型)

+   `git` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (GIT 模型)

+   `gpt-sw3` — [GPTSw3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt-sw3#transformers.GPTSw3Tokenizer) (GPT-Sw3 模型)

+   `gpt2` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (OpenAI GPT-2 模型)

+   `gpt_bigcode` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (GPTBigCode 模型)

+   `gpt_neo` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (GPT Neo 模型)

+   `gpt_neox` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast) (GPT NeoX 模型)

+   `gpt_neox_japanese` — [GPTNeoXJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer) (GPT NeoX Japanese 模型)

+   `gptj` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (GPT-J 模型)

+   `gptsan-japanese` — [GPTSanJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseTokenizer) (GPTSAN-japanese 模型)

+   `groupvit` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast) (GroupViT 模型)

+   `herbert` — [HerbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizer) 或 [HerbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizerFast) (HerBERT 模型)

+   `hubert` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Hubert 模型)

+   `ibert` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (I-BERT 模型)

+   `idefics` — [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast) (IDEFICS 模型)

+   `instructblip` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (InstructBLIP 模型)

+   `jukebox` — [JukeboxTokenizer](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxTokenizer) (Jukebox 模型)

+   `kosmos-2` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer) 或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast) (KOSMOS-2 模型)

+   `layoutlm` — [LayoutLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizer) 或 [LayoutLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast) (LayoutLM 模型)

+   `layoutlmv2` — [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer) 或 [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer) 或 [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast) (LayoutLMv3 模型)

+   `layoutxlm` — [LayoutXLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer) 或 [LayoutXLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast) (LayoutXLM 模型)

+   `led` — [LEDTokenizer](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizer) 或 [LEDTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizerFast) (LED 模型)

+   `lilt` — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer) 或 [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast) (LiLT 模型)

+   `llama` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer) 或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast) (LLaMA 模型)

+   `llava` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer) 或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast) (LLaVa 模型)

+   `longformer` — [LongformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizer) 或 [LongformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizerFast) (Longformer 模型)

+   `longt5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast) (LongT5 模型)

+   `luke` — [LukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeTokenizer) (LUKE 模型)

+   `lxmert` — [LxmertTokenizer](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizer) 或 [LxmertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizerFast) (LXMERT 模型)

+   `m2m_100` — [M2M100Tokenizer](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Tokenizer) (M2M100 模型)

+   `marian` — [MarianTokenizer](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianTokenizer) (Marian 模型)

+   `mbart` — [MBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizer) 或 [MBartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizerFast) (mBART 模型)

+   `mbart50` — [MBart50Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50Tokenizer) 或 [MBart50TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50TokenizerFast) (mBART-50 模型)

+   `mega` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (MEGA 模型)

+   `megatron-bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (Megatron-BERT 模型)

+   `mgp-str` — [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer) (MGP-STR 模型)

+   `mistral` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer) 或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast) (Mistral 模型)

+   `mixtral` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer) 或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast) (Mixtral 模型)

+   `mluke` — [MLukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/mluke#transformers.MLukeTokenizer) (mLUKE 模型)

+   `mobilebert` — [MobileBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizer) 或 [MobileBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast) (MobileBERT 模型)

+   `mpnet` — [MPNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizer) 或 [MPNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizerFast) (MPNet 模型)

+   `mpt` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast) (MPT 模型)

+   `mra` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (MRA 模型)

+   `mt5` — [MT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [MT5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast) (MT5 模型)

+   `musicgen` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast) (MusicGen 模型)

+   `mvp` — [MvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizer) 或 [MvpTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizerFast) (MVP 模型)

+   `nezha` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (Nezha 模型)

+   `nllb` — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer) 或 [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast) (NLLB 模型)

+   `nllb-moe` — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer) 或 [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast) (NLLB-MOE 模型)

+   `nystromformer` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer) 或 [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)（Nyströmformer 模型）

+   `oneformer` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)（OneFormer 模型）

+   `openai-gpt` — [OpenAIGPTTokenizer](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer) 或 [OpenAIGPTTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast)（OpenAI GPT 模型）

+   `opt` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer) 或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)（OPT 模型）

+   `owlv2` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)（OWLv2 模型）

+   `owlvit` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)（OWL-ViT 模型）

+   `pegasus` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer) 或 [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)（Pegasus 模型）

+   `pegasus_x` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer) 或 [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)（PEGASUS-X 模型）

+   `perceiver` — [PerceiverTokenizer](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverTokenizer)（Perceiver 模型）

+   `persimmon` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer) 或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)（Persimmon 模型）

+   `phi` — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer) 或 [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)（Phi 模型）

+   `phobert` — [PhobertTokenizer](/docs/transformers/v4.37.2/en/model_doc/phobert#transformers.PhobertTokenizer)（PhoBERT 模型）

+   `pix2struct` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)（Pix2Struct 模型）

+   `plbart` — [PLBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartTokenizer)（PLBart 模型）

+   `prophetnet` — [ProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetTokenizer)（ProphetNet 模型）

+   `qdqbert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)（QDQBert 模型）

+   `qwen2` — [Qwen2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Tokenizer) 或 [Qwen2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2TokenizerFast)（Qwen2 模型）

+   `rag` — [RagTokenizer](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagTokenizer)（RAG 模型）

+   `realm` — [RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer) 或 [RealmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizerFast)（REALM 模型）

+   `reformer` — [ReformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizer) 或 [ReformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizerFast) (Reformer 模型)

+   `rembert` — [RemBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizer) 或 [RemBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizerFast) (RemBERT 模型)

+   `retribert` — [RetriBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizer) 或 [RetriBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizerFast) (RetriBERT 模型)

+   `roberta` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer) 或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertTokenizer) (RoCBert 模型)

+   `roformer` — [RoFormerTokenizer](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizer) 或 [RoFormerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizerFast) (RoFormer 模型)

+   `rwkv` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast) (RWKV 模型)

+   `seamless_m4t` — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer) 或 [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast) (SeamlessM4T 模型)

+   `seamless_m4t_v2` — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer) 或 [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast) (SeamlessM4Tv2 模型)

+   `siglip` — [SiglipTokenizer](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipTokenizer) (SigLIP 模型)

+   `speech_to_text` — [Speech2TextTokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer) (Speech2Text 模型)

+   `speech_to_text_2` — [Speech2Text2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer) (Speech2Text2 模型)

+   `speecht5` — [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer) (SpeechT5 模型)

+   `splinter` — [SplinterTokenizer](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizer) 或 [SplinterTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizerFast) (Splinter 模型)

+   `squeezebert` — [SqueezeBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer) 或 [SqueezeBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast) (SqueezeBERT 模型)

+   `switch_transformers` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast) (SwitchTransformers 模型)

+   `t5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast) (T5 模型)

+   `tapas` — [TapasTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasTokenizer) (TAPAS 模型)

+   `tapex` — [TapexTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapex#transformers.TapexTokenizer) (TAPEX 模型)

+   `transfo-xl` — [TransfoXLTokenizer](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer) (Transformer-XL 模型)

+   `tvp` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (TVP 模型)

+   `umt5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer) 或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast) (UMT5 模型)

+   `vilt` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (ViLT 模型)

+   `vipllava` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer) 或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast) (VipLlava 模型)

+   `visual_bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer) 或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast) (VisualBERT 模型)

+   `vits` — [VitsTokenizer](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsTokenizer) (VITS 模型)

+   `wav2vec2` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Wav2Vec2 模型)

+   `wav2vec2-bert` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Wav2Vec2-BERT 模型)

+   `wav2vec2-conformer` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Wav2Vec2-Conformer 模型)

+   `wav2vec2_phoneme` — [Wav2Vec2PhonemeCTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer) (Wav2Vec2Phoneme 模型)

+   `whisper` — [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer) 或 [WhisperTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizerFast) (Whisper 模型)

+   `xclip` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer) 或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast) (X-CLIP 模型)

+   `xglm` — [XGLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizer) 或 [XGLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizerFast) (XGLM 模型)

+   `xlm` — [XLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMTokenizer) (XLM 模型)

+   `xlm-prophetnet` — [XLMProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer) (XLM-ProphetNet 模型)

+   `xlm-roberta` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer) 或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast) (XLM-RoBERTa 模型)

+   `xlm-roberta-xl` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer) 或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast) (XLM-RoBERTa-XL 模型)

+   `xlnet` — [XLNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizer) 或 [XLNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizerFast) (XLNet 模型)

+   `xmod` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer) 或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast) (X-MOD 模型)

+   `yoso` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer) 或 [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)（YOSO 模型）

示例：

```py
>>> from transformers import AutoTokenizer

>>> # Download vocabulary from huggingface.co and cache.
>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

>>> # Download vocabulary from huggingface.co (user-uploaded) and cache.
>>> tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

>>> # If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
>>> # tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

>>> # Download vocabulary from huggingface.co and define model-specific arguments
>>> tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)
```

#### `register`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L847)

```py
( config_class slow_tokenizer_class = None fast_tokenizer_class = None exist_ok = False )
```

参数

+   `config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 与要注册的模型对应的配置。

+   `slow_tokenizer_class` (`PretrainedTokenizer`, *optional*) — 要注册的慢速分词器。

+   `fast_tokenizer_class` (`PretrainedTokenizerFast`, *optional*) — 要注册的快速分词器。

在此映射中注册一个新的分词器。

## AutoFeatureExtractor

### `class transformers.AutoFeatureExtractor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L239)

```py
( )
```

这是一个通用的特征提取器类，在使用 [AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained) 类方法创建时，将实例化为库的特征提取器类之一。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L253)

```py
( pretrained_model_name_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 这可以是：

    +   一个字符串，预训练特征提取器的 *模型 ID*，托管在 huggingface.co 上的模型存储库中。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained) 方法保存的特征提取器文件的 *目录* 路径，例如 `./my_model_directory/`。

    +   一个保存的特征提取器 JSON *文件* 的路径或 URL，例如 `./my_model_directory/preprocessor_config.json`。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预训练模型特征提取器应该缓存在其中的目录路径，如果不想使用标准缓存。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载特征提取器文件并覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如 `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `token` (`str` 或 *bool*, *optional*) — 用作远程文件的 HTTP 令牌授权的令牌。如果为 `True`，将使用运行 `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `return_unused_kwargs` (`bool`, *optional*, defaults to `False`) — 如果为 `False`，则此函数仅返回最终的特征提取器对象。如果为 `True`，则此函数返回一个 `Tuple(feature_extractor, unused_kwargs)`，其中 *unused_kwargs* 是一个字典，包含那些未被用于更新 `feature_extractor` 的键/值对：即 `kwargs` 的一部分，未被用于更新 `feature_extractor` 且被忽略的部分。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。只有对您信任的存储库以及您已阅读代码的情况下，才应将此选项设置为 `True`，因为它将在本地机器上执行 Hub 上存在的代码。

+   `kwargs` (`Dict[str, Any]`, *optional*) — 任何键为特征提取器属性的 kwargs 中的值将用于覆盖加载的值。关于键/值对中键不是特征提取器属性的行为由 `return_unused_kwargs` 关键参数控制。

从预训练模型词汇表中实例化库中的特征提取器类之一。

要实例化的特征提取器类是根据配置对象的 `model_type` 属性（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载）选择的，或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `audio-spectrogram-transformer` — [ASTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/audio-spectrogram-transformer#transformers.ASTFeatureExtractor) (Audio Spectrogram Transformer 模型)

+   `beit` — [BeitFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/beit#transformers.BeitFeatureExtractor) (BEiT 模型)

+   `chinese_clip` — [ChineseCLIPFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/chinese_clip#transformers.ChineseCLIPFeatureExtractor) (Chinese-CLIP 模型)

+   `clap` — [ClapFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/clap#transformers.ClapFeatureExtractor) (CLAP 模型)

+   `clip` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/clip#transformers.CLIPFeatureExtractor) (CLIP 模型)

+   `clipseg` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/vit#transformers.ViTFeatureExtractor) (CLIPSeg 模型)

+   `clvp` — [ClvpFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/clvp#transformers.ClvpFeatureExtractor) (CLVP 模型)

+   `conditional_detr` — [ConditionalDetrFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor) (Conditional DETR 模型)

+   `convnext` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/convnext#transformers.ConvNextFeatureExtractor) (ConvNeXT 模型)

+   `cvt` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/convnext#transformers.ConvNextFeatureExtractor) (CvT 模型)

+   `data2vec-audio` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Data2VecAudio 模型)

+   `data2vec-vision` — [BeitFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/beit#transformers.BeitFeatureExtractor) (Data2VecVision 模型)

+   `deformable_detr` — [DeformableDetrFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor) (Deformable DETR 模型)

+   `deit` — [DeiTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/deit#transformers.DeiTFeatureExtractor) (DeiT 模型)

+   `detr` — [DetrFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/detr#transformers.DetrFeatureExtractor) (DETR 模型)

+   `dinat` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/vit#transformers.ViTFeatureExtractor) (DiNAT 模型)

+   `donut-swin` — [DonutFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutFeatureExtractor) (DonutSwin 模型)

+   `dpt` — [DPTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/dpt#transformers.DPTFeatureExtractor) (DPT 模型)

+   `encodec` — [EncodecFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/encodec#transformers.EncodecFeatureExtractor) (EnCodec 模型)

+   `flava` — [FlavaFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/flava#transformers.FlavaFeatureExtractor) (FLAVA 模型)

+   `glpn` — [GLPNFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/glpn#transformers.GLPNFeatureExtractor) (GLPN 模型)

+   `groupvit` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor) (GroupViT 模型)

+   `hubert` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Hubert 模型)

+   `imagegpt` — [ImageGPTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor) (ImageGPT 模型)

+   `layoutlmv2` — [LayoutLMv2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor) (LayoutLMv3 模型)

+   `levit` — [LevitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitFeatureExtractor) (LeViT 模型)

+   `maskformer` — [MaskFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor) (MaskFormer 模型)

+   `mctct` — [MCTCTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTFeatureExtractor) (M-CTC-T 模型)

+   `mobilenet_v1` — [MobileNetV1FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1FeatureExtractor) (MobileNetV1 模型)

+   `mobilenet_v2` — [MobileNetV2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2FeatureExtractor) (MobileNetV2 模型)

+   `mobilevit` — [MobileViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor) (MobileViT 模型)

+   `nat` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (NAT 模型)

+   `owlvit` — [OwlViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor) (OWL-ViT 模型)

+   `perceiver` — [PerceiverFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor) (Perceiver 模型)

+   `poolformer` — [PoolFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor) (PoolFormer 模型)

+   `pop2piano` — [Pop2PianoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoFeatureExtractor) (Pop2Piano 模型)

+   `regnet` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor) (RegNet 模型)

+   `resnet` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor) (ResNet 模型)

+   `seamless_m4t` — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor) (SeamlessM4T 模型)

+   `seamless_m4t_v2` — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor) (SeamlessM4Tv2 模型)

+   `segformer` — [SegformerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerFeatureExtractor) (SegFormer 模型)

+   `sew` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (SEW 模型)

+   `sew-d` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (SEW-D 模型)

+   `speech_to_text` — [Speech2TextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor) (Speech2Text 模型)

+   `speecht5` — [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor) (SpeechT5 模型)

+   `swiftformer` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (SwiftFormer 模型)

+   `swin` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (Swin Transformer 模型)

+   `swinv2` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (Swin Transformer V2 模型)

+   `table-transformer` — [DetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrFeatureExtractor) (Table Transformer 模型)

+   `timesformer` — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor) (TimeSformer 模型)

+   `tvlt` — [TvltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltFeatureExtractor) (TVLT 模型)

+   `unispeech` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (UniSpeech 模型)

+   `unispeech-sat` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (UniSpeechSat 模型)

+   `univnet` — [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor) (UnivNet 模型)

+   `van` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor) (VAN 模型)

+   `videomae` — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor) (VideoMAE 模型)

+   `vilt` — [ViltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltFeatureExtractor) (ViLT 模型)

+   `vit` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (ViT 模型)

+   `vit_mae` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (ViTMAE 模型)

+   `vit_msn` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor) (ViTMSN 模型)

+   `wav2vec2` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Wav2Vec2 模型)

+   `wav2vec2-bert` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Wav2Vec2-BERT 模型)

+   `wav2vec2-conformer` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Wav2Vec2-Conformer 模型)

+   `wavlm` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (WavLM 模型)

+   `whisper` — [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor) (Whisper 模型)

+   `xclip` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor) (X-CLIP 模型)

+   `yolos` — [YolosFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosFeatureExtractor) (YOLOS 模型)

当您想使用私有模型时，需要传递 `token=True`。

示例：

```py
>>> from transformers import AutoFeatureExtractor

>>> # Download feature extractor from huggingface.co and cache.
>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

>>> # If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
>>> # feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")
```

#### `register`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L388)

```py
( config_class feature_extractor_class exist_ok = False )
```

参数

+   `config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 要注册的模型对应的配置。

+   `feature_extractor_class` (`FeatureExtractorMixin`) — 要注册的特征提取器。

为此类注册一个新的特征提取器。

## AutoImageProcessor

### `class transformers.AutoImageProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L251)

```py
( )
```

这是一个通用的图像处理器类，在使用 [AutoImageProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained) 类方法创建时，将被实例化为库中的图像处理器类之一。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L265)

```py
( pretrained_model_name_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 这可以是：

    +   一个预训练图像处理器的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained) 方法保存的图像处理器文件的 *目录* 路径，例如，`./my_model_directory/`。

    +   一个保存的图像处理器 JSON *文件* 的路径或 URL，例如，`./my_model_directory/preprocessor_config.json`。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选*) — 预下载的预训练模型图像处理器应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载图像处理器文件并覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求上使用。

+   `token` (`str` 或 *bool*, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，将使用运行 `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `return_unused_kwargs` (`bool`, *可选*, 默认为 `False`) — 如果为 `False`，则此函数仅返回最终的图像处理器对象。如果为 `True`，则此函数返回一个 `Tuple(image_processor, unused_kwargs)`，其中 *unused_kwargs* 是一个字典，包含那些键/值对，其键不是图像处理器属性：即 `kwargs` 中未被用于更新 `image_processor` 且被忽略的部分。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `kwargs` (`Dict[str, Any]`, *可选*) — 任何键为图像处理器属性的 kwargs 中的值将用于覆盖加载的值。关于键/值对中键 *不是* 图像处理器属性的行为由 `return_unused_kwargs` 关键字参数控制。

从预训练模型词汇表中实例化库中的一个图像处理器类。

要实例化的图像处理器类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `align` — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor) (ALIGN 模型)

+   `beit` — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor) (BEiT 模型)

+   `bit` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor) (BiT 模型)

+   `blip` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor) (BLIP 模型)

+   `blip-2` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor) (BLIP-2 模型)

+   `bridgetower` — [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor) (BridgeTower 模型)

+   `chinese_clip` — [ChineseCLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPImageProcessor) (Chinese-CLIP 模型)

+   `clip` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (CLIP 模型)

+   `clipseg` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (CLIPSeg 模型)

+   `conditional_detr` — [ConditionalDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrImageProcessor) (Conditional DETR 模型)

+   `convnext` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor) (ConvNeXT 模型)

+   `convnextv2` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor) (ConvNeXTV2 模型)

+   `cvt` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor) (CvT 模型)

+   `data2vec-vision` — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor) (Data2VecVision 模型)

+   `deformable_detr` — [DeformableDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrImageProcessor) (Deformable DETR 模型)

+   `deit` — [DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor) (DeiT 模型)

+   `deta` — [DetaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaImageProcessor) (DETA 模型)

+   `detr` — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor) (DETR 模型)

+   `dinat` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (DiNAT 模型)

+   `dinov2` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor) (DINOv2 模型)

+   `donut-swin` — [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor) (DonutSwin 模型)

+   `dpt` — [DPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTImageProcessor) (DPT 模型)

+   `efficientformer` — [EfficientFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerImageProcessor) (EfficientFormer 模型)

+   `efficientnet` — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor) (EfficientNet 模型)

+   `flava` — [FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor) (FLAVA 模型)

+   `focalnet` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor) (FocalNet 模型)

+   `fuyu` — [FuyuImageProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuImageProcessor) (Fuyu 模型)

+   `git` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (GIT 模型)

+   `glpn` — [GLPNImageProcessor](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNImageProcessor) (GLPN 模型)

+   `groupvit` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (GroupViT 模型)

+   `idefics` — [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor) (IDEFICS 模型)

+   `imagegpt` — [ImageGPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor) (ImageGPT 模型)

+   `instructblip` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor) (InstructBLIP 模型)

+   `kosmos-2` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (KOSMOS-2 模型)

+   `layoutlmv2` — [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor) (LayoutLMv3 模型)

+   `levit` — [LevitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitImageProcessor) (LeViT 模型)

+   `llava` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (LLaVa 模型)

+   `mask2former` — [Mask2FormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor) (Mask2Former 模型)

+   `maskformer` — [MaskFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerImageProcessor) (MaskFormer 模型)

+   `mgp-str` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (MGP-STR 模型)

+   `mobilenet_v1` — [MobileNetV1ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ImageProcessor) (MobileNetV1 模型)

+   `mobilenet_v2` — [MobileNetV2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ImageProcessor) (MobileNetV2 模型)

+   `mobilevit` — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor) (MobileViT 模型)

+   `mobilevitv2` — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor) (MobileViTV2 模型)

+   `nat` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (NAT 模型)

+   `nougat` — [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor) (Nougat 模型)

+   `oneformer` — [OneFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerImageProcessor) (OneFormer 模型)

+   `owlv2` — [Owlv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ImageProcessor) (OWLv2 模型)

+   `owlvit` — [OwlViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTImageProcessor) (OWL-ViT 模型)

+   `perceiver` — [PerceiverImageProcessor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverImageProcessor) (Perceiver 模型)

+   `pix2struct` — [Pix2StructImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructImageProcessor) (Pix2Struct 模型)

+   `poolformer` — [PoolFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerImageProcessor) (PoolFormer 模型)

+   `pvt` — [PvtImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtImageProcessor) (PVT 模型)

+   `regnet` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor) (RegNet 模型)

+   `resnet` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor) (ResNet 模型)

+   `sam` — [SamImageProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamImageProcessor) (SAM 模型)

+   `segformer` — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor) (SegFormer 模型)

+   `siglip` — [SiglipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipImageProcessor) (SigLIP 模型)

+   `swiftformer` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (SwiftFormer 模型)

+   `swin` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (Swin Transformer model)

+   `swin2sr` — [Swin2SRImageProcessor](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRImageProcessor) (Swin2SR model)

+   `swinv2` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (Swin Transformer V2 model)

+   `table-transformer` — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor) (Table Transformer model)

+   `timesformer` — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor) (TimeSformer model)

+   `tvlt` — [TvltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltImageProcessor) (TVLT model)

+   `tvp` — [TvpImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpImageProcessor) (TVP model)

+   `upernet` — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor) (UPerNet model)

+   `van` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor) (VAN model)

+   `videomae` — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor) (VideoMAE model)

+   `vilt` — [ViltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltImageProcessor) (ViLT model)

+   `vipllava` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (VipLlava model)

+   `vit` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (ViT model)

+   `vit_hybrid` — [ViTHybridImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridImageProcessor) (ViT Hybrid model)

+   `vit_mae` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (ViTMAE model)

+   `vit_msn` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor) (ViTMSN model)

+   `vitmatte` — [VitMatteImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteImageProcessor) (ViTMatte model)

+   `xclip` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor) (X-CLIP model)

+   `yolos` — [YolosImageProcessor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosImageProcessor) (YOLOS model)

当您想使用私有模型时，需要传递`token=True`。

示例：

```py
>>> from transformers import AutoImageProcessor

>>> # Download image processor from huggingface.co and cache.
>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")

>>> # If image processor files are in a directory (e.g. image processor was saved using *save_pretrained('./test/saved_model/')*)
>>> # image_processor = AutoImageProcessor.from_pretrained("./test/saved_model/")
```

#### `register`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L422)

```py
( config_class image_processor_class exist_ok = False )
```

参数

+   `config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 与要注册的模型对应的配置。

+   `image_processor_class` ([ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)) — 要注册的图像处理器。

为这个类注册一个新的图像处理器。

## AutoProcessor

### `class transformers.AutoProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L129)

```py
( )
```

这是一个通用的处理器类，在使用[AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained)类方法创建时，将作为库的处理器类之一实例化。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L143)

```py
( pretrained_model_name_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 这可以是：

    +   一个字符串，预训练特征提取器的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用`save_pretrained()`方法保存的处理器文件，例如`./my_model_directory/`。

+   `cache_dir`（`str`或`os.PathLike`，*可选*） — 下载的预训练模型特征提取器应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `force_download`（`bool`，*可选*，默认为`False`） — 是否强制（重新）下载特征提取器文件并覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`） — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*） — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128'，'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `token`（`str`或*bool*，*可选*） — 用作远程文件的HTTP bearer授权的令牌。如果为`True`，将使用运行`huggingface-cli login`时生成的令牌（存储在`~/.huggingface`）。

+   `revision`（`str`，*可选*，默认为`"main"`） — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `return_unused_kwargs`（`bool`，*可选*，默认为`False`） — 如果为`False`，则此函数仅返回最终特征提取器对象。如果为`True`，则此函数返回一个`Tuple(feature_extractor, unused_kwargs)`，其中*unused_kwargs*是一个字典，包含未使用的键/值对，这些键不是特征提取器属性：即`kwargs`的一部分，未用于更新`feature_extractor`且被忽略。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在Hub上定义自定义模型的代码。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地计算机上执行Hub上存在的代码。

+   `kwargs`（`Dict[str, Any]`，*可选*） — 任何键为特征提取器属性的kwargs中的值将用于覆盖加载的值。关于键/值对中键不是特征提取器属性的行为由`return_unused_kwargs`关键字参数控制。

从预训练模型词汇表中实例化库中的处理器类之一。

要实例化的处理器类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载）：

+   `align` — [AlignProcessor](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignProcessor)（ALIGN模型）

+   `altclip` — [AltCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPProcessor)（AltCLIP模型）

+   `bark` — [BarkProcessor](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor)（Bark模型）

+   `blip` — [BlipProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipProcessor)（BLIP模型）

+   `blip-2` — [Blip2Processor](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Processor)（BLIP-2模型）

+   `bridgetower` — [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)（BridgeTower模型）

+   `chinese_clip` — [ChineseCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPProcessor)（Chinese-CLIP模型）

+   `clap` — [ClapProcessor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor) (CLAP 模型)

+   `clip` — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor) (CLIP 模型)

+   `clipseg` — [CLIPSegProcessor](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegProcessor) (CLIPSeg 模型)

+   `clvp` — [ClvpProcessor](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpProcessor) (CLVP 模型)

+   `flava` — [FlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor) (FLAVA 模型)

+   `fuyu` — [FuyuProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuProcessor) (Fuyu 模型)

+   `git` — [GitProcessor](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitProcessor) (GIT 模型)

+   `groupvit` — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor) (GroupViT 模型)

+   `hubert` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor) (Hubert 模型)

+   `idefics` — [IdeficsProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor) (IDEFICS 模型)

+   `instructblip` — [InstructBlipProcessor](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipProcessor) (InstructBLIP 模型)

+   `kosmos-2` — [Kosmos2Processor](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor) (KOSMOS-2 模型)

+   `layoutlmv2` — [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor) (LayoutLMv3 模型)

+   `llava` — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor) (LLaVa 模型)

+   `markuplm` — [MarkupLMProcessor](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMProcessor) (MarkupLM 模型)

+   `mctct` — [MCTCTProcessor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTProcessor) (M-CTC-T 模型)

+   `mgp-str` — [MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor) (MGP-STR 模型)

+   `oneformer` — [OneFormerProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerProcessor) (OneFormer 模型)

+   `owlv2` — [Owlv2Processor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Processor) (OWLv2 模型)

+   `owlvit` — [OwlViTProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTProcessor) (OWL-ViT 模型)

+   `pix2struct` — [Pix2StructProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructProcessor) (Pix2Struct 模型)

+   `pop2piano` — [Pop2PianoProcessor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoProcessor) (Pop2Piano 模型)

+   `sam` — [SamProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamProcessor) (SAM 模型)

+   `seamless_m4t` — [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor) (SeamlessM4T 模型)

+   `sew` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor) (SEW 模型)

+   `sew-d` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor) (SEW-D 模型)

+   `siglip` — [SiglipProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipProcessor) (SigLIP 模型)

+   `speech_to_text` — [Speech2TextProcessor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextProcessor) (Speech2Text 模型)

+   `speech_to_text_2` — [Speech2Text2Processor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor) (Speech2Text2 模型)

+   `speecht5` — [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor) (SpeechT5 模型)

+   `trocr` — [TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)（TrOCR模型）

+   `tvlt` — [TvltProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltProcessor)（TVLT模型）

+   `tvp` — [TvpProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpProcessor)（TVP模型）

+   `unispeech` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（UniSpeech模型）

+   `unispeech-sat` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（UniSpeechSat模型）

+   `vilt` — [ViltProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltProcessor)（ViLT模型）

+   `vipllava` — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)（VipLlava模型）

+   `vision-text-dual-encoder` — [VisionTextDualEncoderProcessor](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor)（VisionTextDualEncoder模型）

+   `wav2vec2` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（Wav2Vec2模型）

+   `wav2vec2-bert` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（Wav2Vec2-BERT模型）

+   `wav2vec2-conformer` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（Wav2Vec2-Conformer模型）

+   `wavlm` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（WavLM模型）

+   `whisper` — [WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)（Whisper模型）

+   `xclip` — [XCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPProcessor)（X-CLIP模型）

当您想使用私有模型时，需要传递`token=True`。

示例：

```py
>>> from transformers import AutoProcessor

>>> # Download processor from huggingface.co and cache.
>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

>>> # If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
>>> # processor = AutoProcessor.from_pretrained("./test/saved_model/")
```

#### `register`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L347)

```py
( config_class processor_class exist_ok = False )
```

参数

+   `config_class`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 与要注册的模型对应的配置。

+   `processor_class` (`FeatureExtractorMixin`) — 要注册的处理器。

为这个类注册一个新的处理器。

## 通用模型类

以下自动类可用于实例化一个基本模型类，而无需特定头部。

### AutoModel

### `class transformers.AutoModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1304)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的基本模型类之一实例化。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)配置类：[ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)（音频频谱变换器模型）

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)（ALBERT模型）

    +   [AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig) 配置类: [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel) (ALIGN 模型)

    +   [AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig) 配置类: [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel) (AltCLIP 模型)

    +   [AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig) 配置类: [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel) (Autoformer 模型)

    +   [BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig) 配置类: [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel) (Bark 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel) (BART 模型)

    +   [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig) 配置类: [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel) (BEiT 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel) (BERT 模型)

    +   [BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig) 配置类: [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder) (Bert Generation 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel) (BigBird 模型)

    +   [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig) 配置类: [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel) (BigBird-Pegasus 模型)

    +   [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig) 配置类: [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel) (BioGpt 模型)

    +   [BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig) 配置类: [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel) (BiT 模型)

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig) 配置类: [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel) (Blenderbot 模型)

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig) 配置类: [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel) (BlenderbotSmall 模型)

    +   [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config) 配置类: [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model) (BLIP-2 模型)

    +   [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig) 配置类: [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel) (BLIP 模型)

    +   [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig) 配置类: [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel) (BLOOM 模型)

    +   [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig) 配置类: [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel) (BridgeTower 模型)

    +   [BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig) 配置类: [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel) (BROS 模型)

    +   [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig) 配置类: [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel) (CLIP 模型)

    +   [CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig) 配置类: [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel) (CLIPSeg 模型)

    +   [CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig) 配置类: [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel) (CLIPVisionModel 模型)

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig) 配置类: [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel) (CTRL 模型)

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) 配置类: [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel) (CamemBERT 模型)

    +   [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig) 配置类: [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel) (CANINE 模型)

    +   [ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig) 配置类: [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel) (Chinese-CLIP 模型)

    +   [ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig) 配置类: [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel) (CLAP 模型)

    +   [ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig) 配置类: [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration) (CLVP 模型)

    +   [CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig) 配置类: [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel) (CodeGen 模型)

    +   [ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig) 配置类: [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel) (Conditional DETR 模型)

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) 配置类: [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel) (ConvBERT 模型)

    +   [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig) 配置类: [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel) (ConvNeXT 模型)

    +   [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config) 配置类: [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model) (ConvNeXTV2 模型)

    +   [CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig) 配置类: [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel) (CPM-Ant 模型)

    +   [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig) 配置类: [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel) (CvT 模型)

    +   [DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig) 配置类: [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder) (DPR 模型)

    +   [DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig) 配置类: [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel) (DPT 模型)

    +   [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig) 配置类: [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel) (Data2VecAudio 模型)

    +   [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig) 配置类: [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel) (Data2VecText 模型)

    +   [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig) 配置类: [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel) (Data2VecVision 模型)

    +   [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig) 配置类: [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel) (DeBERTa 模型)

    +   [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类: [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model) (DeBERTa-v2 模型)

    +   [DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig) 配置类: [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel) (Decision Transformer 模型)

    +   [DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig) 配置类: [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel) (Deformable DETR 模型)

    +   [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig) 配置类: [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel) (DeiT 模型)

    +   [DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig) 配置类: [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel) (DETA 模型)

    +   [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig) 配置类: [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel) (DETR 模型)

    +   [DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig) 配置类: [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel) (DiNAT 模型)

    +   [Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config) 配置类: [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model) (DINOv2 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel) (DistilBERT 模型)

    +   [DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig) 配置类: [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel) (DonutSwin 模型)

    +   [EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig) 配置类: [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel) (EfficientFormer 模型)

    +   [EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig) 配置类: [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel) (EfficientNet 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel) (ELECTRA 模型)

    +   [EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig) 配置类: [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel) (EnCodec 模型)

    +   [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig) 配置类: [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel) (ERNIE 模型)

    +   [ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig) 配置类: [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel) (ErnieM 模型)

    +   [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig) 配置类: [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel) (ESM 模型)

    +   [FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig) 配置类: [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel) (FNet 模型)

    +   [FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig) 配置类: [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel) (FairSeq 机器翻译模型)

    +   [FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig) 配置类: [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel) (Falcon 模型)

    +   [FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig) 配置类: [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel) (FastSpeech2Conformer 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel) (FlauBERT 模型)

    +   [FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig) 配置类: [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel) (FLAVA 模型)

    +   [FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig) 配置类: [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel) (FocalNet 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel) 或 [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel) (Funnel Transformer 模型)

    +   [GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig) 配置类: [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel) (GLPN 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model) (OpenAI GPT-2 模型)

    +   [GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig) 配置类: [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel) (GPTBigCode 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel) (GPT-J 模型)

    +   [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig) 配置类: [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel) (GPT Neo 模型)

    +   [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig) 配置类: [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel) (GPT NeoX 模型)

    +   [GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig) 配置类: [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel) (GPT NeoX 日语模型)

    +   [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig) 配置类: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration) (GPTSAN-japanese 模型)

    +   [GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig) 配置类: [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel) (GIT 模型)

    +   [GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig) 配置类: [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel) (Graphormer 模型)

    +   [GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig) 配置类: [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel) (GroupViT 模型)

    +   [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig) 配置类: [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel) (Hubert 模型)

    +   [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig) 配置类: [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel) (I-BERT 模型)

    +   [IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig) 配置类: [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel) (IDEFICS 模型)

    +   [ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig) 配置类: [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel) (ImageGPT 模型)

    +   [InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig) 配置类: [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel) (Informer 模型)

    +   [JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig) 配置类: [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel) (Jukebox 模型)

    +   [Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config) 配置类: [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model) (KOSMOS-2 模型)

    +   [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig) 配置类: [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel) (LED 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel) (LayoutLM 模型)

    +   [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config) 配置类: [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model) (LayoutLMv2 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model) (LayoutLMv3 模型)

    +   [LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig) 配置类: [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel) (LeViT 模型)

    +   [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig) 配置类: [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel) (LiLT 模型)

    +   [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig) 配置类: [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel) (LLaMA 模型)

    +   [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config) 配置类: [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model) (LongT5 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel) (Longformer 模型)

    +   [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig) 配置类: [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel) (LUKE 模型)

    +   [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig) 配置类: [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel) (LXMERT 模型)

    +   [M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config) 配置类: [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model) (M2M100 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel) (mBART 模型)

    +   [MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig) 配置类: [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel) (M-CTC-T 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel) (MPNet 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model) (MT5 模型)

    +   [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig) 配置类: [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel) (Marian 模型)

    +   [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig) 配置类: [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel) (MarkupLM 模型)

    +   [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig) 配置类: [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel) (Mask2Former 模型)

    +   [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig) 配置类: [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel) (MaskFormer 模型)

    +   `MaskFormerSwinConfig` 配置类: `MaskFormerSwinModel` (MaskFormerSwin 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel) (Megatron-BERT 模型)

    +   [MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig) 配置类: [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition) (MGP-STR 模型)

    +   [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig) 配置类: [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel) (Mistral 模型)

    +   [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig) 配置类: [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel) (Mixtral 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel) (MobileBERT 模型)

    +   [MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config) 配置类: [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model) (MobileNetV1 模型)

    +   [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config) 配置类: [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model) (MobileNetV2 模型)

    +   [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig) 配置类: [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel) (MobileViT 模型)

    +   [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config) 配置类: [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model) (MobileViTV2 模型)

    +   [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) 配置类: [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel) (MPT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel) (MRA 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel) (MVP 模型)

    +   [NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig) 配置类: [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel) (NAT 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel) (Nezha 模型)

    +   [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig) 配置类: [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel) (NLLB-MOE 模型)

    +   [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) 配置类: [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel) (Nyströmformer 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel) (OPT 模型)

    +   [OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig) 配置类: [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel) (OneFormer 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel) (OpenAI GPT 模型)

    +   [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig) 配置类: [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel) (OpenLlama 模型)

    +   [OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig) 配置类: [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel) (OWL-ViT 模型)

    +   [Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config) 配置类: [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model) (OWLv2 模型)

    +   [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig) 配置类: [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel) (PLBart 模型)

    +   [PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig) 配置类: [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel) (PatchTSMixer 模型)

    +   [PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig) 配置类: [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel) (PatchTST 模型)

    +   [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) 配置类: [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel) (Pegasus 模型)

    +   [PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig) 配置类: [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel) (PEGASUS-X 模型)

    +   [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig) 配置类: [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel) (Perceiver 模型)

    +   [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig) 配置类: [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel) (Persimmon 模型)

    +   [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig) 配置类: [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel) (Phi 模型)

    +   [PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig) 配置类: [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel) (PoolFormer 模型)

    +   [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig) 配置类: [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel) (ProphetNet 模型)

    +   [PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig) 配置类: [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel) (PVT 模型)

    +   [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) 配置类: [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel) (QDQBert 模型)

    +   [Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config) 配置类: [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model) (Qwen2 模型)

    +   [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig) 配置类: [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel) (Reformer 模型)

    +   [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) 配置类: [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel) (RegNet 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel) (RemBERT 模型)

    +   [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) 配置类: [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel) (ResNet 模型)

    +   [RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig) 配置类: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel) (RetriBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel) (RoCBert 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel) (RoBERTa-PreLayerNorm 模型)

    +   [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig) 配置类: [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel) (RWKV 模型)

    +   [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig) 配置类: [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel) (SEW 模型)

    +   [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig) 配置类: [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel) (SEW-D 模型)

    +   [SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig) 配置类: [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel) (SAM 模型)

    +   [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig) 配置类: [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel) (SeamlessM4T 模型)

    +   [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config) 配置类: [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model) (SeamlessM4Tv2 模型)

    +   [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig) 配置类: [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel) (SegFormer 模型)

    +   [SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig) 配置类: [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel) (SigLIP 模型)

    +   [SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig) 配置类: [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel) (SiglipVisionModel 模型)

    +   [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig) 配置类: [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel) (Speech2Text 模型)

    +   [SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config) 配置类: [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model) (SpeechT5 模型)

    +   [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig) 配置类: [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel) (Splinter 模型)

    +   [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) 配置类: [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel) (SqueezeBERT 模型)

    +   [SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig) 配置类: [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel) (SwiftFormer 模型)

    +   [Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig) 配置类: [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel) (Swin2SR 模型)

    +   [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig) 配置类: [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel) (Swin Transformer 模型)

    +   [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config) 配置类: [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model) (Swin Transformer V2 模型)

    +   [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig) 配置类: [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel) (SwitchTransformers 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类: [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model) (T5 模型)

    +   [TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig) 配置类: [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel) (Table Transformer 模型)

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) 配置类: [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel) (TAPAS 模型)

    +   [TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig) 配置类: [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel) (Time Series Transformer 模型)

    +   [TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig) 配置类: [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel) (TimeSformer 模型)

    +   `TimmBackboneConfig` 配置类: `TimmBackbone` (TimmBackbone 模型)

    +   [TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig) 配置类: [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel) (轨迹Transformer模型)

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类: [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel) (Transformer-XL模型)

    +   [TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig) 配置类: [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel) (TVLT模型)

    +   [TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig) 配置类: [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel) (TVP模型)

    +   [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config) 配置类: [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model) (UMT5模型)

    +   [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig) 配置类: [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel) (UniSpeech模型)

    +   [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) 配置类: [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel) (UniSpeechSat模型)

    +   [UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig) 配置类: [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel) (UnivNet模型)

    +   [VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig) 配置类: [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel) (VAN模型)

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig) 配置类: [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel) (ViT模型)

    +   [ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig) 配置类: [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel) (ViT混合模型)

    +   [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig) 配置类: [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel) (ViTMAE模型)

    +   [ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig) 配置类: [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel) (ViTMSN模型)

    +   [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig) 配置类: [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel) (VideoMAE模型)

    +   [ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig) 配置类: [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel) (ViLT模型)

    +   [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig) 配置类: [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel) (VisionTextDualEncoder模型)

    +   [VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig) 配置类: [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel) (VisualBERT模型)

    +   [VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig) 配置类: [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel) (VitDet 模型)

    +   [VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig) 配置类: [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel) (VITS 模型)

    +   [VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig) 配置类: [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel) (ViViT 模型)

    +   [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig) 配置类: [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel) (Wav2Vec2-BERT 模型)

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类: [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model) (Wav2Vec2 模型)

    +   [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig) 配置类: [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel) (Wav2Vec2-Conformer 模型)

    +   [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig) 配置类: [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel) (WavLM 模型)

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类: [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel) (Whisper 模型)

    +   [XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig) 配置类: [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel) (X-CLIP 模型)

    +   [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig) 配置类: [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel) (XGLM 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel) (XLM 模型)

    +   [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig) 配置类: [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel) (XLM-ProphetNet 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel) (XLM-RoBERTa 模型)

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类: [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel) (XLM-RoBERTa-XL 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类: [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel) (XLNet 模型)

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig) 配置类: [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel) (X-MOD 模型)

    +   [YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig) 配置类: [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel) (YOLOS 模型)

    +   [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig) 配置类: [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel) (YOSO 模型)

从配置中实例化库的基础模型类。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModel

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModel.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个*tensorflow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应该将配置对象作为`config`参数提供。使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型的加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以被自动加载：

    +   模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 下载预训练模型配置应该被缓存的目录路径，如果不使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的代码。只有在您信任的存储库中并且已阅读代码的情况下，才应将此选项设置为 `True`，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载，行为不同：

    +   如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库的基本模型类之一。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel) (ALBERT 模型)

+   `align` — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel) (ALIGN 模型)

+   `altclip` — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel) (AltCLIP 模型)

+   `audio-spectrogram-transformer` — [ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel) (音频频谱变换器模型)

+   `autoformer` — [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel) (Autoformer 模型)

+   `bark` — [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel) (Bark 模型)

+   `bart` — [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel) (BART 模型)

+   `beit` — [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel) (BEiT 模型)

+   `bert` — [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel) (BERT 模型)

+   `bert-generation` — [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder) (Bert Generation 模型)

+   `big_bird` — [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel) (BigBird 模型)

+   `bigbird_pegasus` — [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel) (BigBird-Pegasus 模型)

+   `biogpt` — [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel) (BioGpt 模型)

+   `bit` — [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel) (BiT 模型)

+   `blenderbot` — [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel) (Blenderbot 模型)

+   `blenderbot-small` — [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel) (BlenderbotSmall 模型)

+   `blip` — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel) (BLIP 模型)

+   `blip-2` — [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model) (BLIP-2 模型)

+   `bloom` — [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel) (BLOOM 模型)

+   `bridgetower` — [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel) (BridgeTower 模型)

+   `bros` — [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel) (BROS 模型)

+   `camembert` — [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel) (CamemBERT 模型)

+   `canine` — [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel) (CANINE 模型)

+   `chinese_clip` — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel) (Chinese-CLIP 模型)

+   `clap` — [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel) (CLAP 模型)

+   `clip` — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel) (CLIP 模型)

+   `clip_vision_model` — [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel) (CLIPVisionModel 模型)

+   `clipseg` — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel) (CLIPSeg 模型)

+   `clvp` — [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration) (CLVP 模型)

+   `code_llama` — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel) (CodeLlama 模型)

+   `codegen` — [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel) (CodeGen 模型)

+   `conditional_detr` — [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel) (Conditional DETR 模型)

+   `convbert` — [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel) (ConvBERT 模型)

+   `convnext` — [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel) (ConvNeXT 模型)

+   `convnextv2` — [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model) (ConvNeXTV2 模型)

+   `cpmant` — [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel) (CPM-Ant 模型)

+   `ctrl` — [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel) (CTRL 模型)

+   `cvt` — [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel) (CvT 模型)

+   `data2vec-audio` — [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel) (Data2VecAudio 模型)

+   `data2vec-text` — [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel) (Data2VecText 模型)

+   `data2vec-vision` — [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel) (Data2VecVision 模型)

+   `deberta` — [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model) (DeBERTa-v2 模型)

+   `decision_transformer` — [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel) (Decision Transformer 模型)

+   `deformable_detr` — [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel) (Deformable DETR 模型)

+   `deit` — [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel) (DeiT 模型)

+   `deta` — [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel) (DETA 模型)

+   `detr` — [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel) (DETR 模型)

+   `dinat` — [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel) (DiNAT 模型)

+   `dinov2` — [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model) (DINOv2 模型)

+   `distilbert` — [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel) (DistilBERT 模型)

+   `donut-swin` — [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel) (DonutSwin 模型)

+   `dpr` — [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder) (DPR 模型)

+   `dpt` — [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel) (DPT 模型)

+   `efficientformer` — [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel) (EfficientFormer 模型)

+   `efficientnet` — [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel) (EfficientNet 模型)

+   `electra` — [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel) (ELECTRA 模型)

+   `encodec` — [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel) (EnCodec 模型)

+   `ernie` — [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel) (ERNIE 模型)

+   `ernie_m` — [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel) (ErnieM 模型)

+   `esm` — [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel) (ESM 模型)

+   `falcon` — [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel) (Falcon 模型)

+   `fastspeech2_conformer` — [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel) (FastSpeech2Conformer 模型)

+   `flaubert` — [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel) (FlauBERT 模型)

+   `flava` — [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel) (FLAVA 模型)

+   `fnet` — [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel) (FNet 模型)

+   `focalnet` — [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel) (FocalNet 模型)

+   `fsmt` — [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel) (FairSeq 机器翻译模型)

+   `funnel` — [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel) 或 [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel) (Funnel Transformer 模型)

+   `git` — [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel) (GIT 模型)

+   `glpn` — [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel) (GLPN 模型)

+   `gpt-sw3` — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model) (GPT-Sw3 模型)

+   `gpt2` — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model) (OpenAI GPT-2 模型)

+   `gpt_bigcode` — [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel) (GPTBigCode 模型)

+   `gpt_neo` — [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel) (GPT Neo 模型)

+   `gpt_neox` — [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel) (GPT NeoX 模型)

+   `gpt_neox_japanese` — [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel) (GPT NeoX Japanese 模型)

+   `gptj` — [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel) (GPT-J 模型)

+   `gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration) (GPTSAN-japanese 模型)

+   `graphormer` — [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel) (Graphormer 模型)

+   `groupvit` — [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel) (GroupViT 模型)

+   `hubert` — [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel) (Hubert 模型)

+   `ibert` — [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel) (I-BERT 模型)

+   `idefics` — [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel) (IDEFICS 模型)

+   `imagegpt` — [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel) (ImageGPT 模型)

+   `informer` — [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel) (Informer 模型)

+   `jukebox` — [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel) (Jukebox 模型)

+   `kosmos-2` — [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model) (KOSMOS-2 模型)

+   `layoutlm` — [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel) (LayoutLM 模型)

+   `layoutlmv2` — [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model) (LayoutLMv3 模型)

+   `led` — [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel) (LED 模型)

+   `levit` — [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel) (LeViT 模型)

+   `lilt` — [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel) (LiLT 模型)

+   `llama` — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel) (LLaMA 模型)

+   `longformer` — [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel) (Longformer 模型)

+   `longt5` — [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model) (LongT5 模型)

+   `luke` — [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel) (LUKE 模型)

+   `lxmert` — [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel) (LXMERT 模型)

+   `m2m_100` — [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model) (M2M100 模型)

+   `marian` — [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel) (Marian 模型)

+   `markuplm` — [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel) (MarkupLM 模型)

+   `mask2former` — [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel) (Mask2Former 模型)

+   `maskformer` — [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel) (MaskFormer 模型)

+   `maskformer-swin` — `MaskFormerSwinModel` (MaskFormerSwin 模型)

+   `mbart` — [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel) (mBART 模型)

+   `mctct` — [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel) (M-CTC-T 模型)

+   `mega` — [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel) (MEGA 模型)

+   `megatron-bert` — [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel) (Megatron-BERT模型)

+   `mgp-str` — [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition) (MGP-STR模型)

+   `mistral` — [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel) (Mistral模型)

+   `mixtral` — [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel) (Mixtral模型)

+   `mobilebert` — [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel) (MobileBERT模型)

+   `mobilenet_v1` — [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model) (MobileNetV1模型)

+   `mobilenet_v2` — [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model) (MobileNetV2模型)

+   `mobilevit` — [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel) (MobileViT模型)

+   `mobilevitv2` — [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model) (MobileViTV2模型)

+   `mpnet` — [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel) (MPNet模型)

+   `mpt` — [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel) (MPT模型)

+   `mra` — [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel) (MRA模型)

+   `mt5` — [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model) (MT5模型)

+   `mvp` — [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel) (MVP模型)

+   `nat` — [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel) (NAT模型)

+   `nezha` — [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel) (Nezha模型)

+   `nllb-moe` — [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel) (NLLB-MOE模型)

+   `nystromformer` — [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel) (Nyströmformer模型)

+   `oneformer` — [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel) (OneFormer模型)

+   `open-llama` — [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel) (OpenLlama模型)

+   `openai-gpt` — [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel) (OpenAI GPT模型)

+   `opt` — [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel) (OPT模型)

+   `owlv2` — [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model) (OWLv2模型)

+   `owlvit` — [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel) (OWL-ViT模型)

+   `patchtsmixer` — [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel) (PatchTSMixer模型)

+   `patchtst` — [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel) (PatchTST模型)

+   `pegasus` — [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel) (Pegasus模型)

+   `pegasus_x` — [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel) (PEGASUS-X模型)

+   `perceiver` — [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel) (感知器模型)

+   `persimmon` — [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel) (Persimmon模型)

+   `phi` — [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel) (Phi模型)

+   `plbart` — [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel) (PLBart模型)

+   `poolformer` — [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel) (PoolFormer 模型)

+   `prophetnet` — [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel) (ProphetNet 模型)

+   `pvt` — [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel) (PVT 模型)

+   `qdqbert` — [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel) (QDQBert 模型)

+   `qwen2` — [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model) (Qwen2 模型)

+   `reformer` — [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel) (Reformer 模型)

+   `regnet` — [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel) (RegNet 模型)

+   `rembert` — [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel) (RemBERT 模型)

+   `resnet` — [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel) (ResNet 模型)

+   `retribert` — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel) (RetriBERT 模型)

+   `roberta` — [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel) (RoCBert 模型)

+   `roformer` — [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel) (RoFormer 模型)

+   `rwkv` — [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel) (RWKV 模型)

+   `sam` — [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel) (SAM 模型)

+   `seamless_m4t` — [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel) (SeamlessM4T 模型)

+   `seamless_m4t_v2` — [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model) (SeamlessM4Tv2 模型)

+   `segformer` — [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel) (SegFormer 模型)

+   `sew` — [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel) (SEW 模型)

+   `sew-d` — [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel) (SEW-D 模型)

+   `siglip` — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel) (SigLIP 模型)

+   `siglip_vision_model` — [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel) (SiglipVisionModel 模型)

+   `speech_to_text` — [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel) (Speech2Text 模型)

+   `speecht5` — [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model) (SpeechT5 模型)

+   `splinter` — [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel) (Splinter 模型)

+   `squeezebert` — [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel) (SqueezeBERT 模型)

+   `swiftformer` — [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel) (SwiftFormer 模型)

+   `swin` — [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel) (Swin Transformer 模型)

+   `swin2sr` — [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel) (Swin2SR 模型)

+   `swinv2` — [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model) (Swin Transformer V2 模型)

+   `switch_transformers` — [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel) (SwitchTransformers 模型)

+   `t5` — [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model) (T5 模型)

+   `table-transformer` — [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel) (Table Transformer 模型)

+   `tapas` — [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel) (TAPAS 模型)

+   `time_series_transformer` — [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel) (Time Series Transformer 模型)

+   `timesformer` — [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel) (TimeSformer 模型)

+   `timm_backbone` — `TimmBackbone` (TimmBackbone 模型)

+   `trajectory_transformer` — [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel) (Trajectory Transformer 模型)

+   `transfo-xl` — [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel) (Transformer-XL 模型)

+   `tvlt` — [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel) (TVLT 模型)

+   `tvp` — [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel) (TVP 模型)

+   `umt5` — [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model) (UMT5 模型)

+   `unispeech` — [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel) (UniSpeech 模型)

+   `unispeech-sat` — [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel) (UniSpeechSat 模型)

+   `univnet` — [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel) (UnivNet 模型)

+   `van` — [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel) (VAN 模型)

+   `videomae` — [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel) (VideoMAE 模型)

+   `vilt` — [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel) (ViLT 模型)

+   `vision-text-dual-encoder` — [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel) (VisionTextDualEncoder 模型)

+   `visual_bert` — [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel) (VisualBERT 模型)

+   `vit` — [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel) (ViT 模型)

+   `vit_hybrid` — [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel) (ViT Hybrid 模型)

+   `vit_mae` — [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel) (ViTMAE 模型)

+   `vit_msn` — [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel) (ViTMSN 模型)

+   `vitdet` — [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel) (VitDet 模型)

+   `vits` — [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel) (VITS 模型)

+   `vivit` — [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel) (ViViT 模型)

+   `wav2vec2` — [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model) (Wav2Vec2 模型)

+   `wav2vec2-bert` — [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel) (Wav2Vec2-BERT 模型)

+   `wav2vec2-conformer` — [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel) (Wav2Vec2-Conformer 模型)

+   `wavlm` — [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel) (WavLM 模型)

+   `whisper` — [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel) (Whisper 模型)

+   `xclip` — [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel) (X-CLIP 模型)

+   `xglm` — [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel) (XGLM 模型)

+   `xlm` — [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel) (XLM 模型)

+   `xlm-prophetnet` — [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel) (XLM-ProphetNet 模型)

+   `xlm-roberta` — [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel) (XLM-RoBERTa 模型)

+   `xlm-roberta-xl` — [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel) (XLM-RoBERTa-XL 模型)

+   `xlnet` — [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel) (XLNet 模型)

+   `xmod` — [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel) (X-MOD 模型)

+   `yolos` — [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel) (YOLOS 模型)

+   `yoso` — [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel) (YOSO 模型)

默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例:

```py
>>> from transformers import AutoConfig, AutoModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModel.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModel.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModel

### `class transformers.TFAutoModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L531)

```py
( *args **kwargs )
```

这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，会被实例化为库中的基础模型类之一。

这个类不能直接使用 `__init__()` 实例化（会报错）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类: [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel) (ALBERT 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel) (BERT 模型)

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig) 配置类: [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel) (Blenderbot 模型)

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig) 配置类: [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel) (BlenderbotSmall 模型)

    +   [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig) 配置类: [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel) (BLIP 模型)

    +   [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig) 配置类: [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel) (CLIP 模型)

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig) 配置类: [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel) (CTRL 模型)

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) 配置类: [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel) (CamemBERT 模型)

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) 配置类: [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel) (ConvBERT 模型)

    +   [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig) 配置类: [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel) (ConvNeXT 模型)

    +   [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config) 配置类: [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model) (ConvNeXTV2 模型)

    +   [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig) 配置类: [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel) (CvT 模型)

    +   [DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig) 配置类: [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder) (DPR 模型)

    +   [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig) 配置类: [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel) (Data2VecVision 模型)

    +   [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig) 配置类: [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel) (DeBERTa 模型)

    +   [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类: [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model) (DeBERTa-v2 模型)

    +   [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig) 配置类: [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel) (DeiT 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel) (DistilBERT 模型)

    +   [EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig) 配置类: [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel) (EfficientFormer 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel) (ELECTRA 模型)

    +   [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig) 配置类: [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel) (ESM 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel) 或 [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel) (Funnel Transformer 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model) (OpenAI GPT-2 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel) (GPT-J 模型)

    +   [GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig) 配置类: [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel) (GroupViT 模型)

    +   [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig) 配置类: [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel) (Hubert 模型)

    +   [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig) 配置类: [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel) (LED 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel) (LayoutLM 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model) (LayoutLMv3 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel) (Longformer 模型)

    +   [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig) 配置类: [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel) (LXMERT 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel) (mBART 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel) (MPNet 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model) (MT5 模型)

    +   [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig) 配置类: [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel) (Marian 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel) (MobileBERT 模型)

    +   [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig) 配置类: [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel) (MobileViT 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel) (OPT 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel) (OpenAI GPT 模型)

    +   [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) 配置类: [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel) (Pegasus 模型)

    +   [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) 配置类: [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel) (RegNet 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel) (RemBERT 模型)

    +   [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) 配置类: [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel) (ResNet 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel) (RoBERTa-PreLayerNorm 模型)

    +   [SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig) 配置类: [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel) (SAM 模型)

    +   [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig) 配置类: [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel) (SegFormer 模型)

    +   [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig) 配置类: [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel) (Speech2Text 模型)

    +   [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig) 配置类: [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel) (Swin Transformer 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类: [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model) (T5 模型)

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) 配置类: [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel) (TAPAS 模型)

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类: [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel) (Transformer-XL 模型)

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig) 配置类: [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel) (ViT 模型)

    +   [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig) 配置类: [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel) (ViTMAE 模型)

    +   [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig) 配置类：[TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)（VisionTextDualEncoder模型）

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类：[TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)（Wav2Vec2模型）

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类：[TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)（Whisper模型）

    +   [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig) 配置类：[TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)（XGLM模型）

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类：[TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)（XLM模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)（XLM-RoBERTa模型）

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类：[TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)（XLNet模型）

从配置实例化库中的一个基础模型类。

注意：从配置文件加载模型**不会**加载模型权重。它只会影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModel

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModel.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如`./my_model_directory/`。

    +   一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并加载TensorFlow模型的加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以自动加载：

    +   该模型是库中提供的一个模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如 `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的模型文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为不同：

    +   如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库的基本模型类之一。

根据配置对象的 `model_type` 属性选择要实例化的模型类（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上进行模式匹配来回退：

+   `albert` — [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel) (ALBERT 模型)

+   `bart` — [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel) (BART 模型)

+   `bert` — [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel) (BERT 模型)

+   `blenderbot` — [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel) (Blenderbot 模型)

+   `blenderbot-small` — [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel) (BlenderbotSmall 模型)

+   `blip` — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel) (BLIP 模型)

+   `camembert` — [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel) (CamemBERT 模型)

+   `clip` — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel) (CLIP 模型)

+   `convbert` — [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel) (ConvBERT 模型)

+   `convnext` — [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel) (ConvNeXT 模型)

+   `convnextv2` — [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model) (ConvNeXTV2 模型)

+   `ctrl` — [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel) (CTRL 模型)

+   `cvt` — [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel) (CvT 模型)

+   `data2vec-vision` — [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel) (Data2VecVision 模型)

+   `deberta` — [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel) (DeBERTa 模型)

+   `deberta-v2` — [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model) (DeBERTa-v2 模型)

+   `deit` — [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel) (DeiT 模型)

+   `distilbert` — [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel) (DistilBERT 模型)

+   `dpr` — [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder) (DPR 模型)

+   `efficientformer` — [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel) (EfficientFormer 模型)

+   `electra` — [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel) (ELECTRA 模型)

+   `esm` — [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel) (ESM 模型)

+   `flaubert` — [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel) (FlauBERT 模型)

+   `funnel` — [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel) 或 [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel) (Funnel Transformer 模型)

+   `gpt-sw3` — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model) (GPT-Sw3 模型)

+   `gpt2` — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model) (OpenAI GPT-2 模型)

+   `gptj` — [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel) (GPT-J 模型)

+   `groupvit` — [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel) (GroupViT 模型)

+   `hubert` — [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel) (Hubert 模型)

+   `layoutlm` — [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel) (LayoutLM 模型)

+   `layoutlmv3` — [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model) (LayoutLMv3 模型)

+   `led` — [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel) (LED 模型)

+   `longformer` — [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel) (Longformer 模型)

+   `lxmert` — [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel) (LXMERT 模型)

+   `marian` — [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel) (Marian 模型)

+   `mbart` — [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel) (mBART 模型)

+   `mobilebert` — [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel) (MobileBERT 模型)

+   `mobilevit` — [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel) (MobileViT 模型)

+   `mpnet` — [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel) (MPNet 模型)

+   `mt5` — [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model) (MT5 模型)

+   `openai-gpt` — [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel) (OpenAI GPT 模型)

+   `opt` — [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel) (OPT 模型)

+   `pegasus` — [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel) (Pegasus 模型)

+   `regnet` — [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel) (RegNet 模型)

+   `rembert` — [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel) (RemBERT 模型)

+   `resnet` — [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel) (ResNet 模型)

+   `roberta` — [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel) (RoFormer 模型)

+   `sam` — [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel) (SAM 模型)

+   `segformer` — [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel) (SegFormer 模型)

+   `speech_to_text` — [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel) (Speech2Text 模型)

+   `swin` — [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel) (Swin Transformer 模型)

+   `t5` — [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model) (T5 模型)

+   `tapas` — [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel) (TAPAS 模型)

+   `transfo-xl` — [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel) (Transformer-XL 模型)

+   `vision-text-dual-encoder` — [TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel) (VisionTextDualEncoder 模型)

+   `vit` — [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel) (ViT 模型)

+   `vit_mae` — [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel) (ViTMAE 模型)

+   `wav2vec2` — [TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model) (Wav2Vec2 模型)

+   `whisper` — [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel) (Whisper 模型)

+   `xglm` — [TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel) (XGLM 模型)

+   `xlm` — [TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel) (XLM-RoBERTa 模型)

+   `xlnet` — [TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel) (XLNet 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModel.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModel.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModel

### `class transformers.FlaxAutoModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L276)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库的基础模型类之一。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类：[FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)（ALBERT 模型）

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类：[FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)（BART 模型）

    +   [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig) 配置类：[FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)（BEiT 模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类：[FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)（BERT 模型）

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类：[FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)（BigBird 模型）

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig) 配置类：[FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)（Blenderbot 模型）

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig) 配置类：[FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)（BlenderbotSmall 模型）

    +   [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig) 配置类：[FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)（BLOOM 模型）

    +   [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig) 配置类：[FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)（CLIP 模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类：[FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)（DistilBERT 模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类：[FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)（ELECTRA 模型）

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类：[FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)（OpenAI GPT-2 模型）

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类：[FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)（GPT-J 模型）

    +   [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig) 配置类: [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel) (GPT Neo 模型)

    +   [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig) 配置类: [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel) (LLaMA 模型)

    +   [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config) 配置类: [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model) (LongT5 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel) (mBART 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model) (MT5 模型)

    +   [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig) 配置类: [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel) (Marian 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel) (OPT 模型)

    +   [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) 配置类: [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel) (Pegasus 模型)

    +   [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) 配置类: [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel) (RegNet 模型)

    +   [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) 配置类: [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel) (ResNet 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel) (RoBERTa-PreLayerNorm 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类: [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model) (T5 模型)

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig) 配置类: [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel) (ViT 模型)

    +   [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig) 配置类: [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel) (VisionTextDualEncoder 模型)

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类: [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model) (Wav2Vec2 模型)

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类: [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel) (Whisper 模型)

    +   [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig) 配置类: [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel) (XGLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel) (XLM-RoBERTa 模型)

从配置中实例化库中的基础模型类之一。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, FlaxAutoModel

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModel.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   一个 *PyTorch state_dict save file* 的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应提供配置对象作为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。

+   `model_args` (额外的位置参数, *可选*) — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载:

    +   该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch checkpoint save 文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载，行为不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个键对应于配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型中实例化库的基本模型类之一。

根据配置对象的 `model_type` 属性选择要实例化的模型类（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel) (ALBERT 模型)

+   `bart` — [FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel) (BART 模型)

+   `beit` — [FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel) (BEiT 模型)

+   `bert` — [FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel) (BERT 模型)

+   `big_bird` — [FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel) (BigBird 模型)

+   `blenderbot` — [FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel) (Blenderbot 模型)

+   `blenderbot-small` — [FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel) (BlenderbotSmall 模型)

+   `bloom` — [FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel) (BLOOM 模型)

+   `clip` — [FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel) (CLIP 模型)

+   `distilbert` — [FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel) (DistilBERT 模型)

+   `electra` — [FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)（ELECTRA模型）

+   `gpt-sw3` — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)（GPT-Sw3模型）

+   `gpt2` — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)（OpenAI GPT-2模型）

+   `gpt_neo` — [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)（GPT Neo模型）

+   `gptj` — [FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)（GPT-J模型）

+   `llama` — [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)（LLaMA模型）

+   `longt5` — [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)（LongT5模型）

+   `marian` — [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)（Marian模型）

+   `mbart` — [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)（mBART模型）

+   `mt5` — [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)（MT5模型）

+   `opt` — [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)（OPT模型）

+   `pegasus` — [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)（Pegasus模型）

+   `regnet` — [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)（RegNet模型）

+   `resnet` — [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)（ResNet模型）

+   `roberta` — [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)（RoBERTa模型）

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)（RoBERTa-PreLayerNorm模型）

+   `roformer` — [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)（RoFormer模型）

+   `t5` — [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)（T5模型）

+   `vision-text-dual-encoder` — [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)（VisionTextDualEncoder模型）

+   `vit` — [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)（ViT模型）

+   `wav2vec2` — [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)（Wav2Vec2模型）

+   `whisper` — [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)（Whisper模型）

+   `xglm` — [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)（XGLM模型）

+   `xlm-roberta` — [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)（XLM-RoBERTa模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModel.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModel.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

## 通用预训练类

以下自动类可用于实例化带有预训练头部的模型。

### AutoModelForPreTraining

### `class transformers.AutoModelForPreTraining`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1311)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有预训练头部）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig) 配置类: [AlbertForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertForPreTraining) (ALBERT 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig) 配置类: [BartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartForConditionalGeneration) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig) 配置类: [BertForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForPreTraining) (BERT 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [BigBirdForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdForPreTraining) (BigBird 模型)

    +   [BloomConfig](/docs/transformers/v4.37.2/zh/model_doc/bloom#transformers.BloomConfig) 配置类: [BloomForCausalLM](/docs/transformers/v4.37.2/zh/model_doc/bloom#transformers.BloomForCausalLM) (BLOOM 模型)

    +   [CTRLConfig](/docs/transformers/v4.37.2/zh/model_doc/ctrl#transformers.CTRLConfig) 配置类: [CTRLLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/ctrl#transformers.CTRLLMHeadModel) (CTRL 模型)

    +   [CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig) 配置类: [CamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertForMaskedLM) (CamemBERT 模型)

    +   [Data2VecTextConfig](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextConfig) 配置类: [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextForMaskedLM) (Data2VecText 模型)

    +   [DebertaConfig](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaConfig) 配置类: [DebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaForMaskedLM) (DeBERTa 模型)

    +   [DebertaV2Config](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类: [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM) (DeBERTa-v2 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [DistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertForMaskedLM) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraConfig) 配置类: [ElectraForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraForPreTraining) (ELECTRA 模型)

    +   [ErnieConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieConfig) 配置类: [ErnieForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieForPreTraining) (ERNIE 模型)

    +   [FNetConfig](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetConfig) 配置类: [FNetForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetForPreTraining) (FNet 模型)

    +   [FSMTConfig](/docs/transformers/v4.37.2/zh/model_doc/fsmt#transformers.FSMTConfig) 配置类: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/fsmt#transformers.FSMTForConditionalGeneration) (FairSeq 机器翻译模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.FlaubertWithLMHeadModel) (FlauBERT 模型)

    +   [FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig) 配置类: [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining) (FLAVA 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining) (Funnel Transformer 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel) (OpenAI GPT-2 模型)

    +   [GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig) 配置类: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM) (GPTBigCode 模型)

    +   [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig) 配置类: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration) (GPTSAN-japanese 模型)

    +   [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig) 配置类: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM) (I-BERT 模型)

    +   [IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig) 配置类: [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text) (IDEFICS 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM) (LayoutLM 模型)

    +   [LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig) 配置类: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration) (LLaVa 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM) (Longformer 模型)

    +   [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig) 配置类: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM) (LUKE 模型)

    +   [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig) 配置类: [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining) (LXMERT 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM) (MPNet 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining) (Megatron-BERT 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining) (MobileBERT 模型)

    +   [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) 配置类: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM) (MPT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM) (MRA 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration) (MVP 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining) (Nezha 模型)

    +   [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig) 配置类: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration) (NLLB-MOE 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel) (OpenAI GPT 模型)

    +   [RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig) 配置类: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel) (RetriBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining) (RoCBert 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

    +   [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig) 配置类: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM) (RWKV 模型)

    +   [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig) 配置类: [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining) (Splinter 模型)

    +   [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) 配置类: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM) (SqueezeBERT 模型)

    +   [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig) 配置类: [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration) (SwitchTransformers 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类: [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration) (T5 模型)

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) 配置类: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM) (TAPAS 模型)

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel) (Transformer-XL 模型)

    +   [TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig) 配置类: [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining) (TVLT 模型)

    +   [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig) 配置类: [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining) (UniSpeech 模型)

    +   [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) 配置类: [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining) (UniSpeechSat 模型)

    +   [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig) 配置类: [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining) (ViTMAE 模型)

    +   [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig) 配置类: [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining) (VideoMAE 模型)

    +   [VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig) 配置类: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration) (VipLlava 模型)

    +   [VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig) 配置类: [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining) (VisualBERT 模型)

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类: [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining) (Wav2Vec2 模型)

    +   [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig) 配置类: [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining) (Wav2Vec2-Conformer 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM) (XLM-RoBERTa-XL 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类: [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel) (XLNet 模型)

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig) 配置类: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM) (X-MOD 模型)

从配置实例化库中的一个模型类（带有预训练头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForPreTraining

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForPreTraining.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，托管在huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_tf`（`bool`，*可选*，默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除未完全接收的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 要使用的代理服务器的字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载了 `config`，行为会有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个与配置属性对应的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有预训练头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [AlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForPreTraining) (ALBERT 模型)

+   `bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration) (BART 模型)

+   `bert` — [BertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForPreTraining) (BERT 模型)

+   `big_bird` — [BigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining) (BigBird 模型)

+   `bloom` — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM) (BLOOM 模型)

+   `camembert` — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM) (CamemBERT 模型)

+   `ctrl` — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel) (CTRL 模型)

+   `data2vec-text` — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM) (Data2VecText 模型)

+   `deberta` — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM) (DistilBERT 模型)

+   `electra` — [ElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForPreTraining) (ELECTRA 模型)

+   `ernie` — [ErnieForPreTraining](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForPreTraining) (ERNIE 模型)

+   `flaubert` — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel) (FlauBERT 模型)

+   `flava` — [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining) (FLAVA 模型)

+   `fnet` — [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining) (FNet 模型)

+   `fsmt` — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration) (FairSeq 机器翻译模型)

+   `funnel` — [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining) (Funnel Transformer 模型)

+   `gpt-sw3` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel) (GPT-Sw3 模型)

+   `gpt2` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel) (OpenAI GPT-2 模型)

+   `gpt_bigcode` — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM) (GPTBigCode 模型)

+   `gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration) (GPTSAN-japanese 模型)

+   `ibert` — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM) (I-BERT 模型)

+   `idefics` — [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text) (IDEFICS 模型)

+   `layoutlm` — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM) (LayoutLM 模型)

+   `llava` — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration) (LLaVa 模型)

+   `longformer` — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM) (Longformer 模型)

+   `luke` — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM) (LUKE 模型)

+   `lxmert` — [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining) (LXMERT 模型)

+   `mega` — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM) (MEGA 模型)

+   `megatron-bert` — [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining) (Megatron-BERT 模型)

+   `mobilebert` — [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining) (MobileBERT 模型)

+   `mpnet` — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM) (MPNet 模型)

+   `mpt` — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM) (MPT 模型)

+   `mra` — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM) (MRA 模型)

+   `mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration) (MVP 模型)

+   `nezha` — [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining) (Nezha 模型)

+   `nllb-moe` — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration) (NLLB-MOE 模型)

+   `openai-gpt` — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel) (OpenAI GPT 模型)

+   `retribert` — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel) (RetriBERT 模型)

+   `roberta` — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining) (RoCBert 模型)

+   `rwkv` — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM) (RWKV 模型)

+   `splinter` — [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining) (Splinter 模型)

+   `squeezebert` — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM) (SqueezeBERT 模型)

+   `switch_transformers` — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration) (SwitchTransformers 模型)

+   `t5` — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration) (T5 模型)

+   `tapas` — [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM) (TAPAS 模型)

+   `transfo-xl` — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel) (Transformer-XL 模型)

+   `tvlt` — [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining) (TVLT 模型)

+   `unispeech` — [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining) (UniSpeech 模型)

+   `unispeech-sat` — [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining) (UniSpeechSat 模型)

+   `videomae` — [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining) (VideoMAE 模型)

+   `vipllava` — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration) (VipLlava 模型)

+   `visual_bert` — [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining) (VisualBERT 模型)

+   `vit_mae` — [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining) (ViTMAE 模型)

+   `wav2vec2` — [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining) (Wav2Vec2 模型)

+   `wav2vec2-conformer` — [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining) (Wav2Vec2-Conformer 模型)

+   `xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel) (XLM 模型)

+   `xlm-roberta` — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

+   `xlm-roberta-xl` — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM) (XLM-RoBERTa-XL 模型)

+   `xlnet` — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel) (XLNet 模型)

+   `xmod` — [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM) (X-MOD 模型)

默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForPreTraining

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForPreTraining.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForPreTraining

### `class transformers.TFAutoModelForPreTraining`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L547)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有预训练头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)（ALBERT模型）

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)（BART模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)（BERT模型）

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)配置类：[TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)（CTRL模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)配置类：[TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)（CamemBERT模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)配置类：[TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)（DistilBERT模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)配置类：[TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)（ELECTRA模型）

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)配置类：[TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)（FlauBERT模型）

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)配置类：[TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)（漏斗Transformer模型）

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)配置类：[TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)（OpenAI GPT-2模型）

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)配置类：[TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)（LayoutLM模型）

    +   [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)配置类：[TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)（LXMERT模型）

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)配置类：[TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)（MPNet模型）

    +   [MobileBertConfig](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.MobileBertConfig) 配置类：[TFMobileBertForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)（MobileBERT 模型）

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/zh/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类：[TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)（OpenAI GPT 模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.RobertaConfig) 配置类：[TFRobertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.TFRobertaForMaskedLM)（RoBERTa 模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类：[TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)（RoBERTa-PreLayerNorm 模型）

    +   [T5Config](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.T5Config) 配置类：[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.TFT5ForConditionalGeneration)（T5 模型）

    +   [TapasConfig](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TapasConfig) 配置类：[TFTapasForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TFTapasForMaskedLM)（TAPAS 模型）

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/zh/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类：[TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)（Transformer-XL 模型）

    +   [ViTMAEConfig](/docs/transformers/v4.37.2/zh/model_doc/vit_mae#transformers.ViTMAEConfig) 配置类：[TFViTMAEForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)（ViTMAE 模型）

    +   [XLMConfig](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMConfig) 配置类：[TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.TFXLMWithLMHeadModel)（XLM 模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)（XLM-RoBERTa 模型）

    +   [XLNetConfig](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.XLNetConfig) 配置类：[TFXLNetLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.TFXLNetLMHeadModel)（XLNet 模型）

从配置实例化库中的一个模型类（带有预训练头）。

注意：从配置文件加载模型 **不会** 加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForPreTraining

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForPreTraining.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 路径，例如，`./my_model_directory/`。

    +   路径或 URL 指向 *PyTorch state_dict 保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应提供配置对象作为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*optional*） — 用于模型的配置，而不是自动加载的配置。当以下情况发生时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为 *config.json* 的配置 JSON 文件加载模型。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制下载（重新下载）模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个对应配置属性的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有预训练头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining) (ALBERT 模型)

+   `bart` — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration) (BART 模型)

+   `bert` — [TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining) (BERT 模型)

+   `camembert` — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM) (CamemBERT 模型)

+   `ctrl` — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel) (CTRL 模型)

+   `distilbert` — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM) (DistilBERT 模型)

+   `electra` — [TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining) (ELECTRA 模型)

+   `flaubert` — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel) (FlauBERT 模型)

+   `funnel` — [TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining) (Funnel Transformer 模型)

+   `gpt-sw3` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel) (GPT-Sw3 模型)

+   `gpt2` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel) (OpenAI GPT-2 模型)

+   `layoutlm` — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM) (LayoutLM 模型)

+   `lxmert` — [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining) (LXMERT 模型)

+   `mobilebert` — [TFMobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining) (MobileBERT 模型)

+   `mpnet` — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM) (MPNet 模型)

+   `openai-gpt` — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel) (OpenAI GPT 模型)

+   `roberta` — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

+   `t5` — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration) (T5 模型)

+   `tapas` — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM) (TAPAS 模型)

+   `transfo-xl` — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel) (Transformer-XL 模型)

+   `vit_mae` — [TFViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining) (ViTMAE 模型)

+   `xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)（XLM模型）

+   `xlm-roberta` — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)（XLM-RoBERTa模型）

+   `xlnet` — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)（XLNet模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForPreTraining

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForPreTraining.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForPreTraining

### `class transformers.FlaxAutoModelForPreTraining`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L283)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有预训练头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)（ALBERT模型）

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)（BERT模型）

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)配置类：[FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)（BigBird模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)配置类：[FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)（ELECTRA模型）

    +   [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)配置类：[FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)（LongT5模型）

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)配置类：[FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)配置类：[FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)（MT5模型）

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)配置类：[FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)（RoFormer模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)配置类：[FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)（RoBERTa模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类: [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration) (T5 模型)

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类: [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining) (Wav2Vec2 模型)

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类: [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration) (Whisper 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

从配置实例化库中的一个模型类（带有预训练头）时，可以自动加载配置。

注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, FlaxAutoModelForPreTraining

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForPreTraining.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:

    +   一个字符串，预训练模型的 *model id*，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   *PyTorch state_dict save file* 的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应将配置对象作为 `config` 参数提供。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*) — 用于替代自动加载的配置的模型配置。当:

    +   是库提供的模型（使用预训练模型的 *model id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` 或 `os.PathLike`，*可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 在 Hub 上使用的特定代码修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，其行为有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有预训练头）。

根据配置对象的 `model_type` 属性选择要实例化的模型类（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)（ALBERT模型）

+   `bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）

+   `bert` — [FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)（BERT模型）

+   `big_bird` — [FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)（BigBird模型）

+   `electra` — [FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)（ELECTRA模型）

+   `longt5` — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration) (LongT5 模型)

+   `mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration) (mBART 模型)

+   `mt5` — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration) (MT5 模型)

+   `roberta` — [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM) (RoFormer 模型)

+   `t5` — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration) (T5 模型)

+   `wav2vec2` — [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining) (Wav2Vec2 模型)

+   `whisper` — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration) (Whisper 模型)

+   `xlm-roberta` — [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

示例:

```py
>>> from transformers import AutoConfig, FlaxAutoModelForPreTraining

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForPreTraining.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

## 自然语言处理

以下自动类适用于以下自然语言处理任务。

### AutoModelForCausalLM

### `class transformers.AutoModelForCausalLM`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1326)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库中的一个模型类（带有因果语言建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel) (BERT 模型)

    +   [BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig) 配置类: [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder) (Bert Generation 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM) (BigBird 模型)

    +   [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig) 配置类: [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM) (BigBird-Pegasus 模型)

    +   [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig) 配置类: [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM) (BioGpt 模型)

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig) 配置类: [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM) (Blenderbot 模型)

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig) 配置类: [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM) (BlenderbotSmall 模型)

    +   [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig) 配置类: [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM) (BLOOM 模型)

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig) 配置类: [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel) (CTRL 模型)

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) 配置类: [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM) (CamemBERT 模型)

    +   [CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig) 配置类: [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM) (CodeGen 模型)

    +   [CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig) 配置类: [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM) (CPM-Ant 模型)

    +   [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig) 配置类: [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM) (Data2VecText 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM) (ELECTRA 模型)

    +   [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig) 配置类: [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM) (ERNIE 模型)

    +   [FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig) 配置类: [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM) (Falcon 模型)

    +   [FuyuConfig](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuConfig) 配置类: [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM) (Fuyu 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel) (OpenAI GPT-2 模型)

    +   [GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig) 配置类: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM) (GPTBigCode 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM) (GPT-J 模型)

    +   [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig) 配置类: [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM) (GPT Neo 模型)

    +   [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig) 配置类: [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM) (GPT NeoX 模型)

    +   [GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig) 配置类: [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM) (GPT NeoX Japanese 模型)

    +   [GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig) 配置类: [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM) (GIT 模型)

    +   [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig) 配置类: [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM) (LLaMA 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM) (mBART 模型)

    +   [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig) 配置类: [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM) (Marian 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM) (Megatron-BERT 模型)

    +   [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig) 配置类: [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM) (Mistral 模型)

    +   [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig) 配置类: [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM) (Mixtral 模型)

    +   [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) 配置类: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM) (MPT 模型)

    +   [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig) 配置类: [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM) (MusicGen 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM) (MVP 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM) (OPT 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel) (OpenAI GPT 模型)

    +   [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig) 配置类: [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM) (OpenLlama 模型)

    +   [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig) 配置类: [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM) (PLBart 模型)

    +   [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) 配置类: [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM) (Pegasus 模型)

    +   [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig) 配置类: [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM) (Persimmon 模型)

    +   [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig) 配置类: [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM) (Phi 模型)

    +   [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig) 配置类: [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM) (ProphetNet 模型)

    +   [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) 配置类: [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel) (QDQBert 模型)

    +   [Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config) 配置类: [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM) (Qwen2 模型)

    +   [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig) 配置类: [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead) (Reformer 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM) (RemBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM) (RoCBert 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM) (RoBERTa-PreLayerNorm 模型)

    +   [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig) 配置类: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM) (RWKV 模型)

    +   [Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config) 配置类: [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM) (Speech2Text2 模型)

    +   [TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig) 配置类: [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM) (TrOCR 模型)

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel) (Transformer-XL 模型)

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类：[WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)（Whisper 模型）

    +   [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig) 配置类：[XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)（XGLM 模型）

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类：[XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)（XLM 模型）

    +   [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig) 配置类：[XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)（XLM-ProphetNet 模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)（XLM-RoBERTa 模型）

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类：[XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)（XLM-RoBERTa-XL 模型）

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类：[XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)（XLNet 模型）

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig) 配置类：[XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)（X-MOD 模型）

从配置实例化库中的一个模型类（带有因果语言建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForCausalLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForCausalLM.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`）- 可以是：

    +   一个字符串，预训练模型的*模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间下的用户或组织名称，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将 `from_tf` 设置为 `True`，并且应提供配置对象作为 `config` 参数。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载 PyTorch 模型后，此加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 用于替代自动加载的配置的模型配置。当：

    +   模型是库提供的模型（使用预训练模型的*模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并在目录中找到名为 *config.json* 的配置 JSON 文件。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为`"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs` (额外的关键字参数, *optional*) — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，其行为会有所不同：

    +   如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则首先将 `kwargs` 传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个键对应于一个配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型中实例化库中的一个模型类（带有因果语言建模头）。

根据配置对象的 `model_type` 属性（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），选择要实例化的模型类，或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `bart` — [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM) (BART 模型)

+   `bert` — [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel) (BERT 模型)

+   `bert-generation` — [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder) (Bert Generation 模型)

+   `big_bird` — [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM) (BigBird 模型)

+   `bigbird_pegasus` — [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM) (BigBird-Pegasus 模型)

+   `biogpt` — [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM) (BioGpt 模型)

+   `blenderbot` — [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM) (Blenderbot 模型)

+   `blenderbot-small` — [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM) (BlenderbotSmall 模型)

+   `bloom` — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM) (BLOOM 模型)

+   `camembert` — [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM) (CamemBERT 模型)

+   `code_llama` — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM) (CodeLlama 模型)

+   `codegen` — [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM) (CodeGen 模型)

+   `cpmant` — [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM) (CPM-Ant 模型)

+   `ctrl` — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel) (CTRL 模型)

+   `data2vec-text` — [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM) (Data2VecText 模型)

+   `electra` — [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM) (ELECTRA 模型)

+   `ernie` — [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM) (ERNIE 模型)

+   `falcon` — [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM) (Falcon 模型)

+   `fuyu` — [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM) (Fuyu 模型)

+   `git` — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM) (GIT 模型)

+   `gpt-sw3` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel) (GPT-Sw3 模型)

+   `gpt2` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel) (OpenAI GPT-2 模型)

+   `gpt_bigcode` — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM) (GPTBigCode 模型)

+   `gpt_neo` — [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM) (GPT Neo 模型)

+   `gpt_neox` — [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM) (GPT NeoX 模型)

+   `gpt_neox_japanese` — [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM) (GPT NeoX 日语模型)

+   `gptj` — [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM) (GPT-J 模型)

+   `llama` — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM) (LLaMA 模型)

+   `marian` — [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM) (Marian 模型)

+   `mbart` — [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM) (mBART 模型)

+   `mega` — [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM) (MEGA 模型)

+   `megatron-bert` — [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM) (Megatron-BERT 模型)

+   `mistral` — [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM) (Mistral 模型)

+   `mixtral` — [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM) (Mixtral 模型)

+   `mpt` — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM) (MPT 模型)

+   `musicgen` — [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM) (MusicGen 模型)

+   `mvp` — [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM) (MVP 模型)

+   `open-llama` — [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM) (OpenLlama 模型)

+   `openai-gpt` — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel) (OpenAI GPT 模型)

+   `opt` — [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM) (OPT 模型)

+   `pegasus` — [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM) (Pegasus 模型)

+   `persimmon` — [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM) (Persimmon 模型)

+   `phi` — [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM) (Phi 模型)

+   `plbart` — [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM) (PLBart 模型)

+   `prophetnet` — [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM) (ProphetNet 模型)

+   `qdqbert` — [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel) (QDQBert 模型)

+   `qwen2` — [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM) (Qwen2 模型)

+   `reformer` — [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead) (Reformer 模型)

+   `rembert` — [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM) (RemBERT 模型)

+   `roberta` — [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM) (RoCBert 模型)

+   `roformer` — [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM) (RoFormer 模型)

+   `rwkv` — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)（RWKV模型）

+   `speech_to_text_2` — [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)（Speech2Text2模型）

+   `transfo-xl` — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)（Transformer-XL模型）

+   `trocr` — [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)（TrOCR模型）

+   `whisper` — [WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)（Whisper模型）

+   `xglm` — [XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)（XGLM模型）

+   `xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)（XLM模型）

+   `xlm-prophetnet` — [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)（XLM-ProphetNet模型）

+   `xlm-roberta` — [XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)（XLM-RoBERTa模型）

+   `xlm-roberta-xl` — [XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)（XLM-RoBERTa-XL模型）

+   `xlnet` — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)（XLNet模型）

+   `xmod` — [XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)（X-MOD模型）

默认情况下，该模型处于评估模式，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForCausalLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForCausalLM.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForCausalLM

### `class transformers.TFAutoModelForCausalLM`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L562)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库中的模型类之一实例化（带有因果语言建模头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—将要实例化的模型类是基于配置类选择的：

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)（BERT模型）

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)配置类：[TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)（CTRL模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)配置类：[TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)（CamemBERT模型）

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)配置类：[TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)（OpenAI GPT-2模型）

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)配置类：[TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)（GPT-J模型）

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM) (OPT 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel) (OpenAI GPT 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM) (RemBERT 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM) (RoBERTa-PreLayerNorm 模型)

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类: [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel) (Transformer-XL 模型)

    +   [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig) 配置类: [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM) (XGLM 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM) (XLM-RoBERTa 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类: [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel) (XLNet 模型)

从配置实例化库中的一个模型类（带有因果语言建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForCausalLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForCausalLM.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：

    +   一个字符串，预训练模型的*模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   路径或url到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象作为`config`参数提供。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当：

    +   模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`）— 是否返回包含丢失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可以用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有因果语言建模头）。

根据配置对象的 `model_type` 属性选择要实例化的模型类（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `bert` — [TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel) (BERT 模型)

+   `camembert` — [TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM) (CamemBERT 模型)

+   `ctrl` — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel) (CTRL 模型)

+   `gpt-sw3` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel) (GPT-Sw3 模型)

+   `gpt2` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel) (OpenAI GPT-2 模型)

+   `gptj` — [TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM) (GPT-J 模型)

+   `openai-gpt` — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel) (OpenAI GPT 模型)

+   `opt` — [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM) (OPT 模型)

+   `rembert` — [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM) (RemBERT 模型)

+   `roberta` — [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM) (RoFormer 模型)

+   `transfo-xl` — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel) (Transformer-XL 模型)

+   `xglm` — [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM) (XGLM 模型)

+   `xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM) (XLM-RoBERTa 模型)

+   `xlnet` — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel) (XLNet 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForCausalLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForCausalLM.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForCausalLM

### `class transformers.FlaxAutoModelForCausalLM`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L290)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库中的一个模型类（带有因果语言建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM) (BERT 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM) (BigBird 模型)

    +   [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig) 配置类: [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM) (BLOOM 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM) (ELECTRA 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel) (OpenAI GPT-2 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM) (GPT-J 模型)

    +   [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig) 配置类: [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM) (GPT Neo 模型)

    +   [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig) 配置类: [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM) (LLaMA 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM) (OPT 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM) (RoBERTa-PreLayerNorm 模型)

    +   [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig) 配置类: [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM) (XGLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM) (XLM-RoBERTa 模型)

从配置中实例化库中的一个模型类（带有因果语言建模头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForCausalLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForCausalLM.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的*模型 ID*，托管在 huggingface.co 上的模型存储库中。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict save file*的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应该将配置对象作为 `config` 参数提供。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并加载 TensorFlow 模型后，此加载路径比较慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型 ID*字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理服务器在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否只查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有因果语言建模头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `bart` — [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)（BART模型）

+   `bert` — [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)（BERT模型）

+   `big_bird` — [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)（BigBird模型）

+   `bloom` — [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)（BLOOM模型）

+   `electra` — [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)（ELECTRA模型）

+   `gpt-sw3` — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)（GPT-Sw3模型）

+   `gpt2` — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)（OpenAI GPT-2模型）

+   `gpt_neo` — [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)（GPT Neo模型）

+   `gptj` — [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)（GPT-J模型）

+   `llama` — [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)（LLaMA模型）

+   `opt` — [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)（OPT模型）

+   `roberta` — [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)（RoBERTa模型）

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)（RoBERTa-PreLayerNorm模型）

+   `xglm` — [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)（XGLM模型）

+   `xlm-roberta` — [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)（XLM-RoBERTa 模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForCausalLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForCausalLM.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForMaskedLM

### `class transformers.AutoModelForMaskedLM`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1333)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有一个掩码语言建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)） — 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig) 配置类：[AlbertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertForMaskedLM)（ALBERT 模型）

    +   [BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig) 配置类：[BartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartForConditionalGeneration)（BART 模型）

    +   [BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig) 配置类：[BertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForMaskedLM)（BERT 模型）

    +   [BigBirdConfig](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdConfig) 配置类：[BigBirdForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdForMaskedLM)（BigBird 模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig) 配置类：[CamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertForMaskedLM)（CamemBERT 模型）

    +   [ConvBertConfig](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertConfig) 配置类：[ConvBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertForMaskedLM)（ConvBERT 模型）

    +   [Data2VecTextConfig](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextConfig) 配置类：[Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)（Data2VecText 模型）

    +   [DebertaConfig](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaConfig) 配置类：[DebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaForMaskedLM)（DeBERTa 模型）

    +   [DebertaV2Config](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类：[DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)（DeBERTa-v2 模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig) 配置类：[DistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertForMaskedLM)（DistilBERT 模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraConfig) 配置类：[ElectraForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraForMaskedLM)（ELECTRA 模型）

    +   [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig) 配置类: [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM) (ERNIE 模型)

    +   [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig) 配置类: [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM) (ESM 模型)

    +   [FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig) 配置类: [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM) (FNet 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM) (Funnel Transformer 模型)

    +   [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig) 配置类: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM) (I-BERT 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM) (LayoutLM 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM) (Longformer 模型)

    +   [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig) 配置类: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM) (LUKE 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration) (mBART 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM) (MPNet 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM) (Megatron-BERT 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM) (MobileBERT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM) (MRA 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration) (MVP 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM) (Nezha 模型)

    +   [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) 配置类: [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM) (Nyströmformer 模型)

    +   [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig) 配置类: [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM) (Perceiver 模型)

    +   [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) 配置类: [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM) (QDQBert 模型)

    +   [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig) 配置类: [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM) (Reformer 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM) (RemBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM) (RoCBert 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

    +   [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) 配置类: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM) (SqueezeBERT 模型)

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) 配置类: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM) (TAPAS 模型)

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类: `Wav2Vec2ForMaskedLM` (Wav2Vec2 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM) (XLM-RoBERTa-XL 模型)

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig) 配置类: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM) (X-MOD 模型)

    +   [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig) 配置类：[YosoForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMaskedLM)（YOSO模型）

从配置实例化库中的一个模型类（带有掩码语言建模头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForMaskedLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForMaskedLM.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str`或`os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*） — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。

+   `cache_dir` (`str`或`os.PathLike`, *可选*) — 下载预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *可选*, 默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺少键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地计算机上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型中实例化库中的一个模型类（带有掩码语言建模头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `albert` — [AlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMaskedLM)（ALBERT模型）

+   `bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)（BART模型）

+   `bert` — [BertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMaskedLM)（BERT模型）

+   `big_bird` — [BigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM)（BigBird模型）

+   `camembert` — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)（CamemBERT模型）

+   `convbert` — [ConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM)（ConvBERT模型）

+   `data2vec-text` — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)（Data2VecText模型）

+   `deberta` — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)（DeBERTa模型）

+   `deberta-v2` — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM) (DistilBERT 模型)

+   `electra` — [ElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMaskedLM) (ELECTRA 模型)

+   `ernie` — [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM) (ERNIE 模型)

+   `esm` — [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM) (ESM 模型)

+   `flaubert` — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel) (FlauBERT 模型)

+   `fnet` — [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM) (FNet 模型)

+   `funnel` — [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM) (Funnel Transformer 模型)

+   `ibert` — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM) (I-BERT 模型)

+   `layoutlm` — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM) (LayoutLM 模型)

+   `longformer` — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM) (Longformer 模型)

+   `luke` — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM) (LUKE 模型)

+   `mbart` — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration) (mBART 模型)

+   `mega` — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM) (MEGA 模型)

+   `megatron-bert` — [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM) (Megatron-BERT 模型)

+   `mobilebert` — [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM) (MobileBERT 模型)

+   `mpnet` — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM) (MPNet 模型)

+   `mra` — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM) (MRA 模型)

+   `mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration) (MVP 模型)

+   `nezha` — [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM) (Nezha 模型)

+   `nystromformer` — [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM) (Nyströmformer 模型)

+   `perceiver` — [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM) (Perceiver 模型)

+   `qdqbert` — [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM) (QDQBert 模型)

+   `reformer` — [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM) (Reformer 模型)

+   `rembert` — [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM) (RemBERT 模型)

+   `roberta` — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM) (RoCBert 模型)

+   `roformer` — [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM) (RoFormer 模型)

+   `squeezebert` — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)（SqueezeBERT 模型）

+   `tapas` — [TapasForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TapasForMaskedLM)（TAPAS 模型）

+   `wav2vec2` — `Wav2Vec2ForMaskedLM`（Wav2Vec2 模型）

+   `xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMWithLMHeadModel)（XLM 模型）

+   `xlm-roberta` — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)（XLM-RoBERTa 模型）

+   `xlm-roberta-xl` — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)（XLM-RoBERTa-XL 模型）

+   `xmod` — [XmodForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xmod#transformers.XmodForMaskedLM)（X-MOD 模型）

+   `yoso` — [YosoForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/yoso#transformers.YosoForMaskedLM)（YOSO 模型）

默认情况下，使用 `model.eval()` 将模型设置为评估模式（例如，关闭了 dropout 模块）。要训练模型，应该首先使用 `model.train()` 将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForMaskedLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForMaskedLM.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForMaskedLM

### `class transformers.TFAutoModelForMaskedLM`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L612)

```py
( *args **kwargs )
```

这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库中的模型类之一实例化（带有掩码语言建模头）。

这个类不能直接使用 `__init__()` 实例化（会报错）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)） — 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig) 配置类：[TFAlbertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForMaskedLM)（ALBERT 模型）

    +   [BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig) 配置类：[TFBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForMaskedLM)（BERT 模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig) 配置类：[TFCamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForMaskedLM)（CamemBERT 模型）

    +   [ConvBertConfig](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertConfig) 配置类：[TFConvBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.TFConvBertForMaskedLM)（ConvBERT 模型）

    +   [DebertaConfig](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaConfig) 配置类：[TFDebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.TFDebertaForMaskedLM)（DeBERTa 模型）

    +   [DebertaV2Config](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类：[TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)（DeBERTa-v2 模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig) 配置类：[TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)（DistilBERT 模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [TFElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMaskedLM) (ELECTRA 模型)

    +   [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig) 配置类: [TFEsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForMaskedLM) (ESM 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM) (Funnel Transformer 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM) (LayoutLM 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM) (Longformer 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM) (MPNet 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM) (MobileBERT 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM) (RemBERT 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) 配置类: [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM) (TAPAS 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

从配置实例化库中的一个模型类（带有掩码语言建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForMaskedLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForMaskedLM.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：

    +   预训练模型的 *model id* 字符串，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间，如 `dbmdz/bert-base-german-cased`。

    +   包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 路径，例如 `./my_model_directory/`。

    +   指向 *PyTorch state_dict 保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*) — 用于模型的配置，而不是自动加载的配置。当：

    +   该模型是库提供的模型（使用预训练模型的 *model id* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在该目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` 或 `os.PathLike`，*可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt` (`bool`，*可选*，默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`，*可选*，默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖已存在的缓存版本。

+   `resume_download` (`bool`，*可选*，默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`，*可选*) — 要按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理将在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`，*可选*，默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为 `False`） — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为 `"main"`） — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为会有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个对应于配置属性的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有遮蔽语言建模头）。

要实例化的模型类基于配置对象的 `model_type` 属性（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来选择：

+   `albert` — [TFAlbertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForMaskedLM) (ALBERT 模型)

+   `bert` — [TFBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForMaskedLM) (BERT 模型)

+   `camembert` — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForMaskedLM) (CamemBERT 模型)

+   `convbert` — [TFConvBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.TFConvBertForMaskedLM) (ConvBERT 模型)

+   `deberta` — [TFDebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.TFDebertaForMaskedLM) (DeBERTa 模型)

+   `deberta-v2` — [TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM) (DeBERTa-v2 模型)

+   `distilbert` — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.TFDistilBertForMaskedLM) (DistilBERT 模型)

+   `electra` — [TFElectraForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.TFElectraForMaskedLM) (ELECTRA 模型)

+   `esm` — [TFEsmForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/esm#transformers.TFEsmForMaskedLM) (ESM 模型)

+   `flaubert` — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel) (FlauBERT 模型)

+   `funnel` — [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/funnel#transformers.TFFunnelForMaskedLM) (Funnel Transformer 模型)

+   `layoutlm` — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM) (LayoutLM 模型)

+   `longformer` — [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/longformer#transformers.TFLongformerForMaskedLM) (Longformer 模型)

+   `mobilebert` — [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM) (MobileBERT 模型)

+   `mpnet` — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM) (MPNet 模型)

+   `rembert` — [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM) (RemBERT 模型)

+   `roberta` — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM) (RoFormer 模型)

+   `tapas` — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM) (TAPAS 模型)

+   `xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM) (XLM-RoBERTa 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForMaskedLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForMaskedLM.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForMaskedLM

### `class transformers.FlaxAutoModelForMaskedLM`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L297)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的模型类之一（带有遮蔽语言建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类: [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM) (ALBERT 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM) (BERT 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM) (BigBird 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM) (ELECTRA 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类：[FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类：[FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)（RoFormer模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类：[FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)（RoBERTa模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类：[FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)（RoBERTa-PreLayerNorm模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)（XLM-RoBERTa模型）

从配置实例化库中的一个模型类（带有掩码语言建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForMaskedLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForMaskedLM.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当以下情况自动加载配置时：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 预下载的模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码与模型的其余部分不在同一存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了`config`配置，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有掩码语言建模头）。

实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `albert` — [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)（ALBERT模型）

+   `bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）

+   `bert` — [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)（BERT模型）

+   `big_bird` — [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)（BigBird模型）

+   `distilbert` — [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)（DistilBERT模型）

+   `electra` - [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)（ELECTRA模型）

+   `mbart` - [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）

+   `roberta` - [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)（RoBERTa模型）

+   `roberta-prelayernorm` - [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)（RoBERTa-PreLayerNorm模型）

+   `roformer` - [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)（RoFormer模型）

+   `xlm-roberta` - [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)（XLM-RoBERTa模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForMaskedLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForMaskedLM.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### 自动模型用于生成口罩

### `class transformers.AutoModelForMaskGeneration`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1292)

```py
( *args **kwargs )
```

### TFAutoModelForMaskGeneration

### `class transformers.TFAutoModelForMaskGeneration`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L523)

```py
( *args **kwargs )
```

### AutoModelForSeq2SeqLM

### `class transformers.AutoModelForSeq2SeqLM`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1340)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库的模型类之一（带有序列到序列语言建模头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-选择要实例化的模型类基于配置类：

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)（BART模型）

    +   [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)配置类：[BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)（BigBird-Pegasus模型）

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)配置类：[BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)（Blenderbot模型）

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)配置类：[BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)（BlenderbotSmall模型）

    +   [EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)配置类：[EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)（编码器解码器模型）

    +   [FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig) 配置类: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration) (FairSeq 机器翻译模型)

    +   [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig) 配置类: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration) (GPTSAN-japanese 模型)

    +   [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig) 配置类: [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration) (LED 模型)

    +   [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config) 配置类: [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration) (LongT5 模型)

    +   [M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config) 配置类: [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration) (M2M100 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration) (mBART 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration) (MT5 模型)

    +   [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig) 配置类: [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel) (Marian 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration) (MVP 模型)

    +   [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig) 配置类: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration) (NLLB-MOE 模型)

    +   [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig) 配置类: [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration) (PLBart 模型)

    +   [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) 配置类: [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration) (Pegasus 模型)

    +   [PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig) 配置类: [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration) (PEGASUS-X 模型)

    +   [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig) 配置类: [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration) (ProphetNet 模型)

    +   [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig) 配置类: [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText) (SeamlessM4T 模型)

    +   [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config) 配置类：[SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText) (SeamlessM4Tv2 模型)

    +   [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig) 配置类：[SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration) (SwitchTransformers 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类：[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration) (T5 模型)

    +   [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config) 配置类：[UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration) (UMT5 模型)

    +   [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig) 配置类：[XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration) (XLM-ProphetNet 模型)

从配置实例化库中的模型类（带有序列到序列语言建模头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForSeq2SeqLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("t5-base")
>>> model = AutoModelForSeq2SeqLM.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：

    +   一个字符串，即在 huggingface.co 上托管的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个指向使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。

    +   一个指向 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载 PyTorch 模型后，此加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 用于替代从保存的权重文件加载的状态字典的状态字典。

    如果您想从预训练配置创建模型，但加载自己的权重，可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`，*可选*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *可选*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在Hub上定义自定义模型的代码。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有序列到序列语言建模头）。

要实例化的模型类基于配置对象的 `model_type` 属性进行选择（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration) (BART 模型)

+   `bigbird_pegasus` — [BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration) (BigBird-Pegasus 模型)

+   `blenderbot` — [BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration) (Blenderbot 模型)

+   `blenderbot-small` — [BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration) (BlenderbotSmall 模型)

+   `encoder-decoder` — [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel) (编码器解码器模型)

+   `fsmt` — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration) (FairSeq 机器翻译模型)

+   `gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration) (GPTSAN-japanese 模型)

+   `led` — [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration) (LED 模型)

+   `longt5` — [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration) (LongT5 模型)

+   `m2m_100` — [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration) (M2M100 模型)

+   `marian` — [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel) (Marian 模型)

+   `mbart` — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration) (mBART 模型)

+   `mt5` — [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration) (MT5 模型)

+   `mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration) (MVP 模型)

+   `nllb-moe` — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration) (NLLB-MOE 模型)

+   `pegasus` — [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration) (Pegasus 模型)

+   `pegasus_x` — [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration) (PEGASUS-X 模型)

+   `plbart` — [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration) (PLBart 模型)

+   `prophetnet` — [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration) (ProphetNet 模型)

+   `seamless_m4t` — [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText) (SeamlessM4T 模型)

+   `seamless_m4t_v2` — [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText) (SeamlessM4Tv2 模型)

+   `switch_transformers` — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration) (SwitchTransformers 模型)

+   `t5` — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration) (T5 模型)

+   `umt5` — [UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration) (UMT5 模型)

+   `xlm-prophetnet` — [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration) (XLM-ProphetNet 模型)

默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例:

```py
>>> from transformers import AutoConfig, AutoModelForSeq2SeqLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

>>> # Update configuration during loading
>>> model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
>>> model = AutoModelForSeq2SeqLM.from_pretrained(
...     "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForSeq2SeqLM

### `class transformers.TFAutoModelForSeq2SeqLM`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L619)

```py
( *args **kwargs )
```

这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库中的模型类之一实例化（带有序列到序列语言建模头）。

这个类不能直接使用 `__init__()` 实例化（会报错）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration) (BART 模型)

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig) 配置类: [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration) (Blenderbot 模型)

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig) 配置类: [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration) (BlenderbotSmall 模型)

    +   [EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig) 配置类: [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel) (编码器解码器模型)

    +   [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig) 配置类: [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration) (LED 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration) (mBART 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration) (MT5 模型)

    +   [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig) 配置类: [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel) (Marian 模型)

    +   [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig) 配置类: [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration) (Pegasus 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)配置类：[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)（T5模型）

从配置中实例化库中的一个模型类（带有序列到序列语言建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("t5-base")
>>> model = TFAutoModelForSeq2SeqLM.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或命名空间下的用户或组织名称，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*PyTorch状态字典保存文件*的路径或URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是由库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除未完全接收的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于 Hub 上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 id，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为会有所不同:

    +   如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个键对应一个配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有序列到序列语言建模头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退:

+   `bart` — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration) (BART 模型)

+   `blenderbot` — [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration) (Blenderbot 模型)

+   `blenderbot-small` — [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration) (BlenderbotSmall 模型)

+   `encoder-decoder` — [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel) (编码器解码器模型)

+   `led` — [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration) (LED 模型)

+   `marian` — [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel) (Marian 模型)

+   `mbart` — [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration) (mBART 模型)

+   `mt5` — [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration) (MT5 模型)

+   `pegasus` — [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration) (Pegasus 模型)

+   `t5` — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration) (T5 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

>>> # Update configuration during loading
>>> model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
>>> model = TFAutoModelForSeq2SeqLM.from_pretrained(
...     "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForSeq2SeqLM

### `class transformers.FlaxAutoModelForSeq2SeqLM`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L304)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有序列到序列语言建模头）。

这个类不能直接使用`__init__()`进行实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)）— 选择要实例化的模型类基于配置类：

    +   [BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig) 配置类：[FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）

    +   [BlenderbotConfig](/docs/transformers/v4.37.2/zh/model_doc/blenderbot#transformers.BlenderbotConfig) 配置类：[FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)（Blenderbot模型）

    +   [BlenderbotSmallConfig](/docs/transformers/v4.37.2/zh/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig) 配置类：[FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)（BlenderbotSmall模型）

    +   [EncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/encoder-decoder#transformers.EncoderDecoderConfig) 配置类：[FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/zh/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)（编码器解码器模型）

    +   [LongT5Config](/docs/transformers/v4.37.2/zh/model_doc/longt5#transformers.LongT5Config) 配置类：[FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)（LongT5模型）

    +   [MBartConfig](/docs/transformers/v4.37.2/zh/model_doc/mbart#transformers.MBartConfig) 配置类：[FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）

    +   [MT5Config](/docs/transformers/v4.37.2/zh/model_doc/mt5#transformers.MT5Config) 配置类：[FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)（MT5模型）

    +   [MarianConfig](/docs/transformers/v4.37.2/zh/model_doc/marian#transformers.MarianConfig) 配置类：[FlaxMarianMTModel](/docs/transformers/v4.37.2/zh/model_doc/marian#transformers.FlaxMarianMTModel)（Marian模型）

    +   [PegasusConfig](/docs/transformers/v4.37.2/zh/model_doc/pegasus#transformers.PegasusConfig) 配置类：[FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)（Pegasus模型）

    +   [T5Config](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.T5Config) 配置类：[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)（T5模型）

从配置实例化库的模型类之一（带有序列到序列语言建模头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("t5-base")
>>> model = FlaxAutoModelForSeq2SeqLM.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的*模型标识符*，托管在huggingface.co上的模型存储库中。有效的模型标识符可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   指向*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并将配置对象提供为`config`参数。使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型的加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：

    +   该模型是库提供的模型（使用预训练模型的*模型标识符*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 下载预训练模型配置应缓存的目录路径，如果不使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。每个请求都会使用代理。

+   `output_loading_info(bool,` *可选*，默认为`False`）— 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`） — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有序列到序列语言建模头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration) (BART 模型)

+   `blenderbot` — [FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration) (Blenderbot 模型)

+   `blenderbot-small` — [FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration) (BlenderbotSmall 模型)

+   `encoder-decoder` — [FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel) (编码器解码器模型)

+   `longt5` — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration) (LongT5 模型)

+   `marian` — [FlaxMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianMTModel) (Marian 模型)

+   `mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration) (mBART 模型)

+   `mt5` — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration) (MT5 模型)

+   `pegasus` — [FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration) (Pegasus 模型)

+   `t5` — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration) (T5 模型)

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
>>> model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
...     "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForSequenceClassification

### `class transformers.AutoModelForSequenceClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1351)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库的模型类之一（带有序列分类头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 选择要实例化的模型类基于配置类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)（ALBERT模型）

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)（BART模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)（BERT模型）

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)配置类：[BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)（BigBird模型）

    +   [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)配置类：[BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)（BigBird-Pegasus模型）

    +   [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)配置类：[BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)（BioGpt模型）

    +   [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)配置类：[BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)（BLOOM模型）

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)配置类：[CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)（CTRL模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)配置类：[CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)（CamemBERT模型）

    +   [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)配置类：[CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)（CANINE模型）

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)配置类：[ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)（ConvBERT模型）

    +   [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)配置类：[Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)（Data2VecText模型）

    +   DebertaConfig配置类：DebertaForSequenceClassification（DeBERTa模型）

    +   DebertaV2Config配置类：DebertaV2ForSequenceClassification（DeBERTa-v2模型）

    +   DistilBertConfig配置类：DistilBertForSequenceClassification（DistilBERT模型）

    +   ElectraConfig配置类：ElectraForSequenceClassification（ELECTRA模型）

    +   ErnieConfig配置类：ErnieForSequenceClassification（ERNIE模型）

    +   ErnieMConfig配置类：ErnieMForSequenceClassification（ErnieM模型）

    +   EsmConfig配置类：EsmForSequenceClassification（ESM模型）

    +   FNetConfig配置类：FNetForSequenceClassification（FNet模型）

    +   FalconConfig配置类：FalconForSequenceClassification（Falcon模型）

    +   FlaubertConfig配置类：FlaubertForSequenceClassification（FlauBERT模型）

    +   FunnelConfig配置类：FunnelForSequenceClassification（Funnel Transformer模型）

    +   GPT2Config配置类：GPT2ForSequenceClassification（OpenAI GPT-2模型）

    +   GPTBigCodeConfig配置类：GPTBigCodeForSequenceClassification（GPTBigCode模型）

    +   GPTJConfig配置类：GPTJForSequenceClassification（GPT-J模型）

    +   GPTNeoConfig配置类：GPTNeoForSequenceClassification（GPT Neo模型）

    +   [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig) 配置类: [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification) (GPT NeoX 模型)

    +   [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig) 配置类: [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification) (I-BERT 模型)

    +   [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig) 配置类: [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification) (LED 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification) (LayoutLM 模型)

    +   [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config) 配置类: [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification) (LayoutLMv2 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification) (LayoutLMv3 模型)

    +   [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig) 配置类: [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification) (LiLT 模型)

    +   [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig) 配置类: [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification) (LLaMA 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification) (Longformer 模型)

    +   [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig) 配置类: [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification) (LUKE 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification) (mBART 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification) (MPNet 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification) (MT5 模型)

    +   [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig) 配置类: [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification) (MarkupLM 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification) (Megatron-BERT 模型)

    +   [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig) 配置类: [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification) (Mistral 模型)

    +   [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig) 配置类: [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification) (Mixtral 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification) (MobileBERT 模型)

    +   [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) 配置类: [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification) (MPT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification) (MRA 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification) (MVP 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification) (Nezha 模型)

    +   [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) 配置类: [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification) (Nyströmformer 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification) (OPT 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification) (OpenAI GPT 模型)

    +   [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig) 配置类: [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification) (OpenLlama 模型)

    +   [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig) 配置类: [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification) (PLBart 模型)

    +   [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig) 配置类: [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification) (Perceiver 模型)

    +   [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig) 配置类: [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification) (Persimmon 模型)

    +   PhiConfig配置类：PhiForSequenceClassification（Phi模型）

    +   QDQBertConfig配置类：QDQBertForSequenceClassification（QDQBert模型）

    +   Qwen2Config配置类：Qwen2ForSequenceClassification（Qwen2模型）

    +   ReformerConfig配置类：ReformerForSequenceClassification（Reformer模型）

    +   RemBertConfig配置类：RemBertForSequenceClassification（RemBERT模型）

    +   RoCBertConfig配置类：RoCBertForSequenceClassification（RoCBert模型）

    +   RoFormerConfig配置类：RoFormerForSequenceClassification（RoFormer模型）

    +   RobertaConfig配置类：RobertaForSequenceClassification（RoBERTa模型）

    +   RobertaPreLayerNormConfig配置类：RobertaPreLayerNormForSequenceClassification（RoBERTa-PreLayerNorm模型）

    +   SqueezeBertConfig配置类：SqueezeBertForSequenceClassification（SqueezeBERT模型）

    +   T5Config配置类：T5ForSequenceClassification（T5模型）

    +   TapasConfig配置类：TapasForSequenceClassification（TAPAS模型）

    +   TransfoXLConfig配置类：TransfoXLForSequenceClassification（Transformer-XL模型）

    +   UMT5Config配置类：UMT5ForSequenceClassification（UMT5模型）

    +   XLMConfig配置类：XLMForSequenceClassification（XLM模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)（XLM-RoBERTa模型）

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类：[XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)（XLM-RoBERTa-XL模型）

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类：[XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)（XLNet模型）

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig) 配置类：[XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)（X-MOD模型）

    +   [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig) 配置类：[YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)（YOSO模型）

从配置实例化库中的一个模型类（带有序列分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForSequenceClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForSequenceClassification.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录来重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 用于替代从保存的权重文件加载的状态字典的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器的协议或端点的字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将用于每个请求。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设所有相关的配置更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有序列分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification) (ALBERT 模型)

+   `bart` — [BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification) (BART 模型)

+   `bert` — [BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification) (BERT 模型)

+   `big_bird` — [BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification) (BigBird 模型)

+   `bigbird_pegasus` — [BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification) (BigBird-Pegasus 模型)

+   `biogpt` — [BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification) (BioGpt 模型)

+   `bloom` — [BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification) (BLOOM 模型)

+   `camembert` — [CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification) (CamemBERT 模型)

+   `canine` — [CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification) (CANINE 模型)

+   `code_llama` — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification) (CodeLlama 模型)

+   `convbert` — [ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification) (ConvBERT 模型)

+   `ctrl` — [CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification) (CTRL 模型)

+   `data2vec-text` — [Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification) (Data2VecText 模型)

+   `deberta` — [DebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification) (DistilBERT 模型)

+   `electra` — [ElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForSequenceClassification) (ELECTRA 模型)

+   `ernie` — [ErnieForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForSequenceClassification) (ERNIE 模型)

+   `ernie_m` — [ErnieMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForSequenceClassification) (ErnieM 模型)

+   `esm` — [EsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForSequenceClassification) (ESM 模型)

+   `falcon` — [FalconForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForSequenceClassification) (Falcon 模型)

+   `flaubert` — [FlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification) (FlauBERT 模型)

+   `fnet` — [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification) (FNet 模型)

+   `funnel` — [FunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification) (Funnel Transformer model)

+   `gpt-sw3` — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification) (GPT-Sw3 model)

+   `gpt2` — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification) (OpenAI GPT-2 model)

+   `gpt_bigcode` — [GPTBigCodeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForSequenceClassification) (GPTBigCode model)

+   `gpt_neo` — [GPTNeoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification) (GPT Neo model)

+   `gpt_neox` — [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification) (GPT NeoX model)

+   `gptj` — [GPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification) (GPT-J model)

+   `ibert` — [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification) (I-BERT model)

+   `layoutlm` — [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification) (LayoutLM model)

+   `layoutlmv2` — [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification) (LayoutLMv2 model)

+   `layoutlmv3` — [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification) (LayoutLMv3 model)

+   `led` — [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification) (LED model)

+   `lilt` — [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification) (LiLT model)

+   `llama` — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification) (LLaMA model)

+   `longformer` — [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification) (Longformer model)

+   `luke` — [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification) (LUKE model)

+   `markuplm` — [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification) (MarkupLM model)

+   `mbart` — [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification) (mBART model)

+   `mega` — [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification) (MEGA model)

+   `megatron-bert` — [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification) (Megatron-BERT model)

+   `mistral` — [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification) (Mistral model)

+   `mixtral` — [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification) (Mixtral model)

+   `mobilebert` — [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification) (MobileBERT model)

+   `mpnet` — [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification) (MPNet model)

+   `mpt` — [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification) (MPT model)

+   `mra` — [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification) (MRA 模型)

+   `mt5` — [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification) (MT5 模型)

+   `mvp` — [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification) (MVP 模型)

+   `nezha` — [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification) (Nezha 模型)

+   `nystromformer` — [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification) (Nyströmformer 模型)

+   `open-llama` — [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification) (OpenLlama 模型)

+   `openai-gpt` — [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification) (OpenAI GPT 模型)

+   `opt` — [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification) (OPT 模型)

+   `perceiver` — [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification) (Perceiver 模型)

+   `persimmon` — [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification) (Persimmon 模型)

+   `phi` — [PhiForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForSequenceClassification) (Phi 模型)

+   `plbart` — [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification) (PLBart 模型)

+   `qdqbert` — [QDQBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification) (QDQBert 模型)

+   `qwen2` — [Qwen2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForSequenceClassification) (Qwen2 模型)

+   `reformer` — [ReformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification) (Reformer 模型)

+   `rembert` — [RemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification) (RemBERT 模型)

+   `roberta` — [RobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForSequenceClassification) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification) (RoCBert 模型)

+   `roformer` — [RoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification) (RoFormer 模型)

+   `squeezebert` — [SqueezeBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification) (SqueezeBERT 模型)

+   `t5` — [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification) (T5 模型)

+   `tapas` — [TapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForSequenceClassification) (TAPAS 模型)

+   `transfo-xl` — [TransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification) (Transformer-XL 模型)

+   `umt5` — [UMT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForSequenceClassification) (UMT5 模型)

+   `xlm` — [XLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForSequenceClassification) (XLM 模型)

+   `xlm-roberta` — [XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification) (XLM-RoBERTa 模型)

+   `xlm-roberta-xl` — [XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification) (XLM-RoBERTa-XL 模型)

+   `xlnet` — [XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification) (XLNet 模型)

+   `xmod` — [XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification) (X-MOD 模型)

+   `yoso` — [YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification) (YOSO 模型)

默认情况下，该模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例:

```py
>>> from transformers import AutoConfig, AutoModelForSequenceClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForSequenceClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForSequenceClassification

### `class transformers.TFAutoModelForSequenceClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L628)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有序列分类头）

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 实例化的模型类基于配置类进行选择:

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类: [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification) (ALBERT 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [TFBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForSequenceClassification) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [TFBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForSequenceClassification) (BERT 模型)

    +   [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig) 配置类: [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification) (CTRL 模型)

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) 配置类: [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification) (CamemBERT 模型)

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) 配置类: [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification) (ConvBERT 模型)

    +   [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig) 配置类: [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification) (DeBERTa 模型)

    +   [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类: [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification) (DeBERTa-v2 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification) (ELECTRA 模型)

    +   [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig) 配置类: [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForSequenceClassification) (ESM 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification) (Funnel Transformer 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification) (OpenAI GPT-2 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification) (GPT-J 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification) (LayoutLM 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification) (LayoutLMv3 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification) (Longformer 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification) (MPNet 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification) (MobileBERT 模型)

    +   [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig) 配置类: [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification) (OpenAI GPT 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification) (RemBERT 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification) (RoBERTa-PreLayerNorm 模型)

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig) 配置类: [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification) (TAPAS 模型)

    +   [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig) 配置类: [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification) (Transformer-XL 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification) (XLM-RoBERTa 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类: [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification) (XLNet 模型)

从配置实例化库中的一个模型类（带有序列分类头）。

注意: 从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForSequenceClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForSequenceClassification.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:

    +   一个字符串，预训练模型的*模型 id*，托管在huggingface.co上的模型存储库中。有效的模型 id 可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   路径或URL到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*） — 用于模型的配置，而不是自动加载的配置。当以下情况自动加载配置时：

    +   模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*） — 下载预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺少键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：

    +   如果提供了`config`配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个键对应一个配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有序列分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForSequenceClassification) (ALBERT 模型)

+   `bart` — [TFBartForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.TFBartForSequenceClassification) (BART 模型)

+   `bert` — [TFBertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForSequenceClassification) (BERT 模型)

+   `camembert` — [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForSequenceClassification) (CamemBERT 模型)

+   `convbert` — [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.TFConvBertForSequenceClassification) (ConvBERT 模型)

+   `ctrl` — [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/ctrl#transformers.TFCTRLForSequenceClassification) (CTRL 模型)

+   `deberta` — [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.TFDebertaForSequenceClassification) (DeBERTa 模型)

+   `deberta-v2` — [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification) (DeBERTa-v2 模型)

+   `distilbert` — [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification) (DistilBERT 模型)

+   `electra` — [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.TFElectraForSequenceClassification) (ELECTRA 模型)

+   `esm` — [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/esm#transformers.TFEsmForSequenceClassification) (ESM 模型)

+   `flaubert` — [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification) (FlauBERT 模型)

+   `funnel` — [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/funnel#transformers.TFFunnelForSequenceClassification) (漏斗变换器模型)

+   `gpt-sw3` — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification) (GPT-Sw3 模型)

+   `gpt2` — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification) (OpenAI GPT-2 模型)

+   `gptj` — [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/gptj#transformers.TFGPTJForSequenceClassification) (GPT-J 模型)

+   `layoutlm` — [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification) (LayoutLM 模型)

+   `layoutlmv3` — [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification) (LayoutLMv3 模型)

+   `longformer` — [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/longformer#transformers.TFLongformerForSequenceClassification) (Longformer 模型)

+   `mobilebert` — [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification) (MobileBERT 模型)

+   `mpnet` — [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification) (MPNet 模型)

+   `openai-gpt` — [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification) (OpenAI GPT 模型)

+   `rembert` — [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification) (RemBERT 模型)

+   `roberta` — [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification) (RoFormer 模型)

+   `tapas` — [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification) (TAPAS 模型)

+   `transfo-xl` — [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification) (Transformer-XL 模型)

+   `xlm` — [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification) (XLM-RoBERTa 模型)

+   `xlnet` — [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification) (XLNet 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForSequenceClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForSequenceClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForSequenceClassification

### `class transformers.FlaxAutoModelForSequenceClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L313)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有序列分类头）。

这个类不能直接使用 `__init__()` 实例化 (会报错)。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类: [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification) (ALBERT 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig) 配置类: [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification) (BERT 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类：[FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)（BigBird模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类：[FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)（DistilBERT模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类：[FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)（ELECTRA模型）

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类：[FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)（mBART模型）

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类：[FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)（RoFormer模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类：[FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)（RoBERTa模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类：[FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)（RoBERTa-PreLayerNorm模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)（XLM-RoBERTa模型）

从配置实例化库中的一个模型类（带有序列分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForSequenceClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict保存文件*的路径或URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）- 下载的预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`）- 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）- 要使用的代理服务器的字典，按协议或端点划分，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`）- 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）- 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的自定义建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）- 在Hub上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载的情况而表现不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型中实例化库的模型类之一（带有序列分类头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `albert` — [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)（ALBERT模型）

+   `bart` — [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)（BART模型）

+   `bert` — [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)（BERT模型）

+   `big_bird` — [FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)（BigBird模型）

+   `distilbert` — [FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)（DistilBERT模型）

+   `electra` — [FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)（ELECTRA模型）

+   `mbart` — [FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)（mBART模型）

+   `roberta` — [FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)（RoBERTa模型）

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)（RoBERTa-PreLayerNorm模型）

+   `roformer` — [FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)（RoFormer模型）

+   `xlm-roberta` — [FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)（XLM-RoBERTa模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForSequenceClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForMultipleChoice

### `class transformers.AutoModelForMultipleChoice`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1407)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库的模型类之一（带有多选头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 要实例化的模型类是根据配置类选择的：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)（ALBERT模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)（BERT模型）

    +   BigBirdConfig配置类：BigBirdForMultipleChoice（BigBird模型）

    +   CamembertConfig配置类：CamembertForMultipleChoice（CamemBERT模型）

    +   CanineConfig配置类：CanineForMultipleChoice（CANINE模型）

    +   ConvBertConfig配置类：ConvBertForMultipleChoice（ConvBERT模型）

    +   Data2VecTextConfig配置类：Data2VecTextForMultipleChoice（Data2VecText模型）

    +   DebertaV2Config配置类：DebertaV2ForMultipleChoice（DeBERTa-v2模型）

    +   DistilBertConfig配置类：DistilBertForMultipleChoice（DistilBERT模型）

    +   ElectraConfig配置类：ElectraForMultipleChoice（ELECTRA模型）

    +   ErnieConfig配置类：ErnieForMultipleChoice（ERNIE模型）

    +   ErnieMConfig配置类：ErnieMForMultipleChoice（ErnieM模型）

    +   FNetConfig配置类：FNetForMultipleChoice（FNet模型）

    +   FlaubertConfig配置类：FlaubertForMultipleChoice（FlauBERT模型）

    +   FunnelConfig配置类：FunnelForMultipleChoice（Funnel Transformer模型）

    +   IBertConfig配置类：IBertForMultipleChoice（I-BERT模型）

    +   LongformerConfig配置类：LongformerForMultipleChoice（Longformer模型）

    +   LukeConfig配置类：LukeForMultipleChoice（LUKE模型）

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice) (MPNet 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice) (Megatron-BERT 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice) (MobileBERT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice) (MRA 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice) (Nezha 模型)

    +   [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) 配置类: [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice) (Nyströmformer 模型)

    +   [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) 配置类: [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice) (QDQBert 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [RemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice) (RemBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice) (RoCBert 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice) (RoBERTa-PreLayerNorm 模型)

    +   [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) 配置类: [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice) (SqueezeBERT 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [XLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForMultipleChoice) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)配置类：[XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)（XLM-RoBERTa模型）

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)配置类：[XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)（XLM-RoBERTa-XL模型）

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)配置类：[XLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice)（XLNet模型）

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)配置类：[XmodForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMultipleChoice)（X-MOD模型）

    +   [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)配置类：[YosoForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMultipleChoice)（YOSO模型）

从配置中实例化库中的一个模型类（带有多选头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForMultipleChoice

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForMultipleChoice.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个路径或url到一个*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*） — 下载预训练模型配置应缓存的目录路径，如果不使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，其行为有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有多选头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice) (ALBERT 模型)

+   `bert` — [BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice) (BERT 模型)

+   `big_bird` — [BigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice) (BigBird 模型)

+   `camembert` — [CamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice) (CamemBERT 模型)

+   `canine` — [CanineForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForMultipleChoice) (CANINE 模型)

+   `convbert` — [ConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice) (ConvBERT 模型)

+   `data2vec-text` — [Data2VecTextForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice) (Data2VecText 模型)

+   `deberta-v2` — [DebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice) (DistilBERT 模型)

+   `electra` — [ElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMultipleChoice) (ELECTRA 模型)

+   `ernie` — [ErnieForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMultipleChoice) (ERNIE 模型)

+   `ernie_m` — [ErnieMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForMultipleChoice) (ErnieM 模型)

+   `flaubert` — [FlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice) (FlauBERT 模型)

+   `fnet` — [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice) (FNet 模型)

+   `funnel` — [FunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice) (Funnel Transformer 模型)

+   `ibert` — [IBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMultipleChoice) (I-BERT 模型)

+   `longformer` — [LongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice) (Longformer 模型)

+   `luke` — [LukeForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMultipleChoice) (LUKE 模型)

+   `mega` — [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice) (MEGA 模型)

+   `megatron-bert` — [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice) (Megatron-BERT 模型)

+   `mobilebert` — [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice) (MobileBERT 模型)

+   `mpnet` — [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice) (MPNet 模型)

+   `mra` — [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice) (MRA 模型)

+   `nezha` — [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice) (Nezha 模型)

+   `nystromformer` — [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice) (Nyströmformer 模型)

+   `qdqbert` — [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)（QDQBert 模型）

+   `rembert` — [RemBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/rembert#transformers.RemBertForMultipleChoice)（RemBERT 模型）

+   `roberta` — [RobertaForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.RobertaForMultipleChoice)（RoBERTa 模型）

+   `roberta-prelayernorm` — [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)（RoBERTa-PreLayerNorm 模型）

+   `roc_bert` — [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)（RoCBert 模型）

+   `roformer` — [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.RoFormerForMultipleChoice)（RoFormer 模型）

+   `squeezebert` — [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)（SqueezeBERT 模型）

+   `xlm` — [XLMForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMForMultipleChoice)（XLM 模型）

+   `xlm-roberta` — [XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)（XLM-RoBERTa 模型）

+   `xlm-roberta-xl` — [XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)（XLM-RoBERTa-XL 模型）

+   `xlnet` — [XLNetForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.XLNetForMultipleChoice)（XLNet 模型）

+   `xmod` — [XmodForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xmod#transformers.XmodForMultipleChoice)（X-MOD 模型）

+   `yoso` — [YosoForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/yoso#transformers.YosoForMultipleChoice)（YOSO 模型）

默认情况下，模型处于评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForMultipleChoice

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForMultipleChoice.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForMultipleChoice

### `class transformers.TFAutoModelForMultipleChoice`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L675)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库中的模型类之一（带有多选头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig) 配置类：[TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForMultipleChoice)（ALBERT 模型）

    +   [BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig) 配置类：[TFBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForMultipleChoice)（BERT 模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig) 配置类：[TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForMultipleChoice)（CamemBERT 模型）

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) 配置类: [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice) (ConvBERT 模型)

    +   [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类: [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice) (DeBERTa-v2 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice) (ELECTRA 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice) (Funnel Transformer 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice) (Longformer 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice) (MPNet 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice) (MobileBERT 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice) (RemBERT 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice) (RoBERTa-PreLayerNorm 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice) (XLM-RoBERTa 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类：[TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)（XLNet模型）

从配置实例化库中的一个模型类（带有多选头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForMultipleChoice

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForMultipleChoice.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：

    +   一个字符串，预训练模型的 *model id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   模型是由库提供的模型（使用预训练模型的 *model id* 字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并且在目录中找到名为 *config.json* 的配置文件。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载预训练模型配置文件应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, 默认为 `False`) — 从PyTorch检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`） — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在 Hub 上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`） — 用于 Hub 上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设所有相关的配置更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有多选头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退： 

+   `albert` — [TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice) (ALBERT 模型)

+   `bert` — [TFBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMultipleChoice) (BERT 模型)

+   `camembert` — [TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice) (CamemBERT 模型)

+   `convbert` — [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice) (ConvBERT 模型)

+   `deberta-v2` — [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice) (DeBERTa-v2 模型)

+   `distilbert` — [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice) (DistilBERT 模型)

+   `electra` — [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice) (ELECTRA 模型)

+   `flaubert` — [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice) (FlauBERT 模型)

+   `funnel` — [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice) (Funnel Transformer 模型)

+   `longformer` — [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice) (Longformer 模型)

+   `mobilebert` — [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice) (MobileBERT 模型)

+   `mpnet` — [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice) (MPNet 模型)

+   `rembert` — [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice) (RemBERT 模型)

+   `roberta` — [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice) (RoFormer 模型)

+   `xlm` — [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice) (XLM-RoBERTa 模型)

+   `xlnet` — [TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice) (XLNet 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForMultipleChoice

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForMultipleChoice.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForMultipleChoice

### `class transformers.FlaxAutoModelForMultipleChoice`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L338)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有多选头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类: [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice) (ALBERT 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice) (BERT 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice) (BigBird 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice) (ELECTRA 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类：[FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)（RoBERTa 模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类：[FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)（RoBERTa-PreLayerNorm 模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)（XLM-RoBERTa 模型）

从配置实例化库中的一个模型类（带有多选头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForMultipleChoice.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`） — 可以是：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict 保存文件*的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应将配置对象作为 `config` 参数提供。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*） — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir`（`str` 或 `os.PathLike`，*可选*） — 预训练模型配置应该被缓存的目录路径，如果不使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为 `False`） — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为 `False`） — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为 `False`） — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有多选头）。

要实例化的模型类基于配置对象的`model_type`属性（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `albert` — [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)（ALBERT模型）

+   `bert` — [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)（BERT模型）

+   `big_bird` — [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)（BigBird模型）

+   `distilbert` — [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)（DistilBERT模型）

+   `electra` — [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)（ELECTRA模型）

+   `roberta` — [FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)（RoBERTa模型）

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)（RoBERTa-PreLayerNorm 模型）

+   `roformer` — [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)（RoFormer 模型）

+   `xlm-roberta` — [FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)（XLM-RoBERTa 模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForMultipleChoice.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForNextSentencePrediction

### `class transformers.AutoModelForNextSentencePrediction`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1414)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有下一个句子预测头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig) 配置类：[BertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForNextSentencePrediction)（BERT 模型）

    +   [ErnieConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieConfig) 配置类：[ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieForNextSentencePrediction)（ERNIE 模型）

    +   [FNetConfig](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetConfig) 配置类：[FNetForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetForNextSentencePrediction)（FNet 模型）

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/zh/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类：[MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)（Megatron-BERT 模型）

    +   [MobileBertConfig](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.MobileBertConfig) 配置类：[MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)（MobileBERT 模型）

    +   [NezhaConfig](/docs/transformers/v4.37.2/zh/model_doc/nezha#transformers.NezhaConfig) 配置类：[NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/nezha#transformers.NezhaForNextSentencePrediction)（Nezha 模型）

    +   [QDQBertConfig](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertConfig) 配置类：[QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)（QDQBert 模型）

从配置实例化库中的一个模型类（带有下一个句子预测头）。

注意：从配置文件加载模型 **不会** 加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForNextSentencePrediction

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForNextSentencePrediction.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。

    +   一个 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并随后加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在该目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 是否不是更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如 `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理服务器将在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）- 用于Hub上代码的特定修订版，如果代码与模型的其余部分位于不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统来存储模型和其他artifacts在huggingface.co上，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有下一个句子预测头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `bert` - [BertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForNextSentencePrediction)（BERT模型）

+   `ernie` - [ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction)（ERNIE模型）

+   `fnet` - [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)（FNet模型）

+   `megatron-bert` - [MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)（Megatron-BERT模型）

+   `mobilebert` - [MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)（MobileBERT模型）

+   `nezha` - [NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction)（Nezha模型）

+   `qdqbert` - [QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)（QDQBert模型）

默认情况下，模型将设置为评估模式，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForNextSentencePrediction

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForNextSentencePrediction.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForNextSentencePrediction

### `class transformers.TFAutoModelForNextSentencePrediction`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L682)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化库的模型类之一（带有下一个句子预测头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—根据配置类选择要实例化的模型类：

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)（BERT模型）

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)配置类：[TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)（MobileBERT模型）

从配置实例化库的模型类之一（带有下一个句子预测头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForNextSentencePrediction.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）—可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   路径或URL指向*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型，然后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）—将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）—下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`) — 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则首先将`kwargs`传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型中实例化库中的一个模型类（带有下一个句子预测头）。

根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来选择要实例化的模型类：

+   `bert` — [TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)（BERT模型）

+   `mobilebert` — [TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)（MobileBERT模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForNextSentencePrediction.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForNextSentencePrediction

### `class transformers.FlaxAutoModelForNextSentencePrediction`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L345)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的模型类之一（带有下一个句子预测头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 实例化的模型类是根据配置类选择的：

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)（BERT模型）

从配置实例化库中的一个模型类（带有下一个句子预测头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForNextSentencePrediction.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置JSON文件来加载模型。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不使用标准缓存，则应将下载的预训练模型配置缓存到的目录路径。

+   `from_pt`（`bool`，*可选*，默认为`False`）- 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将在每个请求上使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否还返回包含缺少键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：

    +   如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有下一个句子预测头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `bert` — [FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)（BERT模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### 自动模型用于标记分类

### `class transformers.AutoModelForTokenClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1400)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库的模型类之一实例化（带有一个标记分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类：[AlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForTokenClassification)（ALBERT 模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类：[BertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForTokenClassification)（BERT 模型）

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig) 配置类：[BigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification)（BigBird 模型）

    +   [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig) 配置类：[BioGptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForTokenClassification)（BioGpt 模型）

    +   [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig) 配置类：[BloomForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForTokenClassification)（BLOOM 模型）

    +   [BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig) 配置类：[BrosForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosForTokenClassification)（BROS 模型）

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) 配置类：[CamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForTokenClassification)（CamemBERT 模型）

    +   [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig) 配置类：[CanineForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForTokenClassification)（CANINE 模型）

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) 配置类：[ConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification)（ConvBERT 模型）

    +   [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig) 配置类：[Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)（Data2VecText 模型）

    +   [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig) 配置类：[DebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForTokenClassification)（DeBERTa 模型）

    +   [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类：[DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)（DeBERTa-v2 模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification) (ELECTRA 模型)

    +   [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig) 配置类: [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification) (ERNIE 模型)

    +   [ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig) 配置类: [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification) (ErnieM 模型)

    +   [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig) 配置类: [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification) (ESM 模型)

    +   [FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig) 配置类: [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification) (FNet 模型)

    +   [FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig) 配置类: [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification) (Falcon 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification) (Funnel Transformer 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification) (OpenAI GPT-2 模型)

    +   [GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig) 配置类: [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification) (GPTBigCode 模型)

    +   [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig) 配置类: [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification) (GPT Neo 模型)

    +   [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig) 配置类: [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification) (GPT NeoX 模型)

    +   [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig) 配置类: [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification) (I-BERT 模型)

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification) (LayoutLM 模型)

    +   [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config) 配置类: [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification) (LayoutLMv2 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification) (LayoutLMv3 模型)

    +   [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig) 配置类: [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification) (LiLT 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification) (Longformer 模型)

    +   [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig) 配置类: [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification) (LUKE 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification) (MPNet 模型)

    +   [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig) 配置类: [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification) (MarkupLM 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification) (Megatron-BERT 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification) (MobileBERT 模型)

    +   [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) 配置类: [MptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForTokenClassification) (MPT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForTokenClassification) (MRA 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForTokenClassification) (Nezha 模型)

    +   [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) 配置类: [NystromformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification) (Nyströmformer 模型)

    +   [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig) 配置类: [PhiForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForTokenClassification) (Phi 模型)

    +   [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) 配置类: [QDQBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification) (QDQBert 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [RemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForTokenClassification) (RemBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification) (RoCBert 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [RoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForTokenClassification) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification) (RoBERTa-PreLayerNorm 模型)

    +   [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) 配置类: [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification) (SqueezeBERT 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [XLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForTokenClassification) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification) (XLM-RoBERTa 模型)

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类: [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification) (XLM-RoBERTa-XL 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类: [XLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification) (XLNet 模型)

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig) 配置类: [XmodForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForTokenClassification) (X-MOD 模型)

    +   [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig) 配置类: [YosoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForTokenClassification) (YOSO 模型)

从配置实例化库中的一个模型类（带有标记分类头）。

注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, AutoModelForTokenClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForTokenClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。

    +   一个指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   路径或URL指向*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*） — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 要使用的代理服务器字典，按协议或端点划分，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为 `False`） — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为 `"main"`） — 用于 Hub 上代码的特定修订版，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载了 `config`，其行为会有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则首先将 `kwargs` 传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个键对应于配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型中实例化库中的一个模型类（带有标记分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（可以作为参数传递，也可以从 `pretrained_model_name_or_path` 中加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [AlbertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertForTokenClassification) (ALBERT 模型)

+   `bert` — [BertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForTokenClassification) (BERT 模型)

+   `big_bird` — [BigBirdForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdForTokenClassification) (BigBird 模型)

+   `biogpt` — [BioGptForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/biogpt#transformers.BioGptForTokenClassification) (BioGpt 模型)

+   `bloom` — [BloomForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/bloom#transformers.BloomForTokenClassification) (BLOOM 模型)

+   `bros` — [BrosForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/bros#transformers.BrosForTokenClassification) (BROS 模型)

+   `camembert` — [CamembertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertForTokenClassification) (CamemBERT 模型)

+   `canine` — [CanineForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/canine#transformers.CanineForTokenClassification) (CANINE 模型)

+   `convbert` — [ConvBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertForTokenClassification) (ConvBERT 模型)

+   `data2vec-text` — [Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextForTokenClassification) (Data2VecText 模型)

+   `deberta` — [DebertaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaForTokenClassification) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification) (DistilBERT 模型)

+   `electra` — [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification) (ELECTRA 模型)

+   `ernie` — [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification) (ERNIE 模型)

+   `ernie_m` — [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification) (ErnieM 模型)

+   `esm` — [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification) (ESM 模型)

+   `falcon` — [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification) (Falcon 模型)

+   `flaubert` — [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification) (FlauBERT 模型)

+   `fnet` — [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification) (FNet 模型)

+   `funnel` — [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification) (Funnel Transformer 模型)

+   `gpt-sw3` — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification) (GPT-Sw3 模型)

+   `gpt2` — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification) (OpenAI GPT-2 模型)

+   `gpt_bigcode` — [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification) (GPTBigCode 模型)

+   `gpt_neo` — [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification) (GPT Neo 模型)

+   `gpt_neox` — [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification) (GPT NeoX 模型)

+   `ibert` — [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification) (I-BERT 模型)

+   `layoutlm` — [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification) (LayoutLM 模型)

+   `layoutlmv2` — [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification) (LayoutLMv3 模型)

+   `lilt` — [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification) (LiLT 模型)

+   `longformer` — [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification) (Longformer 模型)

+   `luke` — [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification) (LUKE 模型)

+   `markuplm` — [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification) (MarkupLM 模型)

+   `mega` — [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification) (MEGA 模型)

+   `megatron-bert` — [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification) (Megatron-BERT 模型)

+   `mobilebert` — [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification) (MobileBERT 模型)

+   `mpnet` — [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification) (MPNet 模型)

+   `mpt` — [MptForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/mpt#transformers.MptForTokenClassification) (MPT 模型)

+   `mra` — [MraForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/mra#transformers.MraForTokenClassification) (MRA 模型)

+   `nezha` — [NezhaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/nezha#transformers.NezhaForTokenClassification) (Nezha 模型)

+   `nystromformer` — [NystromformerForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/nystromformer#transformers.NystromformerForTokenClassification) (Nyströmformer 模型)

+   `phi` — [PhiForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/phi#transformers.PhiForTokenClassification) (Phi 模型)

+   `qdqbert` — [QDQBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertForTokenClassification) (QDQBert 模型)

+   `rembert` — [RemBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/rembert#transformers.RemBertForTokenClassification) (RemBERT 模型)

+   `roberta` — [RobertaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.RobertaForTokenClassification) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roc_bert#transformers.RoCBertForTokenClassification) (RoCBert 模型)

+   `roformer` — [RoFormerForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.RoFormerForTokenClassification) (RoFormer 模型)

+   `squeezebert` — [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification) (SqueezeBERT 模型)

+   `xlm` — [XLMForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMForTokenClassification) (XLM 模型)

+   `xlm-roberta` — [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification) (XLM-RoBERTa 模型)

+   `xlm-roberta-xl` — [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification) (XLM-RoBERTa-XL 模型)

+   `xlnet` — [XLNetForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.XLNetForTokenClassification) (XLNet 模型)

+   `xmod` — [XmodForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xmod#transformers.XmodForTokenClassification) (X-MOD 模型)

+   `yoso` — [YosoForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/yoso#transformers.YosoForTokenClassification) (YOSO 模型)

默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForTokenClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForTokenClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForTokenClassification

### `class transformers.TFAutoModelForTokenClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L666)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库中的一个模型类（带有标记分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（PretrainedConfig）-根据配置类选择要实例化的模型类：

    +   AlbertConfig配置类：TFAlbertForTokenClassification（ALBERT模型）

    +   BertConfig配置类：TFBertForTokenClassification（BERT模型）

    +   CamembertConfig配置类：TFCamembertForTokenClassification（CamemBERT模型）

    +   ConvBertConfig配置类：TFConvBertForTokenClassification（ConvBERT模型）

    +   DebertaConfig配置类：TFDebertaForTokenClassification（DeBERTa模型）

    +   DebertaV2Config配置类：TFDebertaV2ForTokenClassification（DeBERTa-v2模型）

    +   DistilBertConfig配置类：TFDistilBertForTokenClassification（DistilBERT模型）

    +   ElectraConfig配置类：TFElectraForTokenClassification（ELECTRA模型）

    +   EsmConfig配置类：TFEsmForTokenClassification（ESM模型）

    +   FlaubertConfig配置类：TFFlaubertForTokenClassification（FlauBERT模型）

    +   FunnelConfig配置类：TFFunnelForTokenClassification（漏斗变压器模型）

    +   LayoutLMConfig配置类：TFLayoutLMForTokenClassification（LayoutLM模型）

    +   LayoutLMv3Config配置类：TFLayoutLMv3ForTokenClassification（LayoutLMv3模型）

    +   LongformerConfig配置类：TFLongformerForTokenClassification（Longformer模型）

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类：[TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)（MPNet 模型）

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类：[TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)（MobileBERT 模型）

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类：[TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)（RemBERT 模型）

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类：[TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)（RoFormer 模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类：[TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)（RoBERTa 模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类：[TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)（RoBERTa-PreLayerNorm 模型）

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类：[TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)（XLM 模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)（XLM-RoBERTa 模型）

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类：[TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)（XLNet 模型）

从配置实例化库中的一个模型类（带有一个标记分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForTokenClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForTokenClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`）- 可以是：

    +   一个字符串，指定在 huggingface.co 上托管的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间划分，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。

    +   一个 *PyTorch state_dict save file* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应提供配置对象作为 `config` 参数。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并加载 TensorFlow 模型的加载路径比直接加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 用于模型的配置，而不是自动加载的配置。当以下情况自动加载配置时：

    +   模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并且目录中找到名为 *config.json* 的配置 JSON 文件。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 应在其中缓存下载的预训练模型配置的目录路径，如果不应使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地计算机上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（其他关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载：

    +   如果提供了配置与 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有标记分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [TFAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification) (ALBERT 模型)

+   `bert` — [TFBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForTokenClassification) (BERT 模型)

+   `camembert` — [TFCamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification) (CamemBERT 模型)

+   `convbert` — [TFConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification) (ConvBERT 模型)

+   `deberta` — [TFDebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification) (DeBERTa 模型)

+   `deberta-v2` — [TFDebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification) (DeBERTa-v2 模型)

+   `distilbert` — [TFDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification) (DistilBERT 模型)

+   `electra` — [TFElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForTokenClassification) (ELECTRA 模型)

+   `esm` — [TFEsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForTokenClassification) (ESM 模型)

+   `flaubert` — [TFFlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification) (FlauBERT 模型)

+   `funnel` — [TFFunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification) (Funnel Transformer 模型)

+   `layoutlm` — [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification) (LayoutLM 模型)

+   `layoutlmv3` — [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification) (LayoutLMv3 模型)

+   `longformer` — [TFLongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification) (Longformer 模型)

+   `mobilebert` — [TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification) (MobileBERT 模型)

+   `mpnet` — [TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification) (MPNet 模型)

+   `rembert` — [TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification) (RemBERT 模型)

+   `roberta` — [TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification) (RoFormer 模型)

+   `xlm` — [TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification) (XLM-RoBERTa 模型)

+   `xlnet`—[TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)（XLNet模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForTokenClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForTokenClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForTokenClassification

### `class transformers.FlaxAutoModelForTokenClassification`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L329)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有标记分类头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—根据配置类选择要实例化的模型类：

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)（ALBERT模型）

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)（BERT模型）

    +   [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)配置类：[FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)（BigBird模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)配置类：[FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)（DistilBERT模型）

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)配置类：[FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)（ELECTRA模型）

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)配置类：[FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)（RoFormer模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)配置类：[FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)（RoBERTa模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)配置类：[FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)（RoBERTa-PreLayerNorm模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)配置类：[FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)（XLM-RoBERTa模型）

从配置实例化库中的一个模型类（带有标记分类头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForTokenClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForTokenClassification.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个路径或URL指向一个*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并在之后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 下载预训练模型配置的目录路径，如果不使用标准缓存，则应该缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的模型文件。此选项应仅在您信任的存储库中设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，其行为有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则 `kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库的一个模型类（带有标记分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载）选择的，或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification) (ALBERT 模型)

+   `bert` — [FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification) (BERT 模型)

+   `big_bird` — [FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification) (BigBird 模型)

+   `distilbert` — [FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification) (DistilBERT 模型)

+   `electra` — [FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification) (ELECTRA 模型)

+   `roberta` — [FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification) (RoBERTa 模型)

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification) (RoFormer 模型)

+   `xlm-roberta` — [FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification) (XLM-RoBERTa 模型)

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForTokenClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForTokenClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForQuestionAnswering

### `class transformers.AutoModelForQuestionAnswering`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1360)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用from_pretrained()类方法或from_config()类方法创建时，将作为库的模型类之一实例化（带有问答头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

<来源>

```py
( **kwargs )
```

参数

+   `config`（PretrainedConfig）- 根据配置类选择要实例化的模型类：

    +   AlbertConfig配置类：AlbertForQuestionAnswering（ALBERT模型）

    +   BartConfig配置类：BartForQuestionAnswering（BART模型）

    +   BertConfig配置类：BertForQuestionAnswering（BERT模型）

    +   BigBirdConfig配置类：BigBirdForQuestionAnswering（BigBird模型）

    +   BigBirdPegasusConfig配置类：BigBirdPegasusForQuestionAnswering（BigBird-Pegasus模型）

    +   BloomConfig配置类：BloomForQuestionAnswering（BLOOM模型）

    +   CamembertConfig配置类：CamembertForQuestionAnswering（CamemBERT模型）

    +   CanineConfig配置类：CanineForQuestionAnswering（CANINE模型）

    +   ConvBertConfig配置类：ConvBertForQuestionAnswering（ConvBERT模型）

    +   Data2VecTextConfig配置类：Data2VecTextForQuestionAnswering（Data2VecText模型）

    +   DebertaConfig配置类：DebertaForQuestionAnswering（DeBERTa模型）

    +   DebertaV2Config配置类：DebertaV2ForQuestionAnswering（DeBERTa-v2模型）

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering) (ELECTRA 模型)

    +   [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig) 配置类: [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering) (ERNIE 模型)

    +   [ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig) 配置类: [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering) (ErnieM 模型)

    +   [FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig) 配置类: [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering) (FNet 模型)

    +   [FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig) 配置类: [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering) (Falcon 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering) (Funnel Transformer 模型)

    +   [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config) 配置类: [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering) (OpenAI GPT-2 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering) (GPT-J 模型)

    +   [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig) 配置类: [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering) (GPT Neo 模型)

    +   [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig) 配置类: [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering) (GPT NeoX 模型)

    +   [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig) 配置类: [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering) (I-BERT 模型)

    +   [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig) 配置类: [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering) (LED 模型)

    +   [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config) 配置类: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering) (LayoutLMv2 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering) (LayoutLMv3 模型)

    +   [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig) 配置类: [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering) (LiLT 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering) (Longformer 模型)

    +   [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig) 配置类: [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering) (LUKE 模型)

    +   [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig) 配置类: [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering) (LXMERT 模型)

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类: [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering) (mBART 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering) (MPNet 模型)

    +   [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config) 配置类: [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering) (MT5 模型)

    +   [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig) 配置类: [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering) (MarkupLM 模型)

    +   [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig) 配置类: [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering) (MEGA 模型)

    +   [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig) 配置类: [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering) (Megatron-BERT 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering) (MobileBERT 模型)

    +   [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig) 配置类: [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering) (MPT 模型)

    +   [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig) 配置类: [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering) (MRA 模型)

    +   [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig) 配置类: [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering) (MVP 模型)

    +   [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig) 配置类: [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering) (Nezha 模型)

    +   [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig) 配置类: [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering) (Nyströmformer 模型)

    +   [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig) 配置类: [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering) (OPT 模型)

    +   [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig) 配置类: [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering) (QDQBert 模型)

    +   [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig) 配置类: [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering) (Reformer 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering) (RemBERT 模型)

    +   [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig) 配置类: [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering) (RoCBert 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering) (RoBERTa-PreLayerNorm 模型)

    +   [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig) 配置类: [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering) (Splinter 模型)

    +   [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig) 配置类: [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering) (SqueezeBERT 模型)

    +   [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config) 配置类: [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering) (T5 模型)

    +   [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config) 配置类: [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering) (UMT5 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering) (XLM-RoBERTa 模型)

    +   [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig) 配置类: [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering) (XLM-RoBERTa-XL 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)配置类：[XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)（XLNet模型）

    +   [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)配置类：[XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)（X-MOD模型）

    +   [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)配置类：[YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)（YOSO模型）

从配置中实例化库中的一个模型类（带有问答头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间下的用户或组织名称，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个路径或url到一个*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建一个模型，但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以 `revision` 可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在Hub上定义自定义模型并在其自己的建模文件中执行。此选项应仅针对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以 `revision` 可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库的一个模型类（带有问答头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `albert` — [AlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering) (ALBERT模型)

+   `bart` — [BartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForQuestionAnswering) (BART模型)

+   `bert` — [BertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForQuestionAnswering) (BERT模型)

+   `big_bird` — [BigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering) (BigBird模型)

+   `bigbird_pegasus` — [BigBirdPegasusForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering) (BigBird-Pegasus 模型)

+   `bloom` — [BloomForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForQuestionAnswering) (BLOOM 模型)

+   `camembert` — [CamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering) (CamemBERT 模型)

+   `canine` — [CanineForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForQuestionAnswering) (CANINE 模型)

+   `convbert` — [ConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering) (ConvBERT 模型)

+   `data2vec-text` — [Data2VecTextForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering) (Data2VecText 模型)

+   `deberta` — [DebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering) (DeBERTa 模型)

+   `deberta-v2` — [DebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering) (DeBERTa-v2 模型)

+   `distilbert` — [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering) (DistilBERT 模型)

+   `electra` — [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering) (ELECTRA 模型)

+   `ernie` — [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering) (ERNIE 模型)

+   `ernie_m` — [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering) (ErnieM 模型)

+   `falcon` — [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering) (Falcon 模型)

+   `flaubert` — [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple) (FlauBERT 模型)

+   `fnet` — [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering) (FNet 模型)

+   `funnel` — [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering) (Funnel Transformer 模型)

+   `gpt2` — [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering) (OpenAI GPT-2 模型)

+   `gpt_neo` — [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering) (GPT Neo 模型)

+   `gpt_neox` — [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering) (GPT NeoX 模型)

+   `gptj` — [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering) (GPT-J 模型)

+   `ibert` — [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering) (I-BERT 模型)

+   `layoutlmv2` — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering) (LayoutLMv2 模型)

+   `layoutlmv3` — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering) (LayoutLMv3 模型)

+   `led` — [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering) (LED 模型)

+   `lilt` — [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering) (LiLT 模型)

+   `longformer` — [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering) (Longformer 模型)

+   `luke` — [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering) (LUKE 模型)

+   `lxmert` — [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering) (LXMERT 模型)

+   `markuplm` — [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering) (MarkupLM 模型)

+   `mbart` — [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering) (mBART 模型)

+   `mega` — [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering) (MEGA 模型)

+   `megatron-bert` — [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering) (Megatron-BERT 模型)

+   `mobilebert` — [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering) (MobileBERT 模型)

+   `mpnet` — [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering) (MPNet 模型)

+   `mpt` — [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering) (MPT 模型)

+   `mra` — [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering) (MRA 模型)

+   `mt5` — [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering) (MT5 模型)

+   `mvp` — [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering) (MVP 模型)

+   `nezha` — [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering) (Nezha 模型)

+   `nystromformer` — [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering) (Nyströmformer 模型)

+   `opt` — [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering) (OPT 模型)

+   `qdqbert` — [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering) (QDQBert 模型)

+   `reformer` — [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering) (Reformer 模型)

+   `rembert` — [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering) (RemBERT 模型)

+   `roberta` — [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering) (RoBERTa 模型)

+   `roberta-prelayernorm` — [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering) (RoBERTa-PreLayerNorm 模型)

+   `roc_bert` — [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering) (RoCBert 模型)

+   `roformer` — [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering) (RoFormer 模型)

+   `splinter` — [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering) (Splinter 模型)

+   `squeezebert` — [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering) (SqueezeBERT 模型)

+   `t5` — [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering) (T5 模型)

+   `umt5` — [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering) (UMT5 模型)

+   `xlm` — [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple) (XLM 模型)

+   `xlm-roberta` — [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering) (XLM-RoBERTa 模型)

+   `xlm-roberta-xl` — [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering) (XLM-RoBERTa-XL 模型)

+   `xlnet` — [XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple) (XLNet 模型)

+   `xmod` — [XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering) (X-MOD 模型)

+   `yoso` — [YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering) (YOSO 模型)

默认情况下，模型处于评估模式，使用 `model.eval()` (例如，dropout 模块被停用)。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例:

```py
>>> from transformers import AutoConfig, AutoModelForQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForQuestionAnswering.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForQuestionAnswering

### `class transformers.TFAutoModelForQuestionAnswering`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L637)

```py
( *args **kwargs )
```

这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库中的模型类之一实例化 (带有一个问答头)。

这个类不能直接使用 `__init__()` 实例化 (会抛出错误)。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 实例化的模型类基于配置类进行选择:

    +   [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig) 配置类: [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering) (ALBERT 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig) 配置类: [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering) (BERT 模型)

    +   [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig) 配置类: [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering) (CamemBERT 模型)

    +   [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig) 配置类: [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering) (ConvBERT 模型)

    +   [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig) 配置类: [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering) (DeBERTa 模型)

    +   [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config) 配置类: [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering) (DeBERTa-v2 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类: [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering) (ELECTRA 模型)

    +   [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig) 配置类: [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple) (FlauBERT 模型)

    +   [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig) 配置类: [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering) (Funnel Transformer 模型)

    +   [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig) 配置类: [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering) (GPT-J 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering) (LayoutLMv3 模型)

    +   [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig) 配置类: [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering) (Longformer 模型)

    +   [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig) 配置类: [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering) (MPNet 模型)

    +   [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig) 配置类: [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering) (MobileBERT 模型)

    +   [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig) 配置类: [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering) (RemBERT 模型)

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类: [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering) (RoFormer 模型)

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类: [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering) (RoBERTa 模型)

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类: [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering) (RoBERTa-PreLayerNorm 模型)

    +   [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig) 配置类: [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple) (XLM 模型)

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类: [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering) (XLM-RoBERTa 模型)

    +   [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig) 配置类: [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple) (XLNet 模型)

从配置实例化库中的一个模型类（带有问答头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   *PyTorch state_dict save file* 的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并且应将配置对象提供为`config`参数。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并在加载 TensorFlow 模型之后，此加载路径比较慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存模型，并通过提供保存目录重新加载模型。

    +   通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的自己的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地计算机上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）- 如果代码位于Hub上的不同存储库中，则用于代码的特定修订版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*）- 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载：

    +   如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型中实例化库的模型类之一（带有问答头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `albert` - [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)（ALBERT模型）

+   `bert` - [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)（BERT模型）

+   `camembert` - [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)（CamemBERT模型）

+   `convbert` - [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)（ConvBERT模型）

+   `deberta` - [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)（DeBERTa模型）

+   `deberta-v2` - [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)（DeBERTa-v2模型）

+   `distilbert` - [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)（DistilBERT模型）

+   `electra` - [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)（ELECTRA模型）

+   `flaubert` - [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)（FlauBERT模型）

+   `funnel` - [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)（Funnel Transformer模型）

+   `gptj` - [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)（GPT-J模型）

+   `layoutlmv3` - [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)（LayoutLMv3模型）

+   `longformer` — [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/longformer#transformers.TFLongformerForQuestionAnswering) (Longformer 模型)

+   `mobilebert` — [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering) (MobileBERT 模型)

+   `mpnet` — [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering) (MPNet 模型)

+   `rembert` — [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/rembert#transformers.TFRemBertForQuestionAnswering) (RemBERT 模型)

+   `roberta` — [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.TFRobertaForQuestionAnswering) (RoBERTa 模型)

+   `roberta-prelayernorm` — [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering) (RoFormer 模型)

+   `xlm` — [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple) (XLM 模型)

+   `xlm-roberta` — [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering) (XLM-RoBERTa 模型)

+   `xlnet` — [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple) (XLNet 模型)

示例:

```py
>>> from transformers import AutoConfig, TFAutoModelForQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForQuestionAnswering.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForQuestionAnswering

### `class transformers.FlaxAutoModelForQuestionAnswering`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L322)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库中的一个模型类（带有问答头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig) 配置类: [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering) (ALBERT 模型)

    +   [BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig) 配置类: [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.FlaxBartForQuestionAnswering) (BART 模型)

    +   [BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig) 配置类: [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.FlaxBertForQuestionAnswering) (BERT 模型)

    +   [BigBirdConfig](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdConfig) 配置类: [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering) (BigBird 模型)

    +   [DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig) 配置类: [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering) (DistilBERT 模型)

    +   [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig) 配置类：[FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)（ELECTRA 模型）

    +   [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig) 配置类：[FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)（mBART 模型）

    +   [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig) 配置类：[FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)（RoFormer 模型）

    +   [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig) 配置类：[FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)（RoBERTa 模型）

    +   [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig) 配置类：[FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)（RoBERTa-PreLayerNorm 模型）

    +   [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig) 配置类：[FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)（XLM-RoBERTa 模型）

从配置文件实例化库中的一个模型类（带有问答头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 用于模型的配置，而不是自动加载的配置。当：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并且通过提供保存目录来重新加载。

    +   通过提供一个本地目录作为`pretrained_model_name_or_path`来加载模型，并且在该目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir` (`str` 或 `os.PathLike`，*可选*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`，*可选*，默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`，*可选*，默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`，*可选*，默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`，*可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`，*可选*，默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`，*可选*，默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`，*可选*，默认为 `"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可以用来更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载，行为会有所不同：

    +   如果提供了一个带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设所有相关的配置更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有问答头）。

根据配置对象的 `model_type` 属性（如果可能作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上进行模式匹配来选择要实例化的模型类：

+   `albert` — [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)（ALBERT 模型）

+   `bart` — [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering)（BART 模型）

+   `bert` — [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering) (BERT 模型)

+   `big_bird` — [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering) (BigBird 模型)

+   `distilbert` — [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering) (DistilBERT 模型)

+   `electra` — [FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering) (ELECTRA 模型)

+   `mbart` — [FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering) (mBART 模型)

+   `roberta` — [FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering) (RoBERTa 模型)

+   `roberta-prelayernorm` — [FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering) (RoBERTa-PreLayerNorm 模型)

+   `roformer` — [FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering) (RoFormer 模型)

+   `xlm-roberta` — [FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering) (XLM-RoBERTa 模型)

示例:

```py
>>> from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForQuestionAnswering.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForTextEncoding

### `class transformers.AutoModelForTextEncoding`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1296)

```py
( *args **kwargs )
```

### TFAutoModelForTextEncoding

### `class transformers.TFAutoModelForTextEncoding`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L527)

```py
( *args **kwargs )
```

## 计算机视觉

以下自动类适用于以下计算机视觉任务。

### AutoModelForDepthEstimation

### `class transformers.AutoModelForDepthEstimation`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1489)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有深度估计头）。

这个类不能直接使用 `__init__()` 实例化（会报错）。

`from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 实例化的模型类是根据配置类选择的:

    +   [DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig) 配置类: [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation) (DPT 模型)

    +   [GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig) 配置类: [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation) (GLPN 模型)

从配置实例化库中的一个模型类（带有深度估计头）。

注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, AutoModelForDepthEstimation

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForDepthEstimation.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：

    +   一个字符串，托管在 huggingface.co 模型存储库内的预训练模型的 *模型 ID*。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   一个 *tensorflow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 是否不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *可选*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型在其自己的建模文件中。此选项应仅设置为`True`，用于您信任的存储库，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统来存储模型和huggingface.co上的其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*）— 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有深度估计头）。

基于配置对象的`model_type`属性选择要实例化的模型类（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `dpt` — [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)（DPT模型）

+   `glpn` — [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)（GLPN模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForDepthEstimation

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForDepthEstimation.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForImageClassification

### `class transformers.AutoModelForImageClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1423)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将被实例化为库中的一个模型类（带有图像分类头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 选择要实例化的模型类基于配置类：

    +   [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)配置类：[BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)（BEiT模型）

    +   BitConfig配置类：BitForImageClassification（BiT模型）

    +   ConvNextConfig配置类：ConvNextForImageClassification（ConvNeXT模型）

    +   ConvNextV2Config配置类：ConvNextV2ForImageClassification（ConvNeXTV2模型）

    +   CvtConfig配置类：CvtForImageClassification（CvT模型）

    +   Data2VecVisionConfig配置类：Data2VecVisionForImageClassification（Data2VecVision模型）

    +   DeiTConfig配置类：DeiTForImageClassification或DeiTForImageClassificationWithTeacher（DeiT模型）

    +   DinatConfig配置类：DinatForImageClassification（DiNAT模型）

    +   Dinov2Config配置类：Dinov2ForImageClassification（DINOv2模型）

    +   EfficientFormerConfig配置类：EfficientFormerForImageClassification或EfficientFormerForImageClassificationWithTeacher（EfficientFormer模型）

    +   EfficientNetConfig配置类：EfficientNetForImageClassification（EfficientNet模型）

    +   FocalNetConfig配置类：FocalNetForImageClassification（FocalNet模型）

    +   ImageGPTConfig配置类：ImageGPTForImageClassification（ImageGPT模型）

    +   LevitConfig配置类：LevitForImageClassification或LevitForImageClassificationWithTeacher（LeViT模型）

    +   [MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config) 配置类: [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification) (MobileNetV1 模型)

    +   [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config) 配置类: [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification) (MobileNetV2 模型)

    +   [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig) 配置类: [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification) (MobileViT 模型)

    +   [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config) 配置类: [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification) (MobileViTV2 模型)

    +   [NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig) 配置类: [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification) (NAT 模型)

    +   [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig) 配置类: [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned) 或 [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier) 或 [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing) (Perceiver 模型)

    +   [PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig) 配置类: [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification) (PoolFormer 模型)

    +   [PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig) 配置类: [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification) (PVT 模型)

    +   [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) 配置类: [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification) (RegNet 模型)

    +   [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) 配置类: [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification) (ResNet 模型)

    +   [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig) 配置类: [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification) (SegFormer 模型)

    +   [SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig) 配置类: [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification) (SwiftFormer 模型)

    +   [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig) 配置类: [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification) (Swin Transformer 模型)

    +   [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config) 配置类: [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification) (Swin Transformer V2 模型)

    +   [VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig) 配置类: [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification) (VAN 模型)

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig) 配置类: [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification) (ViT 模型)

    +   [ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig) 配置类: [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification) (ViT Hybrid 模型)

    +   [ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig) 配置类: [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification) (ViTMSN 模型)

从配置实例化库中的一个模型类（带有图像分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForImageClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForImageClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间，如 `dbmdz/bert-base-german-cased`。

    +   一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个指向*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应该设置为 `True`，并且应该提供一个配置对象作为 `config` 参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库中提供的一个模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录来重新加载。

    +   通过提供一个本地目录作为 `pretrained_model_name_or_path` 并在目录中找到一个名为 *config.json* 的配置JSON文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    这个选项可以用来从预训练配置创建一个模型，但加载自己的权重。在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器的字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统来存储模型和其他工件在 huggingface.co 上，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中使用。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统来存储模型和其他工件在 huggingface.co 上，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为会有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设所有相关的配置更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有图像分类头）。

根据配置对象的 `model_type` 属性（如果可能作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来选择要实例化的模型类：

+   `beit` — [BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)（BEiT 模型）

+   `bit` — [BitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitForImageClassification)（BiT 模型）

+   `convnext` — [ConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextForImageClassification) (ConvNeXT 模型)

+   `convnextv2` — [ConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2ForImageClassification) (ConvNeXTV2 模型)

+   `cvt` — [CvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtForImageClassification) (CvT 模型)

+   `data2vec-vision` — [Data2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification) (Data2VecVision 模型)

+   `deit` — [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification) 或 [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher) (DeiT 模型)

+   `dinat` — [DinatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatForImageClassification) (DiNAT 模型)

+   `dinov2` — [Dinov2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2ForImageClassification) (DINOv2 模型)

+   `efficientformer` — [EfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassification) 或 [EfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassificationWithTeacher) (EfficientFormer 模型)

+   `efficientnet` — [EfficientNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetForImageClassification) (EfficientNet 模型)

+   `focalnet` — [FocalNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForImageClassification) (FocalNet 模型)

+   `imagegpt` — [ImageGPTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification) (ImageGPT 模型)

+   `levit` — [LevitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassification) 或 [LevitForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher) (LeViT 模型)

+   `mobilenet_v1` — [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification) (MobileNetV1 模型)

+   `mobilenet_v2` — [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification) (MobileNetV2 模型)

+   `mobilevit` — [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification) (MobileViT 模型)

+   `mobilevitv2` — [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification) (MobileViTV2 模型)

+   `nat` — [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification) (NAT 模型)

+   `perceiver` — [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned) 或 [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier) 或 [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing) (Perceiver 模型)

+   `poolformer` — [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification) (PoolFormer 模型)

+   `pvt` — [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification) (PVT 模型)

+   `regnet` — [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)（RegNet模型）

+   `resnet` — [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)（ResNet模型）

+   `segformer` — [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)（SegFormer模型）

+   `swiftformer` — [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)（SwiftFormer模型）

+   `swin` — [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)（Swin Transformer模型）

+   `swinv2` — [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)（Swin Transformer V2模型）

+   `van` — [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)（VAN模型）

+   `vit` — [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)（ViT模型）

+   `vit_hybrid` — [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)（ViT混合模型）

+   `vit_msn` — [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)（ViTMSN模型）

默认情况下，模型处于评估模式，使用`model.eval()`（例如，dropout模块被停用）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForImageClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForImageClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForImageClassification

### `class transformers.TFAutoModelForImageClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L578)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的模型类之一（带有图像分类头）。

这个类不能直接使用`__init__()`进行实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 实例化的模型类基于配置类进行选择：

    +   [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)配置类：[TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)（ConvNeXT模型）

    +   [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)配置类：[TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)（ConvNeXTV2模型）

    +   [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)配置类：[TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)（CvT模型）

    +   [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)配置类：[TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)（Data2VecVision模型）

    +   [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig) 配置类：[TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification) 或 [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)（DeiT 模型）

    +   [EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig) 配置类：[TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification) 或 [TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)（EfficientFormer 模型）

    +   [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig) 配置类：[TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)（MobileViT 模型）

    +   [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) 配置类：[TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)（RegNet 模型）

    +   [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) 配置类：[TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)（ResNet 模型）

    +   [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig) 配置类：[TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)（SegFormer 模型）

    +   [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig) 配置类：[TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)（Swin Transformer 模型）

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig) 配置类：[TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)（ViT 模型）

从配置实例化库中的一个模型类（带有图像分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForImageClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForImageClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：

    +   一个字符串，预训练模型的*模型 id*，托管在huggingface.co上的模型存储库中。有效的模型 id 可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict save file*的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 用于模型的配置，而不是自动加载的配置。当自动加载配置时：

    +   该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并在目录中找到名为 *config.json* 的配置 JSON 文件。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 要使用的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将用于每个请求。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 在 Hub 上使用的代码的特定修订版，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载，行为会有所不同：

    +   如果提供了配置`config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有图像分类头）。

要实例化的模型类是根据配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载）选择的，或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `convnext` — [TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)（ConvNeXT模型）

+   `convnextv2` — [TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)（ConvNeXTV2模型）

+   `cvt` — [TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)（CvT模型）

+   `data2vec-vision` — [TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)（Data2VecVision模型）

+   `deit` — [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)或[TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)（DeiT模型）

+   `efficientformer` — [TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)或[TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)（EfficientFormer模型）

+   `mobilevit` — [TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)（MobileViT模型）

+   `regnet` — [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)（RegNet模型）

+   `resnet` — [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)（ResNet模型）

+   `segformer` — [TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)（SegFormer模型）

+   `swin` — [TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)（Swin Transformer模型）

+   `vit` — [TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)（ViT模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForImageClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForImageClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForImageClassification

### `class transformers.FlaxAutoModelForImageClassification`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L354)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有图像分类头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)配置类：[FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)（BEiT模型）

    +   [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig) 配置类: [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification) (RegNet 模型)

    +   [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig) 配置类: [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification) (ResNet 模型)

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig) 配置类: [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification) (ViT 模型)

从配置实例化库中的一个模型类（带有图像分类头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForImageClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForImageClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   一个 *PyTorch state_dict save file* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型的 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以被自动加载：

    +   模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并且通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 预下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, 默认为 `False`) — 从 PyTorch checkpoint 保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为会有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有图像分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上进行模式匹配来回退：

+   `beit` — [FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)（BEiT 模型）

+   `regnet` — [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)（RegNet 模型）

+   `resnet` — [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)（ResNet 模型）

+   `vit` — [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)（ViT 模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForImageClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForImageClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForVideoClassification

### `class transformers.AutoModelForVideoClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1496)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有视频分类头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 要实例化的模型类是基于配置类选择的：

    +   [TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig) 配置类：[TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)（TimeSformer 模型）

    +   [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig) 配置类：[VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)（VideoMAE 模型）

    +   [VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig) 配置类：[VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)（ViViT 模型）

从配置中实例化库中的一个模型类（带有视频分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForVideoClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForVideoClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型仓库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个路径或url指向*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的模型配置。当以下情况发生时，配置可以被自动加载：

    +   模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在该目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，可以使用此选项。在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从TensorFlow检查点保存文件加载模型权重。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点划分，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅设置为`True`，用于您信任的存储库，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有视频分类头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `timesformer` - [TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)（TimeSformer模型）

+   `videomae` - [VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)（VideoMAE模型）

+   `vivit` - [VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)（ViViT模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForVideoClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForVideoClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForMaskedImageModeling

### `class transformers.AutoModelForMaskedImageModeling`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1561)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将作为库的模型类之一实例化（带有遮罩图像建模头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 要实例化的模型类是根据配置类选择的：

    +   [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)配置类：[DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)（DeiT模型）

    +   [FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)配置类：[FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)（FocalNet模型）

    +   [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)配置类：[SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)（Swin Transformer模型）

    +   [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)配置类：[Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)（Swin Transformer V2模型）

    +   [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)配置类：[ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)（ViT模型）

从配置实例化库的模型类之一（带有遮罩图像建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只会影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForMaskedImageModeling

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForMaskedImageModeling.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是以下之一：

    +   一个字符串，指向huggingface.co上模型存储库中预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   路径或url指向*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型的`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。

+   `cache_dir` (`str`或`os.PathLike`, *optional*) — 下载预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *optional*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为`"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了 `config` 或自动加载，行为会有所不同：

    +   如果提供了配置 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个键对应于配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有遮罩图像建模头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退选择：

+   `deit` — [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)（DeiT 模型）

+   `focalnet` — [FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)（FocalNet 模型）

+   `swin` — [SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)（Swin Transformer 模型）

+   `swinv2` — [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)（Swin Transformer V2 模型）

+   `vit` — [ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)（ViT 模型）

默认情况下，该模型被设置为评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForMaskedImageModeling

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForMaskedImageModeling.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForMaskedImageModeling

### `class transformers.TFAutoModelForMaskedImageModeling`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L569)

```py
( *args **kwargs )
```

这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有遮罩图像建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 实例化的模型类基于配置类进行选择：

    +   [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig) 配置类：[TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)（DeiT模型）

    +   [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig) 配置类：[TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)（Swin Transformer模型）

从配置实例化库中的一个模型类（带有遮罩图像建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForMaskedImageModeling

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForMaskedImageModeling.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库的模型类之一（带有遮罩图像建模头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `deit` — [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)（DeiT模型）

+   `swin` — [TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)（Swin Transformer模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForMaskedImageModeling

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForMaskedImageModeling.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForObjectDetection

### `class transformers.AutoModelForObjectDetection`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1473)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库的模型类之一（带有对象检测头）。

此类不能直接使用`__init__()`进行实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig) 配置类：[ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)（条件 DETR 模型）

    +   [DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig) 配置类：[DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)（可变形 DETR 模型）

    +   [DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig) 配置类：[DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)（DETA 模型）

    +   [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig) 配置类：[DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)（DETR 模型）

    +   [TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig) 配置类：[TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)（表格变换器模型）

    +   [YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig) 配置类：[YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)（YOLOS 模型）

从配置中实例化库中的一个模型类（带有对象检测头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForObjectDetection

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForObjectDetection.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：

    +   一个字符串，指向在 huggingface.co 模型仓库中托管的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   指向包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   指向 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将 `from_tf` 设置为 `True`，并将配置对象作为 `config` 参数提供。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载 PyTorch 模型后，此加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*） — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存模型，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 是否不是更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点分组，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将用于每个请求。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为 `True`，并且您已阅读了代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，其行为有所不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有对象检测头）。

要实例化的模型类是根据配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载（如果可能））选择的，或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来选择：

+   `conditional_detr` — [ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)（条件DETR模型）

+   `deformable_detr` — [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)（可变形DETR模型）

+   `deta` — [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)（DETA模型）

+   `detr` — [DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)（DETR模型）

+   `table-transformer` — [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)（表格变换器模型）

+   `yolos` — [YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)（YOLOS模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForObjectDetection

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForObjectDetection.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForImageSegmentation

### `class transformers.AutoModelForImageSegmentation`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1439)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有图像分割头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 要实例化的模型类是根据配置类选择的：

    +   [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)配置类：[DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR模型）

从配置中实例化库中的一个模型类（带有图像分割头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForImageSegmentation

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForImageSegmentation.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   *TensorFlow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并随后加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*） — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*） — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`，*可选*） — 下载预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`，*可选*） — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含丢失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设所有相关的配置更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有图像分割头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `detr` — [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForImageSegmentation

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForImageSegmentation.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForImageToImage

### `class transformers.AutoModelForImageToImage`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1300)

```py
( *args **kwargs )
```

### AutoModelForSemanticSegmentation

### `class transformers.AutoModelForSemanticSegmentation`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1446)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有语义分割头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 要实例化的模型类是根据配置类选择的：

    +   [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig) 配置类：[BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)（BEiT模型）

    +   [DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig) 配置类：[DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)（DPT模型）

    +   [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig) 配置类: [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)（Data2VecVision 模型）

    +   [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config) 配置类: [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)（MobileNetV2 模型）

    +   [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig) 配置类: [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)（MobileViT 模型）

    +   [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config) 配置类: [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)（MobileViTV2 模型）

    +   [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig) 配置类: [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)（SegFormer 模型）

    +   [UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig) 配置类: [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)（UPerNet 模型）

从配置实例化库中的一个模型类（带有语义分割头）。

注意：通过配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForSemanticSegmentation

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForSemanticSegmentation.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`） — 可以是以下之一：

    +   一个字符串，一个托管在 huggingface.co 模型仓库中的预训练模型的 *模型id*。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间，如 `dbmdz/bert-base-german-cased`。

    +   一个指向使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   一个路径或url指向一个 *tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应该设置为 `True` 并且应该提供一个配置对象作为 `config` 参数。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并在之后加载 PyTorch 模型的加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*） — 用于替代自动加载的配置的模型配置。当以下情况发生时，配置可以被自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型id* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供一个本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到一个名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 要使用的状态字典，而不是从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 是否不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为 `"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为会有所不同：

    +   如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个与配置属性对应的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有语义分割头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退到：

+   `beit` - [BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)（BEiT模型）

+   `data2vec-vision` - [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)（Data2VecVision模型）

+   `dpt` - [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)（DPT模型）

+   `mobilenet_v2` - [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)（MobileNetV2模型）

+   `mobilevit` - [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)（MobileViT模型）

+   `mobilevitv2` - [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)（MobileViTV2模型）

+   `segformer` - [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)（SegFormer模型）

+   `upernet` - [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)（UPerNet模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForSemanticSegmentation

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForSemanticSegmentation.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForSemanticSegmentation

### `class transformers.TFAutoModelForSemanticSegmentation`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L596)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库的模型类之一（带有语义分割头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 选择要实例化的模型类基于配置类：

    +   [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)配置类：[TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)（Data2VecVision模型）

    +   [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)配置类：[TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)（MobileViT模型）

    +   [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)配置类：[TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)（SegFormer模型）

从配置实例化库的模型类之一（带有语义分割头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForSemanticSegmentation.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   字符串，托管在huggingface.co模型存储库内的预训练模型的*model id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   路径或url到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并加载TensorFlow模型后，此加载路径比较慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：

    +   该模型是由库提供的模型（使用预训练模型的*model id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载预训练模型配置的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *optional*, defaults to `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型在其自己的建模文件中。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：

    +   如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设所有相关的配置更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有语义分割头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `data2vec-vision` — [TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)（Data2VecVision模型）

+   `mobilevit` — [TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)（MobileViT模型）

+   `segformer` — [TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)（SegFormer模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForSemanticSegmentation.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### 实例分割的自动模型

### `class transformers.AutoModelForInstanceSegmentation`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1464)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的一个模型类（带有实例分割头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 要实例化的模型类是根据配置类选择的：

    +   [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)配置类：[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）

从配置实例化库中的模型类（带有实例分割头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForInstanceSegmentation

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForInstanceSegmentation.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：

    +   一个字符串，托管在 huggingface.co 上的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   *TensorFlow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将 `from_tf` 设置为 `True`，并将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并随后加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况自动加载配置时：

    +   该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict`（*Dict[str, torch.Tensor]*, *optional*） — 用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 是否不是更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow checkpoint 保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器的协议或端点的字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。

+   `output_loading_info` (`bool`, *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）- 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅在您信任的存储库中设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）- 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载了`config`，行为不同：

    +   如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型中实例化库中的模型类之一（带有实例分割头）。

选择要实例化的模型类基于配置对象的`model_type`属性（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `maskformer` - [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForInstanceSegmentation

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForInstanceSegmentation.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForUniversalSegmentation

### `class transformers.AutoModelForUniversalSegmentation`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1455)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将作为库中的模型类之一实例化（带有通用图像分割头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 选择要实例化的模型类基于配置类：

    +   [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)配置类：[DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR模型）

    +   [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)配置类：[Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)（Mask2Former模型）

    +   [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)配置类：[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）

    +   [OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)配置类：[OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)（OneFormer模型）

从配置实例化库中的一个模型类（带有通用图像分割头）时自动加载配置。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForUniversalSegmentation

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForUniversalSegmentation.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）—可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   一个指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个路径或URL指向一个*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型之后，这种加载路径比较慢。

+   `model_args`（额外的位置参数，*可选*）—将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—要使用的模型配置，而不是自动加载的配置。当：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供一个本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）—要使用的状态字典，而不是从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建一个模型，但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否是一个更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不使用标准缓存，可以用于缓存下载的预训练模型配置的目录路径。

+   `from_tf`（`bool`，*可选*，默认为`False`）- 从 TensorFlow 检查点保存文件中加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）- 要使用的代理服务器的协议或端点的字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) - 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) - 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）- 用于 Hub 上代码的特定修订版，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载的情况，行为会有所不同：

    +   如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有通用图像分割头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `detr` - [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR 模型）

+   `mask2former` - [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)（Mask2Former 模型）

+   `maskformer` — [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）

+   `oneformer` — [OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)（OneFormer模型）

默认情况下，使用 `model.eval()` 将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForUniversalSegmentation

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForUniversalSegmentation.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForUniversalSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForUniversalSegmentation.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForZeroShotImageClassification

### `class transformers.AutoModelForZeroShotImageClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1430)

```py
( *args **kwargs )
```

这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库中的模型类之一实例化（带有零样本图像分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 实例化的模型类基于配置类选择：

    +   [AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig) 配置类：[AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)（ALIGN模型）

    +   [AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig) 配置类：[AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)（AltCLIP模型）

    +   [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig) 配置类：[BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)（BLIP模型）

    +   [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig) 配置类：[CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)（CLIP模型）

    +   [CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig) 配置类：[CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)（CLIPSeg模型）

    +   [ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig) 配置类：[ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)（中文-CLIP模型）

    +   [SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig) 配置类：[SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)（SigLIP模型）

从配置实例化库中的模型类之一（带有零样本图像分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForZeroShotImageClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForZeroShotImageClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的 *模型 ID*，托管在 huggingface.co 上的模型仓库中。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 路径，例如 `./my_model_directory/`。

    +   一个 *tensorflow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应提供配置对象作为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 是否不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不想使用标准缓存。

+   `from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 要使用的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任并且已阅读代码的存储库设置为`True`，因为它将在本地计算机上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载：

    +   如果提供了`config`配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个键对应于配置属性，将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有零样本图像分类头）。

将要实例化的模型类基于配置对象的`model_type`属性选择（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `align` — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)（ALIGN模型）

+   `altclip` — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)（AltCLIP模型）

+   `blip` — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)（BLIP模型）

+   `chinese_clip` — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)（Chinese-CLIP模型）

+   `clip` — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)（CLIP模型）

+   `clipseg` — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)（CLIPSeg模型）

+   `siglip` — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)（SigLIP模型）

默认情况下，模型以评估模式设置，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForZeroShotImageClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForZeroShotImageClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForZeroShotImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForZeroShotImageClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForZeroShotImageClassification

### `class transformers.TFAutoModelForZeroShotImageClassification`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L587)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库中的模型类之一（带有零样本图像分类头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 选择要实例化的模型类基于配置类：

    +   [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)配置类：[TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)（BLIP模型）

    +   [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)配置类：[TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)（CLIP模型）

从配置实例化库中的一个模型类（带有零射击图像分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForZeroShotImageClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForZeroShotImageClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：

    +   一个字符串，指向huggingface.co模型库中托管的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个路径或URL指向一个*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并在之后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于模型的配置而不是自动加载的配置。当以下情况时可以自动加载配置：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置JSON文件来加载模型。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载 `config`，行为不同：

    +   如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 中与配置属性对应的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有零样本图像分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `blip` — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel) (BLIP 模型)

+   `clip` — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel) (CLIP 模型)

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForZeroShotImageClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForZeroShotImageClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForZeroShotImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForZeroShotImageClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForZeroShotObjectDetection

### `class transformers.AutoModelForZeroShotObjectDetection`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1480)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化库中的一个模型类（带有零样本目标检测头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 选择要实例化的模型类基于配置类：

    +   [OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)配置类：[OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)（OWL-ViT模型）

    +   [Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)配置类：[Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)（OWLv2模型）

从配置实例化库中的模型类（带有零射击目标检测头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForZeroShotObjectDetection.from_config(config)
```

`from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   一个路径或url到*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）- 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`）- 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）- 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）- 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载，行为会有所不同：

    +   如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有零样本目标检测头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `owlv2` - [Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)（OWLv2模型）

+   `owlvit` - [OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)（OWL-ViT模型）

默认情况下，模型以评估模式设置，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForZeroShotObjectDetection.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

## 音频

以下自动类适用于以下音频任务。

### AutoModelForAudioClassification

### `class transformers.AutoModelForAudioClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1510)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有音频分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig) 配置类: [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification) (音频频谱变换器模型)

    +   [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig) 配置类: [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification) (Data2VecAudio 模型)

    +   [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig) 配置类: [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification) (Hubert 模型)

    +   [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig) 配置类: [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification) (SEW 模型)

    +   [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig) 配置类: [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification) (SEW-D 模型)

    +   [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig) 配置类: [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification) (UniSpeech 模型)

    +   [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) 配置类: [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification) (UniSpeechSat 模型)

    +   [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig) 配置类: [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification) (Wav2Vec2-BERT 模型)

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类: [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification) (Wav2Vec2 模型)

    +   [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig) 配置类: [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification) (Wav2Vec2-Conformer 模型)

    +   [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig) 配置类：[WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)（WavLM模型）

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类：[WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)（Whisper模型）

从配置实例化库中的一个模型类（带有音频分类头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForAudioClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForAudioClassification.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是以下之一：

    +   一个字符串，huggingface.co上托管的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*optional*） — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`和在该目录中找到名为*config.json*的配置JSON文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建一个模型，但加载自己的权重，可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是一个更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置文件应该被缓存的目录路径，如果不想使用标准缓存。

+   `from_tf`（`bool`，*optional*，默认为`False`） — 从TensorFlow检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*optional*，默认为`False`） — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为不同：

    +   如果提供了配置 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则首先将 `kwargs` 传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的 `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有音频分类头）。

要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `audio-spectrogram-transformer` — [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification) (音频频谱变换器模型)

+   `data2vec-audio` — [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification) (Data2VecAudio 模型)

+   `hubert` — [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification) (Hubert 模型)

+   `sew` — [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification) (SEW 模型)

+   `sew-d` — [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification) (SEW-D 模型)

+   `unispeech` — [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification) (UniSpeech 模型)

+   `unispeech-sat` — [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification) (UniSpeechSat 模型)

+   `wav2vec2` — [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification) (Wav2Vec2 模型)

+   `wav2vec2-bert` — [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification) (Wav2Vec2-BERT 模型)

+   `wav2vec2-conformer` — [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification) (Wav2Vec2-Conformer 模型)

+   `wavlm` — [WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification) (WavLM 模型)

+   `whisper` — [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification) (Whisper 模型)

默认情况下，该模型被设置为评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForAudioClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForAudioClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForAudioFrameClassification

### `class transformers.TFAutoModelForAudioClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L538)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的模型类（带有音频分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类：[TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification) (Wav2Vec2 模型)

从配置中实例化库中的一个模型类（带有音频分类头）。

注意：从配置文件加载模型 **不会** 加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForAudioClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForAudioClassification.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是以下之一：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个指向包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。

    +   路径或URL到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选的*） — 将传递给底层模型`__init__()`方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选的*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是由库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选的*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *可选的*，默认为`False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *可选的*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选的*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选的*) — 要使用的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选的*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选的*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选的*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选的*，默认为`False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *可选的*，默认为`"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选的*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 中对应配置属性的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型中实例化库中的一个模型类（带有音频分类头）。

实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：

+   `wav2vec2` - [TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)（Wav2Vec2 模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForAudioClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForAudioClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForAudioClassification.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### TFAutoModelForAudioFrameClassification

### `class transformers.AutoModelForAudioFrameClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1533)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库中的一个模型类（带有音频帧（标记）分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 实例化的模型类是根据配置类选择的：

    +   [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig) 配置类：[Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)（Data2VecAudio 模型）

    +   [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) 配置类：[UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)（UniSpeechSat 模型）

    +   [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig) 配置类：[Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)（Wav2Vec2-BERT 模型）

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类：[Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)（Wav2Vec2 模型）

    +   [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig) 配置类：[Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)（Wav2Vec2-Conformer 模型）

    +   [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig) 配置类：[WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)（WavLM 模型）

从配置实例化库中的一个模型类（带有音频帧（令牌）分类头）。

注意：从其配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForAudioFrameClassification

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForAudioFrameClassification.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）—可以是：

    +   一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。

    +   指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将`from_tf`设置为`True`，并将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）—将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）—要使用的状态字典，而不是从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）—应在其中缓存下载的预训练模型配置的目录路径，如果不使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`）—从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）—是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）—是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）—要使用的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：

    +   如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有音频帧（标记）分类头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `data2vec-audio` — [Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)（Data2VecAudio模型）

+   `unispeech-sat` — [UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)（UniSpeechSat模型）

+   `wav2vec2` — [Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)（Wav2Vec2模型）

+   `wav2vec2-bert` — [Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)（Wav2Vec2-BERT模型）

+   `wav2vec2-conformer` — [Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)（Wav2Vec2-Conformer模型）

+   `wavlm` — [WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)（WavLM模型）

默认情况下，该模型以评估模式设置，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForAudioFrameClassification

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForAudioFrameClassification.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForCTC

### `class transformers.AutoModelForCTC`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1517)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库中的一个模型类实例化（带有连接主义时间分类头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig) 配置类：[Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)（Data2VecAudio 模型）

    +   [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig) 配置类：[HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)（Hubert 模型）

    +   [MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig) 配置类：[MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)（M-CTC-T 模型）

    +   [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig) 配置类：[SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)（SEW 模型）

    +   [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig) 配置类：[SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)（SEW-D 模型）

    +   [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig) 配置类：[UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)（UniSpeech 模型）

    +   [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) 配置类：[UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)（UniSpeechSat 模型）

    +   [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig) 配置类：[Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)（Wav2Vec2-BERT 模型）

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类：[Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)（Wav2Vec2 模型）

    +   [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig) 配置类：[Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)（Wav2Vec2-Conformer 模型）

    +   [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig) 配置类：[WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)（WavLM 模型）

从配置实例化库中的一个模型类（带有连接主义时间分类头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForCTC

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForCTC.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的 *model id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间，如 `dbmdz/bert-base-german-cased`。

    +   包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的 *目录* 路径，例如，`./my_model_directory/`。

    +   路径或url指向*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型更慢。

+   `model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — 模型使用的配置，而不是自动加载的配置。当：

    +   该模型是库提供的模型（使用预训练模型的 *model id* 字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并在目录中找到名为 *config.json* 的配置JSON文件。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建一个模型，但加载自己的权重，可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载预训练模型配置文件时应缓存的目录路径，如果不使用标准缓存。

+   `from_tf` (`bool`, *optional*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`） — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`） — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在Hub上定义自定义模型的代码在其自己的建模文件中。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，其行为有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有连接主义时间分类头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `data2vec-audio` — [Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)（Data2VecAudio模型）

+   `hubert` — [HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)（Hubert模型）

+   `mctct` — [MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)（M-CTC-T模型）

+   `sew` — [SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)（SEW模型）

+   `sew-d` — [SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)（SEW-D模型）

+   `unispeech` — [UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)（UniSpeech模型）

+   `unispeech-sat` — [UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)（UniSpeechSat模型）

+   `wav2vec2` — [Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)（Wav2Vec2模型）

+   `wav2vec2-bert` — [Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)（Wav2Vec2-BERT模型）

+   `wav2vec2-conformer` — [Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)（Wav2Vec2-Conformer模型）

+   `wavlm` — [WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)（WavLM模型）

默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()` 将其设置回训练模式

示例:

```py
>>> from transformers import AutoConfig, AutoModelForCTC

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForCTC.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForCTC.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForSpeechSeq2Seq

### `class transformers.AutoModelForSpeechSeq2Seq`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1524)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有序列到序列语音转文本建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类:

    +   [Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig) 配置类: [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration) (Pop2Piano 模型)

    +   [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig) 配置类: [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText) (SeamlessM4T 模型)

    +   [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config) 配置类: [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText) (SeamlessM4Tv2 模型)

    +   [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig) 配置类: [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration) (语音转文本模型)

    +   [SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig) 配置类: [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel) (语音编码解码模型)

    +   [SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config) 配置类: [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText) (SpeechT5 模型)

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类: [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration) (Whisper 模型)

从配置实例化库中的一个模型类（带有序列到序列语音转文本建模头）。

注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForSpeechSeq2Seq.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是:

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如`./my_model_directory/`。

    +   路径或url到一个*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）—将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）—要使用的状态字典，而不是从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型，但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）—下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`）—从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）—是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）—是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）—要使用的代理服务器的字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`）—是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）—是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）—要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型在其自己的建模文件中。此选项应仅对您信任的存储库设置为 `True`，并且您已经阅读了代码，因为它将在本地计算机上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, 默认为`"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，其行为有所不同：

    +   如果提供了 `config` 配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs` 的每个对应于配置属性的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。

从预训练模型实例化库中的一个模型类（带有序列到序列语音转文本建模头）。

根据配置对象的 `model_type` 属性选择要实例化的模型类（如果可能，作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退。

+   `pop2piano` — [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration) (Pop2Piano 模型)

+   `seamless_m4t` — [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText) (SeamlessM4T 模型)

+   `seamless_m4t_v2` — [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText) (SeamlessM4Tv2 模型)

+   `speech-encoder-decoder` — [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel) (Speech 编码器解码器模型)

+   `speech_to_text` — [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration) (Speech2Text 模型)

+   `speecht5` — [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText) (SpeechT5 模型)

+   `whisper` — [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration) (Whisper 模型)

默认情况下，模型设置为评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先将其设置回训练模式，使用 `model.train()`

示例：

```py
>>> from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForSpeechSeq2Seq.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForSpeechSeq2Seq

### `class transformers.TFAutoModelForSpeechSeq2Seq`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L691)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将作为库的模型类之一实例化（带有一个序列到序列语音到文本建模头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 选择要实例化的模型类取决于配置类：

    +   [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)配置类：[TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)（Speech2Text模型）

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)配置类：[TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)（Whisper模型）

从配置实例化库的模型类之一（带有一个序列到序列语音到文本建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForSpeechSeq2Seq.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   路径或url指向*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 用于替代自动加载的配置的模型使用的配置。当：

    +   模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件时，可以自动加载配置。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不使用标准缓存，则应将下载的预训练模型配置缓存到的目录路径。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 要按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为`False`）— 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（其他关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型中实例化库中的一个模型类（带有序列到序列语音到文本建模头）。

实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `speech_to_text` — [TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)（Speech2Text模型）

+   `whisper` — [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)（Whisper模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForSpeechSeq2Seq

### `class transformers.FlaxAutoModelForSpeechSeq2Seq`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L370)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将实例化为库的模型类之一（带有序列到序列语音转文本建模头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）- 要实例化的模型类是基于配置类选择的：

    +   [SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig) 配置类：[FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)（语音编码器解码器模型）

    +   [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig) 配置类：[FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)（Whisper 模型）

从配置中实例化库的模型类之一（带有序列到序列语音转文本建模头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForSpeechSeq2Seq

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForSpeechSeq2Seq.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`）- 可以是以下之一：

    +   一个字符串，托管在 huggingface.co 模型存储库中的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 路径，例如 `./my_model_directory/`。

    +   一个 *PyTorch state_dict 保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并加载 TensorFlow 模型要慢。

+   `model_args`（额外的位置参数，*可选*）- 将传递给底层模型的 `__init__()` 方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）- 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并且在目录中找到名为 *config.json* 的配置 JSON 文件。

+   `cache_dir` (`str`或`os.PathLike`, *可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt` (`bool`, *可选*, 默认为`False`) — 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*, 默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为`False`) — 是否允许在Hub上定义自定义模型的自己的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision` (`str`, *可选*, 默认为`"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载而表现不同：

    +   如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有序列到序列语音到文本建模头）。

实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：

+   `speech-encoder-decoder` — [FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)（语音编码器解码器模型）

+   `whisper` — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)（Whisper 模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForSpeechSeq2Seq

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForAudioXVector

### `class transformers.AutoModelForAudioXVector`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1542)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将作为库中的模型类之一实例化（通过 x-vector 头进行音频检索）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 要实例化的模型类是根据配置类选择的：

    +   [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig) 配置类：[Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)（Data2VecAudio 模型）

    +   [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig) 配置类：[UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)（UniSpeechSat 模型）

    +   [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig) 配置类：[Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)（Wav2Vec2-BERT 模型）

    +   [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config) 配置类：[Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)（Wav2Vec2 模型）

    +   [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig) 配置类：[Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)（Wav2Vec2-Conformer 模型）

    +   [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig) 配置类：[WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)（WavLM 模型）

从配置实例化库中的模型类之一（通过 x-vector 头进行音频检索）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForAudioXVector

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForAudioXVector.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str` 或 `os.PathLike`） — 可以是：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个 *目录* 的路径，其中包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重，例如 `./my_model_directory/`。

    +   路径或指向 *tensorflow 索引检查点文件* 的 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并随后加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*，*可选*) — 用于替代从保存的权重文件加载的状态字典。

    如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`，*可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。

+   `from_tf` (`bool`，*可选*，默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`，*可选*，默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`，*可选*，默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`，*可选*) — 用于每个请求的代理服务器字典，按协议或端点分类，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`，*可选*，默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`，*可选*，默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载，行为不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型中实例化库中的一个模型类（带有通过x-vector头进行音频检索）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `data2vec-audio` — [Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)（Data2VecAudio模型）

+   `unispeech-sat` — [UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)（UniSpeechSat模型）

+   `wav2vec2` — [Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)（Wav2Vec2模型）

+   `wav2vec2-bert` — [Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)（Wav2Vec2-BERT模型）

+   `wav2vec2-conformer` — [Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)（Wav2Vec2-Conformer模型）

+   `wavlm` — [WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)（WavLM模型）

模型默认使用`model.eval()`设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForAudioXVector

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForAudioXVector.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForTextToSpectrogram

### `class transformers.AutoModelForTextToSpectrogram`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1546)

```py
( *args **kwargs )
```

### AutoModelForTextToWaveform

### `class transformers.AutoModelForTextToWaveform`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1550)

```py
( *args **kwargs )
```

## 多模态

以下自动类适用于以下多模态任务。

### AutoModelForTableQuestionAnswering

### `class transformers.AutoModelForTableQuestionAnswering`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1367)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将被实例化为库中的一个模型类（带有表格问答头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 要实例化的模型类是基于配置类选择的：

    +   [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)配置类：[TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)（TAPAS模型）

从配置实例化库中的一个模型类（带有表格问答头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForTableQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
>>> model = AutoModelForTableQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*tensorflow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为`False`）— 是否返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的代码。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上代码的特定修订版本，如果代码与模型的其余部分不在同一存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*）— 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有表格问答头）。

根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来选择要实例化的模型类：

+   `tapas` — [TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)（TAPAS模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForTableQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

>>> # Update configuration during loading
>>> model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
>>> model = AutoModelForTableQuestionAnswering.from_pretrained(
...     "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForTableQuestionAnswering

### `class transformers.TFAutoModelForTableQuestionAnswering`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L655)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config) 类方法创建时，将被实例化为库中的一个模型类（带有表格问答头）。

这个类不能直接使用 `__init__()` 实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)) — 根据配置类选择要实例化的模型类：

    +   [TapasConfig](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TapasConfig) 配置类: [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TFTapasForQuestionAnswering) (TAPAS 模型)

从配置实例化库中的一个模型类（带有表格问答头）。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
>>> model = TFAutoModelForTableQuestionAnswering.from_config(config)
```

`from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：

    +   一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如 `dbmdz/bert-base-german-cased`。

    +   一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 路径，例如，`./my_model_directory/`。

    +   一个 *PyTorch 状态字典保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将 `from_pt` 设置为 `True`，并且应该提供一个配置对象作为 `config` 参数。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型，这种加载路径比直接加载 PyTorch 模型慢。

+   `model_args` (额外的位置参数, *可选*) — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：

    +   该模型是库提供的一个模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存到的目录路径。

+   `from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则首先将`kwargs`传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有表格问答头）。

要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退选择。

+   `tapas` — [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering)（TAPAS模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

>>> # Update configuration during loading
>>> model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
>>> model = TFAutoModelForTableQuestionAnswering.from_pretrained(
...     "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForDocumentQuestionAnswering

### `class transformers.AutoModelForDocumentQuestionAnswering`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1389)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有文档问答头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)) — 选择要实例化的模型类基于配置类:

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类: [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering) (LayoutLM 模型)

    +   [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config) 配置类: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering) (LayoutLMv2 模型)

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering) (LayoutLMv3 模型)

从配置实例化库中的一个模型类（带有文档问答头）。

注意: 从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
>>> model = AutoModelForDocumentQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:

    +   一个字符串，托管在huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   一个*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将`from_tf`设置为`True`，并且应将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型更慢。

+   `model_args` (额外的位置参数，*可选*) — 将传递给底层模型的 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于替代自动加载的配置的模型配置。当以下情况发生时，配置可以被自动加载:

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录来重新加载。

    +   模型通过提供一个本地目录作为`pretrained_model_name_or_path`来加载，并且在该目录中找到一个名为*config.json*的配置JSON文件。

+   `state_dict`（*Dict[str, torch.Tensor]*，*可选*） — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。

+   `cache_dir` (`str`或`os.PathLike`，*可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *可选*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download` (`bool`, *可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`，*可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码。

+   `code_revision` (`str`，*可选*，默认为`"main"`) — 用于Hub上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有文档问答头）。

根据配置对象的`model_type`属性选择要实例化的模型类（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `layoutlm` — [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)（LayoutLM 模型）

+   `layoutlmv2` — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)（LayoutLMv2 模型）

+   `layoutlmv3` — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)（LayoutLMv3 模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，首先应该使用`model.train()`将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

>>> # Update configuration during loading
>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(
...     "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForDocumentQuestionAnswering

### `class transformers.TFAutoModelForDocumentQuestionAnswering`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L644)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的一个模型类（带有文档问答头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 根据配置类选择要实例化的模型类：

    +   [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig) 配置类：[TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)（LayoutLM 模型）

    +   [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config) 配置类：[TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)（LayoutLMv3 模型）

从配置实例化库中的一个模型类（带有文档问答头）。

注意：从配置文件加载模型时**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
>>> model = TFAutoModelForDocumentQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：

    +   一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。

    +   *PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型的`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以自动加载：

    +   该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。

    +   模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*） — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*） — 要使用的代理服务器字典，按协议或端点，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`) — 在Hub上使用的特定代码修订版，如果代码与模型的其余部分存储在不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：

    +   如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的模型类之一（带有文档问答头）。

根据配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），选择要实例化的模型类，或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `layoutlm` — [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)（LayoutLM模型）

+   `layoutlmv3` — [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)（LayoutLMv3模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

>>> # Update configuration during loading
>>> model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
>>> model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
...     "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
... )
```

### AutoModelForVisualQuestionAnswering

### `class transformers.AutoModelForVisualQuestionAnswering`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1378)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的模型类之一（带有视觉问答头）。

这个类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 根据配置类选择要实例化的模型类：

    +   [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config) 配置类：[Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）

    +   [ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig) 配置类：[ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)（ViLT模型）

从配置实例化库中的模型类之一（带有视觉问答头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
>>> model = AutoModelForVisualQuestionAnswering.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：

    +   一个字符串，位于huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。

    +   路径或 URL 到 *tensorflow 索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并随后加载 PyTorch 模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况自动加载配置时：

    +   该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。

    +   该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 不是更简单的选项。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *可选*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为 `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为不同：

    +   如果提供了`config`配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个键对应一个配置属性，将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的模型类之一（带有视觉问答头）。

选择要实例化的模型类基于配置对象的`model_type`属性（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `blip-2` — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）

+   `vilt` — [ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)（ViLT模型）

默认情况下，模型设置为评估模式，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。

示例：

```py
>>> from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

>>> # Update configuration during loading
>>> model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
>>> model = AutoModelForVisualQuestionAnswering.from_pretrained(
...     "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### AutoModelForVision2Seq

### `class transformers.AutoModelForVision2Seq`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1503)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class方法from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class方法from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库中的模型类之一（带有视觉到文本建模头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)配置类：[Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）

    +   [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)配置类：[BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)（BLIP模型）

    +   [GitConfig](/docs/transformers/v4.37.2/zh/model_doc/git#transformers.GitConfig) 配置类: [GitForCausalLM](/docs/transformers/v4.37.2/zh/model_doc/git#transformers.GitForCausalLM) (GIT 模型)

    +   [InstructBlipConfig](/docs/transformers/v4.37.2/zh/model_doc/instructblip#transformers.InstructBlipConfig) 配置类: [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration) (InstructBLIP 模型)

    +   [Kosmos2Config](/docs/transformers/v4.37.2/zh/model_doc/kosmos-2#transformers.Kosmos2Config) 配置类: [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration) (KOSMOS-2 模型)

    +   [LlavaConfig](/docs/transformers/v4.37.2/zh/model_doc/llava#transformers.LlavaConfig) 配置类: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/llava#transformers.LlavaForConditionalGeneration) (LLaVa 模型)

    +   [Pix2StructConfig](/docs/transformers/v4.37.2/zh/model_doc/pix2struct#transformers.Pix2StructConfig) 配置类: [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration) (Pix2Struct 模型)

    +   [VipLlavaConfig](/docs/transformers/v4.37.2/zh/model_doc/vipllava#transformers.VipLlavaConfig) 配置类: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration) (VipLlava 模型)

    +   [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig) 配置类: [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel) (Vision 编码器解码器模型)

从配置实例化库中的一个模型类（带有从视觉到文本的建模头）。

注意: 从配置文件加载模型 **不会** 加载模型权重。 它只影响模型的配置。 使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) 来加载模型权重。

示例:

```py
>>> from transformers import AutoConfig, AutoModelForVision2Seq

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = AutoModelForVision2Seq.from_config(config)
```

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一:

    +   一个字符串，托管在 huggingface.co 模型存储库中的预训练模型的 *模型 id*。 有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如 `dbmdz/bert-base-german-cased`。

    +   指向使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。

    +   一个 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。 在这种情况下，`from_tf` 应设置为 `True`，并且应将配置对象提供为 `config` 参数。 使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并随后加载 PyTorch 模型更慢。

+   `model_args` (额外的位置参数, *可选*) — 将传递给底层模型的 `__init__()` 方法。

+   `config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig), *可选*) — 模型使用的配置，而不是自动加载的配置。 当以下情况发生时，配置可以自动加载:

    +   该模型是库中提供的模型（使用预训练模型的 *模型 id* 字符串加载）。

    +   模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON 文件来加载模型。

+   `state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。

    如果您想从预训练配置创建模型，但加载自己的权重，可以使用此选项。在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) 和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) 不是一个更简单的选项。

+   `cache_dir` (`str` or `os.PathLike`, *optional*) — 下载预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的自己的建模文件。此选项应仅设置为 `True`，用于您信任的存储库，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。

+   `code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交 ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

+   `kwargs`（其他关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了 `config`，行为会有所不同：

    +   如果提供了 `config`，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，`kwargs`将首先传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个对应于配置属性的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库的模型类之一（带有视觉到文本建模头）。

实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `blip` — [BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)（BLIP模型）

+   `blip-2` — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）

+   `git` — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)（GIT模型）

+   `instructblip` — [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)（InstructBLIP模型）

+   `kosmos-2` — [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)（KOSMOS-2模型）

+   `llava` — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)（LLaVa模型）

+   `pix2struct` — [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)（Pix2Struct模型）

+   `vipllava` — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)（VipLlava模型）

+   `vision-encoder-decoder` — [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)（Vision编码器解码器模型）

默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式

示例：

```py
>>> from transformers import AutoConfig, AutoModelForVision2Seq

>>> # Download model and configuration from huggingface.co and cache.
>>> model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
>>> config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
>>> model = AutoModelForVision2Seq.from_pretrained(
...     "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
... )
```

### TFAutoModelForVision2Seq

### `class transformers.TFAutoModelForVision2Seq`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L605)

```py
( *args **kwargs )
```

这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有视觉到文本建模头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)） — 选择要实例化的模型类基于配置类：

    +   [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)配置类：[TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)（BLIP模型）

    +   [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig) 配置类：[TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)（视觉编码器解码器模型）

实例化库中的模型类之一（带有视觉到文本建模头部）从配置中。

注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForVision2Seq

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = TFAutoModelForVision2Seq.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：

    +   一个字符串，托管在huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）— 模型使用的配置，而不是自动加载的配置。当：

    +   该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置JSON文件来加载模型。

+   `cache_dir`（`str`或`os.PathLike`，*可选*）— 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：

    +   如果提供了带有`config`的配置，则`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设所有相关的配置更新已经完成）。

    +   如果未提供配置，则首先将`kwargs`传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有视觉到文本建模头）。

选择要实例化的模型类基于配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载（如果可能）），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：

+   `blip` — [TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)（BLIP模型）

+   `vision-encoder-decoder` — [TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)（视觉编码器解码器模型）

示例：

```py
>>> from transformers import AutoConfig, TFAutoModelForVision2Seq

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = TFAutoModelForVision2Seq.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```

### FlaxAutoModelForVision2Seq

### `class transformers.FlaxAutoModelForVision2Seq`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L363)

```py
( *args **kwargs )
```

这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有视觉到文本建模头）。

此类不能直接使用`__init__()`实例化（会抛出错误）。

#### `from_config`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)

```py
( **kwargs )
```

参数

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）— 选择要实例化的模型类基于配置类：

    +   [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig) 配置类：[FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)（视觉编码器解码器模型）

从配置实例化库中的一个模型类（带有视觉到文本建模头）。

注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForVision2Seq

>>> # Download configuration from huggingface.co and cache.
>>> config = AutoConfig.from_pretrained("bert-base-cased")
>>> model = FlaxAutoModelForVision2Seq.from_config(config)
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)

```py
( *model_args **kwargs )
```

参数

+   `pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：

    +   一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。

    +   一个*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。使用此加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。

+   `model_args`（额外的位置参数，*可选*） — 将传递给底层模型`__init__()`方法。

+   `config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)，*可选*） — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：

    +   该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。

    +   模型使用[save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存，并通过提供保存目录重新加载。

    +   通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。

+   `cache_dir`（`str`或`os.PathLike`，*可选*） — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。

+   `from_pt`（`bool`，*可选*，默认为`False`） — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。

+   `force_download`（`bool`，*可选*，默认为`False`） — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`） — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。

+   `proxies`（`Dict[str, str]`，*可选*） — 要按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only(bool,` *可选*，默认为`False`） — 是否仅查看本地文件（例如，不尝试下载模型）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任并且已阅读代码的存储库设置为`True`，因为它将在本地机器上执行Hub上存在的代码。

+   `code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上代码的特定修订版本，如果代码与模型的其余部分存储在不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

+   `kwargs`（附加关键字参数，*可选*）— 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，其行为会有所不同：

    +   如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）

    +   如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。

从预训练模型实例化库中的一个模型类（带有视觉到文本建模头）。

要实例化的模型类是根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载）选择的，或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退选择。

+   `vision-encoder-decoder` — [FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)（视觉编码器解码器模型）

示例：

```py
>>> from transformers import AutoConfig, FlaxAutoModelForVision2Seq

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

>>> # Update configuration during loading
>>> model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
>>> model.config.output_attentions
True

>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
>>> config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
>>> model = FlaxAutoModelForVision2Seq.from_pretrained(
...     "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
... )
```
