# å¸¦æœ‰ Stable Diffusion XL çš„ ControlNet

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/diffusers/api/pipelines/controlnet_sdxl`](https://huggingface.co/docs/diffusers/api/pipelines/controlnet_sdxl)

ControlNet åœ¨ [å‘æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ·»åŠ æ¡ä»¶æ§åˆ¶](https://huggingface.co/papers/2302.05543) ä¸­ç”± Lvmin Zhangã€Anyi Rao å’Œ Maneesh Agrawala æå‡ºã€‚

ä½¿ç”¨ ControlNet æ¨¡å‹ï¼Œæ‚¨å¯ä»¥æä¾›é¢å¤–çš„æ§åˆ¶å›¾åƒæ¥è°ƒèŠ‚å’Œæ§åˆ¶ Stable Diffusion ç”Ÿæˆã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æä¾›æ·±åº¦å›¾ï¼ŒControlNet æ¨¡å‹å°†ç”Ÿæˆä¸€ä¸ªä¿ç•™æ·±åº¦å›¾ä¸­ç©ºé—´ä¿¡æ¯çš„å›¾åƒã€‚è¿™æ˜¯ä¸€ç§æ›´çµæ´»å’Œå‡†ç¡®çš„æ§åˆ¶å›¾åƒç”Ÿæˆè¿‡ç¨‹çš„æ–¹å¼ã€‚

è¯¥è®ºæ–‡çš„æ‘˜è¦ä¸ºï¼š

*æˆ‘ä»¬æå‡ºäº† ControlNetï¼Œè¿™æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç”¨äºå‘å¤§å‹ã€é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ·»åŠ ç©ºé—´è°ƒèŠ‚æ§åˆ¶ã€‚ControlNet é”å®šäº†ç”Ÿäº§å°±ç»ªçš„å¤§å‹æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡å¤ä½¿ç”¨å®ƒä»¬çš„æ·±åº¦å’Œç¨³å¥çš„ç¼–ç å±‚ï¼Œè¿™äº›ç¼–ç å±‚ç»è¿‡æ•°åäº¿å¼ å›¾åƒçš„é¢„è®­ç»ƒï¼Œä½œä¸ºå­¦ä¹ å„ç§æ¡ä»¶æ§åˆ¶çš„å¼ºå¤§æ”¯æ’‘ã€‚ç¥ç»æ¶æ„è¿æ¥äº†â€œé›¶å·ç§¯â€ï¼ˆä»é›¶åˆå§‹åŒ–çš„å·ç§¯å±‚ï¼‰ï¼Œé€æ¸å¢åŠ å‚æ•°ï¼Œç¡®ä¿æ²¡æœ‰æœ‰å®³å™ªéŸ³ä¼šå½±å“å¾®è°ƒã€‚æˆ‘ä»¬æµ‹è¯•äº†å„ç§è°ƒèŠ‚æ§åˆ¶ï¼Œä¾‹å¦‚è¾¹ç¼˜ã€æ·±åº¦ã€åˆ†å‰²ã€äººä½“å§¿åŠ¿ç­‰ï¼Œä½¿ç”¨å•ä¸ªæˆ–å¤šä¸ªæ¡ä»¶ï¼Œæœ‰æˆ–æ²¡æœ‰æç¤ºï¼Œä¸ Stable Diffusion ç»“åˆã€‚æˆ‘ä»¬å±•ç¤ºäº† ControlNet çš„è®­ç»ƒå¯¹äºå°å‹ï¼ˆ<50kï¼‰å’Œå¤§å‹ï¼ˆ>1mï¼‰æ•°æ®é›†æ˜¯ç¨³å¥çš„ã€‚å¹¿æ³›çš„ç»“æœè¡¨æ˜ï¼ŒControlNet å¯èƒ½ä¿ƒè¿›æ›´å¹¿æ³›çš„åº”ç”¨ï¼Œä»¥æ§åˆ¶å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚*

æ‚¨å¯ä»¥åœ¨ğŸ¤— [Diffusers](https://huggingface.co/diffusers) Hub ç»„ç»‡ä¸­æ‰¾åˆ°é¢å¤–çš„è¾ƒå°çš„ Stable Diffusion XLï¼ˆSDXLï¼‰ControlNet æ£€æŸ¥ç‚¹ï¼Œå¹¶åœ¨ Hub ä¸Šæµè§ˆ[ç¤¾åŒºè®­ç»ƒçš„](https://huggingface.co/models?other=stable-diffusion-xl&other=controlnet)æ£€æŸ¥ç‚¹ã€‚

ğŸ§ª è®¸å¤š SDXL ControlNet æ£€æŸ¥ç‚¹æ˜¯å®éªŒæ€§çš„ï¼Œæœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚æ¬¢è¿æ‰“å¼€ä¸€ä¸ª[Issue](https://github.com/huggingface/diffusers/issues/new/choose)ï¼Œå‘Šè¯‰æˆ‘ä»¬å¦‚ä½•æ”¹è¿›ï¼

å¦‚æœæ‚¨æ²¡æœ‰çœ‹åˆ°æ‚¨æ„Ÿå…´è¶£çš„æ£€æŸ¥ç‚¹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„è®­ç»ƒè„šæœ¬è®­ç»ƒè‡ªå·±çš„ SDXL ControlNetã€‚

ç¡®ä¿æŸ¥çœ‹è°ƒåº¦å™¨æŒ‡å—ä»¥äº†è§£å¦‚ä½•æ¢ç´¢è°ƒåº¦å™¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶æŸ¥çœ‹è·¨ç®¡é“é‡ç”¨ç»„ä»¶éƒ¨åˆ†ï¼Œä»¥äº†è§£å¦‚ä½•æœ‰æ•ˆåœ°å°†ç›¸åŒç»„ä»¶åŠ è½½åˆ°å¤šä¸ªç®¡é“ä¸­ã€‚

## StableDiffusionXLControlNetPipeline

`diffusers.StableDiffusionXLControlNetPipeline` ç±»

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L117)

```py
( vae: AutoencoderKL text_encoder: CLIPTextModel text_encoder_2: CLIPTextModelWithProjection tokenizer: CLIPTokenizer tokenizer_2: CLIPTokenizer unet: UNet2DConditionModel controlnet: Union scheduler: KarrasDiffusionSchedulers force_zeros_for_empty_prompt: bool = True add_watermarker: Optional = None feature_extractor: CLIPImageProcessor = None image_encoder: CLIPVisionModelWithProjection = None )
```

å‚æ•°

+   `vae` (AutoencoderKL) â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºå½¢å¼ã€‚

+   `text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)) â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚

+   `text_encoder_2` ([CLIPTextModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelWithProjection)) â€” ç¬¬äºŒä¸ªå†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)ï¼‰ã€‚

+   `tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)) â€” ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„ `CLIPTokenizer`ã€‚

+   `tokenizer_2` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)) â€” ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„ `CLIPTokenizer`ã€‚

+   `unet` (UNet2DConditionModel) â€” ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œå˜é‡çš„ `UNet2DConditionModel`ã€‚

+   `controlnet` (ControlNetModel æˆ– `List[ControlNetModel]`) â€” åœ¨å»å™ªè¿‡ç¨‹ä¸­ä¸º `unet` æä¾›é¢å¤–çš„æ¡ä»¶ã€‚å¦‚æœå°†å¤šä¸ª ControlNet è®¾ç½®ä¸ºåˆ—è¡¨ï¼Œåˆ™æ¯ä¸ª ControlNet çš„è¾“å‡ºå°†ç›¸åŠ ï¼Œä»¥åˆ›å»ºä¸€ä¸ªç»„åˆçš„é¢å¤–æ¡ä»¶ã€‚

+   `scheduler` (SchedulerMixin) â€” ç”¨äºä¸ `unet` ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œå˜é‡çš„è°ƒåº¦ç¨‹åºã€‚å¯ä»¥æ˜¯ DDIMSchedulerã€LMSDiscreteScheduler æˆ– PNDMScheduler ä¸­çš„ä¸€ä¸ªã€‚

+   `force_zeros_for_empty_prompt` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `"True"`) â€” æ˜¯å¦å§‹ç»ˆå°†è´Ÿæç¤ºåµŒå…¥è®¾ç½®ä¸º 0ã€‚ä¹Ÿè¯·å‚é˜… `stabilityai/stable-diffusion-xl-base-1-0` çš„é…ç½®ã€‚

+   `add_watermarker` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨ [invisible_watermark](https://github.com/ShieldMnt/invisible-watermark/) åº“å¯¹è¾“å‡ºå›¾åƒè¿›è¡Œæ°´å°å¤„ç†ã€‚å¦‚æœæœªå®šä¹‰ï¼Œä¸”å®‰è£…äº†è¯¥è½¯ä»¶åŒ…ï¼Œåˆ™é»˜è®¤ä¸º `True`ï¼›å¦åˆ™ä¸ä½¿ç”¨æ°´å°å¤„ç†ã€‚

ä½¿ç”¨ Stable Diffusion XL å’Œ ControlNet æŒ‡å¯¼çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæµæ°´çº¿ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª DiffusionPipelineã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚

è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•:

+   load_textual_inversion() ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥

+   load_lora_weights() ç”¨äºåŠ è½½ LoRA æƒé‡

+   `save_lora_weights()` ç”¨äºä¿å­˜ LoRA æƒé‡

+   from_single_file() ç”¨äºåŠ è½½ `.ckpt` æ–‡ä»¶

+   load_ip_adapter() ç”¨äºåŠ è½½ IP é€‚é…å™¨

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L943)

```py
( prompt: Union = None prompt_2: Union = None image: Union = None height: Optional = None width: Optional = None num_inference_steps: int = 50 guidance_scale: float = 5.0 negative_prompt: Union = None negative_prompt_2: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None ip_adapter_image: Union = None output_type: Optional = 'pil' return_dict: bool = True cross_attention_kwargs: Optional = None controlnet_conditioning_scale: Union = 1.0 guess_mode: bool = False control_guidance_start: Union = 0.0 control_guidance_end: Union = 1.0 original_size: Tuple = None crops_coords_top_left: Tuple = (0, 0) target_size: Tuple = None negative_original_size: Optional = None negative_crops_coords_top_left: Tuple = (0, 0) negative_target_size: Optional = None clip_skip: Optional = None callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] **kwargs ) â†’ export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple
```

å‚æ•°

+   `prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’ `prompt_embeds`ã€‚

+   `prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” å‘é€åˆ° `tokenizer_2` å’Œ `text_encoder_2` çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨ `prompt`ã€‚

+   `image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`, `List[PIL.Image.Image]`, `List[np.ndarray]`, â€” `List[List[torch.FloatTensor]]`, `List[List[np.ndarray]]` æˆ– `List[List[PIL.Image.Image]]`): ç”¨äºä¸º`unet`æä¾›æŒ‡å¯¼çš„ ControlNet è¾“å…¥æ¡ä»¶ã€‚å¦‚æœæŒ‡å®šç±»å‹ä¸º`torch.FloatTensor`ï¼Œåˆ™æŒ‰åŸæ ·ä¼ é€’ç»™ ControlNetã€‚`PIL.Image.Image`ä¹Ÿå¯ä»¥ä½œä¸ºå›¾åƒæ¥å—ã€‚è¾“å‡ºå›¾åƒçš„å°ºå¯¸é»˜è®¤ä¸º`image`çš„å°ºå¯¸ã€‚å¦‚æœä¼ é€’äº†é«˜åº¦å’Œ/æˆ–å®½åº¦ï¼Œ`image`å°†ç›¸åº”è°ƒæ•´å¤§å°ã€‚å¦‚æœåœ¨`init`ä¸­æŒ‡å®šäº†å¤šä¸ª ControlNetsï¼Œåˆ™å¿…é¡»å°†å›¾åƒä½œä¸ºåˆ—è¡¨ä¼ é€’ï¼Œä»¥ä¾¿åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ å¯ä»¥æ­£ç¡®æ‰¹å¤„ç†ä¸ºå•ä¸ª ControlNet çš„è¾“å…¥ã€‚

+   `height` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`self.unet.config.sample_size * self.vae_scale_factor`) â€” ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚ä½äº 512 åƒç´ çš„ä»»ä½•å†…å®¹éƒ½ä¸é€‚ç”¨äº[stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)å’Œæœªç»ä¸“é—¨è°ƒæ•´ä»¥é€‚åº”ä½åˆ†è¾¨ç‡çš„æ£€æŸ¥ç‚¹ã€‚

+   `width` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`self.unet.config.sample_size * self.vae_scale_factor`) â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚ä½äº 512 åƒç´ çš„ä»»ä½•å†…å®¹éƒ½ä¸é€‚ç”¨äº[stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)å’Œæœªç»ä¸“é—¨è°ƒæ•´ä»¥é€‚åº”ä½åˆ†è¾¨ç‡çš„æ£€æŸ¥ç‚¹ã€‚

+   `num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 50) â€” é™å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„é™å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚

+   `guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 5.0) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“`guidance_scale > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚

+   `negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨å¼•å¯¼æ—¶ï¼ˆ`guidance_scale < 1`ï¼‰å°†è¢«å¿½ç•¥ã€‚

+   `negative_prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚è¿™å°†å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­éƒ½ä½¿ç”¨`negative_prompt`ã€‚

+   `num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚

+   `eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” å¯¹åº”äº[DDIM](https://arxiv.org/abs/2010.02502)è®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ã€‚ä»…é€‚ç”¨äº DDIMSchedulerï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚

+   `generator` (`torch.Generator` æˆ– `List[torch.Generator]`, *å¯é€‰*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚

+   `latents` (`torch.FloatTensor`, *å¯é€‰*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é¢„å…ˆç”Ÿæˆçš„å™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºå¾®è°ƒç›¸åŒçš„ç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é€šè¿‡ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚

+   `prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„å…ˆç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚

+   `negative_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„å…ˆç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆ`negative_prompt_embeds`ã€‚

+   `pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œæ± åŒ–æ–‡æœ¬åµŒå…¥å°†ä» `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚

+   `negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿé¢æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œè´Ÿé¢æ± åŒ–æ–‡æœ¬åµŒå…¥å°†ä» `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚ip_adapter_image â€” (`PipelineImageInput`, *optional*): å¯é€‰çš„å›¾åƒè¾“å…¥ï¼Œç”¨äºä¸ IP é€‚é…å™¨ä¸€èµ·ä½¿ç”¨ã€‚

+   `output_type` (`str`, *optional*, é»˜è®¤ä¸º `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹© `PIL.Image` æˆ– `np.array` ä¹‹é—´ã€‚

+   `return_dict` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å› StableDiffusionPipelineOutput è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `cross_attention_kwargs` (`dict`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™ `AttentionProcessor` çš„ kwargs å­—å…¸ï¼Œå¦‚ [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py) ä¸­å®šä¹‰ã€‚

+   `controlnet_conditioning_scale` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º 1.0) â€” åœ¨å°† ControlNet çš„è¾“å‡ºæ·»åŠ åˆ°åŸå§‹ `unet` ä¸­çš„æ®‹å·®ä¹‹å‰ï¼Œå°†å…¶ä¹˜ä»¥ `controlnet_conditioning_scale`ã€‚å¦‚æœåœ¨ `init` ä¸­æŒ‡å®šäº†å¤šä¸ª ControlNetsï¼Œå¯ä»¥å°†ç›¸åº”çš„æ¯”ä¾‹è®¾ç½®ä¸ºåˆ—è¡¨ã€‚

+   `guess_mode` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ§åˆ¶ç½‘ç»œç¼–ç å™¨å°è¯•è¯†åˆ«è¾“å…¥å›¾åƒçš„å†…å®¹ï¼Œå³ä½¿æ‚¨åˆ é™¤äº†æ‰€æœ‰æç¤ºã€‚å»ºè®®è®¾ç½® `guidance_scale` å€¼åœ¨ 3.0 åˆ° 5.0 ä¹‹é—´ã€‚

+   `control_guidance_start` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º 0.0) â€” æ§åˆ¶ç½‘ç»œå¼€å§‹åº”ç”¨çš„æ€»æ­¥éª¤ç™¾åˆ†æ¯”ã€‚

+   `control_guidance_end` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º 1.0) â€” æ§åˆ¶ç½‘ç»œåœæ­¢åº”ç”¨çš„æ€»æ­¥éª¤ç™¾åˆ†æ¯”ã€‚

+   `original_size` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (1024, 1024)) â€” å¦‚æœ `original_size` ä¸ `target_size` ä¸åŒï¼Œå›¾åƒå°†å‘ˆç°ä¸ºç¼©å°æˆ–æ”¾å¤§ã€‚å¦‚æœæœªæŒ‡å®šï¼Œ`original_size` é»˜è®¤ä¸º `(height, width)`ã€‚ä½œä¸º SDXL çš„å¾®è°ƒæ¡ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [`huggingface.co/papers/2307.01952`](https://huggingface.co/papers/2307.01952) ç¬¬ 2.2 èŠ‚ã€‚

+   `crops_coords_top_left` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (0, 0)) â€” `crops_coords_top_left` å¯ç”¨äºç”Ÿæˆä¸€ä¸ªçœ‹èµ·æ¥ä»ä½ç½® `crops_coords_top_left` å‘ä¸‹â€œè£å‰ªâ€çš„å›¾åƒã€‚é€šå¸¸é€šè¿‡å°† `crops_coords_top_left` è®¾ç½®ä¸º (0, 0) æ¥å®ç°æœ‰åˆ©çš„ã€å±…ä¸­çš„å›¾åƒã€‚ä½œä¸º SDXL çš„å¾®è°ƒæ¡ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [`huggingface.co/papers/2307.01952`](https://huggingface.co/papers/2307.01952) ç¬¬ 2.2 èŠ‚ã€‚

+   `target_size` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (1024, 1024)) â€” å¯¹äºå¤§å¤šæ•°æƒ…å†µï¼Œ`target_size` åº”è®¾ç½®ä¸ºç”Ÿæˆå›¾åƒçš„æœŸæœ›é«˜åº¦å’Œå®½åº¦ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º `(height, width)`ã€‚ä½œä¸º SDXL çš„å¾®è°ƒæ¡ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [`huggingface.co/papers/2307.01952`](https://huggingface.co/papers/2307.01952) ç¬¬ 2.2 èŠ‚ã€‚

+   `negative_original_size` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (1024, 1024)) â€” åŸºäºç‰¹å®šå›¾åƒåˆ†è¾¨ç‡å¦å®šåœ°è°ƒæ•´ç”Ÿæˆè¿‡ç¨‹ã€‚ä½œä¸º SDXL çš„å¾®è°ƒæ¡ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [`huggingface.co/papers/2307.01952`](https://huggingface.co/papers/2307.01952) ç¬¬ 2.2 èŠ‚ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒæ­¤é—®é¢˜çº¿ç¨‹ï¼š[`github.com/huggingface/diffusers/issues/4208`](https://github.com/huggingface/diffusers/issues/4208)ã€‚

+   `negative_crops_coords_top_left`ï¼ˆ`Tuple[int]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º(0, 0)ï¼‰â€”æ ¹æ®ç‰¹å®šè£å‰ªåæ ‡å¯¹ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œè´Ÿæ¡ä»¶åŒ–ã€‚ä½œä¸º SDXL çš„å¾®æ¡ä»¶åŒ–çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚[`huggingface.co/papers/2307.01952`](https://huggingface.co/papers/2307.01952)ç¬¬ 2.2 èŠ‚ä¸­æ‰€è¿°ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒæ­¤é—®é¢˜çº¿ç¨‹ï¼š[`github.com/huggingface/diffusers/issues/4208`](https://github.com/huggingface/diffusers/issues/4208)ã€‚

+   `negative_target_size`ï¼ˆ`Tuple[int]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º(1024, 1024)ï¼‰â€”æ ¹æ®ç›®æ ‡å›¾åƒåˆ†è¾¨ç‡å¯¹ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œè´Ÿæ¡ä»¶åŒ–ã€‚å¯¹äºå¤§å¤šæ•°æƒ…å†µï¼Œå®ƒåº”ä¸`target_size`ç›¸åŒã€‚ä½œä¸º SDXL çš„å¾®æ¡ä»¶åŒ–çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚[`huggingface.co/papers/2307.01952`](https://huggingface.co/papers/2307.01952)ç¬¬ 2.2 èŠ‚ä¸­æ‰€è¿°ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒæ­¤é—®é¢˜çº¿ç¨‹ï¼š[`github.com/huggingface/diffusers/issues/4208`](https://github.com/huggingface/diffusers/issues/4208)ã€‚

+   `clip_skip`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€”åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦è·³è¿‡çš„ CLIP å±‚æ•°ã€‚å€¼ä¸º 1 æ„å‘³ç€å°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚

+   `callback_on_step_end`ï¼ˆ`Callable`ï¼Œ*å¯é€‰*ï¼‰â€”åœ¨æ¨æ–­æœŸé—´æ¯ä¸ªå»å™ªæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`ã€‚`callback_kwargs`å°†åŒ…æ‹¬ç”±`callback_on_step_end_tensor_inputs`æŒ‡å®šçš„æ‰€æœ‰å¼ é‡çš„åˆ—è¡¨ã€‚

+   `callback_on_step_end_tensor_inputs`ï¼ˆ`List`ï¼Œ*å¯é€‰*ï¼‰â€”`callback_on_step_end`å‡½æ•°çš„å¼ é‡è¾“å…¥åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æŒ‡å®šçš„å¼ é‡å°†ä½œä¸º`callback_kwargs`å‚æ•°ä¼ é€’ã€‚æ‚¨åªèƒ½åŒ…å«åœ¨ç®¡é“ç±»çš„`._callback_tensor_inputs`å±æ€§ä¸­åˆ—å‡ºçš„å˜é‡ã€‚

è¿”å›

StableDiffusionPipelineOutput æˆ–`tuple`

å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å› StableDiffusionPipelineOutputï¼Œå¦åˆ™è¿”å›ä¸€ä¸ªåŒ…å«è¾“å‡ºå›¾åƒçš„`tuple`ã€‚

ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> # !pip install opencv-python transformers accelerate
>>> from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL
>>> from diffusers.utils import load_image
>>> import numpy as np
>>> import torch

>>> import cv2
>>> from PIL import Image

>>> prompt = "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting"
>>> negative_prompt = "low quality, bad quality, sketches"

>>> # download an image
>>> image = load_image(
...     "https://hf.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png"
... )

>>> # initialize the models and pipeline
>>> controlnet_conditioning_scale = 0.5  # recommended for good generalization
>>> controlnet = ControlNetModel.from_pretrained(
...     "diffusers/controlnet-canny-sdxl-1.0", torch_dtype=torch.float16
... )
>>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
>>> pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
...     "stabilityai/stable-diffusion-xl-base-1.0", controlnet=controlnet, vae=vae, torch_dtype=torch.float16
... )
>>> pipe.enable_model_cpu_offload()

>>> # get canny image
>>> image = np.array(image)
>>> image = cv2.Canny(image, 100, 200)
>>> image = image[:, :, None]
>>> image = np.concatenate([image, image, image], axis=2)
>>> canny_image = Image.fromarray(image)

>>> # generate image
>>> image = pipe(
...     prompt, controlnet_conditioning_scale=controlnet_conditioning_scale, image=canny_image
... ).images[0]
```

#### `disable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L887)

```py
( )
```

å¦‚æœå¯ç”¨ï¼Œç¦ç”¨ FreeU æœºåˆ¶ã€‚

#### `disable_vae_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L234)

```py
( )
```

ç¦ç”¨åˆ‡ç‰‡ VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_slicing`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

#### `disable_vae_tiling`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L251)

```py
( )
```

ç¦ç”¨å¹³é“º VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_tiling`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

#### `enable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L864)

```py
( s1: float s2: float b1: float b2: float )
```

å‚æ•°

+   `s1`ï¼ˆ`float`ï¼‰â€”ç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾è´¡çŒ®çš„ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚

+   `s2`ï¼ˆ`float`ï¼‰â€”ç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾è´¡çŒ®çš„ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚

+   `b1`ï¼ˆ`float`ï¼‰â€”ç”¨äºæ”¾å¤§ç¬¬ 1 é˜¶æ®µçš„éª¨å¹²ç‰¹å¾è´¡çŒ®çš„ç¼©æ”¾å› å­ã€‚

+   `b2`ï¼ˆ`float`ï¼‰â€”ç”¨äºæ”¾å¤§ç¬¬ 2 é˜¶æ®µçš„éª¨å¹²ç‰¹å¾è´¡çŒ®çš„ç¼©æ”¾å› å­ã€‚

å¯ç”¨ FreeU æœºåˆ¶ï¼Œå¦‚[`arxiv.org/abs/2309.11497`](https://arxiv.org/abs/2309.11497)ã€‚

ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºåº”ç”¨å®ƒä»¬çš„é˜¶æ®µã€‚

è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion v1ã€v2 å’Œ Stable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚

#### `enable_vae_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L226)

```py
( )
```

å¯ç”¨åˆ‡ç‰‡ VAE è§£ç ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†åœ¨å‡ ä¸ªæ­¥éª¤ä¸­å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆåˆ‡ç‰‡ä»¥è¿›è¡Œè§£ç ã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜å¹¶å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°éå¸¸æœ‰ç”¨ã€‚

#### `enable_vae_tiling`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L242)

```py
( )
```

å¯ç”¨å¹³é“º VAE è§£ç ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†å°†è¾“å…¥å¼ é‡åˆ†æˆç“¦ç‰‡ä»¥åœ¨å‡ ä¸ªæ­¥éª¤ä¸­è¿›è¡Œè§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚

#### `encode_prompt`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L259)

```py
( prompt: str prompt_2: Optional = None device: Optional = None num_images_per_prompt: int = 1 do_classifier_free_guidance: bool = True negative_prompt: Optional = None negative_prompt_2: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None lora_scale: Optional = None clip_skip: Optional = None )
```

å‚æ•°

+   `prompt` (`str` or `List[str]`, *optional*) â€” è¦ç¼–ç çš„æç¤º

+   `prompt_2` (`str` or `List[str]`, *optional*) â€” è¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨è®¾å¤‡ä¸­ä½¿ç”¨`prompt` â€” (`torch.device`): torch è®¾å¤‡

+   `num_images_per_prompt` (`int`) â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡

+   `do_classifier_free_guidance` (`bool`) â€” æ˜¯å¦ä½¿ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼

+   `negative_prompt` (`str` or `List[str]`, *optional*) â€” ä¸ç”¨æ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶è¢«å¿½ç•¥ï¼ˆå³å¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™è¢«å¿½ç•¥ï¼‰ã€‚

+   `negative_prompt_2` (`str` or `List[str]`, *optional*) â€” ä¸ç”¨æ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºï¼Œè¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`negative_prompt`

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆè´Ÿ negative_prompt_embedsã€‚

+   `pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„æ–‡æœ¬åµŒå…¥ã€‚

+   `negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„ negative_prompt_embedsã€‚

+   `lora_scale` (`float`, *optional*) â€” å¦‚æœåŠ è½½äº† LoRA å±‚ï¼Œåˆ™å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰ LoRA å±‚çš„ lora æ¯”ä¾‹ã€‚

+   `clip_skip` (`int`, *optional*) â€” è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦ä» CLIP ä¸­è·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º 1 è¡¨ç¤ºå°†ä½¿ç”¨é¢„ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚

å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
