- en: Text-to-image
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ°å›¾åƒ
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The Stable Diffusion model was created by researchers and engineers from [CompVis](https://github.com/CompVis),
    [Stability AI](https://stability.ai/), [Runway](https://github.com/runwayml),
    and [LAION](https://laion.ai/). The [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    is capable of generating photorealistic images given any text input. Itâ€™s trained
    on 512x512 images from a subset of the LAION-5B dataset. This model uses a frozen
    CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M
    UNet and 123M text encoder, the model is relatively lightweight and can run on
    consumer GPUs. Latent diffusion is the research on top of which Stable Diffusion
    was built. It was proposed in [High-Resolution Image Synthesis with Latent Diffusion
    Models](https://huggingface.co/papers/2112.10752) by Robin Rombach, Andreas Blattmann,
    Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£æ¨¡å‹æ˜¯ç”±[CompVis](https://github.com/CompVis)ã€[Stability AI](https://stability.ai/)ã€[Runway](https://github.com/runwayml)å’Œ[LAION](https://laion.ai/)çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåˆ›å»ºçš„ã€‚[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)èƒ½å¤Ÿæ ¹æ®ä»»ä½•æ–‡æœ¬è¾“å…¥ç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚å®ƒæ˜¯åœ¨LAION-5Bæ•°æ®é›†çš„512x512å›¾åƒä¸Šè®­ç»ƒçš„ã€‚è¯¥æ¨¡å‹ä½¿ç”¨å†»ç»“çš„CLIP
    ViT-L/14æ–‡æœ¬ç¼–ç å™¨æ¥æ ¹æ®æ–‡æœ¬æç¤ºå¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ã€‚è¯¥æ¨¡å‹å…·æœ‰860M UNetå’Œ123Mæ–‡æœ¬ç¼–ç å™¨ï¼Œç›¸å¯¹è½»é‡çº§ï¼Œå¯ä»¥åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œã€‚æ½œåœ¨æ‰©æ•£æ˜¯ç¨³å®šæ‰©æ•£æ„å»ºåœ¨å…¶ä¹‹ä¸Šçš„ç ”ç©¶ã€‚å®ƒæ˜¯ç”±Robin
    Rombachã€Andreas Blattmannã€Dominik Lorenzã€Patrick Esserã€BjÃ¶rn Ommeråœ¨[High-Resolution
    Image Synthesis with Latent Diffusion Models](https://huggingface.co/papers/2112.10752)ä¸­æå‡ºçš„ã€‚
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦ï¼š
- en: '*By decomposing the image formation process into a sequential application of
    denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis
    results on image data and beyond. Additionally, their formulation allows for a
    guiding mechanism to control the image generation process without retraining.
    However, since these models typically operate directly in pixel space, optimization
    of powerful DMs often consumes hundreds of GPU days and inference is expensive
    due to sequential evaluations. To enable DM training on limited computational
    resources while retaining their quality and flexibility, we apply them in the
    latent space of powerful pretrained autoencoders. In contrast to previous work,
    training diffusion models on such a representation allows for the first time to
    reach a near-optimal point between complexity reduction and detail preservation,
    greatly boosting visual fidelity. By introducing cross-attention layers into the
    model architecture, we turn diffusion models into powerful and flexible generators
    for general conditioning inputs such as text or bounding boxes and high-resolution
    synthesis becomes possible in a convolutional manner. Our latent diffusion models
    (LDMs) achieve a new state of the art for image inpainting and highly competitive
    performance on various tasks, including unconditional image generation, semantic
    scene synthesis, and super-resolution, while significantly reducing computational
    requirements compared to pixel-based DMs. Code is available at [https://github.com/CompVis/latent-diffusion](https://github.com/CompVis/latent-diffusion).*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*é€šè¿‡å°†å›¾åƒå½¢æˆè¿‡ç¨‹åˆ†è§£ä¸ºé€æ­¥åº”ç”¨å»å™ªè‡ªåŠ¨ç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ï¼ŒDMsåœ¨å›¾åƒæ•°æ®åŠå…¶ä»–é¢†åŸŸå®ç°äº†æœ€å…ˆè¿›çš„åˆæˆç»“æœã€‚æ­¤å¤–ï¼Œå®ƒä»¬çš„å…¬å¼å…è®¸å¼•å¯¼æœºåˆ¶æ¥æ§åˆ¶å›¾åƒç”Ÿæˆè¿‡ç¨‹è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›æ¨¡å‹é€šå¸¸ç›´æ¥åœ¨åƒç´ ç©ºé—´ä¸­æ“ä½œï¼Œä¼˜åŒ–å¼ºå¤§çš„DMsé€šå¸¸æ¶ˆè€—æ•°ç™¾ä¸ªGPUå¤©ï¼Œç”±äºé¡ºåºè¯„ä¼°ï¼Œæ¨æ–­æˆæœ¬æ˜‚è´µã€‚ä¸ºäº†åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸Šè®­ç»ƒDMå¹¶ä¿æŒå…¶è´¨é‡å’Œçµæ´»æ€§ï¼Œæˆ‘ä»¬å°†å®ƒä»¬åº”ç”¨äºå¼ºå¤§é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ã€‚ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œåœ¨è¿™ç§è¡¨ç¤ºä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹é¦–æ¬¡å®ç°äº†åœ¨å¤æ‚æ€§å‡å°‘å’Œç»†èŠ‚ä¿ç•™ä¹‹é—´è¾¾åˆ°è¿‘ä¹æœ€ä¼˜ç‚¹ï¼Œæå¤§åœ°æå‡äº†è§†è§‰ä¿çœŸåº¦ã€‚é€šè¿‡åœ¨æ¨¡å‹æ¶æ„ä¸­å¼•å…¥äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œæˆ‘ä»¬å°†æ‰©æ•£æ¨¡å‹è½¬å˜ä¸ºå¼ºå¤§ä¸”çµæ´»çš„ç”Ÿæˆå™¨ï¼Œç”¨äºä¸€èˆ¬æ¡ä»¶è¾“å…¥ï¼Œå¦‚æ–‡æœ¬æˆ–è¾¹ç•Œæ¡†ï¼Œé«˜åˆ†è¾¨ç‡åˆæˆä»¥å·ç§¯æ–¹å¼å˜å¾—å¯èƒ½ã€‚æˆ‘ä»¬çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰åœ¨å›¾åƒä¿®è¡¥å’Œå„ç§ä»»åŠ¡ä¸Šå®ç°äº†æ–°çš„æŠ€æœ¯æ°´å¹³ï¼ŒåŒ…æ‹¬æ— æ¡ä»¶å›¾åƒç”Ÿæˆã€è¯­ä¹‰åœºæ™¯åˆæˆå’Œè¶…åˆ†è¾¨ç‡ï¼ŒåŒæ—¶ä¸åŸºäºåƒç´ çš„DMç›¸æ¯”æ˜¾è‘—é™ä½äº†è®¡ç®—è¦æ±‚ã€‚ä»£ç å¯åœ¨[https://github.com/CompVis/latent-diffusion](https://github.com/CompVis/latent-diffusion)ä¸Šæ‰¾åˆ°ã€‚*'
- en: Make sure to check out the Stable Diffusion [Tips](overview#tips) section to
    learn how to explore the tradeoff between scheduler speed and quality, and how
    to reuse pipeline components efficiently!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿æŸ¥çœ‹ç¨³å®šæ‰©æ•£[Tips](overview#tips)éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•æ¢ç´¢è°ƒåº¦ç¨‹åºé€Ÿåº¦å’Œè´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œä»¥åŠå¦‚ä½•æœ‰æ•ˆåœ°é‡ç”¨ç®¡é“ç»„ä»¶ï¼
- en: If youâ€™re interested in using one of the official checkpoints for a task, explore
    the [CompVis](https://huggingface.co/CompVis), [Runway](https://huggingface.co/runwayml),
    and [Stability AI](https://huggingface.co/stabilityai) Hub organizations!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£ä½¿ç”¨å®˜æ–¹æ£€æŸ¥ç‚¹æ‰§è¡Œä»»åŠ¡ï¼Œè¯·æ¢ç´¢[CompVis](https://huggingface.co/CompVis)ã€[Runway](https://huggingface.co/runwayml)å’Œ[Stability
    AI](https://huggingface.co/stabilityai) Hub ç»„ç»‡ï¼
- en: StableDiffusionPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipeline
- en: '### `class diffusers.StableDiffusionPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L118)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L118)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºå½¢å¼ã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” A `CLIPTokenizer` to tokenize text.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” ä¸€ä¸ª`CLIPTokenizer`ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” ä¸€ä¸ª`UNet2DConditionModel`ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„è°ƒåº¦å™¨ã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a modelâ€™s potential harms.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” ç”¨äºä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è§†ä¸ºå…·æœ‰æ”»å‡»æ€§æˆ–æœ‰å®³çš„åˆ†ç±»æ¨¡å—ã€‚è¯·å‚è€ƒ[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” ä¸€ä¸ª`CLIPImageProcessor`ï¼Œç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾ï¼›ä½œä¸º`å®‰å…¨æ£€æŸ¥å™¨`çš„è¾“å…¥ã€‚'
- en: Pipeline for text-to-image generation using Stable Diffusion.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç¨³å®šæ‰©æ•£è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æµæ°´çº¿ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    ç”¨äºåŠ è½½LoRAæƒé‡'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    ç”¨äºä¿å­˜LoRAæƒé‡'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶çš„[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    ç”¨äºåŠ è½½IPé€‚é…å™¨'
- en: '#### `__call__`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L803)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L803)'
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`prompt_embeds`ã€‚'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” The height in pixels of the generated image.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`self.unet.config.sample_size * self.vae_scale_factor`)
    â€” ç”Ÿæˆå›¾åƒçš„é«˜åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” The width in pixels of the generated image.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`self.unet.config.sample_size * self.vae_scale_factor`)
    â€” ç”Ÿæˆå›¾åƒçš„å®½åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚'
- en: '`timesteps` (`List[int]`, *optional*) â€” Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *å¯é€‰*) â€” ç”¨äºä¸æ”¯æŒåœ¨å…¶`set_timesteps`æ–¹æ³•ä¸­ä½¿ç”¨`timesteps`å‚æ•°çš„è°ƒåº¦å™¨ä¸€èµ·ä½¿ç”¨çš„è‡ªå®šä¹‰æ—¶é—´æ­¥ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å°†ä½¿ç”¨ä¼ é€’`num_inference_steps`æ—¶çš„é»˜è®¤è¡Œä¸ºã€‚å¿…é¡»æŒ‰é™åºæ’åˆ—ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“`guidance_scale
    > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶ï¼ˆ`guidance_scale
    < 1`ï¼‰æ—¶å°†è¢«å¿½ç•¥ã€‚'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, defaults to 0.0) â€” å¯¹åº”äº[DDIM](https://arxiv.org/abs/2010.02502)è®ºæ–‡ä¸­çš„å‚æ•°etaï¼ˆÎ·ï¼‰ã€‚ä»…é€‚ç”¨äº[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” ç”¨äºä½¿ç”Ÿæˆå…·æœ‰ç¡®å®šæ€§çš„[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚'
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„é¢„ç”Ÿæˆå™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument. ip_adapter_image â€” (`PipelineImageInput`, *optional*): Optional
    image input to work with IP Adapters.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œ`negative_prompt_embeds`å°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚ip_adapter_image
    â€” (`PipelineImageInput`, *optional*): å¯é€‰çš„å›¾åƒè¾“å…¥ä»¥ä¸IPé€‚é…å™¨ä¸€èµ·ä½¿ç”¨ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹©`PIL.Image`æˆ–`np.array`ä¹‹é—´çš„ä¸€ä¸ªã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¿”å›[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`cross_attention_kwargs` (`dict`, *optional*) â€” A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™`AttentionProcessor`çš„kwargså­—å…¸ï¼Œå¦‚[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)ä¸­å®šä¹‰çš„ã€‚'
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) â€” Guidance rescale
    factor from [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) â€” æ¥è‡ª[Common Diffusion
    Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)çš„æŒ‡å¯¼é‡ç¼©æ”¾å› å­ã€‚æŒ‡å¯¼é‡ç¼©æ”¾å› å­åº”åœ¨ä½¿ç”¨é›¶ç»ˆç«¯SNRæ—¶ä¿®å¤è¿‡æ›å…‰é—®é¢˜ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) â€” åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦ä»CLIPè·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º1æ„å‘³ç€å°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: '`callback_on_step_end` (`Callable`, *optional*) â€” A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) â€” åœ¨æ¨æ–­è¿‡ç¨‹ä¸­æ¯ä¸ªå»å™ªæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`ã€‚`callback_kwargs`å°†åŒ…æ‹¬ç”±`callback_on_step_end_tensor_inputs`æŒ‡å®šçš„æ‰€æœ‰å¼ é‡çš„åˆ—è¡¨ã€‚'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” `callback_on_step_end`å‡½æ•°çš„å¼ é‡è¾“å…¥åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æŒ‡å®šçš„å¼ é‡å°†ä½œä¸º`callback_kwargs`å‚æ•°ä¼ é€’ã€‚æ‚¨åªèƒ½åŒ…æ‹¬åœ¨æ‚¨çš„ç®¡é“ç±»çš„`._callback_tensor_inputs`å±æ€§ä¸­åˆ—å‡ºçš„å˜é‡ã€‚'
- en: Returns
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)æˆ–`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains â€œnot-safe-for-workâ€ (nsfw)
    content.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å›[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª`tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«â€œä¸é€‚åˆå·¥ä½œâ€ï¼ˆnsfwï¼‰å†…å®¹çš„ç”Ÿæˆå›¾åƒçš„`bool`åˆ—è¡¨ã€‚
- en: The call function to the pipeline for generation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚
- en: 'Examples:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_attention_slicing`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`slice_size` (`str` or `int`, *optional*, defaults to `"auto"`) â€” When `"auto"`,
    halves the input to the attention heads, so attention will be computed in two
    steps. If `"max"`, maximum amount of memory will be saved by running only one
    slice at a time. If a number is provided, uses as many slices as `attention_head_dim
    // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size`.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`slice_size`ï¼ˆ`str`æˆ–`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"auto"`ï¼‰â€” å½“ä¸º`"auto"`æ—¶ï¼Œå°†è¾“å…¥åˆ†æˆæ³¨æ„åŠ›å¤´çš„ä¸€åŠï¼Œå› æ­¤æ³¨æ„åŠ›å°†åœ¨ä¸¤ä¸ªæ­¥éª¤ä¸­è®¡ç®—ã€‚å¦‚æœä¸º`"max"`ï¼Œå°†é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥èŠ‚çœæœ€å¤§æ•°é‡çš„å†…å­˜ã€‚å¦‚æœæä¾›äº†ä¸€ä¸ªæ•°å­—ï¼Œåˆ™ä½¿ç”¨`attention_head_dim
    // slice_size`ä¸ªåˆ‡ç‰‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`attention_head_dim`å¿…é¡»æ˜¯`slice_size`çš„å€æ•°ã€‚'
- en: Enable sliced attention computation. When this option is enabled, the attention
    module splits the input tensor in slices to compute attention in several steps.
    For more than one attention head, the computation is performed sequentially over
    each head. This is useful to save some memory in exchange for a small speed decrease.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ‡ç‰‡çš„æ³¨æ„åŠ›è®¡ç®—ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç‰‡æ®µï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—å°†æŒ‰é¡ºåºåœ¨æ¯ä¸ªå¤´ä¸Šæ‰§è¡Œã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜ä»¥æ¢å–ä¸€ç‚¹é€Ÿåº¦é™ä½å¾ˆæœ‰ç”¨ã€‚
- en: âš ï¸ Donâ€™t enable attention slicing if youâ€™re already using `scaled_dot_product_attention`
    (SDPA) from PyTorch 2.0 or xFormers. These attention computations are already
    very memory efficient so you wonâ€™t need to enable this function. If you enable
    attention slicing with SDPA or xFormers, it can lead to serious slow downs!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨PyTorch 2.0æˆ–xFormersçš„`scaled_dot_product_attention`ï¼ˆSDPAï¼‰ï¼Œè¯·ä¸è¦å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ã€‚è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸é«˜æ•ˆï¼Œå› æ­¤æ‚¨ä¸éœ€è¦å¯ç”¨æ­¤åŠŸèƒ½ã€‚å¦‚æœæ‚¨åœ¨SDPAæˆ–xFormersä¸Šå¯ç”¨äº†æ³¨æ„åŠ›åˆ‡ç‰‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡å‡é€Ÿï¼
- en: 'Examples:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `disable_attention_slicing`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable sliced attention computation. If `enable_attention_slicing` was previously
    called, attention is computed in one step.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ‡ç‰‡çš„æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚
- en: '#### `enable_vae_slicing`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L251)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L251)'
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ‡ç‰‡çš„VAEè§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†åˆ†å‰²è¾“å…¥å¼ é‡ä»¥åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç ã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜å¹¶å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°å¾ˆæœ‰ç”¨ã€‚
- en: '#### `disable_vae_slicing`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L258)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L258)'
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ‡ç‰‡çš„VAEè§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_slicing`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`attention_op` (`Callable`, *optional*) â€” Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op`ï¼ˆ`Callable`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œ`op`å‚æ•°ä¼ é€’ç»™[xFormersçš„`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)å‡½æ•°çš„é»˜è®¤`None`æ“ä½œç¬¦ã€‚'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°è¾ƒä½çš„GPUå†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶åœ¨æ¨æ–­æœŸé—´å¯èƒ½åŠ é€Ÿã€‚è®­ç»ƒæœŸé—´çš„åŠ é€Ÿä¸è¢«ä¿è¯ã€‚
- en: âš ï¸ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å½“å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚
- en: 'Examples:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚
- en: '#### `enable_vae_tiling`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L265)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L265)'
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ†å— VAE è§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆå¤šä¸ªå—ï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚
- en: '#### `disable_vae_tiling`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L273)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L273)'
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ†å— VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº† `enable_vae_tiling`ï¼Œæ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚
- en: '#### `load_textual_inversion`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_textual_inversion`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike` or `List[str or os.PathLike]`
    or `Dict` or `List[Dict]`) â€” Can be either one of the following or a list of them:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` æˆ– `os.PathLike` æˆ– `List[str or os.PathLike]`
    æˆ– `Dict` æˆ– `List[Dict]`) â€” å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å®ƒä»¬çš„åˆ—è¡¨ï¼š'
- en: A string, the *model id* (for example `sd-concepts-library/low-poly-hd-logos-icons`)
    of a pretrained model hosted on the Hub.
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ Hub ä¸Šæ‰˜ç®¡çš„ *æ¨¡å‹ ID*ï¼ˆä¾‹å¦‚ `sd-concepts-library/low-poly-hd-logos-icons`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_text_inversion_directory/`) containing
    the textual inversion weights.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„ *ç›®å½•* çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./my_text_inversion_directory/`ï¼‰ã€‚
- en: A path to a *file* (for example `./my_text_inversions.pt`) containing textual
    inversion weights.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„ *æ–‡ä»¶* çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./my_text_inversions.pt`ï¼‰ã€‚
- en: A [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict).
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)ã€‚
- en: '`token` (`str` or `List[str]`, *optional*) â€” Override the token to use for
    the textual inversion weights. If `pretrained_model_name_or_path` is a list, then
    `token` must also be a list of equal length.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` æˆ– `List[str]`, *optional*) â€” è¦†ç›–ç”¨äºæ–‡æœ¬åè½¬æƒé‡çš„ä»¤ç‰Œã€‚å¦‚æœ `pretrained_model_name_or_path`
    æ˜¯åˆ—è¡¨ï¼Œåˆ™ `token` ä¹Ÿå¿…é¡»æ˜¯ç›¸åŒé•¿åº¦çš„åˆ—è¡¨ã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).
    If not specified, function will take self.tokenizer.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨
    self.tokenizerã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) â€” A `CLIPTokenizer` to tokenize text. If not specified, function will
    take self.tokenizer.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) â€” ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„ `CLIPTokenizer`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨ self.tokenizerã€‚'
- en: '`weight_name` (`str`, *optional*) â€” Name of a custom weight file. This should
    be used when:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_name` (`str`, *optional*) â€” è‡ªå®šä¹‰æƒé‡æ–‡ä»¶çš„åç§°ã€‚åº”åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ä½¿ç”¨ï¼š'
- en: The saved textual inversion file is in ğŸ¤— Diffusers format, but was saved under
    a specific weight name such as `text_inv.bin`.
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥ ğŸ¤— Diffusers æ ¼å¼ä¿å­˜ï¼Œä½†æ˜¯ä¿å­˜åœ¨ç‰¹å®šæƒé‡åç§°ä¸‹ï¼Œä¾‹å¦‚ `text_inv.bin`ã€‚
- en: The saved textual inversion file is in the Automatic1111 format.
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥ Automatic1111 æ ¼å¼ä¿å­˜ã€‚
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ç¼“å­˜çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º
    `False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†æœåŠ¡å™¨åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º
    `True`ï¼Œæ¨¡å‹å°†ä¸ä¼šä» Hub ä¸‹è½½ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` æˆ– *bool*, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP ä»¤ç‰Œçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œåˆ™ä½¿ç”¨ä» `diffusers-cli
    login` ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID
    æˆ– Git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) â€” The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *optional*, é»˜è®¤ä¸º `""`) â€” æ¨¡å‹æ–‡ä»¶åœ¨ Hub æˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚'
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœæ‚¨åœ¨ä¸‹è½½ä¸­å›½çš„æ¨¡å‹æ—¶é‡åˆ°å¯è®¿é—®æ€§é—®é¢˜ï¼Œè¯·ä½¿ç”¨é•œåƒæºã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚'
- en: Load Textual Inversion embeddings into the text encoder of [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    (both ğŸ¤— Diffusers and Automatic1111 formats are supported).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ–‡æœ¬åè½¬åµŒå…¥åŠ è½½åˆ°[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)çš„æ–‡æœ¬ç¼–ç å™¨ä¸­ï¼ˆæ”¯æŒğŸ¤—
    Diffuserså’ŒAutomatic1111æ ¼å¼ï¼‰ã€‚
- en: 'Example:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: 'To load a Textual Inversion embedding vector in ğŸ¤— Diffusers format:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨ğŸ¤— Diffusersæ ¼å¼ä¸­åŠ è½½æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼š
- en: '[PRE14]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To load a Textual Inversion embedding vector in Automatic1111 format, make sure
    to download the vector first (for example from [civitAI](https://civitai.com/models/3036?modelVersionId=9857))
    and then load the vector
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½Automatic1111æ ¼å¼çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼Œè¯·ç¡®ä¿é¦–å…ˆä¸‹è½½å‘é‡ï¼ˆä¾‹å¦‚ä»[civitAI](https://civitai.com/models/3036?modelVersionId=9857)ï¼‰ç„¶ååŠ è½½å‘é‡
- en: 'locally:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åœ°ï¼š
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#### `from_single_file`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_single_file`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L141)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L141)'
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_link_or_path` (`str` or `os.PathLike`, *optional*) â€” Can
    be either:'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_link_or_path`ï¼ˆ`str`æˆ–`os.PathLike`ï¼Œ*å¯é€‰*ï¼‰â€” å¯ä»¥æ˜¯ï¼š'
- en: A link to the `.ckpt` file (for example `"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`)
    on the Hub.
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨Hubä¸Šé“¾æ¥åˆ°`.ckpt`æ–‡ä»¶ï¼ˆä¾‹å¦‚`"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`ï¼‰ã€‚
- en: A path to a *file* containing all pipeline weights.
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒ…å«æ‰€æœ‰ç®¡é“æƒé‡çš„*æ–‡ä»¶*è·¯å¾„ã€‚
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) â€” Override the default `torch.dtype`
    and load the model with another dtype.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype`ï¼ˆ`str`æˆ–`torch.dtype`ï¼Œ*å¯é€‰*ï¼‰â€” è¦†ç›–é»˜è®¤çš„`torch.dtype`å¹¶ä½¿ç”¨å¦ä¸€ç§dtypeåŠ è½½æ¨¡å‹ã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`ï¼ˆ`Union[str, os.PathLike]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®çš„ç¼“å­˜è·¯å¾„ï¼Œå¦‚æœæœªä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™åˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`ï¼ˆ`Dict[str, str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ä¸ä¼šä»Hubä¸‹è½½æ¨¡å‹ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`ï¼ˆ`str`æˆ–*bool*ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTPä»¤ç‰Œçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"main"`ï¼‰â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤IDæˆ–Gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) â€” If set to `None`,
    the safetensors weights are downloaded if theyâ€™re available **and** if the safetensors
    library is installed. If set to `True`, the model is forcibly loaded from safetensors
    weights. If set to `False`, safetensors weights are not loaded.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_safetensors`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`None`ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`None`ï¼Œåˆ™åœ¨å¯ç”¨æ—¶ä¸‹è½½safetensorsæƒé‡**å¹¶ä¸”**å¦‚æœå·²å®‰è£…safetensorsåº“ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™å¼ºåˆ¶ä»safetensorsæƒé‡åŠ è½½æ¨¡å‹ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™ä¸åŠ è½½safetensorsæƒé‡ã€‚'
- en: Instantiate a [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    from pretrained pipeline weights saved in the `.ckpt` or `.safetensors` format.
    The pipeline is set in evaluation mode (`model.eval()`) by default.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¿å­˜åœ¨`.ckpt`æˆ–`.safetensors`æ ¼å¼ä¸­çš„é¢„è®­ç»ƒç®¡é“æƒé‡å®ä¾‹åŒ–[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç®¡é“è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆ`model.eval()`ï¼‰ã€‚
- en: 'Examples:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE17]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `load_lora_weights`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    â€” See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path_or_dict`ï¼ˆ`str`æˆ–`os.PathLike`æˆ–`dict`ï¼‰â€” å‚è§[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚'
- en: '`kwargs` (`dict`, *optional*) â€” See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€” å‚è§[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚'
- en: '`adapter_name` (`str`, *optional*) â€” Adapter name to be used for referencing
    the loaded adapter model. If not specified, it will use `default_{i}` where i
    is the total number of adapters being loaded.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå¼•ç”¨åŠ è½½çš„é€‚é…å™¨æ¨¡å‹çš„é€‚é…å™¨åç§°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨`default_{i}`ï¼Œå…¶ä¸­iæ˜¯è¦åŠ è½½çš„é€‚é…å™¨æ€»æ•°ã€‚'
- en: Load LoRA weights specified in `pretrained_model_name_or_path_or_dict` into
    `self.unet` and `self.text_encoder`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å°†åœ¨ `pretrained_model_name_or_path_or_dict` ä¸­æŒ‡å®šçš„ LoRA æƒé‡åŠ è½½åˆ° `self.unet` å’Œ `self.text_encoder`
    ä¸­ã€‚
- en: All kwargs are forwarded to `self.lora_state_dict`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ kwargs éƒ½å°†è½¬å‘åˆ° `self.lora_state_dict`ã€‚
- en: See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    for more details on how the state dict is loaded.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½çŠ¶æ€å­—å…¸çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: See [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    for more details on how the state dict is loaded into `self.unet`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ° `self.unet` ä¸­çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: See [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    for more details on how the state dict is loaded into `self.text_encoder`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ° `self.text_encoder` ä¸­çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: '#### `save_lora_weights`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
- en: '[PRE19]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to save LoRA parameters
    to. Will be created if it doesnâ€™t exist.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜ LoRA å‚æ•°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºè¯¥ç›®å½•ã€‚'
- en: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” State dict of the LoRA layers corresponding to the `unet`.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` æˆ– `Dict[str, torch.Tensor]`)
    â€” ä¸ `unet` å¯¹åº”çš„ LoRA å±‚çš„çŠ¶æ€å­—å…¸ã€‚'
- en: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” State dict of the LoRA layers corresponding to the `text_encoder`. Must explicitly
    pass the text encoder LoRA state dict because it comes from ğŸ¤— Transformers.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` æˆ– `Dict[str, torch.Tensor]`)
    â€” ä¸ `text_encoder` å¯¹åº”çš„ LoRA å±‚çš„çŠ¶æ€å­—å…¸ã€‚å¿…é¡»æ˜¾å¼ä¼ é€’æ–‡æœ¬ç¼–ç å™¨ LoRA çŠ¶æ€å­—å…¸ï¼Œå› ä¸ºå®ƒæ¥è‡ª ğŸ¤— Transformersã€‚'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) â€” Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®
    `is_main_process=True`ï¼Œä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚'
- en: '`save_function` (`Callable`) â€” The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function` (`Callable`) â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢ `torch.save`
    æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡ `DIFFUSERS_SAVE_MODE` è¿›è¡Œé…ç½®ã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors` ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„
    PyTorch æ–¹æ³•ä¸ `pickle`ã€‚'
- en: Save the LoRA parameters corresponding to the UNet and text encoder.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿å­˜ä¸ UNet å’Œæ–‡æœ¬ç¼–ç å™¨å¯¹åº”çš„ LoRA å‚æ•°ã€‚
- en: '#### `disable_freeu`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L678)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L678)'
- en: '[PRE20]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå·²å¯ç”¨ï¼Œåˆ™ç¦ç”¨ FreeU æœºåˆ¶ã€‚
- en: '#### `enable_freeu`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L656)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L656)'
- en: '[PRE21]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1` (`float`) â€” ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚'
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2` (`float`) â€” ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚'
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1` (`float`) â€” ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚'
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2` (`float`) â€” ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨ FreeU æœºåˆ¶ï¼Œå¦‚ [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)
    ä¸­æ‰€è¿°ã€‚
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬åº”ç”¨çš„é˜¶æ®µã€‚
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion
    v1ã€v2 å’Œ Stable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚
- en: '#### `encode_prompt`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L312)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L312)'
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded device â€”
    (`torch.device`): torch device'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” è¦ç¼–ç çš„æç¤ºè®¾å¤‡ â€” (`torch.device`): torch è®¾å¤‡'
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡'
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) â€” æ˜¯å¦ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸ç”¨æ¥å¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨å¼•å¯¼æ—¶è¢«å¿½ç•¥ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™è¢«å¿½ç•¥ï¼‰ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆ`negative_prompt_embeds`ã€‚'
- en: '`lora_scale` (`float`, *optional*) â€” A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœåŠ è½½äº†LoRAå±‚ï¼Œåˆ™å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰LoRAå±‚çš„LoRAæ¯”ä¾‹ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€” ä»CLIPä¸­è·³è¿‡çš„å±‚æ•°ï¼Œç”¨äºè®¡ç®—æç¤ºåµŒå…¥ã€‚å€¼ä¸º1æ„å‘³ç€å°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨çš„éšè—çŠ¶æ€ã€‚
- en: '#### `fuse_qkv_projections`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `fuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L683)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L683)'
- en: '[PRE23]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹UNetåº”ç”¨èåˆã€‚'
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹VAEåº”ç”¨èåˆã€‚'
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨èåˆçš„QKVæŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆå³æŸ¥è¯¢ã€é”®ã€å€¼ï¼‰éƒ½è¢«èåˆã€‚å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚
- en: This API is ğŸ§ª experimental.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_guidance_scale_embedding`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L744)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L744)'
- en: '[PRE24]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`timesteps` (`torch.Tensor`) â€” generate embedding vectors at these timesteps'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps`ï¼ˆ`torch.Tensor`ï¼‰â€” åœ¨è¿™äº›æ—¶é—´æ­¥ç”ŸæˆåµŒå…¥å‘é‡'
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) â€” dimension of the embeddings
    to generate dtype â€” data type of the generated embeddings'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dim`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º512ï¼‰â€” è¦ç”Ÿæˆçš„åµŒå…¥çš„ç»´åº¦dtype â€” ç”Ÿæˆçš„åµŒå…¥çš„æ•°æ®ç±»å‹ã€‚'
- en: Returns
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`torch.FloatTensor`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: å½¢çŠ¶ä¸º`(len(timesteps), embedding_dim)`çš„åµŒå…¥å‘é‡
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: å‚è§[https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
- en: '#### `unfuse_qkv_projections`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unfuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L715)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L715)'
- en: '[PRE25]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹UNetåº”ç”¨èåˆã€‚'
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹VAEåº”ç”¨èåˆã€‚'
- en: Disable QKV projection fusion if enabled.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¯ç”¨ï¼Œç¦ç”¨QKVæŠ•å½±èåˆã€‚
- en: This API is ğŸ§ª experimental.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚
- en: StableDiffusionPipelineOutput
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE26]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) â€” List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images`ï¼ˆ`List[PIL.Image.Image]`æˆ–`np.ndarray`ï¼‰â€” é•¿åº¦ä¸º`batch_size`çš„å»å™ªPILå›¾åƒåˆ—è¡¨æˆ–å½¢çŠ¶ä¸º`(batch_size,
    height, width, num_channels)`çš„NumPyæ•°ç»„ã€‚'
- en: '`nsfw_content_detected` (`List[bool]`) â€” List indicating whether the corresponding
    generated image contains â€œnot-safe-for-workâ€ (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected`ï¼ˆ`List[bool]`ï¼‰â€” è¡¨ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰çš„åˆ—è¡¨ï¼Œå¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º`None`ã€‚'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚
- en: FlaxStableDiffusionPipeline
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxStableDiffusionPipeline
- en: '### `class diffusers.FlaxStableDiffusionPipeline`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.FlaxStableDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L81)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L81)'
- en: '[PRE27]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([FlaxAutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.FlaxAutoencoderKL))
    â€” Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[FlaxAutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.FlaxAutoencoderKL)ï¼‰â€”
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`text_encoder` ([FlaxCLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPTextModel))
    â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([FlaxCLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPTextModel))
    â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” A `CLIPTokenizer` to tokenize text.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” ä¸€ä¸ªç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„`CLIPTokenizer`ã€‚'
- en: '`unet` ([FlaxUNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.FlaxUNet2DConditionModel))
    â€” A `FlaxUNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([FlaxUNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.FlaxUNet2DConditionModel))
    â€” ä¸€ä¸ªç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨å˜é‡çš„`FlaxUNet2DConditionModel`ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of `FlaxDDIMScheduler`, `FlaxLMSDiscreteScheduler`, `FlaxPNDMScheduler`,
    or `FlaxDPMSolverMultistepScheduler`.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” ä¸`unet`ç»“åˆä½¿ç”¨çš„è°ƒåº¦å™¨ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨å˜é‡ã€‚å¯ä»¥æ˜¯`FlaxDDIMScheduler`ã€`FlaxLMSDiscreteScheduler`ã€`FlaxPNDMScheduler`æˆ–`FlaxDPMSolverMultistepScheduler`ä¹‹ä¸€ã€‚'
- en: '`safety_checker` (`FlaxStableDiffusionSafetyChecker`) â€” Classification module
    that estimates whether generated images could be considered offensive or harmful.
    Please refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a modelâ€™s potential harms.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`FlaxStableDiffusionSafetyChecker`) â€” ä¸€ä¸ªåˆ†ç±»æ¨¡å—ï¼Œç”¨äºä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è®¤ä¸ºæ˜¯å†’çŠ¯æˆ–æœ‰å®³çš„ã€‚è¯·å‚è€ƒ[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” ä¸€ä¸ªç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾çš„`CLIPImageProcessor`ï¼›ä½œä¸º`å®‰å…¨æ£€æŸ¥å™¨`çš„è¾“å…¥ã€‚'
- en: Flax-based pipeline for text-to-image generation using Stable Diffusion.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç¨³å®šæ‰©æ•£è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„åŸºäºFlaxçš„ç®¡é“ã€‚
- en: This model inherits from [FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: '#### `__call__`'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L310)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L310)'
- en: '[PRE28]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    image generation.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” The height in pixels of the generated image.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” The width in pixels of the generated image.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`ç´§å¯†ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“`guidance_scale
    > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚'
- en: '`latents` (`jnp.ndarray`, *optional*) â€” Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    array is generated by sampling using the supplied random `generator`.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`jnp.ndarray`, *å¯é€‰*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é¢„å…ˆç”Ÿæˆçš„å˜ˆæ‚æ½œåœ¨å˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ä»¥ç”¨æ¥è°ƒæ•´ç›¸åŒç”Ÿæˆä¸ä¸åŒæç¤ºçš„ç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é€šè¿‡ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡Œé‡‡æ ·ç”Ÿæˆä¸€ä¸ªæ½œåœ¨å˜é‡æ•°ç»„ã€‚'
- en: '`jit` (`bool`, defaults to `False`) â€” Whether to run `pmap` versions of the
    generation and safety scoring functions.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jit` (`bool`, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿è¡Œç”Ÿæˆå’Œå®‰å…¨è¯„åˆ†å‡½æ•°çš„`pmap`ç‰ˆæœ¬ã€‚'
- en: This argument exists because `__call__` is not yet end-to-end pmap-able. It
    will be removed in a future release.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå‚æ•°å­˜åœ¨æ˜¯å› ä¸º`__call__`ç›®å‰è¿˜ä¸èƒ½å®Œå…¨è¿›è¡Œpmapã€‚å®ƒå°†åœ¨å°†æ¥çš„ç‰ˆæœ¬ä¸­è¢«ç§»é™¤ã€‚
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚'
- en: Returns
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    æˆ– `tuple`'
- en: If `return_dict` is `True`, [FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains â€œnot-safe-for-workâ€ (nsfw)
    content.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å›[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª`tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ã€‚
- en: The call function to the pipeline for generation.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚
- en: 'Examples:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE29]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: FlaxStableDiffusionPipelineOutput
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxStableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput`'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L31)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L31)'
- en: '[PRE30]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`np.ndarray`) â€” Denoised images of array shape of `(batch_size, height,
    width, num_channels)`.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`np.ndarray`) â€” å½¢çŠ¶ä¸º`(batch_size, height, width, num_channels)`çš„å»å™ªå›¾åƒæ•°ç»„ã€‚'
- en: '`nsfw_content_detected` (`List[bool]`) â€” List indicating whether the corresponding
    generated image contains â€œnot-safe-for-workâ€ (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) â€” åˆ—è¡¨æŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ï¼Œæˆ–è€…å¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º`None`ã€‚'
- en: Output class for Flax-based Stable Diffusion pipelines.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: FlaxåŸºç¡€ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚
- en: '#### `replace`'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `replace`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
- en: '[PRE31]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: â€œReturns a new object replacing the specified fields with new values.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: â€œè¿”å›ä¸€ä¸ªç”¨æ–°å€¼æ›¿æ¢æŒ‡å®šå­—æ®µçš„æ–°å¯¹è±¡ã€‚
