- en: Text-to-image
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本到图像
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The Stable Diffusion model was created by researchers and engineers from [CompVis](https://github.com/CompVis),
    [Stability AI](https://stability.ai/), [Runway](https://github.com/runwayml),
    and [LAION](https://laion.ai/). The [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    is capable of generating photorealistic images given any text input. It’s trained
    on 512x512 images from a subset of the LAION-5B dataset. This model uses a frozen
    CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M
    UNet and 123M text encoder, the model is relatively lightweight and can run on
    consumer GPUs. Latent diffusion is the research on top of which Stable Diffusion
    was built. It was proposed in [High-Resolution Image Synthesis with Latent Diffusion
    Models](https://huggingface.co/papers/2112.10752) by Robin Rombach, Andreas Blattmann,
    Dominik Lorenz, Patrick Esser, Björn Ommer.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散模型是由[CompVis](https://github.com/CompVis)、[Stability AI](https://stability.ai/)、[Runway](https://github.com/runwayml)和[LAION](https://laion.ai/)的研究人员和工程师创建的。[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)能够根据任何文本输入生成逼真的图像。它是在LAION-5B数据集的512x512图像上训练的。该模型使用冻结的CLIP
    ViT-L/14文本编码器来根据文本提示对模型进行条件化。该模型具有860M UNet和123M文本编码器，相对轻量级，可以在消费级GPU上运行。潜在扩散是稳定扩散构建在其之上的研究。它是由Robin
    Rombach、Andreas Blattmann、Dominik Lorenz、Patrick Esser、Björn Ommer在[High-Resolution
    Image Synthesis with Latent Diffusion Models](https://huggingface.co/papers/2112.10752)中提出的。
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要：
- en: '*By decomposing the image formation process into a sequential application of
    denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis
    results on image data and beyond. Additionally, their formulation allows for a
    guiding mechanism to control the image generation process without retraining.
    However, since these models typically operate directly in pixel space, optimization
    of powerful DMs often consumes hundreds of GPU days and inference is expensive
    due to sequential evaluations. To enable DM training on limited computational
    resources while retaining their quality and flexibility, we apply them in the
    latent space of powerful pretrained autoencoders. In contrast to previous work,
    training diffusion models on such a representation allows for the first time to
    reach a near-optimal point between complexity reduction and detail preservation,
    greatly boosting visual fidelity. By introducing cross-attention layers into the
    model architecture, we turn diffusion models into powerful and flexible generators
    for general conditioning inputs such as text or bounding boxes and high-resolution
    synthesis becomes possible in a convolutional manner. Our latent diffusion models
    (LDMs) achieve a new state of the art for image inpainting and highly competitive
    performance on various tasks, including unconditional image generation, semantic
    scene synthesis, and super-resolution, while significantly reducing computational
    requirements compared to pixel-based DMs. Code is available at [https://github.com/CompVis/latent-diffusion](https://github.com/CompVis/latent-diffusion).*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*通过将图像形成过程分解为逐步应用去噪自动编码器、扩散模型（DMs），DMs在图像数据及其他领域实现了最先进的合成结果。此外，它们的公式允许引导机制来控制图像生成过程而无需重新训练。然而，由于这些模型通常直接在像素空间中操作，优化强大的DMs通常消耗数百个GPU天，由于顺序评估，推断成本昂贵。为了在有限的计算资源上训练DM并保持其质量和灵活性，我们将它们应用于强大预训练自动编码器的潜在空间。与以往的工作相比，在这种表示上训练扩散模型首次实现了在复杂性减少和细节保留之间达到近乎最优点，极大地提升了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型转变为强大且灵活的生成器，用于一般条件输入，如文本或边界框，高分辨率合成以卷积方式变得可能。我们的潜在扩散模型（LDMs）在图像修补和各种任务上实现了新的技术水平，包括无条件图像生成、语义场景合成和超分辨率，同时与基于像素的DM相比显著降低了计算要求。代码可在[https://github.com/CompVis/latent-diffusion](https://github.com/CompVis/latent-diffusion)上找到。*'
- en: Make sure to check out the Stable Diffusion [Tips](overview#tips) section to
    learn how to explore the tradeoff between scheduler speed and quality, and how
    to reuse pipeline components efficiently!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 确保查看稳定扩散[Tips](overview#tips)部分，了解如何探索调度程序速度和质量之间的权衡，以及如何有效地重用管道组件！
- en: If you’re interested in using one of the official checkpoints for a task, explore
    the [CompVis](https://huggingface.co/CompVis), [Runway](https://huggingface.co/runwayml),
    and [Stability AI](https://huggingface.co/stabilityai) Hub organizations!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣使用官方检查点执行任务，请探索[CompVis](https://huggingface.co/CompVis)、[Runway](https://huggingface.co/runwayml)和[Stability
    AI](https://huggingface.co/stabilityai) Hub 组织！
- en: StableDiffusionPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipeline
- en: '### `class diffusers.StableDiffusionPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L118)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L118)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — 变分自动编码器（VAE）模型，用于将图像编码和解码为潜在表示形式。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — 冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 一个`CLIPTokenizer`用于对文本进行标记化。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 一个`UNet2DConditionModel`，用于去噪编码图像潜在特征。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 与`unet`结合使用以去噪编码图像潜在特征的调度器。可以是[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)或[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)之一。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) — 用于估计生成的图像是否可能被视为具有攻击性或有害的分类模块。请参考[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 一个`CLIPImageProcessor`，用于从生成的图像中提取特征；作为`安全检查器`的输入。'
- en: Pipeline for text-to-image generation using Stable Diffusion.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用稳定扩散进行文本到图像生成的流水线。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有流水线实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该流水线还继承以下加载方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    用于加载LoRA权重'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    用于保存LoRA权重'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于加载`.ckpt`文件的[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    用于加载IP适配器'
- en: '#### `__call__`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L803)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L803)'
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *可选*) — 用于指导图像生成的提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为`self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的高度（以像素为单位）。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为`self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的宽度（以像素为单位）。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`timesteps` (`List[int]`, *optional*) — Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *可选*) — 用于与支持在其`set_timesteps`方法中使用`timesteps`参数的调度器一起使用的自定义时间步。如果未定义，则将使用传递`num_inference_steps`时的默认行为。必须按降序排列。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为7.5) — 更高的引导比例值鼓励模型生成与文本`prompt`密切相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 指导图像生成中不包括的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用指导时（`guidance_scale
    < 1`）时将被忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, defaults to 0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数eta（η）。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度程序中将被忽略。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — 用于使生成具有确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中采样的预生成噪声潜变量，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，将使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，文本嵌入将从`prompt`输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument. ip_adapter_image — (`PipelineImageInput`, *optional*): Optional
    image input to work with IP Adapters.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，`negative_prompt_embeds`将从`negative_prompt`输入参数生成。ip_adapter_image
    — (`PipelineImageInput`, *optional*): 可选的图像输入以与IP适配器一起使用。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是普通元组。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给`AttentionProcessor`的kwargs字典，如[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中定义的。'
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) — Guidance rescale
    factor from [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) — 来自[Common Diffusion
    Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)的指导重缩放因子。指导重缩放因子应在使用零终端SNR时修复过曝光问题。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 在计算提示嵌入时要从CLIP跳过的层数。值为1意味着将使用预最终层的输出来计算提示嵌入。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) — 在推断过程中每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`将包括由`callback_on_step_end_tensor_inputs`指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — `callback_on_step_end`函数的张量输入列表。列表中指定的张量将作为`callback_kwargs`参数传递。您只能包括在您的管道类的`._callback_tensor_inputs`属性中列出的变量。'
- en: Returns
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个`tuple`，其中第一个元素是包含生成图像的列表，第二个元素是一个包含“不适合工作”（nsfw）内容的生成图像的`bool`列表。
- en: The call function to the pipeline for generation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_attention_slicing`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`slice_size` (`str` or `int`, *optional*, defaults to `"auto"`) — When `"auto"`,
    halves the input to the attention heads, so attention will be computed in two
    steps. If `"max"`, maximum amount of memory will be saved by running only one
    slice at a time. If a number is provided, uses as many slices as `attention_head_dim
    // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size`.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`slice_size`（`str`或`int`，*可选*，默认为`"auto"`）— 当为`"auto"`时，将输入分成注意力头的一半，因此注意力将在两个步骤中计算。如果为`"max"`，将通过一次只运行一个切片来节省最大数量的内存。如果提供了一个数字，则使用`attention_head_dim
    // slice_size`个切片。在这种情况下，`attention_head_dim`必须是`slice_size`的倍数。'
- en: Enable sliced attention computation. When this option is enabled, the attention
    module splits the input tensor in slices to compute attention in several steps.
    For more than one attention head, the computation is performed sequentially over
    each head. This is useful to save some memory in exchange for a small speed decrease.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片的注意力计算。当启用此选项时，注意力模块将输入张量分割成片段，以便在多个步骤中计算注意力。对于多个注意力头，计算将按顺序在每个头上执行。这对于节省一些内存以换取一点速度降低很有用。
- en: ⚠️ Don’t enable attention slicing if you’re already using `scaled_dot_product_attention`
    (SDPA) from PyTorch 2.0 or xFormers. These attention computations are already
    very memory efficient so you won’t need to enable this function. If you enable
    attention slicing with SDPA or xFormers, it can lead to serious slow downs!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 如果您已经在使用PyTorch 2.0或xFormers的`scaled_dot_product_attention`（SDPA），请不要启用注意力切片。这些注意力计算已经非常高效，因此您不需要启用此功能。如果您在SDPA或xFormers上启用了注意力切片，可能会导致严重减速！
- en: 'Examples:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `disable_attention_slicing`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable sliced attention computation. If `enable_attention_slicing` was previously
    called, attention is computed in one step.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片的注意力计算。如果之前调用了`enable_attention_slicing`，则注意力将在一步中计算。
- en: '#### `enable_vae_slicing`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L251)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L251)'
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片的VAE解码。当启用此选项时，VAE将分割输入张量以在多个步骤中计算解码。这对于节省一些内存并允许更大的批量大小很有用。
- en: '#### `disable_vae_slicing`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L258)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L258)'
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片的VAE解码。如果之前启用了`enable_vae_slicing`，则此方法将返回到一步计算解码。
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_op` (`Callable`, *optional*) — Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op`（`Callable`，*可选*）— 用作`op`参数传递给[xFormers的`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)函数的默认`None`操作符。'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 启用[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。当启用此选项时，您应该观察到较低的GPU内存使用量，并在推断期间可能加速。训练期间的加速不被保证。
- en: ⚠️ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 当内存高效注意力和切片注意力都启用时，内存高效注意力优先。
- en: 'Examples:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。
- en: '#### `enable_vae_tiling`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L265)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L265)'
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 启用分块 VAE 解码。当启用此选项时，VAE 将将输入张量分割成多个块，以便在多个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `disable_vae_tiling`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L273)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L273)'
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用分块 VAE 解码。如果之前启用了 `enable_vae_tiling`，此方法将返回到一步计算解码。
- en: '#### `load_textual_inversion`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_textual_inversion`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike` or `List[str or os.PathLike]`
    or `Dict` or `List[Dict]`) — Can be either one of the following or a list of them:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike` 或 `List[str or os.PathLike]`
    或 `Dict` 或 `List[Dict]`) — 可以是以下之一或它们的列表：'
- en: A string, the *model id* (for example `sd-concepts-library/low-poly-hd-logos-icons`)
    of a pretrained model hosted on the Hub.
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型在 Hub 上托管的 *模型 ID*（例如 `sd-concepts-library/low-poly-hd-logos-icons`）。
- en: A path to a *directory* (for example `./my_text_inversion_directory/`) containing
    the textual inversion weights.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含文本反转权重的 *目录* 的路径（例如 `./my_text_inversion_directory/`）。
- en: A path to a *file* (for example `./my_text_inversions.pt`) containing textual
    inversion weights.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含文本反转权重的 *文件* 的路径（例如 `./my_text_inversions.pt`）。
- en: A [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict).
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)。
- en: '`token` (`str` or `List[str]`, *optional*) — Override the token to use for
    the textual inversion weights. If `pretrained_model_name_or_path` is a list, then
    `token` must also be a list of equal length.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 `List[str]`, *optional*) — 覆盖用于文本反转权重的令牌。如果 `pretrained_model_name_or_path`
    是列表，则 `token` 也必须是相同长度的列表。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).
    If not specified, function will take self.tokenizer.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) — 冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。如果未指定，函数将使用
    self.tokenizer。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) — A `CLIPTokenizer` to tokenize text. If not specified, function will
    take self.tokenizer.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) — 用于对文本进行标记化的 `CLIPTokenizer`。如果未指定，函数将使用 self.tokenizer。'
- en: '`weight_name` (`str`, *optional*) — Name of a custom weight file. This should
    be used when:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_name` (`str`, *optional*) — 自定义权重文件的名称。应在以下情况下使用：'
- en: The saved textual inversion file is in 🤗 Diffusers format, but was saved under
    a specific weight name such as `text_inv.bin`.
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存的文本反转文件以 🤗 Diffusers 格式保存，但是保存在特定权重名称下，例如 `text_inv.bin`。
- en: The saved textual inversion file is in the Automatic1111 format.
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存的文本反转文件以 Automatic1111 格式保存。
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — 下载的预训练模型配置缓存的目录路径，如果不使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否恢复下载模型权重和配置文件。如果设置为
    `False`，任何未完全下载的文件将被删除。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理服务器在每个请求上使用。'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won’t be downloaded from the Hub.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, 默认为 `False`) — 是否仅加载本地模型权重和配置文件。如果设置为
    `True`，模型将不会从 Hub 下载。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 *bool*, *optional*) — 用作远程文件的 HTTP 令牌的令牌。如果为 `True`，则使用从 `diffusers-cli
    login` 生成的令牌（存储在 `~/.huggingface`）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID
    或 Git 允许的任何标识符。'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) — The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *optional*, 默认为 `""`) — 模型文件在 Hub 或本地较大模型存储库中的子文件夹位置。'
- en: '`mirror` (`str`, *optional*) — Mirror source to resolve accessibility issues
    if you’re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror`（`str`，*可选*）— 如果您在下载中国的模型时遇到可访问性问题，请使用镜像源。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。'
- en: Load Textual Inversion embeddings into the text encoder of [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    (both 🤗 Diffusers and Automatic1111 formats are supported).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本反转嵌入加载到[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)的文本编码器中（支持🤗
    Diffusers和Automatic1111格式）。
- en: 'Example:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'To load a Textual Inversion embedding vector in 🤗 Diffusers format:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要在🤗 Diffusers格式中加载文本反转嵌入向量：
- en: '[PRE14]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To load a Textual Inversion embedding vector in Automatic1111 format, make sure
    to download the vector first (for example from [civitAI](https://civitai.com/models/3036?modelVersionId=9857))
    and then load the vector
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载Automatic1111格式的文本反转嵌入向量，请确保首先下载向量（例如从[civitAI](https://civitai.com/models/3036?modelVersionId=9857)）然后加载向量
- en: 'locally:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 本地：
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#### `from_single_file`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_single_file`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L141)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L141)'
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_link_or_path` (`str` or `os.PathLike`, *optional*) — Can
    be either:'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_link_or_path`（`str`或`os.PathLike`，*可选*）— 可以是：'
- en: A link to the `.ckpt` file (for example `"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`)
    on the Hub.
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Hub上链接到`.ckpt`文件（例如`"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`）。
- en: A path to a *file* containing all pipeline weights.
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有管道权重的*文件*路径。
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) — Override the default `torch.dtype`
    and load the model with another dtype.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype`（`str`或`torch.dtype`，*可选*）— 覆盖默认的`torch.dtype`并使用另一种dtype加载模型。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`Union[str, os.PathLike]`，*可选*）— 下载预训练模型配置的缓存路径，如果未使用标准缓存。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否恢复下载模型权重和配置文件。如果设置为`False`，则删除任何未完全下载的文件。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won’t be downloaded from the Hub.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only`（`bool`，*可选*，默认为`False`）— 是否仅加载本地模型权重和配置文件。如果设置为`True`，则不会从Hub下载模型。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`str`或*bool*，*可选*）— 用作远程文件的HTTP令牌的令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`中）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。可以是分支名称、标签名称、提交ID或Git允许的任何标识符。'
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) — If set to `None`,
    the safetensors weights are downloaded if they’re available **and** if the safetensors
    library is installed. If set to `True`, the model is forcibly loaded from safetensors
    weights. If set to `False`, safetensors weights are not loaded.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_safetensors`（`bool`，*可选*，默认为`None`）— 如果设置为`None`，则在可用时下载safetensors权重**并且**如果已安装safetensors库。如果设置为`True`，则强制从safetensors权重加载模型。如果设置为`False`，则不加载safetensors权重。'
- en: Instantiate a [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    from pretrained pipeline weights saved in the `.ckpt` or `.safetensors` format.
    The pipeline is set in evaluation mode (`model.eval()`) by default.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 从保存在`.ckpt`或`.safetensors`格式中的预训练管道权重实例化[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。默认情况下，管道设置为评估模式（`model.eval()`）。
- en: 'Examples:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `load_lora_weights`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    — See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path_or_dict`（`str`或`os.PathLike`或`dict`）— 参见[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)。'
- en: '`kwargs` (`dict`, *optional*) — See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`dict`，*可选*）— 参见[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)。'
- en: '`adapter_name` (`str`, *optional*) — Adapter name to be used for referencing
    the loaded adapter model. If not specified, it will use `default_{i}` where i
    is the total number of adapters being loaded.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`（`str`，*可选*）— 用于引用加载的适配器模型的适配器名称。如果未指定，将使用`default_{i}`，其中i是要加载的适配器总数。'
- en: Load LoRA weights specified in `pretrained_model_name_or_path_or_dict` into
    `self.unet` and `self.text_encoder`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 将在 `pretrained_model_name_or_path_or_dict` 中指定的 LoRA 权重加载到 `self.unet` 和 `self.text_encoder`
    中。
- en: All kwargs are forwarded to `self.lora_state_dict`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 kwargs 都将转发到 `self.lora_state_dict`。
- en: See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    for more details on how the state dict is loaded.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    以获取有关如何加载状态字典的更多详细信息。
- en: See [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    for more details on how the state dict is loaded into `self.unet`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    以获取有关如何将状态字典加载到 `self.unet` 中的更多详细信息。
- en: See [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    for more details on how the state dict is loaded into `self.text_encoder`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    以获取有关如何将状态字典加载到 `self.text_encoder` 中的更多详细信息。
- en: '#### `save_lora_weights`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
- en: '[PRE19]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory to save LoRA parameters
    to. Will be created if it doesn’t exist.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` 或 `os.PathLike`) — 保存 LoRA 参数的目录。如果不存在，将创建该目录。'
- en: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    — State dict of the LoRA layers corresponding to the `unet`.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` 或 `Dict[str, torch.Tensor]`)
    — 与 `unet` 对应的 LoRA 层的状态字典。'
- en: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    — State dict of the LoRA layers corresponding to the `text_encoder`. Must explicitly
    pass the text encoder LoRA state dict because it comes from 🤗 Transformers.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` 或 `Dict[str, torch.Tensor]`)
    — 与 `text_encoder` 对应的 LoRA 层的状态字典。必须显式传递文本编码器 LoRA 状态字典，因为它来自 🤗 Transformers。'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) — Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *可选*, 默认为 `True`) — 调用此函数的进程是否为主进程。在分布式训练期间，当您需要在所有进程上调用此函数时，这很有用。在这种情况下，仅在主进程上设置
    `is_main_process=True`，以避免竞争条件。'
- en: '`save_function` (`Callable`) — The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function` (`Callable`) — 用于保存状态字典的函数。在分布式训练期间，当您需要用另一种方法替换 `torch.save`
    时，这很有用。可以使用环境变量 `DIFFUSERS_SAVE_MODE` 进行配置。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *可选*, 默认为 `True`) — 是否使用 `safetensors` 保存模型，还是使用传统的
    PyTorch 方法与 `pickle`。'
- en: Save the LoRA parameters corresponding to the UNet and text encoder.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 保存与 UNet 和文本编码器对应的 LoRA 参数。
- en: '#### `disable_freeu`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L678)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L678)'
- en: '[PRE20]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已启用，则禁用 FreeU 机制。
- en: '#### `enable_freeu`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L656)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L656)'
- en: '[PRE21]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1` (`float`) — 第 1 阶段的缩放因子，用于减弱跳跃特征的贡献。这样做是为了减轻增强去噪过程中的“过度平滑效应”。'
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2` (`float`) — 第 2 阶段的缩放因子，用于减弱跳跃特征的贡献。这样做是为了减轻增强去噪过程中的“过度平滑效应”。'
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1` (`float`) — 第 1 阶段的缩放因子，用于放大骨干特征的贡献。'
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2` (`float`) — 第 2 阶段的缩放因子，用于放大骨干特征的贡献。'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 FreeU 机制，如 [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)
    中所述。
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子后缀表示它们应用的阶段。
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同管道（如 Stable Diffusion
    v1、v2 和 Stable Diffusion XL）的值组合。
- en: '#### `encode_prompt`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L312)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L312)'
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 要编码的提示设备 — (`torch.device`): torch 设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用分类器自由指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`（`str`或`List[str]`，*可选*）— 不用来引导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。在不使用引导时被忽略（即，如果`guidance_scale`小于`1`，则被忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，文本嵌入将从`prompt`输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale`（`float`，*可选*）— 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的LoRA比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip`（`int`，*可选*）— 从CLIP中跳过的层数，用于计算提示嵌入。值为1意味着将使用预最终层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器的隐藏状态。
- en: '#### `fuse_qkv_projections`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `fuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L683)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L683)'
- en: '[PRE23]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`unet` (`bool`, defaults to `True`) — To apply fusion on the UNet.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（默认为`True`）— 对UNet应用融合。'
- en: '`vae` (`bool`, defaults to `True`) — To apply fusion on the VAE.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（默认为`True`）— 对VAE应用融合。'
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 启用融合的QKV投影。对于自注意力模块，所有投影矩阵（即查询、键、值）都被融合。对于交叉注意力模块，键和值投影矩阵被融合。
- en: This API is 🧪 experimental.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此API为🧪实验性质。
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_guidance_scale_embedding`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L744)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L744)'
- en: '[PRE24]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`timesteps` (`torch.Tensor`) — generate embedding vectors at these timesteps'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps`（`torch.Tensor`）— 在这些时间步生成嵌入向量'
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) — dimension of the embeddings
    to generate dtype — data type of the generated embeddings'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dim`（`int`，*可选*，默认为512）— 要生成的嵌入的维度dtype — 生成的嵌入的数据类型。'
- en: Returns
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为`(len(timesteps), embedding_dim)`的嵌入向量
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 参见[https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
- en: '#### `unfuse_qkv_projections`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unfuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L715)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L715)'
- en: '[PRE25]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`unet` (`bool`, defaults to `True`) — To apply fusion on the UNet.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（默认为`True`）— 对UNet应用融合。'
- en: '`vae` (`bool`, defaults to `True`) — To apply fusion on the VAE.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（`bool`，默认为`True`）— 对VAE应用融合。'
- en: Disable QKV projection fusion if enabled.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用，禁用QKV投影融合。
- en: This API is 🧪 experimental.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 此API为🧪实验性质。
- en: StableDiffusionPipelineOutput
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE26]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images`（`List[PIL.Image.Image]`或`np.ndarray`）— 长度为`batch_size`的去噪PIL图像列表或形状为`(batch_size,
    height, width, num_channels)`的NumPy数组。'
- en: '`nsfw_content_detected` (`List[bool]`) — List indicating whether the corresponding
    generated image contains “not-safe-for-work” (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected`（`List[bool]`）— 表示相应生成的图像是否包含“不安全内容”（nsfw）的列表，如果无法执行安全检查，则为`None`。'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散管道的输出类。
- en: FlaxStableDiffusionPipeline
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxStableDiffusionPipeline
- en: '### `class diffusers.FlaxStableDiffusionPipeline`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.FlaxStableDiffusionPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L81)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L81)'
- en: '[PRE27]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([FlaxAutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.FlaxAutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（[FlaxAutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.FlaxAutoencoderKL)）—
    变分自动编码器（VAE）模型，用于将图像编码和解码为潜在表示。'
- en: '`text_encoder` ([FlaxCLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([FlaxCLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPTextModel))
    — 冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 一个用于对文本进行标记化的`CLIPTokenizer`。'
- en: '`unet` ([FlaxUNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.FlaxUNet2DConditionModel))
    — A `FlaxUNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([FlaxUNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.FlaxUNet2DConditionModel))
    — 一个用于去噪编码图像潜在变量的`FlaxUNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of `FlaxDDIMScheduler`, `FlaxLMSDiscreteScheduler`, `FlaxPNDMScheduler`,
    or `FlaxDPMSolverMultistepScheduler`.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 与`unet`结合使用的调度器，用于去噪编码图像潜在变量。可以是`FlaxDDIMScheduler`、`FlaxLMSDiscreteScheduler`、`FlaxPNDMScheduler`或`FlaxDPMSolverMultistepScheduler`之一。'
- en: '`safety_checker` (`FlaxStableDiffusionSafetyChecker`) — Classification module
    that estimates whether generated images could be considered offensive or harmful.
    Please refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`FlaxStableDiffusionSafetyChecker`) — 一个分类模块，用于估计生成的图像是否可能被认为是冒犯或有害的。请参考[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 一个用于从生成的图像中提取特征的`CLIPImageProcessor`；作为`安全检查器`的输入。'
- en: Flax-based pipeline for text-to-image generation using Stable Diffusion.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 使用稳定扩散进行文本到图像生成的基于Flax的管道。
- en: This model inherits from [FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[FlaxDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.FlaxDiffusionPipeline)。查看超类文档以获取所有管道实现的通用方法（下载、保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L310)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L310)'
- en: '[PRE28]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成的提示或提示。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 7.5) — 更高的引导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`latents` (`jnp.ndarray`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    array is generated by sampling using the supplied random `generator`.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`jnp.ndarray`, *可选*) — 从高斯分布中预先生成的嘈杂潜在变量，用作图像生成的输入。可以用来调整相同生成与不同提示的生成。如果未提供，则通过使用提供的随机`generator`进行采样生成一个潜在变量数组。'
- en: '`jit` (`bool`, defaults to `False`) — Whether to run `pmap` versions of the
    generation and safety scoring functions.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jit` (`bool`, 默认为 `False`) — 是否运行生成和安全评分函数的`pmap`版本。'
- en: This argument exists because `__call__` is not yet end-to-end pmap-able. It
    will be removed in a future release.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个参数存在是因为`__call__`目前还不能完全进行pmap。它将在将来的版本中被移除。
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回一个[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)而不是一个普通的元组。'
- en: Returns
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[FlaxStableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput)，否则返回一个`tuple`，其中第一个元素是包含生成图像的列表，第二个元素是一个列表，指示相应生成的图像是否包含“不安全内容”（nsfw）。
- en: The call function to the pipeline for generation.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: FlaxStableDiffusionPipelineOutput
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxStableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput`'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L31)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L31)'
- en: '[PRE30]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`np.ndarray`) — Denoised images of array shape of `(batch_size, height,
    width, num_channels)`.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`np.ndarray`) — 形状为`(batch_size, height, width, num_channels)`的去噪图像数组。'
- en: '`nsfw_content_detected` (`List[bool]`) — List indicating whether the corresponding
    generated image contains “not-safe-for-work” (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) — 列表指示相应生成的图像是否包含“不安全内容”（nsfw），或者如果无法执行安全检查，则为`None`。'
- en: Output class for Flax-based Stable Diffusion pipelines.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: Flax基础稳定扩散管道的输出类。
- en: '#### `replace`'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `replace`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
- en: '[PRE31]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: “Returns a new object replacing the specified fields with new values.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: “返回一个用新值替换指定字段的新对象。
