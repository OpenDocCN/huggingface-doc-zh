# XLSR-Wav2Vec2

> 原文：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xlsr_wav2vec2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xlsr_wav2vec2)

## 概述

XLSR-Wav2Vec2模型是由Alexis Conneau，Alexei Baevski，Ronan Collobert，Abdelrahman Mohamed，Michael Auli在[无监督跨语言表示学习语音识别](https://arxiv.org/abs/2006.13979)中提出的。

论文摘要如下：

*本文介绍了XLSR，通过在多种语言的语音的原始波形上预训练单一模型来学习跨语言语音表示。我们构建在wav2vec 2.0的基础上，该模型通过解决对掩码潜在语音表示的对比任务进行训练，并共同学习跨语言共享的潜在量化。结果模型在标记数据上进行微调，实验表明跨语言预训练明显优于单语言预训练。在CommonVoice基准测试中，XLSR相对音素错误率降低了72%，相对于已知最佳结果。在BABEL上，我们的方法相对于类似系统改善了16%的词错误率。我们的方法实现了一个单一的多语言语音识别模型，与强大的个体模型竞争。分析表明，潜在的离散语音表示在不同语言之间共享，对于相关语言的共享增加。我们希望通过发布在53种语言中预训练的大型模型XLSR-53来促进低资源语音理解的研究。*

原始代码可以在[这里](https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec)找到。

## 使用提示

+   XLSR-Wav2Vec2是一个语音模型，接受与语音信号的原始波形对应的浮点数组。

+   XLSR-Wav2Vec2模型是使用连接主义时间分类（CTC）进行训练的，因此模型输出必须使用[Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)进行解码。

XLSR-Wav2Vec2的架构基于Wav2Vec2模型，因此可以参考[Wav2Vec2的文档页面](wav2vec2)。
