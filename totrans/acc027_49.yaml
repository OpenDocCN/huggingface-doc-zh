- en: Helpful Utilities
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有用的工具
- en: 'Original text: [https://huggingface.co/docs/accelerate/package_reference/utilities](https://huggingface.co/docs/accelerate/package_reference/utilities)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/accelerate/package_reference/utilities](https://huggingface.co/docs/accelerate/package_reference/utilities)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Below are a variety of utility functions that 🤗 Accelerate provides, broken
    down by use-case.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是🤗 Accelerate提供的各种实用函数，按用例分类。
- en: Constants
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常量
- en: Constants used throughout 🤗 Accelerate for reference
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 用于参考的🤗 Accelerate中使用的常量
- en: The following are constants used when utilizing [Accelerator.save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在使用[Accelerator.save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)时使用的常量
- en: '`utils.MODEL_NAME`: `"pytorch_model"` `utils.OPTIMIZER_NAME`: `"optimizer"`
    `utils.RNG_STATE_NAME`: `"random_states"` `utils.SCALER_NAME`: `"scaler.pt` `utils.SCHEDULER_NAME`:
    `"scheduler`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`utils.MODEL_NAME`: `"pytorch_model"` `utils.OPTIMIZER_NAME`: `"optimizer"`
    `utils.RNG_STATE_NAME`: `"random_states"` `utils.SCALER_NAME`: `"scaler.pt` `utils.SCHEDULER_NAME`:
    `"scheduler`'
- en: The following are constants used when utilizing [Accelerator.save_model()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_model)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在使用[Accelerator.save_model()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_model)时使用的常量
- en: '`utils.WEIGHTS_NAME`: `"pytorch_model.bin"` `utils.SAFE_WEIGHTS_NAME`: `"model.safetensors"`
    `utils.WEIGHTS_INDEX_NAME`: `"pytorch_model.bin.index.json"` `utils.SAFE_WEIGHTS_INDEX_NAME`:
    `"model.safetensors.index.json"`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`utils.WEIGHTS_NAME`: `"pytorch_model.bin"` `utils.SAFE_WEIGHTS_NAME`: `"model.safetensors"`
    `utils.WEIGHTS_INDEX_NAME`: `"pytorch_model.bin.index.json"` `utils.SAFE_WEIGHTS_INDEX_NAME`:
    `"model.safetensors.index.json"`'
- en: Data Classes
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据类
- en: These are basic dataclasses used throughout 🤗 Accelerate and they can be passed
    in as parameters.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在🤗 Accelerate中使用的基本数据类，可以作为参数传递。
- en: Standalone
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 独立的
- en: These are standalone dataclasses used for checks, such as the type of distributed
    system being used
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是用于检查的独立数据类，例如正在使用的分布式系统类型
- en: '### `class accelerate.utils.ComputeEnvironment`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.ComputeEnvironment`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L329)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L329)'
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Represents a type of the compute environment.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 代表计算环境的一种类型。
- en: 'Values:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 值：
- en: '`LOCAL_MACHINE` — private/custom cluster hardware.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LOCAL_MACHINE` — 私有/自定义集群硬件。'
- en: '`AMAZON_SAGEMAKER` — Amazon SageMaker as compute environment.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AMAZON_SAGEMAKER` — Amazon SageMaker作为计算环境。'
- en: '### `class accelerate.DistributedType`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.DistributedType`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L285)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L285)'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Represents a type of distributed environment.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 代表一种分布式环境类型。
- en: 'Values:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 值：
- en: '`NO` — Not a distributed environment, just a single process.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NO` — 不是分布式环境，只是单个进程。'
- en: '`MULTI_CPU` — Distributed on multiple CPU nodes.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MULTI_CPU` — 在多个CPU节点上分布。'
- en: '`MULTI_GPU` — Distributed on multiple GPUs.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MULTI_GPU` — 在多个GPU上分布。'
- en: '`MULTI_NPU` — Distributed on multiple NPUs.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MULTI_NPU` — 在多个NPU上分布。'
- en: '`MULTI_XPU` — Distributed on multiple XPUs.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MULTI_XPU` — 在多个XPU上分布。'
- en: '`DEEPSPEED` — Using DeepSpeed.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEEPSPEED` — 使用DeepSpeed。'
- en: '`TPU` — Distributed on TPUs.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TPU` — 在TPU上分布。'
- en: '### `class accelerate.utils.DynamoBackend`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.DynamoBackend`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L344)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L344)'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Represents a dynamo backend (see [https://github.com/pytorch/torchdynamo](https://github.com/pytorch/torchdynamo)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 代表一个dynamo后端（参见[https://github.com/pytorch/torchdynamo](https://github.com/pytorch/torchdynamo)）。
- en: 'Values:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 值：
- en: '`NO` — Do not use torch dynamo.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NO` — 不使用torch dynamo。'
- en: '`EAGER` — Uses PyTorch to run the extracted GraphModule. This is quite useful
    in debugging TorchDynamo issues.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EAGER` — 使用PyTorch来运行提取的GraphModule。在调试TorchDynamo问题时非常有用。'
- en: '`AOT_EAGER` — Uses AotAutograd with no compiler, i.e, just using PyTorch eager
    for the AotAutograd’s extracted forward and backward graphs. This is useful for
    debugging, and unlikely to give speedups.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AOT_EAGER` — 使用AotAutograd而不使用编译器，即仅使用PyTorch eager进行AotAutograd的提取的前向和后向图。这对调试很有用，不太可能提供加速。'
- en: '`INDUCTOR` — Uses TorchInductor backend with AotAutograd and cudagraphs by
    leveraging codegened Triton kernels. [Read more](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`INDUCTOR` — 使用TorchInductor后端与AotAutograd和cudagraphs，通过利用codegened Triton内核。[阅读更多](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)'
- en: '`AOT_TS_NVFUSER` — nvFuser with AotAutograd/TorchScript. [Read more](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AOT_TS_NVFUSER` — 使用AotAutograd/TorchScript的nvFuser。[阅读更多](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)'
- en: '`NVPRIMS_NVFUSER` — nvFuser with PrimTorch. [Read more](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NVPRIMS_NVFUSER` — 使用PrimTorch的nvFuser。[阅读更多](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)'
- en: '`CUDAGRAPHS` — cudagraphs with AotAutograd. [Read more](https://github.com/pytorch/torchdynamo/pull/757)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CUDAGRAPHS` — 使用AotAutograd的cudagraphs。[阅读更多](https://github.com/pytorch/torchdynamo/pull/757)'
- en: '`OFI` — Uses Torchscript optimize_for_inference. Inference only. [Read more](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OFI` — 使用Torchscript optimize_for_inference。仅推理。[阅读更多](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)'
- en: '`FX2TRT` — Uses Nvidia TensorRT for inference optimizations. Inference only.
    [Read more](https://github.com/pytorch/TensorRT/blob/master/docsrc/tutorials/getting_started_with_fx_path.rst)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FX2TRT` — 使用Nvidia TensorRT进行推理优化。仅推理。[阅读更多](https://github.com/pytorch/TensorRT/blob/master/docsrc/tutorials/getting_started_with_fx_path.rst)'
- en: '`ONNXRT` — Uses ONNXRT for inference on CPU/GPU. Inference only. [Read more](https://onnxruntime.ai/)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ONNXRT` — 使用ONNXRT在CPU/GPU上进行推理。仅推理。[阅读更多](https://onnxruntime.ai/)'
- en: '`TENSORRT` — Uses ONNXRT to run TensorRT for inference optimizations. [Read
    more](https://github.com/onnx/onnx-tensorrt)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TENSORRT` — 使用ONNXRT来运行TensorRT进行推理优化。[阅读更多](https://github.com/onnx/onnx-tensorrt)'
- en: '`IPEX` — Uses IPEX for inference on CPU. Inference only. [Read more](https://github.com/intel/intel-extension-for-pytorch).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IPEX` — 在CPU上使用IPEX进行推断。仅推断。[阅读更多](https://github.com/intel/intel-extension-for-pytorch)。'
- en: '`TVM` — Uses Apach TVM for inference optimizations. [Read more](https://tvm.apache.org/)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TVM` — 使用Apach TVM进行推断优化。[阅读更多](https://tvm.apache.org/)'
- en: '### `class accelerate.utils.LoggerType`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.LoggerType`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L392)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L392)'
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Represents a type of supported experiment tracker
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表示支持的实验跟踪器类型
- en: 'Values:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 值：
- en: '`ALL` — all available trackers in the environment that are supported'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ALL` — 环境中所有可用的受支持跟踪器'
- en: '`TENSORBOARD` — TensorBoard as an experiment tracker'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TENSORBOARD` — TensorBoard作为实验跟踪器'
- en: '`WANDB` — wandb as an experiment tracker'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WANDB` — wandb作为实验跟踪器'
- en: '`COMETML` — comet_ml as an experiment tracker'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`COMETML` — comet_ml作为实验跟踪器'
- en: '`DVCLIVE` — dvclive as an experiment tracker'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DVCLIVE` — dvclive作为实验跟踪器'
- en: '### `class accelerate.utils.PrecisionType`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.PrecisionType`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L414)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L414)'
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Represents a type of precision used on floating point values
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表示浮点值上使用的精度类型
- en: 'Values:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 值：
- en: '`NO` — using full precision (FP32)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NO` — 使用全精度（FP32）'
- en: '`FP16` — using half precision'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FP16` — 使用半精度'
- en: '`BF16` — using brain floating point precision'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BF16` — 使用脑浮点精度'
- en: '### `class accelerate.utils.RNGType`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.RNGType`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L430)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L430)'
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: An enumeration.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个枚举。
- en: '### `class accelerate.utils.SageMakerDistributedType`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.SageMakerDistributedType`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L312)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L312)'
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Represents a type of distributed environment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表示分布式环境类型。
- en: 'Values:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 值：
- en: '`NO` — Not a distributed environment, just a single process.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NO` — 不是分布式环境，只是一个单一进程。'
- en: '`DATA_PARALLEL` — using sagemaker distributed data parallelism.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DATA_PARALLEL` — 使用sagemaker分布式数据并行。'
- en: '`MODEL_PARALLEL` — using sagemaker distributed model parallelism.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL_PARALLEL` — 使用sagemaker分布式模型并行。'
- en: Kwargs
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kwargs
- en: These are configurable arguments for specific interactions throughout the PyTorch
    ecosystem that Accelerate handles under the hood.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是加速在幕后处理的PyTorch生态系统中特定交互的可配置参数。
- en: '### `class accelerate.AutocastKwargs`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.AutocastKwargs`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L60)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L60)'
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Use this object in your [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    to customize how `torch.autocast` behaves. Please refer to the documentation of
    this [context manager](https://pytorch.org/docs/stable/amp.html#torch.autocast)
    for more information on each argument.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)中使用此对象，以自定义`torch.autocast`的行为。请参考此[上下文管理器](https://pytorch.org/docs/stable/amp.html#torch.autocast)的文档，以获取有关每个参数的更多信息。
- en: 'Example:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '### `class accelerate.DistributedDataParallelKwargs`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.DistributedDataParallelKwargs`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L82)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L82)'
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Use this object in your [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    to customize how your model is wrapped in a `torch.nn.parallel.DistributedDataParallel`.
    Please refer to the documentation of this [wrapper](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)
    for more information on each argument.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)中使用此对象，以自定义如何将您的模型包装在`torch.nn.parallel.DistributedDataParallel`中。请参考此[包装器](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)的文档，以获取有关每个参数的更多信息。
- en: '`gradient_as_bucket_view` is only available in PyTorch 1.7.0 and later versions.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`gradient_as_bucket_view` 仅在PyTorch 1.7.0及更高版本中可用。'
- en: '`static_graph` is only available in PyTorch 1.11.0 and later versions.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`static_graph` 仅在PyTorch 1.11.0及更高版本中可用。'
- en: 'Example:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '### `class accelerate.utils.FP8RecipeKwargs`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.FP8RecipeKwargs`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L179)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L179)'
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`backend` (`str`, *optional*, defaults to “msamp”) — Which FP8 engine to use.
    Must be one of `"msamp"` (MS-AMP) or `"te"` (TransformerEngine).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backend` (`str`, *可选*, 默认为“msamp”) — 使用的FP8引擎。必须是`"msamp"`（MS-AMP）或`"te"`（TransformerEngine）之一。'
- en: '`margin` (`int`, *optional*, default to 0) — The margin to use for the gradient
    scaling.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`margin` (`int`, *可选*, 默认为0) — 用于梯度缩放的边距。'
- en: '`interval` (`int`, *optional*, default to 1) — The interval to use for how
    often the scaling factor is recomputed.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`interval` (`int`, *可选*, 默认为1) — 用于重新计算缩放因子的间隔。'
- en: '`fp8_format` (`str`, *optional*, default to “E4M3”) — The format to use for
    the FP8 recipe. Must be one of `E4M3` or `HYBRID`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fp8_format` (`str`, *可选*, 默认为“E4M3”) — 用于FP8配方的格式。必须是`E4M3`或`HYBRID`之一。'
- en: '`amax_history_len` (`int`, *optional*, default to 1024) — The length of the
    history to use for the scaling factor computation'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`amax_history_len` (`int`, *可选*, 默认为1024) — 用于缩放因子计算的历史长度'
- en: '`amax_compute_algo` (`str`, *optional*, default to “most_recent”) — The algorithm
    to use for the scaling factor computation. Must be one of `max` or `most_recent`.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`amax_compute_algo` (`str`, *可选*, 默认为“most_recent”) — 用于缩放因子计算的算法。必须是`max`或`most_recent`之一。'
- en: '`override_linear_precision` (`tuple` of three `bool`, *optional*, default to
    `(False, False, False)`) — Whether or not to execute `fprop`, `dgrad`, and `wgrad`
    GEMMS in higher precision.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`override_linear_precision`（三个`bool`的`tuple`，*可选*，默认为`(False, False, False)`）
    — 是否在更高精度中执行`fprop`、`dgrad`和`wgrad` GEMMS。'
- en: '`optimization_level` (`str`), one of `O1`, `O2`. (default is `O2`) — What level
    of 8-bit collective communication should be used with MS-AMP. In general:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimization_level`（`str`），其中之一为`O1`、`O2`。 （默认为`O2`） — 使用MS-AMP时应使用的8位集体通信级别。一般来说：'
- en: 'O1: Weight gradients and `all_reduce` communications are done in fp8, reducing
    GPU memory usage and communication bandwidth'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'O1: 权重梯度和`all_reduce`通信在fp8中完成，减少了GPU内存使用和通信带宽'
- en: 'O2: First-order optimizer states are in 8-bit, and second order states are
    in FP16. Only available when using Adam or AdamW. This maintains accuracy and
    can potentially save the highest memory.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'O2: 一阶优化器状态为8位，二阶状态为FP16。 仅在使用Adam或AdamW时可用。这可以保持准确性，并可能节省最高的内存。'
- en: '03: Specifically for DeepSpeed, implements capabilities so weights and master
    weights of models are stored in FP8\. If `fp8` is selected and deepspeed is enabled,
    will be used by default. (Not available currently).'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '03: 专门为DeepSpeed实现功能，使模型的权重和主权重存储在FP8中。如果选择了`fp8`并启用了deepspeed，则将默认使用（目前不可用）。'
- en: Use this object in your [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    to customize the initialization of the recipe for FP8 mixed precision training
    with `transformer-engine` or `ms-amp`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)中使用此对象，以自定义使用`transformer-engine`或`ms-amp`进行FP8混合精度训练的配方的初始化。
- en: For more information on `transformer-engine` args, please refer to the API [documentation](https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/api/common.html).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`transformer-engine`参数的更多信息，请参考API[文档](https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/api/common.html)。
- en: For more information on the `ms-amp` args, please refer to the Optimization
    Level [documentation](https://azure.github.io/MS-AMP/docs/user-tutorial/optimization-level).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`ms-amp`参数的更多信息，请参考优化级别[文档](https://azure.github.io/MS-AMP/docs/user-tutorial/optimization-level)。
- en: '[PRE12]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To use MS-AMP as an engine, pass `backend="msamp"` and the `optimization_level`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要将MS-AMP作为引擎使用，请传递`backend="msamp"`和`optimization_level`：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '### `class accelerate.GradScalerKwargs`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.GradScalerKwargs`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L118)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L118)'
- en: '[PRE14]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Use this object in your [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    to customize the behavior of mixed precision, specifically how the `torch.cuda.amp.GradScaler`
    used is created. Please refer to the documentation of this [scaler](https://pytorch.org/docs/stable/amp.html?highlight=gradscaler)
    for more information on each argument.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)中使用此对象，以自定义混合精度的行为，特别是如何创建所使用的`torch.cuda.amp.GradScaler`。请参考此[scaler](https://pytorch.org/docs/stable/amp.html?highlight=gradscaler)的文档，以获取有关每个参数的更多信息。
- en: '`GradScaler` is only available in PyTorch 1.5.0 and later versions.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`GradScaler`仅在PyTorch 1.5.0及更高版本中可用。'
- en: 'Example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '### `class accelerate.InitProcessGroupKwargs`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.InitProcessGroupKwargs`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L149)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L149)'
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Use this object in your [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    to customize the initialization of the distributed processes. Please refer to
    the documentation of this [method](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group)
    for more information on each argument.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)中使用此对象，以自定义分布式进程的初始化。请参考此[method](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group)的文档，以获取有关每个参数的更多信息。
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Plugins
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插件
- en: 'These are plugins that can be passed to the [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    object. While they are defined elsewhere in the documentation, for convenience
    all of them are available to see here:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是可以传递给[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)对象的插件。虽然它们在文档的其他地方定义，但为了方便，所有插件都可以在此处查看：
- en: '### `class accelerate.DeepSpeedPlugin`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.DeepSpeedPlugin`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L562)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L562)'
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This plugin is used to integrate DeepSpeed.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件用于集成DeepSpeed。
- en: '#### `deepspeed_config_process`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `deepspeed_config_process`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L756)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L756)'
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Process the DeepSpeed config with the values from the kwargs.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用kwargs中的值处理DeepSpeed配置。
- en: '### `class accelerate.FullyShardedDataParallelPlugin`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.FullyShardedDataParallelPlugin`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L872)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L872)'
- en: '[PRE20]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This plugin is used to enable fully sharded data parallelism.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件用于启用完全分片的数据并行。
- en: '#### `get_module_class_from_name`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_module_class_from_name`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1025)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1025)'
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`module` (`torch.nn.Module`) — The module to get the class from.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`module`（`torch.nn.Module`） — 要从中获取类的模块。'
- en: '`name` (`str`) — The name of the class.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`（`str`） — 类的名称。'
- en: Gets a class from a module by its name.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 通过名称从模块中获取一个类。
- en: '### `class accelerate.utils.GradientAccumulationPlugin`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.GradientAccumulationPlugin`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L505)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L505)'
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: A plugin to configure gradient accumulation behavior.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一个插件，用于配置梯度累积行为。
- en: '### `class accelerate.utils.MegatronLMPlugin`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.MegatronLMPlugin`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1105)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1105)'
- en: '[PRE23]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Plugin for Megatron-LM to enable tensor, pipeline, sequence and data parallelism.
    Also to enable selective activation recomputation and optimized fused kernels.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 用于Megatron-LM的插件，以启用张量、管道、序列和数据并行。还可启用选择性激活重计算和优化融合内核。
- en: '### `class accelerate.utils.TorchDynamoPlugin`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.TorchDynamoPlugin`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L526)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L526)'
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This plugin is used to compile a model with PyTorch 2.0
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件用于使用PyTorch 2.0编译模型
- en: Configurations
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: These are classes which can be configured and passed through to the appropriate
    integration
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是可以配置并传递给适当集成的类
- en: '### `class accelerate.utils.BnbQuantizationConfig`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.BnbQuantizationConfig`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1480)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1480)'
- en: '[PRE25]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: A plugin to enable BitsAndBytes 4bit and 8bit quantization
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一个插件，用于启用BitsAndBytes 4位和8位量化
- en: '### `class accelerate.utils.ProjectConfiguration`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class accelerate.utils.ProjectConfiguration`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L457)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L457)'
- en: '[PRE26]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Configuration for the Accelerator object based on inner-project needs.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内部项目需求的加速器对象的配置。
- en: '#### `set_directories`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_directories`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L495)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L495)'
- en: '[PRE27]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Sets `self.project_dir` and `self.logging_dir` to the appropriate values.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 将`self.project_dir`和`self.logging_dir`设置为适当的值。
- en: Environmental Variables
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境变量
- en: These are environmental variables that can be enabled for different use cases
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是可以为不同用例启用的环境变量
- en: '`ACCELERATE_DEBUG_MODE` (`str`): Whether to run accelerate in debug mode. More
    info available [here](../usage_guides/debug.md).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ACCELERATE_DEBUG_MODE`（`str`）：是否在调试模式下运行加速。更多信息请参阅[此处](../usage_guides/debug.md)。'
- en: Data Manipulation and Operations
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据操作和操作
- en: These include data operations that mimic the same `torch` ops but can be used
    on distributed processes.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括模拟相同`torch`操作的数据操作，但可以在分布式进程上使用。
- en: '#### `accelerate.utils.broadcast`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.broadcast`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L542)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L542)'
- en: '[PRE28]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tensor` (nested list/tuple/dictionary of `torch.Tensor`) — The data to gather.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensor`（嵌套列表/元组/张量字典的`torch.Tensor`）-要收集的数据。'
- en: '`from_process` (`int`, *optional*, defaults to 0) — The process from which
    to send the data'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_process`（`int`，*可选*，默认为0）-要发送数据的进程'
- en: Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to
    all devices.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 递归广播嵌套列表/元组/张量字典中的张量到所有设备。
- en: '#### `accelerate.utils.broadcast_object_list`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.broadcast_object_list`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L564)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L564)'
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`object_list` (list of picklable objects) — The list of objects to broadcast.
    This list will be modified inplace.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`object_list`（可拾取对象列表）-要广播的对象列表。此列表将被就地修改。'
- en: '`from_process` (`int`, *optional*, defaults to 0) — The process from which
    to send the data.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_process`（`int`，*可选*，默认为0）-要发送数据的进程。'
- en: Broadcast a list of picklable objects form one process to the others.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个进程向其他进程广播一个可拾取对象列表。
- en: '#### `accelerate.utils.concatenate`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.concatenate`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L605)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L605)'
- en: '[PRE30]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`data` (nested list/tuple/dictionary of lists of tensors `torch.Tensor`) —
    The data to concatenate.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data`（嵌套列表/元组/张量字典的张量列表`torch.Tensor`）-要连接的数据。'
- en: '`dim` (`int`, *optional*, defaults to 0) — The dimension on which to concatenate.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim`（`int`，*可选*，默认为0）-要连接的维度。'
- en: Recursively concatenate the tensors in a nested list/tuple/dictionary of lists
    of tensors with the same shape.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 递归连接具有相同形状的张量列表/元组/字典中的张量。
- en: '#### `accelerate.utils.convert_outputs_to_fp32`'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.convert_outputs_to_fp32`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L813)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L813)'
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '#### `accelerate.utils.convert_to_fp32`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.convert_to_fp32`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L766)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L766)'
- en: '[PRE32]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tensor` (nested list/tuple/dictionary of `torch.Tensor`) — The data to convert
    from FP16/BF16 to FP32.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensor`（嵌套列表/元组/张量字典的`torch.Tensor`）-要从FP16/BF16转换为FP32的数据。'
- en: Recursively converts the elements nested list/tuple/dictionary of tensors in
    FP16/BF16 precision to FP32.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 递归将FP16/BF16精度中的嵌套列表/元组/张量字典中的元素转换为FP32。
- en: '#### `accelerate.utils.gather`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.gather`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L422)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L422)'
- en: '[PRE33]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tensor` (nested list/tuple/dictionary of `torch.Tensor`) — The data to gather.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensor`（嵌套列表/元组/张量字典的`torch.Tensor`）-要收集的数据。'
- en: Recursively gather tensor in a nested list/tuple/dictionary of tensors from
    all devices.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 从所有设备中递归收集嵌套列表/元组/张量字典中的张量。
- en: '#### `accelerate.utils.gather_object`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.gather_object`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L449)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L449)'
- en: '[PRE34]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`object` (nested list/tuple/dictionary of picklable object) — The data to gather.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`对象`（嵌套的列表/元组/字典，包含可pickle对象）- 要收集的数据。'
- en: Recursively gather object in a nested list/tuple/dictionary of objects from
    all devices.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地从所有设备中的嵌套列表/元组/字典对象中收集对象。
- en: '#### `accelerate.utils.listify`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.listify`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L283)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L283)'
- en: '[PRE35]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`data` (nested list/tuple/dictionary of `torch.Tensor`) — The data from which
    to convert to regular numbers.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`数据`（嵌套的列表/元组/字典，包含`torch.Tensor`）- 要转换为常规数字的数据。'
- en: Recursively finds tensors in a nested list/tuple/dictionary and converts them
    to a list of numbers.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地查找嵌套列表/元组/字典中的张量，并将它们转换为数字列表。
- en: '#### `accelerate.utils.pad_across_processes`'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.pad_across_processes`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L631)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L631)'
- en: '[PRE36]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tensor` (nested list/tuple/dictionary of `torch.Tensor`) — The data to gather.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`张量`（嵌套的列表/元组/字典，包含`torch.Tensor`）- 要收集的数据。'
- en: '`dim` (`int`, *optional*, defaults to 0) — The dimension on which to pad.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim`（`int`，*可选*，默认为0）- 要填充的维度。'
- en: '`pad_index` (`int`, *optional*, defaults to 0) — The value with which to pad.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_index`（`int`，*可选*，默认为0）- 用于填充的值。'
- en: '`pad_first` (`bool`, *optional*, defaults to `False`) — Whether to pad at the
    beginning or the end.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_first`（`bool`，*可选*，默认为`False`）- 是否在开头或结尾填充。'
- en: Recursively pad the tensors in a nested list/tuple/dictionary of tensors from
    all devices to the same size so they can safely be gathered.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地填充来自所有设备的嵌套列表/元组/字典中的张量，使它们达到相同的大小，以便安全地收集。
- en: '#### `accelerate.utils.recursively_apply`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.recursively_apply`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L93)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L93)'
- en: '[PRE37]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`func` (`callable`) — The function to recursively apply.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`func`（`callable`）- 要递归应用的函数。'
- en: '`data` (nested list/tuple/dictionary of `main_type`) — The data on which to
    apply `func` *args — Positional arguments that will be passed to `func` when applied
    on the unpacked data.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`数据`（嵌套的列表/元组/字典，包含`main_type`）- 要应用`func`的数据*args- 当应用于解包数据时将传递给`func`的位置参数。'
- en: '`main_type` (`type`, *optional*, defaults to `torch.Tensor`) — The base type
    of the objects to which apply `func`.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main_type`（`type`，*可选*，默认为`torch.Tensor`）- 要应用`func`的对象的基本类型。'
- en: '`error_on_other_type` (`bool`, *optional*, defaults to `False`) — Whether to
    return an error or not if after unpacking `data`, we get on an object that is
    not of type `main_type`. If `False`, the function will leave objects of types
    different than `main_type` unchanged. **kwargs — Keyword arguments that will be
    passed to `func` when applied on the unpacked data.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`error_on_other_type`（`bool`，*可选*，默认为`False`）- 如果在解包`数据`后得到一个不是`main_type`类型的对象，是否返回错误。如果为`False`，函数将保持与`main_type`不同类型的对象不变。**kwargs-
    当应用于解包数据时将传递给`func`的关键字参数。'
- en: Recursively apply a function on a data structure that is a nested list/tuple/dictionary
    of a given base type.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地在给定基本类型的嵌套列表/元组/字典上应用函数。
- en: '#### `accelerate.utils.reduce`'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.reduce`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L724)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L724)'
- en: '[PRE38]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tensor` (nested list/tuple/dictionary of `torch.Tensor`) — The data to reduce.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`张量`（嵌套的列表/元组/字典，包含`torch.Tensor`）- 要减少的数据。'
- en: '`reduction` (`str`, *optional*, defaults to `"mean"`) — A reduction method.
    Can be of “mean”, “sum”, or “none”'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reduction`（`str`，*可选*，默认为`"mean"`）- 一种减少方法。可以是“mean”，“sum”或“none”'
- en: '`scale` (`float`, *optional*) — A default scaling value to be applied after
    the reduce, only valied on XLA.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale`（`float`，*可选*）- 在减少后应用的默认缩放值，仅在XLA上有效。'
- en: Recursively reduce the tensors in a nested list/tuple/dictionary of lists of
    tensors across all processes by the mean of a given operation.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 通过给定操作的平均值，递归地减少所有进程中的张量列表/元组/字典中的张量。
- en: '#### `accelerate.utils.send_to_device`'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.send_to_device`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L144)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L144)'
- en: '[PRE39]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Parameters
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tensor` (nested list/tuple/dictionary of `torch.Tensor`) — The data to send
    to a given device.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`张量`（嵌套的列表/元组/字典，包含`torch.Tensor`）- 要发送到指定设备的数据。'
- en: '`device` (`torch.device`) — The device to send the data to.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`（`torch.device`）- 要发送数据的设备。'
- en: Recursively sends the elements in a nested list/tuple/dictionary of tensors
    to a given device.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地将嵌套的列表/元组/字典中的元素发送到指定设备。
- en: '#### `accelerate.utils.slice_tensors`'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.slice_tensors`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L585)'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L585)'
- en: '[PRE40]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`data` (nested list/tuple/dictionary of `torch.Tensor`) — The data to slice.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`数据`（嵌套的列表/元组/字典，包含`torch.Tensor`）- 要切片的数据。'
- en: '`tensor_slice` (`slice`) — The slice to take.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensor_slice`（`slice`）- 要取的切片。'
- en: Recursively takes a slice in a nested list/tuple/dictionary of tensors.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地在嵌套的列表/元组/字典中的张量中取一个切片。
- en: Environment Checks
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境检查
- en: These functionalities check the state of the current working environment including
    information about the operating system itself, what it can support, and if particular
    dependencies are installed.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能检查当前工作环境的状态，包括有关操作系统本身的信息，它可以支持的内容，以及特定依赖项是否已安装。
- en: '#### `accelerate.utils.is_bf16_available`'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_bf16_available`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L130)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L130)'
- en: '[PRE41]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Checks if bf16 is supported, optionally ignoring the TPU
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 检查是否支持bf16，可选择忽略TPU
- en: '#### `accelerate.utils.is_ipex_available`'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_ipex_available`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L255)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L255)'
- en: '[PRE42]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '#### `accelerate.utils.is_mps_available`'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_mps_available`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L251)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L251)'
- en: '[PRE43]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '#### `accelerate.utils.is_npu_available`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_npu_available`'
- en: '[PRE44]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Checks if `torch_npu` is installed and potentially if a NPU is in the environment
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 检查是否安装了`torch_npu`，并且可能环境中是否有NPU
- en: '#### `accelerate.utils.is_torch_version`'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_torch_version`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/versions.py#L46)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/versions.py#L46)'
- en: '[PRE45]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`operation` (`str`) — A string representation of an operator, such as `">"`
    or `"<="`'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`operation`（`str`）— 操作符的字符串表示，例如`">"`或`"<="`'
- en: '`version` (`str`) — A string version of PyTorch'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version`（`str`）— PyTorch的字符串版本'
- en: Compares the current PyTorch version to a given reference with an operation.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 将当前的PyTorch版本与给定的参考版本进行比较。
- en: '#### `accelerate.utils.is_tpu_available`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_tpu_available`'
- en: '[PRE46]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Checks if `torch_xla` is installed and potentially if a TPU is in the environment
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 检查是否安装了`torch_xla`，并且可能环境中是否有TPU
- en: '#### `accelerate.utils.is_xpu_available`'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.is_xpu_available`'
- en: '[PRE47]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: check if user disables it explicitly
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 检查用户是否明确禁用它
- en: Environment Manipulation
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境操作
- en: '#### `accelerate.utils.patch_environment`'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.patch_environment`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L219)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L219)'
- en: '[PRE48]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: A context manager that will add each keyword argument passed to `os.environ`
    and remove them when exiting.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 一个上下文管理器，将每个关键字参数添加到`os.environ`中，并在退出时将它们删除。
- en: Will convert the values in `kwargs` to strings and upper-case all the keys.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 将`kwargs`中的值转换为字符串，并将所有键大写。
- en: 'Example:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE49]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '#### `accelerate.utils.clear_environment`'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.clear_environment`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L186)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L186)'
- en: '[PRE50]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: A context manager that will cache origin `os.environ` and replace it with a
    empty dictionary in this context.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 一个上下文管理器，将缓存的原始`os.environ`替换为一个空字典在这个上下文中。
- en: When this context exits, the cached `os.environ` will be back.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 当此上下文退出时，缓存的`os.environ`将恢复。
- en: 'Example:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE51]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '#### `accelerate.commands.config.default.write_basic_config`'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.commands.config.default.write_basic_config`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/commands/config/default.py#L29)'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/commands/config/default.py#L29)'
- en: '[PRE52]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Parameters
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`mixed_precision` (`str`, *optional*, defaults to “no”) — Mixed Precision to
    use. Should be one of “no”, “fp16”, or “bf16”'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixed_precision`（`str`，*可选*，默认为“no”）— 要使用的混合精度。应该是“no”，“fp16”或“bf16”中的一个。'
- en: '`save_location` (`str`, *optional*, defaults to `default_json_config_file`)
    — Optional custom save location. Should be passed to `--config_file` when using
    `accelerate launch`. Default location is inside the huggingface cache folder (`~/.cache/huggingface`)
    but can be overriden by setting the `HF_HOME` environmental variable, followed
    by `accelerate/default_config.yaml`.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_location`（`str`，*可选*，默认为`default_json_config_file`）— 可选的自定义保存位置。在使用`accelerate
    launch`时应传递给`--config_file`。默认位置位于huggingface缓存文件夹内（`~/.cache/huggingface`），但可以通过设置`HF_HOME`环境变量，然后跟随`accelerate/default_config.yaml`来覆盖。'
- en: '`use_xpu` (`bool`, *optional*, defaults to `False`) — Whether to use XPU if
    available.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_xpu`（`bool`，*可选*，默认为`False`）— 是否在可用时使用XPU。'
- en: Creates and saves a basic cluster config to be used on a local machine with
    potentially multiple GPUs. Will also set CPU if it is a CPU-only machine.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 创建并保存一个基本的集群配置，用于在本地机器上使用可能有多个GPU。如果是仅CPU的机器，还将设置CPU。
- en: When setting up 🤗 Accelerate for the first time, rather than running `accelerate
    config` [~utils.write_basic_config] can be used as an alternative for quick configuration.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 首次设置🤗 Accelerate时，可以使用`accelerate config`而不是运行[~utils.write_basic_config]作为快速配置的替代方法。
- en: Memory
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存
- en: '#### `accelerate.find_executable_batch_size`'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.find_executable_batch_size`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/memory.py#L83)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/memory.py#L83)'
- en: '[PRE53]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Parameters
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`function` (`callable`, *optional*) — A function to wrap'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`function`（`callable`，*可选*）— 要包装的函数'
- en: '`starting_batch_size` (`int`, *optional*) — The batch size to try and fit into
    memory'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`starting_batch_size`（`int`，*可选*）— 尝试适应内存的批量大小'
- en: A basic decorator that will try to execute `function`. If it fails from exceptions
    related to out-of-memory or CUDNN, the batch size is cut in half and passed to
    `function`
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本的装饰器，将尝试执行`function`。如果由于内存不足或CUDNN相关的异常而失败，则将批量大小减半并传递给`function`
- en: '`function` must take in a `batch_size` parameter as its first argument.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '`function`必须将`batch_size`参数作为其第一个参数。'
- en: 'Example:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE54]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Modeling
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模
- en: These utilities relate to interacting with PyTorch models
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实用程序与与PyTorch模型交互有关
- en: '#### `accelerate.utils.calculate_maximum_sizes`'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.calculate_maximum_sizes`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1004)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1004)'
- en: '[PRE55]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Computes the total size of the model and its largest layer
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 计算模型及其最大层的总大小
- en: '#### `accelerate.utils.compute_module_sizes`'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.compute_module_sizes`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L686)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L686)'
- en: '[PRE56]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Compute the size of each submodule of a given model.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 计算给定模型的每个子模块的大小。
- en: '#### `accelerate.utils.extract_model_from_parallel`'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.extract_model_from_parallel`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L56)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L56)'
- en: '[PRE57]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Parameters
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to extract.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要提取的模型。'
- en: '`keep_fp32_wrapper` (`bool`, *optional*) — Whether to remove mixed precision
    hooks from the model.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_fp32_wrapper` (`bool`, *可选*) — 是否从模型中删除混合精度钩子。'
- en: Returns
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.nn.Module`'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.nn.Module`'
- en: The extracted model.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 提取的模型。
- en: Extract a model from its distributed containers.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 从其分布式容器中提取模型。
- en: '#### `accelerate.utils.get_balanced_memory`'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.get_balanced_memory`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L872)'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L872)'
- en: '[PRE58]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Parameters
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to analyze.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要分析的模型。'
- en: '`max_memory` (`Dict`, *optional*) — A dictionary device identifier to maximum
    memory. Will default to the maximum memory available if unset. Example: `max_memory={0:
    "1GB"}`.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *可选*) — 设备标识符到最大内存的字典。如果未设置，将默认为可用的最大内存。示例：`max_memory={0:
    "1GB"}`。'
- en: '`no_split_module_classes` (`List[str]`, *optional*) — A list of layer class
    names that should never be split across device (for instance any layer that has
    a residual connection).'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_split_module_classes` (`List[str]`, *可选*) — 不应跨设备拆分的层类名列表（例如具有残差连接的任何层）。'
- en: '`dtype` (`str` or `torch.dtype`, *optional*) — If provided, the weights will
    be converted to that type when loaded.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`str` 或 `torch.dtype`, *可选*) — 如果提供，加载时将将权重转换为该类型。'
- en: '`special_dtypes` (`Dict[str, Union[str, torch.device]]`, *optional*) — If provided,
    special dtypes to consider for some specific weights (will override dtype used
    as default for all weights).'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_dtypes` (`Dict[str, Union[str, torch.device]]`, *可选*) — 如果提供，用于某些特定权重的特殊数据类型（将覆盖默认用于所有权重的
    dtype）。'
- en: '`low_zero` (`bool`, *optional*) — Minimizes the number of weights on GPU 0,
    which is convenient when it’s used for other operations (like the Transformers
    generate function).'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_zero` (`bool`, *可选*) — 最小化 GPU 0 上的权重数量，在其他操作（如 Transformers 生成函数）中使用时很方便。'
- en: Compute a `max_memory` dictionary for [infer_auto_device_map()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.infer_auto_device_map)
    that will balance the use of each available GPU.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 为 [infer_auto_device_map()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.infer_auto_device_map)
    计算一个 `max_memory` 字典，以平衡每个可用 GPU 的使用。
- en: All computation is done analyzing sizes and dtypes of the model parameters.
    As a result, the model can be on the meta device (as it would if initialized within
    the `init_empty_weights` context manager).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 所有计算都是通过分析模型参数的大小和数据类型来完成的。因此，模型可以位于元设备上（就像在 `init_empty_weights` 上下文管理器中初始化时一样）。
- en: '#### `accelerate.utils.get_max_layer_size`'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.get_max_layer_size`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L719)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L719)'
- en: '[PRE59]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Parameters
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`modules` (`List[Tuple[str, torch.nn.Module]]`) — The list of named modules
    where we want to determine the maximum layer size.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modules` (`List[Tuple[str, torch.nn.Module]]`) — 我们要确定最大层尺寸的命名模块列表。'
- en: '`module_sizes` (`Dict[str, int]`) — A dictionary mapping each layer name to
    its size (as generated by `compute_module_sizes`).'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`module_sizes` (`Dict[str, int]`) — 将每个层名称映射到其大小的字典（由 `compute_module_sizes`
    生成）。'
- en: '`no_split_module_classes` (`List[str]`) — A list of class names for layers
    we don’t want to be split.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_split_module_classes` (`List[str]`) — 不希望拆分的层类名列表。'
- en: Returns
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Tuple[int, List[str]]`'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tuple[int, List[str]]`'
- en: The maximum size of a layer with the list of layer names realizing that maximum
    size.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 具有实现最大尺寸的层名称列表的最大层尺寸。
- en: 'Utility function that will scan a list of named modules and return the maximum
    size used by one full layer. The definition of a layer being:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 将扫描命名模块列表并返回一个完整层使用的最大尺寸的实用函数。层的定义为：
- en: a module with no direct children (just parameters and buffers)
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有直接子级（只有参数和缓冲区）的模块
- en: a module whose class name is in the list `no_split_module_classes`
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类名在列表 `no_split_module_classes` 中的模块
- en: '#### `accelerate.infer_auto_device_map`'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.infer_auto_device_map`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1022)'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1022)'
- en: '[PRE60]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Parameters
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to analyze.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要分析的模型。'
- en: '`max_memory` (`Dict`, *optional*) — A dictionary device identifier to maximum
    memory. Will default to the maximum memory available if unset. Example: `max_memory={0:
    "1GB"}`.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *可选*) — 设备标识符到最大内存的字典。如果未设置，将默认为可用的最大内存。示例：`max_memory={0:
    "1GB"}`。'
- en: '`no_split_module_classes` (`List[str]`, *optional*) — A list of layer class
    names that should never be split across device (for instance any layer that has
    a residual connection).'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_split_module_classes` (`List[str]`, *可选*) — 不应跨设备拆分的层类名列表（例如具有残差连接的任何层）。'
- en: '`dtype` (`str` or `torch.dtype`, *optional*) — If provided, the weights will
    be converted to that type when loaded.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`str` 或 `torch.dtype`, *可选*) — 如果提供，加载时将将权重转换为该类型。'
- en: '`special_dtypes` (`Dict[str, Union[str, torch.device]]`, *optional*) — If provided,
    special dtypes to consider for some specific weights (will override dtype used
    as default for all weights).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_dtypes` (`Dict[str, Union[str, torch.device]]`, *可选*) — 如果提供，用于某些特定权重的特殊数据类型（将覆盖默认用于所有权重的
    dtype）。'
- en: '`verbose` (`bool`, *optional*, defaults to `False`) — Whether or not to provide
    debugging statements as the function builds the device_map.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose` (`bool`, *可选*, 默认为 `False`) — 是否在函数构建 device_map 时提供调试语句。'
- en: '`clean_result` (`bool`, *optional*, defaults to `True`) — Clean the resulting
    device_map by grouping all submodules that go on the same device together.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_result` (`bool`, *可选*, 默认为 `True`) — 通过将所有放在同一设备上的子模块分组来清理结果的 device_map。'
- en: 'Compute a device map for a given model giving priority to GPUs, then offload
    on CPU and finally offload to disk, such that:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 为给定模型计算设备映射，优先考虑GPU，然后转移到CPU，最后转移到磁盘，使得：
- en: we don’t exceed the memory available of any of the GPU.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不会超出任何GPU可用的内存。
- en: if offload to the CPU is needed, there is always room left on GPU 0 to put back
    the layer offloaded on CPU that has the largest size.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要转移到CPU，总是在GPU 0上留有空间，以将在CPU上转移的具有最大尺寸的层放回。
- en: if offload to the CPU is needed,we don’t exceed the RAM available on the CPU.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要转移到CPU，我们不会超出CPU可用的RAM。
- en: if offload to the disk is needed, there is always room left on the CPU to put
    back the layer offloaded on disk that has the largest size.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要转移到磁盘，总是在CPU上留有空间，以将在磁盘上转移的具有最大尺寸的层放回。
- en: All computation is done analyzing sizes and dtypes of the model parameters.
    As a result, the model can be on the meta device (as it would if initialized within
    the `init_empty_weights` context manager).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 所有计算都是通过分析模型参数的大小和数据类型来完成的。因此，模型可以在元设备上（就像在`init_empty_weights`上下文管理器中初始化时一样）。
- en: '#### `accelerate.load_checkpoint_in_model`'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.load_checkpoint_in_model`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1442)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1442)'
- en: '[PRE61]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Parameters
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model in which we want to load a checkpoint.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 我们要加载检查点的模型。'
- en: '`checkpoint` (`str` or `os.PathLike`) — The folder checkpoint to load. It can
    be:'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`checkpoint` (`str`或`os.PathLike`) — 要加载的文件夹检查点。它可以是：'
- en: a path to a file containing a whole model state dict
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含整个模型状态字典的文件路径。
- en: a path to a `.json` file containing the index to a sharded checkpoint
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含分片检查点索引的`.json`文件路径。
- en: a path to a folder containing a unique `.index.json` file and the shards of
    a checkpoint.
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含唯一的`.index.json`文件和检查点分片的文件夹路径。
- en: a path to a folder containing a unique pytorch_model.bin or a model.safetensors
    file.
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含唯一的pytorch_model.bin或model.safetensors文件的文件夹路径。
- en: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *optional*) — A map
    that specifies where each submodule should go. It doesn’t need to be refined to
    each parameter/buffer name, once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *可选*) — 一个指定每个子模块应该去哪里的映射。它不需要细化到每个参数/缓冲区名称，一旦给定模块名称在内，它的每个子模块都将被发送到相同的设备。'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) — If the `device_map`
    contains any value `"disk"`, the folder where we will offload weights.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str`或`os.PathLike`, *可选*) — 如果`device_map`包含任何值为`"disk"`，则我们将转移权重的文件夹。'
- en: '`dtype` (`str` or `torch.dtype`, *optional*) — If provided, the weights will
    be converted to that type when loaded.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`str`或`torch.dtype`, *可选*) — 如果提供，加载时权重将转换为该类型。'
- en: '`offload_state_dict` (`bool`, *optional*, defaults to `False`) — If `True`,
    will temporarily offload the CPU state dict on the hard drive to avoid getting
    out of CPU RAM if the weight of the CPU state dict + the biggest shard does not
    fit.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *可选*, 默认为`False`) — 如果为`True`，将临时将CPU状态字典转移到硬盘上，以避免如果CPU状态字典的权重+最大分片的权重不适合时超出CPU
    RAM。'
- en: '`offload_buffers` (`bool`, *optional*, defaults to `False`) — Whether or not
    to include the buffers in the weights offloaded to disk.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_buffers` (`bool`, *可选*, 默认为`False`) — 是否将缓冲区包含在转移到磁盘的权重中。'
- en: '`keep_in_fp32_modules(List[str],` *optional*) — A list of the modules that
    we keep in `torch.float32` dtype.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_in_fp32_modules(List[str],` *可选*) — 我们保留在`torch.float32`数据类型中的模块列表。'
- en: '`offload_8bit_bnb` (`bool`, *optional*) — Whether or not to enable offload
    of 8-bit modules on cpu/disk.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_8bit_bnb` (`bool`, *可选*) — 是否启用在cpu/disk上转移8位模块。'
- en: Loads a (potentially sharded) checkpoint inside a model, potentially sending
    weights to a given device as they are loaded.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型中加载（可能是分片的）检查点，可能在加载时将权重发送到指定的设备。
- en: Once loaded across devices, you still need to call [dispatch_model()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.dispatch_model)
    on your model to make it able to run. To group the checkpoint loading and dispatch
    in one single call, use [load_checkpoint_and_dispatch()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.load_checkpoint_and_dispatch).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦跨设备加载，您仍然需要在模型上调用[dispatch_model()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.dispatch_model)使其能够运行。要将检查点加载和分发组合在一个单一调用中，请使用[load_checkpoint_and_dispatch()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.load_checkpoint_and_dispatch)。
- en: '#### `accelerate.utils.load_offloaded_weights`'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.load_offloaded_weights`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L842)'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L842)'
- en: '[PRE62]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Parameters
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to load the weights into.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要加载权重的模型。'
- en: '`index` (`dict`) — A dictionary containing the parameter name and its metadata
    for each parameter that was offloaded from the model.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index` (`dict`) — 包含从模型转移的每个参数的参数名称及其元数据的字典。'
- en: '`offload_folder` (`str`) — The folder where the offloaded weights are stored.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str`) — 存储转移权重的文件夹。'
- en: Loads the weights from the offload folder into the model.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 将权重从转移文件夹加载到模型中。
- en: '#### `accelerate.utils.load_state_dict`'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.load_state_dict`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1301)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1301)'
- en: '[PRE63]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Parameters
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`checkpoint_file` (`str`) — The path to the checkpoint to load.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`checkpoint_file` (`str`) — 要加载的检查点路径。'
- en: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *optional*) — A map
    that specifies where each submodule should go. It doesn’t need to be refined to
    each parameter/buffer name, once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *可选*) — 指定每个子模块应该去的位置的映射。不需要对每个参数/缓冲区名称进行细化，一旦给定模块名称在内，它的每个子模块都将被发送到相同的设备。'
- en: Load a checkpoint from a given file. If the checkpoint is in the safetensors
    format and a device map is passed, the weights can be fast-loaded directly on
    the GPU.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定文件加载检查点。如果检查点是在safetensors格式中并且传递了设备映射，则权重可以直接快速加载到GPU上。
- en: '#### `accelerate.utils.offload_state_dict`'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.offload_state_dict`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/offload.py#L85)'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/offload.py#L85)'
- en: '[PRE64]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Parameters
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_dir` (`str` or `os.PathLike`) — The directory in which to offload the
    state dict.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_dir` (`str` 或 `os.PathLike`) — 要卸载状态字典的目录。'
- en: '`state_dict` (`Dict[str, torch.Tensor]`) — The dictionary of tensors to offload.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (`Dict[str, torch.Tensor]`) — 要卸载的张量字典。'
- en: Offload a state dict in a given folder.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定文件夹中卸载状态字典。
- en: '#### `accelerate.utils.retie_parameters`'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.retie_parameters`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L644)'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L644)'
- en: '[PRE65]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Parameters
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model in which to retie parameters.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要重新绑定参数的模型。'
- en: '`tied_params` (`List[List[str]]`) — A mapping parameter name to tied parameter
    name as obtained by `find_tied_parameters`.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tied_params` (`List[List[str]]`) — 通过`find_tied_parameters`获得的参数名称到绑定参数名称的映射。'
- en: Reties tied parameters in a given model if the link was broken (for instance
    when adding hooks).
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定模型中重新绑定绑定参数，如果链接被断开（例如添加钩子时）。
- en: '#### `accelerate.utils.set_module_tensor_to_device`'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.set_module_tensor_to_device`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L275)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L275)'
- en: '[PRE66]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Parameters
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`module` (`torch.nn.Module`) — The module in which the tensor we want to move
    lives.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`module` (`torch.nn.Module`) — 我们想要移动的张量所在的模块。'
- en: '`tensor_name` (`str`) — The full name of the parameter/buffer.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensor_name` (`str`) — 参数/缓冲区的完整名称。'
- en: '`device` (`int`, `str` or `torch.device`) — The device on which to set the
    tensor.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`int`, `str` 或 `torch.device`) — 要设置张量的设备。'
- en: '`value` (`torch.Tensor`, *optional*) — The value of the tensor (useful when
    going from the meta device to any other device).'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value` (`torch.Tensor`, *可选*) — 张量的值（在从元设备转到任何其他设备时有用）。'
- en: '`dtype` (`torch.dtype`, *optional*) — If passed along the value of the parameter
    will be cast to this `dtype`. Otherwise, `value` will be cast to the dtype of
    the existing parameter in the model.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`torch.dtype`, *可选*) — 如果传递了参数，参数的值将被转换为这个`dtype`。否则，`value`将被转换为模型中现有参数的`dtype`。'
- en: '`fp16_statistics` (`torch.HalfTensor`, *optional*) — The list of fp16 statistics
    to set on the module, used for 8 bit model serialization.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fp16_statistics` (`torch.HalfTensor`, *可选*) — 要设置在模块上的fp16统计信息列表，用于8位模型序列化。'
- en: '`tied_params_map` (Dict[int, Dict[torch.device, torch.Tensor]], *optional*,
    defaults to `None`) — A map of current data pointers to dictionaries of devices
    to already dispatched tied weights. For a given execution device, this parameter
    is useful to reuse the first available pointer of a shared weight on the device
    for all others, instead of duplicating memory.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tied_params_map` (Dict[int, Dict[torch.device, torch.Tensor]], *可选*, 默认为`None`)
    — 当前数据指针到已分派的绑定权重设备字典的映射。对于给定的执行设备，此参数对于重用设备上共享权重的第一个可用指针对于所有其他设备而言是有用的，而不是复制内存。'
- en: A helper function to set a given tensor (parameter of buffer) of a module on
    a specific device (note that doing `param.to(device)` creates a new tensor not
    linked to the parameter, which is why we need this function).
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 一个辅助函数，用于将模块的给定张量（参数或缓冲区）设置在特定设备上（请注意，执行`param.to(device)`会创建一个与参数不相关联的新张量，这就是为什么我们需要这个函数）。
- en: '#### `accelerate.utils.shard_checkpoint`'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.shard_checkpoint`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L193)'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L193)'
- en: '[PRE67]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Parameters
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`state_dict` (`Dict[str, torch.Tensor]`) — The state dictionary of a model
    to save.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (`Dict[str, torch.Tensor]`) — 要保存的模型的状态字典。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"10GB"`) — The maximum
    size of each sub-checkpoint. If expressed as a string, needs to be digits followed
    by a unit (like `"5MB"`).'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int` 或 `str`, *可选*, 默认为`"10GB"`) — 每个子检查点的最大大小。如果以字符串形式表示，需要是数字后跟一个单位（如`"5MB"`）。'
- en: '`weights_name` (`str`, *optional*, defaults to `"pytorch_model.bin"`) — The
    name of the model save file.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weights_name` (`str`, *可选*, 默认为`"pytorch_model.bin"`) — 模型保存文件的名称。'
- en: Splits a model state dictionary in sub-checkpoints so that the final size of
    each sub-checkpoint does not exceed a given size.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型状态字典拆分为子检查点，以便每个子检查点的最终大小不超过给定大小。
- en: The sub-checkpoints are determined by iterating through the `state_dict` in
    the order of its keys, so there is no optimization made to make each sub-checkpoint
    as close as possible to the maximum size passed. For example, if the limit is
    10GB and we have weights of sizes [6GB, 6GB, 2GB, 6GB, 2GB, 2GB] they will get
    sharded as [6GB], [6+2GB], [6+2+2GB] and not [6+2+2GB], [6+2GB], [6GB].
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 子检查点是通过按照其键的顺序迭代`state_dict`来确定的，因此没有优化使每个子检查点尽可能接近传递的最大大小。例如，如果限制为10GB，我们有大小为[6GB,
    6GB, 2GB, 6GB, 2GB, 2GB]的权重，它们将被分割为[6GB]，[6+2GB]，[6+2+2GB]，而不是[6+2+2GB]，[6+2GB]，[6GB]。
- en: If one of the model’s weight is bigger that `max_sahrd_size`, it will end up
    in its own sub-checkpoint which will have a size greater than `max_shard_size`.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型的权重之一大于`max_shard_size`，它将最终位于自己的子检查点中，其大小大于`max_shard_size`。
- en: Parallel
  id: totrans-465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行
- en: These include general utilities that should be used when working in parallel.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括应该在并行工作时使用的通用实用程序。
- en: '#### `accelerate.utils.extract_model_from_parallel`'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.extract_model_from_parallel`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L56)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L56)'
- en: '[PRE68]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Parameters
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to extract.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要提取的模型。'
- en: '`keep_fp32_wrapper` (`bool`, *optional*) — Whether to remove mixed precision
    hooks from the model.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_fp32_wrapper` (`bool`, *可选*) — 是否从模型中删除混合精度钩子。'
- en: Returns
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.nn.Module`'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.nn.Module`'
- en: The extracted model.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 提取的模型。
- en: Extract a model from its distributed containers.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 从其分布式容器中提取模型。
- en: '#### `accelerate.utils.save`'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.save`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L156)'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L156)'
- en: '[PRE69]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Parameters
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_on_each_node` (`bool`, *optional*, defaults to `False`) — Whether to
    only save on the global main process'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_on_each_node` (`bool`, *可选*, 默认为 `False`) — 是否仅在全局主进程上保存'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `False`) — Whether to
    save `obj` using `safetensors` or the traditional PyTorch way (that uses `pickle`).'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *可选*, 默认为 `False`) — 是否使用 `safetensors` 或传统的
    PyTorch 方式（使用 `pickle`）保存 `obj`。'
- en: Save the data to disk. Use in place of `torch.save()`.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据保存到磁盘。用于替代 `torch.save()`。
- en: '#### `accelerate.utils.wait_for_everyone`'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.wait_for_everyone`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L108)'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L108)'
- en: '[PRE70]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Introduces a blocking point in the script, making sure all processes have reached
    this point before continuing.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在脚本中引入一个阻塞点，确保所有进程在继续之前都已到达此点。
- en: Make sure all processes will reach this instruction otherwise one of your processes
    will hang forever.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 确保所有进程将到达此指令，否则其中一个进程将永远挂起。
- en: Random
  id: totrans-489
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机
- en: These utilities relate to setting and synchronizing of all the random states.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实用程序涉及设置和同步所有随机状态。
- en: '#### `accelerate.utils.set_seed`'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.set_seed`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L31)'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L31)'
- en: '[PRE71]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Parameters
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`seed` (`int`) — The seed to set.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seed` (`int`) — 要设置的种子。'
- en: '`device_specific` (`bool`, *optional*, defaults to `False`) — Whether to differ
    the seed on each device slightly with `self.process_index`.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_specific` (`bool`, *可选*, 默认为 `False`) — 是否稍微在每个设备上使用 `self.process_index`
    不同的种子。'
- en: Helper function for reproducible behavior to set the seed in `random`, `numpy`,
    `torch`.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在 `random`、`numpy`、`torch` 中设置种子以获得可重现行为的辅助函数。
- en: '#### `accelerate.utils.synchronize_rng_state`'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.synchronize_rng_state`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L57)'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L57)'
- en: '[PRE72]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '#### `accelerate.synchronize_rng_states`'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.synchronize_rng_states`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L109)'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L109)'
- en: '[PRE73]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: PyTorch XLA
  id: totrans-504
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch XLA
- en: These include utilities that are useful while using PyTorch with XLA.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括在使用 PyTorch 与 XLA 时有用的实用程序。
- en: '#### `accelerate.utils.install_xla`'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.install_xla`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/torch_xla.py#L20)'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/torch_xla.py#L20)'
- en: '[PRE74]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Parameters
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`upgrade` (`bool`, *optional*, defaults to `False`) — Whether to upgrade `torch`
    and install the latest `torch_xla` wheels.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upgrade` (`bool`, *可选*, 默认为 `False`) — 是否升级 `torch` 并安装最新的 `torch_xla` 轮子。'
- en: Helper function to install appropriate xla wheels based on the `torch` version
    in Google Colaboratory.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Colaboratory 中根据 `torch` 版本安装适当的 xla 轮子的辅助函数。
- en: 'Example:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE75]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Loading model weights
  id: totrans-514
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载模型权重
- en: These include utilities that are useful to load checkpoints.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括有用于加载检查点的实用程序。
- en: '#### `accelerate.load_checkpoint_in_model`'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.load_checkpoint_in_model`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1442)'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1442)'
- en: '[PRE76]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Parameters
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model in which we want to load a checkpoint.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 我们要加载检查点的模型。'
- en: '`checkpoint` (`str` or `os.PathLike`) — The folder checkpoint to load. It can
    be:'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`checkpoint` (`str` 或 `os.PathLike`) — 要加载的文件夹检查点。可以是：'
- en: a path to a file containing a whole model state dict
  id: totrans-522
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含整个模型状态字典的文件路径
- en: a path to a `.json` file containing the index to a sharded checkpoint
  id: totrans-523
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含指向分片检查点索引的`.json`文件的路径
- en: a path to a folder containing a unique `.index.json` file and the shards of
    a checkpoint.
  id: totrans-524
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含唯一的 `.index.json` 文件和检查点分片的文件夹路径。
- en: a path to a folder containing a unique pytorch_model.bin or a model.safetensors
    file.
  id: totrans-525
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含唯一的 pytorch_model.bin 或 model.safetensors 文件的文件夹路径。
- en: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *optional*) — A map
    that specifies where each submodule should go. It doesn’t need to be refined to
    each parameter/buffer name, once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *可选*) — 指定每个子模块应放置在何处的映射。它不需要被细化到每个参数/缓冲区名称，一旦给定模块名称在内部，它的每个子模块都将被发送到相同的设备。'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) — If the `device_map`
    contains any value `"disk"`, the folder where we will offload weights.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str` 或 `os.PathLike`, *可选*) — 如果 `device_map` 包含任何值 `"disk"`，则我们将卸载权重的文件夹。'
- en: '`dtype` (`str` or `torch.dtype`, *optional*) — If provided, the weights will
    be converted to that type when loaded.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`str` 或 `torch.dtype`, *可选*) — 如果提供，加载时将将权重转换为该类型。'
- en: '`offload_state_dict` (`bool`, *optional*, defaults to `False`) — If `True`,
    will temporarily offload the CPU state dict on the hard drive to avoid getting
    out of CPU RAM if the weight of the CPU state dict + the biggest shard does not
    fit.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *可选*, 默认为 `False`) — 如果为 `True`，将临时将 CPU 状态字典转移到硬盘上，以避免如果
    CPU 状态字典的重量 + 最大分片的重量不适合 CPU RAM。'
- en: '`offload_buffers` (`bool`, *optional*, defaults to `False`) — Whether or not
    to include the buffers in the weights offloaded to disk.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_buffers` (`bool`, *可选*, 默认为 `False`) — 是否将缓冲区包含在卸载到磁盘的权重中。'
- en: '`keep_in_fp32_modules(List[str],` *optional*) — A list of the modules that
    we keep in `torch.float32` dtype.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_in_fp32_modules(List[str],` *可选*) — 我们保留在 `torch.float32` 数据类型中的模块列表。'
- en: '`offload_8bit_bnb` (`bool`, *optional*) — Whether or not to enable offload
    of 8-bit modules on cpu/disk.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_8bit_bnb` (`bool`, *可选*) — 是否启用在cpu/磁盘上卸载8位模块。'
- en: Loads a (potentially sharded) checkpoint inside a model, potentially sending
    weights to a given device as they are loaded.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 加载（可能是分片的）检查点到模型中，可能在加载时将权重发送到给定设备。
- en: Once loaded across devices, you still need to call [dispatch_model()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.dispatch_model)
    on your model to make it able to run. To group the checkpoint loading and dispatch
    in one single call, use [load_checkpoint_and_dispatch()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.load_checkpoint_and_dispatch).
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在设备间加载完成，您仍然需要调用[dispatch_model()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.dispatch_model)来使模型能够运行。为了在一个单一调用中组合检查点加载和分发，可以使用[load_checkpoint_and_dispatch()](/docs/accelerate/v0.27.2/en/package_reference/big_modeling#accelerate.load_checkpoint_and_dispatch)。
- en: Quantization
  id: totrans-535
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量化
- en: These include utilities that are useful to quantize model.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括对量化模型有用的实用程序。
- en: '#### `accelerate.utils.load_and_quantize_model`'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `accelerate.utils.load_and_quantize_model`'
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/bnb.py#L44)'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/bnb.py#L44)'
- en: '[PRE77]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Parameters
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — Input model. The model can be already loaded
    or on the meta device'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 输入模型。该模型可以已经加载或在元设备上'
- en: '`bnb_quantization_config` (`BnbQuantizationConfig`) — The bitsandbytes quantization
    parameters'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bnb_quantization_config` (`BnbQuantizationConfig`) — 位和字节量化参数'
- en: '`weights_location` (`str` or `os.PathLike`) — The folder weights_location to
    load. It can be:'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weights_location` (`str` or `os.PathLike`) — 要加载的权重文件夹。可以是：'
- en: a path to a file containing a whole model state dict
  id: totrans-544
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含整个模型状态字典的文件路径
- en: a path to a `.json` file containing the index to a sharded checkpoint
  id: totrans-545
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含分片检查点索引的 `.json` 文件路径
- en: a path to a folder containing a unique `.index.json` file and the shards of
    a checkpoint.
  id: totrans-546
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含唯一的 `.index.json` 文件和检查点分片的文件夹路径。
- en: a path to a folder containing a unique pytorch_model.bin file.
  id: totrans-547
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含唯一的 pytorch_model.bin 文件的文件夹路径。
- en: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *optional*) — A map
    that specifies where each submodule should go. It doesn’t need to be refined to
    each parameter/buffer name, once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`Dict[str, Union[int, str, torch.device]]`, *可选*) — 指定每个子模块应该去哪里的映射。它不需要被细化到每个参数/缓冲区名称，一旦给定模块名称在内，它的每个子模块都将被发送到相同的设备。'
- en: '`no_split_module_classes` (`List[str]`, *optional*) — A list of layer class
    names that should never be split across device (for instance any layer that has
    a residual connection).'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_split_module_classes` (`List[str]`, *可选*) — 不应该跨设备分割的层类名称列表（例如具有残差连接的任何层）。'
- en: '`max_memory` (`Dict`, *optional*) — A dictionary device identifier to maximum
    memory. Will default to the maximum memory available if unset.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *可选*) — 设备标识符到最大内存的字典。如果未设置，将默认为可用的最大内存。'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) — If the `device_map`
    contains any value `"disk"`, the folder where we will offload weights.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str` or `os.PathLike`, *可选*) — 如果 `device_map` 包含任何值为 `"disk"`，则我们将卸载权重的文件夹。'
- en: '`offload_state_dict` (`bool`, *optional*, defaults to `False`) — If `True`,
    will temporarily offload the CPU state dict on the hard drive to avoid getting
    out of CPU RAM if the weight of the CPU state dict + the biggest shard does not
    fit.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *可选*, 默认为 `False`) — 如果为 `True`，将临时将CPU状态字典卸载到硬盘上，以避免如果CPU状态字典的重量
    + 最大分片的重量不适合时会超出CPU RAM。'
- en: Returns
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.nn.Module`'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.nn.Module`'
- en: The quantized model
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 量化后的模型
- en: This function will quantize the input model with the associated config passed
    in `bnb_quantization_config`. If the model is in the meta device, we will load
    and dispatch the weights according to the `device_map` passed. If the model is
    already loaded, we will quantize the model and put the model on the GPU,
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将使用传递给 `bnb_quantization_config` 的相关配置对输入模型进行量化。如果模型在元设备上，我们将根据传递的 `device_map`
    加载和分发权重。如果模型已经加载，我们将量化模型并将模型放在GPU上，
