# 关键字参数处理程序

> 原始文本：[https://huggingface.co/docs/accelerate/package_reference/kwargs](https://huggingface.co/docs/accelerate/package_reference/kwargs)

以下对象可以传递给主要的 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 来自定义与分布式训练或混合精度相关的一些 PyTorch 对象的创建方式。

## 自动转换关键字参数

### `class accelerate.AutocastKwargs`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L60)

```py
( enabled: bool = True cache_enabled: bool = None )
```

在您的 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 中使用此对象，以自定义 `torch.autocast` 的行为。请参阅此 [上下文管理器](https://pytorch.org/docs/stable/amp.html#torch.autocast) 的文档，以获取有关每个参数的更多信息。

示例：

```py
from accelerate import Accelerator
from accelerate.utils import AutocastKwargs

kwargs = AutocastKwargs(cache_enabled=True)
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

## DistributedDataParallelKwargs

### `class accelerate.DistributedDataParallelKwargs`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L82)

```py
( dim: int = 0 broadcast_buffers: bool = True bucket_cap_mb: int = 25 find_unused_parameters: bool = False check_reduction: bool = False gradient_as_bucket_view: bool = False static_graph: bool = False )
```

在您的 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 中使用此对象，以自定义如何将您的模型包装在 `torch.nn.parallel.DistributedDataParallel` 中。请参阅此 [包装器](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html) 的文档，以获取有关每个参数的更多信息。

`gradient_as_bucket_view` 仅适用于 PyTorch 1.7.0 及更高版本。

`static_graph` 仅适用于 PyTorch 1.11.0 及更高版本。

示例：

```py
from accelerate import Accelerator
from accelerate.utils import DistributedDataParallelKwargs

kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

## FP8RecipeKwargs

### `class accelerate.utils.FP8RecipeKwargs`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L179)

```py
( backend: Literal = 'MSAMP' opt_level: Literal = 'O2' margin: int = 0 interval: int = 1 fp8_format: Literal = 'E4M3' amax_history_len: int = 1 amax_compute_algo: Literal = 'most_recent' override_linear_precision: Tuple = (False, False, False) )
```

参数

+   `backend`（`str`，*可选*，默认为 `"msamp"`）— 要使用的 FP8 引擎。必须是 `"msamp"`（MS-AMP）或 `"te"`（TransformerEngine）之一。

+   `margin`（`int`，*可选*，默认为 0）— 用于梯度缩放的边距。

+   `interval`（`int`，*可选*，默认为 1）— 用于多久重新计算一次缩放因子的间隔。

+   `fp8_format`（`str`，*可选*，默认为 `E4M3`）— 用于 FP8 配方的格式。必须是 `E4M3` 或 `HYBRID` 之一。

+   `amax_history_len`（`int`，*可选*，默认为 1024）— 用于缩放因子计算的历史长度

+   `amax_compute_algo`（`str`，*可选*，默认为 `most_recent`）— 用于缩放因子计算的算法。必须是 `max` 或 `most_recent` 之一。

+   `override_linear_precision`（三个 `bool` 的 `tuple`，*可选*，默认为 `(False, False, False)`）— 是否在更高精度中执行 `fprop`、`dgrad` 和 `wgrad` GEMMS。

+   `optimization_level`（`str`），其中之一为 `O1`、`O2`。 （默认为 `O2`）— 应使用哪个级别的 8 位集体通信与 MS-AMP。一般来说：

    +   O1：权重梯度和 `all_reduce` 通信以 fp8 完成，减少 GPU 内存使用和通信带宽

    +   O2：一阶优化器状态为 8 位，二阶状态为 FP16。仅在使用 Adam 或 AdamW 时可用。这可以保持准确性并潜在地节省最高的内存。

    +   03：专门为 DeepSpeed 实现功能，使模型的权重和主权重存储在 FP8 中。如果选择了 `fp8` 并启用了 deepspeed，则将默认使用。 （目前不可用）。

在您的 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 中使用此对象，以自定义使用 `transformer-engine` 或 `ms-amp` 进行 FP8 混合精度训练的配方的初始化。

有关 `transformer-engine` 参数的更多信息，请参阅 API [文档](https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/api/common.html)。

有关 `ms-amp` 参数的更多信息，请参考优化级别 [文档](https://azure.github.io/MS-AMP/docs/user-tutorial/optimization-level)。

```py
from accelerate import Accelerator
from accelerate.utils import FP8RecipeKwargs

kwargs = FP8RecipeKwargs(backend="te", fp8_format="HYBRID")
accelerator = Accelerator(mixed_precision="fp8", kwargs_handlers=[kwargs])
```

要将 MS-AMP 用作引擎，请传递 `backend="msamp"` 和 `optimization_level`：

```py
kwargs = FP8RecipeKwargs(backend="msamp", optimization_level="02")
```

## GradScalerKwargs

### `class accelerate.GradScalerKwargs`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L118)

```py
( init_scale: float = 65536.0 growth_factor: float = 2.0 backoff_factor: float = 0.5 growth_interval: int = 2000 enabled: bool = True )
```

在您的 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 中使用此对象来自定义混合精度的行为，特别是如何创建 `torch.cuda.amp.GradScaler` 的使用。有关每个参数的更多信息，请参考此 [scaler](https://pytorch.org/docs/stable/amp.html?highlight=gradscaler) 的文档。

`GradScaler` 仅在 PyTorch 1.5.0 及更高版本中可用。

示例：

```py
from accelerate import Accelerator
from accelerate.utils import GradScalerKwargs

kwargs = GradScalerKwargs(backoff_filter=0.25)
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

## InitProcessGroupKwargs

### `class accelerate.InitProcessGroupKwargs`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L149)

```py
( backend: Optional = 'nccl' init_method: Optional = None timeout: timedelta = datetime.timedelta(seconds=1800) )
```

在您的 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 中使用此对象来自定义分布式进程的初始化。有关每个参数的更多信息，请参考此 [方法](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group) 的文档。

```py
from datetime import timedelta
from accelerate import Accelerator
from accelerate.utils import InitProcessGroupKwargs

kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=800))
accelerator = Accelerator(kwargs_handlers=[kwargs])
```
