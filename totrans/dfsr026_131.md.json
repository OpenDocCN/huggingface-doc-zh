["```py\n( vae: AutoencoderKL text_encoder: ClapTextModelWithProjection tokenizer: Union unet: UNet2DConditionModel scheduler: KarrasDiffusionSchedulers vocoder: SpeechT5HifiGan )\n```", "```py\n( prompt: Union = None audio_length_in_s: Optional = None num_inference_steps: int = 10 guidance_scale: float = 2.5 negative_prompt: Union = None num_waveforms_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None return_dict: bool = True callback: Optional = None callback_steps: Optional = 1 cross_attention_kwargs: Optional = None output_type: Optional = 'np' ) \u2192 export const metadata = 'undefined';AudioPipelineOutput or tuple\n```", "```py\n>>> from diffusers import AudioLDMPipeline\n>>> import torch\n>>> import scipy\n\n>>> repo_id = \"cvssp/audioldm-s-full-v2\"\n>>> pipe = AudioLDMPipeline.from_pretrained(repo_id, torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"Techno music with a strong, upbeat tempo and high melodic riffs\"\n>>> audio = pipe(prompt, num_inference_steps=10, audio_length_in_s=5.0).audios[0]\n\n>>> # save the audio sample as a .wav file\n>>> scipy.io.wavfile.write(\"techno.wav\", rate=16000, data=audio)\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( audios: ndarray )\n```"]