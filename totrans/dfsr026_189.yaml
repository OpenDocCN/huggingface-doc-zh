- en: DDPMScheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/ddpm](https://huggingface.co/docs/diffusers/api/schedulers/ddpm)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: '[Denoising Diffusion Probabilistic Models](https://huggingface.co/papers/2006.11239)
    (DDPM) by Jonathan Ho, Ajay Jain and Pieter Abbeel proposes a diffusion based
    model of the same name. In the context of the ü§ó Diffusers library, DDPM refers
    to the discrete denoising scheduler from the paper as well as the pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*We present high quality image synthesis results using diffusion probabilistic
    models, a class of latent variable models inspired by considerations from nonequilibrium
    thermodynamics. Our best results are obtained by training on a weighted variational
    bound designed according to a novel connection between diffusion probabilistic
    models and denoising score matching with Langevin dynamics, and our models naturally
    admit a progressive lossy decompression scheme that can be interpreted as a generalization
    of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an
    Inception score of 9.46 and a state-of-the-art FID score of 3.17\. On 256x256
    LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is
    available at [this https URL](https://github.com/hojonathanho/diffusion).*'
  prefs: []
  type: TYPE_NORMAL
- en: DDPMScheduler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.DDPMScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L129)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`num_train_timesteps` (`int`, defaults to 1000) ‚Äî The number of diffusion steps
    to train the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beta_start` (`float`, defaults to 0.0001) ‚Äî The starting `beta` value of inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beta_end` (`float`, defaults to 0.02) ‚Äî The final `beta` value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beta_schedule` (`str`, defaults to `"linear"`) ‚Äî The beta schedule, a mapping
    from a beta range to a sequence of betas for stepping the model. Choose from `linear`,
    `scaled_linear`, or `squaredcos_cap_v2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trained_betas` (`np.ndarray`, *optional*) ‚Äî An array of betas to pass directly
    to the constructor without using `beta_start` and `beta_end`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variance_type` (`str`, defaults to `"fixed_small"`) ‚Äî Clip the variance when
    adding noise to the denoised sample. Choose from `fixed_small`, `fixed_small_log`,
    `fixed_large`, `fixed_large_log`, `learned` or `learned_range`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_sample` (`bool`, defaults to `True`) ‚Äî Clip the predicted sample for
    numerical stability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_sample_range` (`float`, defaults to 1.0) ‚Äî The maximum magnitude for
    sample clipping. Valid only when `clip_sample=True`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prediction_type` (`str`, defaults to `epsilon`, *optional*) ‚Äî Prediction type
    of the scheduler function; can be `epsilon` (predicts the noise of the diffusion
    process), `sample` (directly predicts the noisy sample`) or` v_prediction` (see
    section 2.4 of [Imagen Video](https://imagen.research.google/video/paper.pdf)
    paper).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`thresholding` (`bool`, defaults to `False`) ‚Äî Whether to use the ‚Äúdynamic
    thresholding‚Äù method. This is unsuitable for latent-space diffusion models such
    as Stable Diffusion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dynamic_thresholding_ratio` (`float`, defaults to 0.995) ‚Äî The ratio for the
    dynamic thresholding method. Valid only when `thresholding=True`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample_max_value` (`float`, defaults to 1.0) ‚Äî The threshold value for dynamic
    thresholding. Valid only when `thresholding=True`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestep_spacing` (`str`, defaults to `"leading"`) ‚Äî The way the timesteps
    should be scaled. Refer to Table 2 of the [Common Diffusion Noise Schedules and
    Sample Steps are Flawed](https://huggingface.co/papers/2305.08891) for more information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`steps_offset` (`int`, defaults to 0) ‚Äî An offset added to the inference steps.
    You can use a combination of `offset=1` and `set_alpha_to_one=False` to make the
    last step use step 0 for the previous alpha product like in Stable Diffusion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rescale_betas_zero_snr` (`bool`, defaults to `False`) ‚Äî Whether to rescale
    the betas to have zero terminal SNR. This enables the model to generate very bright
    and dark samples instead of limiting it to samples with medium brightness. Loosely
    related to [`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DDPMScheduler` explores the connections between denoising score matching and
    Langevin dynamics sampling.'
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `scale_model_input`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L236)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`sample` (`torch.FloatTensor`) ‚Äî The input sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestep` (`int`, *optional*) ‚Äî The current timestep in the diffusion chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: A scaled input sample.
  prefs: []
  type: TYPE_NORMAL
- en: Ensures interchangeability with schedulers that need to scale the denoising
    model input depending on the current timestep.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `set_timesteps`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L253)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`) ‚Äî The number of diffusion steps used when generating
    samples with a pre-trained model. If used, `timesteps` must be `None`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`str` or `torch.device`, *optional*) ‚Äî The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List[int]`, *optional*) ‚Äî Custom timesteps used to support arbitrary
    spacing between timesteps. If `None`, then the default timestep spacing strategy
    of equal spacing between timesteps is used. If `timesteps` is passed, `num_inference_steps`
    must be `None`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sets the discrete timesteps used for the diffusion chain (to be run before inference).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `step`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L401)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`model_output` (`torch.FloatTensor`) ‚Äî The direct output from learned diffusion
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestep` (`float`) ‚Äî The current discrete timestep in the diffusion chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample` (`torch.FloatTensor`) ‚Äî A current instance of a sample created by
    the diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) ‚Äî A random number generator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) ‚Äî Whether or not to
    return a [DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    or `tuple`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If return_dict is `True`, [DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  prefs: []
  type: TYPE_NORMAL
- en: DDPMSchedulerOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L30)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prev_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` for images) ‚Äî Computed sample `(x_{t-1})` of previous timestep. `prev_sample`
    should be used as next model input in the denoising loop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pred_original_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)` for images) ‚Äî The predicted denoised sample `(x_{0})` based on
    the model output from the current timestep. `pred_original_sample` can be used
    to preview progress or for guidance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output class for the scheduler‚Äôs `step` function output.
  prefs: []
  type: TYPE_NORMAL
