# HerBERT

> 原始文本: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/herbert](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/herbert)

## 概述

HerBERT模型是由Piotr Rybak、Robert Mroczkowski、Janusz Tracz和Ireneusz Gawlik在[波兰语理解全面基准KLEJ](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)中提出的。它是一个基于BERT的语言模型，仅使用MLM目标在波兰语语料库上训练，动态屏蔽整个单词。

论文摘要如下:

*近年来，一系列基于Transformer的模型在一般自然语言理解（NLU）任务中取得了重大进展。这样快速的研究进展不可能没有一般NLU基准，这些基准允许对所提出的方法进行公平比较。然而，这样的基准仅适用于少数几种语言。为了缓解这个问题，我们引入了一个全面的波兰语理解多任务基准，并附带在线排行榜。它包括一系列多样的任务，从现有的命名实体识别、问答、文本蕴涵等数据集中采用。我们还为电子商务领域引入了一个新的情感分析任务，名为Allegro Reviews（AR）。为了确保一个共同的评估方案，并促进能够泛化到不同NLU任务的模型，该基准包括来自不同领域和应用的数据集。此外，我们发布了HerBERT，这是一个专门为波兰语训练的基于Transformer的模型，它在平均性能方面表现最佳，并在九项任务中的三项中取得最佳结果。最后，我们提供了广泛的评估，包括几个标准基线和最近提出的多语言Transformer模型。*

这个模型是由[rmroczkowski](https://huggingface.co/rmroczkowski)贡献的。原始代码可以在[这里](https://github.com/allegro/HerBERT)找到。

## 用法示例

```py
>>> from transformers import HerbertTokenizer, RobertaModel

>>> tokenizer = HerbertTokenizer.from_pretrained("allegro/herbert-klej-cased-tokenizer-v1")
>>> model = RobertaModel.from_pretrained("allegro/herbert-klej-cased-v1")

>>> encoded_input = tokenizer.encode("Kto ma lepszą sztukę, ma lepszy rząd – to jasne.", return_tensors="pt")
>>> outputs = model(encoded_input)

>>> # HerBERT can also be loaded using AutoTokenizer and AutoModel:
>>> import torch
>>> from transformers import AutoModel, AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("allegro/herbert-klej-cased-tokenizer-v1")
>>> model = AutoModel.from_pretrained("allegro/herbert-klej-cased-v1")
```

Herbert的实现与`BERT`相同，除了分词方法。有关API参考和示例，请参考[BERT文档](bert)。

## HerbertTokenizer

### `class transformers.HerbertTokenizer`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L289)

```py
( vocab_file merges_file tokenizer_file = None cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' sep_token = '</s>' bos_token = '<s>' do_lowercase_and_remove_accent = False additional_special_tokens = ['<special0>', '<special1>', '<special2>', '<special3>', '<special4>', '<special5>', '<special6>', '<special7>', '<special8>', '<special9>'] lang2id = None id2lang = None **kwargs )
```

构建HerBERT的BPE分词器。

特点:

+   使用BERT的预分词器：BaseTokenizer在空格上分割标记，也在标点上分割。每个标点字符的出现将被单独处理。

+   这种预分词输入是BPE子标记化的

这个分词器继承自[XLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMTokenizer)，其中包含大部分方法。用户应参考超类以获取有关方法的更多信息。

#### `build_inputs_with_special_tokens`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L526)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — 要添加特殊标记的ID列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。

返回

`List[int]`

带有适当特殊标记的[input IDs](../glossary#input-ids)列表。

通过连接和添加特殊标记，为序列分类任务构建模型输入的序列或序列对。XLM序列的格式如下：

+   单个序列: `<s> X </s>`

+   序列对: `<s> A </s> B </s>`

#### `convert_tokens_to_string`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L520)

```py
( tokens )
```

将一系列标记（字符串）转换为单个字符串。

#### `create_token_type_ids_from_sequences`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L583)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — ID列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。

返回

`List[int]`

根据给定序列的[标记类型ID](../glossary#token-type-ids)列表。

从传递的两个序列创建一个用于序列对分类任务的掩码。一个XLM序列

序列对掩码具有以下格式：

```py
0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
| first sequence    | second sequence |
```

如果`token_ids_1`为`None`，则此方法仅返回掩码的第一部分（0）。

#### `get_special_tokens_mask`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert.py#L554)

```py
( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — ID列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。

+   `already_has_special_tokens` (`bool`, *可选*, 默认为`False`) — 标记列表是否已经为模型格式化了特殊标记。

返回

`List[int]`

一个整数列表，范围为[0, 1]：1表示特殊标记，0表示序列标记。

从没有添加特殊标记的标记列表中检索序列ID。在使用标记器的`prepare_for_model`方法添加特殊标记时调用此方法。

## HerbertTokenizerFast

### `class transformers.HerbertTokenizerFast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L40)

```py
( vocab_file = None merges_file = None tokenizer_file = None cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' sep_token = '</s>' **kwargs )
```

参数

+   `vocab_file` (`str`) — 词汇文件的路径。

+   `merges_file` (`str`) — 合并文件的路径。

为HerBERT构建一个“快速”BPE标记器（由HuggingFace的*tokenizers*库支持）。

特殊之处：

+   使用BERT的预标记器：BertPreTokenizer在空格上分割标记，也在标点上分割。每个标点字符的出现将被单独处理。

此标记器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数方法。用户应参考超类以获取有关方法的更多信息。

#### `build_inputs_with_special_tokens`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L89)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — 将添加特殊标记的ID列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。

返回

`List[int]`

具有适当特殊标记的[输入ID](../glossary#input-ids)列表。

通过连接和添加特殊标记从序列或序列对构建用于序列分类任务的模型输入。HerBERT，如BERT序列具有以下格式：

+   单个序列：`<s> X </s>`

+   序列对：`<s> A </s> B </s>`

#### `create_token_type_ids_from_sequences`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L143)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — ID列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。

返回

`List[int]`

根据给定序列的[标记类型ID](../glossary#token-type-ids)列表。

从传递的两个序列创建一个用于序列对分类任务的掩码。HerBERT，如

BERT序列对掩码具有以下格式：

```py
0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
| first sequence    | second sequence |
```

#### `get_special_tokens_mask`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/herbert/tokenization_herbert_fast.py#L116)

```py
( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — ID列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。

+   `already_has_special_tokens` (`bool`, *可选*, 默认为`False`) — 标记列表是否已经为模型格式化了特殊标记。

返回

`List[int]`

一个整数列表，范围为[0, 1]：1表示特殊标记，0表示序列标记。

从没有添加特殊标记的令牌列表中检索序列标识。在使用分词器的`prepare_for_model`方法添加特殊标记时调用此方法。
