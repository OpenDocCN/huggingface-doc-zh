- en: Depth-to-image
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ·±åº¦åˆ°å›¾åƒ
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/depth2img](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/depth2img)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/depth2img](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/depth2img)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The Stable Diffusion model can also infer depth based on an image using [MiDaS](https://github.com/isl-org/MiDaS).
    This allows you to pass a text prompt and an initial image to condition the generation
    of new images as well as a `depth_map` to preserve the image structure.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£æ¨¡å‹è¿˜å¯ä»¥åŸºäºå›¾åƒæ¨æ–­æ·±åº¦ï¼Œä½¿ç”¨[MiDaS](https://github.com/isl-org/MiDaS)ã€‚è¿™å…è®¸æ‚¨ä¼ é€’æ–‡æœ¬æç¤ºå’Œåˆå§‹å›¾åƒæ¥è°ƒèŠ‚ç”Ÿæˆæ–°å›¾åƒçš„è¿‡ç¨‹ï¼Œä»¥åŠä¸€ä¸ª`depth_map`æ¥ä¿ç•™å›¾åƒç»“æ„ã€‚
- en: Make sure to check out the Stable Diffusion [Tips](overview#tips) section to
    learn how to explore the tradeoff between scheduler speed and quality, and how
    to reuse pipeline components efficiently!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿æŸ¥çœ‹ç¨³å®šæ‰©æ•£[Tips](overview#tips)éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•æ¢ç´¢è°ƒåº¦å™¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œä»¥åŠå¦‚ä½•é«˜æ•ˆåœ°é‡ç”¨ç®¡é“ç»„ä»¶ï¼
- en: If youâ€™re interested in using one of the official checkpoints for a task, explore
    the [CompVis](https://huggingface.co/CompVis), [Runway](https://huggingface.co/runwayml),
    and [Stability AI](https://huggingface.co/stabilityai) Hub organizations!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£ä½¿ç”¨å®˜æ–¹æ£€æŸ¥ç‚¹æ¥æ‰§è¡Œä»»åŠ¡ï¼Œè¯·æ¢ç´¢[CompVis](https://huggingface.co/CompVis)ã€[Runway](https://huggingface.co/runwayml)å’Œ[Stability
    AI](https://huggingface.co/stabilityai) Hub ç»„ç»‡ï¼
- en: StableDiffusionDepth2ImgPipeline
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionDepth2ImgPipeline
- en: '### `class diffusers.StableDiffusionDepth2ImgPipeline`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`diffusers.StableDiffusionDepth2ImgPipeline`ç±»'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py#L77)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py#L77)'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” A `CLIPTokenizer` to tokenize text.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„`CLIPTokenizer`ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„`UNet2DConditionModel`ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„è°ƒåº¦å™¨ã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: Pipeline for text-guided depth-based image-to-image generation using Stable
    Diffusion.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºä½¿ç”¨ç¨³å®šæ‰©æ•£è¿›è¡Œæ–‡æœ¬å¼•å¯¼çš„åŸºäºæ·±åº¦çš„å›¾åƒåˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£ä¸ºæ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®¡é“è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    ç”¨äºåŠ è½½ LoRA æƒé‡'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    ç”¨äºä¿å­˜ LoRA æƒé‡'
- en: '#### `__call__`'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py#L599)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py#L599)'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`prompt_embeds`ã€‚'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) â€” `Image` or tensor representing
    an image batch to be used as the starting point. Can accept image latents as `image`
    only if `depth_map` is not `None`.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, æˆ– `List[np.ndarray]`) â€” ç”¨ä½œèµ·å§‹ç‚¹çš„å›¾åƒæ‰¹æ¬¡çš„`Image`æˆ–å¼ é‡ã€‚åªæœ‰åœ¨`depth_map`ä¸ä¸º`None`æ—¶æ‰èƒ½æ¥å—å›¾åƒæ½œåœ¨ç‰¹å¾ä½œä¸º`image`ã€‚'
- en: '`depth_map` (`torch.FloatTensor`, *optional*) â€” Depth prediction to be used
    as additional conditioning for the image generation process. If not defined, it
    automatically predicts the depth with `self.depth_estimator`.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depth_map` (`torch.FloatTensor`, *å¯é€‰*) â€” æ·±åº¦é¢„æµ‹ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆè¿‡ç¨‹çš„é¢å¤–æ¡ä»¶ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™ä¼šä½¿ç”¨ `self.depth_estimator`
    è‡ªåŠ¨é¢„æµ‹æ·±åº¦ã€‚'
- en: '`strength` (`float`, *optional*, defaults to 0.8) â€” Indicates extent to transform
    the reference `image`. Must be between 0 and 1\. `image` is used as a starting
    point and more noise is added the higher the `strength`. The number of denoising
    steps depends on the amount of noise initially added. When `strength` is 1, added
    noise is maximum and the denoising process runs for the full number of iterations
    specified in `num_inference_steps`. A value of 1 essentially ignores `image`.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.8) â€” æŒ‡ç¤ºè¦è½¬æ¢å‚è€ƒ `image` çš„ç¨‹åº¦ã€‚å¿…é¡»åœ¨ 0 å’Œ 1 ä¹‹é—´ã€‚`image`
    ç”¨ä½œèµ·ç‚¹ï¼Œ`strength` è¶Šé«˜ï¼Œæ·»åŠ çš„å™ªéŸ³å°±è¶Šå¤šã€‚å»å™ªæ­¥éª¤çš„æ•°é‡å–å†³äºæœ€åˆæ·»åŠ çš„å™ªéŸ³é‡ã€‚å½“ `strength` ä¸º 1 æ—¶ï¼Œæ·»åŠ çš„å™ªéŸ³æœ€å¤§ï¼Œå»å™ªè¿‡ç¨‹å°†è¿è¡ŒæŒ‡å®šçš„
    `num_inference_steps` æ¬¡è¿­ä»£ã€‚å€¼ä¸º 1 å®è´¨ä¸Šå¿½ç•¥äº† `image`ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference. This parameter is modulated by `strength`.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨æ–­é€Ÿåº¦ã€‚è¯¥å‚æ•°å—
    `strength` è°ƒèŠ‚ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ `prompt` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“
    `guidance_scale > 1` æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’
    `negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨å¼•å¯¼æ—¶ï¼ˆ`guidance_scale < 1`ï¼‰ä¼šè¢«å¿½ç•¥ã€‚'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” å¯¹åº”äº [DDIM](https://arxiv.org/abs/2010.02502)
    è®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ã€‚ä»…é€‚ç”¨äº [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­ä¼šè¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` æˆ– `List[torch.Generator]`, *å¯é€‰*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä»
    `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä»
    `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆ `negative_prompt_embeds`ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹© `PIL.Image` æˆ– `np.array`
    ä¹‹é—´çš„ä¸€ä¸ªã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å› [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`cross_attention_kwargs` (`dict`, *optional*) â€” A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™ [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    ä¸­å®šä¹‰çš„ `AttentionProcessor` çš„ kwargs å­—å…¸ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *å¯é€‰*) â€” åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦è·³è¿‡çš„ CLIP å±‚çš„æ•°é‡ã€‚å€¼ä¸º 1 è¡¨ç¤ºå°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: '`callback_on_step_end` (`Callable`, *optional*) â€” A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *å¯é€‰*) â€” åœ¨æ¨æ–­æœŸé—´æ¯ä¸ªå»å™ªæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`ã€‚`callback_kwargs`
    å°†åŒ…æ‹¬ç”± `callback_on_step_end_tensor_inputs` æŒ‡å®šçš„æ‰€æœ‰å¼ é‡çš„åˆ—è¡¨ã€‚'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs`ï¼ˆ`List`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äº `callback_on_step_end`
    å‡½æ•°çš„å¼ é‡è¾“å…¥åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æŒ‡å®šçš„å¼ é‡å°†ä½œä¸º `callback_kwargs` å‚æ•°ä¼ é€’ã€‚æ‚¨åªèƒ½åŒ…å«åœ¨ç®¡é“ç±»çš„ `._callback_tensor_inputs`
    å±æ€§ä¸­åˆ—å‡ºçš„å˜é‡ã€‚'
- en: Returns
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    æˆ– `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ `return_dict` ä¸º `True`ï¼Œåˆ™è¿”å› [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª
    `tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ã€‚
- en: The call function to the pipeline for generation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚
- en: 'Examples:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_attention_slicing`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`slice_size` (`str` or `int`, *optional*, defaults to `"auto"`) â€” When `"auto"`,
    halves the input to the attention heads, so attention will be computed in two
    steps. If `"max"`, maximum amount of memory will be saved by running only one
    slice at a time. If a number is provided, uses as many slices as `attention_head_dim
    // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size`.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`slice_size`ï¼ˆ`str` æˆ– `int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"auto"`ï¼‰â€” å½“ä¸º `"auto"` æ—¶ï¼Œå°†è¾“å…¥å‡åŠåˆ°æ³¨æ„åŠ›å¤´éƒ¨ï¼Œå› æ­¤æ³¨æ„åŠ›å°†åœ¨ä¸¤ä¸ªæ­¥éª¤ä¸­è®¡ç®—ã€‚å¦‚æœä¸º
    `"max"`ï¼Œå°†é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥ä¿å­˜æœ€å¤§å†…å­˜é‡ã€‚å¦‚æœæä¾›äº†ä¸€ä¸ªæ•°å­—ï¼Œåˆ™ä½¿ç”¨ `attention_head_dim // slice_size`
    ä¸ªåˆ‡ç‰‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`attention_head_dim` å¿…é¡»æ˜¯ `slice_size` çš„å€æ•°ã€‚'
- en: Enable sliced attention computation. When this option is enabled, the attention
    module splits the input tensor in slices to compute attention in several steps.
    For more than one attention head, the computation is performed sequentially over
    each head. This is useful to save some memory in exchange for a small speed decrease.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆå¤šä¸ªæ­¥éª¤è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—å°†æŒ‰é¡ºåºåœ¨æ¯ä¸ªå¤´ä¸Šæ‰§è¡Œã€‚è¿™å¯¹äºåœ¨èŠ‚çœä¸€äº›å†…å­˜ä»¥æ¢å–ä¸€ç‚¹é€Ÿåº¦é™ä½å¾ˆæœ‰ç”¨ã€‚
- en: âš ï¸ Donâ€™t enable attention slicing if youâ€™re already using `scaled_dot_product_attention`
    (SDPA) from PyTorch 2.0 or xFormers. These attention computations are already
    very memory efficient so you wonâ€™t need to enable this function. If you enable
    attention slicing with SDPA or xFormers, it can lead to serious slow downs!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 æˆ– xFormers ä¸­çš„ `scaled_dot_product_attention`ï¼ˆSDPAï¼‰ï¼Œè¯·ä¸è¦å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ã€‚è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸å†…å­˜é«˜æ•ˆï¼Œå› æ­¤æ‚¨ä¸éœ€è¦å¯ç”¨æ­¤åŠŸèƒ½ã€‚å¦‚æœæ‚¨åœ¨
    SDPA æˆ– xFormers ä¸­å¯ç”¨äº†æ³¨æ„åŠ›åˆ‡ç‰‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡çš„å‡é€Ÿï¼
- en: 'Examples:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `disable_attention_slicing`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable sliced attention computation. If `enable_attention_slicing` was previously
    called, attention is computed in one step.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº† `enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`attention_op` (`Callable`, *optional*) â€” Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op`ï¼ˆ`Callable`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œ xFormers çš„ [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    å‡½æ•°çš„ `op` å‚æ•°çš„é»˜è®¤ `None` æ“ä½œç¬¦çš„è¦†ç›–ã€‚'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨æ¥è‡ª [xFormers](https://facebookresearch.github.io/xformers/) çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°æ›´ä½çš„
    GPU å†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶ä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯èƒ½ä¼šåŠ é€Ÿã€‚è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ é€Ÿä¸è¢«ä¿è¯ã€‚
- en: âš ï¸ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å½“åŒæ—¶å¯ç”¨å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚
- en: 'Examples:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨æ¥è‡ª [xFormers](https://facebookresearch.github.io/xformers/) çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚
- en: '#### `load_textual_inversion`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_textual_inversion`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike` or `List[str or os.PathLike]`
    or `Dict` or `List[Dict]`) â€” Can be either one of the following or a list of them:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`ï¼ˆ`str` æˆ– `os.PathLike` æˆ– `List[str or os.PathLike]`
    æˆ– `Dict` æˆ– `List[Dict]`ï¼‰â€” å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å…¶ä¸­çš„åˆ—è¡¨ï¼š'
- en: A string, the *model id* (for example `sd-concepts-library/low-poly-hd-logos-icons`)
    of a pretrained model hosted on the Hub.
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ Hub ä¸Šçš„ *æ¨¡å‹ id*ï¼ˆä¾‹å¦‚ `sd-concepts-library/low-poly-hd-logos-icons`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_text_inversion_directory/`) containing
    the textual inversion weights.
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„*ç›®å½•*çš„è·¯å¾„ï¼ˆä¾‹å¦‚`./my_text_inversion_directory/`ï¼‰ã€‚
- en: A path to a *file* (for example `./my_text_inversions.pt`) containing textual
    inversion weights.
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„*æ–‡ä»¶*çš„è·¯å¾„ï¼ˆä¾‹å¦‚`./my_text_inversions.pt`ï¼‰ã€‚
- en: A [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict).
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[torchçŠ¶æ€å­—å…¸](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)ã€‚
- en: '`token` (`str` or `List[str]`, *optional*) â€” Override the token to use for
    the textual inversion weights. If `pretrained_model_name_or_path` is a list, then
    `token` must also be a list of equal length.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€”è¦†ç›–ç”¨äºæ–‡æœ¬åè½¬æƒé‡çš„ä»¤ç‰Œã€‚å¦‚æœ`pretrained_model_name_or_path`æ˜¯åˆ—è¡¨ï¼Œåˆ™`token`ä¹Ÿå¿…é¡»æ˜¯ç›¸åŒé•¿åº¦çš„åˆ—è¡¨ã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).
    If not specified, function will take self.tokenizer.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)ï¼Œ*å¯é€‰*ï¼‰â€”å†»ç»“æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨self.tokenizerã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) â€” A `CLIPTokenizer` to tokenize text. If not specified, function will
    take self.tokenizer.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨äºæ ‡è®°æ–‡æœ¬çš„`CLIPTokenizer`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨self.tokenizerã€‚'
- en: '`weight_name` (`str`, *optional*) â€” Name of a custom weight file. This should
    be used when:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€”è‡ªå®šä¹‰æƒé‡æ–‡ä»¶çš„åç§°ã€‚åº”åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ä½¿ç”¨ï¼š'
- en: The saved textual inversion file is in ğŸ¤— Diffusers format, but was saved under
    a specific weight name such as `text_inv.bin`.
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶æ˜¯ğŸ¤— Diffusersæ ¼å¼ï¼Œä½†æ˜¯ä¿å­˜åœ¨ç‰¹å®šæƒé‡åç§°ä¸‹ï¼Œä¾‹å¦‚`text_inv.bin`ã€‚
- en: The saved textual inversion file is in the Automatic1111 format.
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶æ˜¯Automatic1111æ ¼å¼ã€‚
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`ï¼ˆ`Union[str, os.PathLike]`ï¼Œ*å¯é€‰*ï¼‰â€”ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœæœªä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€”æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€”æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`ï¼ˆ`Dict[str, str]`ï¼Œ*å¯é€‰*ï¼‰â€”è¦ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ï¼Œä¾‹å¦‚ï¼Œ`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€”æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œæ¨¡å‹å°†ä¸ä¼šä»Hubä¸‹è½½ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`ï¼ˆ`str`æˆ–*bool*ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli
    login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"main"`ï¼‰â€”è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤IDæˆ–Gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) â€” The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`""`ï¼‰â€”æ¨¡å‹æ–‡ä»¶åœ¨Hubæˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚'
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€”åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶è§£å†³å¯è®¿é—®æ€§é—®é¢˜çš„é•œåƒæºã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚'
- en: Load Textual Inversion embeddings into the text encoder of [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    (both ğŸ¤— Diffusers and Automatic1111 formats are supported).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ–‡æœ¬åè½¬åµŒå…¥åŠ è½½åˆ°[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)çš„æ–‡æœ¬ç¼–ç å™¨ä¸­ï¼ˆæ”¯æŒğŸ¤—
    Diffuserså’ŒAutomatic1111æ ¼å¼ï¼‰ã€‚
- en: 'Example:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: 'To load a Textual Inversion embedding vector in ğŸ¤— Diffusers format:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½ğŸ¤— Diffusersæ ¼å¼çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼š
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To load a Textual Inversion embedding vector in Automatic1111 format, make sure
    to download the vector first (for example from [civitAI](https://civitai.com/models/3036?modelVersionId=9857))
    and then load the vector
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½Automatic1111æ ¼å¼çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼Œè¯·ç¡®ä¿é¦–å…ˆä¸‹è½½å‘é‡ï¼ˆä¾‹å¦‚ä»[civitAI](https://civitai.com/models/3036?modelVersionId=9857)ï¼‰ç„¶ååŠ è½½å‘é‡
- en: 'locally:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åœ°ï¼š
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#### `load_lora_weights`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    â€” See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path_or_dict`ï¼ˆ`str`æˆ–`os.PathLike`æˆ–`dict`ï¼‰â€”å‚è§[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚'
- en: '`kwargs` (`dict`, *optional*) â€” See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`dict`, *optional*) â€” æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚'
- en: '`adapter_name` (`str`, *optional*) â€” Adapter name to be used for referencing
    the loaded adapter model. If not specified, it will use `default_{i}` where i
    is the total number of adapters being loaded.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *optional*) â€” ç”¨äºå¼•ç”¨åŠ è½½çš„é€‚é…å™¨æ¨¡å‹çš„é€‚é…å™¨åç§°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨`default_{i}`ï¼Œå…¶ä¸­iæ˜¯è¦åŠ è½½çš„é€‚é…å™¨æ€»æ•°ã€‚'
- en: Load LoRA weights specified in `pretrained_model_name_or_path_or_dict` into
    `self.unet` and `self.text_encoder`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å°†åœ¨`pretrained_model_name_or_path_or_dict`ä¸­æŒ‡å®šçš„LoRAæƒé‡åŠ è½½åˆ°`self.unet`å’Œ`self.text_encoder`ä¸­ã€‚
- en: All kwargs are forwarded to `self.lora_state_dict`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰kwargséƒ½å°†è½¬å‘åˆ°`self.lora_state_dict`ã€‚
- en: See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    for more details on how the state dict is loaded.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³å¦‚ä½•åŠ è½½çŠ¶æ€å­—å…¸çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚
- en: See [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    for more details on how the state dict is loaded into `self.unet`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°`self.unet`ä¸­çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)ã€‚
- en: See [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    for more details on how the state dict is loaded into `self.text_encoder`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°`self.text_encoder`ä¸­çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)ã€‚
- en: '#### `save_lora_weights`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to save LoRA parameters
    to. Will be created if it doesnâ€™t exist.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` or `os.PathLike`) â€” ä¿å­˜LoRAå‚æ•°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºè¯¥ç›®å½•ã€‚'
- en: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” State dict of the LoRA layers corresponding to the `unet`.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” ä¸`unet`å¯¹åº”çš„LoRAå±‚çš„çŠ¶æ€å­—å…¸ã€‚'
- en: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” State dict of the LoRA layers corresponding to the `text_encoder`. Must explicitly
    pass the text encoder LoRA state dict because it comes from ğŸ¤— Transformers.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” ä¸`text_encoder`å¯¹åº”çš„LoRAå±‚çš„çŠ¶æ€å­—å…¸ã€‚å¿…é¡»æ˜¾å¼ä¼ é€’æ–‡æœ¬ç¼–ç å™¨LoRAçŠ¶æ€å­—å…¸ï¼Œå› ä¸ºå®ƒæ¥è‡ªğŸ¤— Transformersã€‚'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) â€” Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *optional*, defaults to `True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­å¾ˆæœ‰ç”¨ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®`is_main_process=True`ä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚'
- en: '`save_function` (`Callable`) â€” The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function` (`Callable`) â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢`torch.save`æ—¶å¾ˆæœ‰ç”¨ã€‚å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡`DIFFUSERS_SAVE_MODE`è¿›è¡Œé…ç½®ã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦ä½¿ç”¨`safetensors`æˆ–ä¼ ç»Ÿçš„PyTorchæ–¹å¼ä½¿ç”¨`pickle`ä¿å­˜æ¨¡å‹ã€‚'
- en: Save the LoRA parameters corresponding to the UNet and text encoder.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿å­˜å¯¹åº”äºUNetå’Œæ–‡æœ¬ç¼–ç å™¨çš„LoRAå‚æ•°ã€‚
- en: '#### `encode_prompt`'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py#L185)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py#L185)'
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded device â€”
    (`torch.device`): torch device'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) â€” è¦ç¼–ç çš„æç¤º'
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡'
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) â€” æ˜¯å¦ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” ä¸ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚å¦‚æœä¸ä½¿ç”¨æŒ‡å¯¼ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆ`negative_prompt_embeds`ã€‚'
- en: '`lora_scale` (`float`, *optional*) â€” A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *optional*) â€” å°†åº”ç”¨äºåŠ è½½LoRAå±‚çš„æ‰€æœ‰æ–‡æœ¬ç¼–ç å™¨LoRAå±‚çš„LoRAæ¯”ä¾‹ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *å¯é€‰*) â€” åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦ä»CLIPè·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º1æ„å‘³ç€å°†ä½¿ç”¨å‰ä¸€å±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
- en: StableDiffusionPipelineOutput
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) â€” List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` æˆ– `np.ndarray`) â€” é•¿åº¦ä¸º`batch_size`çš„å»å™ªPILå›¾åƒåˆ—è¡¨ï¼Œæˆ–å½¢çŠ¶ä¸º`(batch_size,
    height, width, num_channels)`çš„NumPyæ•°ç»„ã€‚'
- en: '`nsfw_content_detected` (`List[bool]`) â€” List indicating whether the corresponding
    generated image contains â€œnot-safe-for-workâ€ (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) â€” åˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ï¼Œå¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º`None`ã€‚'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚
