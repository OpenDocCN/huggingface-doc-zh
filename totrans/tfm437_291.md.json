["```py\nfrom transformers import SwinConfig, UperNetConfig, UperNetForSemanticSegmentation\n\nbackbone_config = SwinConfig(out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"])\n\nconfig = UperNetConfig(backbone_config=backbone_config)\nmodel = UperNetForSemanticSegmentation(config)\n```", "```py\nfrom transformers import ConvNextConfig, UperNetConfig, UperNetForSemanticSegmentation\n\nbackbone_config = ConvNextConfig(out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"])\n\nconfig = UperNetConfig(backbone_config=backbone_config)\nmodel = UperNetForSemanticSegmentation(config)\n```", "```py\n>>> from transformers import UperNetConfig, UperNetForSemanticSegmentation\n\n>>> # Initializing a configuration\n>>> configuration = UperNetConfig()\n\n>>> # Initializing a model (with random weights) from the configuration\n>>> model = UperNetForSemanticSegmentation(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoImageProcessor, UperNetForSemanticSegmentation\n>>> from PIL import Image\n>>> from huggingface_hub import hf_hub_download\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"openmmlab/upernet-convnext-tiny\")\n>>> model = UperNetForSemanticSegmentation.from_pretrained(\"openmmlab/upernet-convnext-tiny\")\n\n>>> filepath = hf_hub_download(\n...     repo_id=\"hf-internal-testing/fixtures_ade20k\", filename=\"ADE_val_00000001.jpg\", repo_type=\"dataset\"\n... )\n>>> image = Image.open(filepath).convert(\"RGB\")\n\n>>> inputs = image_processor(images=image, return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits  # shape (batch_size, num_labels, height, width)\n>>> list(logits.shape)\n[1, 150, 512, 512]\n```"]