["```py\nfrom transformers import BarkModel\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = BarkModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16).to(device)\n```", "```py\nmodel.enable_cpu_offload()\n```", "```py\nmodel =  model.to_bettertransformer()\n```", "```py\npip install -U flash-attn --no-build-isolation\n```", "```py\nmodel = BarkModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").to(device)\n```", "```py\nfrom transformers import BarkModel\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# load in fp16 and use Flash Attention 2\nmodel = BarkModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").to(device)\n\n# enable CPU offload\nmodel.enable_cpu_offload()\n```", "```py\n>>> from transformers import AutoProcessor, BarkModel\n\n>>> processor = AutoProcessor.from_pretrained(\"suno/bark\")\n>>> model = BarkModel.from_pretrained(\"suno/bark\")\n\n>>> voice_preset = \"v2/en_speaker_6\"\n\n>>> inputs = processor(\"Hello, my dog is cute\", voice_preset=voice_preset)\n\n>>> audio_array = model.generate(**inputs)\n>>> audio_array = audio_array.cpu().numpy().squeeze()\n```", "```py\n>>> # Multilingual speech - simplified Chinese\n>>> inputs = processor(\"\u60ca\u4eba\u7684\uff01\u6211\u4f1a\u8bf4\u4e2d\u6587\")\n\n>>> # Multilingual speech - French - let's use a voice_preset as well\n>>> inputs = processor(\"Incroyable! Je peux g\u00e9n\u00e9rer du son.\", voice_preset=\"fr_speaker_5\")\n\n>>> # Bark can also generate music. You can help it out by adding music notes around your lyrics.\n>>> inputs = processor(\"\u266a Hello, my dog is cute \u266a\")\n\n>>> audio_array = model.generate(**inputs)\n>>> audio_array = audio_array.cpu().numpy().squeeze()\n```", "```py\n>>> # Adding non-speech cues to the input text\n>>> inputs = processor(\"Hello uh ... [clears throat], my dog is cute [laughter]\")\n\n>>> audio_array = model.generate(**inputs)\n>>> audio_array = audio_array.cpu().numpy().squeeze()\n```", "```py\n>>> from scipy.io.wavfile import write as write_wav\n\n>>> # save audio to disk, but first take the sample rate from the model config\n>>> sample_rate = model.generation_config.sample_rate\n>>> write_wav(\"bark_generation.wav\", sample_rate, audio_array)\n```", "```py\n( semantic_config: Dict = None coarse_acoustics_config: Dict = None fine_acoustics_config: Dict = None codec_config: Dict = None initializer_range = 0.02 **kwargs )\n```", "```py\n( semantic_config: BarkSemanticConfig coarse_acoustics_config: BarkCoarseConfig fine_acoustics_config: BarkFineConfig codec_config: PretrainedConfig **kwargs ) \u2192 export const metadata = 'undefined';BarkConfig\n```", "```py\n( tokenizer speaker_embeddings = None )\n```", "```py\n( text = None voice_preset = None return_tensors = 'pt' max_length = 256 add_special_tokens = False return_attention_mask = True return_token_type_ids = False **kwargs ) \u2192 export const metadata = 'undefined';Tuple(BatchEncoding, BatchFeature)\n```", "```py\n( pretrained_processor_name_or_path speaker_embeddings_dict_path = 'speaker_embeddings_path.json' **kwargs )\n```", "```py\n( save_directory speaker_embeddings_dict_path = 'speaker_embeddings_path.json' speaker_embeddings_directory = 'speaker_embeddings' push_to_hub: bool = False **kwargs )\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None history_prompt: Optional = None return_output_lengths: Optional = None **kwargs ) \u2192 export const metadata = 'undefined';By default\n```", "```py\n>>> from transformers import AutoProcessor, BarkModel\n\n>>> processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n>>> model = BarkModel.from_pretrained(\"suno/bark-small\")\n\n>>> # To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`\n>>> voice_preset = \"v2/en_speaker_6\"\n\n>>> inputs = processor(\"Hello, my dog is cute, I need him in my life\", voice_preset=voice_preset)\n\n>>> audio_array = model.generate(**inputs, semantic_max_new_tokens=100)\n>>> audio_array = audio_array.cpu().numpy().squeeze()\n```", "```py\n( gpu_id: Optional = 0 )\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )\n```", "```py\n( config )\n```", "```py\n( codebook_idx: int input_ids: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None position_ids: Optional = None head_mask: Optional = None labels: Optional = None input_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )\n```", "```py\n( block_size = 1024 input_vocab_size = 10048 output_vocab_size = 10048 num_layers = 12 num_heads = 12 hidden_size = 768 dropout = 0.0 bias = True initializer_range = 0.02 use_cache = True **kwargs )\n```", "```py\n>>> from transformers import BarkCoarseConfig, BarkCoarseModel\n\n>>> # Initializing a Bark sub-module style configuration\n>>> configuration = BarkCoarseConfig()\n\n>>> # Initializing a model (with random weights) from the suno/bark style configuration\n>>> model = BarkCoarseModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( tie_word_embeddings = True n_codes_total = 8 n_codes_given = 1 **kwargs )\n```", "```py\n>>> from transformers import BarkFineConfig, BarkFineModel\n\n>>> # Initializing a Bark sub-module style configuration\n>>> configuration = BarkFineConfig()\n\n>>> # Initializing a model (with random weights) from the suno/bark style configuration\n>>> model = BarkFineModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( block_size = 1024 input_vocab_size = 10048 output_vocab_size = 10048 num_layers = 12 num_heads = 12 hidden_size = 768 dropout = 0.0 bias = True initializer_range = 0.02 use_cache = True **kwargs )\n```", "```py\n>>> from transformers import BarkSemanticConfig, BarkSemanticModel\n\n>>> # Initializing a Bark sub-module style configuration\n>>> configuration = BarkSemanticConfig()\n\n>>> # Initializing a model (with random weights) from the suno/bark style configuration\n>>> model = BarkSemanticModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```"]