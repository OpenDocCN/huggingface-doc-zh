- en: aMUSEd
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/amused](https://huggingface.co/docs/diffusers/api/pipelines/amused)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'aMUSEd was introduced in [aMUSEd: An Open MUSE Reproduction](https://huggingface.co/papers/2401.01808)
    by Suraj Patil, William Berman, Robin Rombach, and Patrick von Platen.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Amused is a lightweight text to image model based off of the [MUSE](https://arxiv.org/abs/2301.00704)
    architecture. Amused is particularly useful in applications that require a lightweight
    and fast model such as generating many images quickly at once.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Amused is a vqvae token based transformer that can generate an image in fewer
    forward passes than many diffusion models. In contrast with muse, it uses the
    smaller text encoder CLIP-L/14 instead of t5-xxl. Due to its small parameter count
    and few forward pass generation process, amused can generate many images quickly.
    This benefit is seen particularly at larger batch sizes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '*We present aMUSEd, an open-source, lightweight masked image model (MIM) for
    text-to-image generation based on MUSE. With 10 percent of MUSE’s parameters,
    aMUSEd is focused on fast image generation. We believe MIM is under-explored compared
    to latent diffusion, the prevailing approach for text-to-image generation. Compared
    to latent diffusion, MIM requires fewer inference steps and is more interpretable.
    Additionally, MIM can be fine-tuned to learn additional styles with only a single
    image. We hope to encourage further exploration of MIM by demonstrating its effectiveness
    on large-scale text-to-image generation and releasing reproducible training code.
    We also release checkpoints for two models which directly produce images at 256x256
    and 512x512 resolutions.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Params |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| [amused-256](https://huggingface.co/amused/amused-256) | 603M |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| [amused-512](https://huggingface.co/amused/amused-512) | 608M |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: AmusedPipeline
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.AmusedPipeline`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused.py#L44)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#### `__call__`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused.py#L74)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height` (`int`, *optional*, defaults to `self.transformer.config.sample_size
    * self.vae_scale_factor`) — The height in pixels of the generated image.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 16) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 10.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.IntTensor`, *optional*) — Pre-generated tokens representing
    latent vectors in `self.vqvae`, to be used as inputs for image gneration. If not
    provided, the starting latents will be completely masked.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument. A single vector from
    the pooled and projected final hidden states.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，文本嵌入将从`prompt`输入参数生成。来自池化和投影的最终隐藏状态的单个向量。'
- en: '`encoder_hidden_states` (`torch.FloatTensor`, *optional*) — Pre-generated penultimate
    hidden states from the text encoder providing additional text conditioning.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`torch.FloatTensor`, *可选*) — 文本编码器生成的倒数第二隐藏状态，提供额外的文本调节。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，`negative_prompt_embeds`将从`negative_prompt`输入参数生成。'
- en: '`negative_encoder_hidden_states` (`torch.FloatTensor`, *optional*) — Analogous
    to `encoder_hidden_states` for the positive prompt.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_encoder_hidden_states` (`torch.FloatTensor`, *可选*) — 与正面提示的`encoder_hidden_states`类似。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是普通元组。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推理期间每`callback_steps`步调用的函数。该函数使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为1) — 调用`callback`函数的频率。如果未指定，将在每一步调用回调。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *可选*) — 如果指定，则作为`AttentionProcessor`的kwargs字典传递给`self.processor`中定义的`AttentionProcessor`。'
- en: '`micro_conditioning_aesthetic_score` (`int`, *optional*, defaults to 6) — The
    targeted aesthetic score according to the laion aesthetic classifier. See [https://laion.ai/blog/laion-aesthetics/](https://laion.ai/blog/laion-aesthetics/)
    and the micro-conditioning section of [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`micro_conditioning_aesthetic_score` (`int`, *可选*, 默认为6) — 根据laion审美分类器的目标审美评分。参见[https://laion.ai/blog/laion-aesthetics/](https://laion.ai/blog/laion-aesthetics/)和[https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952)的微调节部分。'
- en: '`micro_conditioning_crop_coord` (`Tuple[int]`, *optional*, defaults to (0,
    0)) — The targeted height, width crop coordinates. See the micro-conditioning
    section of [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`micro_conditioning_crop_coord` (`Tuple[int]`, *可选*, 默认为(0, 0)) — 目标高度、宽度裁剪坐标。参见[https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952)的微调节部分。'
- en: '`temperature` (`Union[int, Tuple[int, int], List[int]]`, *optional*, defaults
    to (2, 0)) — Configures the temperature scheduler on `self.scheduler` see `AmusedScheduler#set_timesteps`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature` (`Union[int, Tuple[int, int], List[int]]`, *可选*, 默认为(2, 0)) —
    配置`self.scheduler`上的温度调度器，参见`AmusedScheduler#set_timesteps`。'
- en: Returns
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)，否则返回一个`tuple`，其中第一个元素是包含生成图像的列表。
- en: The call function to the pipeline for generation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_op` (`Callable`, *optional*) — Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`, *可选*) — 用作`xFormers`的[`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)函数的`op`参数的默认`None`操作符的覆盖。'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从[xFormers](https://facebookresearch.github.io/xformers/)启用内存高效注意力。启用此选项时，您应该观察到较低的GPU内存使用量和推理期间的潜在加速。训练期间的加速不被保证。
- en: ⚠️ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 当启用内存高效注意力和切片注意力时，内存高效注意力优先。
- en: 'Examples:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从[xFormers](https://facebookresearch.github.io/xformers/)中禁用内存高效注意力。
- en: '### `class diffusers.AmusedImg2ImgPipeline`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.AmusedImg2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_img2img.py#L52)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_img2img.py#L52)'
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `__call__`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_img2img.py#L87)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_img2img.py#L87)'
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 指导图像生成的提示。如果未定义，则需要传递 `prompt_embeds`。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, numpy array or tensor
    representing an image batch to be used as the starting point. For both numpy array
    and pytorch tensor, the expected value range is between `[0, 1]` If it’s a tensor
    or a list or tensors, the expected shape should be `(B, C, H, W)` or `(C, H, W)`.
    If it is a numpy array or a list of arrays, the expected shape should be `(B,
    H, W, C)` or `(H, W, C)` It can also accept image latents as `image`, but if passing
    latents directly it is not encoded again.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 代表要用作起点的图像批次的图像、numpy数组或张量。对于numpy数组和pytorch张量，期望值范围在
    `[0, 1]` 之间。如果是张量或张量列表，则期望形状应为 `(B, C, H, W)` 或 `(C, H, W)`。如果是numpy数组或数组列表，则期望形状应为
    `(B, H, W, C)` 或 `(H, W, C)`。也可以将图像潜变量作为 `image`，但如果直接传递潜变量，则不会再次编码。'
- en: '`strength` (`float`, *optional*, defaults to 0.5) — Indicates extent to transform
    the reference `image`. Must be between 0 and 1\. `image` is used as a starting
    point and more noise is added the higher the `strength`. The number of denoising
    steps depends on the amount of noise initially added. When `strength` is 1, added
    noise is maximum and the denoising process runs for the full number of iterations
    specified in `num_inference_steps`. A value of 1 essentially ignores `image`.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *可选*, 默认为 0.5) — 表示转换参考 `image` 的程度。必须在 0 和 1 之间。`image`
    用作起点，`strength` 越高，添加的噪音越多。去噪步骤的数量取决于最初添加的噪音量。当 `strength` 为 1 时，添加的噪音最大，去噪过程将运行指定的
    `num_inference_steps` 的完整迭代次数。值为 1 实质上忽略了 `image`。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 16) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 16) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 10.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 10.0) — 更高的指导比例值鼓励模型生成与文本 `prompt` 密切相关的图像，但会降低图像质量。当
    `guidance_scale > 1` 时启用指导比例。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 指导图像生成时不包含的提示。如果未定义，则需要传递 `negative_prompt_embeds`。在不使用指导时被忽略
    (`guidance_scale < 1`)。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *可选*) — 用于使生成过程确定性的 [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument. A single vector from
    the pooled and projected final hidden states.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入 (提示加权)。如果未提供，则文本嵌入将从
    `prompt` 输入参数生成。来自汇总和投影的最终隐藏状态的单个向量。'
- en: '`encoder_hidden_states` (`torch.FloatTensor`, *optional*) — Pre-generated penultimate
    hidden states from the text encoder providing additional text conditioning.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`torch.FloatTensor`, *可选*) — 从文本编码器中预生成的倒数第二隐藏状态，提供额外的文本调节。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负面文本嵌入。可用于轻松调整文本输入
    (提示加权)。如果未提供，`negative_prompt_embeds` 将从 `negative_prompt` 输入参数生成。'
- en: '`negative_encoder_hidden_states` (`torch.FloatTensor`, *optional*) — Analogous
    to `encoder_hidden_states` for the positive prompt.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_encoder_hidden_states` (`torch.FloatTensor`, *可选*) — 与正面提示的 `encoder_hidden_states`
    类似。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。选择 `PIL.Image` 或 `np.array`
    之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是普通元组。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推断期间每`callback_steps`步调用的函数。该函数使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为1) — 调用`callback`函数的频率。如果未指定，则在每一步调用回调。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *可选*) — 如果指定，将传递给`AttentionProcessor`的kwargs字典，如在[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中定义的。'
- en: '`micro_conditioning_aesthetic_score` (`int`, *optional*, defaults to 6) — The
    targeted aesthetic score according to the laion aesthetic classifier. See [https://laion.ai/blog/laion-aesthetics/](https://laion.ai/blog/laion-aesthetics/)
    and the micro-conditioning section of [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`micro_conditioning_aesthetic_score` (`int`, *可选*, 默认为6) — 根据laion审美分类器的目标审美评分。请参阅[https://laion.ai/blog/laion-aesthetics/](https://laion.ai/blog/laion-aesthetics/)和[https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952)的微调节部分。'
- en: '`micro_conditioning_crop_coord` (`Tuple[int]`, *optional*, defaults to (0,
    0)) — The targeted height, width crop coordinates. See the micro-conditioning
    section of [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`micro_conditioning_crop_coord` (`Tuple[int]`, *可选*, 默认为(0, 0)) — 目标高度、宽度裁剪坐标。请参阅[https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952)的微调节部分。'
- en: '`temperature` (`Union[int, Tuple[int, int], List[int]]`, *optional*, defaults
    to (2, 0)) — Configures the temperature scheduler on `self.scheduler` see `AmusedScheduler#set_timesteps`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature` (`Union[int, Tuple[int, int], List[int]]`, *可选*, 默认为(2, 0)) —
    配置`self.scheduler`上的温度调度程序，参见`AmusedScheduler#set_timesteps`。'
- en: Returns
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)，否则返回一个`tuple`，其中第一个元素是包含生成图像的列表。
- en: The call function to the pipeline for generation.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_op` (`Callable`, *optional*) — Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`, *可选*) — 用作xFormers的[`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)函数的`op`参数的默认`None`操作符的覆盖。'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 启用[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。启用此选项时，您应该观察到较低的GPU内存使用量和潜在的推断加速。训练期间的加速不被保证。
- en: ⚠️ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 当启用内存高效注意力和切片注意力时，内存高效注意力优先。
- en: 'Examples:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE11]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。
- en: '### `class diffusers.AmusedInpaintPipeline`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.AmusedInpaintPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_inpaint.py#L60)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_inpaint.py#L60)'
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `__call__`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_inpaint.py#L103)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/amused/pipeline_amused_inpaint.py#L103)'
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 用于引导图像生成的提示或提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, numpy array or tensor
    representing an image batch to be used as the starting point. For both numpy array
    and pytorch tensor, the expected value range is between `[0, 1]` If it’s a tensor
    or a list or tensors, the expected shape should be `(B, C, H, W)` or `(C, H, W)`.
    If it is a numpy array or a list of arrays, the expected shape should be `(B,
    H, W, C)` or `(H, W, C)` It can also accept image latents as `image`, but if passing
    latents directly it is not encoded again.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 代表要用作起点的图像批次的`Image`、numpy数组或张量。对于numpy数组和pytorch张量，期望的值范围在`[0,
    1]`之间。如果是张量或张量列表，则期望的形状应为`(B, C, H, W)`或`(C, H, W)`。如果是numpy数组或数组列表，则期望的形状应为`(B,
    H, W, C)`或`(H, W, C)`。它还可以接受图像潜变量作为`image`，但如果直接传递潜变量，则不会再次编码。'
- en: '`mask_image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, numpy array or tensor
    representing an image batch to mask `image`. White pixels in the mask are repainted
    while black pixels are preserved. If `mask_image` is a PIL image, it is converted
    to a single channel (luminance) before use. If it’s a numpy array or pytorch tensor,
    it should contain one color channel (L) instead of 3, so the expected shape for
    pytorch tensor would be `(B, 1, H, W)`, `(B, H, W)`, `(1, H, W)`, `(H, W)`. And
    for numpy array would be for `(B, H, W, 1)`, `(B, H, W)`, `(H, W, 1)`, or `(H,
    W)`.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 代表要遮罩`image`的图像批次的`Image`、numpy数组或张量。遮罩中的白色像素被重新绘制，而黑色像素被保留。如果`mask_image`是PIL图像，则在使用之前将其转换为单通道（亮度）。如果是numpy数组或pytorch张量，则应包含一个颜色通道（L），而不是3个，因此pytorch张量的预期形状为`(B,
    1, H, W)`、`(B, H, W)`、`(1, H, W)`、`(H, W)`。对于numpy数组，预期形状为`(B, H, W, 1)`、`(B,
    H, W)`、`(H, W, 1)`或`(H, W)`。'
- en: '`strength` (`float`, *optional*, defaults to 1.0) — Indicates extent to transform
    the reference `image`. Must be between 0 and 1\. `image` is used as a starting
    point and more noise is added the higher the `strength`. The number of denoising
    steps depends on the amount of noise initially added. When `strength` is 1, added
    noise is maximum and the denoising process runs for the full number of iterations
    specified in `num_inference_steps`. A value of 1 essentially ignores `image`.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *optional*, 默认为1.0) — 指示转换参考`image`的程度。必须在0和1之间。`image`用作起点，`strength`越高，添加的噪音越多。降噪步骤的数量取决于最初添加的噪音量。当`strength`为1时，添加的噪音最大，降噪过程将运行指定的`num_inference_steps`的完整迭代次数。值为1基本上忽略`image`。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 16) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为16) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 10.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认为10.0) — 更高的指导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用指导比例。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 用于指导在图像生成中不包括什么的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用指导时被忽略（`guidance_scale
    < 1`）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, 默认为1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *optional*) — 用于使生成过程确定性的 [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument. A single vector from
    the pooled and projected final hidden states.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`prompt`输入参数生成文本嵌入。来自汇总和投影的最终隐藏状态的单个向量。'
- en: '`encoder_hidden_states` (`torch.FloatTensor`, *optional*) — Pre-generated penultimate
    hidden states from the text encoder providing additional text conditioning.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`torch.FloatTensor`, *optional*) — 从文本编码器中预生成的倒数第二隐藏状态，提供额外的文本调节。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，`negative_prompt_embeds`将从`negative_prompt`输入参数生成。'
- en: '`negative_encoder_hidden_states` (`torch.FloatTensor`, *optional*) — Analogous
    to `encoder_hidden_states` for the positive prompt.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_encoder_hidden_states` (`torch.FloatTensor`, *optional*) — 与正提示的`encoder_hidden_states`类似。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为 `True`) — 是否返回 [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    而不是普通的 tuple。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 在推理过程中每 `callback_steps` 步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, 默认为 1) — 调用 `callback` 函数的频率。如果未指定，则在每一步都会调用回调函数。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给 [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    中定义的 `AttentionProcessor` 的 kwargs 字典。'
- en: '`micro_conditioning_aesthetic_score` (`int`, *optional*, defaults to 6) — The
    targeted aesthetic score according to the laion aesthetic classifier. See [https://laion.ai/blog/laion-aesthetics/](https://laion.ai/blog/laion-aesthetics/)
    and the micro-conditioning section of [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`micro_conditioning_aesthetic_score` (`int`, *optional*, 默认为 6) — 根据 laion
    美学分类器的目标美学分数。请参阅 [https://laion.ai/blog/laion-aesthetics/](https://laion.ai/blog/laion-aesthetics/)
    和 [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952) 的微调节部分。'
- en: '`micro_conditioning_crop_coord` (`Tuple[int]`, *optional*, defaults to (0,
    0)) — The targeted height, width crop coordinates. See the micro-conditioning
    section of [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952).'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`micro_conditioning_crop_coord` (`Tuple[int]`, *optional*, 默认为 (0, 0)) — 目标高度、宽度裁剪坐标。请参阅
    [https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952) 的微调节部分。'
- en: '`temperature` (`Union[int, Tuple[int, int], List[int]]`, *optional*, defaults
    to (2, 0)) — Configures the temperature scheduler on `self.scheduler` see `AmusedScheduler#set_timesteps`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature` (`Union[int, Tuple[int, int], List[int]]`, *optional*, 默认为 (2,
    0)) — 配置 `self.scheduler` 上的温度调度器，参见 `AmusedScheduler#set_timesteps`。'
- en: Returns
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `return_dict` 为 `True`，则返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)，否则返回一个
    `tuple`，其中第一个元素是生成的图像的列表。
- en: The call function to the pipeline for generation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE15]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_op` (`Callable`, *optional*) — Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`, *optional*) — 覆盖用作 xFormers 的 [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    函数的 `op` 参数的默认 `None` 操作符。'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 启用来自 [xFormers](https://facebookresearch.github.io/xformers/) 的内存高效注意力。启用此选项时，您应该观察到更低的
    GPU 内存使用量，并在推理过程中可能加速。训练过程中的加速不被保证。
- en: ⚠️ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 当内存高效注意力和切片注意力同时启用时，内存高效注意力优先。
- en: 'Examples:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE17]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用来自 [xFormers](https://facebookresearch.github.io/xformers/) 的内存高效注意力。
