["```py\n( peft_type: Union = None auto_mapping: Optional = None base_model_name_or_path: Optional = None revision: Optional = None task_type: Union = None inference_mode: bool = False num_virtual_tokens: int = None token_dim: int = None num_transformer_submodules: Optional = None num_attention_heads: Optional = None num_layers: Optional = None prompt_tuning_init: Union = <PromptTuningInit.RANDOM: 'RANDOM'> prompt_tuning_init_text: Optional = None tokenizer_name_or_path: Optional = None tokenizer_kwargs: Optional = None )\n```", "```py\n( config word_embeddings )\n```", "```py\n>>> from peft import PromptEmbedding, PromptTuningConfig\n\n>>> config = PromptTuningConfig(\n...     peft_type=\"PROMPT_TUNING\",\n...     task_type=\"SEQ_2_SEQ_LM\",\n...     num_virtual_tokens=20,\n...     token_dim=768,\n...     num_transformer_submodules=1,\n...     num_attention_heads=12,\n...     num_layers=12,\n...     prompt_tuning_init=\"TEXT\",\n...     prompt_tuning_init_text=\"Predict if sentiment of this review is positive, negative or neutral\",\n...     tokenizer_name_or_path=\"t5-base\",\n... )\n\n>>> # t5_model.shared is the word embeddings of the base model\n>>> prompt_embedding = PromptEmbedding(config, t5_model.shared)\n```"]