# åˆ›å»ºå¯å¤ç°çš„æµæ°´çº¿

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/reproducibility](https://huggingface.co/docs/diffusers/using-diffusers/reproducibility)

å¯å¤ç°æ€§å¯¹äºæµ‹è¯•ã€å¤åˆ¶ç»“æœç”šè‡³ç”¨äº[æ”¹å–„å›¾åƒè´¨é‡](reusing_seeds)éƒ½å¾ˆé‡è¦ã€‚ç„¶è€Œï¼Œåœ¨æ‰©æ•£æ¨¡å‹ä¸­çš„éšæœºæ€§æ˜¯ä¸€ç§æœŸæœ›çš„å±æ€§ï¼Œå› ä¸ºå®ƒå…è®¸æµæ°´çº¿æ¯æ¬¡è¿è¡Œæ—¶ç”Ÿæˆä¸åŒçš„å›¾åƒã€‚è™½ç„¶æ‚¨ä¸èƒ½æœŸæœ›åœ¨ä¸åŒå¹³å°ä¸Šè·å¾—å®Œå…¨ç›¸åŒçš„ç»“æœï¼Œä½†æ‚¨å¯ä»¥æœŸæœ›åœ¨ä¸€å®šå®¹å·®èŒƒå›´å†…åœ¨å‘å¸ƒå’Œå¹³å°ä¹‹é—´å¤ç°ç»“æœã€‚å³ä½¿å¦‚æ­¤ï¼Œå®¹å·®ä¹Ÿå–å†³äºæ‰©æ•£æµæ°´çº¿å’Œæ£€æŸ¥ç‚¹ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé‡è¦äº†è§£å¦‚ä½•æ§åˆ¶æ‰©æ•£æ¨¡å‹ä¸­çš„éšæœºæºæˆ–ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•ã€‚

ğŸ’¡ æˆ‘ä»¬å¼ºçƒˆå»ºè®®é˜…è¯»PyTorchå…³äºå¯å¤ç°æ€§çš„[å£°æ˜](https://pytorch.org/docs/stable/notes/randomness.html)ï¼š

> æ— æ³•ä¿è¯åœ¨PyTorchå‘å¸ƒã€å•ä¸ªæäº¤æˆ–ä¸åŒå¹³å°ä¹‹é—´å®Œå…¨å¯å¤ç°çš„ç»“æœã€‚æ­¤å¤–ï¼Œå³ä½¿ä½¿ç”¨ç›¸åŒçš„ç§å­ï¼Œåœ¨CPUå’ŒGPUæ‰§è¡Œä¹‹é—´ä¹Ÿå¯èƒ½æ— æ³•å¤ç°ç»“æœã€‚

## æ§åˆ¶éšæœºæ€§

åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæµæ°´çº¿ä¸¥é‡ä¾èµ–éšæœºæŠ½æ ·æ“ä½œï¼ŒåŒ…æ‹¬åˆ›å»ºé«˜æ–¯å™ªå£°å¼ é‡ä»¥å»å™ªå’Œåœ¨è°ƒåº¦æ­¥éª¤ä¸­æ·»åŠ å™ªå£°ã€‚

åœ¨ä¸¤ä¸ªæ¨ç†æ­¥éª¤ä¹‹åæŸ¥çœ‹[DDIMPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/ddim#diffusers.DDIMPipeline)ä¸­çš„å¼ é‡å€¼ï¼š

```py
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np").images
print(np.abs(image).sum())
```

è¿è¡Œä¸Šé¢çš„ä»£ç ä¼šæ‰“å°ä¸€ä¸ªå€¼ï¼Œä½†å¦‚æœå†æ¬¡è¿è¡Œï¼Œä¼šå¾—åˆ°ä¸åŒçš„å€¼ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ

æ¯æ¬¡è¿è¡Œæµæ°´çº¿æ—¶ï¼Œ[`torch.randn`](https://pytorch.org/docs/stable/generated/torch.randn.html)ä½¿ç”¨ä¸åŒçš„éšæœºç§å­åˆ›å»ºé«˜æ–¯å™ªå£°ï¼Œé€æ­¥å»å™ªã€‚è¿™å¯¼è‡´æ¯æ¬¡è¿è¡Œæ—¶éƒ½ä¼šäº§ç”Ÿä¸åŒçš„ç»“æœï¼Œè¿™å¯¹äºæ‰©æ•£æµæ°´çº¿æ˜¯å¾ˆå¥½çš„ï¼Œå› ä¸ºå®ƒæ¯æ¬¡ç”Ÿæˆä¸åŒçš„éšæœºå›¾åƒã€‚

ä½†æ˜¯ï¼Œå¦‚æœæ‚¨éœ€è¦å¯é åœ°ç”Ÿæˆç›¸åŒçš„å›¾åƒï¼Œåˆ™å–å†³äºæ‚¨æ˜¯åœ¨CPUè¿˜æ˜¯GPUä¸Šè¿è¡Œæµæ°´çº¿ã€‚

### CPU

è¦åœ¨CPUä¸Šç”Ÿæˆå¯å¤ç°çš„ç»“æœï¼Œæ‚¨éœ€è¦ä½¿ç”¨PyTorch [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)å¹¶è®¾ç½®ä¸€ä¸ªç§å­ï¼š

```py
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)

# create a generator for reproducibility
generator = torch.Generator(device="cpu").manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```

ç°åœ¨å½“æ‚¨è¿è¡Œä¸Šé¢çš„ä»£ç æ—¶ï¼Œæ— è®ºå¦‚ä½•éƒ½ä¼šæ‰“å°ä¸€ä¸ªå€¼`1491.1711`ï¼Œå› ä¸º`Generator`å¯¹è±¡ä¸ç§å­ä¸€èµ·ä¼ é€’ç»™æµæ°´çº¿çš„æ‰€æœ‰éšæœºå‡½æ•°ã€‚

å¦‚æœæ‚¨åœ¨æ‚¨çš„ç‰¹å®šç¡¬ä»¶å’ŒPyTorchç‰ˆæœ¬ä¸Šè¿è¡Œæ­¤ä»£ç ç¤ºä¾‹ï¼Œæ‚¨åº”è¯¥è·å¾—ç±»ä¼¼çš„ç»“æœï¼Œå¦‚æœä¸æ˜¯ç›¸åŒçš„è¯ã€‚

ğŸ’¡ ä¸€å¼€å§‹å¯èƒ½æœ‰ç‚¹ä¸ç›´è§‚ï¼Œå°†`Generator`å¯¹è±¡ä¼ é€’ç»™æµæ°´çº¿è€Œä¸ä»…ä»…æ˜¯è¡¨ç¤ºç§å­çš„æ•´æ•°å€¼ï¼Œä½†è¿™æ˜¯å¤„ç†PyTorchä¸­æ¦‚ç‡æ¨¡å‹æ—¶æ¨èçš„è®¾è®¡ï¼Œå› ä¸º`Generator`æ˜¯å¯ä»¥ä¼ é€’ç»™å¤šä¸ªæµæ°´çº¿çš„*éšæœºçŠ¶æ€*ã€‚

### GPU

åœ¨GPUä¸Šç¼–å†™å¯å¤ç°çš„æµæ°´çº¿æœ‰ç‚¹æ£˜æ‰‹ï¼Œä¸ä¿è¯åœ¨ä¸åŒç¡¬ä»¶ä¸Šå®Œå…¨å¯å¤ç°ï¼Œå› ä¸ºçŸ©é˜µä¹˜æ³• - æ‰©æ•£æµæ°´çº¿éœ€è¦å¤§é‡çš„çŸ©é˜µä¹˜æ³• - åœ¨GPUä¸Šæ¯”åœ¨CPUä¸Šä¸å¤ªç¡®å®šã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åœ¨GPUä¸Šè¿è¡Œä¸Šé¢çš„ç›¸åŒä»£ç ç¤ºä¾‹ï¼š

```py
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)
ddim.to("cuda")

# create a generator for reproducibility
generator = torch.Generator(device="cuda").manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```

å³ä½¿ä½¿ç”¨ç›¸åŒçš„ç§å­ï¼Œç»“æœä¹Ÿä¸ç›¸åŒï¼Œå› ä¸ºGPUä½¿ç”¨çš„éšæœºæ•°ç”Ÿæˆå™¨ä¸CPUä¸åŒã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒğŸ§¨ Diffusersæœ‰ä¸€ä¸ª`randn_tensor()`å‡½æ•°ï¼Œç”¨äºåœ¨CPUä¸Šåˆ›å»ºéšæœºå™ªå£°ï¼Œç„¶åå°†å¼ é‡ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœéœ€è¦ï¼‰ã€‚`randn_tensor`å‡½æ•°åœ¨æµæ°´çº¿å†…çš„å„å¤„éƒ½è¢«ä½¿ç”¨ï¼Œå…è®¸ç”¨æˆ·**å§‹ç»ˆ**ä¼ é€’ä¸€ä¸ªCPU `Generator`ï¼Œå³ä½¿æµæ°´çº¿åœ¨GPUä¸Šè¿è¡Œã€‚

ç°åœ¨æ‚¨ä¼šçœ‹åˆ°ç»“æœç°åœ¨æ›´æ¥è¿‘äº†ï¼

```py
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)
ddim.to("cuda")

# create a generator for reproducibility; notice you don't place it on the GPU!
generator = torch.manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```

ğŸ’¡ å¦‚æœå¯å¤ç°æ€§å¾ˆé‡è¦ï¼Œæˆ‘ä»¬å»ºè®®å§‹ç»ˆä¼ é€’ä¸€ä¸ªCPUç”Ÿæˆå™¨ã€‚æ€§èƒ½æŸå¤±é€šå¸¸å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå¹¶ä¸”æ‚¨å°†ç”Ÿæˆæ¯”åœ¨GPUä¸Šè¿è¡Œæµæ°´çº¿æ—¶æ›´ç›¸ä¼¼çš„å€¼ã€‚

å¯¹äºæ›´å¤æ‚çš„æµæ°´çº¿ï¼Œæ¯”å¦‚[UnCLIPPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/unclip#diffusers.UnCLIPPipeline)ï¼Œè¿™äº›é€šå¸¸ææ˜“å—åˆ°ç²¾åº¦è¯¯å·®ä¼ æ’­çš„å½±å“ã€‚ä¸è¦æœŸæœ›åœ¨ä¸åŒçš„GPUç¡¬ä»¶æˆ–PyTorchç‰ˆæœ¬ä¸Šè·å¾—ç±»ä¼¼çš„ç»“æœã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦åœ¨å®Œå…¨ç›¸åŒçš„ç¡¬ä»¶å’ŒPyTorchç‰ˆæœ¬ä¸Šè¿è¡Œä»¥å®ç°å®Œå…¨çš„å¯é‡ç°æ€§ã€‚

## ç¡®å®šæ€§ç®—æ³•

æ‚¨è¿˜å¯ä»¥é…ç½®PyTorchä½¿ç”¨ç¡®å®šæ€§ç®—æ³•æ¥åˆ›å»ºå¯é‡ç°çš„æµæ°´çº¿ã€‚ä½†æ˜¯ï¼Œæ‚¨åº”è¯¥æ„è¯†åˆ°ç¡®å®šæ€§ç®—æ³•å¯èƒ½æ¯”éç¡®å®šæ€§ç®—æ³•æ…¢ï¼Œæ‚¨å¯èƒ½ä¼šè§‚å¯Ÿåˆ°æ€§èƒ½ä¸‹é™ã€‚ä½†å¦‚æœå¯¹æ‚¨æ¥è¯´å¯é‡ç°æ€§å¾ˆé‡è¦ï¼Œé‚£ä¹ˆè¿™å°±æ˜¯æ­£ç¡®çš„æ–¹å¼ï¼

å½“æ“ä½œåœ¨å¤šä¸ªCUDAæµä¸­å¯åŠ¨æ—¶ï¼Œä¼šå‘ç”Ÿéç¡®å®šæ€§è¡Œä¸ºã€‚ä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œå°†ç¯å¢ƒå˜é‡[`CUBLAS_WORKSPACE_CONFIG`](https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility)è®¾ç½®ä¸º`:16:8`ï¼Œä»¥åœ¨è¿è¡Œæ—¶ä»…ä½¿ç”¨ä¸€ä¸ªç¼“å†²åŒºå¤§å°ã€‚

PyTorché€šå¸¸ä¼šå¯¹å¤šä¸ªç®—æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä»¥é€‰æ‹©æœ€å¿«çš„ç®—æ³•ï¼Œä½†å¦‚æœæ‚¨å¸Œæœ›å®ç°å¯é‡ç°æ€§ï¼Œåº”è¯¥ç¦ç”¨æ­¤åŠŸèƒ½ï¼Œå› ä¸ºåŸºå‡†æµ‹è¯•å¯èƒ½ä¼šæ¯æ¬¡é€‰æ‹©ä¸åŒçš„ç®—æ³•ã€‚æœ€åï¼Œå°†`True`ä¼ é€’ç»™[`torch.use_deterministic_algorithms`](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)ä»¥å¯ç”¨ç¡®å®šæ€§ç®—æ³•ã€‚

```py
import os
import torch

os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":16:8"

torch.backends.cudnn.benchmark = False
torch.use_deterministic_algorithms(True)
```

ç°åœ¨å½“æ‚¨ä¸¤æ¬¡è¿è¡Œç›¸åŒçš„æµæ°´çº¿æ—¶ï¼Œæ‚¨å°†è·å¾—ç›¸åŒçš„ç»“æœã€‚

```py
import torch
from diffusers import DDIMScheduler, StableDiffusionPipeline

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True).to("cuda")
pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
g = torch.Generator(device="cuda")

prompt = "A bear is playing a guitar on Times Square"

g.manual_seed(0)
result1 = pipe(prompt=prompt, num_inference_steps=50, generator=g, output_type="latent").images

g.manual_seed(0)
result2 = pipe(prompt=prompt, num_inference_steps=50, generator=g, output_type="latent").images

print("L_inf dist =", abs(result1 - result2).max())
"L_inf dist = tensor(0., device='cuda:0')"
```
