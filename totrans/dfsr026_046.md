# 创建可复现的流水线

> 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/reproducibility](https://huggingface.co/docs/diffusers/using-diffusers/reproducibility)

可复现性对于测试、复制结果甚至用于[改善图像质量](reusing_seeds)都很重要。然而，在扩散模型中的随机性是一种期望的属性，因为它允许流水线每次运行时生成不同的图像。虽然您不能期望在不同平台上获得完全相同的结果，但您可以期望在一定容差范围内在发布和平台之间复现结果。即使如此，容差也取决于扩散流水线和检查点。

这就是为什么重要了解如何控制扩散模型中的随机源或使用确定性算法。

💡 我们强烈建议阅读PyTorch关于可复现性的[声明](https://pytorch.org/docs/stable/notes/randomness.html)：

> 无法保证在PyTorch发布、单个提交或不同平台之间完全可复现的结果。此外，即使使用相同的种子，在CPU和GPU执行之间也可能无法复现结果。

## 控制随机性

在推理过程中，流水线严重依赖随机抽样操作，包括创建高斯噪声张量以去噪和在调度步骤中添加噪声。

在两个推理步骤之后查看[DDIMPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/ddim#diffusers.DDIMPipeline)中的张量值：

```py
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np").images
print(np.abs(image).sum())
```

运行上面的代码会打印一个值，但如果再次运行，会得到不同的值。这是怎么回事？

每次运行流水线时，[`torch.randn`](https://pytorch.org/docs/stable/generated/torch.randn.html)使用不同的随机种子创建高斯噪声，逐步去噪。这导致每次运行时都会产生不同的结果，这对于扩散流水线是很好的，因为它每次生成不同的随机图像。

但是，如果您需要可靠地生成相同的图像，则取决于您是在CPU还是GPU上运行流水线。

### CPU

要在CPU上生成可复现的结果，您需要使用PyTorch [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)并设置一个种子：

```py
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)

# create a generator for reproducibility
generator = torch.Generator(device="cpu").manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```

现在当您运行上面的代码时，无论如何都会打印一个值`1491.1711`，因为`Generator`对象与种子一起传递给流水线的所有随机函数。

如果您在您的特定硬件和PyTorch版本上运行此代码示例，您应该获得类似的结果，如果不是相同的话。

💡 一开始可能有点不直观，将`Generator`对象传递给流水线而不仅仅是表示种子的整数值，但这是处理PyTorch中概率模型时推荐的设计，因为`Generator`是可以传递给多个流水线的*随机状态*。

### GPU

在GPU上编写可复现的流水线有点棘手，不保证在不同硬件上完全可复现，因为矩阵乘法 - 扩散流水线需要大量的矩阵乘法 - 在GPU上比在CPU上不太确定。例如，如果您在GPU上运行上面的相同代码示例：

```py
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)
ddim.to("cuda")

# create a generator for reproducibility
generator = torch.Generator(device="cuda").manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```

即使使用相同的种子，结果也不相同，因为GPU使用的随机数生成器与CPU不同。

为了解决这个问题，🧨 Diffusers有一个`randn_tensor()`函数，用于在CPU上创建随机噪声，然后将张量移动到GPU（如果需要）。`randn_tensor`函数在流水线内的各处都被使用，允许用户**始终**传递一个CPU `Generator`，即使流水线在GPU上运行。

现在您会看到结果现在更接近了！

```py
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)
ddim.to("cuda")

# create a generator for reproducibility; notice you don't place it on the GPU!
generator = torch.manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```

💡 如果可复现性很重要，我们建议始终传递一个CPU生成器。性能损失通常可以忽略不计，并且您将生成比在GPU上运行流水线时更相似的值。

对于更复杂的流水线，比如[UnCLIPPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/unclip#diffusers.UnCLIPPipeline)，这些通常极易受到精度误差传播的影响。不要期望在不同的GPU硬件或PyTorch版本上获得类似的结果。在这种情况下，您需要在完全相同的硬件和PyTorch版本上运行以实现完全的可重现性。

## 确定性算法

您还可以配置PyTorch使用确定性算法来创建可重现的流水线。但是，您应该意识到确定性算法可能比非确定性算法慢，您可能会观察到性能下降。但如果对您来说可重现性很重要，那么这就是正确的方式！

当操作在多个CUDA流中启动时，会发生非确定性行为。为了避免这种情况，将环境变量[`CUBLAS_WORKSPACE_CONFIG`](https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility)设置为`:16:8`，以在运行时仅使用一个缓冲区大小。

PyTorch通常会对多个算法进行基准测试，以选择最快的算法，但如果您希望实现可重现性，应该禁用此功能，因为基准测试可能会每次选择不同的算法。最后，将`True`传递给[`torch.use_deterministic_algorithms`](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)以启用确定性算法。

```py
import os
import torch

os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":16:8"

torch.backends.cudnn.benchmark = False
torch.use_deterministic_algorithms(True)
```

现在当您两次运行相同的流水线时，您将获得相同的结果。

```py
import torch
from diffusers import DDIMScheduler, StableDiffusionPipeline

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True).to("cuda")
pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
g = torch.Generator(device="cuda")

prompt = "A bear is playing a guitar on Times Square"

g.manual_seed(0)
result1 = pipe(prompt=prompt, num_inference_steps=50, generator=g, output_type="latent").images

g.manual_seed(0)
result2 = pipe(prompt=prompt, num_inference_steps=50, generator=g, output_type="latent").images

print("L_inf dist =", abs(result1 - result2).max())
"L_inf dist = tensor(0., device='cuda:0')"
```
