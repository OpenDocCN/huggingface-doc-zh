["```py\n>>> from transformers import HubertModel, HubertConfig\n\n>>> # Initializing a Hubert facebook/hubert-base-ls960 style configuration\n>>> configuration = HubertConfig()\n\n>>> # Initializing a model from the facebook/hubert-base-ls960 style configuration\n>>> model = HubertModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoProcessor, HubertModel\n>>> from datasets import load_dataset\n>>> import soundfile as sf\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n>>> model = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n\n>>> def map_to_array(batch):\n...     speech, _ = sf.read(batch[\"file\"])\n...     batch[\"speech\"] = speech\n...     return batch\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.map(map_to_array)\n\n>>> input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n>>> hidden_states = model(input_values).last_hidden_state\n```", "```py\n>>> from transformers import AutoProcessor, HubertForCTC\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n>>> dataset = dataset.sort(\"id\")\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n>>> model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n\n>>> # audio file is decoded on the fly\n>>> inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n>>> predicted_ids = torch.argmax(logits, dim=-1)\n\n>>> # transcribe speech\n>>> transcription = processor.batch_decode(predicted_ids)\n>>> transcription[0]\n'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'\n\n>>> inputs[\"labels\"] = processor(text=dataset[0][\"text\"], return_tensors=\"pt\").input_ids\n\n>>> # compute loss\n>>> loss = model(**inputs).loss\n>>> round(loss.item(), 2)\n22.68\n```", "```py\n>>> from transformers import AutoFeatureExtractor, HubertForSequenceClassification\n>>> from datasets import load_dataset\n>>> import torch\n\n>>> dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n>>> dataset = dataset.sort(\"id\")\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"superb/hubert-base-superb-ks\")\n>>> model = HubertForSequenceClassification.from_pretrained(\"superb/hubert-base-superb-ks\")\n\n>>> # audio file is decoded on the fly\n>>> inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> predicted_class_ids = torch.argmax(logits, dim=-1).item()\n>>> predicted_label = model.config.id2label[predicted_class_ids]\n>>> predicted_label\n'_unknown_'\n\n>>> # compute loss - target_label is e.g. \"down\"\n>>> target_label = model.config.id2label[0]\n>>> inputs[\"labels\"] = torch.tensor([model.config.label2id[target_label]])\n>>> loss = model(**inputs).loss\n>>> round(loss.item(), 2)\n8.53\n```", "```py\n>>> from transformers import AutoProcessor, TFHubertModel\n>>> from datasets import load_dataset\n>>> import soundfile as sf\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n>>> model = TFHubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n\n>>> def map_to_array(batch):\n...     speech, _ = sf.read(batch[\"file\"])\n...     batch[\"speech\"] = speech\n...     return batch\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.map(map_to_array)\n\n>>> input_values = processor(ds[\"speech\"][0], return_tensors=\"tf\").input_values  # Batch size 1\n>>> hidden_states = model(input_values).last_hidden_state\n```", "```py\n>>> import tensorflow as tf\n>>> from transformers import AutoProcessor, TFHubertForCTC\n>>> from datasets import load_dataset\n>>> import soundfile as sf\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n>>> model = TFHubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n\n>>> def map_to_array(batch):\n...     speech, _ = sf.read(batch[\"file\"])\n...     batch[\"speech\"] = speech\n...     return batch\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.map(map_to_array)\n\n>>> input_values = processor(ds[\"speech\"][0], return_tensors=\"tf\").input_values  # Batch size 1\n>>> logits = model(input_values).logits\n>>> predicted_ids = tf.argmax(logits, axis=-1)\n\n>>> transcription = processor.decode(predicted_ids[0])\n\n>>> # compute loss\n>>> target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n\n>>> # Pass the transcription as text to encode labels\n>>> labels = processor(text=transcription, return_tensors=\"tf\").input_values\n\n>>> loss = model(input_values, labels=labels).loss\n```"]