- en: Accelerated PyTorch Training on Mac
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Mac上加速PyTorch训练
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/mps](https://huggingface.co/docs/accelerate/usage_guides/mps)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/accelerate/usage_guides/mps](https://huggingface.co/docs/accelerate/usage_guides/mps)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: With PyTorch v1.12 release, developers and researchers can take advantage of
    Apple silicon GPUs for significantly faster model training. This unlocks the ability
    to perform machine learning workflows like prototyping and fine-tuning locally,
    right on Mac. Apple’s Metal Performance Shaders (MPS) as a backend for PyTorch
    enables this and can be used via the new `"mps"` device. This will map computational
    graphs and primitives on the MPS Graph framework and tuned kernels provided by
    MPS. For more information please refer official documents [Introducing Accelerated
    PyTorch Training on Mac](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)
    and [MPS BACKEND](https://pytorch.org/docs/stable/notes/mps.html).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过PyTorch v1.12版本，开发人员和研究人员可以利用Apple硅GPU进行更快的模型训练。这使得能够在Mac上本地进行原型设计和微调等机器学习工作流程成为可能。Apple的Metal
    Performance Shaders（MPS）作为PyTorch的后端实现了这一点，并可以通过新的"`mps`"设备使用。这将在MPS图框架上映射计算图和基于MPS提供的调整内核。有关更多信息，请参考官方文档[在Mac上介绍加速PyTorch训练](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)和[MPS后端](https://pytorch.org/docs/stable/notes/mps.html)。
- en: Benefits of Training and Inference using Apple Silicon Chips
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Apple Silicon芯片进行训练和推断的好处
- en: Enables users to train larger networks or batch sizes locally
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用户能够在本地训练更大的网络或批量大小。
- en: Reduces data retrieval latency and provides the GPU with direct access to the
    full memory store due to unified memory architecture. Therefore, improving end-to-end
    performance.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于统一内存架构，降低数据检索延迟并使GPU直接访问完整内存存储，从而提高端到端性能。
- en: Reduces costs associated with cloud-based development or the need for additional
    local GPUs.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 降低与基于云的开发或需要额外本地GPU相关的成本。
- en: '**Pre-requisites**: To install torch with mps support, please follow this nice
    medium article [GPU-Acceleration Comes to PyTorch on M1 Macs](https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**先决条件**：要安装带有mps支持的torch，请按照这篇不错的中等文章[GPU加速来到M1 Mac上的PyTorch](https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1)。'
- en: How it works out of the box
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开箱即用的工作原理
- en: It is enabled by default on MacOs machines with MPS enabled Apple Silicon GPUs.
    To disable it, pass `--cpu` flag to `accelerate launch` command or answer the
    corresponding question when answering the `accelerate config` questionnaire.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在启用了MPS的Apple Silicon GPU的MacOS机器上默认启用。要禁用它，请在`accelerate launch`命令中传递`--cpu`标志，或在回答`accelerate
    config`问卷时回答相应问题。
- en: 'You can directly run the following script to test it out on MPS enabled Apple
    Silicon machines:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接在启用了MPS的Apple Silicon机器上运行以下脚本进行测试：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A few caveats to be aware of
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需要注意的一些注意事项
- en: We strongly recommend to install PyTorch >= 1.13 (nightly version at the time
    of writing) on your MacOS machine. It has major fixes related to model correctness
    and performance improvements for transformer based models. Please refer to [https://github.com/pytorch/pytorch/issues/82707](https://github.com/pytorch/pytorch/issues/82707)
    for more details.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们强烈建议在您的MacOS机器上安装PyTorch >= 1.13（在撰写本文时为nightly版本）。它修复了与模型正确性和基于transformer的模型性能改进相关的主要问题。请参考[https://github.com/pytorch/pytorch/issues/82707](https://github.com/pytorch/pytorch/issues/82707)获取更多详细信息。
- en: Distributed setups `gloo` and `nccl` are not working with `mps` device. This
    means that currently only single GPU of `mps` device type can be used.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分布式设置`gloo`和`nccl`与`mps`设备不兼容。这意味着目前只能使用`mps`设备类型的单个GPU。
- en: Finally, please, remember that, 🤗 `Accelerate` only integrates MPS backend,
    therefore if you have any problems or questions with regards to MPS backend usage,
    please, file an issue with [PyTorch GitHub](https://github.com/pytorch/pytorch/issues).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请记住，🤗 `Accelerate`仅集成了MPS后端，因此如果您对MPS后端的使用有任何问题或疑问，请在[PyTorch GitHub](https://github.com/pytorch/pytorch/issues)上提交问题。
