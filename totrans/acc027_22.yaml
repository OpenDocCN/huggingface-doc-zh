- en: Accelerated PyTorch Training on Mac
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨Macä¸ŠåŠ é€ŸPyTorchè®­ç»ƒ
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/mps](https://huggingface.co/docs/accelerate/usage_guides/mps)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/accelerate/usage_guides/mps](https://huggingface.co/docs/accelerate/usage_guides/mps)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: With PyTorch v1.12 release, developers and researchers can take advantage of
    Apple silicon GPUs for significantly faster model training. This unlocks the ability
    to perform machine learning workflows like prototyping and fine-tuning locally,
    right on Mac. Appleâ€™s Metal Performance Shaders (MPS) as a backend for PyTorch
    enables this and can be used via the new `"mps"` device. This will map computational
    graphs and primitives on the MPS Graph framework and tuned kernels provided by
    MPS. For more information please refer official documents [Introducing Accelerated
    PyTorch Training on Mac](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)
    and [MPS BACKEND](https://pytorch.org/docs/stable/notes/mps.html).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡PyTorch v1.12ç‰ˆæœ¬ï¼Œå¼€å‘äººå‘˜å’Œç ”ç©¶äººå‘˜å¯ä»¥åˆ©ç”¨Appleç¡…GPUè¿›è¡Œæ›´å¿«çš„æ¨¡å‹è®­ç»ƒã€‚è¿™ä½¿å¾—èƒ½å¤Ÿåœ¨Macä¸Šæœ¬åœ°è¿›è¡ŒåŸå‹è®¾è®¡å’Œå¾®è°ƒç­‰æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æˆä¸ºå¯èƒ½ã€‚Appleçš„Metal
    Performance Shadersï¼ˆMPSï¼‰ä½œä¸ºPyTorchçš„åç«¯å®ç°äº†è¿™ä¸€ç‚¹ï¼Œå¹¶å¯ä»¥é€šè¿‡æ–°çš„"`mps`"è®¾å¤‡ä½¿ç”¨ã€‚è¿™å°†åœ¨MPSå›¾æ¡†æ¶ä¸Šæ˜ å°„è®¡ç®—å›¾å’ŒåŸºäºMPSæä¾›çš„è°ƒæ•´å†…æ ¸ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£[åœ¨Macä¸Šä»‹ç»åŠ é€ŸPyTorchè®­ç»ƒ](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)å’Œ[MPSåç«¯](https://pytorch.org/docs/stable/notes/mps.html)ã€‚
- en: Benefits of Training and Inference using Apple Silicon Chips
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Apple SiliconèŠ¯ç‰‡è¿›è¡Œè®­ç»ƒå’Œæ¨æ–­çš„å¥½å¤„
- en: Enables users to train larger networks or batch sizes locally
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨æœ¬åœ°è®­ç»ƒæ›´å¤§çš„ç½‘ç»œæˆ–æ‰¹é‡å¤§å°ã€‚
- en: Reduces data retrieval latency and provides the GPU with direct access to the
    full memory store due to unified memory architecture. Therefore, improving end-to-end
    performance.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”±äºç»Ÿä¸€å†…å­˜æ¶æ„ï¼Œé™ä½æ•°æ®æ£€ç´¢å»¶è¿Ÿå¹¶ä½¿GPUç›´æ¥è®¿é—®å®Œæ•´å†…å­˜å­˜å‚¨ï¼Œä»è€Œæé«˜ç«¯åˆ°ç«¯æ€§èƒ½ã€‚
- en: Reduces costs associated with cloud-based development or the need for additional
    local GPUs.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é™ä½ä¸åŸºäºäº‘çš„å¼€å‘æˆ–éœ€è¦é¢å¤–æœ¬åœ°GPUç›¸å…³çš„æˆæœ¬ã€‚
- en: '**Pre-requisites**: To install torch with mps support, please follow this nice
    medium article [GPU-Acceleration Comes to PyTorch on M1 Macs](https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…ˆå†³æ¡ä»¶**ï¼šè¦å®‰è£…å¸¦æœ‰mpsæ”¯æŒçš„torchï¼Œè¯·æŒ‰ç…§è¿™ç¯‡ä¸é”™çš„ä¸­ç­‰æ–‡ç« [GPUåŠ é€Ÿæ¥åˆ°M1 Macä¸Šçš„PyTorch](https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1)ã€‚'
- en: How it works out of the box
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¼€ç®±å³ç”¨çš„å·¥ä½œåŸç†
- en: It is enabled by default on MacOs machines with MPS enabled Apple Silicon GPUs.
    To disable it, pass `--cpu` flag to `accelerate launch` command or answer the
    corresponding question when answering the `accelerate config` questionnaire.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯ç”¨äº†MPSçš„Apple Silicon GPUçš„MacOSæœºå™¨ä¸Šé»˜è®¤å¯ç”¨ã€‚è¦ç¦ç”¨å®ƒï¼Œè¯·åœ¨`accelerate launch`å‘½ä»¤ä¸­ä¼ é€’`--cpu`æ ‡å¿—ï¼Œæˆ–åœ¨å›ç­”`accelerate
    config`é—®å·æ—¶å›ç­”ç›¸åº”é—®é¢˜ã€‚
- en: 'You can directly run the following script to test it out on MPS enabled Apple
    Silicon machines:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ç›´æ¥åœ¨å¯ç”¨äº†MPSçš„Apple Siliconæœºå™¨ä¸Šè¿è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡Œæµ‹è¯•ï¼š
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A few caveats to be aware of
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éœ€è¦æ³¨æ„çš„ä¸€äº›æ³¨æ„äº‹é¡¹
- en: We strongly recommend to install PyTorch >= 1.13 (nightly version at the time
    of writing) on your MacOS machine. It has major fixes related to model correctness
    and performance improvements for transformer based models. Please refer to [https://github.com/pytorch/pytorch/issues/82707](https://github.com/pytorch/pytorch/issues/82707)
    for more details.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼ºçƒˆå»ºè®®åœ¨æ‚¨çš„MacOSæœºå™¨ä¸Šå®‰è£…PyTorch >= 1.13ï¼ˆåœ¨æ’°å†™æœ¬æ–‡æ—¶ä¸ºnightlyç‰ˆæœ¬ï¼‰ã€‚å®ƒä¿®å¤äº†ä¸æ¨¡å‹æ­£ç¡®æ€§å’ŒåŸºäºtransformerçš„æ¨¡å‹æ€§èƒ½æ”¹è¿›ç›¸å…³çš„ä¸»è¦é—®é¢˜ã€‚è¯·å‚è€ƒ[https://github.com/pytorch/pytorch/issues/82707](https://github.com/pytorch/pytorch/issues/82707)è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: Distributed setups `gloo` and `nccl` are not working with `mps` device. This
    means that currently only single GPU of `mps` device type can be used.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒå¼è®¾ç½®`gloo`å’Œ`nccl`ä¸`mps`è®¾å¤‡ä¸å…¼å®¹ã€‚è¿™æ„å‘³ç€ç›®å‰åªèƒ½ä½¿ç”¨`mps`è®¾å¤‡ç±»å‹çš„å•ä¸ªGPUã€‚
- en: Finally, please, remember that, ğŸ¤— `Accelerate` only integrates MPS backend,
    therefore if you have any problems or questions with regards to MPS backend usage,
    please, file an issue with [PyTorch GitHub](https://github.com/pytorch/pytorch/issues).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè¯·è®°ä½ï¼ŒğŸ¤— `Accelerate`ä»…é›†æˆäº†MPSåç«¯ï¼Œå› æ­¤å¦‚æœæ‚¨å¯¹MPSåç«¯çš„ä½¿ç”¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘é—®ï¼Œè¯·åœ¨[PyTorch GitHub](https://github.com/pytorch/pytorch/issues)ä¸Šæäº¤é—®é¢˜ã€‚
