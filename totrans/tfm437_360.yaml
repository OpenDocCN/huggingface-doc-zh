- en: Nougat
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nougat
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: 'The Nougat model was proposed in [Nougat: Neural Optical Understanding for
    Academic Documents](https://arxiv.org/abs/2308.13418) by Lukas Blecher, Guillem
    Cucurull, Thomas Scialom, Robert Stojnic. Nougat uses the same architecture as
    [Donut](donut), meaning an image Transformer encoder and an autoregressive text
    Transformer decoder to translate scientific PDFs to markdown, enabling easier
    access to them.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'Nougatæ¨¡å‹æ˜¯ç”±Lukas Blecherã€Guillem Cucurullã€Thomas Scialomã€Robert Stojnicæå‡ºçš„[Nougat:
    ç”¨äºå­¦æœ¯æ–‡æ¡£çš„ç¥ç»å…‰å­¦ç†è§£](https://arxiv.org/abs/2308.13418)ã€‚Nougatä½¿ç”¨ä¸[Donut](donut)ç›¸åŒçš„æ¶æ„ï¼Œå³å›¾åƒTransformerç¼–ç å™¨å’Œè‡ªå›å½’æ–‡æœ¬Transformerè§£ç å™¨ï¼Œå°†ç§‘å­¦PDFè½¬æ¢ä¸ºæ ‡è®°ï¼Œä½¿å…¶æ›´æ˜“äºè®¿é—®ã€‚'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*Scientific knowledge is predominantly stored in books and scientific journals,
    often in the form of PDFs. However, the PDF format leads to a loss of semantic
    information, particularly for mathematical expressions. We propose Nougat (Neural
    Optical Understanding for Academic Documents), a Visual Transformer model that
    performs an Optical Character Recognition (OCR) task for processing scientific
    documents into a markup language, and demonstrate the effectiveness of our model
    on a new dataset of scientific documents. The proposed approach offers a promising
    solution to enhance the accessibility of scientific knowledge in the digital age,
    by bridging the gap between human-readable documents and machine-readable text.
    We release the models and code to accelerate future work on scientific text recognition.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç§‘å­¦çŸ¥è¯†ä¸»è¦å­˜å‚¨åœ¨ä¹¦ç±å’Œç§‘å­¦æœŸåˆŠä¸­ï¼Œé€šå¸¸ä»¥PDFå½¢å¼å­˜åœ¨ã€‚ç„¶è€Œï¼ŒPDFæ ¼å¼ä¼šå¯¼è‡´è¯­ä¹‰ä¿¡æ¯çš„ä¸¢å¤±ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ•°å­¦è¡¨è¾¾å¼ã€‚æˆ‘ä»¬æå‡ºäº†Nougatï¼ˆç”¨äºå­¦æœ¯æ–‡æ¡£çš„ç¥ç»å…‰å­¦ç†è§£ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè§†è§‰Transformeræ¨¡å‹ï¼Œç”¨äºå°†ç§‘å­¦æ–‡æ¡£è¿›è¡Œå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ä»»åŠ¡ï¼Œè½¬æ¢ä¸ºæ ‡è®°è¯­è¨€ï¼Œå¹¶å±•ç¤ºäº†æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ–°çš„ç§‘å­¦æ–‡æ¡£æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ºå¢å¼ºæ•°å­—æ—¶ä»£ç§‘å­¦çŸ¥è¯†çš„å¯è®¿é—®æ€§æä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡å¼¥åˆäººç±»å¯è¯»æ–‡æ¡£å’Œæœºå™¨å¯è¯»æ–‡æœ¬ä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬å‘å¸ƒäº†æ¨¡å‹å’Œä»£ç ï¼Œä»¥åŠ é€Ÿæœªæ¥å…³äºç§‘å­¦æ–‡æœ¬è¯†åˆ«çš„å·¥ä½œã€‚*'
- en: '![drawing](../Images/815b74c6366c16cb9cb90a9d9b246b4c.png) Nougat high-level
    overview. Taken from the [original paper](https://arxiv.org/abs/2308.13418).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![å›¾ç¤º](../Images/815b74c6366c16cb9cb90a9d9b246b4c.png) Nougaté«˜å±‚æ¦‚è¿°ã€‚æ‘˜è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2308.13418)ã€‚'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/facebookresearch/nougat).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯åœ¨[æ­¤å¤„](https://github.com/facebookresearch/nougat)æ‰¾åˆ°ã€‚
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æç¤º
- en: The quickest way to get started with Nougat is by checking the [tutorial notebooks](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Nougat),
    which show how to use the model at inference time as well as fine-tuning on custom
    data.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼€å§‹ä½¿ç”¨Nougatçš„æœ€å¿«æ–¹æ³•æ˜¯æŸ¥çœ‹[æ•™ç¨‹ç¬”è®°æœ¬](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Nougat)ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨æ¨ç†æ—¶ä½¿ç”¨æ¨¡å‹ä»¥åŠåœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚
- en: Nougat is always used within the [VisionEncoderDecoder](vision-encoder-decoder)
    framework. The model is identical to [Donut](donut) in terms of architecture.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nougatå§‹ç»ˆåœ¨[VisionEncoderDecoder](vision-encoder-decoder)æ¡†æ¶å†…ä½¿ç”¨ã€‚è¯¥æ¨¡å‹åœ¨æ¶æ„ä¸Šä¸[Donut](donut)ç›¸åŒã€‚
- en: Inference
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨ç†
- en: Nougatâ€™s `VisionEncoderDecoder` model accepts images as input and makes use
    of [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    to autoregressively generate text given the input image.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Nougatçš„`VisionEncoderDecoder`æ¨¡å‹æ¥å—å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶åˆ©ç”¨[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)æ¥è‡ªåŠ¨å›å½’ç”Ÿæˆç»™å®šè¾“å…¥å›¾åƒçš„æ–‡æœ¬ã€‚
- en: The [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    class is responsible for preprocessing the input image and [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)
    decodes the generated target tokens to the target string. The [NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)
    wraps [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    and [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)
    classes into a single instance to both extract the input features and decode the
    predicted token ids.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)ç±»è´Ÿè´£é¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œ[NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)è§£ç ç”Ÿæˆçš„ç›®æ ‡æ ‡è®°ä¸ºç›®æ ‡å­—ç¬¦ä¸²ã€‚[NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)å°†[NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)å’Œ[NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)ç±»å°è£…ä¸ºå•ä¸ªå®ä¾‹ï¼Œç”¨äºæå–è¾“å…¥ç‰¹å¾å’Œè§£ç é¢„æµ‹çš„æ ‡è®°IDã€‚'
- en: Step-by-step PDF transcription
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€æ­¥PDFè½¬å½•
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: See the [model hub](https://huggingface.co/models?filter=nougat) to look for
    Nougat checkpoints.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æŸ¥çœ‹[æ¨¡å‹ä¸­å¿ƒ](https://huggingface.co/models?filter=nougat)ä»¥æŸ¥æ‰¾Nougatæ£€æŸ¥ç‚¹ã€‚
- en: The model is identical to [Donut](donut) in terms of architecture.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹åœ¨æ¶æ„ä¸Šä¸[Donut](donut)ç›¸åŒã€‚
- en: NougatImageProcessor
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NougatImageProcessor
- en: '### `class transformers.NougatImageProcessor`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.NougatImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L57)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L57)'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`do_crop_margin` (`bool`, *optional*, defaults to `True`) â€” Whether to crop
    the image margins.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_crop_margin`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦è£å‰ªå›¾åƒè¾¹è·ã€‚'
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) â€” Whether to resize the
    imageâ€™s (height, width) dimensions to the specified `size`. Can be overridden
    by `do_resize` in the `preprocess` method.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦å°†å›¾åƒçš„ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šçš„`size`ã€‚å¯ä»¥åœ¨`preprocess`æ–¹æ³•ä¸­é€šè¿‡`do_resize`è¿›è¡Œè¦†ç›–ã€‚'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 896, "width":
    672}`): Size of the image after resizing. Can be overridden by `size` in the `preprocess`
    method.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *å¯é€‰*, é»˜è®¤ä¸º `{"height" -- 896, "width": 672}`): è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚å¯ä»¥è¢«
    `preprocess` æ–¹æ³•ä¸­çš„ `size` è¦†ç›–ã€‚'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`)
    â€” Resampling filter to use if resizing the image. Can be overridden by `resample`
    in the `preprocess` method.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *å¯é€‰*, é»˜è®¤ä¸º `Resampling.BILINEAR`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚å¯ä»¥è¢«
    `preprocess` æ–¹æ³•ä¸­çš„ `resample` è¦†ç›–ã€‚'
- en: '`do_thumbnail` (`bool`, *optional*, defaults to `True`) â€” Whether to resize
    the image using thumbnail method.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_thumbnail` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä½¿ç”¨ç¼©ç•¥å›¾æ–¹æ³•è°ƒæ•´å›¾åƒå¤§å°ã€‚'
- en: '`do_align_long_axis` (`bool`, *optional*, defaults to `False`) â€” Whether to
    align the long axis of the image with the long axis of `size` by rotating by 90
    degrees.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_align_long_axis` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦é€šè¿‡æ—‹è½¬ 90 åº¦æ¥ä½¿å›¾åƒçš„é•¿è½´ä¸ `size`
    çš„é•¿è½´å¯¹é½ã€‚'
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) â€” Whether to pad the images
    to the largest image size in the batch.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†å›¾åƒå¡«å……åˆ°æ‰¹å¤„ç†ä¸­æœ€å¤§çš„å›¾åƒå°ºå¯¸ã€‚'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) â€” Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`
    parameter in the `preprocess` method.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor` é‡æ–°ç¼©æ”¾å›¾åƒã€‚å¯ä»¥è¢«
    `preprocess` æ–¹æ³•ä¸­çš„ `do_rescale` å‚æ•°è¦†ç›–ã€‚'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) â€” Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in the `preprocess` method.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` æˆ– `float`, *å¯é€‰*, é»˜è®¤ä¸º `1/255`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚å¯ä»¥è¢«
    `preprocess` æ–¹æ³•ä¸­çš„ `rescale_factor` å‚æ•°è¦†ç›–ã€‚'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) â€” Whether to normalize
    the image. Can be overridden by `do_normalize` in the `preprocess` method.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„
    `do_normalize` è¦†ç›–ã€‚'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`)
    â€” Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `IMAGENET_DEFAULT_MEAN`) â€”
    å¦‚æœå½’ä¸€åŒ–å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„å‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_mean` å‚æ•°è¦†ç›–ã€‚'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`)
    â€” Image standard deviation.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `IMAGENET_DEFAULT_STD`) â€” å›¾åƒæ ‡å‡†å·®ã€‚'
- en: Constructs a Nougat image processor.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»º Nougat å›¾åƒå¤„ç†å™¨ã€‚
- en: '#### `preprocess`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L358)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L358)'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`ImageInput`) â€” Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒã€‚æœŸæœ›å•ä¸ªå›¾åƒæˆ–æ‰¹å¤„ç†å›¾åƒï¼Œåƒç´ å€¼èŒƒå›´ä¸º 0 åˆ° 255ã€‚'
- en: '`do_crop_margin` (`bool`, *optional*, defaults to `self.do_crop_margin`) â€”
    Whether to crop the image margins.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_crop_margin` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_crop_margin`) â€” æ˜¯å¦è£å‰ªå›¾åƒè¾¹ç¼˜ã€‚'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) â€” Whether to
    resize the image.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_resize`) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) â€” Size of the
    image after resizing. Shortest edge of the image is resized to min(size[â€œheightâ€],
    size[â€œwidthâ€]) with the longest edge resized to keep the input aspect ratio.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *å¯é€‰*, é»˜è®¤ä¸º `self.size`) â€” è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚å›¾åƒçš„æœ€çŸ­è¾¹è°ƒæ•´ä¸º min(size[â€œheightâ€],
    size[â€œwidthâ€])ï¼Œæœ€é•¿è¾¹è°ƒæ•´ä»¥ä¿æŒè¾“å…¥çš„é•¿å®½æ¯”ã€‚'
- en: '`resample` (`int`, *optional*, defaults to `self.resample`) â€” Resampling filter
    to use if resizing the image. This can be one of the enum `PILImageResampling`.
    Only has an effect if `do_resize` is set to `True`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.resample`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚è¿™å¯ä»¥æ˜¯æšä¸¾
    `PILImageResampling` ä¸­çš„ä¸€ä¸ªã€‚ä»…å½“ `do_resize` è®¾ç½®ä¸º `True` æ—¶æ‰ä¼šç”Ÿæ•ˆã€‚'
- en: '`do_thumbnail` (`bool`, *optional*, defaults to `self.do_thumbnail`) â€” Whether
    to resize the image using thumbnail method.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_thumbnail` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_thumbnail`) â€” æ˜¯å¦ä½¿ç”¨ç¼©ç•¥å›¾æ–¹æ³•è°ƒæ•´å›¾åƒå¤§å°ã€‚'
- en: '`do_align_long_axis` (`bool`, *optional*, defaults to `self.do_align_long_axis`)
    â€” Whether to align the long axis of the image with the long axis of `size` by
    rotating by 90 degrees.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_align_long_axis` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_align_long_axis`) â€” æ˜¯å¦é€šè¿‡æ—‹è½¬
    90 åº¦æ¥ä½¿å›¾åƒçš„é•¿è½´ä¸ `size` çš„é•¿è½´å¯¹é½ã€‚'
- en: '`do_pad` (`bool`, *optional*, defaults to `self.do_pad`) â€” Whether to pad the
    images to the largest image size in the batch.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_pad`) â€” æ˜¯å¦å°†å›¾åƒå¡«å……åˆ°æ‰¹å¤„ç†ä¸­æœ€å¤§çš„å›¾åƒå°ºå¯¸ã€‚'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) â€” Whether
    to rescale the image by the specified scale `rescale_factor`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_rescale`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor`
    é‡æ–°ç¼©æ”¾å›¾åƒã€‚'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `self.rescale_factor`)
    â€” Scale factor to use if rescaling the image.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` æˆ– `float`, *å¯é€‰*, é»˜è®¤ä¸º `self.rescale_factor`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) â€” Whether
    to normalize the image.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_normalize`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    â€” Image mean to use for normalization.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `self.image_mean`) â€” ç”¨äºå½’ä¸€åŒ–çš„å›¾åƒå‡å€¼ã€‚'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    â€” Image standard deviation to use for normalization.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `self.image_std`) â€” ç”¨äºå½’ä¸€åŒ–çš„å›¾åƒæ ‡å‡†å·®ã€‚'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) â€” The type of tensors
    to return. Can be one of:'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` æˆ– `TensorType`, *å¯é€‰*) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€:'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'æœªè®¾ç½®: è¿”å› `np.ndarray` çš„åˆ—è¡¨ã€‚'
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW` æˆ– `''tf''`: è¿”å›ç±»å‹ä¸º `tf.Tensor` çš„æ‰¹å¤„ç†ã€‚'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` æˆ– `''pt''`: è¿”å›ç±»å‹ä¸º `torch.Tensor` çš„æ‰¹å¤„ç†ã€‚'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY` æˆ– `''np''`: è¿”å›ç±»å‹ä¸º `np.ndarray` çš„æ‰¹å¤„ç†ã€‚'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX` æˆ– `''jax''`: è¿”å›ç±»å‹ä¸º `jax.numpy.ndarray` çš„æ‰¹å¤„ç†ã€‚'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    â€” The channel dimension format for the output image. Can be one of:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` æˆ– `str`, *optional*, é»˜è®¤ä¸º `ChannelDimension.FIRST`)
    â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`: å›¾åƒæ ¼å¼ä¸º (num_channels, height, width)ã€‚'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`: å›¾åƒæ ¼å¼ä¸º (height, width, num_channels)ã€‚'
- en: 'Unset: defaults to the channel dimension format of the input image.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœªè®¾ç½®ï¼šé»˜è®¤ä¸ºè¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) â€” The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format` (`ChannelDimension` æˆ– `str`, *optional*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` æˆ– `ChannelDimension.FIRST`: å›¾åƒæ ¼å¼ä¸º (num_channels, height,
    width)ã€‚'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` æˆ– `ChannelDimension.LAST`: å›¾åƒæ ¼å¼ä¸º (height, width, num_channels)ã€‚'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` æˆ– `ChannelDimension.NONE`: å›¾åƒæ ¼å¼ä¸º (height, width)ã€‚'
- en: Preprocess an image or batch of images.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†ä¸€å¼ å›¾ç‰‡æˆ–ä¸€æ‰¹å›¾ç‰‡ã€‚
- en: NougatTokenizerFast
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NougatTokenizerFast
- en: '### `class transformers.NougatTokenizerFast`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.NougatTokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L376)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L376)'
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_file` (`str`, *optional*) â€” [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a .model extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`, *optional*) â€” [SentencePiece](https://github.com/google/sentencepiece)
    æ–‡ä»¶ï¼ˆé€šå¸¸å…·æœ‰ .model æ‰©å±•åï¼‰ï¼Œå…¶ä¸­åŒ…å«å®ä¾‹åŒ–åˆ†è¯å™¨æ‰€éœ€çš„è¯æ±‡è¡¨ã€‚'
- en: '`tokenizer_file` (`str`, *optional*) â€” [tokenizers](https://github.com/huggingface/tokenizers)
    file (generally has a .json extension) that contains everything needed to load
    the tokenizer.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_file` (`str`, *optional*) â€” [tokenizers](https://github.com/huggingface/tokenizers)
    æ–‡ä»¶ï¼ˆé€šå¸¸å…·æœ‰ .json æ‰©å±•åï¼‰ï¼Œå…¶ä¸­åŒ…å«åŠ è½½åˆ†è¯å™¨æ‰€éœ€çš„æ‰€æœ‰å†…å®¹ã€‚'
- en: '`clean_up_tokenization_spaces` (`str`, *optional*, defaults to `False`) â€” Wether
    to cleanup spaces after decoding, cleanup consists in removing potential artifacts
    like extra spaces.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces` (`str`, *optional*, é»˜è®¤ä¸º `False`) â€” è§£ç åæ˜¯å¦æ¸…é™¤ç©ºæ ¼ï¼Œæ¸…é™¤åŒ…æ‹¬åˆ é™¤é¢å¤–ç©ºæ ¼ç­‰æ½œåœ¨ç‘•ç–µã€‚'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) â€” The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, é»˜è®¤ä¸º `"<unk>"`) â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­ä¸å­˜åœ¨çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸º IDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚'
- en: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) â€” The beginning of sequence
    token that was used during pretraining. Can be used a sequence classifier token.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *optional*, é»˜è®¤ä¸º `"<s>"`) â€” åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨çš„åºåˆ—å¼€å§‹æ ‡è®°ã€‚å¯ç”¨ä½œåºåˆ—åˆ†ç±»å™¨æ ‡è®°ã€‚'
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) â€” The end of sequence
    token.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *optional*, é»˜è®¤ä¸º `"</s>"`) â€” åºåˆ—ç»“æŸæ ‡è®°ã€‚'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) â€” The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, é»˜è®¤ä¸º `"<pad>"`) â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚'
- en: '`model_max_length` (`int`, *optional*) â€” The maximum length (in number of tokens)
    for the inputs to the transformer model. When the tokenizer is loaded with [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained),
    this will be set to the value stored for the associated model in `max_model_input_sizes`
    (see above). If no value is provided, will default to VERY_LARGE_INTEGER (`int(1e30)`).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_max_length` (`int`, *optional*) â€” è½¬æ¢å™¨æ¨¡å‹è¾“å…¥çš„æœ€å¤§é•¿åº¦ï¼ˆä»¥æ ‡è®°æ•°è®¡ï¼‰ã€‚å½“ä½¿ç”¨ [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)
    åŠ è½½åˆ†è¯å™¨æ—¶ï¼Œå°†è®¾ç½®ä¸ºå­˜å‚¨åœ¨ `max_model_input_sizes` ä¸­çš„ç›¸å…³æ¨¡å‹çš„å€¼ï¼ˆè¯·å‚è§ä¸Šæ–‡ï¼‰ã€‚å¦‚æœæœªæä¾›å€¼ï¼Œå°†é»˜è®¤ä¸º VERY_LARGE_INTEGER
    (`int(1e30)`ï¼‰ã€‚'
- en: '`padding_side` (`str`, *optional*) â€” The side on which the model should have
    padding applied. Should be selected between [â€˜rightâ€™, â€˜leftâ€™]. Default value is
    picked from the class attribute of the same name.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_side` (`str`, *optional*) â€” æ¨¡å‹åº”ç”¨å¡«å……çš„ä¾§é¢ã€‚åº”åœ¨ [''right'', ''left''] ä¸­é€‰æ‹©ã€‚é»˜è®¤å€¼ä»åŒåçš„ç±»å±æ€§ä¸­é€‰æ‹©ã€‚'
- en: '`truncation_side` (`str`, *optional*) â€” The side on which the model should
    have truncation applied. Should be selected between [â€˜rightâ€™, â€˜leftâ€™]. Default
    value is picked from the class attribute of the same name.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_side` (`str`, *optional*) â€” æ¨¡å‹åº”ç”¨æˆªæ–­çš„ä¾§é¢ã€‚åº”åœ¨ [''right'', ''left'']
    ä¸­é€‰æ‹©ã€‚é»˜è®¤å€¼ä»åŒåçš„ç±»å±æ€§ä¸­é€‰æ‹©ã€‚'
- en: '`chat_template` (`str`, *optional*) â€” A Jinja template string that will be
    used to format lists of chat messages. See [https://huggingface.co/docs/transformers/chat_templating](https://huggingface.co/docs/transformers/chat_templating)
    for a full description.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chat_template` (`str`, *optional*) â€” ä¸€ä¸ª Jinja æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–èŠå¤©æ¶ˆæ¯åˆ—è¡¨ã€‚è¯¦ç»†æè¿°è¯·å‚è§ [https://huggingface.co/docs/transformers/chat_templating](https://huggingface.co/docs/transformers/chat_templating)ã€‚'
- en: '`model_input_names` (`List[string]`, *optional*) â€” The list of inputs accepted
    by the forward pass of the model (like `"token_type_ids"` or `"attention_mask"`).
    Default value is picked from the class attribute of the same name.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input_names` (`List[string]`, *optional*) â€” æ¨¡å‹å‰å‘ä¼ é€’æ¥å—çš„è¾“å…¥åˆ—è¡¨ï¼ˆå¦‚ `"token_type_ids"`
    æˆ– `"attention_mask"`ï¼‰ã€‚é»˜è®¤å€¼ä»åŒåçš„ç±»å±æ€§ä¸­é€‰æ‹©ã€‚'
- en: '`bos_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    representing the beginning of a sentence. Will be associated to `self.bos_token`
    and `self.bos_token_id`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str` æˆ– `tokenizers.AddedToken`, *optional*) â€” è¡¨ç¤ºå¥å­å¼€å¤´çš„ç‰¹æ®Šæ ‡è®°ã€‚å°†ä¸
    `self.bos_token` å’Œ `self.bos_token_id` å…³è”ã€‚'
- en: '`eos_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    representing the end of a sentence. Will be associated to `self.eos_token` and
    `self.eos_token_id`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨å¥å­ç»“æŸçš„ç‰¹æ®Šæ ‡è®°ã€‚å°†ä¸`self.eos_token`å’Œ`self.eos_token_id`ç›¸å…³è”ã€‚'
- en: '`unk_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    representing an out-of-vocabulary token. Will be associated to `self.unk_token`
    and `self.unk_token_id`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨è¯æ±‡å¤–æ ‡è®°çš„ç‰¹æ®Šæ ‡è®°ã€‚å°†ä¸`self.unk_token`å’Œ`self.unk_token_id`ç›¸å…³è”ã€‚'
- en: '`sep_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    separating two different sentences in the same input (used by BERT for instance).
    Will be associated to `self.sep_token` and `self.sep_token_id`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºåœ¨åŒä¸€è¾“å…¥ä¸­åˆ†éš”ä¸¤ä¸ªä¸åŒå¥å­çš„ç‰¹æ®Šæ ‡è®°ï¼ˆä¾‹å¦‚BERTä½¿ç”¨ï¼‰ã€‚å°†ä¸`self.sep_token`å’Œ`self.sep_token_id`ç›¸å…³è”ã€‚'
- en: '`pad_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    used to make arrays of tokens the same size for batching purpose. Will then be
    ignored by attention mechanisms or loss computation. Will be associated to `self.pad_token`
    and `self.pad_token_id`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿æ ‡è®°æ•°ç»„å¤§å°ç›¸åŒä»¥è¿›è¡Œæ‰¹å¤„ç†çš„ç‰¹æ®Šæ ‡è®°ã€‚ç„¶åå°†è¢«æ³¨æ„æœºåˆ¶æˆ–æŸå¤±è®¡ç®—å¿½ç•¥ã€‚å°†ä¸`self.pad_token`å’Œ`self.pad_token_id`ç›¸å…³è”ã€‚'
- en: '`cls_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    representing the class of the input (used by BERT for instance). Will be associated
    to `self.cls_token` and `self.cls_token_id`.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨è¾“å…¥ç±»åˆ«çš„ç‰¹æ®Šæ ‡è®°ï¼ˆä¾‹å¦‚BERTä½¿ç”¨ï¼‰ã€‚å°†ä¸`self.cls_token`å’Œ`self.cls_token_id`ç›¸å…³è”ã€‚'
- en: '`mask_token` (`str` or `tokenizers.AddedToken`, *optional*) â€” A special token
    representing a masked token (used by masked-language modeling pretraining objectives,
    like BERT). Will be associated to `self.mask_token` and `self.mask_token_id`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨æ©ç æ ‡è®°çš„ç‰¹æ®Šæ ‡è®°ï¼ˆç”¨äºæ©ç è¯­è¨€å»ºæ¨¡é¢„è®­ç»ƒç›®æ ‡ï¼Œå¦‚BERTï¼‰ã€‚å°†ä¸`self.mask_token`å’Œ`self.mask_token_id`ç›¸å…³è”ã€‚'
- en: '`additional_special_tokens` (tuple or list of `str` or `tokenizers.AddedToken`,
    *optional*) â€” A tuple or a list of additional special tokens. Add them here to
    ensure they are skipped when decoding with `skip_special_tokens` is set to True.
    If they are not part of the vocabulary, they will be added at the end of the vocabulary.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`additional_special_tokens`ï¼ˆå…ƒç»„æˆ–`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ç»„é¢å¤–çš„ç‰¹æ®Šæ ‡è®°ã€‚åœ¨è¿™é‡Œæ·»åŠ å®ƒä»¬ä»¥ç¡®ä¿åœ¨å°†`skip_special_tokens`è®¾ç½®ä¸ºTrueæ—¶è§£ç æ—¶è·³è¿‡å®ƒä»¬ã€‚å¦‚æœå®ƒä»¬ä¸æ˜¯è¯æ±‡çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒä»¬å°†è¢«æ·»åŠ åˆ°è¯æ±‡çš„æœ«å°¾ã€‚'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `True`) â€” Whether
    or not the model should cleanup the spaces that were added when splitting the
    input text during the tokenization process.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ¨¡å‹æ˜¯å¦åº”æ¸…é™¤åœ¨æ ‡è®°åŒ–è¿‡ç¨‹ä¸­æ‹†åˆ†è¾“å…¥æ–‡æœ¬æ—¶æ·»åŠ çš„ç©ºæ ¼ã€‚'
- en: '`split_special_tokens` (`bool`, *optional*, defaults to `False`) â€” Whether
    or not the special tokens should be split during the tokenization process. The
    default behavior is to not split special tokens. This means that if `<s>` is the
    `bos_token`, then `tokenizer.tokenize("<s>") = [''<s>`]. Otherwise, if `split_special_tokens=True`,
    then `tokenizer.tokenize("<s>")` will be give `[''<'', ''s'', ''>'']`. This argument
    is only supported for `slow` tokenizers for the moment.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split_special_tokens`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦åœ¨æ ‡è®°åŒ–è¿‡ç¨‹ä¸­æ‹†åˆ†ç‰¹æ®Šæ ‡è®°ã€‚é»˜è®¤è¡Œä¸ºæ˜¯ä¸æ‹†åˆ†ç‰¹æ®Šæ ‡è®°ã€‚è¿™æ„å‘³ç€å¦‚æœ`<s>`æ˜¯`bos_token`ï¼Œé‚£ä¹ˆ`tokenizer.tokenize("<s>")
    = [''<s>`]`ã€‚å¦åˆ™ï¼Œå¦‚æœ`split_special_tokens=True`ï¼Œé‚£ä¹ˆ`tokenizer.tokenize("<s>")`å°†ç»™å‡º`[''<'',
    ''s'', ''>'']`ã€‚æ­¤å‚æ•°ç›®å‰ä»…æ”¯æŒ`slow`åˆ†è¯å™¨ã€‚'
- en: '`tokenizer_object` (`tokenizers.Tokenizer`) â€” A `tokenizers.Tokenizer` object
    from ğŸ¤— tokenizers to instantiate from. See [Using tokenizers from ğŸ¤— tokenizers](../fast_tokenizers)
    for more information.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_object`ï¼ˆ`tokenizers.Tokenizer`ï¼‰â€” æ¥è‡ªğŸ¤— tokenizersçš„`tokenizers.Tokenizer`å¯¹è±¡ï¼Œç”¨äºå®ä¾‹åŒ–ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[ä½¿ç”¨ğŸ¤—
    tokenizersä¸­çš„åˆ†è¯å™¨](../fast_tokenizers)ã€‚'
- en: '`tokenizer_file` (`str`) â€” A path to a local JSON file representing a previously
    serialized `tokenizers.Tokenizer` object from ğŸ¤— tokenizers.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_file`ï¼ˆ`str`ï¼‰â€” ä»£è¡¨ä»¥å‰åºåˆ—åŒ–çš„`tokenizers.Tokenizer`å¯¹è±¡çš„æœ¬åœ°JSONæ–‡ä»¶çš„è·¯å¾„ã€‚'
- en: Fast tokenizer for Nougat (backed by HuggingFace tokenizers library).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Nougatçš„å¿«é€Ÿåˆ†è¯å™¨ï¼ˆç”±HuggingFaceåˆ†è¯å™¨åº“æ”¯æŒï¼‰ã€‚
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods. This class mainly adds Nougat-specific
    methods for postprocessing the generated text.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ†è¯å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)ï¼Œå…¶ä¸­åŒ…å«å¤§å¤šæ•°ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒè¿™ä¸ªè¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚è¿™ä¸ªç±»ä¸»è¦ä¸ºåå¤„ç†ç”Ÿæˆçš„æ–‡æœ¬æ·»åŠ äº†Nougatç‰¹å®šçš„æ–¹æ³•ã€‚
- en: Class attributes (overridden by derived classes)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»å±æ€§ï¼ˆç”±æ´¾ç”Ÿç±»è¦†ç›–ï¼‰
- en: '`vocab_files_names` (`Dict[str, str]`) â€” A dictionary with, as keys, the `__init__`
    keyword name of each vocabulary file required by the model, and as associated
    values, the filename for saving the associated file (string).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_files_names`ï¼ˆ`Dict[str, str]`ï¼‰â€” ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®æ˜¯æ¨¡å‹æ‰€éœ€çš„æ¯ä¸ªè¯æ±‡æ–‡ä»¶çš„`__init__`å…³é”®å­—åç§°ï¼Œå…¶ç›¸å…³å€¼æ˜¯ç”¨äºä¿å­˜ç›¸å…³æ–‡ä»¶çš„æ–‡ä»¶åï¼ˆå­—ç¬¦ä¸²ï¼‰ã€‚'
- en: '`pretrained_vocab_files_map` (`Dict[str, Dict[str, str]]`) â€” A dictionary of
    dictionaries, with the high-level keys being the `__init__` keyword name of each
    vocabulary file required by the model, the low-level being the `short-cut-names`
    of the pretrained models with, as associated values, the `url` to the associated
    pretrained vocabulary file.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_vocab_files_map`ï¼ˆ`Dict[str, Dict[str, str]]`ï¼‰â€” ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é«˜çº§é”®æ˜¯æ¨¡å‹æ‰€éœ€çš„æ¯ä¸ªè¯æ±‡æ–‡ä»¶çš„`__init__`å…³é”®å­—åç§°ï¼Œä½çº§åˆ«æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„`short-cut-names`ï¼Œä½œä¸ºç›¸å…³å€¼ï¼Œæ˜¯ä¸ç›¸å…³é¢„è®­ç»ƒè¯æ±‡æ–‡ä»¶ç›¸å…³è”çš„`url`ã€‚'
- en: '`max_model_input_sizes` (`Dict[str, Optional[int]]`) â€” A dictionary with, as
    keys, the `short-cut-names` of the pretrained models, and as associated values,
    the maximum length of the sequence inputs of this model, or `None` if the model
    has no maximum input size.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_model_input_sizes`ï¼ˆ`Dict[str, Optional[int]]`ï¼‰â€” ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„`short-cut-names`ï¼Œå…¶ç›¸å…³å€¼æ˜¯è¯¥æ¨¡å‹çš„åºåˆ—è¾“å…¥çš„æœ€å¤§é•¿åº¦ï¼Œå¦‚æœæ¨¡å‹æ²¡æœ‰æœ€å¤§è¾“å…¥å¤§å°ï¼Œåˆ™ä¸º`None`ã€‚'
- en: '`pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) â€” A dictionary
    with, as keys, the `short-cut-names` of the pretrained models, and as associated
    values, a dictionary of specific arguments to pass to the `__init__` method of
    the tokenizer class for this pretrained model when loading the tokenizer with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)
    method.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) â€” ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºé¢„è®­ç»ƒæ¨¡å‹çš„`short-cut-names`ï¼Œå€¼ä¸ºä¼ é€’ç»™åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æ—¶tokenizerç±»çš„`__init__`æ–¹æ³•çš„ç‰¹å®šå‚æ•°çš„å­—å…¸ã€‚'
- en: '`model_input_names` (`List[str]`) â€” A list of inputs expected in the forward
    pass of the model.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input_names` (`List[str]`) â€” æ¨¡å‹å‰å‘ä¼ é€’ä¸­é¢„æœŸçš„è¾“å…¥åˆ—è¡¨ã€‚'
- en: '`padding_side` (`str`) â€” The default value for the side on which the model
    should have padding applied. Should be `''right''` or `''left''`.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_side` (`str`) â€” æ¨¡å‹åº”è¯¥åº”ç”¨å¡«å……çš„é»˜è®¤å€¼ã€‚åº”ä¸º`''right''`æˆ–`''left''`ã€‚'
- en: '`truncation_side` (`str`) â€” The default value for the side on which the model
    should have truncation applied. Should be `''right''` or `''left''`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_side` (`str`) â€” æ¨¡å‹åº”è¯¥åº”ç”¨æˆªæ–­çš„é»˜è®¤å€¼ã€‚åº”ä¸º`''right''`æˆ–`''left''`ã€‚'
- en: '#### `correct_tables`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `correct_tables`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L470)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L470)'
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`generation` (str) â€” The generated text to be postprocessed.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation` (str) â€” è¦è¿›è¡Œåå¤„ç†çš„ç”Ÿæˆæ–‡æœ¬ã€‚'
- en: Returns
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: str
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: The postprocessed text.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†çš„æ–‡æœ¬ã€‚
- en: Takes a generated string and fixes tables/tabulars to make them match the markdown
    format needed.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥å—ä¸€ä¸ªç”Ÿæˆçš„å­—ç¬¦ä¸²ï¼Œå¹¶ä¿®å¤è¡¨æ ¼/è¡¨æ ¼ï¼Œä½¿å…¶ç¬¦åˆæ‰€éœ€çš„Markdownæ ¼å¼ã€‚
- en: 'Example:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `post_process_generation`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_generation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L600)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L600)'
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`generation` (Union[str, List[str]]) â€” The generated text or a list of generated
    texts.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation` (Union[str, List[str]]) â€” ç”Ÿæˆçš„æ–‡æœ¬æˆ–ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨ã€‚'
- en: '`fix_markdown` (`bool`, *optional*, defaults to `True`) â€” Whether to perform
    Markdown formatting fixes.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fix_markdown` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æ‰§è¡ŒMarkdownæ ¼å¼ä¿®å¤ã€‚'
- en: '`num_workers` (`int`, *optional*) â€” Optional number of workers to pass to leverage
    multiprocessing (postprocessing several texts in parallel).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers` (`int`, *å¯é€‰*) â€” ä¼ é€’ç»™åˆ©ç”¨å¤šè¿›ç¨‹çš„å·¥ä½œäººå‘˜æ•°é‡ï¼ˆå¹¶è¡Œåå¤„ç†å¤šä¸ªæ–‡æœ¬ï¼‰ã€‚'
- en: Returns
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: Union[str, List[str]]
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Union[str, List[str]]
- en: The postprocessed text or list of postprocessed texts.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†çš„æ–‡æœ¬æˆ–åå¤„ç†æ–‡æœ¬åˆ—è¡¨ã€‚
- en: Postprocess a generated text or a list of generated texts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†ç”Ÿæˆçš„æ–‡æœ¬æˆ–ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨ã€‚
- en: This function can be used to perform postprocessing on generated text, such
    as fixing Markdown formatting.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å‡½æ•°å¯ç”¨äºå¯¹ç”Ÿæˆçš„æ–‡æœ¬æ‰§è¡Œåå¤„ç†ï¼Œä¾‹å¦‚ä¿®å¤Markdownæ ¼å¼ã€‚
- en: Postprocessing is quite slow so it is recommended to use multiprocessing to
    speed up the process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨å¤šè¿›ç¨‹åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚
- en: '#### `post_process_single`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_single`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L505)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L505)'
- en: '[PRE7]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`generation` (str) â€” The generated text to be postprocessed.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation` (str) â€” è¦è¿›è¡Œåå¤„ç†çš„ç”Ÿæˆæ–‡æœ¬ã€‚'
- en: '`fix_markdown` (bool, optional) â€” Whether to perform Markdown formatting fixes.
    Default is True.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fix_markdown` (bool, optional) â€” æ˜¯å¦æ‰§è¡ŒMarkdownæ ¼å¼ä¿®å¤ã€‚é»˜è®¤ä¸ºTrueã€‚'
- en: Returns
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: str
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: The postprocessed text.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†çš„æ–‡æœ¬ã€‚
- en: Postprocess a single generated text. Regular expressions used here are taken
    directly from the Nougat article authors. These expressions are commented for
    clarity and tested end-to-end in most cases.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†å•ä¸ªç”Ÿæˆçš„æ–‡æœ¬ã€‚æ­¤å¤„ä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥æ¥è‡ªNougatæ–‡ç« ä½œè€…ã€‚è¿™äº›è¡¨è¾¾å¼å·²ç»è¿‡æ³¨é‡Šä»¥ç¡®ä¿æ¸…æ™°ï¼Œå¹¶åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¿›è¡Œäº†ç«¯åˆ°ç«¯æµ‹è¯•ã€‚
- en: '#### `remove_hallucinated_references`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `remove_hallucinated_references`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L440)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L440)'
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`text` (`str`) â€” The input text containing references.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) â€” åŒ…å«å¼•ç”¨çš„è¾“å…¥æ–‡æœ¬ã€‚'
- en: Returns
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`str`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The text with hallucinated references removed.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ é™¤è™šæ„å¼•ç”¨çš„æ–‡æœ¬ã€‚
- en: Remove hallucinated or missing references from the text.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ–‡æœ¬ä¸­åˆ é™¤è™šæ„æˆ–ç¼ºå¤±çš„å¼•ç”¨ã€‚
- en: This function identifies and removes references that are marked as missing or
    hallucinated from the input text.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å‡½æ•°è¯†åˆ«å¹¶åˆ é™¤è¾“å…¥æ–‡æœ¬ä¸­æ ‡è®°ä¸ºç¼ºå¤±æˆ–è™šæ„çš„å¼•ç”¨ã€‚
- en: NougatProcessor
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NougatProcessor
- en: '### `class transformers.NougatProcessor`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.NougatProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L27)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L27)'
- en: '[PRE9]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`image_processor` ([NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor))
    â€” An instance of [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor).
    The image processor is a required input.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` ([NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor))
    â€” ä¸€ä¸ª[NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)çš„å®ä¾‹ã€‚å›¾åƒå¤„ç†å™¨æ˜¯å¿…éœ€çš„è¾“å…¥ã€‚'
- en: '`tokenizer` ([NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast))
    â€” An instance of [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast).
    The tokenizer is a required input.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast))
    â€” ä¸€ä¸ª[NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)çš„å®ä¾‹ã€‚åˆ†è¯å™¨æ˜¯å¿…éœ€çš„è¾“å…¥ã€‚'
- en: Constructs a Nougat processor which wraps a Nougat image processor and a Nougat
    tokenizer into a single processor.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªNougatå¤„ç†å™¨ï¼Œå°†Nougatå›¾åƒå¤„ç†å™¨å’ŒNougat tokenizeråŒ…è£…æˆä¸€ä¸ªå•ä¸€å¤„ç†å™¨ã€‚
- en: '[NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)
    offers all the functionalities of [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    and [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast).
    See the [**call**()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.__call__)
    and [decode()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.decode)
    for more information.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)
    æä¾›äº† [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    å’Œ [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)
    çš„æ‰€æœ‰åŠŸèƒ½ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ [**call**()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.__call__)
    å’Œ [decode()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.decode)ã€‚ '
- en: '#### `__call__`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L49)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L49)'
- en: '[PRE10]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `from_pretrained`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE11]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) â€” This can be either:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) â€” è¿™å¯ä»¥æ˜¯ï¼š'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„ *æ¨¡å‹ id*ï¼Œæ‰˜ç®¡åœ¨ huggingface.co ä¸Šçš„æ¨¡å‹å­˜å‚¨åº“ä¸­ã€‚æœ‰æ•ˆçš„æ¨¡å‹ id å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚ `bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚
    `dbmdz/bert-base-german-cased`ã€‚
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªåŒ…å«ä½¿ç”¨ [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    æ–¹æ³•ä¿å­˜çš„ç‰¹å¾æå–å™¨æ–‡ä»¶çš„ *ç›®å½•* è·¯å¾„ï¼Œä¾‹å¦‚ `./my_model_directory/`ã€‚
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs â€” Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å·²ä¿å­˜çš„ç‰¹å¾æå–å™¨ JSON *æ–‡ä»¶* çš„è·¯å¾„æˆ– URLï¼Œä¾‹å¦‚ `./my_model_directory/preprocessor_config.json`ã€‚**kwargs
    â€” ä¼ é€’ç»™ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    å’Œ `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å®ä¾‹åŒ–ä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸å…³è”çš„å¤„ç†å™¨ã€‚
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ç‰¹å¾æå–å™¨ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)ã€å›¾åƒå¤„ç†å™¨
    [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    å’Œåˆ†è¯å™¨ `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` æ–¹æ³•ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚
- en: '#### `save_pretrained`'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE12]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` or `os.PathLike`) â€” å°†ä¿å­˜ç‰¹å¾æå–å™¨ JSON æ–‡ä»¶å’Œåˆ†è¯å™¨æ–‡ä»¶çš„ç›®å½•ï¼ˆå¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™å°†åˆ›å»ºï¼‰ã€‚'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨ä¿å­˜æ¨¡å‹åå°†å…¶æ¨é€åˆ°Hugging
    Faceæ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°ï¼‰ã€‚'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) â€” Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *optional*) â€” ä¼ é€’ç»™ [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚'
- en: Saves the attributes of this processor (feature extractor, tokenizerâ€¦) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å¤„ç†å™¨çš„å±æ€§ï¼ˆç‰¹å¾æå–å™¨ã€åˆ†è¯å™¨ç­‰ï¼‰ä¿å­˜åœ¨æŒ‡å®šçš„ç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    æ–¹æ³•é‡æ–°åŠ è½½ã€‚
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    å’Œ [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚
- en: '#### `batch_decode`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L141)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L141)'
- en: '[PRE13]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This method forwards all its arguments to NougatTokenizerâ€™s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹æ³•å°†æ‰€æœ‰å‚æ•°è½¬å‘ç»™NougatTokenizerçš„[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)ã€‚è¯·å‚è€ƒæ­¤æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `decode`'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `è§£ç `'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L148)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L148)'
- en: '[PRE14]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This method forwards all its arguments to NougatTokenizerâ€™s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹æ³•å°†æ‰€æœ‰å‚æ•°è½¬å‘ç»™NougatTokenizerçš„[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)ã€‚è¯·å‚è€ƒæ­¤æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `post_process_generation`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `åå¤„ç†ç”Ÿæˆ`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L155)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L155)'
- en: '[PRE15]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This method forwards all its arguments to NougatTokenizerâ€™s `~PreTrainedTokenizer.post_process_generation`.
    Please refer to the docstring of this method for more information.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹æ³•å°†æ‰€æœ‰å‚æ•°è½¬å‘ç»™NougatTokenizerçš„`~PreTrainedTokenizer.post_process_generation`ã€‚è¯·å‚è€ƒæ­¤æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
