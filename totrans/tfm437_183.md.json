["```py\n>>> from transformers import HerbertTokenizer, RobertaModel\n\n>>> tokenizer = HerbertTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n>>> model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")\n\n>>> encoded_input = tokenizer.encode(\"Kto ma lepsz\u0105 sztuk\u0119, ma lepszy rz\u0105d \u2013 to jasne.\", return_tensors=\"pt\")\n>>> outputs = model(encoded_input)\n\n>>> # HerBERT can also be loaded using AutoTokenizer and AutoModel:\n>>> import torch\n>>> from transformers import AutoModel, AutoTokenizer\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n>>> model = AutoModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")\n```", "```py\n0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n| first sequence    | second sequence |\n```", "```py\n0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n| first sequence    | second sequence |\n```"]