["```py\n( nf nx )\n```", "```py\n( config: PretrainedConfig )\n```", "```py\n( hidden_states: FloatTensor p_mask: Optional = None ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( config: PretrainedConfig )\n```", "```py\n( hidden_states: FloatTensor start_states: Optional = None start_positions: Optional = None p_mask: Optional = None ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( config )\n```", "```py\n( hidden_states: FloatTensor start_states: Optional = None start_positions: Optional = None cls_index: Optional = None ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( loss: Optional = None start_top_log_probs: Optional = None start_top_index: Optional = None end_top_log_probs: Optional = None end_top_index: Optional = None cls_logits: Optional = None )\n```", "```py\n( config )\n```", "```py\n( hidden_states: FloatTensor start_positions: Optional = None end_positions: Optional = None cls_index: Optional = None is_impossible: Optional = None p_mask: Optional = None return_dict: bool = False ) \u2192 export const metadata = 'undefined';transformers.modeling_utils.SquadHeadOutput or tuple(torch.FloatTensor)\n```", "```py\n( config: PretrainedConfig )\n```", "```py\n( hidden_states: FloatTensor cls_index: Optional = None ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( forward_fn: Callable chunk_size: int chunk_dim: int *input_tensors ) \u2192 export const metadata = 'undefined';torch.Tensor\n```", "```py\n# rename the usual forward() fn to forward_chunk()\ndef forward_chunk(self, hidden_states):\n    hidden_states = self.decoder(hidden_states)\n    return hidden_states\n\n# implement a chunked forward function\ndef forward(self, hidden_states):\n    return apply_chunking_to_forward(self.forward_chunk, self.chunk_size_lm_head, self.seq_len_dim, hidden_states)\n```", "```py\n( heads: List n_heads: int head_size: int already_pruned_heads: Set ) \u2192 export const metadata = 'undefined';Tuple[Set[int], torch.LongTensor]\n```", "```py\n( layer: Union index: LongTensor dim: Optional = None ) \u2192 export const metadata = 'undefined';torch.nn.Linear or Conv1D\n```", "```py\n( layer: Conv1D index: LongTensor dim: int = 1 ) \u2192 export const metadata = 'undefined';Conv1D\n```", "```py\n( layer: Linear index: LongTensor dim: int = 0 ) \u2192 export const metadata = 'undefined';torch.nn.Linear\n```", "```py\n( nf nx initializer_range = 0.02 **kwargs )\n```", "```py\n( config: PretrainedConfig initializer_range: float = 0.02 **kwargs )\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( initializer_range: float = 0.02 ) \u2192 export const metadata = 'undefined';tf.keras.initializers.TruncatedNormal\n```", "```py\n( )\n```", "```py\n( tensor: Union ) \u2192 export const metadata = 'undefined';List[int]\n```"]