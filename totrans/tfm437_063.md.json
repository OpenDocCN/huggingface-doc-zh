["```py\nI will ask you to perform a task, your job is to come up with a series of simple commands in Python that will perform the task.\n[...]\nYou can print intermediate results if it makes sense to do so.\n\nTools:\n- document_qa: This is a tool that answers a question about a document (pdf). It takes an input named `document` which should be the document containing the information, as well as a `question` that is the question about the document. It returns a text that contains the answer to the question.\n- image_captioner: This is a tool that generates a description of an image. It takes an input named `image` which should be the image to the caption and returns a text that contains the description in English.\n[...]\n\nTask: \"Answer the question in the variable `question` about the image stored in the variable `image`. The question is in French.\"\n\nI will use the following tools: `translator` to translate the question into English and then `image_qa` to answer the question on the input image.\n\nAnswer:\n```", "```py\n\nTask: \"Identify the oldest person in the `document` and create an image showcasing the result as a banner.\"\n\nI will use the following tools: `document_qa` to find the oldest person in the document, then `image_generator` to generate an image according to the answer.\n\nAnswer:\n```", "```py\n\n[...]\n\nTask: \"Draw me a picture of rivers and lakes\"\n\nI will use the following\n```", "```py\n- <tool.name>: <tool.description>\n```", "```py\nfrom transformers import load_tool\n\ndocument_qa = load_tool(\"document-question-answering\")\nprint(f\"- {document_qa.name}: {document_qa.description}\")\n```", "```py\n- document_qa: This is a tool that answers a question about a document (pdf). It takes an input named `document` which should be the document containing the information, as well as a `question` that is the question about the document. It returns a text that contains the answer to the question.\n```", "```py\nTask: \"Identify the oldest person in the `document` and create an image showcasing the result as a banner.\"\n\nI will use the following tools: `document_qa` to find the oldest person in the document, then `image_generator` to generate an image according to the answer.\n\nAnswer:\n```", "```py\n\n```", "```py\nTask: \"Draw me a picture of rivers and lakes\"\n\nI will use the following\n```", "```py\nagent.run(\"Draw me a picture of rivers and lakes\")\n```", "```py\n[...]\n\n=====\n\nHuman: Answer the question in the variable `question` about the image stored in the variable `image`.\n\nAssistant: I will use the tool `image_qa` to answer the question on the input image.\n\n```", "```py\n\nHuman: I tried this code, it worked but didn't give me a good result. The question is in French\n\nAssistant: In this case, the question needs to be translated first. I will use the tool `translator` to do this.\n\n```", "```py\n\n=====\n\n[...]\n```", "```py\nHuman: <user-input>\\n\\nAssistant:\n```", "```py\nfrom transformers import HfAgent\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\n\nagent.run(\"Show me a tree\", return_code=True)\n```", "```py\n==Explanation from the agent==\nI will use the following tool: `image_segmenter` to create a segmentation mask for the image.\n\n==Code generated by the agent==\nmask = image_segmenter(image, prompt=\"tree\")\n```", "```py\nagent.toolbox[\"image_generator\"].description\n```", "```py\n'This is a tool that creates an image according to a prompt, which is a text description. It takes an input named `prompt` which contains the image description and outputs an image.\n```", "```py\nagent.run(\"Create an image of a tree\", return_code=True)\n```", "```py\n==Explanation from the agent==\nI will use the following tool `image_generator` to generate an image of a tree.\n\n==Code generated by the agent==\nimage = image_generator(prompt=\"tree\")\n```", "```py\nagent.run(\"Make an image of a house and a car\", return_code=True)\n```", "```py\n==Explanation from the agent== \nI will use the following tools `image_generator` to generate an image of a house and `image_transformer` to transform the image of a car into the image of a house.\n\n==Code generated by the agent==\nhouse_image = image_generator(prompt=\"A house\")\ncar_image = image_generator(prompt=\"A car\")\nhouse_car_image = image_transformer(image=car_image, prompt=\"A house\")\n```", "```py\nagent.toolbox[\"modifier\"] = agent.toolbox.pop(\"image_transformer\")\nagent.toolbox[\"modifier\"].description = agent.toolbox[\"modifier\"].description.replace(\n    \"transforms an image according to a prompt\", \"modifies an image\"\n)\n```", "```py\nagent.run(\"Make an image of a house and a car\", return_code=True)\n```", "```py\n==Explanation from the agent==\nI will use the following tools: `image_generator` to generate an image of a house, then `image_generator` to generate an image of a car.\n\n==Code generated by the agent==\nhouse_image = image_generator(prompt=\"A house\")\ncar_image = image_generator(prompt=\"A car\")\n```", "```py\nagent.run(\"Create image: 'A house and car'\", return_code=True)\n```", "```py\n==Explanation from the agent==\nI will use the following tool: `image_generator` to generate an image.\n\n==Code generated by the agent==\nimage = image_generator(prompt=\"A house and car\")\n```", "```py\ntemplate = \"\"\" [...] \"\"\"\n\nagent = HfAgent(your_endpoint, run_prompt_template=template)\n```", "```py\nHuman: <<task>>\n\nAssistant:\n```", "```py\ntemplate = \"\"\" [...] \"\"\"\n\nagent = HfAgent(url_endpoint=your_endpoint, chat_prompt_template=template)\n```", "```py\nfrom transformers import load_tool\n\ncontrolnet_transformer = load_tool(\"diffusers/controlnet-canny-tool\")\nupscaler = load_tool(\"diffusers/latent-upscaler-tool\")\n```", "```py\nprint(f\"Description: '{controlnet_transformer.description}'\")\nprint(f\"Name: '{controlnet_transformer.name}'\")\n```", "```py\nDescription: 'This is a tool that transforms an image with ControlNet according to a prompt. \nIt takes two inputs: `image`, which should be the image to transform, and `prompt`, which should be the prompt to use to change it. It returns the modified image.'\nName: 'image_transformer'\n```", "```py\ntools = [controlnet_transformer, upscaler]\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\", additional_tools=tools)\n```", "```py\nimage_transformer has been replaced by <transformers_modules.diffusers.controlnet-canny-tool.bd76182c7777eba9612fc03c0\n8718a60c0aa6312.image_transformation.ControlNetTransformationTool object at 0x7f1d3bfa3a00> as provided in `additional_tools`\n```", "```py\nprint(\"\\n\".join([f\"- {a}\" for a in agent.toolbox.keys()]))\n```", "```py\n- document_qa\n- image_captioner\n- image_qa\n- image_segmenter\n- transcriber\n- summarizer\n- text_classifier\n- text_qa\n- text_reader\n- translator\n- image_transformer\n- text_downloader\n- image_generator\n- video_generator\n- image_upscaler\n```", "```py\nfrom diffusers.utils import load_image\n\nimage = load_image(\n    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rivers_and_lakes.png\"\n)\n```", "```py\nimage = agent.run(\"Transform the image: 'A frozen lake and snowy forest'\", image=image)\n```", "```py\n==Explanation from the agent==\nI will use the following tool: `image_transformer` to transform the image.\n\n==Code generated by the agent==\nimage = image_transformer(image, prompt=\"A frozen lake and snowy forest\")\n```", "```py\nimage = agent.run(\"Upscale the image\", image)\n```", "```py\n==Explanation from the agent==\nI will use the following tool: `image_upscaler` to upscale the image.\n\n==Code generated by the agent==\nupscaled_image = image_upscaler(image)\n```", "```py\nfrom huggingface_hub import list_models\n\ntask = \"text-classification\"\n\nmodel = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\nprint(model.id)\n```", "```py\nfrom transformers import Tool\n\nclass HFModelDownloadsTool(Tool):\n    pass\n```", "```py\nfrom transformers import Tool\nfrom huggingface_hub import list_models\n\nclass HFModelDownloadsTool(Tool):\n    name = \"model_download_counter\"\n    description = (\n        \"This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. \"\n        \"It takes the name of the category (such as text-classification, depth-estimation, etc), and \"\n        \"returns the name of the checkpoint.\"\n    )\n\n    inputs = [\"text\"]\n    outputs = [\"text\"]\n\n    def __call__(self, task: str):\n        model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n        return model.id\n```", "```py\nfrom model_downloads import HFModelDownloadsTool\n\ntool = HFModelDownloadsTool()\n```", "```py\ntool.push_to_hub(\"hf-model-downloads\")\n```", "```py\nfrom transformers import load_tool\n\ntool = load_tool(\"lysandre/hf-model-downloads\")\n```", "```py\nfrom transformers import HfAgent\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\", additional_tools=[tool])\n\nagent.run(\n    \"Can you read out loud the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n)\n```", "```py\n==Code generated by the agent==\nmodel = model_download_counter(task=\"text-to-video\")\nprint(f\"The model with the most downloads is {model}.\")\naudio_model = text_reader(model)\n\n==Result==\nThe model with the most downloads is damo-vilab/text-to-video-ms-1.7b.\n```", "```py\nfrom transformers import HfAgent, load_tool\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\nagent.toolbox[\"image-transformation\"] = load_tool(\"diffusers/controlnet-canny-tool\")\n```", "```py\nfrom gradio_tools import StableDiffusionPromptGeneratorTool\n\ngradio_tool = StableDiffusionPromptGeneratorTool()\n```", "```py\nfrom transformers import Tool\n\ntool = Tool.from_gradio(gradio_tool)\n```", "```py\nfrom transformers import HfAgent\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\", additional_tools=[tool])\n\nagent.run(\"Generate an image of the `prompt` after improving it.\", prompt=\"A rabbit wearing a space suit\")\n```", "```py\n==Explanation from the agent==\nI will use the following  tools: `StableDiffusionPromptGenerator` to improve the prompt, then `image_generator` to generate an image according to the improved prompt.\n\n==Code generated by the agent==\nimproved_prompt = StableDiffusionPromptGenerator(prompt)\nprint(f\"The improved prompt is {improved_prompt}.\")\nimage = image_generator(improved_prompt)\n```"]