- en: Adding support for new architectures
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºæ–°æ¶æ„æ·»åŠ æ”¯æŒ
- en: 'Original text: [https://huggingface.co/docs/optimum-neuron/community/contributing](https://huggingface.co/docs/optimum-neuron/community/contributing)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'åŸæ–‡é“¾æ¥: [https://huggingface.co/docs/optimum-neuron/community/contributing](https://huggingface.co/docs/optimum-neuron/community/contributing)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '***NOTE:*** â—This section does not apply to the decoder modelâ€™s inference with
    autoregressive sampling integrated through `transformers-neuronx`. If you want
    to add support for these models, please open an issue on the Optimum Neuron GitHub
    repo, and ping maintainers for help.'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***æ³¨æ„:*** â—è¿™ä¸€éƒ¨åˆ†ä¸é€‚ç”¨äºé€šè¿‡`transformers-neuronx`è¿›è¡Œè‡ªå›å½’é‡‡æ ·çš„è§£ç å™¨æ¨¡å‹çš„æ¨æ–­ã€‚å¦‚æœæ‚¨æƒ³ä¸ºè¿™äº›æ¨¡å‹æ·»åŠ æ”¯æŒï¼Œè¯·åœ¨Optimum
    Neuron GitHubå­˜å‚¨åº“ä¸Šå¼€å¯ä¸€ä¸ªé—®é¢˜ï¼Œå¹¶@ç»´æŠ¤è€…å¯»æ±‚å¸®åŠ©ã€‚'
- en: You want to export and run a new model on AWS Inferentia or Trainium? Check
    the guideline, and submit a pull request to [ğŸ¤— Optimum Neuronâ€™s GitHub repo](https://github.com/huggingface/optimum-neuron/)!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨æƒ³åœ¨AWS Inferentiaæˆ–Trainiumä¸Šå¯¼å‡ºå¹¶è¿è¡Œæ–°æ¨¡å‹å—ï¼ŸæŸ¥çœ‹æŒ‡å—ï¼Œå¹¶å‘[ğŸ¤— Optimum Neuronçš„GitHubå­˜å‚¨åº“](https://github.com/huggingface/optimum-neuron/)æäº¤æ‹‰å–è¯·æ±‚ï¼
- en: 'To support a new model architecture in the Optimum Neuron library here are
    some steps to follow:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åœ¨Optimum Neuronåº“ä¸­æ”¯æŒæ–°çš„æ¨¡å‹æ¶æ„ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›è¦éµå¾ªçš„æ­¥éª¤ï¼š
- en: Implement a custom Neuron configuration.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ç°è‡ªå®šä¹‰ç¥ç»å…ƒé…ç½®ã€‚
- en: Export and validate the model.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¼å‡ºå¹¶éªŒè¯æ¨¡å‹ã€‚
- en: Contribute to the GitHub repo.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è´¡çŒ®åˆ°GitHubå­˜å‚¨åº“ã€‚
- en: Implement a custom Neuron configuration
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®ç°è‡ªå®šä¹‰ç¥ç»å…ƒé…ç½®
- en: 'To support the export of a new model to a Neuron compatible format, the first
    thing to do is to define a Neuron configuration, describing how to export the
    PyTorch model by specifying:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ”¯æŒå°†æ–°æ¨¡å‹å¯¼å‡ºä¸ºNeuronå…¼å®¹æ ¼å¼ï¼Œé¦–å…ˆè¦åšçš„æ˜¯å®šä¹‰ä¸€ä¸ªç¥ç»å…ƒé…ç½®ï¼Œæè¿°å¦‚ä½•é€šè¿‡æŒ‡å®šæ¥å¯¼å‡ºPyTorchæ¨¡å‹ï¼š
- en: The input names.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾“å…¥åç§°ã€‚
- en: The output names.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾“å‡ºåç§°ã€‚
- en: 'The dummy inputs used to trace the model: the Neuron Compiler records the computational
    graph via tracing and works on the resulting `TorchScript` module.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨äºè·Ÿè¸ªæ¨¡å‹çš„è™šæ‹Ÿè¾“å…¥ï¼šNeuronç¼–è¯‘å™¨é€šè¿‡è·Ÿè¸ªè®°å½•è®¡ç®—å›¾ï¼Œå¹¶åœ¨ç”Ÿæˆçš„`TorchScript`æ¨¡å—ä¸Šå·¥ä½œã€‚
- en: The compilation arguments used to control the trade-off between hardware efficiency
    (latency, throughput) and accuracy.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨äºæ§åˆ¶ç¡¬ä»¶æ•ˆç‡ï¼ˆå»¶è¿Ÿã€ååé‡ï¼‰å’Œå‡†ç¡®æ€§ä¹‹é—´æƒè¡¡çš„ç¼–è¯‘å‚æ•°ã€‚
- en: Depending on the choice of model and task, we represent the data above with
    configuration classes. Each configuration class is associated with a specific
    model architecture, and follows the naming convention `ArchitectureNameNeuronConfig`.
    For instance, the configuration that specifies the Neuron export of BERT models
    is `BertNeuronConfig`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ¨¡å‹å’Œä»»åŠ¡çš„é€‰æ‹©ï¼Œæˆ‘ä»¬ä½¿ç”¨é…ç½®ç±»è¡¨ç¤ºä¸Šé¢çš„æ•°æ®ã€‚æ¯ä¸ªé…ç½®ç±»ä¸ç‰¹å®šçš„æ¨¡å‹æ¶æ„ç›¸å…³è”ï¼Œå¹¶éµå¾ªå‘½åçº¦å®š`ArchitectureNameNeuronConfig`ã€‚ä¾‹å¦‚ï¼ŒæŒ‡å®šBERTæ¨¡å‹çš„Neuronå¯¼å‡ºçš„é…ç½®æ˜¯`BertNeuronConfig`ã€‚
- en: 'Since many architectures share similar properties for their Neuron configuration,
    ğŸ¤— Optimum adopts a 3-level class hierarchy:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè®¸å¤šæ¶æ„å…±äº«ç±»ä¼¼çš„ç¥ç»å…ƒé…ç½®å±æ€§ï¼ŒğŸ¤— Optimumé‡‡ç”¨äº†3çº§ç±»å±‚æ¬¡ç»“æ„ï¼š
- en: Abstract and generic base classes. These handle all the fundamental features,
    while being agnostic to the modality (text, image, audio, etc).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŠ½è±¡å’Œé€šç”¨çš„åŸºç±»ã€‚è¿™äº›å¤„ç†æ‰€æœ‰åŸºæœ¬ç‰¹æ€§ï¼ŒåŒæ—¶å¯¹æ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰ï¼‰ä¿æŒä¸å¯çŸ¥ã€‚
- en: Middle-end classes. These are aware of the modality. Multiple config classes
    could exist for the same modality, depending on the inputs they support. They
    specify which input generators should be used for generating the dummy inputs,
    but remain model-agnostic.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸­é—´ç±»ã€‚è¿™äº›äº†è§£æ¨¡æ€ã€‚å¯¹äºåŒä¸€æ¨¡æ€ï¼Œå¯èƒ½å­˜åœ¨å¤šä¸ªé…ç½®ç±»ï¼Œå–å†³äºå®ƒä»¬æ”¯æŒçš„è¾“å…¥ã€‚å®ƒä»¬æŒ‡å®šåº”ä½¿ç”¨å“ªäº›è¾“å…¥ç”Ÿæˆå™¨æ¥ç”Ÿæˆè™šæ‹Ÿè¾“å…¥ï¼Œä½†ä¿æŒä¸æ¨¡å‹æ— å…³ã€‚
- en: Model-specific classes like the `BertNeuronConfig` mentioned above. These are
    the ones actually used to export models.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åƒä¸Šé¢æåˆ°çš„`BertNeuronConfig`è¿™æ ·çš„ç‰¹å®šäºæ¨¡å‹çš„ç±»ã€‚è¿™äº›å®é™…ä¸Šæ˜¯ç”¨äºå¯¼å‡ºæ¨¡å‹çš„ç±»ã€‚
- en: 'Example: Adding support for ESM models'
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼šä¸ºESMæ¨¡å‹æ·»åŠ æ”¯æŒ
- en: Here we take the support of [ESM models](https://huggingface.co/docs/transformers/model_doc/esm#esm)
    as an example. Letâ€™s create an `EsmNeuronConfig` class in the `optimum/exporters/neuron/model_configs.py`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»¥[ESMæ¨¡å‹](https://huggingface.co/docs/transformers/model_doc/esm#esm)ä¸ºä¾‹ã€‚è®©æˆ‘ä»¬åœ¨`optimum/exporters/neuron/model_configs.py`ä¸­åˆ›å»ºä¸€ä¸ª`EsmNeuronConfig`ç±»ã€‚
- en: When an Esm model interprets as a text encoder, we are able to inherit from
    the middle-end class [`TextEncoderNeuronConfig`](https://github.com/huggingface/optimum-neuron/blob/v0.0.18/optimum/exporters/neuron/config.py#L36).
    Since the modeling and configuration of Esm is almost the same as BERT when it
    is interpreted as an encoder, we can use the `NormalizedConfigManager` with `model_type=bert`
    to normalize the configuration to generate dummy inputs for tracing the model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸€ä¸ªEsmæ¨¡å‹è¢«è§£é‡Šä¸ºæ–‡æœ¬ç¼–ç å™¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸­é—´ç±»[`TextEncoderNeuronConfig`](https://github.com/huggingface/optimum-neuron/blob/v0.0.18/optimum/exporters/neuron/config.py#L36)ç»§æ‰¿ã€‚ç”±äºå½“Esmè¢«è§£é‡Šä¸ºç¼–ç å™¨æ—¶ï¼Œå»ºæ¨¡å’Œé…ç½®å‡ ä¹ä¸BERTç›¸åŒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`NormalizedConfigManager`å’Œ`model_type=bert`æ¥è§„èŒƒåŒ–é…ç½®ï¼Œä»¥ç”Ÿæˆç”¨äºè·Ÿè¸ªæ¨¡å‹çš„è™šæ‹Ÿè¾“å…¥ã€‚
- en: And one last step, since `optimum-neuron` is an extension of `optimum`, we need
    to register the Neuron config that we create to the [TasksManager](https://huggingface.co/docs/optimum/main/en/exporters/task_manager#optimum.exporters.TasksManager)
    with the `register_in_tasks_manager` decorator by specifying the model type and
    supported tasks.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€æ­¥ï¼Œç”±äº`optimum-neuron`æ˜¯`optimum`çš„æ‰©å±•ï¼Œæˆ‘ä»¬éœ€è¦å°†åˆ›å»ºçš„ç¥ç»å…ƒé…ç½®æ³¨å†Œåˆ°[TasksManager](https://huggingface.co/docs/optimum/main/en/exporters/task_manager#optimum.exporters.TasksManager)ä¸­ï¼Œé€šè¿‡æŒ‡å®šæ¨¡å‹ç±»å‹å’Œæ”¯æŒçš„ä»»åŠ¡ä½¿ç”¨`register_in_tasks_manager`è£…é¥°å™¨ã€‚
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Export and validate the model
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¼å‡ºå¹¶éªŒè¯æ¨¡å‹
- en: 'With the Neuron configuration class that you implemented, now do a quick test
    if it works as expected:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ‚¨å®ç°çš„ç¥ç»å…ƒé…ç½®ç±»ï¼Œç°åœ¨å¿«é€Ÿæµ‹è¯•ä¸€ä¸‹æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œï¼š
- en: Export
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼å‡º
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'During the export [`validate_model_outputs`](https://github.com/huggingface/optimum-neuron/blob/7b18de9ddfa5c664c94051304c651eaf855c3e0b/optimum/exporters/neuron/convert.py#L136)
    will be called to validate the outputs of your exported Neuron model by comparing
    them to the results of PyTorch on the CPU. You could also validate the model manually
    with:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯¼å‡ºæœŸé—´ï¼Œå°†è°ƒç”¨[`validate_model_outputs`](https://github.com/huggingface/optimum-neuron/blob/7b18de9ddfa5c664c94051304c651eaf855c3e0b/optimum/exporters/neuron/convert.py#L136)æ¥éªŒè¯å¯¼å‡ºçš„Neuronæ¨¡å‹çš„è¾“å‡ºï¼Œé€šè¿‡å°†å…¶ä¸PyTorchåœ¨CPUä¸Šçš„ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨éªŒè¯æ¨¡å‹ã€‚
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Inference (optional)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨æ–­ï¼ˆå¯é€‰ï¼‰
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Contribute to the GitHub repo
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è´¡çŒ®åˆ°GitHubä»“åº“
- en: We are almost all set. Now submit a pull request to make your work accessible
    to all community members!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡ ä¹å·²ç»å‡†å¤‡å°±ç»ªã€‚ç°åœ¨æäº¤ä¸€ä¸ªæ‹‰å–è¯·æ±‚ï¼Œä½¿æ‚¨çš„å·¥ä½œå¯¹æ‰€æœ‰ç¤¾åŒºæˆå‘˜å¯è®¿é—®ï¼
- en: Open an issue in the [Optimum Neuron GitHub repo](https://github.com/huggingface/optimum-neuron/issues)
    to describe the new feature and make it visible to Optimum Neuronâ€™s maintainers.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨[Optimum Neuron GitHubä»“åº“](https://github.com/huggingface/optimum-neuron/issues)ä¸­å¼€å¯ä¸€ä¸ªé—®é¢˜æ¥æè¿°æ–°åŠŸèƒ½ï¼Œå¹¶è®©Optimum
    Neuronçš„ç»´æŠ¤è€…ä»¬çœ‹åˆ°ã€‚
- en: Add the model to the exporter test in [`optimum-neuron/tests/exporters/exporters_utils.py`](https://github.com/huggingface/optimum-neuron/blob/v0.0.18/tests/exporters/exporters_utils.py)
    and the inference test in [`optimum-neuron/tests/inference/inference_utils.py`](https://github.com/huggingface/optimum-neuron/blob/v0.0.18/tests/inference/inference_utils.py).
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹æ·»åŠ åˆ°[`optimum-neuron/tests/exporters/exporters_utils.py`](https://github.com/huggingface/optimum-neuron/blob/v0.0.18/tests/exporters/exporters_utils.py)ä¸­çš„å¯¼å‡ºå™¨æµ‹è¯•å’Œ[`optimum-neuron/tests/inference/inference_utils.py`](https://github.com/huggingface/optimum-neuron/blob/v0.0.18/tests/inference/inference_utils.py)ä¸­çš„æ¨ç†æµ‹è¯•ã€‚
- en: Open a pull request! (Donâ€™t forget to link it to the issue you opened, so that
    the maintainers could better track it and provide help when needed.)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼€å¯ä¸€ä¸ªæ‹‰å–è¯·æ±‚ï¼ï¼ˆä¸è¦å¿˜è®°å°†å…¶é“¾æ¥åˆ°æ‚¨å¼€å¯çš„é—®é¢˜ï¼Œä»¥ä¾¿ç»´æŠ¤è€…åœ¨éœ€è¦æ—¶æ›´å¥½åœ°è·Ÿè¸ªå¹¶æä¾›å¸®åŠ©ã€‚ï¼‰
- en: We usually test smaller checkpoints to accelerate the CIs, you could find tiny
    models for testing under the [`Hugging Face Internal Testing Organization`](https://huggingface.co/hf-internal-testing).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸æˆ‘ä»¬ä¼šæµ‹è¯•è¾ƒå°çš„æ£€æŸ¥ç‚¹ä»¥åŠ é€ŸCIï¼Œæ‚¨å¯ä»¥åœ¨[`Hugging Face Internal Testing Organization`](https://huggingface.co/hf-internal-testing)ä¸‹æ‰¾åˆ°ç”¨äºæµ‹è¯•çš„å¾®å‹æ¨¡å‹ã€‚
- en: You have made a new model accessible on Neuron for the community! Thanks for
    joining us in the endeavor of democratizing good machine learning ğŸ¤—.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å·²ç»åœ¨Neuronä¸Šä¸ºç¤¾åŒºæä¾›äº†ä¸€ä¸ªæ–°çš„æ¨¡å‹ï¼æ„Ÿè°¢æ‚¨åŠ å…¥æˆ‘ä»¬åŠªåŠ›ä½¿ä¼˜ç§€çš„æœºå™¨å­¦ä¹ æ°‘ä¸»åŒ–çš„è¡ŒåŠ¨ğŸ¤—ã€‚
