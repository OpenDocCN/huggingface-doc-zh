- en: Using TEI locally with GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/text-embeddings-inference/local_gpu](https://huggingface.co/docs/text-embeddings-inference/local_gpu)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/text-embeddings-inference/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/entry/start.f5781b4e.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/scheduler.b108d059.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/singletons.26f524d0.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/paths.e8cea87f.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/entry/app.ca5804ae.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/index.008de539.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/nodes/0.a44871a2.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/nodes/6.3d8f1e3e.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/CodeBlock.3968c746.js">
    <link rel="modulepreload" href="/docs/text-embeddings-inference/main/en/_app/immutable/chunks/Heading.88bfeb84.js">
  prefs: []
  type: TYPE_NORMAL
- en: You can install `text-embeddings-inference` locally to run it on your own machine
    with a GPU. To make sure that your hardware is supported, check out the [Supported
    models and hardware](supported_models) page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: CUDA and NVIDIA drivers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make sure you have CUDA and the NVIDIA drivers installed - NVIDIA drivers on
    your device need to be compatible with CUDA version 12.2 or higher.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the NVIDIA binaries to your path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Install Rust'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Install Rust](([https://rustup.rs/](https://rustup.rs/)) on your machine by
    run the following in your terminal, then following the instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3: Install necessary packages'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step can take a while as we need to compile a lot of cuda kernels.
  prefs: []
  type: TYPE_NORMAL
- en: For Turing GPUs (T4, RTX 2000 series … )
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For Ampere and Hopper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 4: Launch Text Embeddings Inference'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can now launch Text Embeddings Inference on GPU with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
