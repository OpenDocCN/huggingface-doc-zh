- en: Using TEI locally with GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/text-embeddings-inference/local_gpu](https://huggingface.co/docs/text-embeddings-inference/local_gpu)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: You can install `text-embeddings-inference` locally to run it on your own machine
    with a GPU. To make sure that your hardware is supported, check out the [Supported
    models and hardware](supported_models) page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: CUDA and NVIDIA drivers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make sure you have CUDA and the NVIDIA drivers installed - NVIDIA drivers on
    your device need to be compatible with CUDA version 12.2 or higher.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the NVIDIA binaries to your path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Install Rust'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Install Rust](([https://rustup.rs/](https://rustup.rs/)) on your machine by
    run the following in your terminal, then following the instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3: Install necessary packages'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step can take a while as we need to compile a lot of cuda kernels.
  prefs: []
  type: TYPE_NORMAL
- en: For Turing GPUs (T4, RTX 2000 series â€¦ )
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For Ampere and Hopper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 4: Launch Text Embeddings Inference'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can now launch Text Embeddings Inference on GPU with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
