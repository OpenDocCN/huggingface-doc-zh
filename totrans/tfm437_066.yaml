- en: Performance and Scalability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能和可伸缩性
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/performance](https://huggingface.co/docs/transformers/v4.37.2/en/performance)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/performance](https://huggingface.co/docs/transformers/v4.37.2/en/performance)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Training large transformer models and deploying them to production present various
    challenges.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 训练大型Transformer模型并将其部署到生产环境中会带来各种挑战。
- en: During training, the model may require more GPU memory than available or exhibit
    slow training speed. In the deployment phase, the model can struggle to handle
    the required throughput in a production environment.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，模型可能需要比可用GPU内存更多的GPU内存，或者表现出训练速度较慢。在部署阶段，模型可能难以处理生产环境中所需的吞吐量。
- en: This documentation aims to assist you in overcoming these challenges and finding
    the optimal setting for your use-case. The guides are divided into training and
    inference sections, as each comes with different challenges and solutions. Within
    each section you’ll find separate guides for different hardware configurations,
    such as single GPU vs. multi-GPU for training or CPU vs. GPU for inference.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文档旨在帮助您克服这些挑战，并找到适合您用例的最佳设置。指南分为训练和推理部分，因为每个部分都有不同的挑战和解决方案。在每个部分中，您将找到针对不同硬件配置的单独指南，例如单个GPU与多个GPU进行训练，或CPU与GPU进行推理。
- en: Use this document as your starting point to navigate further to the methods
    that match your scenario.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 将本文档作为您进一步导航到与您的情况匹配的方法的起点。
- en: Training
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: Training large transformer models efficiently requires an accelerator such as
    a GPU or TPU. The most common case is where you have a single GPU. The methods
    that you can apply to improve training efficiency on a single GPU extend to other
    setups such as multiple GPU. However, there are also techniques that are specific
    to multi-GPU or CPU training. We cover them in separate sections.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 训练大型Transformer模型高效地需要像GPU或TPU这样的加速器。最常见的情况是你只有一块GPU。您可以应用的方法来提高单个GPU上的训练效率也适用于其他设置，如多个GPU。然而，也有一些特定于多GPU或CPU训练的技术。我们在单独的部分中进行介绍。
- en: '[Methods and tools for efficient training on a single GPU](perf_train_gpu_one):
    start here to learn common approaches that can help optimize GPU memory utilization,
    speed up the training, or both.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在单个GPU上进行高效训练的方法和工具](perf_train_gpu_one)：从这里开始学习可以帮助优化GPU内存利用率、加快训练速度或两者兼具的常见方法。'
- en: '[Multi-GPU training section](perf_train_gpu_many): explore this section to
    learn about further optimization methods that apply to a multi-GPU settings, such
    as data, tensor, and pipeline parallelism.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多GPU训练部分](perf_train_gpu_many)：探索本节，了解适用于多GPU设置的进一步优化方法，如数据、张量和管道并行。'
- en: '[CPU training section](perf_train_cpu): learn about mixed precision training
    on CPU.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CPU训练部分](perf_train_cpu)：了解在CPU上进行混合精度训练。'
- en: '[Efficient Training on Multiple CPUs](perf_train_cpu_many): learn about distributed
    CPU training.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在多个CPU上进行高效训练](perf_train_cpu_many)：了解分布式CPU训练。'
- en: '[Training on TPU with TensorFlow](perf_train_tpu_tf): if you are new to TPUs,
    refer to this section for an opinionated introduction to training on TPUs and
    using XLA.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用TensorFlow在TPU上训练](perf_train_tpu_tf)：如果您是TPU的新手，请参考本节，了解在TPU上训练和使用XLA的主观介绍。'
- en: '[Custom hardware for training](perf_hardware): find tips and tricks when building
    your own deep learning rig.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于训练的自定义硬件](perf_hardware)：在构建自己的深度学习装置时找到技巧和窍门。'
- en: '[Hyperparameter Search using Trainer API](hpo_train)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Trainer API进行超参数搜索](hpo_train)'
- en: Inference
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: Efficient inference with large models in a production environment can be as
    challenging as training them. In the following sections we go through the steps
    to run inference on CPU and single/multi-GPU setups.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中使用大型模型进行高效推理可能与训练它们一样具有挑战性。在接下来的部分中，我们将介绍在CPU和单/多GPU设置上运行推理的步骤。
- en: '[Inference on a single CPU](perf_infer_cpu)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在单个CPU上进行推理](perf_infer_cpu)'
- en: '[Inference on a single GPU](perf_infer_gpu_one)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在单个GPU上进行推理](perf_infer_gpu_one)'
- en: '[Multi-GPU inference](perf_infer_gpu_one)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多GPU推理](perf_infer_gpu_one)'
- en: '[XLA Integration for TensorFlow Models](tf_xla)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLA集成用于TensorFlow模型](tf_xla)'
- en: Training and inference
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和推理
- en: Here you’ll find techniques, tips and tricks that apply whether you are training
    a model, or running inference with it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您将找到适用于训练模型或使用模型进行推理的技术、提示和技巧。
- en: '[Instantiating a big model](big_models)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实例化一个大模型](big_models)'
- en: '[Troubleshooting performance issues](debugging)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[性能问题的故障排除](debugging)'
- en: Contribute
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贡献
- en: This document is far from being complete and a lot more needs to be added, so
    if you have additions or corrections to make please don’t hesitate to open a PR
    or if you aren’t sure start an Issue and we can discuss the details there.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这份文档远未完整，还有很多需要添加的内容，所以如果您有补充或更正，请不要犹豫，打开一个PR，或者如果您不确定，请开始一个Issue，我们可以在那里讨论细节。
- en: When making contributions that A is better than B, please try to include a reproducible
    benchmark and/or a link to the source of that information (unless it comes directly
    from you).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在提出A优于B的贡献时，请尽量包含可重现的基准测试和/或指向该信息来源的链接（除非信息直接来自您）。
