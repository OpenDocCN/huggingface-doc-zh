["```py\nfrom transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"bert-base-cased\")\n```", "```py\n>>> import os\n>>> import tempfile\n\n>>> with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir)\n...     print(sorted(os.listdir(tmp_dir)))\n['config.json', 'pytorch_model.bin']\n```", "```py\n>>> with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     print(sorted(os.listdir(tmp_dir)))\n['config.json', 'pytorch_model-00001-of-00003.bin', 'pytorch_model-00002-of-00003.bin', 'pytorch_model-00003-of-00003.bin', 'pytorch_model.bin.index.json']\n```", "```py\n>>> with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     new_model = AutoModel.from_pretrained(tmp_dir)\n```", "```py\n>>> import json\n\n>>> with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     with open(os.path.join(tmp_dir, \"pytorch_model.bin.index.json\"), \"r\") as f:\n...         index = json.load(f)\n\n>>> print(index.keys())\ndict_keys(['metadata', 'weight_map'])\n```", "```py\n>>> index[\"metadata\"]\n{'total_size': 433245184}\n```", "```py\n>>> index[\"weight_map\"]\n{'embeddings.LayerNorm.bias': 'pytorch_model-00001-of-00003.bin',\n 'embeddings.LayerNorm.weight': 'pytorch_model-00001-of-00003.bin',\n ...\n```", "```py\n>>> from transformers.modeling_utils import load_sharded_checkpoint\n\n>>> with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     load_sharded_checkpoint(model, tmp_dir)\n```"]