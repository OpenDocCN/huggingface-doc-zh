["```py\npip install transformers\n```", "```py\nfrom transformers import pipeline\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npipe = pipeline(task=\"image-to-image\", model=\"caidas/swin2SR-lightweight-x2-64\", device=device)\n```", "```py\nfrom PIL import Image\nimport requests\n\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\n\nprint(image.size)\n```", "```py\n# (532, 432)\n```", "```py\nupscaled = pipe(image)\nprint(upscaled.size)\n```", "```py\n# (1072, 880)\n```", "```py\nfrom transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor \n\nmodel = Swin2SRForImageSuperResolution.from_pretrained(\"caidas/swin2SR-lightweight-x2-64\").to(device)\nprocessor = Swin2SRImageProcessor(\"caidas/swin2SR-lightweight-x2-64\")\n```", "```py\npixel_values = processor(image, return_tensors=\"pt\").pixel_values\nprint(pixel_values.shape)\n\npixel_values = pixel_values.to(device)\n```", "```py\nimport torch\n\nwith torch.no_grad():\n  outputs = model(pixel_values)\n```", "```py\n(loss=None, reconstruction=tensor([[[[0.8270, 0.8269, 0.8275,  ..., 0.7463, 0.7446, 0.7453],\n          [0.8287, 0.8278, 0.8283,  ..., 0.7451, 0.7448, 0.7457],\n          [0.8280, 0.8273, 0.8269,  ..., 0.7447, 0.7446, 0.7452],\n          ...,\n          [0.5923, 0.5933, 0.5924,  ..., 0.0697, 0.0695, 0.0706],\n          [0.5926, 0.5932, 0.5926,  ..., 0.0673, 0.0687, 0.0705],\n          [0.5927, 0.5914, 0.5922,  ..., 0.0664, 0.0694, 0.0718]]]],\n       device='cuda:0'), hidden_states=None, attentions=None)\n```", "```py\noutputs.reconstruction.data.shape\n# torch.Size([1, 3, 880, 1072])\n```", "```py\nimport numpy as np\n\n# squeeze, take to CPU and clip the values\noutput = outputs.reconstruction.data.squeeze().cpu().clamp_(0, 1).numpy()\n# rearrange the axes\noutput = np.moveaxis(output, source=0, destination=-1)\n# bring values back to pixel values range\noutput = (output * 255.0).round().astype(np.uint8)\nImage.fromarray(output)\n```"]