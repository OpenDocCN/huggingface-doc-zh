["```py\n!pip install -q transformers accelerate\n!pip install peft\n!pip install diffusers\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\npipe_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\npipe = DiffusionPipeline.from_pretrained(pipe_id, torch_dtype=torch.float16).to(\"cuda\")\n```", "```py\npipe.load_lora_weights(\"CiroN2022/toy-face\", weight_name=\"toy_face_sdxl.safetensors\", adapter_name=\"toy\")\n```", "```py\nprompt = \"toy_face of a hacker with a hoodie\"\n\nlora_scale= 0.9\nimage = pipe(\n    prompt, num_inference_steps=30, cross_attention_kwargs={\"scale\": lora_scale}, generator=torch.manual_seed(0)\n).images[0]\nimage\n```", "```py\npipe.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\", adapter_name=\"pixel\")\npipe.set_adapters(\"pixel\")\n```", "```py\nprompt = \"a hacker with a hoodie, pixel art\"\nimage = pipe(\n    prompt, num_inference_steps=30, cross_attention_kwargs={\"scale\": lora_scale}, generator=torch.manual_seed(0)\n).images[0]\nimage\n```", "```py\npipe.set_adapters([\"pixel\", \"toy\"], adapter_weights=[0.5, 1.0])\n```", "```py\n# Notice how the prompt is constructed.\nprompt = \"toy_face of a hacker with a hoodie, pixel art\"\nimage = pipe(\n    prompt, num_inference_steps=30, cross_attention_kwargs={\"scale\": 1.0}, generator=torch.manual_seed(0)\n).images[0]\nimage\n```", "```py\n# First, set the adapter.\npipe.set_adapters(\"toy\")\n\n# Then, run inference.\nprompt = \"toy_face of a hacker with a hoodie\"\nlora_scale= 0.9\nimage = pipe(\n    prompt, num_inference_steps=30, cross_attention_kwargs={\"scale\": lora_scale}, generator=torch.manual_seed(0)\n).images[0]\nimage\n```", "```py\npipe.disable_lora()\n\nprompt = \"toy_face of a hacker with a hoodie\"\nlora_scale= 0.9\nimage = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]\nimage\n```", "```py\nactive_adapters = pipe.get_active_adapters()\nactive_adapters\n[\"toy\", \"pixel\"]\n```", "```py\nlist_adapters_component_wise = pipe.get_list_adapters()\nlist_adapters_component_wise\n{\"text_encoder\": [\"toy\", \"pixel\"], \"unet\": [\"toy\", \"pixel\"], \"text_encoder_2\": [\"toy\", \"pixel\"]}\n```", "```py\npipe.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\", adapter_name=\"pixel\")\npipe.load_lora_weights(\"CiroN2022/toy-face\", weight_name=\"toy_face_sdxl.safetensors\", adapter_name=\"toy\")\n\npipe.set_adapters([\"pixel\", \"toy\"], adapter_weights=[0.5, 1.0])\n# Fuses the LoRAs into the Unet\npipe.fuse_lora()\n\nprompt = \"toy_face of a hacker with a hoodie, pixel art\"\nimage = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]\n\n# Gets the Unet back to the original state\npipe.unfuse_lora()\n```", "```py\npipe.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\", adapter_name=\"pixel\")\npipe.load_lora_weights(\"CiroN2022/toy-face\", weight_name=\"toy_face_sdxl.safetensors\", adapter_name=\"toy\")\n\npipe.set_adapters([\"pixel\"], adapter_weights=[0.5, 1.0])\n# Fuses the LoRAs into the Unet\npipe.fuse_lora(adapter_names=[\"pixel\"])\n\nprompt = \"a hacker with a hoodie, pixel art\"\nimage = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]\n\n# Gets the Unet back to the original state\npipe.unfuse_lora()\n\n# Fuse all adapters\npipe.fuse_lora(adapter_names=[\"pixel\", \"toy\"])\n\nprompt = \"toy_face of a hacker with a hoodie, pixel art\"\nimage = pipe(prompt, num_inference_steps=30, generator=torch.manual_seed(0)).images[0]\n```", "```py\npipe.fuse_lora(lora_scale=1.0)\npipe.unload_lora_weights()\npipe.save_pretrained(\"path-to-pipeline\")\n```"]