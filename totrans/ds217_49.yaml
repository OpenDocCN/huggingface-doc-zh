- en: Structure your repository
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建您的存储库
- en: 'Original text: [https://huggingface.co/docs/datasets/repository_structure](https://huggingface.co/docs/datasets/repository_structure)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/repository_structure](https://huggingface.co/docs/datasets/repository_structure)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: To host and share your dataset, create a dataset repository on the Hugging Face
    Hub and upload your data files.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 要托管和共享您的数据集，请在Hugging Face Hub上创建一个数据集存储库并上传您的数据文件。
- en: This guide will show you how to structure your dataset repository when you upload
    it. A dataset with a supported structure and file format (`.txt`, `.csv`, `.parquet`,
    `.jsonl`, `.mp3`, `.jpg`, `.zip` etc.) are loaded automatically with [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    and it’ll have a dataset viewer on its dataset page on the Hub.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将向您展示如何在上传时构建数据集存储库。具有支持的结构和文件格式（`.txt`、`.csv`、`.parquet`、`.jsonl`、`.mp3`、`.jpg`、`.zip`等）的数据集将自动加载，并且在Hub上的数据集页面上将有一个数据集查看器。
- en: Main use-case
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要用例
- en: 'The simplest dataset structure has two files: `train.csv` and `test.csv` (this
    works with any supported file format).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的数据集结构有两个文件：`train.csv`和`test.csv`（这适用于任何支持的文件格式）。
- en: Your repository will also contain a `README.md` file, the [dataset card](dataset_card)
    displayed on your dataset page.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您的存储库还将包含一个`README.md`文件，显示在数据集页面上的[数据集卡片](dataset_card)。
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this simple case, you’ll get a dataset with two splits: `train` (containing
    examples from `train.csv`) and `test` (containing examples from `test.csv`).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种简单情况下，您将获得一个包含`train.csv`中示例的`train`拆分和一个包含`test.csv`中示例的`test`拆分的数据集。
- en: Define your splits and subsets in YAML
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在YAML中定义您的拆分和子集
- en: Splits
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分
- en: If you have multiple files and want to define which file goes into which split,
    you can use the YAML `configs` field at the top of your README.md.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有多个文件并且想要定义哪个文件放入哪个拆分，可以在README.md顶部使用YAML的`configs`字段。
- en: 'For example, given a repository like this one:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，给定这样一个存储库：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can define your splits by adding the `configs` field in the YAML block
    at the top of your README.md:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在README.md顶部的YAML块中添加`configs`字段来定义您的拆分：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can select multiple files per split using a list of paths:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用路径列表选择每个拆分的多个文件：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Or you can use glob patterns to automatically list all the files you need:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您可以使用通配符模式自动列出所需的所有文件：
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that `config_name` field is required even if you have a single configuration.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，即使只有一个配置，`config_name`字段也是必需的。
- en: Configurations
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: 'Your dataset might have several subsets of data that you want to be able to
    load separately. In that case you can define a list of configurations inside the
    `configs` field in YAML:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据集可能有几个您希望能够单独加载的数据子集。在这种情况下，您可以在YAML的`configs`字段中定义一个配置列表：
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Each configuration is shown separately on the Hugging Face Hub, and can be
    loaded by passing its name as a second parameter:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个配置都单独显示在Hugging Face Hub上，并且可以通过将其名称作为第二个参数传递来加载：
- en: '[PRE8]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Builder parameters
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建器参数
- en: 'Not only `data_files`, but other builder-specific parameters can be passed
    via YAML, allowing for more flexibility on how to load the data while not requiring
    any custom code. For example, define which separator to use in which configuration
    to load your `csv` files:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅可以通过YAML传递`data_files`，还可以通过YAML传递其他特定于构建器的参数，从而在加载数据时提供更多灵活性而不需要任何自定义代码。例如，定义在哪个配置中使用哪个分隔符加载您的`csv`文件：
- en: '[PRE9]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Refer to [specific builders’ documentation](./package_reference/builder_classes)
    to see what configuration parameters they have.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参考[特定构建器文档](./package_reference/builder_classes)以查看它们具有哪些配置参数。
- en: 'You can set a default configuration using `default: true`, e.g. you can run
    `main_data = load_dataset("my_dataset_repository")` if you set'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '您可以使用`default: true`来设置默认配置，例如，如果您设置了，您可以运行`main_data = load_dataset("my_dataset_repository")`'
- en: '[PRE10]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Automatic splits detection
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动拆分检测
- en: If no YAML is provided, 🤗 Datasets searches for certain patterns in the dataset
    repository to automatically infer the dataset splits. There is an order to the
    patterns, beginning with the custom filename split format to treating all files
    as a single split if no pattern is found.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有提供YAML，🤗 数据集将搜索数据集存储库中的某些模式，以自动推断数据集拆分。这些模式有一定的顺序，从自定义文件名拆分格式开始，如果找不到任何模式，则将所有文件视为单个拆分。
- en: Directory name
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目录名称
- en: 'Your data files may also be placed into different directories named `train`,
    `test`, and `validation` where each directory contains the data files for that
    split:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据文件也可以放置在名为`train`、`test`和`validation`的不同目录中，每个目录包含该拆分的数据文件：
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Filename splits
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文件名拆分
- en: If you don’t have any non-traditional splits, then you can place the split name
    anywhere in the data file and it is automatically inferred. The only rule is that
    the split name must be delimited by non-word characters, like `test-file.csv`
    for example instead of `testfile.csv`. Supported delimiters include underscores,
    dashes, spaces, dots, and numbers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有任何非传统拆分，那么您可以将拆分名称放在数据文件的任何位置，并且会自动推断。唯一的规则是拆分名称必须由非单词字符分隔，例如，`test-file.csv`而不是`testfile.csv`。支持的分隔符包括下划线、破折号、空格、点和数字。
- en: 'For example, the following file names are all acceptable:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下文件名都是可接受的：
- en: 'train split: `train.csv`, `my_train_file.csv`, `train1.csv`'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练拆分：`train.csv`、`my_train_file.csv`、`train1.csv`
- en: 'validation split: `validation.csv`, `my_validation_file.csv`, `validation1.csv`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证拆分：`validation.csv`、`my_validation_file.csv`、`validation1.csv`
- en: 'test split: `test.csv`, `my_test_file.csv`, `test1.csv`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试拆分：`test.csv`、`my_test_file.csv`、`test1.csv`
- en: 'Here is an example where all the files are placed into a directory named `data`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个所有文件都放置在名为`data`的目录中的示例：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Custom filename split
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义文件名拆分
- en: If your dataset splits have custom names that aren’t `train`, `test`, or `validation`,
    then you can name your data files like `data/<split_name>-xxxxx-of-xxxxx.csv`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集拆分具有非`train`、`test`或`validation`的自定义名称，则可以将数据文件命名为`data/<split_name>-xxxxx-of-xxxxx.csv`。
- en: 'Here is an example with three splits, `train`, `test`, and `random`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个具有三个拆分`train`、`test`和`random`的示例：
- en: '[PRE13]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Single split
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单个拆分
- en: When 🤗 Datasets can’t find any of the above patterns, then it’ll treat all the
    files as a single train split. If your dataset splits aren’t loading as expected,
    it may be due to an incorrect pattern.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当🤗数据集找不到以上任何模式时，它将把所有文件视为单个训练拆分。如果您的数据集拆分加载不符合预期，可能是由于不正确的模式。
- en: Split name keywords
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拆分名称关键字
- en: 'There are several ways to name splits. Validation splits are sometimes called
    “dev”, and test splits may be referred to as “eval”. These other split names are
    also supported, and the following keywords are equivalent:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种命名拆分的方法。验证拆分有时称为“dev”，测试拆分可能被称为“eval”。这些其他拆分名称也受支持，以下关键字是等效的：
- en: train, training
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: train，training
- en: validation, valid, val, dev
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证，有效，val，dev
- en: test, testing, eval, evaluation
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试，测试，评估，评估
- en: 'The structure below is a valid repository:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结构是一个有效的存储库：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Multiple files per split
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个拆分多个文件
- en: 'If one of your splits comprises several files, 🤗 Datasets can still infer whether
    it is the train, validation, and test split from the file name. For example, if
    your train and test splits span several files:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的某个拆分包含多个文件，🤗数据集仍然可以推断出它是来自文件名的训练，验证和测试拆分。例如，如果您的训练和测试拆分跨越多个文件：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Make sure all the files of your `train` set have *train* in their names (same
    for test and validation). Even if you add a prefix or suffix to `train` in the
    file name (like `my_train_file_00001.csv` for example), 🤗 Datasets can still infer
    the appropriate split.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的`train`集的所有文件名称中都有*train*（测试和验证也是如此）。即使您在文件名中添加了前缀或后缀以`train`（例如`my_train_file_00001.csv`），🤗数据集仍然可以推断出适当的拆分。
- en: For convenience, you can also place your data files into different directories.
    In this case, the split name is inferred from the directory name.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，您还可以将数据文件放入不同的目录中。在这种情况下，拆分名称是从目录名称推断出来的。
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For more flexibility over how to load and generate a dataset, you can also write
    a [dataset loading script](./dataset_script).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更灵活地加载和生成数据集，您还可以编写一个[数据集加载脚本]（./dataset_script）。
