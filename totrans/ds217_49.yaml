- en: Structure your repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/datasets/repository_structure](https://huggingface.co/docs/datasets/repository_structure)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: To host and share your dataset, create a dataset repository on the Hugging Face
    Hub and upload your data files.
  prefs: []
  type: TYPE_NORMAL
- en: This guide will show you how to structure your dataset repository when you upload
    it. A dataset with a supported structure and file format (`.txt`, `.csv`, `.parquet`,
    `.jsonl`, `.mp3`, `.jpg`, `.zip` etc.) are loaded automatically with [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    and it‚Äôll have a dataset viewer on its dataset page on the Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Main use-case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The simplest dataset structure has two files: `train.csv` and `test.csv` (this
    works with any supported file format).'
  prefs: []
  type: TYPE_NORMAL
- en: Your repository will also contain a `README.md` file, the [dataset card](dataset_card)
    displayed on your dataset page.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple case, you‚Äôll get a dataset with two splits: `train` (containing
    examples from `train.csv`) and `test` (containing examples from `test.csv`).'
  prefs: []
  type: TYPE_NORMAL
- en: Define your splits and subsets in YAML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Splits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have multiple files and want to define which file goes into which split,
    you can use the YAML `configs` field at the top of your README.md.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, given a repository like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can define your splits by adding the `configs` field in the YAML block
    at the top of your README.md:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can select multiple files per split using a list of paths:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Or you can use glob patterns to automatically list all the files you need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note that `config_name` field is required even if you have a single configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your dataset might have several subsets of data that you want to be able to
    load separately. In that case you can define a list of configurations inside the
    `configs` field in YAML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Each configuration is shown separately on the Hugging Face Hub, and can be
    loaded by passing its name as a second parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Builder parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Not only `data_files`, but other builder-specific parameters can be passed
    via YAML, allowing for more flexibility on how to load the data while not requiring
    any custom code. For example, define which separator to use in which configuration
    to load your `csv` files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Refer to [specific builders‚Äô documentation](./package_reference/builder_classes)
    to see what configuration parameters they have.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can set a default configuration using `default: true`, e.g. you can run
    `main_data = load_dataset("my_dataset_repository")` if you set'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Automatic splits detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If no YAML is provided, ü§ó Datasets searches for certain patterns in the dataset
    repository to automatically infer the dataset splits. There is an order to the
    patterns, beginning with the custom filename split format to treating all files
    as a single split if no pattern is found.
  prefs: []
  type: TYPE_NORMAL
- en: Directory name
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Your data files may also be placed into different directories named `train`,
    `test`, and `validation` where each directory contains the data files for that
    split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Filename splits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you don‚Äôt have any non-traditional splits, then you can place the split name
    anywhere in the data file and it is automatically inferred. The only rule is that
    the split name must be delimited by non-word characters, like `test-file.csv`
    for example instead of `testfile.csv`. Supported delimiters include underscores,
    dashes, spaces, dots, and numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following file names are all acceptable:'
  prefs: []
  type: TYPE_NORMAL
- en: 'train split: `train.csv`, `my_train_file.csv`, `train1.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'validation split: `validation.csv`, `my_validation_file.csv`, `validation1.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'test split: `test.csv`, `my_test_file.csv`, `test1.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is an example where all the files are placed into a directory named `data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Custom filename split
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If your dataset splits have custom names that aren‚Äôt `train`, `test`, or `validation`,
    then you can name your data files like `data/<split_name>-xxxxx-of-xxxxx.csv`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example with three splits, `train`, `test`, and `random`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Single split
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When ü§ó Datasets can‚Äôt find any of the above patterns, then it‚Äôll treat all the
    files as a single train split. If your dataset splits aren‚Äôt loading as expected,
    it may be due to an incorrect pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Split name keywords
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are several ways to name splits. Validation splits are sometimes called
    ‚Äúdev‚Äù, and test splits may be referred to as ‚Äúeval‚Äù. These other split names are
    also supported, and the following keywords are equivalent:'
  prefs: []
  type: TYPE_NORMAL
- en: train, training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: validation, valid, val, dev
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: test, testing, eval, evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The structure below is a valid repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Multiple files per split
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If one of your splits comprises several files, ü§ó Datasets can still infer whether
    it is the train, validation, and test split from the file name. For example, if
    your train and test splits span several files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Make sure all the files of your `train` set have *train* in their names (same
    for test and validation). Even if you add a prefix or suffix to `train` in the
    file name (like `my_train_file_00001.csv` for example), ü§ó Datasets can still infer
    the appropriate split.
  prefs: []
  type: TYPE_NORMAL
- en: For convenience, you can also place your data files into different directories.
    In this case, the split name is inferred from the directory name.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: For more flexibility over how to load and generate a dataset, you can also write
    a [dataset loading script](./dataset_script).
  prefs: []
  type: TYPE_NORMAL
