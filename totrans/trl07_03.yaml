- en: Quickstart
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/trl/quickstart](https://huggingface.co/docs/trl/quickstart)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/trl/v0.7.10/en/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/entry/start.d9a24ea1.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/scheduler.9039eef2.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/singletons.9eef12cc.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/paths.1355483e.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/entry/app.5bef33b8.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/index.ded8f90d.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/nodes/0.abccdcd8.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/nodes/18.a2a75e85.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/CodeBlock.8580f3e8.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/Heading.f027f30d.js">
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fine-tuning a language model via PPO consists of roughly three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rollout**: The language model generates a response or continuation based
    on a query which could be the start of a sentence.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evaluation**: The query and response are evaluated with a function, model,
    human feedback, or some combination of them. The important thing is that this
    process should yield a scalar value for each query/response pair. The optimization
    will aim at maximizing this value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Optimization**: This is the most complex part. In the optimisation step the
    query/response pairs are used to calculate the log-probabilities of the tokens
    in the sequences. This is done with the model that is trained and a reference
    model, which is usually the pre-trained model before fine-tuning. The KL-divergence
    between the two outputs is used as an additional reward signal to make sure the
    generated responses don’t deviate too far from the reference language model. The
    active language model is then trained with PPO.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The full process is illustrated in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00db2b272395f1f726efb5b3cd2a73ca.png)'
  prefs: []
  type: TYPE_IMG
- en: Minimal example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following code illustrates the steps above.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In general, you would run steps 3-6 in a for-loop and run it on many diverse
    queries. You can find more realistic examples in the examples section.
  prefs: []
  type: TYPE_NORMAL
- en: How to use a trained model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After training a `AutoModelForCausalLMWithValueHead`, you can directly use the
    model in `transformers`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can also load your model with `AutoModelForCausalLMWithValueHead` if you
    want to use the value head, for example to continue training.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
