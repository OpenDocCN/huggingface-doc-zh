# 比较不同设备设置之间的性能

> 原始文本：[https://huggingface.co/docs/accelerate/concept_guides/performance](https://huggingface.co/docs/accelerate/concept_guides/performance)

评估和比较来自不同设置的性能可能会非常棘手，如果您不知道要查找什么。例如，您不能在TPU、多GPU和单GPU上使用相同的脚本和相同的批量大小运行Accelerate，并期望您的结果能够对齐。

但为什么？

这个教程将涵盖三个原因：

1.  **设置正确的种子**

1.  **观察到的批量大小**

1.  **学习率**

## 设置种子

虽然这个问题并没有出现得很多，但请确保在所有分布式情况下使用[utils.set_seed()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.set_seed)来完全设置种子，以便训练是可重现的：

```py
from accelerate.utils import set_seed

set_seed(42)
```

为什么这很重要？在幕后，这将设置**5**个不同的种子设置：

```py
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # ^^ safe to call this function even if cuda is not available
    if is_tpu_available():
        xm.set_rng_state(seed)
```

随机状态、numpy的状态、torch、torch的cuda状态，以及如果TPUs可用，torch_xla的cuda状态。

## 观察到的批量大小

在使用Accelerate进行训练时，传递给数据加载器的批量大小是**每个GPU的批量大小**。这意味着在两个GPU上的批量大小为64实际上是128。因此，在单个GPU上进行测试时，需要考虑到这一点，以及类似地对于TPUs。

下表可用作快速参考，尝试不同的批量大小：

在这个例子中，有两个GPU用于“多GPU”，以及一个具有8个工作节点的TPU pod

| 单个GPU批量大小 | 多GPU等效批量大小 | TPU等效批量大小 |
| --- | --- | --- |
| 256 | 128 | 32 |
| 128 | 64 | 16 |
| 64 | 32 | 8 |
| 32 | 16 | 4 |

## 学习率

正如多个来源所指出[[1](https://aws.amazon.com/blogs/machine-learning/scalable-multi-node-deep-learning-training-using-gpus-in-the-aws-cloud/)][[2](https://docs.nvidia.com/clara/clara-train-sdk/pt/model.html#classification-models-multi-gpu-training)]，学习率应该根据设备数量*线性*缩放。下面的代码片段展示了如何在Accelerate中实现这一点：

由于用户可以定义自己的学习率调度程序，我们将此留给用户决定是否希望调整他们的学习率。

```py
learning_rate = 1e-3
accelerator = Accelerator()
learning_rate *= accelerator.num_processes

optimizer = AdamW(params=model.parameters(), lr=learning_rate)
```

您还会发现`accelerate`将根据正在训练的进程数量调整学习率。这是因为早期观察到的批量大小。因此，在使用2个GPU的情况下，学习率将比单个GPU频繁调整两倍，以考虑批量大小增加两倍（如果不对单个GPU实例的批量大小进行更改）。

## 梯度累积和混合精度

当使用梯度累积和混合精度时，由于梯度平均（累积）和精度损失（混合精度）的工作方式，预计会出现一定程度的性能下降。这将在比较不同计算设置之间的逐批损失时明显看到。然而，在训练结束时，总体损失、指标和性能应该是*大致*相同的。
