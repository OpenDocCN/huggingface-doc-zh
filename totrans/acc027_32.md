# 比较不同设备设置之间的性能

> 原始文本：[`huggingface.co/docs/accelerate/concept_guides/performance`](https://huggingface.co/docs/accelerate/concept_guides/performance)

评估和比较来自不同设置的性能可能会非常棘手，如果您不知道要查找什么。例如，您不能在 TPU、多 GPU 和单 GPU 上使用相同的脚本和相同的批量大小运行 Accelerate，并期望您的结果能够对齐。

但为什么？

这个教程将涵盖三个原因：

1.  **设置正确的种子**

1.  **观察到的批量大小**

1.  **学习率**

## 设置种子

虽然这个问题并没有出现得很多，但请确保在所有分布式情况下使用 utils.set_seed()来完全设置种子，以便训练是可重现的：

```py
from accelerate.utils import set_seed

set_seed(42)
```

为什么这很重要？在幕后，这将设置**5**个不同的种子设置：

```py
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # ^^ safe to call this function even if cuda is not available
    if is_tpu_available():
        xm.set_rng_state(seed)
```

随机状态、numpy 的状态、torch、torch 的 cuda 状态，以及如果 TPUs 可用，torch_xla 的 cuda 状态。

## 观察到的批量大小

在使用 Accelerate 进行训练时，传递给数据加载器的批量大小是**每个 GPU 的批量大小**。这意味着在两个 GPU 上的批量大小为 64 实际上是 128。因此，在单个 GPU 上进行测试时，需要考虑到这一点，以及类似地对于 TPUs。

下表可用作快速参考，尝试不同的批量大小：

在这个例子中，有两个 GPU 用于“多 GPU”，以及一个具有 8 个工作节点的 TPU pod

| 单个 GPU 批量大小 | 多 GPU 等效批量大小 | TPU 等效批量大小 |
| --- | --- | --- |
| 256 | 128 | 32 |
| 128 | 64 | 16 |
| 64 | 32 | 8 |
| 32 | 16 | 4 |

## 学习率

正如多个来源所指出[[1](https://aws.amazon.com/blogs/machine-learning/scalable-multi-node-deep-learning-training-using-gpus-in-the-aws-cloud/)][[2](https://docs.nvidia.com/clara/clara-train-sdk/pt/model.html#classification-models-multi-gpu-training)]，学习率应该根据设备数量*线性*缩放。下面的代码片段展示了如何在 Accelerate 中实现这一点：

由于用户可以定义自己的学习率调度程序，我们将此留给用户决定是否希望调整他们的学习率。

```py
learning_rate = 1e-3
accelerator = Accelerator()
learning_rate *= accelerator.num_processes

optimizer = AdamW(params=model.parameters(), lr=learning_rate)
```

您还会发现`accelerate`将根据正在训练的进程数量调整学习率。这是因为早期观察到的批量大小。因此，在使用 2 个 GPU 的情况下，学习率将比单个 GPU 频繁调整两倍，以考虑批量大小增加两倍（如果不对单个 GPU 实例的批量大小进行更改）。

## 梯度累积和混合精度

当使用梯度累积和混合精度时，由于梯度平均（累积）和精度损失（混合精度）的工作方式，预计会出现一定程度的性能下降。这将在比较不同计算设置之间的逐批损失时明显看到。然而，在训练结束时，总体损失、指标和性能应该是*大致*相同的。
