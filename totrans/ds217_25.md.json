["```py\n>>> from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n>>> import torch\n>>> torch.set_grad_enabled(False)\n>>> ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n>>> ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n```", "```py\n>>> from datasets import load_dataset\n>>> ds = load_dataset('crime_and_punish', split='train[:100]')\n>>> ds_with_embeddings = ds.map(lambda example: {'embeddings': ctx_encoder(**ctx_tokenizer(example[\"line\"], return_tensors=\"pt\"))[0][0].numpy()})\n```", "```py\n>>> ds_with_embeddings.add_faiss_index(column='embeddings')\n```", "```py\n>>> from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n>>> q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n>>> q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n\n>>> question = \"Is it serious ?\"\n>>> question_embedding = q_encoder(**q_tokenizer(question, return_tensors=\"pt\"))[0][0].numpy()\n>>> scores, retrieved_examples = ds_with_embeddings.get_nearest_examples('embeddings', question_embedding, k=10)\n>>> retrieved_examples[\"line\"][0]\n'_that_ serious? It is not serious at all. It\u2019s simply a fantasy to amuse\\r\\n'\n```", "```py\n>>> faiss_index = ds_with_embeddings.get_index('embeddings').faiss_index\n>>> limits, distances, indices = faiss_index.range_search(x=question_embedding.reshape(1, -1), thresh=0.95)\n```", "```py\n>>> ds_with_embeddings.save_faiss_index('embeddings', 'my_index.faiss')\n```", "```py\n>>> ds = load_dataset('crime_and_punish', split='train[:100]')\n>>> ds.load_faiss_index('embeddings', 'my_index.faiss')\n```", "```py\n>>> from datasets import load_dataset\n>>> squad = load_dataset('squad', split='validation')\n```", "```py\n>>> squad.add_elasticsearch_index(\"context\", host=\"localhost\", port=\"9200\")\n```", "```py\n>>> query = \"machine\"\n>>> scores, retrieved_examples = squad.get_nearest_examples(\"context\", query, k=10)\n>>> retrieved_examples[\"title\"][0]\n'Computational_complexity_theory'\n```", "```py\n>>> from datasets import load_dataset\n>>> squad = load_dataset('squad', split='validation')\n>>> squad.add_elasticsearch_index(\"context\", host=\"localhost\", port=\"9200\", es_index_name=\"hf_squad_val_context\")\n>>> squad.get_index(\"context\").es_index_name\nhf_squad_val_context\n```", "```py\n>>> from datasets import load_dataset\n>>> squad = load_dataset('squad', split='validation')\n>>> squad.load_elasticsearch_index(\"context\", host=\"localhost\", port=\"9200\", es_index_name=\"hf_squad_val_context\")\n>>> query = \"machine\"\n>>> scores, retrieved_examples = squad.get_nearest_examples(\"context\", query, k=10)\n```", "```py\n>>> import elasticsearch as es\n>>> import elasticsearch.helpers\n>>> from elasticsearch import Elasticsearch\n>>> es_client = Elasticsearch([{\"host\": \"localhost\", \"port\": \"9200\"}])  # default client\n>>> es_config = {\n...     \"settings\": {\n...         \"number_of_shards\": 1,\n...         \"analysis\": {\"analyzer\": {\"stop_standard\": {\"type\": \"standard\", \" stopwords\": \"_english_\"}}},\n...     },\n...     \"mappings\": {\"properties\": {\"text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"}}},\n... }  # default config\n>>> es_index_name = \"hf_squad_context\"  # name of the index in Elasticsearch\n>>> squad.add_elasticsearch_index(\"context\", es_client=es_client, es_config=es_config, es_index_name=es_index_name)\n```"]