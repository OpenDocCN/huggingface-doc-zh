- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit1/summary](https://huggingface.co/learn/deep-rl-course/unit1/summary)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: 'That was a lot of information! Let’s summarize:'
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning is a computational approach of learning from actions.
    We build an agent that learns from the environment **by interacting with it through
    trial and error** and receiving rewards (negative or positive) as feedback.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The goal of any RL agent is to maximize its expected cumulative reward (also
    called expected return) because RL is based on the **reward hypothesis**, which
    is that **all goals can be described as the maximization of the expected cumulative
    reward.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The RL process is a loop that outputs a sequence of **state, action, reward
    and next state.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To calculate the expected cumulative reward (expected return), we discount
    the rewards: the rewards that come sooner (at the beginning of the game) **are
    more probable to happen since they are more predictable than the long term future
    reward.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To solve an RL problem, you want to **find an optimal policy**. The policy is
    the “brain” of your agent, which will tell us **what action to take given a state.**
    The optimal policy is the one which **gives you the actions that maximize the
    expected return.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two ways to find your optimal policy:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By training your policy directly: **policy-based methods.**'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'By training a value function that tells us the expected return the agent will
    get at each state and use this function to define our policy: **value-based methods.**'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we speak about Deep RL because we introduce **deep neural networks
    to estimate the action to take (policy-based) or to estimate the value of a state
    (value-based)** hence the name “deep”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
