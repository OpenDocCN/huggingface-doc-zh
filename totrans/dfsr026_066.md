# 文本反转

> 原始文本：[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)

[Textual Inversion](https://hf.co/papers/2208.01618)是一种训练技术，用于个性化图像生成模型，只需提供几个示例图像，让模型学习。该技术通过学习和更新文本嵌入（新嵌入与您在提示中必须使用的特殊单词相关联）来匹配您提供的示例图像。

如果您在具有有限vRAM的GPU上进行训练，您应该尝试在训练命令中启用`gradient_checkpointing`和`mixed_precision`参数。您还可以通过使用[xFormers](../optimization/xformers)的内存高效注意力来减少内存占用。JAX/Flax训练也支持在TPU和GPU上进行高效训练，但不支持梯度检查点或xFormers。与PyTorch相同的配置和设置，Flax训练脚本应至少快约70%！

本指南将探讨[textual_inversion.py](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)脚本，帮助您更熟悉它，并了解如何为自己的用例进行调整。

在运行脚本之前，请确保您从源代码安装库：

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

导航到包含训练脚本的示例文件夹，并安装您正在使用的脚本所需的依赖项：

PyTorchFlax

```py
cd examples/textual_inversion
pip install -r requirements.txt
```

🤗 Accelerate是一个库，可以帮助您在多个GPU/TPU上进行训练，或者使用混合精度。它将根据您的硬件和环境自动配置您的训练设置。查看🤗 Accelerate [快速入门](https://huggingface.co/docs/accelerate/quicktour)以了解更多信息。

初始化🤗 Accelerate环境：

```py
accelerate config
```

要设置默认的🤗 Accelerate环境而不选择任何配置：

```py
accelerate config default
```

或者，如果您的环境不支持交互式shell，比如笔记本，您可以使用：

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

最后，如果您想在自己的数据集上训练模型，请查看[创建用于训练的数据集](create_dataset)指南，了解如何创建适用于训练脚本的数据集。

以下部分突出显示了训练脚本的重要部分，有助于了解如何修改它，但并未详细涵盖脚本的每个方面。如果您有兴趣了解更多，请随时阅读[脚本](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)，如果您有任何问题或疑虑，请告诉我们。

## 脚本参数

训练脚本有许多参数，可帮助您根据需要定制训练运行。所有参数及其描述都列在[`parse_args()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L176)函数中。在适用的情况下，Diffusers为每个参数提供默认值，如训练批量大小和学习率，但如果您愿意，可以在训练命令中更改这些值。

例如，要增加梯度累积步数，超过默认值1：

```py
accelerate launch textual_inversion.py \
  --gradient_accumulation_steps=4
```

还有一些其他基本和重要的参数需要指定：

+   `--pretrained_model_name_or_path`: Hub上模型的名称或预训练模型的本地路径

+   `--train_data_dir`: 指向包含训练数据集（例如图像）的文件夹路径

+   `--output_dir`: 保存训练模型的位置

+   `--push_to_hub`: 是否将训练好的模型推送到Hub

+   `--checkpointing_steps`: 保存检查点的频率，当模型训练时；如果由于某种原因训练中断，您可以通过在训练命令中添加`--resume_from_checkpoint`来从该检查点继续训练

+   `--num_vectors`：要学习嵌入的向量数量；增加此参数有助于模型学习更好，但会增加训练成本

+   `--placeholder_token`：将学习的嵌入与之关联的特殊单词（您必须在推理中使用该单词）

+   `--initializer_token`：大致描述您要训练的对象或风格的单词

+   `--learnable_property`：您是否正在训练模型学习新的“风格”（例如，梵高的绘画风格）或“对象”（例如，您的狗）

## 训练脚本

与其他一些训练脚本不同，textual_inversion.py具有一个自定义数据集类，[`TextualInversionDataset`](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L487)用于创建数据集。您可以自定义图像大小、占位符标记、插值方法、是否裁剪图像等。如果您需要更改数据集的创建方式，可以修改`TextualInversionDataset`。

接下来，您将在[`main()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L573)函数中找到数据集预处理代码和训练循环。

脚本首先加载[tokenizer](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L616)、[scheduler和model](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L622)：

```py
# Load tokenizer
if args.tokenizer_name:
    tokenizer = CLIPTokenizer.from_pretrained(args.tokenizer_name)
elif args.pretrained_model_name_or_path:
    tokenizer = CLIPTokenizer.from_pretrained(args.pretrained_model_name_or_path, subfolder="tokenizer")

# Load scheduler and models
noise_scheduler = DDPMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder="scheduler")
text_encoder = CLIPTextModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="text_encoder", revision=args.revision
)
vae = AutoencoderKL.from_pretrained(args.pretrained_model_name_or_path, subfolder="vae", revision=args.revision)
unet = UNet2DConditionModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="unet", revision=args.revision
)
```

接下来在tokenizer旁边添加特殊的[占位符标记](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L632)，并调整嵌入以考虑新标记。

然后，脚本从`TextualInversionDataset`中[创建数据集](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L716)：

```py
train_dataset = TextualInversionDataset(
    data_root=args.train_data_dir,
    tokenizer=tokenizer,
    size=args.resolution,
    placeholder_token=(" ".join(tokenizer.convert_ids_to_tokens(placeholder_token_ids))),
    repeats=args.repeats,
    learnable_property=args.learnable_property,
    center_crop=args.center_crop,
    set="train",
)
train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=args.train_batch_size, shuffle=True, num_workers=args.dataloader_num_workers
)
```

最后，[训练循环](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L784)处理从预测嘈杂残差到更新特殊占位符标记的嵌入权重的所有其他内容。

如果您想了解训练循环的工作原理，请查看[理解管道、模型和调度器](../using-diffusers/write_own_pipeline)教程，该教程解释了去噪过程的基本模式。

## 启动脚本

一旦您完成了所有更改或对默认配置满意，您就可以启动训练脚本了！🚀

对于本指南，您将下载一些[猫玩具的图像](https://huggingface.co/datasets/diffusers/cat_toy_example)并将它们存储在一个目录中。但请记住，如果您愿意，您可以创建并使用自己的数据集（请参阅[创建用于训练的数据集](create_dataset)指南）。

```py
from huggingface_hub import snapshot_download

local_dir = "./cat"
snapshot_download(
    "diffusers/cat_toy_example", local_dir=local_dir, repo_type="dataset", ignore_patterns=".gitattributes"
)
```

将环境变量`MODEL_NAME`设置为Hub上的模型ID或本地模型的路径，并将`DATA_DIR`设置为您刚下载猫图像的路径。脚本将以下文件创建并保存到您的存储库中：

+   `learned_embeds.bin`：与您的示例图像对应的学习嵌入向量

+   `token_identifier.txt`：特殊的占位符标记

+   `type_of_concept.txt`：您正在训练的概念类型（“对象”或“风格”）

在单个V100 GPU上进行完整的训练需要约1小时。

在启动脚本之前还有一件事。如果您有兴趣跟踪训练过程，您可以在训练过程中定期保存生成的图像。将以下参数添加到训练命令中：

```py
--validation_prompt="A <cat-toy> train"
--num_validation_images=4
--validation_steps=100
```

PyTorchFlax

```py
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export DATA_DIR="./cat"

accelerate launch textual_inversion.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --train_data_dir=$DATA_DIR \
  --learnable_property="object" \
  --placeholder_token="<cat-toy>" \
  --initializer_token="toy" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --max_train_steps=3000 \
  --learning_rate=5.0e-04 \
  --scale_lr \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --output_dir="textual_inversion_cat" \
  --push_to_hub
```

训练完成后，您可以像这样使用您新训练的模型进行推理：

PyTorchFlax

```py
from diffusers import StableDiffusionPipeline
import torch

pipeline = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to("cuda")
pipeline.load_textual_inversion("sd-concepts-library/cat-toy")
image = pipeline("A <cat-toy> train", num_inference_steps=50).images[0]
image.save("cat-train.png")
```

## 下一步

恭喜您训练出自己的文本反转模型！🎉 要了解如何使用您的新模型，以下指南可能会有所帮助：

+   学习如何[加载文本反转嵌入](../using-diffusers/loading_adapters)，并将其用作负嵌入。

+   学习如何使用[文本反转](textual_inversion_inference)进行推理，包括 Stable Diffusion 1/2 和 Stable Diffusion XL。
