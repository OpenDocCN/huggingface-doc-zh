# 命令行

> [https://huggingface.co/docs/accelerate/package_reference/cli](https://huggingface.co/docs/accelerate/package_reference/cli)

以下是所有可用命令🤗加速及其参数的列表

## 加速配置

**命令**:

`accelerate config` 或 `accelerate-config`

启动一系列提示，创建并保存一个`default_config.yml`配置文件，用于您的训练系统。应始终首先在您的机器上运行。

**用法**:

```py
accelerate config [arguments]
```

**可选参数**:

+   `--config_file CONFIG_FILE` (`str`) — 用于存储配置文件的路径。默认为缓存位置中名为default_config.yaml的文件，该位置是环境变量`HF_HOME`的内容后缀为‘accelerate’，或者如果您没有这样的环境变量，则为您的缓存目录(`~/.cache`或`XDG_CACHE_HOME`的内容)后缀为`huggingface`。

+   `-h`, `--help` (`bool`) — 显示帮助信息并退出

## 加速配置默认

**命令**:

`accelerate config default` 或 `accelerate-config default`

为加速创建一个默认配置文件，只设置了几个标志。

**用法**:

```py
accelerate config default [arguments]
```

**可选参数**:

+   `--config_file CONFIG_FILE` (`str`) — 用于存储配置文件的路径。默认为缓存位置中名为default_config.yaml的文件，该位置是环境变量`HF_HOME`的内容后缀为‘accelerate’，或者如果您没有这样的环境变量，则为您的缓存目录(`~/.cache`或`XDG_CACHE_HOME`的内容)后缀为`huggingface`。

+   `-h`, `--help` (`bool`) — 显示帮助信息并退出

+   `--mixed_precision {no,fp16,bf16}` (`str`) — 是否使用混合精度训练。选择在FP16和BF16（bfloat16）训练之间。BF16训练仅受Nvidia Ampere GPU和PyTorch 1.10或更高版本支持。

## 加速配置更新

**命令**:

`accelerate config update` 或 `accelerate-config update`

使用最新默认值更新现有配置文件，同时保留旧配置。

**用法**:

```py
accelerate config update [arguments]
```

**可选参数**:

+   `--config_file CONFIG_FILE` (`str`) — 要更新的配置文件的路径。默认为缓存位置中名为default_config.yaml的文件，该位置是环境变量`HF_HOME`的内容后缀为‘accelerate’，或者如果您没有这样的环境变量，则为您的缓存目录(`~/.cache`或`XDG_CACHE_HOME`的内容)后缀为`huggingface`。

+   `-h`, `--help` (`bool`) — 显示帮助信息并退出

## 加速环境

**命令**:

`accelerate env` 或 `accelerate-env` 或 `python -m accelerate.commands.env`

列出传递的🤗加速配置文件的内容。在打开[GitHub存储库](https://github.com/huggingface/accelerate)上的问题时应始终使用。

**用法**:

```py
accelerate env [arguments]
```

**可选参数**:

+   `--config_file CONFIG_FILE` (`str`) — 用于存储配置文件的路径。默认为缓存位置中名为default_config.yaml的文件，该位置是环境变量`HF_HOME`的内容后缀为‘accelerate’，或者如果您没有这样的环境变量，则为您的缓存目录(`~/.cache`或`XDG_CACHE_HOME`的内容)后缀为`huggingface`。

+   `-h`, `--help` (`bool`) — 显示帮助信息并退出

## 加速启动

**命令**:

`accelerate launch` 或 `accelerate-launch` 或 `python -m accelerate.commands.launch`

在分布式系统上启动指定的脚本，使用正确的参数。

**用法**:

```py
accelerate launch [arguments] {training_script} --{training_script-argument-1} --{training_script-argument-2} ...
```

**位置参数**:

+   `{training_script}` — 要并行启动的脚本的完整路径

+   `--{training_script-argument-1}` — 训练脚本的参数

**可选参数**:

+   `-h`, `--help` (`bool`) — 显示帮助信息并退出

+   `--config_file CONFIG_FILE` (`str`)— 用于启动脚本中默认值的配置文件。

+   `-m`, `--module` (`bool`) — 将每个进程更改为将启动脚本解释为Python模块，以与‘python -m’相同的行为执行。

+   `--no_python` (`bool`) — 跳过在训练脚本前添加“python” - 直接执行它。当脚本不是Python脚本时很有用。

+   `--debug` (`bool`) — 当某些内容失败时是否打印出torch.distributed堆栈跟踪。

+   `-q`, `--quiet` (`bool`) — 从启动堆栈跟踪中消除子进程错误，仅显示相关的跟踪。 （仅适用于DeepSpeed和单进程配置）。

其余这些参数通过指定的`--config_file`（或默认配置）进行配置，其值从中读取。也可以手动传递。

**硬件选择参数**：

+   `--cpu` (`bool`) — 是否强制在CPU上进行训练。

+   `--multi_gpu` (`bool`) — 是否应启动分布式GPU训练。

+   `--tpu` (`bool`) — 是否应启动TPU训练。

+   `--ipex` (`bool`) — 是否应启动Intel Pytorch Extension（IPEX）训练。

**资源选择参数**：

以下参数对于调整可用硬件的使用方式很有用

+   `--mixed_precision {no,fp16,bf16}` (`str`) — 是否使用混合精度训练。选择在FP16和BF16（bfloat16）训练之间。BF16训练仅在Nvidia Ampere GPU和PyTorch 1.10或更高版本上受支持。

+   `--num_processes NUM_PROCESSES` (`int`) — 要并行启动的进程总数。

+   `--num_machines NUM_MACHINES` (`int`) — 在此训练中使用的机器总数。

+   `--num_cpu_threads_per_process NUM_CPU_THREADS_PER_PROCESS` (`int`) — 每个进程的CPU线程数。可以调整以获得最佳性能。

**训练范式参数**：

以下参数对于选择要使用的训练范式很有用。

+   `--use_deepspeed` (`bool`) — 是否使用DeepSpeed进行训练。

+   `--use_fsdp` (`bool`) — 是否使用FullyShardedDataParallel进行训练。

+   `--use_megatron_lm` (`bool`) — 是否使用Megatron-LM进行训练。

+   `--use_xpu` (`bool`) — 是否使用IPEX插件来加速XPU上的训练。

**分布式GPU参数**：

以下参数仅在传递`multi_gpu`或通过`accelerate config`配置多GPU训练时有用：

+   `--gpu_ids` (`str`) — 应该在此机器上用于训练的GPU（按id）作为逗号分隔的列表

+   `--same_network` (`bool`) — 用于多节点训练的所有机器是否存在于同一本地网络上。

+   `--machine_rank MACHINE_RANK` (`int`) — 启动此脚本的机器的等级。

+   `--main_process_ip MAIN_PROCESS_IP` (`str`) — 排名0的机器的IP地址。

+   `--main_process_port MAIN_PROCESS_PORT` (`int`) — 用于与排名0的机器通信的端口。

+   `--rdzv_backend` (`str`) — 要使用的会面方法，例如“static”或“c10d”

+   `--rdzv_conf` (`str`) — 附加的会面配置（<key1>=<value1>,<key2>=<value2>,…）。

+   `--max_restarts` (`int`) — 在失败之前的最大工作组重启次数。

+   `--monitor_interval` (`float`) — 监视工作者状态的间隔，以秒为单位。

**TPU参数**：

以下参数仅在传递`tpu`或通过`accelerate config`配置TPU训练时有用：

+   `--main_training_function MAIN_TRAINING_FUNCTION` (`str`) — 要在脚本中执行的主函数的名称。

+   `--downcast_bf16` (`bool`) — 在TPU上使用bf16精度时，是否将浮点和双精度张量都转换为bfloat16，还是将双精度张量保留为float32。

**DeepSpeed参数**：

以下参数仅在传递`use_deepspeed`或通过`accelerate config`配置`deepspeed`时有用：

+   `--deepspeed_config_file` (`str`) — DeepSpeed配置文件。

+   `--zero_stage` (`int`) — DeepSpeed的ZeRO优化阶段。

+   `--offload_optimizer_device` (`str`) — 决定在哪里（none|cpu|nvme）卸载优化器状态。

+   `--offload_param_device` (`str`) — 决定在哪里（none|cpu|nvme）卸载参数。

+   `--gradient_accumulation_steps` (`int`) — 在训练脚本中使用的梯度累积步数。

+   `--gradient_clipping` (`float`) — 在训练脚本中使用的梯度裁剪值。

+   `--zero3_init_flag` (`str`) — 决定是否启用`deepspeed.zero.Init`来构建大型模型。仅适用于DeepSpeed ZeRO Stage-3。

+   `--zero3_save_16bit_model` (`str`) — 决定在使用ZeRO Stage-3时是否保存16位模型权重。仅适用于DeepSpeed ZeRO Stage-3。

+   `--deepspeed_hostfile` (`str`) — 用于配置多节点计算资源的DeepSpeed主机文件。

+   `--deepspeed_exclusion_filter` (`str`) — 在使用多节点设置时的DeepSpeed排除过滤器字符串。

+   `--deepspeed_inclusion_filter` (`str`) — 在使用多节点设置时的DeepSpeed包含过滤器字符串。

+   `--deepspeed_multinode_launcher` (`str`) — 要使用的DeepSpeed多节点启动器。

**Fully Sharded Data Parallelism 参数**：

以下参数仅在传递`use_fsdp`或通过`accelerate config`配置完全分片数据并行时有用：

+   `--fsdp_offload_params` (`str`) — 决定是否将参数和梯度卸载到CPU（true|false）。

+   `--fsdp_min_num_params` (`int`) — FSDP 的默认自动包装的最小参数数量。

+   `--fsdp_sharding_strategy` (`int`) — FSDP 的分片策略。

+   `--fsdp_auto_wrap_policy` (`str`) — FSDP 的自动包装策略。

+   `--fsdp_transformer_layer_cls_to_wrap` (`str`) — 要包装的Transformer层类名（区分大小写），例如，`BertLayer`，`GPTJBlock`，`T5Block` …

+   `--fsdp_backward_prefetch_policy` (`str`) — FSDP 的向后预取策略。

+   `--fsdp_state_dict_type` (`str`) — FSDP 的状态字典类型。

**Megatron-LM 参数**：

以下参数仅在传递`use_megatron_lm`或通过`accelerate config`配置Megatron-LM时有用：

+   `--megatron_lm_tp_degree` (“) — Megatron-LM 的张量并行（TP）度。

+   `--megatron_lm_pp_degree` (“) — Megatron-LM 的管道并行（PP）度。

+   `--megatron_lm_num_micro_batches` (“) — 当PP degree > 1时，Megatron-LM 的微批次数。

+   `--megatron_lm_sequence_parallelism` (“) — 决定在TP degree > 1时是否启用序列并行。

+   `--megatron_lm_recompute_activations` (“) — 决定是否启用选择性激活重计算。

+   `--megatron_lm_use_distributed_optimizer` (“) — 决定是否使用分布式优化器，将优化器状态和梯度分片到数据并行（DP）等级。

+   `--megatron_lm_gradient_clipping` (“) — 基于全局L2范数的Megatron-LM梯度裁剪值（0为禁用）。

**AWS SageMaker 参数**：

以下参数仅在SageMaker中训练时有用

+   `--aws_access_key_id AWS_ACCESS_KEY_ID` (`str`) — 用于启动Amazon SageMaker训练作业的AWS_ACCESS_KEY_ID

+   `--aws_secret_access_key AWS_SECRET_ACCESS_KEY` (`str`) — 用于启动Amazon SageMaker训练作业的AWS_SECRET_ACCESS_KEY

## accelerate estimate-memory

**命令**：

`accelerate estimate-memory` 或 `accelerate-estimate-memory` 或 `python -m accelerate.commands.estimate`

估计在Hub上托管的特定模型需要加载的总vRAM，以及用于训练的估计。需要安装`huggingface_hub`。

在进行推理时，通常将结果整体分配增加≤20% [参考此处](https://blog.eleuther.ai/transformer-math/)。我们将来会有更广泛的估计，将自动包含在计算中。

**用法**：

```py
accelerate estimate-memory {MODEL_NAME} --library_name {LIBRARY_NAME} --dtypes {dtype_1} {dtype_2} ...
```

**必需参数**：

+   `MODEL_NAME` (`str`)— Hugging Face Hub上的模型名称

**可选参数**：

+   `--library_name {timm,transformers}` (`str`) — 模型与之集成的库，例如 `transformers`，仅在Hub上未存储此信息时需要。

+   `--dtypes {float32,float16,int8,int4}` (`[{float32,float16,int8,int4} ...]`) — 用于模型的数据类型，必须是`float32`、`float16`、`int8`和`int4`中的一个（或多个）

+   `--trust_remote_code` (`bool`) — 是否允许在Hub上定义自定义模型的代码在其自己的建模文件中。此选项仅应传递给您信任的存储库，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。

## accelerate tpu-config

`accelerate tpu-config`

**用法**：

```py
accelerate tpu-config [arguments]
```

**可选参数**：

+   `-h`, `--help` (`bool`) — 显示帮助消息并退出

**配置参数**：

可以通过`accelerate config`配置的参数。

+   `--config_file` (`str`) — 用于accelerate的配置文件路径。

+   `--tpu_name` (`str`) — 要使用的TPU的名称。如果未指定，将使用配置文件中指定的TPU。

+   `--tpu_zone` (`str`) — 要使用的TPU的区域。如果未指定，将使用配置文件中指定的区域。

**TPU参数**：

在TPU内部运行的选项的参数。

+   `--command_file` (`str`) — 包含在启动时在pod上运行的命令的文件路径。

+   `--command` (`str`) — 在pod上运行的命令。可以多次传递。

+   `--install_accelerate` (`bool`) — 是否在pod上安装accelerate。默认为False。

+   `--accelerate_version` (`str`) — 安装在pod上的accelerate版本。如果未指定，将使用最新的pypi版本。指定‘dev’以从GitHub安装。

+   `--debug` (`bool`) — 如果设置，将打印将要运行的命令而不是运行它。

## accelerate test

`accelerate test`或`accelerate-test`

运行`accelerate/test_utils/test_script.py`来验证🤗 Accelerate是否已在您的系统上正确配置并运行。

**用法**：

```py
accelerate test [arguments]
```

**可选参数**：

+   `--config_file CONFIG_FILE` (`str`) — 用于存储配置文件的路径。默认为缓存位置中名为default_config.yaml的文件，该位置是环境变量`HF_HOME`的内容后缀为‘accelerate’，或者如果您没有这样的环境变量，则是您的缓存目录（`~/.cache`或`XDG_CACHE_HOME`的内容）后缀为`huggingface`。

+   `-h`, `--help` (`bool`) — 显示帮助消息并退出
