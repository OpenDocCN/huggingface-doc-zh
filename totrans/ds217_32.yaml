- en: Create an audio dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/datasets/audio_dataset](https://huggingface.co/docs/datasets/audio_dataset)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: 'You can share a dataset with your team or with anyone in the community by creating
    a dataset repository on the Hugging Face Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several methods for creating and sharing an audio dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an audio dataset from local files in python with [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub).
    This is an easy way that requires only a few steps in python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an audio dataset repository with the `AudioFolder` builder. This is a
    no-code solution for quickly creating an audio dataset with several thousand audio
    files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an audio dataset by writing a loading script. This method is for advanced
    users and requires more effort and coding, but you have greater flexibility over
    how a dataset is defined, downloaded, and generated which can be useful for more
    complex or large scale audio datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can control access to your dataset by requiring users to share their contact
    information first. Check out the [Gated datasets](https://huggingface.co/docs/hub/datasets-gated)
    guide for more information about how to enable this feature on the Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Local files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can load your own dataset using the paths to your audio files. Use the
    [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    function to take a column of audio file paths, and cast it to the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then upload the dataset to the Hugging Face Hub using [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a dataset repository containing your audio dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: AudioFolder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `AudioFolder` is a dataset builder designed to quickly load an audio dataset
    with several thousand audio files without requiring you to write any code. Any
    additional information about your dataset - such as transcription, speaker accent,
    or speaker intent - is automatically loaded by `AudioFolder` as long as you include
    this information in a metadata file (`metadata.csv`/`metadata.jsonl`).
  prefs: []
  type: TYPE_NORMAL
- en: ðŸ’¡ Take a look at the [Split pattern hierarchy](repository_structure#split-pattern-hierarchy)
    to learn more about how `AudioFolder` creates dataset splits based on your dataset
    repository structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a dataset repository on the Hugging Face Hub and upload your dataset
    directory following the `AudioFolder` structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `data` folder can be any name you want.
  prefs: []
  type: TYPE_NORMAL
- en: It can be helpful to store your metadata as a `jsonl` file if the data columns
    contain a more complex format (like a list of floats) to avoid parsing errors
    or reading complex values as strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The metadata file should include a `file_name` column to link an audio file
    to itâ€™s metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you can store your dataset in a directory structure like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Users can now load your dataset and the associated metadata by specifying `audiofolder`
    in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    and the dataset directory in `data_dir`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use `audiofolder` to load datasets involving multiple splits.
    To do so, your dataset directory might have the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note that if audio files are located not right next to a metadata file, `file_name`
    column should be a full relative path to an audio file, not just its filename.
  prefs: []
  type: TYPE_NORMAL
- en: 'For audio datasets that donâ€™t have any associated metadata, `AudioFolder` automatically
    infers the class labels of the dataset based on the directory name. It might be
    useful for audio classification tasks. Your dataset directory might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the dataset with `AudioFolder`, and it will create a `label` column from
    the directory name (language id):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: If all audio files are contained in a single directory or if they are not on
    the same level of directory structure, `label` column wonâ€™t be added automatically.
    If you need it, set `drop_labels=False` explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Some audio datasets, like those found in [Kaggle competitions](https://www.kaggle.com/competitions/kaggle-pog-series-s01e02/overview),
    have separate metadata files for each split. Provided the metadata features are
    the same for each split, `audiofolder` can be used to load all splits at once.
    If the metadata features differ across each split, you should load them with separate
    `load_dataset()` calls.
  prefs: []
  type: TYPE_NORMAL
- en: Loading script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Write a dataset loading script to manually create a dataset. It defines a datasetâ€™s
    splits and configurations, and handles downloading and generating the dataset
    examples. The script should have the same name as your dataset folder or repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `data` folder can be any name you want, it doesnâ€™t have to be `data`. This
    folder is optional, unless youâ€™re hosting your dataset on the Hub.
  prefs: []
  type: TYPE_NORMAL
- en: 'This directory structure allows your dataset to be loaded in one line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This guide will show you how to create a dataset loading script for audio datasets,
    which is a bit different from [creating a loading script for text datasets](./dataset_script).
    Audio datasets are commonly stored in `tar.gz` archives which requires a particular
    approach to support streaming mode. While streaming is not required, we highly
    encourage implementing streaming support in your audio dataset because users without
    a lot of disk space can use your dataset without downloading it. Learn more about
    streaming in the [Stream](./stream) guide!
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example using TAR archives:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to learning how to create a streamable dataset, youâ€™ll also learn
    how to:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a dataset builder class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create dataset configurations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add dataset metadata.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download and define the dataset splits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upload the dataset to the Hub.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best way to learn is to open up an existing audio dataset loading script,
    like [Vivos](https://huggingface.co/datasets/vivos/blob/main/vivos.py), and follow
    along!
  prefs: []
  type: TYPE_NORMAL
- en: This guide shows how to process audio data stored in TAR archives - the most
    frequent case for audio datasets. Check out [minds14](https://huggingface.co/datasets/PolyAI/minds14/blob/main/minds14.py)
    dataset for an example of an audio script which uses ZIP archives.
  prefs: []
  type: TYPE_NORMAL
- en: To help you get started, we created a loading script [template](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)
    you can copy and use as a starting point!
  prefs: []
  type: TYPE_NORMAL
- en: Create a dataset builder class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    is the base class for datasets generated from a dictionary generator. Within this
    class, there are three methods to help create your dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '`_info` stores information about your dataset like its description, license,
    and features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_split_generators` downloads the dataset and defines its splits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_generate_examples` generates the datasetâ€™s samples containing the audio data
    and other features specified in `info` for each split.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Start by creating your dataset class as a subclass of [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    and add the three methods. Donâ€™t worry about filling in each of these methods
    yet, youâ€™ll develop those over the next few sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Multiple configurations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In some cases, a dataset may have more than one configuration. For example,
    [LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia)
    dataset has several configurations corresponding to different languages.
  prefs: []
  type: TYPE_NORMAL
- en: To create different configurations, use the [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class to create a subclass of your dataset. The only required parameter is the
    `name` of the configuration, which must be passed to the configurationâ€™s superclass
    `__init__()`. Otherwise, you can specify any custom parameters you want in your
    configuration class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Define your configurations in the `BUILDER_CONFIGS` class variable inside [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder).
    In this example, the author imports the languages from a separate `release_stats.py`
    [file](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/release_stats.py)
    from their repository, and then loops through each language to create a configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Typically, users need to specify a configuration to load in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    otherwise a `ValueError` is raised. You can avoid this by setting a default dataset
    configuration to load in `DEFAULT_CONFIG_NAME`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now if users want to load the Balinese (`bal`) configuration, they can use
    the configuration name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Add dataset metadata
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Adding information about your dataset helps users to learn more about it. This
    information is stored in the [DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo)
    class which is returned by the `info` method. Users can access this information
    by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a lot of information you can include about your dataset, but some
    important ones are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`description` provides a concise description of the dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`features` specify the dataset column types. Since youâ€™re creating an audio
    loading script, youâ€™ll need to include the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature and the `sampling_rate` of the dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`homepage` provides a link to the dataset homepage.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`license` specify the permissions for using a dataset as defined by the license
    type.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`citation` is a BibTeX citation of the dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Youâ€™ll notice a lot of the dataset information is defined earlier in the loading
    script which can make it easier to read. There are also other `~Dataset.Features`
    you can input, so be sure to check out the full list and [features guide](./about_dataset_features)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Download and define the dataset splits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that youâ€™ve added some information about your dataset, the next step is
    to download the dataset and define the splits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    method to download metadata file at `_PROMPTS_URLS` and audio TAR archive at `_DATA_URL`.
    This method returns the path to the local file/archive. In streaming mode, it
    doesnâ€™t download the file(s) and just returns a URL to stream the data from. This
    method accepts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a relative path to a file inside a Hub dataset repository (for example, in the
    `data/` folder)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a URL to a file hosted somewhere else
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a (nested) list or dictionary of file names or URLs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After youâ€™ve downloaded the dataset, use the [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    to organize the audio files and sentence prompts in each split. Name each split
    with a standard name like: `Split.TRAIN`, `Split.TEST`, and `SPLIT.Validation`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `gen_kwargs` parameter, specify the file path to the `prompts_path` and
    `path_to_clips`. For `audio_files`, youâ€™ll need to use [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    to iterate over the audio files in the TAR archive. This enables streaming for
    your dataset. All of these file paths are passed onto the next step where youâ€™ll
    actually generate the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This implementation does not extract downloaded archives. If you want to extract
    files after download, you need to additionally use [extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract),
    see the [(Advanced) Extract TAR archives](#advanced-extract-tar-archives-locally)
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Generate the dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last method in the [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    class actually generates the samples in the dataset. It yields a dataset according
    to the structure specified in `features` from the `info` method. As you can see,
    `generate_examples` accepts the `prompts_path`, `path_to_clips`, and `audio_files`
    from the previous method as arguments.
  prefs: []
  type: TYPE_NORMAL
- en: Files inside TAR archives are accessed and yielded sequentially. This means
    you need to have the metadata associated with the audio files in the TAR file
    in hand first so you can yield it with its corresponding audio file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Finally, iterate over files in `audio_files` and yield them along with their
    corresponding metadata. [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    yields a tuple of (`path`, `f`) where `path` is a **relative** path to a file
    inside TAR archive and `f` is a file object itself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Put these two steps together, and the whole `_generate_examples` method looks
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Upload the dataset to the Hub
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once your script is ready, [create a dataset card](./dataset_card) and [upload
    it to the Hub](./share).
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations, you can now load your dataset from the Hub! ðŸ¥³
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: (Advanced) Extract TAR archives locally
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the example above downloaded archives are not extracted and therefore examples
    do not contain information about where they are stored locally. To explain how
    to do the extraction in a way that it also supports streaming, we will briefly
    go through the [LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/librivox-indonesia.py)
    loading script.
  prefs: []
  type: TYPE_NORMAL
- en: Download and define the dataset splits
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Use the [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    method to download the audio data at `_AUDIO_URL`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To extract audio TAR archive locally, use the [extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract).
    You can use this method only in non-streaming mode (when `dl_manager.is_streaming=False`).
    This returns a local path to the extracted archive directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use the [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    method to iterate over the archive at `audio_path`, just like in the Vivos example
    above. [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    doesnâ€™t provide any information about the full paths of files from the archive,
    even if it has been extracted. As a result, you need to pass the `local_extracted_archive`
    path to the next step in `gen_kwargs`, in order to preserve information about
    where the archive was extracted to. This is required to construct the correct
    paths to the local files when you generate the examples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The reason you need to use a combination of [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    and [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    is because files in TAR archives canâ€™t be accessed directly by their paths. Instead,
    youâ€™ll need to iterate over the files within the archive! You can use [download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    and [extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)
    with TAR archives only in non-streaming mode, otherwise it would throw an error.
  prefs: []
  type: TYPE_NORMAL
- en: Use the [download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    method to download the metadata file specified in `_METADATA_URL`. This method
    returns a path to a local file in non-streaming mode. In streaming mode, it doesnâ€™t
    download file locally and returns the same URL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now use the [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    to organize the audio files and metadata in each split. Name each split with a
    standard name like: `Split.TRAIN`, `Split.TEST`, and `SPLIT.Validation`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `gen_kwargs` parameter, specify the file paths to `local_extracted_archive`,
    `audio_files`, `metadata_path`, and `path_to_clips`. Remember, for `audio_files`,
    you need to use [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    to iterate over the audio files in the TAR archives. This enables streaming for
    your dataset! All of these file paths are passed onto the next step where the
    dataset samples are generated.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Generate the dataset
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Here `_generate_examples` accepts `local_extracted_archive`, `audio_files`,
    `metadata_path`, and `path_to_clips` from the previous method as arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'TAR files are accessed and yielded sequentially. This means you need to have
    the metadata in `metadata_path` associated with the audio files in the TAR file
    in hand first so that you can yield it with its corresponding audio file further:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now you can yield the files in `audio_files` archive. When you use [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive),
    it yielded a tuple of (`path`, `f`) where `path` is a **relative path** to a file
    inside the archive, and `f` is the file object itself. To get the **full path**
    to the locally extracted file, join the path of the directory (`local_extracted_path`)
    where the archive is extracted to and the relative audio file path (`path`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Put both of these steps together, and the whole `_generate_examples` method
    should look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
