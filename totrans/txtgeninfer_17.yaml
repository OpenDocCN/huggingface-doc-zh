- en: Tensor Parallelism
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¼ é‡å¹¶è¡Œ
- en: 'Original text: [https://huggingface.co/docs/text-generation-inference/conceptual/tensor_parallelism](https://huggingface.co/docs/text-generation-inference/conceptual/tensor_parallelism)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'åŸæ–‡é“¾æ¥: [https://huggingface.co/docs/text-generation-inference/conceptual/tensor_parallelism](https://huggingface.co/docs/text-generation-inference/conceptual/tensor_parallelism)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Tensor parallelism is a technique used to fit a large model in multiple GPUs.
    For example, when multiplying the input tensors with the first weight tensor,
    the matrix multiplication is equivalent to splitting the weight tensor column-wise,
    multiplying each column with the input separately, and then concatenating the
    separate outputs. These outputs are then transferred from the GPUs and concatenated
    together to get the final result, like below ğŸ‘‡
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ é‡å¹¶è¡Œæ˜¯ä¸€ç§æŠ€æœ¯ï¼Œç”¨äºåœ¨å¤šä¸ªGPUä¸­é€‚é…å¤§å‹æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œå½“å°†è¾“å…¥å¼ é‡ä¸ç¬¬ä¸€ä¸ªæƒé‡å¼ é‡ç›¸ä¹˜æ—¶ï¼ŒçŸ©é˜µä¹˜æ³•ç­‰åŒäºæŒ‰åˆ—æ‹†åˆ†æƒé‡å¼ é‡ï¼Œåˆ†åˆ«å°†æ¯åˆ—ä¸è¾“å…¥ç›¸ä¹˜ï¼Œç„¶åå°†å•ç‹¬çš„è¾“å‡ºè¿æ¥èµ·æ¥ã€‚è¿™äº›è¾“å‡ºç„¶åä»GPUä¼ è¾“å¹¶è¿æ¥åœ¨ä¸€èµ·ä»¥è·å¾—æœ€ç»ˆç»“æœï¼Œå¦‚ä¸‹æ‰€ç¤ºğŸ‘‡
- en: '![Image courtesy of Anton Lozkhov](../Images/2434150b9bb14baed7418fdaf716c588.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡ç”±Anton Lozkhovæä¾›](../Images/2434150b9bb14baed7418fdaf716c588.png)'
- en: Tensor Parallelism only works for [models officially supported](../supported_models),
    it will not work when falling back to `transformers`. You can get more information
    about unsupported models [here](../basic_tutorials/non_core_models).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ é‡å¹¶è¡Œä»…é€‚ç”¨äº[å®˜æ–¹æ”¯æŒçš„æ¨¡å‹](../supported_models)ï¼Œå½“å›é€€åˆ°`transformers`æ—¶å°†æ— æ³•ä½¿ç”¨ã€‚æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](../basic_tutorials/non_core_models)è·å–æœ‰å…³ä¸å—æ”¯æŒæ¨¡å‹çš„æ›´å¤šä¿¡æ¯ã€‚
- en: You can learn a lot more details about tensor-parallelism from [the `transformers`
    docs](https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä»[transformersæ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism)ä¸­äº†è§£æ›´å¤šæœ‰å…³å¼ é‡å¹¶è¡Œçš„è¯¦ç»†ä¿¡æ¯ã€‚
