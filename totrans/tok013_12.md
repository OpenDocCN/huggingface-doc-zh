# 编码

> 原始文本：[https://huggingface.co/docs/tokenizers/api/encoding](https://huggingface.co/docs/tokenizers/api/encoding)

PythonRustNode

## 编码

### `class tokenizers.Encoding`

```py
( )
```

[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)代表[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)的输出。

属性注意掩码

返回

`List[int]`

注意掩码

注意掩码

这告诉LM应该关注哪些令牌，哪些不应该。这在批处理序列时尤为重要，我们需要应用填充。

属性ID

返回

`List[int]`

ID列表

生成的ID

ID是语言模型的主要输入。它们是LM理解的令牌索引，数字表示。

属性n_sequences

返回

`int`

这个[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)中的序列数量

所代表的序列数量

属性偏移

返回

一个`Tuple[int, int]`的`List`

偏移列表

与每个令牌相关联的偏移量

这些偏移量让您切片输入字符串，从而检索导致生成相应令牌的原始部分。

属性溢出

一个溢出的[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)的`List`

在使用截断时，[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)负责将输出拆分为所需的片段，以匹配指定的最大长度。此字段允许您检索所有后续片段。

当您使用序列对时，溢出的片段将包含足够的变化，以涵盖所有可能的组合，同时尊重提供的最大长度。

属性序列ID

返回

一个`Optional[int]`的`List`

一个可选序列索引列表。

生成的序列索引。

它们代表与每个令牌相关联的输入序列的索引。如果令牌与任何输入序列无关，例如特殊令牌，则序列ID可以为None。

属性特殊令牌掩码

返回

`List[int]`

特殊令牌掩码

特殊令牌掩码

这指示哪些令牌是特殊令牌，哪些不是。

属性令牌

返回

`List[str]`

令牌列表

生成的令牌

它们是ID的字符串表示。

属性类型ID

返回

`List[int]`

类型ID列表

生成的类型ID

通常用于序列分类或问题回答等任务，这些令牌让LM知道每个令牌对应的输入序列。

属性单词ID

返回

一个`Optional[int]`的`List`

一个可选单词索引列表。

生成的单词索引。

它们代表与每个令牌相关联的单词的索引。当输入被预分词时，它们对应于给定输入标签的ID，否则它们对应于由使用的[PreTokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/pre-tokenizers#tokenizers.pre_tokenizers.PreTokenizer)定义的单词索引。

对于特殊令牌等（从未输入的内容生成的任何令牌），输出为`None`

属性单词

返回

一个`Optional[int]`的`List`

一个可选单词索引列表。

生成的单词索引。

这已被弃用，将在将来的版本中删除。请改用`~tokenizers.Encoding.word_ids`。

它们代表与每个令牌相关联的单词的索引。当输入被预分词时，它们对应于给定输入标签的ID，否则它们对应于由使用的[PreTokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/pre-tokenizers#tokenizers.pre_tokenizers.PreTokenizer)定义的单词索引。

对于特殊令牌等（从未输入的内容生成的任何令牌），输出为`None`

#### `char_to_token`

```py
( char_pos sequence_index = 0 ) → int
```

参数

+   `char_pos` (`int`) — 输入字符串中字符的位置

+   `sequence_index` (`int`, 默认为 `0`) — 包含目标字符的序列的索引

返回

`int`

包含此字符的编码序列中的标记的索引

获取包含输入序列中给定位置的字符的标记。

#### `char_to_word`

```py
( char_pos sequence_index = 0 ) → int
```

参数

+   `char_pos` (`int`) — 输入字符串中字符的位置

+   `sequence_index` (`int`, 默认为 `0`) — 包含目标字符的序列的索引

返回

`int`

包含此字符的单词在输入序列中的索引

获取包含输入序列中给定位置的字符的单词。

#### `合并`

```py
( encodings growing_offsets = True ) → Encoding
```

参数

+   `encodings`（一个[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)的`List`） — 应合并为一个的编码列表

+   `growing_offsets` (`bool`, 默认为 `True`) — 合并时是否应累积偏移量

返回

[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)

生成的Encoding

将编码列表合并为最终的[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)

#### `填充`

```py
( length direction = 'right' pad_id = 0 pad_type_id = 0 pad_token = '[PAD]' )
```

参数

+   `length` (`int`) — 所需长度

    方向 — (`str`, 默认为 `right`): 期望的填充方向。可以是`right`或`left`

+   `pad_id` (`int`, 默认为 `0`) — 与填充标记对应的ID

+   `pad_type_id` (`int`, 默认为 `0`) — 与填充标记对应的类型ID

+   `pad_token` (`str`, 默认为 *[PAD]*) — 要使用的填充标记

在给定长度处填充[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)

#### `set_sequence_id`

```py
( sequence_id )
```

设置给定的序列索引

为此[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)中包含的所有标记的整个范围设置给定的序列索引。

#### `token_to_chars`

```py
( token_index ) → Tuple[int, int]
```

参数

+   `token_index` (`int`) — 编码序列中标记的索引。

返回

`Tuple[int, int]`

标记偏移量`(first, last + 1)`

获取给定索引处标记的偏移量。

返回的偏移量与包含该标记的输入序列相关。为了确定它属于哪个输入序列，您必须调用`~tokenizers.Encoding.token_to_sequence()`。

#### `token_to_sequence`

```py
( token_index ) → int
```

参数

+   `token_index` (`int`) — 编码序列中标记的索引。

返回

`int`

给定标记的序列ID

获取由给定标记表示的序列的索引。

在一般用例中，此方法对于单个序列或一对序列的第一个序列返回`0`，对于一对序列的第二个序列返回`1`

#### `token_to_word`

```py
( token_index ) → int
```

参数

+   `token_index` (`int`) — 编码序列中标记的索引。

返回

`int`

相关输入序列中单词的索引。

获取包含一个输入序列中标记的单词的索引。

返回的单词索引与包含该标记的输入序列相关。为了确定它属于哪个输入序列，您必须调用`~tokenizers.Encoding.token_to_sequence()`。

#### `截断`

```py
( max_length stride = 0 direction = 'right' )
```

参数

+   `max_length` (`int`) — 所需长度

+   `stride` (`int`, 默认为 `0`) — 要包含在每个溢出片段中的先前内容的长度

+   `direction` (`str`, 默认为 `right`) — 截断方向

在给定长度处截断[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)

如果此[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)表示多个序列，在截断时将丢失此信息。它将被视为表示单个序列。

#### `word_to_chars`

```py
( word_index sequence_index = 0 ) → Tuple[int, int]
```

参数

+   `word_index` (`int`) — 输入序列中的一个单词的索引。

+   `sequence_index` (`int`, 默认为 `0`) — 包含目标单词的序列的索引

返回

`Tuple[int, int]`

字符范围（跨度）`(first, last + 1)`

获取输入序列中给定索引处的单词的偏移量。

#### `word_to_tokens`

```py
( word_index sequence_index = 0 ) → Tuple[int, int]
```

参数

+   `word_index` (`int`) — 输入序列中单词的索引。

+   `sequence_index` (`int`，默认为`0`) — 包含目标单词的序列的索引

返回值

`Tuple[int, int]`

标记的范围：`(第一个，最后一个 + 1)`

获取与输入序列中给定索引处的单词对应的编码标记。
