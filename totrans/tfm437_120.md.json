["```py\nfrom transformers import BertTokenizer, BertForSequenceClassification\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n\ninputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\nlabels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\noutputs = model(**inputs, labels=labels)\n```", "```py\noutputs[:2]\n```", "```py\n( *args **kwargs )\n```", "```py\n( )\n```", "```py\n( last_hidden_state: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None pooler_output: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None pooler_output: FloatTensor = None hidden_states: Optional = None past_key_values: Optional = None attentions: Optional = None cross_attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None start_logits: FloatTensor = None end_logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None start_logits: FloatTensor = None end_logits: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( loss: Optional = None spectrogram: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None hidden_states: Optional = None )\n```", "```py\n( loss: Optional = None predicted_depth: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None extract_features: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( loss: Optional = None logits: FloatTensor = None embeddings: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( last_hidden_state: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None loc: Optional = None scale: Optional = None static_features: Optional = None )\n```", "```py\n( loss: Optional = None params: Optional = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None loc: Optional = None scale: Optional = None static_features: Optional = None )\n```", "```py\n( sequences: FloatTensor = None )\n```", "```py\n( last_hidden_state: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( last_hidden_state: tf.Tensor = None pooler_output: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( last_hidden_state: tf.Tensor = None pooler_output: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( last_hidden_state: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( last_hidden_state: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( last_hidden_state: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None cross_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None start_logits: tf.Tensor = None end_logits: tf.Tensor = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( loss: tf.Tensor | None = None start_logits: tf.Tensor = None end_logits: tf.Tensor = None past_key_values: List[tf.Tensor] | None = None decoder_hidden_states: Tuple[tf.Tensor] | None = None decoder_attentions: Tuple[tf.Tensor] | None = None encoder_last_hidden_state: tf.Tensor | None = None encoder_hidden_states: Tuple[tf.Tensor] | None = None encoder_attentions: Tuple[tf.Tensor] | None = None )\n```", "```py\n( last_hidden_state: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( last_hidden_state: Array = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( last_hidden_state: Array = None pooler_output: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( last_hidden_state: Array = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( last_hidden_state: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None past_key_values: Optional = None hidden_states: Optional = None attentions: Optional = None cross_attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( logits: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( start_logits: Array = None end_logits: Array = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( **updates )\n```", "```py\n( start_logits: Array = None end_logits: Array = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )\n```", "```py\n( **updates )\n```"]