- en: Torch API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/safetensors/api/torch](https://huggingface.co/docs/safetensors/api/torch)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '<link href="/docs/safetensors/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/entry/start.1dff7fe5.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/scheduler.9f522b10.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/singletons.c609a45a.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/index.eb046c14.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/paths.077e46fe.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/entry/app.93ba10f9.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/index.4a68349c.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/nodes/0.b1eccf7f.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/nodes/6.d5db588e.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/ExampleCodeBlock.92e1ba8b.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/Heading.5311d788.js">
    <link rel="modulepreload" href="/docs/safetensors/main/en/_app/immutable/chunks/CodeBlock.f4f47d4b.js">
    #### `safetensors.torch.load_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/safetensors/blob/main/bindings/python/py_src/safetensors/torch.py#L284)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`filename` (`str`, or `os.PathLike`) — The name of the file which contains
    the tensors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`Dict[str, any]`, *optional*, defaults to `cpu`) — The device where
    the tensors need to be located after load. available options are all regular torch
    device locations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, torch.Tensor]`'
  prefs: []
  type: TYPE_NORMAL
- en: dictionary that contains name as key, value as `torch.Tensor`
  prefs: []
  type: TYPE_NORMAL
- en: Loads a safetensors file into torch format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#### `safetensors.torch.load`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/safetensors/blob/main/bindings/python/py_src/safetensors/torch.py#L314)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`data` (`bytes`) — The content of a safetensors file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, torch.Tensor]`'
  prefs: []
  type: TYPE_NORMAL
- en: dictionary that contains name as key, value as `torch.Tensor` on cpu
  prefs: []
  type: TYPE_NORMAL
- en: Loads a safetensors file into torch format from pure bytes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#### `safetensors.torch.save_file`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/safetensors/blob/main/bindings/python/py_src/safetensors/torch.py#L250)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`tensors` (`Dict[str, torch.Tensor]`) — The incoming tensors. Tensors need
    to be contiguous and dense.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filename` (`str`, or `os.PathLike`)) — The filename we’re saving into.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metadata` (`Dict[str, str]`, *optional*, defaults to `None`) — Optional text
    only metadata you might want to save in your header. For instance it can be useful
    to specify more about the underlying tensors. This is purely informative and does
    not affect tensor loading.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`None`'
  prefs: []
  type: TYPE_NORMAL
- en: Saves a dictionary of tensors into raw bytes in safetensors format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '#### `safetensors.torch.save`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/safetensors/blob/main/bindings/python/py_src/safetensors/torch.py#L220)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`tensors` (`Dict[str, torch.Tensor]`) — The incoming tensors. Tensors need
    to be contiguous and dense.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metadata` (`Dict[str, str]`, *optional*, defaults to `None`) — Optional text
    only metadata you might want to save in your header. For instance it can be useful
    to specify more about the underlying tensors. This is purely informative and does
    not affect tensor loading.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`bytes`'
  prefs: []
  type: TYPE_NORMAL
- en: The raw bytes representing the format
  prefs: []
  type: TYPE_NORMAL
- en: Saves a dictionary of tensors into raw bytes in safetensors format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#### `safetensors.torch.load_model`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/safetensors/blob/main/bindings/python/py_src/safetensors/torch.py#L176)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`model` (`torch.nn.Module`) — The model to load onto.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filename` (`str`, or `os.PathLike`) — The filename location to load the file
    from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strict` (`bool`, *optional*, defaults to True) — Wether to fail if you’re
    missing keys or having unexpected ones When false, the function simply returns
    missing and unexpected names.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`(missing, unexpected)'
  prefs: []
  type: TYPE_NORMAL
- en: (List[str], List[str])missing`are names in the model which were not modified
    during loading`unexpected` are names that are on the file, but weren’t used during
    the load.
  prefs: []
  type: TYPE_NORMAL
- en: Loads a given filename onto a torch model. This method exists specifically to
    avoid tensor sharing issues which are not allowed in `safetensors`. [More information
    on tensor sharing](../torch_shared_tensors)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `safetensors.torch.save_model`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/safetensors/blob/main/bindings/python/py_src/safetensors/torch.py#L130)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`model` (`torch.nn.Module`) — The model to save on disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filename` (`str`) — The filename location to save the file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metadata` (`Dict[str, str]`, *optional*) — Extra information to save along
    with the file. Some metadata will be added for each dropped tensors. This information
    will not be enough to recover the entire shared structure but might help understanding
    things'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_contiguous` (`boolean`, *optional*, defaults to True) — Forcing the
    state_dict to be saved as contiguous tensors. This has no effect on the correctness
    of the model, but it could potentially change performance if the layout of the
    tensor was chosen specifically for that reason.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saves a given torch model to specified filename. This method exists specifically
    to avoid tensor sharing issues which are not allowed in `safetensors`. [More information
    on tensor sharing](../torch_shared_tensors)
  prefs: []
  type: TYPE_NORMAL
