- en: Installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/optimum-neuron/installation](https://huggingface.co/docs/optimum-neuron/installation)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Our recommendation is to use the [Hugging Face Neuron Deep Learning AMI](https://aws.amazon.com/marketplace/pp/prodview-gr3e6yiscria2)
    (DLAMI). The DLAMI comes with all required libraries pre-packaged for you, including
    the Optimum Neuron, Neuron Drivers, Transformers, Datasets, and Accelerate.
  prefs: []
  type: TYPE_NORMAL
- en: But it can also be installed using `pip` as described below.
  prefs: []
  type: TYPE_NORMAL
- en: Before installing `optimum-neuron` make sure that you have installed the Neuron
    driver and tools, check out [more detailed guide here](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/setup/torch-neuronx.html#setup-torch-neuronx).
  prefs: []
  type: TYPE_NORMAL
- en: Adding pip packages URL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Pointing to the AWS Neuron repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Installing optimum-neuron for AWS Trainium ( trn1 ) or AWS inferentia2 ( inf2
    )
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Installing optimum-neuron for AWS inferentia ( inf1 )
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
