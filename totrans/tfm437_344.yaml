- en: Donut
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Donut
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/donut](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/donut)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/donut](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/donut)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The Donut model was proposed in [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664)
    by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong
    Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park. Donut consists
    of an image Transformer encoder and an autoregressive text Transformer decoder
    to perform document understanding tasks such as document image classification,
    form understanding and visual question answering.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Donut模型是由Geewook Kim、Teakgyu Hong、Moonbin Yim、Jeongyeon Nam、Jinyoung Park、Jinyeong
    Yim、Wonseok Hwang、Sangdoo Yun、Dongyoon Han、Seunghyun Park提出的，用于执行文档理解任务，如文档图像分类、表单理解和视觉问答的图像变压器编码器和自回归文本变压器解码器。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要如下：
- en: '*Understanding document images (e.g., invoices) is a core but challenging task
    since it requires complex functions such as reading text and a holistic understanding
    of the document. Current Visual Document Understanding (VDU) methods outsource
    the task of reading text to off-the-shelf Optical Character Recognition (OCR)
    engines and focus on the understanding task with the OCR outputs. Although such
    OCR-based approaches have shown promising performance, they suffer from 1) high
    computational costs for using OCR; 2) inflexibility of OCR models on languages
    or types of document; 3) OCR error propagation to the subsequent process. To address
    these issues, in this paper, we introduce a novel OCR-free VDU model named Donut,
    which stands for Document understanding transformer. As the first step in OCR-free
    VDU research, we propose a simple architecture (i.e., Transformer) with a pre-training
    objective (i.e., cross-entropy loss). Donut is conceptually simple yet effective.
    Through extensive experiments and analyses, we show a simple OCR-free VDU model,
    Donut, achieves state-of-the-art performances on various VDU tasks in terms of
    both speed and accuracy. In addition, we offer a synthetic data generator that
    helps the model pre-training to be flexible in various languages and domains.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*理解文档图像（例如发票）是一项核心但具有挑战性的任务，因为它需要复杂的功能，如阅读文本和对文档的整体理解。当前的视觉文档理解（VDU）方法将阅读文本的任务外包给现成的光学字符识别（OCR）引擎，并专注于使用OCR输出进行理解任务。尽管这种基于OCR的方法表现出有希望的性能，但它们存在以下问题：1）使用OCR的计算成本高；2）OCR模型在语言或文档类型上的不灵活性；3）OCR错误传播到后续过程。为了解决这些问题，在本文中，我们介绍了一种名为Donut的新型无OCR
    VDU模型，代表文档理解变压器。作为无OCR VDU研究的第一步，我们提出了一个简单的架构（即变压器）和一个预训练目标（即交叉熵损失）。Donut在概念上简单而有效。通过大量实验和分析，我们展示了一个简单的无OCR
    VDU模型Donut，在速度和准确性方面在各种VDU任务上取得了最先进的性能。此外，我们提供了一个合成数据生成器，帮助模型在各种语言和领域中进行灵活的预训练。*'
- en: '![drawing](../Images/c398a3ad84a6b0278997297beeddba0b.png) Donut high-level
    overview. Taken from the [original paper](https://arxiv.org/abs/2111.15664).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/c398a3ad84a6b0278997297beeddba0b.png) Donut高层概述。摘自[原始论文](https://arxiv.org/abs/2111.15664)。'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/clovaai/donut).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[nielsr](https://huggingface.co/nielsr)贡献。原始代码可在[此处](https://github.com/clovaai/donut)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: The quickest way to get started with Donut is by checking the [tutorial notebooks](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Donut),
    which show how to use the model at inference time as well as fine-tuning on custom
    data.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用Donut的最快方法是查看[教程笔记本](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Donut)，展示了如何在推理时使用模型以及在自定义数据上进行微调。
- en: Donut is always used within the [VisionEncoderDecoder](vision-encoder-decoder)
    framework.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Donut始终在[VisionEncoderDecoder](vision-encoder-decoder)框架内使用。
- en: Inference examples
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理示例
- en: Donut’s `VisionEncoderDecoder` model accepts images as input and makes use of
    [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    to autoregressively generate text given the input image.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Donut的`VisionEncoderDecoder`模型接受图像作为输入，并利用[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)来自动生成给定输入图像的文本。
- en: The [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)
    class is responsible for preprocessing the input image and [`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]
    decodes the generated target tokens to the target string. The [DonutProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutProcessor)
    wraps [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)
    and [`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`] into a single instance to
    both extract the input features and decode the predicted token ids.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)类负责预处理输入图像，[`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]解码生成的目标标记为目标字符串。[DonutProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutProcessor)将[DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)和[`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]包装成一个单一实例，既提取输入特征又解码预测的标记ID。'
- en: Step-by-step Document Image Classification
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步文档图像分类
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Step-by-step Document Parsing
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步文档解析
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Step-by-step Document Visual Question Answering (DocVQA)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步文档视觉问答（DocVQA）
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: See the [model hub](https://huggingface.co/models?filter=donut) to look for
    Donut checkpoints.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[model hub](https://huggingface.co/models?filter=donut)以查找Donut检查点。
- en: Training
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: We refer to the [tutorial notebooks](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Donut).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '请参阅[教程笔记本](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Donut)。 '
- en: DonutSwinConfig
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DonutSwinConfig
- en: '### `class transformers.DonutSwinConfig`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DonutSwinConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/configuration_donut_swin.py#L29)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/configuration_donut_swin.py#L29)'
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_size` (`int`, *optional*, defaults to 224) — The size (resolution) of
    each image.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *optional*, defaults to 224) — 每个图像的大小（分辨率）。'
- en: '`patch_size` (`int`, *optional*, defaults to 4) — The size (resolution) of
    each patch.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *optional*, defaults to 4) — 每个补丁的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, defaults to 3) — 输入通道数。'
- en: '`embed_dim` (`int`, *optional*, defaults to 96) — Dimensionality of patch embedding.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embed_dim` (`int`, *optional*, defaults to 96) — 补丁嵌入的维度。'
- en: '`depths` (`list(int)`, *optional*, defaults to `[2, 2, 6, 2]`) — Depth of each
    layer in the Transformer encoder.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depths` (`list(int)`, *optional*, defaults to `[2, 2, 6, 2]`) — Transformer编码器中每层的深度。'
- en: '`num_heads` (`list(int)`, *optional*, defaults to `[3, 6, 12, 24]`) — Number
    of attention heads in each layer of the Transformer encoder.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`list(int)`, *optional*, defaults to `[3, 6, 12, 24]`) — Transformer编码器每层的注意力头数。'
- en: '`window_size` (`int`, *optional*, defaults to 7) — Size of windows.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`window_size` (`int`, *optional*, defaults to 7) — 窗口大小。'
- en: '`mlp_ratio` (`float`, *optional*, defaults to 4.0) — Ratio of MLP hidden dimensionality
    to embedding dimensionality.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlp_ratio` (`float`, *optional*, defaults to 4.0) — MLP隐藏维度与嵌入维度的比率。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether or not a learnable
    bias should be added to the queries, keys and values.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — 是否为查询、键和值添加可学习的偏置。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — The dropout
    probability for all fully connected layers in the embeddings and encoder.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — 嵌入层和编码器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — The
    dropout ratio for the attention probabilities.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — 注意力概率的dropout比率。'
- en: '`drop_path_rate` (`float`, *optional*, defaults to 0.1) — Stochastic depth
    rate.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop_path_rate` (`float`, *optional*, defaults to 0.1) — 随机深度率。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder. If string,
    `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`use_absolute_embeddings` (`bool`, *optional*, defaults to `False`) — Whether
    or not to add absolute position embeddings to the patch embeddings.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_absolute_embeddings` (`bool`, *optional*, defaults to `False`) — 是否将绝对位置嵌入添加到补丁嵌入中。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — 层归一化层使用的epsilon。'
- en: This is the configuration class to store the configuration of a [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel).
    It is used to instantiate a Donut model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Donut [naver-clova-ix/donut-base](https://huggingface.co/naver-clova-ix/donut-base)
    architecture.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)配置的配置类。根据指定的参数实例化一个Donut模型，定义模型架构。使用默认值实例化配置将产生类似于Donut
    [naver-clova-ix/donut-base](https://huggingface.co/naver-clova-ix/donut-base)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: DonutImageProcessor
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DonutImageProcessor
- en: '### `class transformers.DonutImageProcessor`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DonutImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/image_processing_donut.py#L52)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/image_processing_donut.py#L52)'
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions to the specified `size`. Can be overridden
    by `do_resize` in the `preprocess` method.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, defaults to `True`) — 是否将图像的（高度，宽度）尺寸调整为指定的`size`。可以被`preprocess`方法中的`do_resize`覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"shortest_edge" -- 224}`):
    Size of the image after resizing. The shortest edge of the image is resized to
    size[“shortest_edge”], with the longest edge resized to keep the input aspect
    ratio. Can be overridden by `size` in the `preprocess` method.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *optional*, defaults to `{"shortest_edge" -- 224}`):
    调整大小后的图像尺寸。图像的最短边被调整为size[“shortest_edge”]，最长边被调整以保持输入的长宽比。可以被`preprocess`方法中的`size`覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`)
    — Resampling filter to use if resizing the image. Can be overridden by `resample`
    in the `preprocess` method.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`)
    — 如果调整图像大小，要使用的重采样滤波器。可以被`preprocess`方法中的`resample`覆盖。'
- en: '`do_thumbnail` (`bool`, *optional*, defaults to `True`) — Whether to resize
    the image using thumbnail method.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_thumbnail` (`bool`, *optional*, defaults to `True`) — 是否使用缩略图方法调整图像大小。'
- en: '`do_align_long_axis` (`bool`, *optional*, defaults to `False`) — Whether to
    align the long axis of the image with the long axis of `size` by rotating by 90
    degrees.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) — Whether to pad the image.
    If `random_padding` is set to `True` in `preprocess`, each image is padded with
    a random amont of padding on each size, up to the largest image size in the batch.
    Otherwise, all images are padded to the largest image size in the batch.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by `do_rescale`
    in the `preprocess` method.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overridden by `rescale_factor` in
    the `preprocess` method.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by `do_normalize` in the `preprocess` method.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    — Image standard deviation.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constructs a Donut image processor.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '#### `preprocess`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/image_processing_donut.py#L297)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Size of the
    image after resizing. Shortest edge of the image is resized to min(size[“height”],
    size[“width”]) with the longest edge resized to keep the input aspect ratio.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resample` (`int`, *optional*, defaults to `self.resample`) — Resampling filter
    to use if resizing the image. This can be one of the enum `PILImageResampling`.
    Only has an effect if `do_resize` is set to `True`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_thumbnail` (`bool`, *optional*, defaults to `self.do_thumbnail`) — Whether
    to resize the image using thumbnail method.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_align_long_axis` (`bool`, *optional*, defaults to `self.do_align_long_axis`)
    — Whether to align the long axis of the image with the long axis of `size` by
    rotating by 90 degrees.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_pad` (`bool`, *optional*, defaults to `self.do_pad`) — Whether to pad the
    image. If `random_padding` is set to `True`, each image is padded with a random
    amont of padding on each size, up to the largest image size in the batch. Otherwise,
    all images are padded to the largest image size in the batch.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_padding` (`bool`, *optional*, defaults to `self.random_padding`) —
    Whether to use random padding when padding the image. If `True`, each image in
    the batch with be padded with a random amount of padding on each side up to the
    size of the largest image in the batch.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image pixel values.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    Rescale factor to rescale the image by if `do_rescale` is set to `True`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    — Image mean to use for normalization.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    — Image standard deviation to use for normalization.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW`或`''tf''`：返回类型为`tf.Tensor`的批处理。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH`或`''pt''`：返回类型为`torch.Tensor`的批处理。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY`或`''np''`：返回类型为`np.ndarray`的批处理。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX`或`''jax''`：返回类型为`jax.numpy.ndarray`的批处理。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`（`ChannelDimension`或`str`，*可选*，默认为`ChannelDimension.FIRST`）— 输出图片的通道维度格式。可以是以下之一：'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`：图片格式为（通道数，高度，宽度）。'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`：图片格式为（高度，宽度，通道数）。'
- en: 'Unset: defaults to the channel dimension format of the input image.'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：默认为输入图片的通道维度格式。
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format`（`ChannelDimension`或`str`，*可选*）— 输入图片的通道维度格式。如果未设置，将从输入图片中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图片格式为（通道数，高度，宽度）。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图片格式为（高度，宽度，通道数）。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"`或`ChannelDimension.NONE`：图片格式为（高度，宽度）。'
- en: Preprocess an image or batch of images.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一张图片或一批图片。
- en: DonutFeatureExtractor
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DonutFeatureExtractor
- en: '### `class transformers.DonutFeatureExtractor`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DonutFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/feature_extraction_donut.py#L26)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/feature_extraction_donut.py#L26)'
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#### `__call__`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Preprocess an image or a batch of images.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一张图片或一批图片。
- en: DonutProcessor
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DonutProcessor
- en: '### `class transformers.DonutProcessor`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DonutProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L25)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L25)'
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` ([DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor),
    *optional*) — An instance of [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor).
    The image processor is a required input.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor`（[DonutImageProcessor](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutImageProcessor)，*可选*）—
    [DonutImageProcessor](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutImageProcessor)的实例。图像处理器是必需的输入。'
- en: '`tokenizer` ([`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`], *optional*)
    — An instance of [`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]. The tokenizer
    is a required input.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]，*可选*）— [`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]的实例。分词器是必需的输入。'
- en: Constructs a Donut processor which wraps a Donut image processor and an XLMRoBERTa
    tokenizer into a single processor.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Donut处理器，将一个Donut图像处理器和一个XLMRoBERTa分词器包装成一个单一处理器。
- en: '[DonutProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutProcessor)
    offers all the functionalities of [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)
    and [`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]. See the [**call**()](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutProcessor.__call__)
    and [decode()](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutProcessor.decode)
    for more information.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[DonutProcessor](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutProcessor)提供了[DonutImageProcessor](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutImageProcessor)和[`XLMRobertaTokenizer`/`XLMRobertaTokenizerFast`]的所有功能。查看更多信息，请参阅[**call**()](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutProcessor.__call__)和[decode()](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutProcessor.decode)。'
- en: '#### `__call__`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L65)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L65)'
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: When used in normal mode, this method forwards all its arguments to AutoImageProcessor’s
    `__call__()` and returns its output. If used in the context `as_target_processor()`
    this method forwards all its arguments to DonutTokenizer’s `~DonutTokenizer.__call__`.
    Please refer to the doctsring of the above two methods for more information.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常模式下使用时，此方法将所有参数转发到AutoImageProcessor的`__call__()`并返回其输出。如果在上下文`as_target_processor()`中使用，则此方法将所有参数转发到DonutTokenizer的`~DonutTokenizer.__call__`。有关更多信息，请参阅上述两种方法的文档。
- en: '#### `from_pretrained`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE11]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，指向huggingface.co上托管的预训练特征提取器的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下进行命名空间化，如`dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)方法保存的特征提取器文件，例如，`./my_model_directory/`。
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs — Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个保存的特征提取器 JSON *文件*的路径或 URL，例如，`./my_model_directory/preprocessor_config.json`。**kwargs
    — 传递给[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)和`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`的额外关键字参数。
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化与预训练模型相关联的处理器。
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用特征提取器的[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)、图像处理器[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)和分词器`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`方法。更多信息请参考上述方法的文档字符串。
- en: '#### `save_pretrained`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `保存预训练模型`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE12]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` 或 `os.PathLike`) — 将要保存特征提取器 JSON 文件和分词器文件的目录（如果目录不存在，则会创建）。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为 `False`) — 是否在保存后将模型推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) — 传递给[push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的额外关键字参数。'
- en: Saves the attributes of this processor (feature extractor, tokenizer…) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处理器的属性（特征提取器、分词器等）保存在指定的目录中，以便可以使用[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)方法重新加载。
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)和[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)。更多信息请参考上述方法的文档字符串。
- en: '#### `batch_decode`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `批量解码`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L98)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L98)'
- en: '[PRE13]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This method forwards all its arguments to DonutTokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法将所有参数转发给DonutTokenizer的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。更多信息请参考此方法的文档字符串。
- en: '#### `decode`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `解码`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L105)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/processing_donut.py#L105)'
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This method forwards all its arguments to DonutTokenizer’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法将所有参数转发给DonutTokenizer的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。更多信息请参考此方法的文档字符串。
- en: DonutSwinModel
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DonutSwinModel
- en: '### `class transformers.DonutSwinModel`'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DonutSwinModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/modeling_donut_swin.py#L856)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/modeling_donut_swin.py#L856)'
- en: '[PRE15]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Donut Swin Model transformer outputting raw hidden-states without any
    specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Donut Swin模型变压器输出原始隐藏状态，没有特定的头部在顶部。该模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `前向`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/modeling_donut_swin.py#L886)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/donut/modeling_donut_swin.py#L886)'
- en: '[PRE16]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DonutImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）—
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[DonutImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使自注意力模块中选择的头部失效的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮罩，
- en: 0 indicates the head is `masked`.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮罩。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`)
    — Boolean masked positions. Indicates which patches are masked (1) and which aren’t
    (0).'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool_masked_pos`（形状为`(batch_size, num_patches)`的`torch.BoolTensor`）— 布尔掩码位置。指示哪些补丁被屏蔽（1）哪些没有（0）。'
- en: Returns
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`transformers.models.donut.modeling_donut_swin.DonutSwinModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.donut.modeling_donut_swin.DonutSwinModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.donut.modeling_donut_swin.DonutSwinModelOutput` or a
    tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig))
    and inputs.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.donut.modeling_donut_swin.DonutSwinModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)）和输入的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）—
    模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`,
    *optional*, returned when `add_pooling_layer=True` is passed) — Average pooling
    of the last layer hidden-state.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`（形状为`(batch_size, hidden_size)`的`torch.FloatTensor`，*可选*，当传递`add_pooling_layer=True`时返回）—
    最后一层隐藏状态的平均池化。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each stage) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each stage) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, hidden_size, height, width)`.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reshaped_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_hidden_states=True`
    或当 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, hidden_size, height,
    width)` 的 `torch.FloatTensor` 元组（一个用于嵌入的输出 + 一个用于每个阶段的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs reshaped to include the spatial dimensions.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及包括空间维度的初始嵌入输出进行了重塑。
- en: The [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    forward method, overrides the `__call__` special method.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在之后调用 `Module` 实例，而不是这个函数，因为前者会处理运行前后的处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
