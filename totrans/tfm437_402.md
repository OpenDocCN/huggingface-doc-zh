# 🤗 Transformers

> 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/index#contents](https://huggingface.co/docs/transformers/v4.37.2/en/index#contents)

[PyTorch](https://pytorch.org/)、[TensorFlow](https://www.tensorflow.org/)和[JAX](https://jax.readthedocs.io/en/latest/)的最先进机器学习。

🤗 Transformers提供API和工具，可轻松下载和训练最先进的预训练模型。使用预训练模型可以减少计算成本、碳足迹，并节省训练模型所需的时间和资源。这些模型支持不同模态的常见任务，如：

📝 **自然语言处理**：文本分类、命名实体识别、问答、语言建模、摘要、翻译、多项选择和文本生成。

🖼️ **计算机视觉**：图像分类、目标检测和分割。

🗣️ **音频**：自动语音识别和音频分类。

🐙 **多模态**：表格问答、光学字符识别、从扫描文档中提取信息、视频分类和视觉问答。

🤗 Transformers支持PyTorch、TensorFlow和JAX之间的框架互操作性。这提供了在模型的生命周期的每个阶段使用不同框架的灵活性；在一个框架中用三行代码训练模型，然后在另一个框架中加载进行推断。模型还可以导出到ONNX和TorchScript等格式，以在生产环境中部署。

立即加入不断增长的社区，参与[Hub](https://huggingface.co/models)、[论坛](https://discuss.huggingface.co/)或[Discord](https://discord.com/invite/JfAtkvEtRb)！

## 如果您正在寻找Hugging Face团队的定制支持

[![HuggingFace专家加速计划](../Images/4e3f8848a914f36cc180b9e654070ef1.png)](https://huggingface.co/support)

## 目录

文档分为五个部分：

+   **开始**提供了一个快速浏览库和安装说明，让您快速上手。

+   **教程**是初学者入门的好地方。本节将帮助您获得开始使用库所需的基本技能。

+   **操作指南**向您展示如何实现特定目标，比如微调预训练模型用于语言建模，或者如何编写和分享自定义模型。

+   **概念指南**提供了更多关于模型、任务和🤗 Transformers设计理念背后的概念和想法的讨论和解释。

+   **API**描述了所有类和函数：

    +   **主要类**详细介绍了配置、模型、分词器和管道等最重要的类。

    +   **模型**详细介绍了库中实现的每个模型相关的类和函数。

    +   **内部助手**详细介绍了内部使用的实用类和函数。

## 支持的模型和框架

下表表示库中对每个模型的当前支持情况，它们是否有Python分词器（称为“slow”）。一个由🤗 Tokenizers库支持的“fast”分词器，以及它们在Jax（通过Flax）、PyTorch和/或TensorFlow中的支持情况。

| 模型 | PyTorch支持 | TensorFlow支持 | Flax支持 |
| :-: | :-: | :-: | :-: |
| [ALBERT](model_doc/albert) | ✅ | ✅ | ✅ |
| [ALIGN](model_doc/align) | ✅ | ❌ | ❌ |
| [AltCLIP](model_doc/altclip) | ✅ | ❌ | ❌ |
| [音频频谱变换器](model_doc/audio-spectrogram-transformer) | ✅ | ❌ | ❌ |
| [Autoformer](model_doc/autoformer) | ✅ | ❌ | ❌ |
| [Bark](model_doc/bark) | ✅ | ❌ | ❌ |
| [BART](model_doc/bart) | ✅ | ✅ | ✅ |
| [BARThez](model_doc/barthez) | ✅ | ✅ | ✅ |
| [BARTpho](model_doc/bartpho) | ✅ | ✅ | ✅ |
| [BEiT](model_doc/beit) | ✅ | ❌ | ✅ |
| [BERT](model_doc/bert) | ✅ | ✅ | ✅ |
| [Bert 生成](model_doc/bert-generation) | ✅ | ❌ | ❌ |
| [Bert 日语](model_doc/bert-japanese) | ✅ | ✅ | ✅ |
| [BERTweet](model_doc/bertweet) | ✅ | ✅ | ✅ |
| [BigBird](model_doc/big_bird) | ✅ | ❌ | ✅ |
| [BigBird-Pegasus](模型文档/bigbird_pegasus) | ✅ | ❌ | ❌ |
| [BioGpt](模型文档/biogpt) | ✅ | ❌ | ❌ |
| [BiT](模型文档/bit) | ✅ | ❌ | ❌ |
| [Blenderbot](模型文档/blenderbot) | ✅ | ✅ | ✅ |
| [BlenderbotSmall](模型文档/blenderbot-small) | ✅ | ✅ | ✅ |
| [BLIP](模型文档/blip) | ✅ | ✅ | ❌ |
| [BLIP-2](模型文档/blip-2) | ✅ | ❌ | ❌ |
| [BLOOM](模型文档/bloom) | ✅ | ❌ | ✅ |
| [BORT](模型文档/bort) | ✅ | ✅ | ✅ |
| [BridgeTower](模型文档/bridgetower) | ✅ | ❌ | ❌ |
| [BROS](模型文档/bros) | ✅ | ❌ | ❌ |
| [ByT5](模型文档/byt5) | ✅ | ✅ | ✅ |
| [CamemBERT](模型文档/camembert) | ✅ | ✅ | ❌ |
| [CANINE](模型文档/canine) | ✅ | ❌ | ❌ |
| [Chinese-CLIP](模型文档/chinese_clip) | ✅ | ❌ | ❌ |
| [CLAP](模型文档/clap) | ✅ | ❌ | ❌ |
| [CLIP](模型文档/clip) | ✅ | ✅ | ✅ |
| [CLIPSeg](模型文档/clipseg) | ✅ | ❌ | ❌ |
| [CLVP](模型文档/clvp) | ✅ | ❌ | ❌ |
| [CodeGen](模型文档/codegen) | ✅ | ❌ | ❌ |
| [CodeLlama](模型文档/code_llama) | ✅ | ❌ | ✅ |
| [Conditional DETR](模型文档/conditional_detr) | ✅ | ❌ | ❌ |
| [ConvBERT](模型文档/convbert) | ✅ | ✅ | ❌ |
| [ConvNeXT](模型文档/convnext) | ✅ | ✅ | ❌ |
| [ConvNeXTV2](模型文档/convnextv2) | ✅ | ✅ | ❌ |
| [CPM](模型文档/cpm) | ✅ | ✅ | ✅ |
| [CPM-Ant](模型文档/cpmant) | ✅ | ❌ | ❌ |
| [CTRL](模型文档/ctrl) | ✅ | ✅ | ❌ |
| [CvT](模型文档/cvt) | ✅ | ✅ | ❌ |
| [Data2VecAudio](模型文档/data2vec) | ✅ | ❌ | ❌ |
| [Data2VecText](模型文档/data2vec) | ✅ | ❌ | ❌ |
| [Data2VecVision](模型文档/data2vec) | ✅ | ✅ | ❌ |
| [DeBERTa](模型文档/deberta) | ✅ | ✅ | ❌ |
| [DeBERTa-v2](模型文档/deberta-v2) | ✅ | ✅ | ❌ |
| [Decision Transformer](模型文档/decision_transformer) | ✅ | ❌ | ❌ |
| [Deformable DETR](模型文档/deformable_detr) | ✅ | ❌ | ❌ |
| [DeiT](模型文档/deit) | ✅ | ✅ | ❌ |
| [DePlot](模型文档/deplot) | ✅ | ❌ | ❌ |
| [DETA](模型文档/deta) | ✅ | ❌ | ❌ |
| [DETR](模型文档/detr) | ✅ | ❌ | ❌ |
| [DialoGPT](模型文档/dialogpt) | ✅ | ✅ | ✅ |
| [DiNAT](模型文档/dinat) | ✅ | ❌ | ❌ |
| [DINOv2](模型文档/dinov2) | ✅ | ❌ | ❌ |
| [DistilBERT](模型文档/distilbert) | ✅ | ✅ | ✅ |
| [DiT](模型文档/dit) | ✅ | ❌ | ✅ |
| [DonutSwin](模型文档/donut) | ✅ | ❌ | ❌ |
| [DPR](模型文档/dpr) | ✅ | ✅ | ❌ |
| [DPT](模型文档/dpt) | ✅ | ❌ | ❌ |
| [EfficientFormer](模型文档/efficientformer) | ✅ | ✅ | ❌ |
| [EfficientNet](模型文档/efficientnet) | ✅ | ❌ | ❌ |
| [ELECTRA](模型文档/electra) | ✅ | ✅ | ✅ |
| [EnCodec](模型文档/encodec) | ✅ | ❌ | ❌ |
| [Encoder decoder](模型文档/encoder-decoder) | ✅ | ✅ | ✅ |
| [ERNIE](模型文档/ernie) | ✅ | ❌ | ❌ |
| [ErnieM](模型文档/ernie_m) | ✅ | ❌ | ❌ |
| [ESM](模型文档/esm) | ✅ | ✅ | ❌ |
| [FairSeq Machine-Translation](模型文档/fsmt) | ✅ | ❌ | ❌ |
| [Falcon](模型文档/falcon) | ✅ | ❌ | ❌ |
| [FastSpeech2Conformer](模型文档/fastspeech2_conformer) | ✅ | ❌ | ❌ |
| [FLAN-T5](模型文档/flan-t5) | ✅ | ✅ | ✅ |
| [FLAN-UL2](模型文档/flan-ul2) | ✅ | ✅ | ✅ |
| [FlauBERT](模型文档/flaubert) | ✅ | ✅ | ❌ |
| [FLAVA](模型文档/flava) | ✅ | ❌ | ❌ |
| [FNet](模型文档/fnet) | ✅ | ❌ | ❌ |
| [FocalNet](模型文档/focalnet) | ✅ | ❌ | ❌ |
| [Funnel Transformer](模型文档/funnel) | ✅ | ✅ | ❌ |
| [Fuyu](模型文档/fuyu) | ✅ | ❌ | ❌ |
| [GIT](模型文档/git) | ✅ | ❌ | ❌ |
| [GLPN](模型文档/glpn) | ✅ | ❌ | ❌ |
| [GPT Neo](模型文档/gpt_neo) | ✅ | ❌ | ✅ |
| [GPT NeoX](模型文档/gpt_neox) | ✅ | ❌ | ❌ |
| [GPT NeoX Japanese](模型文档/gpt_neox_japanese) | ✅ | ❌ | ❌ |
| [GPT-J](模型文档/gptj) | ✅ | ✅ | ✅ |
| [GPT-Sw3](模型文档/gpt-sw3) | ✅ | ✅ | ✅ |
| [GPTBigCode](模型文档/gpt_bigcode) | ✅ | ❌ | ❌ |
| [GPTSAN-japanese](模型文档/gptsan-japanese) | ✅ | ❌ | ❌ |
| [Graphormer](模型文档/graphormer) | ✅ | ❌ | ❌ |
| [GroupViT](模型文档/groupvit) | ✅ | ✅ | ❌ |
| [HerBERT](模型文档/herbert) | ✅ | ✅ | ✅ |
| [Hubert](模型文档/hubert) | ✅ | ✅ | ❌ |
| [I-BERT](模型文档/ibert) | ✅ | ❌ | ❌ |
| [IDEFICS](模型文档/idefics) | ✅ | ❌ | ❌ |
| [ImageGPT](模型文档/imagegpt) | ✅ | ❌ | ❌ |
| [Informer](模型文档/informer) | ✅ | ❌ | ❌ |
| [InstructBLIP](模型文档/instructblip) | ✅ | ❌ | ❌ |
| [Jukebox](model_doc/jukebox) | ✅ | ❌ | ❌ |
| [KOSMOS-2](model_doc/kosmos-2) | ✅ | ❌ | ❌ |
| [LayoutLM](model_doc/layoutlm) | ✅ | ✅ | ❌ |
| [LayoutLMv2](model_doc/layoutlmv2) | ✅ | ❌ | ❌ |
| [LayoutLMv3](model_doc/layoutlmv3) | ✅ | ✅ | ❌ |
| [LayoutXLM](model_doc/layoutxlm) | ✅ | ❌ | ❌ |
| [LED](model_doc/led) | ✅ | ✅ | ❌ |
| [LeViT](model_doc/levit) | ✅ | ❌ | ❌ |
| [LiLT](model_doc/lilt) | ✅ | ❌ | ❌ |
| [LLaMA](model_doc/llama) | ✅ | ❌ | ✅ |
| [Llama2](model_doc/llama2) | ✅ | ❌ | ✅ |
| [LLaVa](model_doc/llava) | ✅ | ❌ | ❌ |
| [Longformer](model_doc/longformer) | ✅ | ✅ | ❌ |
| [LongT5](model_doc/longt5) | ✅ | ❌ | ✅ |
| [LUKE](model_doc/luke) | ✅ | ❌ | ❌ |
| [LXMERT](model_doc/lxmert) | ✅ | ✅ | ❌ |
| [M-CTC-T](model_doc/mctct) | ✅ | ❌ | ❌ |
| [M2M100](model_doc/m2m_100) | ✅ | ❌ | ❌ |
| [MADLAD-400](model_doc/madlad-400) | ✅ | ✅ | ✅ |
| [Marian](model_doc/marian) | ✅ | ✅ | ✅ |
| [MarkupLM](model_doc/markuplm) | ✅ | ❌ | ❌ |
| [Mask2Former](model_doc/mask2former) | ✅ | ❌ | ❌ |
| [MaskFormer](model_doc/maskformer) | ✅ | ❌ | ❌ |
| [MatCha](model_doc/matcha) | ✅ | ❌ | ❌ |
| [mBART](model_doc/mbart) | ✅ | ✅ | ✅ |
| [mBART-50](model_doc/mbart50) | ✅ | ✅ | ✅ |
| [MEGA](model_doc/mega) | ✅ | ❌ | ❌ |
| [Megatron-BERT](model_doc/megatron-bert) | ✅ | ❌ | ❌ |
| [Megatron-GPT2](model_doc/megatron_gpt2) | ✅ | ✅ | ✅ |
| [MGP-STR](model_doc/mgp-str) | ✅ | ❌ | ❌ |
| [Mistral](model_doc/mistral) | ✅ | ❌ | ❌ |
| [Mixtral](model_doc/mixtral) | ✅ | ❌ | ❌ |
| [mLUKE](model_doc/mluke) | ✅ | ❌ | ❌ |
| [MMS](model_doc/mms) | ✅ | ✅ | ✅ |
| [MobileBERT](model_doc/mobilebert) | ✅ | ✅ | ❌ |
| [MobileNetV1](model_doc/mobilenet_v1) | ✅ | ❌ | ❌ |
| [MobileNetV2](model_doc/mobilenet_v2) | ✅ | ❌ | ❌ |
| [MobileViT](model_doc/mobilevit) | ✅ | ✅ | ❌ |
| [MobileViTV2](model_doc/mobilevitv2) | ✅ | ❌ | ❌ |
| [MPNet](model_doc/mpnet) | ✅ | ✅ | ❌ |
| [MPT](model_doc/mpt) | ✅ | ❌ | ❌ |
| [MRA](model_doc/mra) | ✅ | ❌ | ❌ |
| [MT5](model_doc/mt5) | ✅ | ✅ | ✅ |
| [MusicGen](model_doc/musicgen) | ✅ | ❌ | ❌ |
| [MVP](model_doc/mvp) | ✅ | ❌ | ❌ |
| [NAT](model_doc/nat) | ✅ | ❌ | ❌ |
| [Nezha](model_doc/nezha) | ✅ | ❌ | ❌ |
| [NLLB](model_doc/nllb) | ✅ | ❌ | ❌ |
| [NLLB-MOE](model_doc/nllb-moe) | ✅ | ❌ | ❌ |
| [Nougat](model_doc/nougat) | ✅ | ✅ | ✅ |
| [Nyströmformer](model_doc/nystromformer) | ✅ | ❌ | ❌ |
| [OneFormer](model_doc/oneformer) | ✅ | ❌ | ❌ |
| [OpenAI GPT](model_doc/openai-gpt) | ✅ | ✅ | ❌ |
| [OpenAI GPT-2](model_doc/gpt2) | ✅ | ✅ | ✅ |
| [OpenLlama](model_doc/open-llama) | ✅ | ❌ | ❌ |
| [OPT](model_doc/opt) | ✅ | ✅ | ✅ |
| [OWL-ViT](model_doc/owlvit) | ✅ | ❌ | ❌ |
| [OWLv2](model_doc/owlv2) | ✅ | ❌ | ❌ |
| [PatchTSMixer](model_doc/patchtsmixer) | ✅ | ❌ | ❌ |
| [PatchTST](model_doc/patchtst) | ✅ | ❌ | ❌ |
| [Pegasus](model_doc/pegasus) | ✅ | ✅ | ✅ |
| [PEGASUS-X](model_doc/pegasus_x) | ✅ | ❌ | ❌ |
| [Perceiver](model_doc/perceiver) | ✅ | ❌ | ❌ |
| [Persimmon](model_doc/persimmon) | ✅ | ❌ | ❌ |
| [Phi](model_doc/phi) | ✅ | ❌ | ❌ |
| [PhoBERT](model_doc/phobert) | ✅ | ✅ | ✅ |
| [Pix2Struct](model_doc/pix2struct) | ✅ | ❌ | ❌ |
| [PLBart](model_doc/plbart) | ✅ | ❌ | ❌ |
| [PoolFormer](model_doc/poolformer) | ✅ | ❌ | ❌ |
| [Pop2Piano](model_doc/pop2piano) | ✅ | ❌ | ❌ |
| [ProphetNet](model_doc/prophetnet) | ✅ | ❌ | ❌ |
| [PVT](model_doc/pvt) | ✅ | ❌ | ❌ |
| [QDQBert](model_doc/qdqbert) | ✅ | ❌ | ❌ |
| [Qwen2](model_doc/qwen2) | ✅ | ❌ | ❌ |
| [RAG](model_doc/rag) | ✅ | ✅ | ❌ |
| [REALM](model_doc/realm) | ✅ | ❌ | ❌ |
| [Reformer](model_doc/reformer) | ✅ | ❌ | ❌ |
| [RegNet](model_doc/regnet) | ✅ | ✅ | ✅ |
| [RemBERT](model_doc/rembert) | ✅ | ✅ | ❌ |
| [ResNet](model_doc/resnet) | ✅ | ✅ | ✅ |
| [RetriBERT](model_doc/retribert) | ✅ | ❌ | ❌ |
| [RoBERTa](model_doc/roberta) | ✅ | ✅ | ✅ |
| [RoBERTa-PreLayerNorm](model_doc/roberta-prelayernorm) | ✅ | ✅ | ✅ |
| [RoCBert](model_doc/roc_bert) | ✅ | ❌ | ❌ |
| [RoFormer](model_doc/roformer) | ✅ | ✅ | ✅ |
| [RWKV](model_doc/rwkv) | ✅ | ❌ | ❌ |
| [SAM](model_doc/sam) | ✅ | ✅ | ❌ |
| [SeamlessM4T](model_doc/seamless_m4t) | ✅ | ❌ | ❌ |
| [SeamlessM4Tv2](model_doc/seamless_m4t_v2) | ✅ | ❌ | ❌ |
| [SegFormer](model_doc/segformer) | ✅ | ✅ | ❌ |
| [SEW](model_doc/sew) | ✅ | ❌ | ❌ |
| [SEW-D](model_doc/sew-d) | ✅ | ❌ | ❌ |
| [SigLIP](model_doc/siglip) | ✅ | ❌ | ❌ |
| [Speech Encoder decoder](model_doc/speech-encoder-decoder) | ✅ | ❌ | ✅ |
| [Speech2Text](model_doc/speech_to_text) | ✅ | ✅ | ❌ |
| [SpeechT5](model_doc/speecht5) | ✅ | ❌ | ❌ |
| [Splinter](model_doc/splinter) | ✅ | ❌ | ❌ |
| [SqueezeBERT](model_doc/squeezebert) | ✅ | ❌ | ❌ |
| [SwiftFormer](model_doc/swiftformer) | ✅ | ❌ | ❌ |
| [Swin Transformer](model_doc/swin) | ✅ | ✅ | ❌ |
| [Swin Transformer V2](model_doc/swinv2) | ✅ | ❌ | ❌ |
| [Swin2SR](model_doc/swin2sr) | ✅ | ❌ | ❌ |
| [SwitchTransformers](model_doc/switch_transformers) | ✅ | ❌ | ❌ |
| [T5](model_doc/t5) | ✅ | ✅ | ✅ |
| [T5v1.1](model_doc/t5v1.1) | ✅ | ✅ | ✅ |
| [Table Transformer](model_doc/table-transformer) | ✅ | ❌ | ❌ |
| [TAPAS](model_doc/tapas) | ✅ | ✅ | ❌ |
| [TAPEX](model_doc/tapex) | ✅ | ✅ | ✅ |
| [Time Series Transformer](model_doc/time_series_transformer) | ✅ | ❌ | ❌ |
| [TimeSformer](model_doc/timesformer) | ✅ | ❌ | ❌ |
| [Trajectory Transformer](model_doc/trajectory_transformer) | ✅ | ❌ | ❌ |
| [Transformer-XL](model_doc/transfo-xl) | ✅ | ✅ | ❌ |
| [TrOCR](model_doc/trocr) | ✅ | ❌ | ❌ |
| [TVLT](model_doc/tvlt) | ✅ | ❌ | ❌ |
| [TVP](model_doc/tvp) | ✅ | ❌ | ❌ |
| [UL2](model_doc/ul2) | ✅ | ✅ | ✅ |
| [UMT5](model_doc/umt5) | ✅ | ❌ | ❌ |
| [UniSpeech](model_doc/unispeech) | ✅ | ❌ | ❌ |
| [UniSpeechSat](model_doc/unispeech-sat) | ✅ | ❌ | ❌ |
| [UnivNet](model_doc/univnet) | ✅ | ❌ | ❌ |
| [UPerNet](model_doc/upernet) | ✅ | ❌ | ❌ |
| [VAN](model_doc/van) | ✅ | ❌ | ❌ |
| [VideoMAE](model_doc/videomae) | ✅ | ❌ | ❌ |
| [ViLT](model_doc/vilt) | ✅ | ❌ | ❌ |
| [VipLlava](model_doc/vipllava) | ✅ | ❌ | ❌ |
| [Vision Encoder decoder](model_doc/vision-encoder-decoder) | ✅ | ✅ | ✅ |
| [VisionTextDualEncoder](model_doc/vision-text-dual-encoder) | ✅ | ✅ | ✅ |
| [VisualBERT](model_doc/visual_bert) | ✅ | ❌ | ❌ |
| [ViT](model_doc/vit) | ✅ | ✅ | ✅ |
| [ViT Hybrid](model_doc/vit_hybrid) | ✅ | ❌ | ❌ |
| [VitDet](model_doc/vitdet) | ✅ | ❌ | ❌ |
| [ViTMAE](model_doc/vit_mae) | ✅ | ✅ | ❌ |
| [ViTMatte](model_doc/vitmatte) | ✅ | ❌ | ❌ |
| [ViTMSN](model_doc/vit_msn) | ✅ | ❌ | ❌ |
| [VITS](model_doc/vits) | ✅ | ❌ | ❌ |
| [ViViT](model_doc/vivit) | ✅ | ❌ | ❌ |
| [Wav2Vec2](model_doc/wav2vec2) | ✅ | ✅ | ✅ |
| [Wav2Vec2-BERT](model_doc/wav2vec2-bert) | ✅ | ❌ | ❌ |
| [Wav2Vec2-Conformer](model_doc/wav2vec2-conformer) | ✅ | ❌ | ❌ |
| [Wav2Vec2Phoneme](model_doc/wav2vec2_phoneme) | ✅ | ✅ | ✅ |
| [WavLM](model_doc/wavlm) | ✅ | ❌ | ❌ |
| [Whisper](model_doc/whisper) | ✅ | ✅ | ✅ |
| [X-CLIP](model_doc/xclip) | ✅ | ❌ | ❌ |
| [X-MOD](model_doc/xmod) | ✅ | ❌ | ❌ |
| [XGLM](model_doc/xglm) | ✅ | ✅ | ✅ |
| [XLM](model_doc/xlm) | ✅ | ✅ | ❌ |
| [XLM-ProphetNet](model_doc/xlm-prophetnet) | ✅ | ❌ | ❌ |
| [XLM-RoBERTa](model_doc/xlm-roberta) | ✅ | ✅ | ✅ |
| [XLM-RoBERTa-XL](model_doc/xlm-roberta-xl) | ✅ | ❌ | ❌ |
| [XLM-V](model_doc/xlm-v) | ✅ | ✅ | ✅ |
| [XLNet](model_doc/xlnet) | ✅ | ✅ | ❌ |
| [XLS-R](model_doc/xls_r) | ✅ | ✅ | ✅ |
| [XLSR-Wav2Vec2](model_doc/xlsr_wav2vec2) | ✅ | ✅ | ✅ |
| [YOLOS](model_doc/yolos) | ✅ | ❌ | ❌ |
| [YOSO](model_doc/yoso) | ✅ | ❌ | ❌ |
