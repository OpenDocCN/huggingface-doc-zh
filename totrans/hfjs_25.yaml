- en: 'Interface: TextGenerationStreamBestOfSequence'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/huggingface.js/inference/interfaces/TextGenerationStreamBestOfSequence](https://huggingface.co/docs/huggingface.js/inference/interfaces/TextGenerationStreamBestOfSequence)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: finish _ reason
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `finish_reason`: [`TextGenerationStreamFinishReason`](../modules#textgenerationstreamfinishreason)'
  prefs: []
  type: TYPE_NORMAL
- en: Generation finish reason
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:35](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L35)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: generated _ text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `generated_text`: `string`'
  prefs: []
  type: TYPE_NORMAL
- en: Generated text
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:33](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L33)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: generated _ tokens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `generated_tokens`: `number`'
  prefs: []
  type: TYPE_NORMAL
- en: Number of generated tokens
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:37](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L37)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: prefill
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `prefill`: [`TextGenerationStreamPrefillToken`](TextGenerationStreamPrefillToken)[]'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt tokens
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:41](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L41)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: seed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `Optional` `seed`: `number`'
  prefs: []
  type: TYPE_NORMAL
- en: Sampling seed if sampling was activated
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:39](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L39)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tokens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `tokens`: [`TextGenerationStreamToken`](TextGenerationStreamToken)[]'
  prefs: []
  type: TYPE_NORMAL
- en: Generated tokens
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:43](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L43)'
  prefs: []
  type: TYPE_NORMAL
