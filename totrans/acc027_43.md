# 启动器

> 原始文本：[https://huggingface.co/docs/accelerate/package_reference/launchers](https://huggingface.co/docs/accelerate/package_reference/launchers)

用于在分布式进程上启动训练的函数。

#### `accelerate.notebook_launcher`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/launchers.py#L37)

```py
( function args = () num_processes = None mixed_precision = 'no' use_port = '29500' master_addr = '127.0.0.1' node_rank = 0 num_nodes = 1 )
```

参数

+   `function` (`Callable`) — 要执行的训练函数。如果接受参数，则第一个参数应该是进程运行的索引。

+   `args` (`Tuple`) — 要传递给函数的参数元组（它将接收`*args`）。

+   `num_processes` (`int`, *可选*) — 用于训练的进程数。如果在Colab/Kaggle中有TPU可用，则默认为8，否则默认为可用的GPU数量。

+   `mixed_precision` (`str`, *可选*，默认为`"no"`) — 如果是`fp16`或`bf16`，将在多GPU上使用混合精度训练。

+   `use_port` (`str`, *可选*，默认为`"29500"`) — 在启动多GPU训练时，用于进程间通信的端口。

+   `master_addr` (`str`, *可选*，默认为`"127.0.0.1"`) — 用于进程间通信的地址。

+   `node_rank` (`int`, *可选*，默认为0) — 当前节点的排名。

+   `num_nodes` (`int`, *可选*，默认为1) — 用于训练的节点数。

启动一个训练函数，如果在当前环境中可能的话，将使用多个进程或多个节点（例如具有多个核心的TPU）。

在调用之前，在笔记本会话中绝对不能进行任何对CUDA设备的调用。如果有任何调用已经进行，您需要重新启动笔记本，并确保没有单元格使用任何CUDA功能。

在您的环境中设置`ACCELERATE_DEBUG_MODE="1"`将在真正启动之前运行一个测试，以确保没有进行这些调用。

示例：

```py
# Assume this is defined in a Jupyter Notebook on an instance with two GPUs
from accelerate import notebook_launcher

def train(*args):
    # Your training function here
    ...

notebook_launcher(train, args=(arg1, arg2), num_processes=2, mixed_precision="fp16")
```

#### `accelerate.debug_launcher`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/launchers.py#L224)

```py
( function args = () num_processes = 2 )
```

参数

+   `function` (`Callable`) — 要执行的训练函数。

+   `args` (`Tuple`) — 要传递给函数的参数元组（它将接收`*args`）。

+   `num_processes` (`int`, *可选*，默认为2) — 用于训练的进程数。

启动一个用于调试目的在CPU上使用多个进程的训练函数。

此函数提供用于内部测试和调试，但不适用于真正的训练。它只会使用CPU。
