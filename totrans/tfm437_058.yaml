- en: Export to TFLite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/tflite](https://huggingface.co/docs/transformers/v4.37.2/en/tflite)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/368.6bdc7169.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
  prefs: []
  type: TYPE_NORMAL
- en: '[TensorFlow Lite](https://www.tensorflow.org/lite/guide) is a lightweight framework
    for deploying machine learning models on resource-constrained devices, such as
    mobile phones, embedded systems, and Internet of Things (IoT) devices. TFLite
    is designed to optimize and run models efficiently on these devices with limited
    computational power, memory, and power consumption. A TensorFlow Lite model is
    represented in a special efficient portable format identified by the `.tflite`
    file extension.'
  prefs: []
  type: TYPE_NORMAL
- en: ðŸ¤— Optimum offers functionality to export ðŸ¤— Transformers models to TFLite through
    the `exporters.tflite` module. For the list of supported model architectures,
    please refer to [ðŸ¤— Optimum documentation](https://huggingface.co/docs/optimum/exporters/tflite/overview).
  prefs: []
  type: TYPE_NORMAL
- en: 'To export a model to TFLite, install the required dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To check out all available arguments, refer to the [ðŸ¤— Optimum docs](https://huggingface.co/docs/optimum/main/en/exporters/tflite/usage_guides/export_a_model),
    or view help in command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To export a modelâ€™s checkpoint from the ðŸ¤— Hub, for example, `bert-base-uncased`,
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the logs indicating progress and showing where the resulting
    `model.tflite` is saved, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The example above illustrates exporting a checkpoint from ðŸ¤— Hub. When exporting
    a local model, first make sure that you saved both the modelâ€™s weights and tokenizer
    files in the same directory (`local_path`). When using CLI, pass the `local_path`
    to the `model` argument instead of the checkpoint name on ðŸ¤— Hub.
  prefs: []
  type: TYPE_NORMAL
