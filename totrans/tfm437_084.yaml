- en: Optimize inference using torch.compile()
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/perf_torch_compile](https://huggingface.co/docs/transformers/v4.37.2/en/perf_torch_compile)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This guide aims to provide a benchmark on the inference speed-ups introduced
    with [`torch.compile()`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)¬†for
    [computer vision models in ü§ó Transformers](https://huggingface.co/models?pipeline_tag=image-classification&library=transformers&sort=trending).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of torch.compile
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on the model and the GPU, `torch.compile()` yields up to 30% speed-up
    during inference. To use `torch.compile()`, simply install any version of `torch`
    above 2.0.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'Compiling a model takes time, so it‚Äôs useful if you are compiling the model
    only once instead of every time you infer. To compile any computer vision model
    of your choice, call `torch.compile()` on the model as shown below:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`compile()`¬†comes with multiple modes for compiling, which essentially differ
    in compilation time and inference overhead. `max-autotune`¬†takes longer than `reduce-overhead`¬†but
    results in faster inference. Default mode is fastest for compilation but is not
    as efficient compared to `reduce-overhead` for inference time. In this guide,
    we used the default mode. You can learn more about it [here](https://pytorch.org/get-started/pytorch-2.0/#user-experience).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: We benchmarked `torch.compile` with different computer vision models, tasks,
    types of hardware, and batch sizes on `torch`¬†version 2.0.1.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking code
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Below you can find the benchmarking code for each task. We warm up the GPU before
    inference and take the mean time of 300 inferences, using the same image each
    time.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Image Classification with ViT
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Object Detection with DETR
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Image Segmentation with Segformer
  id: totrans-16
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Below you can find the list of the models we benchmarked.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Classification**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[google/vit-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[microsoft/beit-base-patch16-224-pt22k-ft22k](https://huggingface.co/microsoft/beit-base-patch16-224-pt22k-ft22k)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[facebook/convnext-large-224](https://huggingface.co/facebook/convnext-large-224)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[microsoft/resnet-50](https://huggingface.co/)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image Segmentation**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[nvidia/segformer-b0-finetuned-ade-512-512](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[facebook/mask2former-swin-tiny-coco-panoptic](https://huggingface.co/facebook/mask2former-swin-tiny-coco-panoptic)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[facebook/maskformer-swin-base-ade](https://huggingface.co/facebook/maskformer-swin-base-ade)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[google/deeplabv3_mobilenet_v2_1.0_513](https://huggingface.co/google/deeplabv3_mobilenet_v2_1.0_513)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object Detection**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[google/owlvit-base-patch32](https://huggingface.co/google/owlvit-base-patch32)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[facebook/detr-resnet-101](https://huggingface.co/facebook/detr-resnet-101)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[microsoft/conditional-detr-resnet-50](https://huggingface.co/microsoft/conditional-detr-resnet-50)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Below you can find visualization of inference durations with and without `torch.compile()`¬†and
    percentage improvements for each model in different hardware and batch sizes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/371979e4a66b66d493287c3d7f51d2d8.png)![](../Images/02da43bec655f1f8fc466bdbe14fa012.png)![](../Images/9109d187b7a12ee73d95da7b45b39cb2.png)![](../Images/87a432d9807c5b0267d63ddf71148c01.png)![](../Images/eb2dfd0de63fee7e557533652fc75bef.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: '![Duration Comparison on V100 with Batch Size of 1](../Images/28839892a7c0c288676c2bec3735258a.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: '![Percentage Improvement on T4 with Batch Size of 4](../Images/a404e9b598e7cf47c5e67e3c81e06dd5.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Below you can find inference durations in milliseconds for each model with and
    without `compile()`. Note that OwlViT results in OOM in larger batch sizes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'A100 (batch size: 1)'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 9.325 | 7.584 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 11.759 | 10.500 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/OwlViT | 24.978 | 18.420 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 11.282 | 8.448 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 34.619 | 19.040 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 10.410 | 10.208 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 6.531 | 4.124 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 60.188 | 49.117 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 75.764 | 59.487 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 8.583 | 3.974 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 36.276 | 18.197 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 31.219 | 17.993 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: 'A100 (batch size: 4)'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 14.832 | 14.499 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 18.838 | 16.476 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 13.205 | 13.048 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 48.657 | 32.418 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 22.940 | 21.631 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 6.657 | 4.268 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 74.277 | 61.781 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 180.700 | 159.116 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 14.174 | 8.515 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 68.101 | 44.998 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 56.470 | 35.552 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: 'A100 (batch size: 16)'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 40.944 | 40.010 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 37.005 | 31.144 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 41.854 | 41.048 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 164.382 | 161.902 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 82.258 | 75.561 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 7.018 | 5.024 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 178.945 | 154.814 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 638.570 | 579.826 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 51.693 | 30.310 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 232.887 | 155.021 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 180.491 | 124.032 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
- en: 'V100 (batch size: 1)'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 10.495 | 6.00 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 13.321 | 5.862 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/OwlViT | 25.769 | 22.395 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 11.347 | 7.234 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 33.951 | 19.388 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 11.623 | 10.412 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 6.484 | 3.820 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 64.640 | 49.873 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 95.532 | 72.207 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 9.217 | 4.753 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 52.818 | 28.367 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 39.512 | 20.816 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
- en: 'V100 (batch size: 4)'
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 15.181 | 14.501 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 16.787 | 16.188 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 15.171 | 14.753 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 88.529 | 64.195 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 29.574 | 27.085 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 6.109 | 4.731 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 90.402 | 76.926 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 234.261 | 205.456 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 24.623 | 14.816 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 134.672 | 101.304 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 97.464 | 69.739 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: 'V100 (batch size: 16)'
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 52.209 | 51.633 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 61.013 | 55.499 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 53.938 | 53.581 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | OOM | OOM |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 109.682 | 100.771 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 14.857 | 12.089 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 249.605 | 222.801 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 831.142 | 743.645 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 93.129 | 55.365 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 482.425 | 361.843 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 344.661 | 255.298 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
- en: 'T4 (batch size: 1)'
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 16.520 | 15.786 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 16.116 | 14.205 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/OwlViT | 53.634 | 51.105 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 16.464 | 15.710 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 73.100 | 53.99 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 32.932 | 30.845 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 6.031 | 4.321 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 79.192 | 66.815 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 200.026 | 188.268 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 18.908 | 11.997 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 106.622 | 82.566 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 77.594 | 56.984 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
- en: 'T4 (batch size: 4)'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 43.653 | 43.626 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 45.327 | 42.445 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 52.007 | 51.354 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 277.850 | 268.003 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 119.259 | 105.580 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 13.039 | 11.388 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 201.540 | 184.670 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 764.052 | 711.280 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 74.289 | 48.677 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 421.859 | 357.614 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 289.002 | 226.945 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: 'T4 (batch size: 16)'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **torch 2.0 - no compile** | **torch 2.0 - compile** |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ViT | 163.914 | 160.907 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Segformer | 192.412 | 163.620 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 188.978 | 187.976 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | OOM | OOM |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 422.886 | 388.078 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 44.114 | 37.604 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Mask2former | 756.337 | 695.291 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/Maskformer | 2842.940 | 2656.88 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
- en: '| Image Segmentation/MobileNet | 299.003 | 201.942 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Resnet-101 | 1619.505 | 1262.758 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | 1137.513 | 897.390 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
- en: PyTorch Nightly
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We also benchmarked on PyTorch nightly (2.1.0dev, find the wheel [here](https://download.pytorch.org/whl/nightly/cu118))
    and observed improvement in latency both for uncompiled and compiled models.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: A100
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **Batch Size** | **torch 2.0 - no compile** | **torch 2.0
    - compile** |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | :-: |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | Unbatched | 12.462 | 6.954 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 4 | 14.109 | 12.851 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 16 | 42.179 | 42.147 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | Unbatched | 30.484 | 15.221 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 4 | 46.816 | 30.942 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 16 | 163.749 | 163.706 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
- en: T4
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **Batch Size** | **torch 2.0 - no compile** | **torch 2.0
    - compile** |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | :-: |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | Unbatched | 14.408 | 14.052 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 4 | 47.381 | 46.604 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 16 | 42.179 | 42.147 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | Unbatched | 68.382 | 53.481 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 4 | 269.615 | 204.785 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 16 | OOM | OOM |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
- en: '###¬†V100'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '| **Task/Model** | **Batch Size** | **torch 2.0 - no compile** | **torch 2.0
    - compile** |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | :-: |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | Unbatched | 13.477 | 7.926 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 4 | 15.103 | 14.378 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/BeiT | 16 | 52.517 | 51.691 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | Unbatched | 28.706 | 19.077 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 4 | 88.402 | 62.949 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/DETR | 16 | OOM | OOM |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: Reduce Overhead
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We benchmarked `reduce-overhead` compilation mode for A100 and T4 in Nightly.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: A100
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| **Task/Model** | **Batch Size** | **torch 2.0 - no compile** | **torch 2.0
    - compile** |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | :-: |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | Unbatched | 11.758 | 7.335 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ConvNeXT | 4 | 23.171 | 21.490 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | Unbatched | 7.435 | 3.801 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| Image Classification/ResNet | 4 | 7.261 | 2.187 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| Object Detection/Conditional-DETR | Unbatched | 32.823 | 11.627 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| ÁõÆÊ†áÊ£ÄÊµã/Êù°‰ª∂DETR | Êú™ÊâπÂ§ÑÁêÜ | 32.823 | 11.627 |'
- en: '| Object Detection/Conditional-DETR | 4 | 50.622 | 33.831 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| ÁõÆÊ†áÊ£ÄÊµã/Êù°‰ª∂DETR | 4 | 50.622 | 33.831 |'
- en: '| Image Segmentation/MobileNet | Unbatched | 9.869 | 4.244 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÂâ≤/MobileNet | Êú™ÊâπÂ§ÑÁêÜ | 9.869 | 4.244 |'
- en: '| Image Segmentation/MobileNet | 4 | 14.385 | 7.946 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÂâ≤/MobileNet | 4 | 14.385 | 7.946 |'
- en: T4
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: T4
- en: '| **Task/Model** | **Batch Size** | **torch 2.0 - no compile** | **torch 2.0
    - compile** |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| **‰ªªÂä°/Ê®°Âûã** | **ÊâπÂ§ÑÁêÜÂ§ßÂ∞è** | **torch 2.0 - Êó†ÁºñËØë** | **torch 2.0 - ÁºñËØë** |'
- en: '| :-: | :-: | :-: | :-: |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: | :-: | :-: |'
- en: '| Image Classification/ConvNeXT | Unbatched | 32.137 | 31.84 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÁ±ª/ConvNeXT | Êú™ÊâπÂ§ÑÁêÜ | 32.137 | 31.84 |'
- en: '| Image Classification/ConvNeXT | 4 | 120.944 | 110.209 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÁ±ª/ConvNeXT | 4 | 120.944 | 110.209 |'
- en: '| Image Classification/ResNet | Unbatched | 9.761 | 7.698 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÁ±ª/ResNet | Êú™ÊâπÂ§ÑÁêÜ | 9.761 | 7.698 |'
- en: '| Image Classification/ResNet | 4 | 15.215 | 13.871 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÁ±ª/ResNet | 4 | 15.215 | 13.871 |'
- en: '| Object Detection/Conditional-DETR | Unbatched | 72.150 | 57.660 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| ÁõÆÊ†áÊ£ÄÊµã/Êù°‰ª∂DETR | Êú™ÊâπÂ§ÑÁêÜ | 72.150 | 57.660 |'
- en: '| Object Detection/Conditional-DETR | 4 | 301.494 | 247.543 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| ÁõÆÊ†áÊ£ÄÊµã/Êù°‰ª∂DETR | 4 | 301.494 | 247.543 |'
- en: '| Image Segmentation/MobileNet | Unbatched | 22.266 | 19.339 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÂâ≤/MobileNet | Êú™ÊâπÂ§ÑÁêÜ | 22.266 | 19.339 |'
- en: '| Image Segmentation/MobileNet | 4 | 78.311 | 50.983 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| ÂõæÂÉèÂàÜÂâ≤/MobileNet | 4 | 78.311 | 50.983 |'
