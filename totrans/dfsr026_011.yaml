- en: Load LoRAs for inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载LoRA进行推理
- en: 'Original text: [https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference](https://huggingface.co/docs/diffusers/tutorials/using_peft_for_inference)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: There are many adapters (with LoRAs being the most common type) trained in different
    styles to achieve different effects. You can even combine multiple adapters to
    create new and unique images. With the 🤗 [PEFT](https://huggingface.co/docs/peft/index)
    integration in 🤗 Diffusers, it is really easy to load and manage adapters for
    inference. In this guide, you’ll learn how to use different adapters with [Stable
    Diffusion XL (SDXL)](../api/pipelines/stable_diffusion/stable_diffusion_xl) for
    inference.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多适配器（其中LoRA是最常见的类型）以不同的风格进行训练，以实现不同的效果。您甚至可以组合多个适配器来创建新的独特图像。通过🤗 [PEFT](https://huggingface.co/docs/peft/index)在🤗
    Diffusers中的集成，非常容易加载和管理适配器进行推理。在本指南中，您将学习如何使用不同的适配器与[Stable Diffusion XL (SDXL)](../api/pipelines/stable_diffusion/stable_diffusion_xl)一起进行推理。
- en: Throughout this guide, you’ll use LoRA as the main adapter technique, so we’ll
    use the terms LoRA and adapter interchangeably. You should have some familiarity
    with LoRA, and if you don’t, we welcome you to check out the [LoRA guide](https://huggingface.co/docs/peft/conceptual_guides/lora).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个指南中，您将使用LoRA作为主要适配器技术，因此我们将LoRA和适配器术语互换使用。您应该对LoRA有一定了解，如果没有，欢迎查看[LoRA指南](https://huggingface.co/docs/peft/conceptual_guides/lora)。
- en: Let’s first install all the required libraries.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先安装所有所需的库。
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let’s load a pipeline with a SDXL checkpoint:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们加载一个带有SDXL检查点的管道：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, load a LoRA checkpoint with the [load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    method.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)方法加载一个LoRA检查点。
- en: With the 🤗 PEFT integration, you can assign a specific `adapter_name` to the
    checkpoint, which let’s you easily switch between different LoRA checkpoints.
    Let’s call this adapter `"toy"`.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过🤗 PEFT集成，您可以为检查点分配特定的`adapter_name`，这样您可以轻松在不同的LoRA检查点之间切换。让我们将此适配器命名为`"toy"`。
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And then perform inference:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然后执行推理：
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![toy-face](../Images/5113690135aa0bd78ddd1d3e7c53479d.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![玩具脸](../Images/5113690135aa0bd78ddd1d3e7c53479d.png)'
- en: With the `adapter_name` parameter, it is really easy to use another adapter
    for inference! Load the [nerijs/pixel-art-xl](https://huggingface.co/nerijs/pixel-art-xl)
    adapter that has been fine-tuned to generate pixel art images, and let’s call
    it `"pixel"`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`adapter_name`参数，非常容易为推理使用另一个适配器！加载已经微调以生成像素艺术图像的[nerijs/pixel-art-xl](https://huggingface.co/nerijs/pixel-art-xl)适配器，并将其命名为`"pixel"`。
- en: 'The pipeline automatically sets the first loaded adapter (`"toy"`) as the active
    adapter. But you can activate the `"pixel"` adapter with the [set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)
    method as shown below:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 管道会自动将第一个加载的适配器（`"toy"`）设置为活动适配器。但是您可以使用下面显示的[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法激活`"pixel"`适配器：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s now generate an image with the second adapter and check the result:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用第二个适配器生成一幅图像并检查结果：
- en: '[PRE5]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![pixel-art](../Images/d01ebc0347358d4583b5ade26b841a6f.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![像素艺术](../Images/d01ebc0347358d4583b5ade26b841a6f.png)'
- en: Combine multiple adapters
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组合多个适配器
- en: You can also perform multi-adapter inference where you combine different adapter
    checkpoints for inference.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以执行多适配器推理，其中您将组合不同的适配器检查点进行推理。
- en: Once again, use the [set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)
    method to activate two LoRA checkpoints and specify the weight for how the checkpoints
    should be combined.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法激活两个LoRA检查点，并指定检查点应如何组合的权重。
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that we have set these two adapters, let’s generate an image from the combined
    adapters!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了这两个适配器，让我们从组合适配器生成一幅图像！
- en: LoRA checkpoints in the diffusion community are almost always obtained with
    [DreamBooth](https://huggingface.co/docs/diffusers/main/en/training/dreambooth).
    DreamBooth training often relies on “trigger” words in the input text prompts
    in order for the generation results to look as expected. When you combine multiple
    LoRA checkpoints, it’s important to ensure the trigger words for the corresponding
    LoRA checkpoints are present in the input text prompts.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散社区中的LoRA检查点几乎总是使用[DreamBooth](https://huggingface.co/docs/diffusers/main/en/training/dreambooth)获得的。
    DreamBooth训练通常依赖于输入文本提示中的“触发”词，以便生成结果看起来符合预期。当您组合多个LoRA检查点时，重要的是确保相应LoRA检查点的触发词存在于输入文本提示中。
- en: The trigger words for [CiroN2022/toy-face](https://hf.co/CiroN2022/toy-face)
    and [nerijs/pixel-art-xl](https://hf.co/nerijs/pixel-art-xl) are found in their
    repositories.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 触发词[CiroN2022/toy-face](https://hf.co/CiroN2022/toy-face)和[nerijs/pixel-art-xl](https://hf.co/nerijs/pixel-art-xl)可以在它们的存储库中找到。
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![toy-face-pixel-art](../Images/99de7c335e766f24d86d686716cfbe1c.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![玩具脸像素艺术](../Images/99de7c335e766f24d86d686716cfbe1c.png)'
- en: Impressive! As you can see, the model was able to generate an image that mixes
    the characteristics of both adapters.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 令人印象深刻！正如您所看到的，模型能够生成混合两个适配器特征的图像。
- en: 'If you want to go back to using only one adapter, use the [set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)
    method to activate the `"toy"` adapter:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要回到仅使用一个适配器，请使用[set_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.set_adapters)方法激活`"toy"`适配器：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![toy-face-again](../Images/c176e32c69a0df1e6ed4b22f5a94350b.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![玩具脸再次](../Images/c176e32c69a0df1e6ed4b22f5a94350b.png)'
- en: If you want to switch to only the base model, disable all LoRAs with the [disable_lora()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.disable_lora)
    method.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要切换到仅使用基本模型，请使用[disable_lora()](/docs/diffusers/v0.26.3/en/api/loaders/unet#diffusers.loaders.UNet2DConditionLoadersMixin.disable_lora)方法禁用所有LoRA。
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![no-lora](../Images/13732666737056b846ce11880fe30289.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![no-lora](../Images/13732666737056b846ce11880fe30289.png)'
- en: Monitoring active adapters
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监视活动适配器
- en: 'You have attached multiple adapters in this tutorial, and if you’re feeling
    a bit lost on what adapters have been attached to the pipeline’s components, you
    can easily check the list of active adapters using the [get_active_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_active_adapters)
    method:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，您已经连接了多个适配器，如果您对已连接到管道组件的适配器感到有些迷茫，您可以使用[get_active_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_active_adapters)方法轻松检查活动适配器的列表：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can also get the active adapters of each pipeline component with [get_list_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_list_adapters):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用[get_list_adapters()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.get_list_adapters)获取每个管道组件的活动适配器：
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Fusing adapters into the model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将适配器融合到模型中
- en: You can use PEFT to easily fuse/unfuse multiple adapters directly into the model
    weights (both UNet and text encoder) using the [fuse_lora()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.fuse_lora)
    method, which can lead to a speed-up in inference and lower VRAM usage.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用PEFT轻松地将多个适配器直接融合/解除融合到模型权重中（UNet和文本编码器均可），使用[fuse_lora()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.fuse_lora)方法，这可以加快推理速度并降低VRAM使用率。
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can also fuse some adapters using `adapter_names` for faster generation:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用`adapter_names`来融合一些适配器，以加快生成速度：
- en: '[PRE13]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Saving a pipeline after fusing the adapters
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在融合适配器后保存管道
- en: 'To properly save a pipeline after it’s been loaded with the adapters, it should
    be serialized like so:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载适配器后正确保存管道之前，应该像这样序列化：
- en: '[PRE14]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
