["```py\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npip install .\n```", "```py\ncd examples/textual_inversion\npip install -r requirements.txt\n```", "```py\naccelerate config\n```", "```py\naccelerate config default\n```", "```py\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config()\n```", "```py\naccelerate launch textual_inversion.py \\\n  --gradient_accumulation_steps=4\n```", "```py\n# Load tokenizer\nif args.tokenizer_name:\n    tokenizer = CLIPTokenizer.from_pretrained(args.tokenizer_name)\nelif args.pretrained_model_name_or_path:\n    tokenizer = CLIPTokenizer.from_pretrained(args.pretrained_model_name_or_path, subfolder=\"tokenizer\")\n\n# Load scheduler and models\nnoise_scheduler = DDPMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder=\"scheduler\")\ntext_encoder = CLIPTextModel.from_pretrained(\n    args.pretrained_model_name_or_path, subfolder=\"text_encoder\", revision=args.revision\n)\nvae = AutoencoderKL.from_pretrained(args.pretrained_model_name_or_path, subfolder=\"vae\", revision=args.revision)\nunet = UNet2DConditionModel.from_pretrained(\n    args.pretrained_model_name_or_path, subfolder=\"unet\", revision=args.revision\n)\n```", "```py\ntrain_dataset = TextualInversionDataset(\n    data_root=args.train_data_dir,\n    tokenizer=tokenizer,\n    size=args.resolution,\n    placeholder_token=(\" \".join(tokenizer.convert_ids_to_tokens(placeholder_token_ids))),\n    repeats=args.repeats,\n    learnable_property=args.learnable_property,\n    center_crop=args.center_crop,\n    set=\"train\",\n)\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=args.train_batch_size, shuffle=True, num_workers=args.dataloader_num_workers\n)\n```", "```py\nfrom huggingface_hub import snapshot_download\n\nlocal_dir = \"./cat\"\nsnapshot_download(\n    \"diffusers/cat_toy_example\", local_dir=local_dir, repo_type=\"dataset\", ignore_patterns=\".gitattributes\"\n)\n```", "```py\n--validation_prompt=\"A <cat-toy> train\"\n--num_validation_images=4\n--validation_steps=100\n```", "```py\nexport MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\nexport DATA_DIR=\"./cat\"\n\naccelerate launch textual_inversion.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\n  --train_data_dir=$DATA_DIR \\\n  --learnable_property=\"object\" \\\n  --placeholder_token=\"<cat-toy>\" \\\n  --initializer_token=\"toy\" \\\n  --resolution=512 \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=4 \\\n  --max_train_steps=3000 \\\n  --learning_rate=5.0e-04 \\\n  --scale_lr \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=0 \\\n  --output_dir=\"textual_inversion_cat\" \\\n  --push_to_hub\n```", "```py\nfrom diffusers import StableDiffusionPipeline\nimport torch\n\npipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\npipeline.load_textual_inversion(\"sd-concepts-library/cat-toy\")\nimage = pipeline(\"A <cat-toy> train\", num_inference_steps=50).images[0]\nimage.save(\"cat-train.png\")\n```"]