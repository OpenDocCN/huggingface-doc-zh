# æ–‡æœ¬åˆ°å›¾åƒ

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)

ç¨³å®šæ‰©æ•£æ¨¡å‹æ˜¯ç”±[CompVis](https://github.com/CompVis)ã€[Stability AI](https://stability.ai/)ã€[Runway](https://github.com/runwayml)å’Œ[LAION](https://laion.ai/)çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåˆ›å»ºçš„ã€‚StableDiffusionPipeline èƒ½å¤Ÿæ ¹æ®ä»»ä½•æ–‡æœ¬è¾“å…¥ç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚å®ƒæ˜¯åœ¨ LAION-5B æ•°æ®é›†çš„ 512x512 å›¾åƒä¸Šè®­ç»ƒçš„ã€‚è¯¥æ¨¡å‹ä½¿ç”¨å†»ç»“çš„ CLIP ViT-L/14 æ–‡æœ¬ç¼–ç å™¨æ¥æ ¹æ®æ–‡æœ¬æç¤ºå¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ã€‚è¯¥æ¨¡å‹å…·æœ‰ 860M UNet å’Œ 123M æ–‡æœ¬ç¼–ç å™¨ï¼Œç›¸å¯¹è½»é‡çº§ï¼Œå¯ä»¥åœ¨æ¶ˆè´¹çº§ GPU ä¸Šè¿è¡Œã€‚æ½œåœ¨æ‰©æ•£æ˜¯ç¨³å®šæ‰©æ•£æ„å»ºåœ¨å…¶ä¹‹ä¸Šçš„ç ”ç©¶ã€‚å®ƒæ˜¯ç”± Robin Rombachã€Andreas Blattmannã€Dominik Lorenzã€Patrick Esserã€BjÃ¶rn Ommer åœ¨[High-Resolution Image Synthesis with Latent Diffusion Models](https://huggingface.co/papers/2112.10752)ä¸­æå‡ºçš„ã€‚

è®ºæ–‡æ‘˜è¦ï¼š

*é€šè¿‡å°†å›¾åƒå½¢æˆè¿‡ç¨‹åˆ†è§£ä¸ºé€æ­¥åº”ç”¨å»å™ªè‡ªåŠ¨ç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ï¼ŒDMs åœ¨å›¾åƒæ•°æ®åŠå…¶ä»–é¢†åŸŸå®ç°äº†æœ€å…ˆè¿›çš„åˆæˆç»“æœã€‚æ­¤å¤–ï¼Œå®ƒä»¬çš„å…¬å¼å…è®¸å¼•å¯¼æœºåˆ¶æ¥æ§åˆ¶å›¾åƒç”Ÿæˆè¿‡ç¨‹è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›æ¨¡å‹é€šå¸¸ç›´æ¥åœ¨åƒç´ ç©ºé—´ä¸­æ“ä½œï¼Œä¼˜åŒ–å¼ºå¤§çš„ DMs é€šå¸¸æ¶ˆè€—æ•°ç™¾ä¸ª GPU å¤©ï¼Œç”±äºé¡ºåºè¯„ä¼°ï¼Œæ¨æ–­æˆæœ¬æ˜‚è´µã€‚ä¸ºäº†åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸Šè®­ç»ƒ DM å¹¶ä¿æŒå…¶è´¨é‡å’Œçµæ´»æ€§ï¼Œæˆ‘ä»¬å°†å®ƒä»¬åº”ç”¨äºå¼ºå¤§é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ã€‚ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œåœ¨è¿™ç§è¡¨ç¤ºä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹é¦–æ¬¡å®ç°äº†åœ¨å¤æ‚æ€§å‡å°‘å’Œç»†èŠ‚ä¿ç•™ä¹‹é—´è¾¾åˆ°è¿‘ä¹æœ€ä¼˜ç‚¹ï¼Œæå¤§åœ°æå‡äº†è§†è§‰ä¿çœŸåº¦ã€‚é€šè¿‡åœ¨æ¨¡å‹æ¶æ„ä¸­å¼•å…¥äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œæˆ‘ä»¬å°†æ‰©æ•£æ¨¡å‹è½¬å˜ä¸ºå¼ºå¤§ä¸”çµæ´»çš„ç”Ÿæˆå™¨ï¼Œç”¨äºä¸€èˆ¬æ¡ä»¶è¾“å…¥ï¼Œå¦‚æ–‡æœ¬æˆ–è¾¹ç•Œæ¡†ï¼Œé«˜åˆ†è¾¨ç‡åˆæˆä»¥å·ç§¯æ–¹å¼å˜å¾—å¯èƒ½ã€‚æˆ‘ä»¬çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰åœ¨å›¾åƒä¿®è¡¥å’Œå„ç§ä»»åŠ¡ä¸Šå®ç°äº†æ–°çš„æŠ€æœ¯æ°´å¹³ï¼ŒåŒ…æ‹¬æ— æ¡ä»¶å›¾åƒç”Ÿæˆã€è¯­ä¹‰åœºæ™¯åˆæˆå’Œè¶…åˆ†è¾¨ç‡ï¼ŒåŒæ—¶ä¸åŸºäºåƒç´ çš„ DM ç›¸æ¯”æ˜¾è‘—é™ä½äº†è®¡ç®—è¦æ±‚ã€‚ä»£ç å¯åœ¨[`github.com/CompVis/latent-diffusion`](https://github.com/CompVis/latent-diffusion)ä¸Šæ‰¾åˆ°ã€‚*

ç¡®ä¿æŸ¥çœ‹ç¨³å®šæ‰©æ•£ Tips éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•æ¢ç´¢è°ƒåº¦ç¨‹åºé€Ÿåº¦å’Œè´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œä»¥åŠå¦‚ä½•æœ‰æ•ˆåœ°é‡ç”¨ç®¡é“ç»„ä»¶ï¼

å¦‚æœæ‚¨æœ‰å…´è¶£ä½¿ç”¨å®˜æ–¹æ£€æŸ¥ç‚¹æ‰§è¡Œä»»åŠ¡ï¼Œè¯·æ¢ç´¢[CompVis](https://huggingface.co/CompVis)ã€[Runway](https://huggingface.co/runwayml)å’Œ[Stability AI](https://huggingface.co/stabilityai) Hub ç»„ç»‡ï¼

## StableDiffusionPipeline

### `class diffusers.StableDiffusionPipeline`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L118)

```py
( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: KarrasDiffusionSchedulers safety_checker: StableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor image_encoder: CLIPVisionModelWithProjection = None requires_safety_checker: bool = True )
```

å‚æ•°

+   `vae` (AutoencoderKL) â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºå½¢å¼ã€‚

+   `text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)) â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚

+   `tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)) â€” ä¸€ä¸ª`CLIPTokenizer`ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ã€‚

+   `unet` (UNet2DConditionModel) â€” ä¸€ä¸ª`UNet2DConditionModel`ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚

+   `scheduler` (SchedulerMixin) â€” ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„è°ƒåº¦å™¨ã€‚å¯ä»¥æ˜¯ DDIMSchedulerã€LMSDiscreteScheduler æˆ– PNDMScheduler ä¹‹ä¸€ã€‚

+   `safety_checker` (`StableDiffusionSafetyChecker`) â€” ç”¨äºä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è§†ä¸ºå…·æœ‰æ”»å‡»æ€§æˆ–æœ‰å®³çš„åˆ†ç±»æ¨¡å—ã€‚è¯·å‚è€ƒ[model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)) â€” ä¸€ä¸ª`CLIPImageProcessor`ï¼Œç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾ï¼›ä½œä¸º`å®‰å…¨æ£€æŸ¥å™¨`çš„è¾“å…¥ã€‚

ä½¿ç”¨ç¨³å®šæ‰©æ•£è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æµæ°´çº¿ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª DiffusionPipelineã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚

è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š

+   load_textual_inversion() ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥

+   load_lora_weights() ç”¨äºåŠ è½½ LoRA æƒé‡

+   save_lora_weights() ç”¨äºä¿å­˜ LoRA æƒé‡

+   ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶çš„ from_single_file()

+   load_ip_adapter() ç”¨äºåŠ è½½ IP é€‚é…å™¨

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L803)

```py
( prompt: Union = None height: Optional = None width: Optional = None num_inference_steps: int = 50 timesteps: List = None guidance_scale: float = 7.5 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None ip_adapter_image: Union = None output_type: Optional = 'pil' return_dict: bool = True cross_attention_kwargs: Optional = None guidance_rescale: float = 0.0 clip_skip: Optional = None callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] **kwargs ) â†’ export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple
```

å‚æ•°

+   `prompt` (`str` or `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`prompt_embeds`ã€‚

+   `height` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`self.unet.config.sample_size * self.vae_scale_factor`) â€” ç”Ÿæˆå›¾åƒçš„é«˜åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚

+   `width` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`self.unet.config.sample_size * self.vae_scale_factor`) â€” ç”Ÿæˆå›¾åƒçš„å®½åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚

+   `num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚

+   `timesteps` (`List[int]`, *å¯é€‰*) â€” ç”¨äºä¸æ”¯æŒåœ¨å…¶`set_timesteps`æ–¹æ³•ä¸­ä½¿ç”¨`timesteps`å‚æ•°çš„è°ƒåº¦å™¨ä¸€èµ·ä½¿ç”¨çš„è‡ªå®šä¹‰æ—¶é—´æ­¥ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å°†ä½¿ç”¨ä¼ é€’`num_inference_steps`æ—¶çš„é»˜è®¤è¡Œä¸ºã€‚å¿…é¡»æŒ‰é™åºæ’åˆ—ã€‚

+   `guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“`guidance_scale > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚

+   `negative_prompt` (`str` or `List[str]`, *optional*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶ï¼ˆ`guidance_scale < 1`ï¼‰æ—¶å°†è¢«å¿½ç•¥ã€‚

+   `num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚

+   `eta` (`float`, *optional*, defaults to 0.0) â€” å¯¹åº”äº[DDIM](https://arxiv.org/abs/2010.02502)è®ºæ–‡ä¸­çš„å‚æ•° etaï¼ˆÎ·ï¼‰ã€‚ä»…é€‚ç”¨äº DDIMSchedulerï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚

+   `generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” ç”¨äºä½¿ç”Ÿæˆå…·æœ‰ç¡®å®šæ€§çš„[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚

+   `latents` (`torch.FloatTensor`, *optional*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„é¢„ç”Ÿæˆå™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œ`negative_prompt_embeds`å°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚ip_adapter_image â€” (`PipelineImageInput`, *optional*): å¯é€‰çš„å›¾åƒè¾“å…¥ä»¥ä¸ IP é€‚é…å™¨ä¸€èµ·ä½¿ç”¨ã€‚

+   `output_type` (`str`, *optional*, defaults to `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹©`PIL.Image`æˆ–`np.array`ä¹‹é—´çš„ä¸€ä¸ªã€‚

+   `return_dict` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¿”å› StableDiffusionPipelineOutput è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `cross_attention_kwargs` (`dict`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™`AttentionProcessor`çš„ kwargs å­—å…¸ï¼Œå¦‚[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)ä¸­å®šä¹‰çš„ã€‚

+   `guidance_rescale` (`float`, *optional*, defaults to 0.0) â€” æ¥è‡ª[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)çš„æŒ‡å¯¼é‡ç¼©æ”¾å› å­ã€‚æŒ‡å¯¼é‡ç¼©æ”¾å› å­åº”åœ¨ä½¿ç”¨é›¶ç»ˆç«¯ SNR æ—¶ä¿®å¤è¿‡æ›å…‰é—®é¢˜ã€‚

+   `clip_skip` (`int`, *optional*) â€” åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦ä» CLIP è·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º 1 æ„å‘³ç€å°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚

+   `callback_on_step_end` (`Callable`, *optional*) â€” åœ¨æ¨æ–­è¿‡ç¨‹ä¸­æ¯ä¸ªå»å™ªæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`ã€‚`callback_kwargs`å°†åŒ…æ‹¬ç”±`callback_on_step_end_tensor_inputs`æŒ‡å®šçš„æ‰€æœ‰å¼ é‡çš„åˆ—è¡¨ã€‚

+   `callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” `callback_on_step_end`å‡½æ•°çš„å¼ é‡è¾“å…¥åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æŒ‡å®šçš„å¼ é‡å°†ä½œä¸º`callback_kwargs`å‚æ•°ä¼ é€’ã€‚æ‚¨åªèƒ½åŒ…æ‹¬åœ¨æ‚¨çš„ç®¡é“ç±»çš„`._callback_tensor_inputs`å±æ€§ä¸­åˆ—å‡ºçš„å˜é‡ã€‚

è¿”å›

StableDiffusionPipelineOutput æˆ–`tuple`

å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å› StableDiffusionPipelineOutputï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª`tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«â€œä¸é€‚åˆå·¥ä½œâ€ï¼ˆnsfwï¼‰å†…å®¹çš„ç”Ÿæˆå›¾åƒçš„`bool`åˆ—è¡¨ã€‚

ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
>>> pipe = pipe.to("cuda")

>>> prompt = "a photo of an astronaut riding a horse on mars"
>>> image = pipe(prompt).images[0]
```

#### `enable_attention_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)

```py
( slice_size: Union = 'auto' )
```

å‚æ•°

+   `slice_size`ï¼ˆ`str`æˆ–`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"auto"`ï¼‰â€” å½“ä¸º`"auto"`æ—¶ï¼Œå°†è¾“å…¥åˆ†æˆæ³¨æ„åŠ›å¤´çš„ä¸€åŠï¼Œå› æ­¤æ³¨æ„åŠ›å°†åœ¨ä¸¤ä¸ªæ­¥éª¤ä¸­è®¡ç®—ã€‚å¦‚æœä¸º`"max"`ï¼Œå°†é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥èŠ‚çœæœ€å¤§æ•°é‡çš„å†…å­˜ã€‚å¦‚æœæä¾›äº†ä¸€ä¸ªæ•°å­—ï¼Œåˆ™ä½¿ç”¨`attention_head_dim // slice_size`ä¸ªåˆ‡ç‰‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`attention_head_dim`å¿…é¡»æ˜¯`slice_size`çš„å€æ•°ã€‚

å¯ç”¨åˆ‡ç‰‡çš„æ³¨æ„åŠ›è®¡ç®—ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç‰‡æ®µï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—å°†æŒ‰é¡ºåºåœ¨æ¯ä¸ªå¤´ä¸Šæ‰§è¡Œã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜ä»¥æ¢å–ä¸€ç‚¹é€Ÿåº¦é™ä½å¾ˆæœ‰ç”¨ã€‚

âš ï¸ å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 æˆ– xFormers çš„`scaled_dot_product_attention`ï¼ˆSDPAï¼‰ï¼Œè¯·ä¸è¦å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ã€‚è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸é«˜æ•ˆï¼Œå› æ­¤æ‚¨ä¸éœ€è¦å¯ç”¨æ­¤åŠŸèƒ½ã€‚å¦‚æœæ‚¨åœ¨ SDPA æˆ– xFormers ä¸Šå¯ç”¨äº†æ³¨æ„åŠ›åˆ‡ç‰‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡å‡é€Ÿï¼

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> pipe = StableDiffusionPipeline.from_pretrained(
...     "runwayml/stable-diffusion-v1-5",
...     torch_dtype=torch.float16,
...     use_safetensors=True,
... )

>>> prompt = "a photo of an astronaut riding a horse on mars"
>>> pipe.enable_attention_slicing()
>>> image = pipe(prompt).images[0]
```

#### `disable_attention_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)

```py
( )
```

ç¦ç”¨åˆ‡ç‰‡çš„æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚

#### `enable_vae_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L251)

```py
( )
```

å¯ç”¨åˆ‡ç‰‡çš„ VAE è§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†åˆ†å‰²è¾“å…¥å¼ é‡ä»¥åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç ã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜å¹¶å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°å¾ˆæœ‰ç”¨ã€‚

#### `disable_vae_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L258)

```py
( )
```

ç¦ç”¨åˆ‡ç‰‡çš„ VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_slicing`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

#### `enable_xformers_memory_efficient_attention`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)

```py
( attention_op: Optional = None )
```

å‚æ•°

+   `attention_op`ï¼ˆ`Callable`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œ`op`å‚æ•°ä¼ é€’ç»™[xFormers çš„`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)å‡½æ•°çš„é»˜è®¤`None`æ“ä½œç¬¦ã€‚

å¯ç”¨[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°è¾ƒä½çš„ GPU å†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶åœ¨æ¨æ–­æœŸé—´å¯èƒ½åŠ é€Ÿã€‚è®­ç»ƒæœŸé—´çš„åŠ é€Ÿä¸è¢«ä¿è¯ã€‚

âš ï¸ å½“å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import DiffusionPipeline
>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp

>>> pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16)
>>> pipe = pipe.to("cuda")
>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)
>>> # Workaround for not accepting attention shape using VAE for Flash Attention
>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)
```

#### `disable_xformers_memory_efficient_attention`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)

```py
( )
```

ç¦ç”¨[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚

#### `enable_vae_tiling`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L265)

```py
( )
```

å¯ç”¨åˆ†å— VAE è§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆå¤šä¸ªå—ï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚

#### `disable_vae_tiling`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L273)

```py
( )
```

ç¦ç”¨åˆ†å— VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº† `enable_vae_tiling`ï¼Œæ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

#### `load_textual_inversion`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)

```py
( pretrained_model_name_or_path: Union token: Union = None tokenizer: Optional = None text_encoder: Optional = None **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str` æˆ– `os.PathLike` æˆ– `List[str or os.PathLike]` æˆ– `Dict` æˆ– `List[Dict]`) â€” å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å®ƒä»¬çš„åˆ—è¡¨ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ Hub ä¸Šæ‰˜ç®¡çš„ *æ¨¡å‹ ID*ï¼ˆä¾‹å¦‚ `sd-concepts-library/low-poly-hd-logos-icons`ï¼‰ã€‚

    +   ä¸€ä¸ªæŒ‡å‘åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„ *ç›®å½•* çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./my_text_inversion_directory/`ï¼‰ã€‚

    +   ä¸€ä¸ªæŒ‡å‘åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„ *æ–‡ä»¶* çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./my_text_inversions.pt`ï¼‰ã€‚

    +   ä¸€ä¸ª [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)ã€‚

+   `token` (`str` æˆ– `List[str]`, *optional*) â€” è¦†ç›–ç”¨äºæ–‡æœ¬åè½¬æƒé‡çš„ä»¤ç‰Œã€‚å¦‚æœ `pretrained_model_name_or_path` æ˜¯åˆ—è¡¨ï¼Œåˆ™ `token` ä¹Ÿå¿…é¡»æ˜¯ç›¸åŒé•¿åº¦çš„åˆ—è¡¨ã€‚

+   `text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel), *optional*) â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨ self.tokenizerã€‚

+   `tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer), *optional*) â€” ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„ `CLIPTokenizer`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨ self.tokenizerã€‚

+   `weight_name` (`str`, *optional*) â€” è‡ªå®šä¹‰æƒé‡æ–‡ä»¶çš„åç§°ã€‚åº”åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ä½¿ç”¨ï¼š

    +   ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥ ğŸ¤— Diffusers æ ¼å¼ä¿å­˜ï¼Œä½†æ˜¯ä¿å­˜åœ¨ç‰¹å®šæƒé‡åç§°ä¸‹ï¼Œä¾‹å¦‚ `text_inv.bin`ã€‚

    +   ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥ Automatic1111 æ ¼å¼ä¿å­˜ã€‚

+   `cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ç¼“å­˜çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `force_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚

+   `proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†æœåŠ¡å™¨åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `local_files_only` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œæ¨¡å‹å°†ä¸ä¼šä» Hub ä¸‹è½½ã€‚

+   `token` (`str` æˆ– *bool*, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP ä»¤ç‰Œçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œåˆ™ä½¿ç”¨ä» `diffusers-cli login` ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚

+   `revision` (`str`, *optional*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID æˆ– Git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

+   `subfolder` (`str`, *optional*, é»˜è®¤ä¸º `""`) â€” æ¨¡å‹æ–‡ä»¶åœ¨ Hub æˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚

+   `mirror`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœæ‚¨åœ¨ä¸‹è½½ä¸­å›½çš„æ¨¡å‹æ—¶é‡åˆ°å¯è®¿é—®æ€§é—®é¢˜ï¼Œè¯·ä½¿ç”¨é•œåƒæºã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚

å°†æ–‡æœ¬åè½¬åµŒå…¥åŠ è½½åˆ° StableDiffusionPipeline çš„æ–‡æœ¬ç¼–ç å™¨ä¸­ï¼ˆæ”¯æŒğŸ¤— Diffusers å’Œ Automatic1111 æ ¼å¼ï¼‰ã€‚

ç¤ºä¾‹ï¼š

è¦åœ¨ğŸ¤— Diffusers æ ¼å¼ä¸­åŠ è½½æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼š

```py
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

pipe.load_textual_inversion("sd-concepts-library/cat-toy")

prompt = "A <cat-toy> backpack"

image = pipe(prompt, num_inference_steps=50).images[0]
image.save("cat-backpack.png")
```

è¦åŠ è½½ Automatic1111 æ ¼å¼çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼Œè¯·ç¡®ä¿é¦–å…ˆä¸‹è½½å‘é‡ï¼ˆä¾‹å¦‚ä»[civitAI](https://civitai.com/models/3036?modelVersionId=9857)ï¼‰ç„¶ååŠ è½½å‘é‡

æœ¬åœ°ï¼š

```py
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

pipe.load_textual_inversion("./charturnerv2.pt", token="charturnerv2")

prompt = "charturnerv2, multiple views of the same character in the same outfit, a character turnaround of a woman wearing a black jacket and red shirt, best quality, intricate details."

image = pipe(prompt, num_inference_steps=50).images[0]
image.save("character.png")
```

#### `from_single_file`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L141)

```py
( pretrained_model_link_or_path **kwargs )
```

å‚æ•°

+   `pretrained_model_link_or_path`ï¼ˆ`str`æˆ–`os.PathLike`ï¼Œ*å¯é€‰*ï¼‰â€” å¯ä»¥æ˜¯ï¼š

    +   åœ¨ Hub ä¸Šé“¾æ¥åˆ°`.ckpt`æ–‡ä»¶ï¼ˆä¾‹å¦‚`"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`ï¼‰ã€‚

    +   åŒ…å«æ‰€æœ‰ç®¡é“æƒé‡çš„*æ–‡ä»¶*è·¯å¾„ã€‚

+   `torch_dtype`ï¼ˆ`str`æˆ–`torch.dtype`ï¼Œ*å¯é€‰*ï¼‰â€” è¦†ç›–é»˜è®¤çš„`torch.dtype`å¹¶ä½¿ç”¨å¦ä¸€ç§ dtype åŠ è½½æ¨¡å‹ã€‚

+   `force_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `cache_dir`ï¼ˆ`Union[str, os.PathLike]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®çš„ç¼“å­˜è·¯å¾„ï¼Œå¦‚æœæœªä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `resume_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™åˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚

+   `proxies`ï¼ˆ`Dict[str, str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `local_files_only`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ä¸ä¼šä» Hub ä¸‹è½½æ¨¡å‹ã€‚

+   `token`ï¼ˆ`str`æˆ–*bool*ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP ä»¤ç‰Œçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚

+   `revision`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"main"`ï¼‰â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID æˆ– Git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

+   `use_safetensors`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`None`ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`None`ï¼Œåˆ™åœ¨å¯ç”¨æ—¶ä¸‹è½½ safetensors æƒé‡**å¹¶ä¸”**å¦‚æœå·²å®‰è£… safetensors åº“ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™å¼ºåˆ¶ä» safetensors æƒé‡åŠ è½½æ¨¡å‹ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œåˆ™ä¸åŠ è½½ safetensors æƒé‡ã€‚

ä»ä¿å­˜åœ¨`.ckpt`æˆ–`.safetensors`æ ¼å¼ä¸­çš„é¢„è®­ç»ƒç®¡é“æƒé‡å®ä¾‹åŒ– DiffusionPipelineã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç®¡é“è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆ`model.eval()`ï¼‰ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from diffusers import StableDiffusionPipeline

>>> # Download pipeline from huggingface.co and cache.
>>> pipeline = StableDiffusionPipeline.from_single_file(
...     "https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors"
... )

>>> # Download pipeline from local file
>>> # file is downloaded under ./v1-5-pruned-emaonly.ckpt
>>> pipeline = StableDiffusionPipeline.from_single_file("./v1-5-pruned-emaonly")

>>> # Enable float16 and move to GPU
>>> pipeline = StableDiffusionPipeline.from_single_file(
...     "https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.ckpt",
...     torch_dtype=torch.float16,
... )
>>> pipeline.to("cuda")
```

#### `load_lora_weights`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)

```py
( pretrained_model_name_or_path_or_dict: Union adapter_name = None **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path_or_dict`ï¼ˆ`str`æˆ–`os.PathLike`æˆ–`dict`ï¼‰â€” å‚è§ lora_state_dict()ã€‚

+   `kwargs`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€” å‚è§ lora_state_dict()ã€‚

+   `adapter_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå¼•ç”¨åŠ è½½çš„é€‚é…å™¨æ¨¡å‹çš„é€‚é…å™¨åç§°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨`default_{i}`ï¼Œå…¶ä¸­ i æ˜¯è¦åŠ è½½çš„é€‚é…å™¨æ€»æ•°ã€‚

å°†åœ¨ `pretrained_model_name_or_path_or_dict` ä¸­æŒ‡å®šçš„ LoRA æƒé‡åŠ è½½åˆ° `self.unet` å’Œ `self.text_encoder` ä¸­ã€‚

æ‰€æœ‰ kwargs éƒ½å°†è½¬å‘åˆ° `self.lora_state_dict`ã€‚

æŸ¥çœ‹ lora_state_dict() ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½çŠ¶æ€å­—å…¸çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

æŸ¥çœ‹ load_lora_into_unet() ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ° `self.unet` ä¸­çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

æŸ¥çœ‹ load_lora_into_text_encoder() ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ° `self.text_encoder` ä¸­çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

#### `save_lora_weights`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)

```py
( save_directory: Union unet_lora_layers: Dict = None text_encoder_lora_layers: Dict = None transformer_lora_layers: Dict = None is_main_process: bool = True weight_name: str = None save_function: Callable = None safe_serialization: bool = True )
```

å‚æ•°

+   `save_directory` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜ LoRA å‚æ•°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºè¯¥ç›®å½•ã€‚

+   `unet_lora_layers` (`Dict[str, torch.nn.Module]` æˆ– `Dict[str, torch.Tensor]`) â€” ä¸ `unet` å¯¹åº”çš„ LoRA å±‚çš„çŠ¶æ€å­—å…¸ã€‚

+   `text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` æˆ– `Dict[str, torch.Tensor]`) â€” ä¸ `text_encoder` å¯¹åº”çš„ LoRA å±‚çš„çŠ¶æ€å­—å…¸ã€‚å¿…é¡»æ˜¾å¼ä¼ é€’æ–‡æœ¬ç¼–ç å™¨ LoRA çŠ¶æ€å­—å…¸ï¼Œå› ä¸ºå®ƒæ¥è‡ª ğŸ¤— Transformersã€‚

+   `is_main_process` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½® `is_main_process=True`ï¼Œä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚

+   `save_function` (`Callable`) â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢ `torch.save` æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡ `DIFFUSERS_SAVE_MODE` è¿›è¡Œé…ç½®ã€‚

+   `safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors` ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„ PyTorch æ–¹æ³•ä¸ `pickle`ã€‚

ä¿å­˜ä¸ UNet å’Œæ–‡æœ¬ç¼–ç å™¨å¯¹åº”çš„ LoRA å‚æ•°ã€‚

#### `disable_freeu`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L678)

```py
( )
```

å¦‚æœå·²å¯ç”¨ï¼Œåˆ™ç¦ç”¨ FreeU æœºåˆ¶ã€‚

#### `enable_freeu`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L656)

```py
( s1: float s2: float b1: float b2: float )
```

å‚æ•°

+   `s1` (`float`) â€” ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚

+   `s2` (`float`) â€” ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚

+   `b1` (`float`) â€” ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚

+   `b2` (`float`) â€” ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚

å¯ç”¨ FreeU æœºåˆ¶ï¼Œå¦‚ [`arxiv.org/abs/2309.11497`](https://arxiv.org/abs/2309.11497) ä¸­æ‰€è¿°ã€‚

ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬åº”ç”¨çš„é˜¶æ®µã€‚

è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion v1ã€v2 å’Œ Stable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚

#### `encode_prompt`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L312)

```py
( prompt device num_images_per_prompt do_classifier_free_guidance negative_prompt = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None lora_scale: Optional = None clip_skip: Optional = None )
```

å‚æ•°

+   `prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” è¦ç¼–ç çš„æç¤ºè®¾å¤‡ â€” (`torch.device`): torch è®¾å¤‡

+   `num_images_per_prompt` (`int`) â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡

+   `do_classifier_free_guidance` (`bool`) â€” æ˜¯å¦ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼

+   `negative_prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸ç”¨æ¥å¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨å¼•å¯¼æ—¶è¢«å¿½ç•¥ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™è¢«å¿½ç•¥ï¼‰ã€‚

+   `prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚

+   `negative_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆ`negative_prompt_embeds`ã€‚

+   `lora_scale`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœåŠ è½½äº† LoRA å±‚ï¼Œåˆ™å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰ LoRA å±‚çš„ LoRA æ¯”ä¾‹ã€‚

+   `clip_skip`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€” ä» CLIP ä¸­è·³è¿‡çš„å±‚æ•°ï¼Œç”¨äºè®¡ç®—æç¤ºåµŒå…¥ã€‚å€¼ä¸º 1 æ„å‘³ç€å°†ä½¿ç”¨é¢„æœ€ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚

å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨çš„éšè—çŠ¶æ€ã€‚

#### `fuse_qkv_projections`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L683)

```py
( unet: bool = True vae: bool = True )
```

å‚æ•°

+   `unet`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹ UNet åº”ç”¨èåˆã€‚

+   `vae`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹ VAE åº”ç”¨èåˆã€‚

å¯ç”¨èåˆçš„ QKV æŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆå³æŸ¥è¯¢ã€é”®ã€å€¼ï¼‰éƒ½è¢«èåˆã€‚å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚

æ­¤ API ä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚

#### `get_guidance_scale_embedding`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L744)

```py
( w embedding_dim = 512 dtype = torch.float32 ) â†’ export const metadata = 'undefined';torch.FloatTensor
```

å‚æ•°

+   `timesteps`ï¼ˆ`torch.Tensor`ï¼‰â€” åœ¨è¿™äº›æ—¶é—´æ­¥ç”ŸæˆåµŒå…¥å‘é‡

+   `embedding_dim`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 512ï¼‰â€” è¦ç”Ÿæˆçš„åµŒå…¥çš„ç»´åº¦ dtype â€” ç”Ÿæˆçš„åµŒå…¥çš„æ•°æ®ç±»å‹ã€‚

è¿”å›

`torch.FloatTensor`

å½¢çŠ¶ä¸º`(len(timesteps), embedding_dim)`çš„åµŒå…¥å‘é‡

å‚è§[`github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298`](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)

#### `unfuse_qkv_projections`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L715)

```py
( unet: bool = True vae: bool = True )
```

å‚æ•°

+   `unet`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹ UNet åº”ç”¨èåˆã€‚

+   `vae`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” å¯¹ VAE åº”ç”¨èåˆã€‚

å¦‚æœå¯ç”¨ï¼Œç¦ç”¨ QKV æŠ•å½±èåˆã€‚

æ­¤ API ä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚

## StableDiffusionPipelineOutput

### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)

```py
( images: Union nsfw_content_detected: Optional )
```

å‚æ•°

+   `images`ï¼ˆ`List[PIL.Image.Image]`æˆ–`np.ndarray`ï¼‰â€” é•¿åº¦ä¸º`batch_size`çš„å»å™ª PIL å›¾åƒåˆ—è¡¨æˆ–å½¢çŠ¶ä¸º`(batch_size, height, width, num_channels)`çš„ NumPy æ•°ç»„ã€‚

+   `nsfw_content_detected`ï¼ˆ`List[bool]`ï¼‰â€” è¡¨ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰çš„åˆ—è¡¨ï¼Œå¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º`None`ã€‚

ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚

## FlaxStableDiffusionPipeline

### `class diffusers.FlaxStableDiffusionPipeline`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L81)

```py
( vae: FlaxAutoencoderKL text_encoder: FlaxCLIPTextModel tokenizer: CLIPTokenizer unet: FlaxUNet2DConditionModel scheduler: Union safety_checker: FlaxStableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor dtype: dtype = <class 'jax.numpy.float32'> )
```

å‚æ•°

+   `vae`ï¼ˆFlaxAutoencoderKLï¼‰â€” å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚

+   `text_encoder` ([FlaxCLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPTextModel)) â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚

+   `tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)) â€” ä¸€ä¸ªç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–çš„`CLIPTokenizer`ã€‚

+   `unet` (FlaxUNet2DConditionModel) â€” ä¸€ä¸ªç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨å˜é‡çš„`FlaxUNet2DConditionModel`ã€‚

+   `scheduler` (SchedulerMixin) â€” ä¸`unet`ç»“åˆä½¿ç”¨çš„è°ƒåº¦å™¨ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨å˜é‡ã€‚å¯ä»¥æ˜¯`FlaxDDIMScheduler`ã€`FlaxLMSDiscreteScheduler`ã€`FlaxPNDMScheduler`æˆ–`FlaxDPMSolverMultistepScheduler`ä¹‹ä¸€ã€‚

+   `safety_checker` (`FlaxStableDiffusionSafetyChecker`) â€” ä¸€ä¸ªåˆ†ç±»æ¨¡å—ï¼Œç”¨äºä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è®¤ä¸ºæ˜¯å†’çŠ¯æˆ–æœ‰å®³çš„ã€‚è¯·å‚è€ƒ[model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)) â€” ä¸€ä¸ªç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾çš„`CLIPImageProcessor`ï¼›ä½œä¸º`å®‰å…¨æ£€æŸ¥å™¨`çš„è¾“å…¥ã€‚

ä½¿ç”¨ç¨³å®šæ‰©æ•£è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„åŸºäº Flax çš„ç®¡é“ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª FlaxDiffusionPipelineã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py#L310)

```py
( prompt_ids: array params: Union prng_seed: Array num_inference_steps: int = 50 height: Optional = None width: Optional = None guidance_scale: Union = 7.5 latents: Array = None neg_prompt_ids: Array = None return_dict: bool = True jit: bool = False ) â†’ export const metadata = 'undefined';FlaxStableDiffusionPipelineOutput or tuple
```

å‚æ•°

+   `prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚

+   `height` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.unet.config.sample_size * self.vae_scale_factor`) â€” ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚

+   `width` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.unet.config.sample_size * self.vae_scale_factor`) â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚

+   `num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚

+   `guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`ç´§å¯†ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“`guidance_scale > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚

+   `latents` (`jnp.ndarray`, *å¯é€‰*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é¢„å…ˆç”Ÿæˆçš„å˜ˆæ‚æ½œåœ¨å˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ä»¥ç”¨æ¥è°ƒæ•´ç›¸åŒç”Ÿæˆä¸ä¸åŒæç¤ºçš„ç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é€šè¿‡ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡Œé‡‡æ ·ç”Ÿæˆä¸€ä¸ªæ½œåœ¨å˜é‡æ•°ç»„ã€‚

+   `jit` (`bool`, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿è¡Œç”Ÿæˆå’Œå®‰å…¨è¯„åˆ†å‡½æ•°çš„`pmap`ç‰ˆæœ¬ã€‚

    è¿™ä¸ªå‚æ•°å­˜åœ¨æ˜¯å› ä¸º`__call__`ç›®å‰è¿˜ä¸èƒ½å®Œå…¨è¿›è¡Œ pmapã€‚å®ƒå°†åœ¨å°†æ¥çš„ç‰ˆæœ¬ä¸­è¢«ç§»é™¤ã€‚

+   `return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª FlaxStableDiffusionPipelineOutput è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚

è¿”å›

FlaxStableDiffusionPipelineOutput æˆ– `tuple`

å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å› FlaxStableDiffusionPipelineOutputï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª`tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ã€‚

ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import jax
>>> import numpy as np
>>> from flax.jax_utils import replicate
>>> from flax.training.common_utils import shard

>>> from diffusers import FlaxStableDiffusionPipeline

>>> pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(
...     "runwayml/stable-diffusion-v1-5", revision="bf16", dtype=jax.numpy.bfloat16
... )

>>> prompt = "a photo of an astronaut riding a horse on mars"

>>> prng_seed = jax.random.PRNGKey(0)
>>> num_inference_steps = 50

>>> num_samples = jax.device_count()
>>> prompt = num_samples * [prompt]
>>> prompt_ids = pipeline.prepare_inputs(prompt)
# shard inputs and rng

>>> params = replicate(params)
>>> prng_seed = jax.random.split(prng_seed, jax.device_count())
>>> prompt_ids = shard(prompt_ids)

>>> images = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images
>>> images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
```

## FlaxStableDiffusionPipelineOutput

### `class diffusers.pipelines.stable_diffusion.FlaxStableDiffusionPipelineOutput`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L31)

```py
( images: ndarray nsfw_content_detected: List )
```

å‚æ•°

+   `images` (`np.ndarray`) â€” å½¢çŠ¶ä¸º`(batch_size, height, width, num_channels)`çš„å»å™ªå›¾åƒæ•°ç»„ã€‚

+   `nsfw_content_detected` (`List[bool]`) â€” åˆ—è¡¨æŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ï¼Œæˆ–è€…å¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º`None`ã€‚

Flax åŸºç¡€ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚

#### `replace`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)

```py
( **updates )
```

â€œè¿”å›ä¸€ä¸ªç”¨æ–°å€¼æ›¿æ¢æŒ‡å®šå­—æ®µçš„æ–°å¯¹è±¡ã€‚
