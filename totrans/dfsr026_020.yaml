- en: Load different Stable Diffusion formats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/other-formats](https://huggingface.co/docs/diffusers/using-diffusers/other-formats)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/177.2fae9505.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/DocNotebookDropdown.5fa27ace.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion models are available in different formats depending on the
    framework theyâ€™re trained and saved with, and where you download them from. Converting
    these formats for use in ðŸ¤— Diffusers allows you to use all the features supported
    by the library, such as [using different schedulers](schedulers) for inference,
    [building your custom pipeline](write_own_pipeline), and a variety of techniques
    and methods for [optimizing inference speed](../optimization/opt_overview).
  prefs: []
  type: TYPE_NORMAL
- en: We highly recommend using the `.safetensors` format because it is more secure
    than traditional pickled files which are vulnerable and can be exploited to execute
    any code on your machine (learn more in the [Load safetensors](using_safetensors)
    guide).
  prefs: []
  type: TYPE_NORMAL
- en: This guide will show you how to convert other Stable Diffusion formats to be
    compatible with ðŸ¤— Diffusers.
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch .ckpt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The checkpoint - or `.ckpt` - format is commonly used to store and save models.
    The `.ckpt` file contains the entire model and is typically several GBs in size.
    While you can load and use a `.ckpt` file directly with the [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    method, it is generally better to convert the `.ckpt` file to ðŸ¤— Diffusers so both
    formats are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options for converting a `.ckpt` file: use a Space to convert
    the checkpoint or convert the `.ckpt` file with a script.'
  prefs: []
  type: TYPE_NORMAL
- en: Convert with a Space
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The easiest and most convenient way to convert a `.ckpt` file is to use the
    [SD to Diffusers](https://huggingface.co/spaces/diffusers/sd-to-diffusers) Space.
    You can follow the instructions on the Space to convert the `.ckpt` file.
  prefs: []
  type: TYPE_NORMAL
- en: This approach works well for basic models, but it may struggle with more customized
    models. Youâ€™ll know the Space failed if it returns an empty pull request or error.
    In this case, you can try converting the `.ckpt` file with a script.
  prefs: []
  type: TYPE_NORMAL
- en: Convert with a script
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ðŸ¤— Diffusers provides a [conversion script](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py)
    for converting `.ckpt` files. This approach is more reliable than the Space above.
  prefs: []
  type: TYPE_NORMAL
- en: Before you start, make sure you have a local clone of ðŸ¤— Diffusers to run the
    script and log in to your Hugging Face account so you can open pull requests and
    push your converted model to the Hub.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To use the script:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Git clone the repository containing the `.ckpt` file you want to convert. For
    this example, letâ€™s convert this [TemporalNet](https://huggingface.co/CiaraRowles/TemporalNet)
    `.ckpt` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Open a pull request on the repository where youâ€™re converting the checkpoint
    from:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several input arguments to configure in the conversion script, but
    the most important ones are:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`checkpoint_path`: the path to the `.ckpt` file to convert.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_config_file`: a YAML file defining the configuration of the original
    architecture. If you canâ€™t find this file, try searching for the YAML file in
    the GitHub repository where you found the `.ckpt` file.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dump_path`: the path to the converted model.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, you can take the `cldm_v15.yaml` file from the [ControlNet](https://github.com/lllyasviel/ControlNet/tree/main/models)
    repository because the TemporalNet model is a Stable Diffusion v1.5 and ControlNet
    model.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now you can run the script to convert the `.ckpt` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Once the conversion is done, upload your converted model and test out the resulting
    [pull request](https://huggingface.co/CiaraRowles/TemporalNet/discussions/13)!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Keras .pb or .h5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ðŸ§ª This is an experimental feature. Only Stable Diffusion v1 checkpoints are
    supported by the Convert KerasCV Space at the moment.
  prefs: []
  type: TYPE_NORMAL
- en: '[KerasCV](https://keras.io/keras_cv/) supports training for [Stable Diffusion](https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/stable_diffusion)
    v1 and v2\. However, it offers limited support for experimenting with Stable Diffusion
    models for inference and deployment whereas ðŸ¤— Diffusers has a more complete set
    of features for this purpose, such as different [noise schedulers](https://huggingface.co/docs/diffusers/using-diffusers/schedulers),
    [flash attention](https://huggingface.co/docs/diffusers/optimization/xformers),
    and [other optimization techniques](https://huggingface.co/docs/diffusers/optimization/fp16).'
  prefs: []
  type: TYPE_NORMAL
- en: The [Convert KerasCV](https://huggingface.co/spaces/sayakpaul/convert-kerascv-sd-diffusers)
    Space converts `.pb` or `.h5` files to PyTorch, and then wraps them in a [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    so it is ready for inference. The converted checkpoint is stored in a repository
    on the Hugging Face Hub.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, letâ€™s convert the [`sayakpaul/textual-inversion-kerasio`](https://huggingface.co/sayakpaul/textual-inversion-kerasio/tree/main)
    checkpoint which was trained with Textual Inversion. It uses the special token
    `<my-funny-cat>` to personalize images with cats.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Convert KerasCV Space allows you to input the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Your Hugging Face token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paths to download the UNet and text encoder weights from. Depending on how the
    model was trained, you donâ€™t necessarily need to provide the paths to both the
    UNet and text encoder. For example, Textual Inversion only requires the embeddings
    from the text encoder and a text-to-image model only requires the UNet weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Placeholder token is only applicable for textual inversion models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `output_repo_prefix` is the name of the repository where the converted model
    is stored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click the **Submit** button to automatically convert the KerasCV checkpoint!
    Once the checkpoint is successfully converted, youâ€™ll see a link to the new repository
    containing the converted checkpoint. Follow the link to the new repository, and
    youâ€™ll see the Convert KerasCV Space generated a model card with an inference
    widget to try out the converted model.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you prefer to run inference with code, click on the **Use in Diffusers**
    button in the upper right corner of the model card to copy and paste the code
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can generate an image like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A1111 LoRA files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) (A1111)
    is a popular web UI for Stable Diffusion that supports model sharing platforms
    like [Civitai](https://civitai.com/). Models trained with the Low-Rank Adaptation
    (LoRA) technique are especially popular because theyâ€™re fast to train and have
    a much smaller file size than a fully finetuned model. ðŸ¤— Diffusers supports loading
    A1111 LoRA checkpoints with [load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Download a LoRA checkpoint from Civitai; this example uses the [Blueprintify
    SD XL 1.0](https://civitai.com/models/150986/blueprintify-sd-xl-10) checkpoint,
    but feel free to try out any LoRA checkpoint!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the LoRA checkpoint into the pipeline with the [load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can use the pipeline to generate images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cee84d318d0e1d6c11ae7b5a6f49a8ca.png)'
  prefs: []
  type: TYPE_IMG
