["```py\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npip install .\n```", "```py\ncd examples/consistency_distillation\npip install -r requirements.txt\n```", "```py\naccelerate config\n```", "```py\naccelerate config default\n```", "```py\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config()\n```", "```py\naccelerate launch train_lcm_distill_sd_wds.py \\\n  --mixed_precision=\"fp16\"\n```", "```py\ndef transform(example):\n    image = example[\"image\"]\n    image = TF.resize(image, resolution, interpolation=transforms.InterpolationMode.BILINEAR)\n\n    c_top, c_left, _, _ = transforms.RandomCrop.get_params(image, output_size=(resolution, resolution))\n    image = TF.crop(image, c_top, c_left, resolution, resolution)\n    image = TF.to_tensor(image)\n    image = TF.normalize(image, [0.5], [0.5])\n\n    example[\"image\"] = image\n    return example\n```", "```py\nprocessing_pipeline = [\n    wds.decode(\"pil\", handler=wds.ignore_and_continue),\n    wds.rename(image=\"jpg;png;jpeg;webp\", text=\"text;txt;caption\", handler=wds.warn_and_continue),\n    wds.map(filter_keys({\"image\", \"text\"})),\n    wds.map(transform),\n    wds.to_tuple(\"image\", \"text\"),\n]\n```", "```py\nteacher_unet = UNet2DConditionModel.from_pretrained(\n    args.pretrained_teacher_model, subfolder=\"unet\", revision=args.teacher_revision\n)\n\nunet = UNet2DConditionModel(**teacher_unet.config)\nunet.load_state_dict(teacher_unet.state_dict(), strict=False)\nunet.train()\n```", "```py\noptimizer = optimizer_class(\n    unet.parameters(),\n    lr=args.learning_rate,\n    betas=(args.adam_beta1, args.adam_beta2),\n    weight_decay=args.adam_weight_decay,\n    eps=args.adam_epsilon,\n)\n```", "```py\ndataset = Text2ImageDataset(\n    train_shards_path_or_url=args.train_shards_path_or_url,\n    num_train_examples=args.max_train_samples,\n    per_gpu_batch_size=args.train_batch_size,\n    global_batch_size=args.train_batch_size * accelerator.num_processes,\n    num_workers=args.dataloader_num_workers,\n    resolution=args.resolution,\n    shuffle_buffer_size=1000,\n    pin_memory=True,\n    persistent_workers=True,\n)\ntrain_dataloader = dataset.train_dataloader\n```", "```py\npred_x_0 = predicted_origin(\n    noise_pred,\n    start_timesteps,\n    noisy_model_input,\n    noise_scheduler.config.prediction_type,\n    alpha_schedule,\n    sigma_schedule,\n)\n\nmodel_pred = c_skip_start * noisy_model_input + c_out_start * pred_x_0\n```", "```py\nif args.loss_type == \"l2\":\n    loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\nelif args.loss_type == \"huber\":\n    loss = torch.mean(\n        torch.sqrt((model_pred.float() - target.float()) ** 2 + args.huber_c**2) - args.huber_c\n    )\n```", "```py\nexport MODEL_DIR=\"runwayml/stable-diffusion-v1-5\"\nexport OUTPUT_DIR=\"path/to/saved/model\"\n\naccelerate launch train_lcm_distill_sd_wds.py \\\n    --pretrained_teacher_model=$MODEL_DIR \\\n    --output_dir=$OUTPUT_DIR \\\n    --mixed_precision=fp16 \\\n    --resolution=512 \\\n    --learning_rate=1e-6 --loss_type=\"huber\" --ema_decay=0.95 --adam_weight_decay=0.0 \\\n    --max_train_steps=1000 \\\n    --max_train_samples=4000000 \\\n    --dataloader_num_workers=8 \\\n    --train_shards_path_or_url=\"pipe:curl -L -s https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset/resolve/main/data/{00000..01099}.tar?download=true\" \\\n    --validation_steps=200 \\\n    --checkpointing_steps=200 --checkpoints_total_limit=10 \\\n    --train_batch_size=12 \\\n    --gradient_checkpointing --enable_xformers_memory_efficient_attention \\\n    --gradient_accumulation_steps=1 \\\n    --use_8bit_adam \\\n    --resume_from_checkpoint=latest \\\n    --report_to=wandb \\\n    --seed=453645634 \\\n    --push_to_hub\n```", "```py\nfrom diffusers import UNet2DConditionModel, DiffusionPipeline, LCMScheduler\nimport torch\n\nunet = UNet2DConditionModel.from_pretrained(\"your-username/your-model\", torch_dtype=torch.float16, variant=\"fp16\")\npipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", unet=unet, torch_dtype=torch.float16, variant=\"fp16\")\n\npipeline.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\npipeline.to(\"cuda\")\n\nprompt = \"sushi rolls in the form of panda heads, sushi platter\"\n\nimage = pipeline(prompt, num_inference_steps=4, guidance_scale=1.0).images[0]\n```"]