["```py\n# uncomment to install the necessary libraries in Colab\n#!pip install -q diffusers transformers accelerate invisible-watermark>=0.2.0\n```", "```py\npipeline = StableDiffusionXLPipeline.from_pretrained(..., add_watermarker=False)\n```", "```py\nfrom diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\nimport torch\n\npipeline = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nrefiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\"\n).to(\"cuda\")\n```", "```py\nfrom diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\nimport torch\n\npipeline = StableDiffusionXLPipeline.from_single_file(\n    \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_base_1.0.safetensors\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nrefiner = StableDiffusionXLImg2ImgPipeline.from_single_file(\n    \"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/blob/main/sd_xl_refiner_1.0.safetensors\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\"\n).to(\"cuda\")\n```", "```py\nfrom diffusers import AutoPipelineForText2Image\nimport torch\n\npipeline_text2image = AutoPipelineForText2Image.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\nimage = pipeline_text2image(prompt=prompt).images[0]\nimage\n```", "```py\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import load_image, make_image_grid\n\n# use from_pipe to avoid consuming additional memory when loading a checkpoint\npipeline = AutoPipelineForImage2Image.from_pipe(pipeline_text2image).to(\"cuda\")\n\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png\"\ninit_image = load_image(url)\nprompt = \"a dog catching a frisbee in the jungle\"\nimage = pipeline(prompt, image=init_image, strength=0.8, guidance_scale=10.5).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\n# use from_pipe to avoid consuming additional memory when loading a checkpoint\npipeline = AutoPipelineForInpainting.from_pipe(pipeline_text2image).to(\"cuda\")\n\nimg_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png\"\nmask_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png\"\n\ninit_image = load_image(img_url)\nmask_image = load_image(mask_url)\n\nprompt = \"A deep sea diver floating\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.85, guidance_scale=12.5).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\nbase = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nrefiner = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n    text_encoder_2=base.text_encoder_2,\n    vae=base.vae,\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n    variant=\"fp16\",\n).to(\"cuda\")\n```", "```py\nprompt = \"A majestic lion jumping from a big stone at night\"\n\nimage = base(\n    prompt=prompt,\n    num_inference_steps=40,\n    denoising_end=0.8,\n    output_type=\"latent\",\n).images\nimage = refiner(\n    prompt=prompt,\n    num_inference_steps=40,\n    denoising_start=0.8,\n    image=image,\n).images[0]\nimage\n```", "```py\nfrom diffusers import StableDiffusionXLInpaintPipeline\nfrom diffusers.utils import load_image, make_image_grid\nimport torch\n\nbase = StableDiffusionXLInpaintPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nrefiner = StableDiffusionXLInpaintPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n    text_encoder_2=base.text_encoder_2,\n    vae=base.vae,\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n    variant=\"fp16\",\n).to(\"cuda\")\n\nimg_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\nmask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\ninit_image = load_image(img_url)\nmask_image = load_image(mask_url)\n\nprompt = \"A majestic tiger sitting on a bench\"\nnum_inference_steps = 75\nhigh_noise_frac = 0.7\n\nimage = base(\n    prompt=prompt,\n    image=init_image,\n    mask_image=mask_image,\n    num_inference_steps=num_inference_steps,\n    denoising_end=high_noise_frac,\n    output_type=\"latent\",\n).images\nimage = refiner(\n    prompt=prompt,\n    image=image,\n    mask_image=mask_image,\n    num_inference_steps=num_inference_steps,\n    denoising_start=high_noise_frac,\n).images[0]\nmake_image_grid([init_image, mask_image, image.resize((512, 512))], rows=1, cols=3)\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\nbase = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nrefiner = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n    text_encoder_2=base.text_encoder_2,\n    vae=base.vae,\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n    variant=\"fp16\",\n).to(\"cuda\")\n```", "```py\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\nimage = base(prompt=prompt, output_type=\"latent\").images[0]\n```", "```py\nimage = refiner(prompt=prompt, image=image[None, :]).images[0]\n```", "```py\nfrom diffusers import StableDiffusionXLPipeline\nimport torch\n\npipe = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\nimage = pipe(\n    prompt=prompt,\n    negative_original_size=(512, 512),\n    negative_target_size=(1024, 1024),\n).images[0]\n```", "```py\nfrom diffusers import StableDiffusionXLPipeline\nimport torch\n\npipeline = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\nimage = pipeline(prompt=prompt, crops_coords_top_left=(256, 0)).images[0]\nimage\n```", "```py\nfrom diffusers import StableDiffusionXLPipeline\nimport torch\n\npipe = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\nimage = pipe(\n    prompt=prompt,\n    negative_original_size=(512, 512),\n    negative_crops_coords_top_left=(0, 0),\n    negative_target_size=(1024, 1024),\n).images[0]\nimage\n```", "```py\nfrom diffusers import StableDiffusionXLPipeline\nimport torch\n\npipeline = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n).to(\"cuda\")\n\n# prompt is passed to OAI CLIP-ViT/L-14\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n# prompt_2 is passed to OpenCLIP-ViT/bigG-14\nprompt_2 = \"Van Gogh painting\"\nimage = pipeline(prompt=prompt, prompt_2=prompt_2).images[0]\nimage\n```", "```py\n- base.to(\"cuda\")\n- refiner.to(\"cuda\")\n+ base.enable_model_cpu_offload()\n+ refiner.enable_model_cpu_offload()\n```", "```py\n+ base.unet = torch.compile(base.unet, mode=\"reduce-overhead\", fullgraph=True)\n+ refiner.unet = torch.compile(refiner.unet, mode=\"reduce-overhead\", fullgraph=True)\n```", "```py\n+ base.enable_xformers_memory_efficient_attention()\n+ refiner.enable_xformers_memory_efficient_attention()\n```"]