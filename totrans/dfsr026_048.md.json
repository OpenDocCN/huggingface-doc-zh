["```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\nclass UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n    def __init__(self, unet, scheduler):\n        super().__init__()\n```", "```py\n  from diffusers import DiffusionPipeline\n  import torch\n\n  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n      def __init__(self, unet, scheduler):\n          super().__init__()\n\n+         self.register_modules(unet=unet, scheduler=scheduler)\n```", "```py\n  from diffusers import DiffusionPipeline\n  import torch\n\n  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n      def __init__(self, unet, scheduler):\n          super().__init__()\n\n          self.register_modules(unet=unet, scheduler=scheduler)\n\n+     def __call__(self):\n+         image = torch.randn(\n+             (1, self.unet.config.in_channels, self.unet.config.sample_size, self.unet.config.sample_size),\n+         )\n+         timestep = 1\n\n+         model_output = self.unet(image, timestep).sample\n+         scheduler_output = self.scheduler.step(model_output, timestep, image).prev_sample\n\n+         return scheduler_output\n```", "```py\nfrom diffusers import DDPMScheduler, UNet2DModel\n\nscheduler = DDPMScheduler()\nunet = UNet2DModel()\n\npipeline = UnetSchedulerOneForwardPipeline(unet=unet, scheduler=scheduler)\n\noutput = pipeline()\n```", "```py\npipeline = UnetSchedulerOneForwardPipeline.from_pretrained(\"google/ddpm-cifar10-32\", use_safetensors=True)\n\noutput = pipeline()\n```", "```py\nfrom diffusers import DiffusionPipeline\n\npipe = DiffusionPipeline.from_pretrained(\n    \"google/ddpm-cifar10-32\", custom_pipeline=\"one_step_unet\", use_safetensors=True\n)\npipe()\n```", "```py\nfrom diffusers import DiffusionPipeline\n\npipeline = DiffusionPipeline.from_pretrained(\n    \"google/ddpm-cifar10-32\", custom_pipeline=\"stevhliu/one_step_unet\", use_safetensors=True\n)\n```", "```py\nfrom diffusers import DiffusionPipeline\nfrom transformers import CLIPImageProcessor, CLIPModel\n\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\nclip_model_id = \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n\nfeature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)\nclip_model = CLIPModel.from_pretrained(clip_model_id, torch_dtype=torch.float16)\n\npipeline = DiffusionPipeline.from_pretrained(\n    model_id,\n    custom_pipeline=\"clip_guided_stable_diffusion\",\n    clip_model=clip_model,\n    feature_extractor=feature_extractor,\n    scheduler=scheduler,\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n)\n```", "```py\n# 2\\. Load the pipeline class, if using custom module then load it from the Hub\n# if we load from explicit class, let's use it\nif custom_pipeline is not None:\n    pipeline_class = get_class_from_dynamic_module(\n        custom_pipeline, module_file=CUSTOM_PIPELINE_FILE_NAME, cache_dir=custom_pipeline\n    )\nelif cls != DiffusionPipeline:\n    pipeline_class = cls\nelse:\n    diffusers_module = importlib.import_module(cls.__module__.split(\".\")[0])\n    pipeline_class = getattr(diffusers_module, config_dict[\"_class_name\"])\n```"]