["```py\npip install -q transformers\n```", "```py\n>>> from transformers import pipeline\n\n>>> checkpoint = \"google/owlvit-base-patch32\"\n>>> detector = pipeline(model=checkpoint, task=\"zero-shot-object-detection\")\n```", "```py\n>>> import skimage\n>>> import numpy as np\n>>> from PIL import Image\n\n>>> image = skimage.data.astronaut()\n>>> image = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n\n>>> image\n```", "```py\n>>> predictions = detector(\n...     image,\n...     candidate_labels=[\"human face\", \"rocket\", \"nasa badge\", \"star-spangled banner\"],\n... )\n>>> predictions\n[{'score': 0.3571370542049408,\n  'label': 'human face',\n  'box': {'xmin': 180, 'ymin': 71, 'xmax': 271, 'ymax': 178}},\n {'score': 0.28099656105041504,\n  'label': 'nasa badge',\n  'box': {'xmin': 129, 'ymin': 348, 'xmax': 206, 'ymax': 427}},\n {'score': 0.2110239565372467,\n  'label': 'rocket',\n  'box': {'xmin': 350, 'ymin': -1, 'xmax': 468, 'ymax': 288}},\n {'score': 0.13790413737297058,\n  'label': 'star-spangled banner',\n  'box': {'xmin': 1, 'ymin': 1, 'xmax': 105, 'ymax': 509}},\n {'score': 0.11950037628412247,\n  'label': 'nasa badge',\n  'box': {'xmin': 277, 'ymin': 338, 'xmax': 327, 'ymax': 380}},\n {'score': 0.10649408400058746,\n  'label': 'rocket',\n  'box': {'xmin': 358, 'ymin': 64, 'xmax': 424, 'ymax': 280}}]\n```", "```py\n>>> from PIL import ImageDraw\n\n>>> draw = ImageDraw.Draw(image)\n\n>>> for prediction in predictions:\n...     box = prediction[\"box\"]\n...     label = prediction[\"label\"]\n...     score = prediction[\"score\"]\n\n...     xmin, ymin, xmax, ymax = box.values()\n...     draw.rectangle((xmin, ymin, xmax, ymax), outline=\"red\", width=1)\n...     draw.text((xmin, ymin), f\"{label}: {round(score,2)}\", fill=\"white\")\n\n>>> image\n```", "```py\n>>> from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n\n>>> model = AutoModelForZeroShotObjectDetection.from_pretrained(checkpoint)\n>>> processor = AutoProcessor.from_pretrained(checkpoint)\n```", "```py\n>>> import requests\n\n>>> url = \"https://unsplash.com/photos/oj0zeY2Ltk4/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8MTR8fHBpY25pY3xlbnwwfHx8fDE2Nzc0OTE1NDk&force=true&w=640\"\n>>> im = Image.open(requests.get(url, stream=True).raw)\n>>> im\n```", "```py\n>>> text_queries = [\"hat\", \"book\", \"sunglasses\", \"camera\"]\n>>> inputs = processor(text=text_queries, images=im, return_tensors=\"pt\")\n```", "```py\n>>> import torch\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n...     target_sizes = torch.tensor([im.size[::-1]])\n...     results = processor.post_process_object_detection(outputs, threshold=0.1, target_sizes=target_sizes)[0]\n\n>>> draw = ImageDraw.Draw(im)\n\n>>> scores = results[\"scores\"].tolist()\n>>> labels = results[\"labels\"].tolist()\n>>> boxes = results[\"boxes\"].tolist()\n\n>>> for box, score, label in zip(boxes, scores, labels):\n...     xmin, ymin, xmax, ymax = box\n...     draw.rectangle((xmin, ymin, xmax, ymax), outline=\"red\", width=1)\n...     draw.text((xmin, ymin), f\"{text_queries[label]}: {round(score,2)}\", fill=\"white\")\n\n>>> im\n```", "```py\n>>> images = [image, im]\n>>> text_queries = [\n...     [\"human face\", \"rocket\", \"nasa badge\", \"star-spangled banner\"],\n...     [\"hat\", \"book\", \"sunglasses\", \"camera\"],\n... ]\n>>> inputs = processor(text=text_queries, images=images, return_tensors=\"pt\")\n```", "```py\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n...     target_sizes = [x.size[::-1] for x in images]\n...     results = processor.post_process_object_detection(outputs, threshold=0.1, target_sizes=target_sizes)\n\n>>> image_idx = 1\n>>> draw = ImageDraw.Draw(images[image_idx])\n\n>>> scores = results[image_idx][\"scores\"].tolist()\n>>> labels = results[image_idx][\"labels\"].tolist()\n>>> boxes = results[image_idx][\"boxes\"].tolist()\n\n>>> for box, score, label in zip(boxes, scores, labels):\n...     xmin, ymin, xmax, ymax = box\n...     draw.rectangle((xmin, ymin, xmax, ymax), outline=\"red\", width=1)\n...     draw.text((xmin, ymin), f\"{text_queries[image_idx][label]}: {round(score,2)}\", fill=\"white\")\n\n>>> images[image_idx]\n```", "```py\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image_target = Image.open(requests.get(url, stream=True).raw)\n\n>>> query_url = \"http://images.cocodataset.org/val2017/000000524280.jpg\"\n>>> query_image = Image.open(requests.get(query_url, stream=True).raw)\n```", "```py\n>>> import matplotlib.pyplot as plt\n\n>>> fig, ax = plt.subplots(1, 2)\n>>> ax[0].imshow(image_target)\n>>> ax[1].imshow(query_image)\n```", "```py\n>>> inputs = processor(images=image_target, query_images=query_image, return_tensors=\"pt\")\n```", "```py\n>>> with torch.no_grad():\n...     outputs = model.image_guided_detection(**inputs)\n...     target_sizes = torch.tensor([image_target.size[::-1]])\n...     results = processor.post_process_image_guided_detection(outputs=outputs, target_sizes=target_sizes)[0]\n\n>>> draw = ImageDraw.Draw(image_target)\n\n>>> scores = results[\"scores\"].tolist()\n>>> boxes = results[\"boxes\"].tolist()\n\n>>> for box, score, label in zip(boxes, scores, labels):\n...     xmin, ymin, xmax, ymax = box\n...     draw.rectangle((xmin, ymin, xmax, ymax), outline=\"white\", width=4)\n\n>>> image_target\n```"]