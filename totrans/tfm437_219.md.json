["```py\n>>> import torch\n>>> from transformers import AutoModel, AutoTokenizer\n\n>>> phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n\n>>> # INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n>>> line = \"T\u00f4i l\u00e0 sinh_vi\u00ean tr\u01b0\u1eddng \u0111\u1ea1i_h\u1ecdc C\u00f4ng_ngh\u1ec7 .\"\n\n>>> input_ids = torch.tensor([tokenizer.encode(line)])\n\n>>> with torch.no_grad():\n...     features = phobert(input_ids)  # Models outputs are now tuples\n\n>>> # With TensorFlow 2.0+:\n>>> # from transformers import TFAutoModel\n>>> # phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")\n```", "```py\n( vocab_file merges_file bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' **kwargs )\n```", "```py\n( f )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( tokens )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) \u2192 export const metadata = 'undefined';List[int]\n```"]