["```py\n( features: List return_tensors = 'pt' )\n```", "```py\n( return_tensors: str = 'pt' )\n```", "```py\n( tokenizer: PreTrainedTokenizerBase padding: Union = True max_length: Optional = None pad_to_multiple_of: Optional = None return_tensors: str = 'pt' )\n```", "```py\n( tokenizer: PreTrainedTokenizerBase padding: Union = True max_length: Optional = None pad_to_multiple_of: Optional = None label_pad_token_id: int = -100 return_tensors: str = 'pt' )\n```", "```py\n( tokenizer: PreTrainedTokenizerBase model: Optional = None padding: Union = True max_length: Optional = None pad_to_multiple_of: Optional = None label_pad_token_id: int = -100 return_tensors: str = 'pt' )\n```", "```py\n( tokenizer: PreTrainedTokenizerBase mlm: bool = True mlm_probability: float = 0.15 pad_to_multiple_of: Optional = None tf_experimental_compile: bool = False return_tensors: str = 'pt' )\n```", "```py\n( inputs: Any special_tokens_mask: Optional = None )\n```", "```py\n( inputs: Any vocab_size mask_token_id special_tokens_mask: Optional = None )\n```", "```py\n( inputs: Any special_tokens_mask: Optional = None )\n```", "```py\n( tokenizer: PreTrainedTokenizerBase mlm: bool = True mlm_probability: float = 0.15 pad_to_multiple_of: Optional = None tf_experimental_compile: bool = False return_tensors: str = 'pt' )\n```", "```py\n( inputs: Any mask_labels: Any )\n```", "```py\n( inputs: Any mask_labels: Any )\n```", "```py\n( inputs: Any mask_labels: Any )\n```", "```py\n( tokenizer: PreTrainedTokenizerBase plm_probability: float = 0.16666666666666666 max_span_length: int = 5 return_tensors: str = 'pt' )\n```", "```py\n( inputs: Any )\n```", "```py\n( inputs: Any )\n```", "```py\n( inputs: Any )\n```"]