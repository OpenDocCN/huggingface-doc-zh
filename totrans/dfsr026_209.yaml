- en: VQDiffusionScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VQDiffusionScheduler
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/vq_diffusion](https://huggingface.co/docs/diffusers/api/schedulers/vq_diffusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/schedulers/vq_diffusion](https://huggingface.co/docs/diffusers/api/schedulers/vq_diffusion)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '`VQDiffusionScheduler` converts the transformer model’s output into a sample
    for the unnoised image at the previous diffusion timestep. It was introduced in
    [Vector Quantized Diffusion Model for Text-to-Image Synthesis](https://huggingface.co/papers/2111.14822)
    by Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan,
    Baining Guo.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '`VQDiffusionScheduler` 将变压器模型的输出转换为前一个扩散时间步的未加噪图像样本。由 Shuyang Gu, Dong Chen,
    Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, Baining Guo 在 [用于文本到图像合成的矢量量化扩散模型](https://huggingface.co/papers/2111.14822)
    中引入。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We present the vector quantized diffusion (VQ-Diffusion) model for text-to-image
    generation. This method is based on a vector quantized variational autoencoder
    (VQ-VAE) whose latent space is modeled by a conditional variant of the recently
    developed Denoising Diffusion Probabilistic Model (DDPM). We find that this latent-space
    method is well-suited for text-to-image generation tasks because it not only eliminates
    the unidirectional bias with existing methods but also allows us to incorporate
    a mask-and-replace diffusion strategy to avoid the accumulation of errors, which
    is a serious problem with existing methods. Our experiments show that the VQ-Diffusion
    produces significantly better text-to-image generation results when compared with
    conventional autoregressive (AR) models with similar numbers of parameters. Compared
    with previous GAN-based text-to-image methods, our VQ-Diffusion can handle more
    complex scenes and improve the synthesized image quality by a large margin. Finally,
    we show that the image generation computation in our method can be made highly
    efficient by reparameterization. With traditional AR methods, the text-to-image
    generation time increases linearly with the output image resolution and hence
    is quite time consuming even for normal size images. The VQ-Diffusion allows us
    to achieve a better trade-off between quality and speed. Our experiments indicate
    that the VQ-Diffusion model with the reparameterization is fifteen times faster
    than traditional AR methods while achieving a better image quality.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了用于文本到图像生成的矢量量化扩散（VQ-Diffusion）模型。该方法基于矢量量化变分自动编码器（VQ-VAE），其潜空间由最近开发的去噪扩散概率模型（DDPM）的条件变体建模。我们发现，这种潜空间方法非常适用于文本到图像生成任务，因为它不仅消除了现有方法的单向偏差，还允许我们结合掩码替换扩散策略，以避免错误的积累，这是现有方法的一个严重问题。我们的实验表明，与具有相似参数数量的传统自回归（AR）模型相比，VQ-Diffusion在文本到图像生成结果方面表现显著更好。与先前基于GAN的文本到图像方法相比，我们的VQ-Diffusion可以处理更复杂的场景，并显著提高合成图像的质量。最后，我们展示了我们的方法中的图像生成计算可以通过重新参数化实现高效。对于传统的AR方法，文本到图像生成时间随着输出图像分辨率的增加呈线性增长，因此即使对于普通大小的图像也是非常耗时的。VQ-Diffusion使我们能够在质量和速度之间取得更好的平衡。我们的实验表明，具有重新参数化的VQ-Diffusion模型比传统的AR方法快15倍，同时实现更好的图像质量。*'
- en: VQDiffusionScheduler
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VQDiffusionScheduler
- en: '### `class diffusers.VQDiffusionScheduler`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.VQDiffusionScheduler`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L106)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L106)'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_vec_classes` (`int`) — The number of classes of the vector embeddings
    of the latent pixels. Includes the class for the masked latent pixel.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_vec_classes` (`int`) — 隐像素向量嵌入的类数。包括掩码隐像素的类。'
- en: '`num_train_timesteps` (`int`, defaults to 100) — The number of diffusion steps
    to train the model.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_timesteps` (`int`，默认为 100）— 训练模型的扩散步数。'
- en: '`alpha_cum_start` (`float`, defaults to 0.99999) — The starting cumulative
    alpha value.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha_cum_start` (`float`，默认为 0.99999）— 开始累积 alpha 值。'
- en: '`alpha_cum_end` (`float`, defaults to 0.00009) — The ending cumulative alpha
    value.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha_cum_end` (`float`，默认为 0.00009）— 结束累积 alpha 值。'
- en: '`gamma_cum_start` (`float`, defaults to 0.00009) — The starting cumulative
    gamma value.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gamma_cum_start` (`float`，默认为 0.00009）— 开始累积 gamma 值。'
- en: '`gamma_cum_end` (`float`, defaults to 0.99999) — The ending cumulative gamma
    value.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gamma_cum_end` (`float`，默认为 0.99999）— 结束累积 gamma 值。'
- en: A scheduler for vector quantized diffusion.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 用于矢量量化扩散的调度器。
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自 [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    和 [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。
- en: '#### `log_Q_t_transitioning_to_known_class`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `log_Q_t_transitioning_to_known_class`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L356)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L356)'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`t` (`torch.Long`) — The timestep that determines which transition matrix is
    used.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t` (`torch.Long`) — 确定使用哪个转移矩阵的时间步。'
- en: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — The
    classes of each latent pixel at time `t`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — 时间
    `t` 时每个隐像素的类。'
- en: '`log_onehot_x_t` (`torch.FloatTensor` of shape `(batch size, num classes, num
    latent pixels)`) — The log one-hot vectors of `x_t`.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_onehot_x_t` (`torch.FloatTensor` of shape `(batch size, num classes, num
    latent pixels)`) — `x_t` 的对数独热向量。'
- en: '`cumulative` (`bool`) — If cumulative is `False`, the single step transition
    matrix `t-1`->`t` is used. If cumulative is `True`, the cumulative transition
    matrix `0`->`t` is used.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cumulative` (`bool`) — 如果 cumulative 为 `False`，则使用单步转移矩阵 `t-1`->`t`。如果 cumulative
    为 `True`，则使用累积转移矩阵 `0`->`t`。'
- en: Returns
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`torch.FloatTensor` of shape `(batch size, num classes - 1, num latent pixels)`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为`(batch size, num classes - 1, num latent pixels)`的`torch.FloatTensor`
- en: Each *column* of the returned matrix is a *row* of log probabilities of the
    complete probability transition matrix.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的矩阵的每一列是完整概率转移矩阵的对数概率行。
- en: When non cumulative, returns `self.num_classes - 1` rows because the initial
    latent pixel cannot be masked.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当非累积时，返回`self.num_classes - 1`行，因为初始潜在像素不能被遮蔽。
- en: 'Where:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '`q_n` is the probability distribution for the forward process of the `n`th
    latent pixel.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`q_n`是第`n`个潜在像素正向过程的概率分布。'
- en: C_0 is a class of a latent pixel embedding
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C_0是潜在像素嵌入的一个类别
- en: C_k is the class of the masked latent pixel
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C_k是被遮蔽的潜在像素的类别
- en: 'non-cumulative result (omitting logarithms):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 非累积结果（省略对数）：
- en: <codeblock code="{`cV8wKHhfdCUyMCU3QyUyMHhfJTdCdC0xJTdEJTIwJTNEJTIwQ18wKSUyMC4uLiUyMHFfbih4X3QlMjAlN0MlMjB4XyU3QnQtMSU3RCUyMCUzRCUyMENfMCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMC4lMEFxXzAoeF90JTIwJTdDJTIweF8lN0J0LTElN0QlMjAlM0QlMjBDX2spJTIwLi4uJTIwcV9uKHhfdCUyMCU3QyUyMHhfJTdCdC0xJTdEJTIwJTNEJTIwQ19rKQ==`}"
    highlighted="{`q<span" class="hljs-constructor">_0(x_t | x_{t-1\} = C_0) ... q_n(x_t
    | x_{t-1\} = C_0) . . . . . . . . . q_0(x_t | x_{t-1\} = C_k) ... q_n(x_t | x_{t-1\}
    = C_k)`} wrap={false} />
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`q_0(x_t | x_{t-1} = C_0) ... q_n(x_t | x_{t-1} = C_0) . . . . . . . . . q_0(x_t
    | x_{t-1} = C_k) ... q_n(x_t | x_{t-1} = C_k)`'
- en: 'cumulative result (omitting logarithms):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 累积结果（省略对数）：
- en: <codeblock code="{`cV8wX2N1bXVsYXRpdmUoeF90JTIwJTdDJTIweF8wJTIwJTNEJTIwQ18wKSUyMCUyMCUyMCUyMC4uLiUyMCUyMHFfbl9jdW11bGF0aXZlKHhfdCUyMCU3QyUyMHhfMCUyMCUzRCUyMENfMCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEFxXzBfY3VtdWxhdGl2ZSh4X3QlMjAlN0MlMjB4XzAlMjAlM0QlMjBDXyU3QmstMSU3RCklMjAuLi4lMjBxX25fY3VtdWxhdGl2ZSh4X3QlMjAlN0MlMjB4XzAlMjAlM0QlMjBDXyU3QmstMSU3RCk=`}"
    highlighted="{`q<span" class="hljs-constructor">_0_cumulative(x_t | x_0 = C_0)
    ... q_n_cumulative(x_t | x_0 = C_0) . . . . . . . . . q_0_cumulative(x_t | x_0
    = C_{k-1\}) ... q_n_cumulative(x_t | x_0 = C_{k-1\})`} wrap={false} /></codeblock></codeblock>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`q_0_cumulative(x_t | x_0 = C_0) ... q_n_cumulative(x_t | x_0 = C_0) . . .
    . . . . . . q_0_cumulative(x_t | x_0 = C_{k-1}) ... q_n_cumulative(x_t | x_0 =
    C_{k-1})`'
- en: Calculates the log probabilities of the rows from the (cumulative or non-cumulative)
    transition matrix for each latent pixel in `x_t`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 计算`x_t`中每个潜在像素的（累积或非累积）转移矩阵的对数概率。
- en: '#### `q_posterior`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `q_posterior`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L245)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L245)'
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`log_p_x_0` (`torch.FloatTensor` of shape `(batch size, num classes - 1, num
    latent pixels)`) — The log probabilities for the predicted classes of the initial
    latent pixels. Does not include a prediction for the masked class as the initial
    unnoised image cannot be masked.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_p_x_0`（形状为`(batch size, num classes - 1, num latent pixels)`的`torch.FloatTensor`）—
    初始潜在像素预测类别的对数概率。不包括被遮蔽类别的预测，因为初始未加噪声的图像不能被遮蔽。'
- en: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — The
    classes of each latent pixel at time `t`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_t`（形状为`(batch size, num latent pixels)`的`torch.LongTensor`）— 每个潜在像素在时间`t`的类别。'
- en: '`t` (`torch.Long`) — The timestep that determines which transition matrix is
    used.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t`（`torch.Long`）— 决定使用哪个转移矩阵的时间步。'
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor` of shape `(batch size, num classes, num latent pixels)`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为`(batch size, num classes, num latent pixels)`的`torch.FloatTensor`
- en: The log probabilities for the predicted classes of the image at timestep `t-1`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 时间步`t-1`时图像预测类别的对数概率。
- en: 'Calculates the log probabilities for the predicted classes of the image at
    timestep `t-1`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 计算时间步`t-1`时图像预测类别的对数概率：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#### `set_timesteps`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_timesteps`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L178)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L178)'
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_inference_steps` (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`) — 在使用预训练模型生成样本时使用的扩散步数。'
- en: '`device` (`str` or `torch.device`, *optional*) — The device to which the timesteps
    and diffusion process parameters (alpha, beta, gamma) should be moved to.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`str`或`torch.device`，*可选*) — 将时间步和扩散过程参数（alpha、beta、gamma）移动到的设备。'
- en: Sets the discrete timesteps used for the diffusion chain (to be run before inference).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于扩散链的离散时间步（在推断之前运行）。
- en: '#### `step`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L200)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L200)'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`t` (`torch.long`) — The timestep that determines which transition matrices
    are used.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t` (`torch.long`) — 决定使用哪些转移矩阵的时间步。'
- en: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — The
    classes of each latent pixel at time `t`.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_t` (`torch.LongTensor`，形状为`(batch size, num latent pixels)`) — 时间`t`时每个潜在像素的类。'
- en: '`generator` (`torch.Generator`, or `None`) — A random number generator for
    the noise applied to `p(x_{t-1} | x_t)` before it is sampled from.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`None`) — 用于在从中采样之前应用于`p(x_{t-1} | x_t)`的噪声的随机数生成器。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)
    or `tuple`.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*，默认为`True`) — 是否返回[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)或`tuple`。'
- en: Returns
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)
    or `tuple`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)或`tuple`'
- en: If return_dict is `True`, [VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)，否则返回一个元组，其中第一个元素是样本张量。
- en: Predict the sample from the previous timestep by the reverse transition distribution.
    See [q_posterior()](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.VQDiffusionScheduler.q_posterior)
    for more details about how the distribution is computer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过逆转移分布预测上一个时间步的样本。有关计算分布的更多详细信息，请参阅[q_posterior()](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.VQDiffusionScheduler.q_posterior)。
- en: VQDiffusionSchedulerOutput
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VQDiffusionSchedulerOutput
- en: '### `class diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L27)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L27)'
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prev_sample` (`torch.LongTensor` of shape `(batch size, num latent pixels)`)
    — Computed sample x_{t-1} of previous timestep. `prev_sample` should be used as
    next model input in the denoising loop.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prev_sample` (`torch.LongTensor`，形状为`(batch size, num latent pixels)`) — 计算上一个时间步的先前样本
    x_{t-1}。`prev_sample`应该在去噪循环中作为下一个模型输入使用。'
- en: Output class for the scheduler’s step function output.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 调度程序的步函数输出的输出类。
