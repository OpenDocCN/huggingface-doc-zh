- en: VQDiffusionScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/vq_diffusion](https://huggingface.co/docs/diffusers/api/schedulers/vq_diffusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '`VQDiffusionScheduler` converts the transformer model’s output into a sample
    for the unnoised image at the previous diffusion timestep. It was introduced in
    [Vector Quantized Diffusion Model for Text-to-Image Synthesis](https://huggingface.co/papers/2111.14822)
    by Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan,
    Baining Guo.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '*We present the vector quantized diffusion (VQ-Diffusion) model for text-to-image
    generation. This method is based on a vector quantized variational autoencoder
    (VQ-VAE) whose latent space is modeled by a conditional variant of the recently
    developed Denoising Diffusion Probabilistic Model (DDPM). We find that this latent-space
    method is well-suited for text-to-image generation tasks because it not only eliminates
    the unidirectional bias with existing methods but also allows us to incorporate
    a mask-and-replace diffusion strategy to avoid the accumulation of errors, which
    is a serious problem with existing methods. Our experiments show that the VQ-Diffusion
    produces significantly better text-to-image generation results when compared with
    conventional autoregressive (AR) models with similar numbers of parameters. Compared
    with previous GAN-based text-to-image methods, our VQ-Diffusion can handle more
    complex scenes and improve the synthesized image quality by a large margin. Finally,
    we show that the image generation computation in our method can be made highly
    efficient by reparameterization. With traditional AR methods, the text-to-image
    generation time increases linearly with the output image resolution and hence
    is quite time consuming even for normal size images. The VQ-Diffusion allows us
    to achieve a better trade-off between quality and speed. Our experiments indicate
    that the VQ-Diffusion model with the reparameterization is fifteen times faster
    than traditional AR methods while achieving a better image quality.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: VQDiffusionScheduler
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.VQDiffusionScheduler`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L106)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '`num_vec_classes` (`int`) — The number of classes of the vector embeddings
    of the latent pixels. Includes the class for the masked latent pixel.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_train_timesteps` (`int`, defaults to 100) — The number of diffusion steps
    to train the model.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha_cum_start` (`float`, defaults to 0.99999) — The starting cumulative
    alpha value.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha_cum_end` (`float`, defaults to 0.00009) — The ending cumulative alpha
    value.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gamma_cum_start` (`float`, defaults to 0.00009) — The starting cumulative
    gamma value.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gamma_cum_end` (`float`, defaults to 0.99999) — The ending cumulative gamma
    value.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A scheduler for vector quantized diffusion.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '#### `log_Q_t_transitioning_to_known_class`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L356)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '`t` (`torch.Long`) — The timestep that determines which transition matrix is
    used.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — The
    classes of each latent pixel at time `t`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`log_onehot_x_t` (`torch.FloatTensor` of shape `(batch size, num classes, num
    latent pixels)`) — The log one-hot vectors of `x_t`.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cumulative` (`bool`) — If cumulative is `False`, the single step transition
    matrix `t-1`->`t` is used. If cumulative is `True`, the cumulative transition
    matrix `0`->`t` is used.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor` of shape `(batch size, num classes - 1, num latent pixels)`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Each *column* of the returned matrix is a *row* of log probabilities of the
    complete probability transition matrix.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: When non cumulative, returns `self.num_classes - 1` rows because the initial
    latent pixel cannot be masked.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Where:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '`q_n` is the probability distribution for the forward process of the `n`th
    latent pixel.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C_0 is a class of a latent pixel embedding
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C_k is the class of the masked latent pixel
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'non-cumulative result (omitting logarithms):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: <codeblock code="{`cV8wKHhfdCUyMCU3QyUyMHhfJTdCdC0xJTdEJTIwJTNEJTIwQ18wKSUyMC4uLiUyMHFfbih4X3QlMjAlN0MlMjB4XyU3QnQtMSU3RCUyMCUzRCUyMENfMCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMC4lMEFxXzAoeF90JTIwJTdDJTIweF8lN0J0LTElN0QlMjAlM0QlMjBDX2spJTIwLi4uJTIwcV9uKHhfdCUyMCU3QyUyMHhfJTdCdC0xJTdEJTIwJTNEJTIwQ19rKQ==`}"
    highlighted="{`q<span" class="hljs-constructor">_0(x_t | x_{t-1\} = C_0) ... q_n(x_t
    | x_{t-1\} = C_0) . . . . . . . . . q_0(x_t | x_{t-1\} = C_k) ... q_n(x_t | x_{t-1\}
    = C_k)`} wrap={false} />
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'cumulative result (omitting logarithms):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: <codeblock code="{`cV8wX2N1bXVsYXRpdmUoeF90JTIwJTdDJTIweF8wJTIwJTNEJTIwQ18wKSUyMCUyMCUyMCUyMC4uLiUyMCUyMHFfbl9jdW11bGF0aXZlKHhfdCUyMCU3QyUyMHhfMCUyMCUzRCUyMENfMCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAuJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC4lMEFxXzBfY3VtdWxhdGl2ZSh4X3QlMjAlN0MlMjB4XzAlMjAlM0QlMjBDXyU3QmstMSU3RCklMjAuLi4lMjBxX25fY3VtdWxhdGl2ZSh4X3QlMjAlN0MlMjB4XzAlMjAlM0QlMjBDXyU3QmstMSU3RCk=`}"
    highlighted="{`q<span" class="hljs-constructor">_0_cumulative(x_t | x_0 = C_0)
    ... q_n_cumulative(x_t | x_0 = C_0) . . . . . . . . . q_0_cumulative(x_t | x_0
    = C_{k-1\}) ... q_n_cumulative(x_t | x_0 = C_{k-1\})`} wrap={false} /></codeblock></codeblock>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Calculates the log probabilities of the rows from the (cumulative or non-cumulative)
    transition matrix for each latent pixel in `x_t`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '#### `q_posterior`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L245)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '`log_p_x_0` (`torch.FloatTensor` of shape `(batch size, num classes - 1, num
    latent pixels)`) — The log probabilities for the predicted classes of the initial
    latent pixels. Does not include a prediction for the masked class as the initial
    unnoised image cannot be masked.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — The
    classes of each latent pixel at time `t`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t` (`torch.Long`) — The timestep that determines which transition matrix is
    used.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor` of shape `(batch size, num classes, num latent pixels)`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: The log probabilities for the predicted classes of the image at timestep `t-1`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculates the log probabilities for the predicted classes of the image at
    timestep `t-1`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#### `set_timesteps`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L178)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`) — 在使用预训练模型生成样本时使用的扩散步数。'
- en: '`device` (`str` or `torch.device`, *optional*) — The device to which the timesteps
    and diffusion process parameters (alpha, beta, gamma) should be moved to.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`str`或`torch.device`，*可选*) — 将时间步和扩散过程参数（alpha、beta、gamma）移动到的设备。'
- en: Sets the discrete timesteps used for the diffusion chain (to be run before inference).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于扩散链的离散时间步（在推断之前运行）。
- en: '#### `step`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L200)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L200)'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`t` (`torch.long`) — The timestep that determines which transition matrices
    are used.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t` (`torch.long`) — 决定使用哪些转移矩阵的时间步。'
- en: '`x_t` (`torch.LongTensor` of shape `(batch size, num latent pixels)`) — The
    classes of each latent pixel at time `t`.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_t` (`torch.LongTensor`，形状为`(batch size, num latent pixels)`) — 时间`t`时每个潜在像素的类。'
- en: '`generator` (`torch.Generator`, or `None`) — A random number generator for
    the noise applied to `p(x_{t-1} | x_t)` before it is sampled from.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`None`) — 用于在从中采样之前应用于`p(x_{t-1} | x_t)`的噪声的随机数生成器。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)
    or `tuple`.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*，默认为`True`) — 是否返回[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)或`tuple`。'
- en: Returns
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)
    or `tuple`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)或`tuple`'
- en: If return_dict is `True`, [VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[VQDiffusionSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput)，否则返回一个元组，其中第一个元素是样本张量。
- en: Predict the sample from the previous timestep by the reverse transition distribution.
    See [q_posterior()](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.VQDiffusionScheduler.q_posterior)
    for more details about how the distribution is computer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过逆转移分布预测上一个时间步的样本。有关计算分布的更多详细信息，请参阅[q_posterior()](/docs/diffusers/v0.26.3/en/api/schedulers/vq_diffusion#diffusers.VQDiffusionScheduler.q_posterior)。
- en: VQDiffusionSchedulerOutput
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VQDiffusionSchedulerOutput
- en: '### `class diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.schedulers.scheduling_vq_diffusion.VQDiffusionSchedulerOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L27)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_vq_diffusion.py#L27)'
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prev_sample` (`torch.LongTensor` of shape `(batch size, num latent pixels)`)
    — Computed sample x_{t-1} of previous timestep. `prev_sample` should be used as
    next model input in the denoising loop.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prev_sample` (`torch.LongTensor`，形状为`(batch size, num latent pixels)`) — 计算上一个时间步的先前样本
    x_{t-1}。`prev_sample`应该在去噪循环中作为下一个模型输入使用。'
- en: Output class for the scheduler’s step function output.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 调度程序的步函数输出的输出类。
