["```py\n\n@register_in_tasks_manager(\"esm\", *[\"feature-extraction\", \"fill-mask\", \"text-classification\", \"token-classification\"])\nclass EsmNeuronConfig(TextEncoderNeuronConfig):\n    NORMALIZED_CONFIG_CLASS = NormalizedConfigManager.get_normalized_config_class(\"bert\")\n    ATOL_FOR_VALIDATION = 1e-3  # absolute tolerance to compare for comparing model on CPUs\n\n @property\n    def inputs(self) -> List[str]:\n        return [\"input_ids\", \"attention_mask\"]\n\n```", "```py\noptimum-cli export neuron --model facebook/esm2_t33_650M_UR50D --task text-classification --batch_size 1 --sequence_length 16 esm_neuron/\n```", "```py\nfrom optimum.exporters.neuron import validate_model_outputs\n\nvalidate_model_outputs(\n    neuron_config, base_model, neuron_model_path, neuron_named_outputs, neuron_config.ATOL_FOR_VALIDATION\n)\n```", "```py\nfrom transformers import AutoTokenizer\nfrom optimum.neuron import NeuronModelForSequenceClassification\n\nmodel = NeuronModelForSequenceClassification.from_pretrained(\"esm_neuron/\")\ntokenizer = AutoTokenizer.from_pretrained(\"esm_neuron/\")\ninputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\nlogits = model(**inputs).logits\n```"]