- en: Mask2Former
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mask2Former
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mask2former](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mask2former)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mask2former](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mask2former)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概览
- en: The Mask2Former model was proposed in [Masked-attention Mask Transformer for
    Universal Image Segmentation](https://arxiv.org/abs/2112.01527) by Bowen Cheng,
    Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar. Mask2Former
    is a unified framework for panoptic, instance and semantic segmentation and features
    significant performance and efficiency improvements over [MaskFormer](maskformer).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Mask2Former模型是由Bowen Cheng、Ishan Misra、Alexander G. Schwing、Alexander Kirillov、Rohit
    Girdhar在[Masked-attention Mask Transformer for Universal Image Segmentation](https://arxiv.org/abs/2112.01527)中提出的。Mask2Former是一个统一的全景、实例和语义分割框架，相比于[MaskFormer](maskformer)具有显著的性能和效率改进。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 来自论文的摘要如下：
- en: '*Image segmentation groups pixels with different semantics, e.g., category
    or instance membership. Each choice of semantics defines a task. While only the
    semantics of each task differ, current research focuses on designing specialized
    architectures for each task. We present Masked-attention Mask Transformer (Mask2Former),
    a new architecture capable of addressing any image segmentation task (panoptic,
    instance or semantic). Its key components include masked attention, which extracts
    localized features by constraining cross-attention within predicted mask regions.
    In addition to reducing the research effort by at least three times, it outperforms
    the best specialized architectures by a significant margin on four popular datasets.
    Most notably, Mask2Former sets a new state-of-the-art for panoptic segmentation
    (57.8 PQ on COCO), instance segmentation (50.1 AP on COCO) and semantic segmentation
    (57.7 mIoU on ADE20K).*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像分割将具有不同语义的像素分组，例如类别或实例成员资格。每种语义选择定义了一个任务。虽然每个任务的语义不同，但当前的研究重点是为每个任务设计专门的架构。我们提出了Masked-attention
    Mask Transformer（Mask2Former），这是一种新的架构，能够处理任何图像分割任务（全景、实例或语义）。其关键组件包括掩码注意力，通过限制在预测掩码区域内的交叉注意力来提取局部特征。除了将研究工作量至少减少三倍外，它在四个流行数据集上的表现明显优于最佳专门架构。值得注意的是，Mask2Former在全景分割（COCO上的57.8
    PQ）、实例分割（COCO上的50.1 AP）和语义分割（ADE20K上的57.7 mIoU）方面取得了新的最先进水平。*'
- en: '![drawing](../Images/5ce83994aad79cfa0f1a7945fa6a424d.png) Mask2Former architecture.
    Taken from the [original paper.](https://arxiv.org/abs/2112.01527)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/5ce83994aad79cfa0f1a7945fa6a424d.png) Mask2Former架构。取自[原始论文](https://arxiv.org/abs/2112.01527)。'
- en: This model was contributed by [Shivalika Singh](https://huggingface.co/shivi)
    and [Alara Dirik](https://huggingface.co/adirik). The original code can be found
    [here](https://github.com/facebookresearch/Mask2Former).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型由[Shivalika Singh](https://huggingface.co/shivi)和[Alara Dirik](https://huggingface.co/adirik)贡献。原始代码可以在[这里](https://github.com/facebookresearch/Mask2Former)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: Mask2Former uses the same preprocessing and postprocessing steps as [MaskFormer](maskformer).
    Use [Mask2FormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor)
    or [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    to prepare images and optional targets for the model.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mask2Former使用与[MaskFormer](maskformer)相同的预处理和后处理步骤。使用[Mask2FormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor)或[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)来为模型准备图像和可选目标。
- en: To get the final segmentation, depending on the task, you can call [post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_semantic_segmentation)
    or [post_process_instance_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_instance_segmentation)
    or [post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_panoptic_segmentation).
    All three tasks can be solved using [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    output, panoptic segmentation accepts an optional `label_ids_to_fuse` argument
    to fuse instances of the target object/s (e.g. sky) together.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要获得最终的分割结果，取决于任务，您可以调用[post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_semantic_segmentation)或[post_process_instance_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_instance_segmentation)或[post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_panoptic_segmentation)。所有这三个任务都可以使用[Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)的输出来解决，全景分割接受一个可选的`label_ids_to_fuse`参数，以将目标对象（例如天空）的实例合并在一起。
- en: Resources
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with Mask2Former.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列官方Hugging Face和社区（由🌎表示）资源，可帮助您开始使用Mask2Former。
- en: Demo notebooks regarding inference + fine-tuning Mask2Former on custom data
    can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Mask2Former).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于在自定义数据上进行推理+微调Mask2Former的演示笔记本可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Mask2Former)找到。
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we will review it. The resource should ideally
    demonstrate something new instead of duplicating an existing resource.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在这里，请随时打开一个Pull Request，我们将进行审核。资源应该理想地展示一些新东西，而不是重复现有资源。
- en: Mask2FormerConfig
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mask2FormerConfig
- en: '### `class transformers.Mask2FormerConfig`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Mask2FormerConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/configuration_mask2former.py#L33)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/configuration_mask2former.py#L33)'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*, defaults to `SwinConfig()`)
    — The configuration of the backbone model. If unset, the configuration corresponding
    to `swin-base-patch4-window12-384` will be used.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*, defaults to `SwinConfig()`)
    — 主干模型的配置。如果未设置，将使用与`swin-base-patch4-window12-384`对应的配置。'
- en: '`feature_size` (`int`, *optional*, defaults to 256) — The features (channels)
    of the resulting feature maps.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_size` (`int`, *optional*, defaults to 256) — 结果特征图的特征（通道）。'
- en: '`mask_feature_size` (`int`, *optional*, defaults to 256) — The masks’ features
    size, this value will also be used to specify the Feature Pyramid Network features’
    size.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_size` (`int`, *optional*, defaults to 256) — 掩码的特征大小，此值还将用于指定特征金字塔网络特征的大小。'
- en: '`hidden_dim` (`int`, *optional*, defaults to 256) — Dimensionality of the encoder
    layers.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dim` (`int`, *optional*, defaults to 256) — 编码器层的维度。'
- en: '`encoder_feedforward_dim` (`int`, *optional*, defaults to 1024) — Dimension
    of feedforward network for deformable detr encoder used as part of pixel decoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_feedforward_dim` (`int`, *optional*, defaults to 1024) — 用作像素解码器一部分的可变形detr编码器的前馈网络维度。'
- en: '`encoder_layers` (`int`, *optional*, defaults to 6) — Number of layers in the
    deformable detr encoder used as part of pixel decoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers` (`int`, *optional*, defaults to 6) — 用作像素解码器一部分的可变形detr编码器中的层数。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 10) — Number of layers in
    the Transformer decoder.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *optional*, defaults to 10) — 变压器解码器中的层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 8) — 每个注意力层的注意力头数。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器中所有全连接层的丢失概率。'
- en: '`dim_feedforward` (`int`, *optional*, defaults to 2048) — Feature dimension
    in feedforward network for transformer decoder.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_feedforward` (`int`, *optional*, defaults to 2048) — 变压器解码器中前馈网络的特征维度。'
- en: '`pre_norm` (`bool`, *optional*, defaults to `False`) — Whether to use pre-LayerNorm
    or not for transformer decoder.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pre_norm` (`bool`, *optional*, defaults to `False`) — 是否在变压器解码器中使用预LayerNorm。'
- en: '`enforce_input_projection` (`bool`, *optional*, defaults to `False`) — Whether
    to add an input projection 1x1 convolution even if the input channels and hidden
    dim are identical in the Transformer decoder.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enforce_input_projection` (`bool`, *optional*, defaults to `False`) — 是否在Transformer解码器中添加一个输入投影1x1卷积，即使输入通道和隐藏维度相同。'
- en: '`common_stride` (`int`, *optional*, defaults to 4) — Parameter used for determining
    number of FPN levels used as part of pixel decoder.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`common_stride` (`int`, *optional*, defaults to 4) — 用于确定作为像素解码器一部分使用的FPN级别数的参数。'
- en: '`ignore_value` (`int`, *optional*, defaults to 255) — Category id to be ignored
    during training.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_value` (`int`, *optional*, defaults to 255) — 训练过程中要忽略的类别ID。'
- en: '`num_queries` (`int`, *optional*, defaults to 100) — Number of queries for
    the decoder.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_queries` (`int`, *optional*, defaults to 100) — 解码器的查询次数。'
- en: '`no_object_weight` (`int`, *optional*, defaults to 0.1) — The weight to apply
    to the null (no object) class.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_object_weight` (`int`, *optional*, defaults to 0.1) — 用于空（无对象）类的权重。'
- en: '`class_weight` (`int`, *optional*, defaults to 2.0) — The weight for the cross
    entropy loss.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_weight` (`int`, *optional*, defaults to 2.0) — 交叉熵损失的权重。'
- en: '`mask_weight` (`int`, *optional*, defaults to 5.0) — The weight for the mask
    loss.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_weight` (`int`, *optional*, defaults to 5.0) — 掩码损失的权重。'
- en: '`dice_weight` (`int`, *optional*, defaults to 5.0) — The weight for the dice
    loss.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dice_weight` (`int`, *optional*, defaults to 5.0) — dice损失的权重。'
- en: '`train_num_points` (`str` or `function`, *optional*, defaults to 12544) — Number
    of points used for sampling during loss calculation.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_num_points` (`str` or `function`, *optional*, defaults to 12544) — 在损失计算过程中用于采样的点数。'
- en: '`oversample_ratio` (`float`, *optional*, defaults to 3.0) — Oversampling parameter
    used for calculating no. of sampled points'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oversample_ratio` (`float`, *optional*, defaults to 3.0) — 用于计算采样点数的过采样参数。'
- en: '`importance_sample_ratio` (`float`, *optional*, defaults to 0.75) — Ratio of
    points that are sampled via importance sampling.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`importance_sample_ratio` (`float`, *optional*, defaults to 0.75) — 通过重要性采样抽样的点比例。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`init_xavier_std` (`float`, *optional*, defaults to 1.0) — The scaling factor
    used for the Xavier initialization gain in the HM Attention map module.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_xavier_std` (`float`, *optional*, defaults to 1.0) — 用于HM注意力图模块中Xavier初始化增益的缩放因子。'
- en: '`use_auxiliary_loss` (`boolean``, *optional*, defaults to` True`) -- If` TrueMask2FormerForUniversalSegmentationOutput`
    will contain the auxiliary losses computed using the logits from each decoder’s
    stage.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_auxiliary_loss` (`boolean``, *optional*, defaults to` True`) -- 如果`True`，`Mask2FormerForUniversalSegmentationOutput`将包含使用每个解码器阶段的logits计算的辅助损失。'
- en: '`feature_strides` (`List[int]`, *optional*, defaults to `[4, 8, 16, 32]`) —
    Feature strides corresponding to features generated from backbone network.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_strides` (`List[int]`, *optional*, defaults to `[4, 8, 16, 32]`) —
    与主干网络生成的特征对应的特征步幅。'
- en: '`output_auxiliary_logits` (`bool`, *optional*) — Should the model output its
    `auxiliary_logits` or not.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_auxiliary_logits` (`bool`, *optional*) — 模型是否输出其`auxiliary_logits`。'
- en: This is the configuration class to store the configuration of a [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel).
    It is used to instantiate a Mask2Former model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Mask2Former [facebook/mask2former-swin-small-coco-instance](https://huggingface.co/facebook/mask2former-swin-small-coco-instance)
    architecture.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)的配置。根据指定的参数实例化一个Mask2Former模型，定义模型架构。使用默认值实例化配置将产生类似于Mask2Former
    [facebook/mask2former-swin-small-coco-instance](https://huggingface.co/facebook/mask2former-swin-small-coco-instance)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: Currently, Mask2Former only supports the [Swin Transformer](swin) as backbone.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Mask2Former仅支持[Swin Transformer](swin)作为骨干网络。
- en: 'Examples:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#### `from_backbone_config`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_backbone_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/configuration_mask2former.py#L218)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/configuration_mask2former.py#L218)'
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`backbone_config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The backbone configuration.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 骨干配置。'
- en: Returns
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)'
- en: An instance of a configuration object
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个配置对象的实例
- en: Instantiate a [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    (or a derived class) from a pre-trained backbone model configuration.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练的骨干模型配置实例化一个[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)（或派生类）。
- en: MaskFormer specific outputs
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MaskFormer特定输出
- en: '### `class transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L145)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L145)'
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`, *optional*) — Last hidden states (final feature map) of the last
    stage of the encoder model (backbone). Returned when `output_hidden_states=True`
    is passed.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`，*optional*) — 编码器模型（骨干）最后阶段的最后隐藏状态（最终特征图）。当传递`output_hidden_states=True`时返回。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*) — Tuple of
    `torch.FloatTensor` (one for the output of the embeddings + one for the output
    of each stage) of shape `(batch_size, num_channels, height, width)`. Hidden-states
    (also called feature maps) of the encoder model at the output of each stage. Returned
    when `output_hidden_states=True` is passed.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*) — 编码器模型在每个阶段输出的隐藏状态（也称为特征图）的元组，形状为`(batch_size,
    num_channels, height, width)`。当传递`output_hidden_states=True`时返回。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`, *optional*) — Last hidden states (final feature
    map) of the last stage of the pixel decoder model.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`，*optional*) — 像素解码器模型最后阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, , *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage. Returned when `output_hidden_states=True` is passed.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）的元组，形状为`(batch_size, num_channels, height, width)`。当传递`output_hidden_states=True`时返回。'
- en: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — Final
    output of the transformer decoder `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — 变压器解码器的最终输出`(batch_size,
    sequence_length, hidden_size)`。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the transformer decoder at the output
    of each stage. Returned when `output_hidden_states=True` is passed.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*)
    — 变压器解码器在每个阶段输出的隐藏状态（也称为特征图）的元组，形状为`(batch_size, sequence_length, hidden_size)`。当传递`output_hidden_states=True`时返回。'
- en: '`transformer_decoder_intermediate_states` (`tuple(torch.FloatTensor)` of shape
    `(num_queries, 1, hidden_size)`) — Intermediate decoder activations, i.e. the
    output of each decoder layer, each of them gone through a layernorm.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_intermediate_states` (`tuple(torch.FloatTensor)`，形状为`(num_queries,
    1, hidden_size)`) — 中间解码器激活，即每个解码器层的输出，每个都经过了layernorm。'
- en: '`masks_queries_logits` (`tuple(torch.FloatTensor)` of shape `(batch_size, num_queries,
    height, width)`) — Mask Predictions from each layer in the transformer decoder.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_queries_logits` (`tuple(torch.FloatTensor)`，形状为`(batch_size, num_queries,
    height, width)`) — transformer解码器中每层的掩码预测。'
- en: '`attentions` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when
    `output_attentions=True` is passed) — Tuple of `tuple(torch.FloatTensor)` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Self attentions weights from transformer decoder.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的元组的元组。transformer解码器的自注意力权重。'
- en: Class for outputs of [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel).
    This class returns all the needed hidden states to compute the logits.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 用于[Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)的输出类。该类返回计算logits所需的所有隐藏状态。
- en: '### `class transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L191)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L191)'
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`loss` (`torch.Tensor`, *optional*) — The computed loss, returned when labels
    are present.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.Tensor`，*可选*) — 计算得到的损失，在存在标签时返回。'
- en: '`class_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, num_labels + 1)` representing the proposed classes for each query.
    Note the `+ 1` is needed because we incorporate the null class.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_queries_logits` (`torch.FloatTensor`) — 一个形状为`(batch_size, num_queries,
    num_labels + 1)`的张量，表示每个查询的提议类别。请注意，`+ 1`是因为我们包含了空类别。'
- en: '`masks_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, height, width)` representing the proposed masks for each query.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_queries_logits` (`torch.FloatTensor`) — 一个形状为`(batch_size, num_queries,
    height, width)`的张量，表示每个查询的提议掩码。'
- en: '`auxiliary_logits` (`List[Dict(str, torch.FloatTensor)]`, *optional*) — List
    of class and mask predictions from each layer of the transformer decoder.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_logits` (`List[Dict(str, torch.FloatTensor)]`，*可选*) — transformer解码器每层的类别和掩码预测的列表。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Last hidden states (final feature map) of the last stage of
    the encoder model (backbone).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 编码器模型（骨干）最后阶段的最后隐藏状态（最终特征图）。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the encoder model at the output of
    each stage.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的元组的`torch.FloatTensor`（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。编码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — Last hidden states (final feature map) of the
    last stage of the pixel decoder model.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 像素解码器模型最后阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的元组的`torch.FloatTensor`（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — Final
    output of the transformer decoder `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — transformer解码器的最终输出`(batch_size,
    sequence_length, hidden_size)`。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*,
    returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the transformer decoder at the output
    of each stage.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的元组的`torch.FloatTensor`（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。transformer解码器在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`attentions` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `tuple(torch.FloatTensor)` (one for each layer) of shape `(batch_size,
    num_heads, sequence_length, sequence_length)`. Self and Cross Attentions weights
    from transformer decoder.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(tuple(torch.FloatTensor))`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的元组的元组。来自transformer解码器的自注意力和交叉注意力权重。'
- en: Class for outputs of `Mask2FormerForUniversalSegmentationOutput`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`Mask2FormerForUniversalSegmentationOutput`的输出类。'
- en: This output can be directly passed to [post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_semantic_segmentation)
    or [post_process_instance_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_instance_segmentation)
    or [post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_panoptic_segmentation)
    to compute final segmentation maps. Please, see [`~Mask2FormerImageProcessor]
    for details regarding usage.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出可以直接传递给[post_process_semantic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_semantic_segmentation)或[post_process_instance_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_instance_segmentation)或[post_process_panoptic_segmentation()](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor.post_process_panoptic_segmentation)来计算最终的分割地图。请参阅[`~Mask2FormerImageProcessor]以获取有关用法的详细信息。
- en: Mask2FormerModel
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mask2FormerModel
- en: '### `class transformers.Mask2FormerModel`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Mask2FormerModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2189)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2189)'
- en: '[PRE5]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Mask2Former Model outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Mask2Former模型输出原始隐藏状态，没有特定的头部。这个模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2203)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2203)'
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `AutoImageProcessor.preprocess` for details.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（`torch.FloatTensor`，形状为`(batch_size, num_channels, height, width)`）—
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅`AutoImageProcessor.preprocess`。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask`（形状为`(batch_size, height, width)`的`torch.LongTensor`，*可选*）— 用于避免在填充像素值上执行注意力的掩码。掩码值选择在`[0,
    1]`中：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示真实像素（即`未掩码`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示填充像素（即`掩码`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of Detr’s decoder attention layers.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回Detr解码器注意力层的注意力张量。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a `~Mask2FormerModelOutput`
    instead of a plain tuple.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回`~Mask2FormerModelOutput`而不是普通元组。'
- en: Returns
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig))
    and inputs.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerModelOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)）和输入的各种元素。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`, *optional*) — Last hidden states (final feature map) of the last
    stage of the encoder model (backbone). Returned when `output_hidden_states=True`
    is passed.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`，*可选*）—
    编码器模型（骨干）最后阶段的最后隐藏状态（最终特征图）。当传递`output_hidden_states=True`时返回。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*) — Tuple of
    `torch.FloatTensor` (one for the output of the embeddings + one for the output
    of each stage) of shape `(batch_size, num_channels, height, width)`. Hidden-states
    (also called feature maps) of the encoder model at the output of each stage. Returned
    when `output_hidden_states=True` is passed.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*）— 形状为`(batch_size,
    num_channels, height, width)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个阶段的输出）。编码器模型在每个阶段输出的隐藏状态（也称为特征图）。当传递`output_hidden_states=True`时返回。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`, *optional*) — Last hidden states (final feature
    map) of the last stage of the pixel decoder model.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`，*可选*）—
    像素解码器模型最后阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, , *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage. Returned when `output_hidden_states=True` is passed.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个阶段的输出）。像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）。当传递`output_hidden_states=True`时返回。'
- en: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — Final
    output of the transformer decoder `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state`（`tuple(torch.FloatTensor)`）— 变压器解码器的最终输出`(batch_size,
    sequence_length, hidden_size)`。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the transformer decoder at the output
    of each stage. Returned when `output_hidden_states=True` is passed.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*）— 形状为`(batch_size,
    sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个阶段的输出）。变压器解码器在每个阶段输出的隐藏状态（也称为特征图）。当传递`output_hidden_states=True`时返回。'
- en: '`transformer_decoder_intermediate_states` (`tuple(torch.FloatTensor)` of shape
    `(num_queries, 1, hidden_size)`) — Intermediate decoder activations, i.e. the
    output of each decoder layer, each of them gone through a layernorm.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_intermediate_states`（形状为`(num_queries, 1, hidden_size)`的`tuple(torch.FloatTensor)`)
    — 中间解码器激活，即每个解码器层的输出，每个都经过了一个layernorm。'
- en: '`masks_queries_logits` (`tuple(torch.FloatTensor)` of shape `(batch_size, num_queries,
    height, width)`) Mask Predictions from each layer in the transformer decoder.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_queries_logits`（形状为`(batch_size, num_queries, height, width)`的`tuple(torch.FloatTensor)`)
    — 变压器解码器中每个层的掩码预测。'
- en: '`attentions` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when
    `output_attentions=True` is passed) — Tuple of `tuple(torch.FloatTensor)` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Self attentions weights from transformer decoder.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tuple(torch.FloatTensor)`元组（每个层一个）。来自变压器解码器的自注意权重。'
- en: '`Mask2FormerModelOutput`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`Mask2FormerModelOutput`'
- en: The [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    forward method, overrides the `__call__` special method.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Mask2FormerForUniversalSegmentation
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mask2FormerForUniversalSegmentation
- en: '### `class transformers.Mask2FormerForUniversalSegmentation`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Mask2FormerForUniversalSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2293)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2293)'
- en: '[PRE8]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The Mask2Former Model with heads on top for instance/semantic/panoptic segmentation.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Mask2Former模型在顶部具有用于实例/语义/全景分割的头。这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2350)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/modeling_mask2former.py#L2350)'
- en: '[PRE9]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `AutoImageProcessor.preprocess` for details.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅`AutoImageProcessor.preprocess`。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor`，形状为`(batch_size, height, width)`，*optional*)
    — 避免在填充像素值上执行注意力的掩码。选择的掩码值在`[0, 1]`中：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于真实像素为1（即`not masked`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于填充像素为0（即`masked`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of Detr’s decoder attention layers.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回Detr解码器注意力层的注意力张量。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a `~Mask2FormerModelOutput`
    instead of a plain tuple.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回`~Mask2FormerModelOutput`而不是普通元组。'
- en: '`mask_labels` (`List[torch.Tensor]`, *optional*) — List of mask labels of shape
    `(num_labels, height, width)` to be fed to a model'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_labels` (`List[torch.Tensor]`, *optional*) — 形状为`(num_labels, height,
    width)`的掩码标签列表，用于馈送到模型。'
- en: '`class_labels` (`List[torch.LongTensor]`, *optional*) — list of target class
    labels of shape `(num_labels, height, width)` to be fed to a model. They identify
    the labels of `mask_labels`, e.g. the label of `mask_labels[i][j]` if `class_labels[i][j]`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels` (`List[torch.LongTensor]`, *optional*) — 形状为`(num_labels, height,
    width)`的目标类别标签列表，用于馈送到模型。它们标识`mask_labels`的标签，例如，如果`class_labels[i][j]`的标签是`mask_labels[i][j]`。 '
- en: Returns
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig))
    and inputs.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含各种元素，这取决于配置（[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)）和输入。
- en: '`loss` (`torch.Tensor`, *optional*) — The computed loss, returned when labels
    are present.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.Tensor`, *optional*) — 计算的损失，在存在标签时返回。'
- en: '`class_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, num_labels + 1)` representing the proposed classes for each query.
    Note the `+ 1` is needed because we incorporate the null class.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_queries_logits` (`torch.FloatTensor`) — 形状为`(batch_size, num_queries,
    num_labels + 1)`的张量，表示每个查询的提议类别。请注意，`+ 1`是因为我们包含了空类。'
- en: '`masks_queries_logits` (`torch.FloatTensor`) — A tensor of shape `(batch_size,
    num_queries, height, width)` representing the proposed masks for each query.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_queries_logits` (`torch.FloatTensor`) — 形状为`(batch_size, num_queries,
    height, width)`的张量，表示每个查询的提议掩码。'
- en: '`auxiliary_logits` (`List[Dict(str, torch.FloatTensor)]`, *optional*) — List
    of class and mask predictions from each layer of the transformer decoder.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_logits` (`List[Dict(str, torch.FloatTensor)]`, *optional*) — 来自变压器解码器每一层的类别和掩码预测的列表。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Last hidden states (final feature map) of the last stage of
    the encoder model (backbone).'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 编码器模型（骨干）最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the encoder model at the output of
    each stage.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。编码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size,
    num_channels, height, width)`) — Last hidden states (final feature map) of the
    last stage of the pixel decoder model.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels,
    height, width)`) — 像素解码器模型最后一个阶段的最后隐藏状态（最终特征图）。'
- en: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the pixel decoder model at the output
    of each stage.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*，当传递 `output_hidden_states=True`
    或 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, num_channels, height,
    width)` 的 `torch.FloatTensor` 元组。像素解码器模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — Final
    output of the transformer decoder `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_last_hidden_state` (`tuple(torch.FloatTensor)`) — 变换器解码器的最终输出
    `(batch_size, sequence_length, hidden_size)`。'
- en: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*,
    returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the transformer decoder at the output
    of each stage.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*，当传递 `output_hidden_states=True`
    或 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组。变换器解码器在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`attentions` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `tuple(torch.FloatTensor)` (one for each layer) of shape `(batch_size,
    num_heads, sequence_length, sequence_length)`. Self and Cross Attentions weights
    from transformer decoder.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(tuple(torch.FloatTensor))`, *可选*，当传递 `output_attentions=True`
    或 `config.output_attentions=True` 时返回) — 形状为 `(batch_size, num_heads, sequence_length,
    sequence_length)` 的 `tuple(torch.FloatTensor)` 元组。变换器解码器的自注意力和交叉注意力权重。'
- en: '`Mask2FormerUniversalSegmentationOutput`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`Mask2FormerUniversalSegmentationOutput`'
- en: The [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    forward method, overrides the `__call__` special method.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    的前向方法，覆盖 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用 `Module` 实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'Instance segmentation example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 实例分割示例：
- en: '[PRE10]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Semantic segmentation example:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割示例：
- en: '[PRE11]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Panoptic segmentation example:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 全景分割示例：
- en: '[PRE12]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Mask2FormerImageProcessor
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mask2FormerImageProcessor
- en: '### `class transformers.Mask2FormerImageProcessor`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Mask2FormerImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L345)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L345)'
- en: '[PRE13]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    input to a certain `size`.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *可选*，默认为 `True`) — 是否将输入调整大小到特定的 `size`。'
- en: '`size` (`int`, *optional*, defaults to 800) — Resize the input to the given
    size. Only has an effect if `do_resize` is set to `True`. If size is a sequence
    like `(width, height)`, output size will be matched to this. If size is an int,
    smaller edge of the image will be matched to this number. i.e, if `height > width`,
    then image will be rescaled to `(size * height / width, size)`.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`int`, *可选*，默认为800) — 调整输入大小为给定大小。仅在 `do_resize` 设置为 `True` 时有效。如果
    size 是一个类似 `(width, height)` 的序列，输出大小将匹配到这个大小。如果 size 是一个整数，图像的较小边将匹配到这个数字。即，如果
    `height > width`，那么图像将被重新缩放为 `(size * height / width, size)`。'
- en: '`size_divisor` (`int`, *optional*, defaults to 32) — Some backbones need images
    divisible by a certain number. If not passed, it defaults to the value used in
    Swin Transformer.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisor` (`int`, *可选*，默认为32) — 一些主干网络需要可被某个数字整除的图像。如果未传递，则默认为 Swin Transformer
    中使用的值。'
- en: '`resample` (`int`, *optional*, defaults to `Resampling.BILINEAR`) — An optional
    resampling filter. This can be one of `PIL.Image.Resampling.NEAREST`, `PIL.Image.Resampling.BOX`,
    `PIL.Image.Resampling.BILINEAR`, `PIL.Image.Resampling.HAMMING`, `PIL.Image.Resampling.BICUBIC`
    or `PIL.Image.Resampling.LANCZOS`. Only has an effect if `do_resize` is set to
    `True`.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`int`, *可选*，默认为 `Resampling.BILINEAR`) — 可选的重采样滤波器。可以是 `PIL.Image.Resampling.NEAREST`、`PIL.Image.Resampling.BOX`、`PIL.Image.Resampling.BILINEAR`、`PIL.Image.Resampling.HAMMING`、`PIL.Image.Resampling.BICUBIC`
    或 `PIL.Image.Resampling.LANCZOS` 中的一个。仅在 `do_resize` 设置为 `True` 时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the input to a certain `scale`.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *可选*，默认为 `True`) — 是否将输入重新缩放到特定的 `scale`。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `1/ 255`) — Rescale the
    input by the given factor. Only has an effect if `do_rescale` is set to `True`.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *可选*，默认为 `1/255`) — 通过给定因子重新缩放输入。仅在 `do_rescale`
    设置为 `True` 时有效。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether or not to
    normalize the input with mean and standard deviation.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *可选*，默认为 `True`) — 是否对输入进行均值和标准差归一化。'
- en: '`image_mean` (`int`, *optional*, defaults to `[0.485, 0.456, 0.406]`) — The
    sequence of means for each channel, to be used when normalizing images. Defaults
    to the ImageNet mean.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`int`, *可选*，默认为 `[0.485, 0.456, 0.406]`) — 每个通道的均值序列，用于归一化图像。默认为
    ImageNet 均值。'
- en: '`image_std` (`int`, *optional*, defaults to `[0.229, 0.224, 0.225]`) — The
    sequence of standard deviations for each channel, to be used when normalizing
    images. Defaults to the ImageNet std.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`int`, *可选*，默认为 `[0.229, 0.224, 0.225]`) — 每个通道的标准差序列，用于归一化图像。默认为
    ImageNet 标准差。'
- en: '`ignore_index` (`int`, *optional*) — Label to be assigned to background pixels
    in segmentation maps. If provided, segmentation map pixels denoted with 0 (background)
    will be replaced with `ignore_index`.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reduce_labels` (`bool`, *optional*, defaults to `False`) — Whether or not
    to decrement all label values of segmentation maps by 1\. Usually used for datasets
    where 0 is used for background, and background itself is not included in all classes
    of a dataset (e.g. ADE20k). The background label will be replaced by `ignore_index`.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constructs a Mask2Former image processor. The image processor can be used to
    prepare image(s) and optional targets for the model.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: This image processor inherits from `BaseImageProcessor` which contains most
    of the main methods. Users should refer to this superclass for more information
    regarding those methods.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '#### `preprocess`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L670)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `encode_inputs`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L858)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values_list` (`List[ImageInput]`) — List of images (pixel values) to
    be padded. Each image should be a tensor of shape `(channels, height, width)`.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`segmentation_maps` (`ImageInput`, *optional*) — The corresponding semantic
    segmentation maps with the pixel-wise annotations.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(`bool`, *optional*, defaults to `True`): Whether or not to pad images up to
    the largest image in a batch and create a pixel mask.'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If left to the default, will return a pixel mask that is:'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`instance_id_to_semantic_id` (`List[Dict[int, int]]` or `Dict[int, int]`, *optional*)
    — A mapping between object instance ids and class ids. If passed, `segmentation_maps`
    is treated as an instance segmentation map where each pixel represents an instance
    id. Can be provided as a single dictionary with a global/dataset-level mapping
    or as a list of dictionaries (one per image), to map instance ids in each image
    separately.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of NumPy arrays. If set to `''pt''`,
    return PyTorch `torch.Tensor` objects.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format of the input image. If not provided, it will be inferred.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'A [BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)
    with the following fields:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` — Pixel values to be fed to a model.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pixel_mask` — Pixel mask to be fed to a model (when `=True` or if `pixel_mask`
    is in `self.model_input_names`).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_labels` — Optional list of mask labels of shape `(labels, height, width)`
    to be fed to a model (when `annotations` are provided).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`class_labels` — Optional list of class labels of shape `(labels)` to be fed
    to a model (when `annotations` are provided). They identify the labels of `mask_labels`,
    e.g. the label of `mask_labels[i][j]` if `class_labels[i][j]`.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pad images up to the largest image in a batch and create a corresponding `pixel_mask`.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Mask2Former addresses semantic segmentation with a mask classification paradigm,
    thus input segmentation maps will be converted to lists of binary masks and their
    respective labels. Let’s see an example, assuming `segmentation_maps = [[2,6,7,9]]`,
    the output will contain `mask_labels = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]`
    (four binary masks) and `class_labels = [2,6,7,9]`, the labels for each mask.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '#### `post_process_semantic_segmentation`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L961)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '`outputs` ([Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation))
    — Raw outputs of the model.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_sizes` (`List[Tuple[int, int]]`, *optional*) — List of length (batch_size),
    where each list item (`Tuple[int, int]]`) corresponds to the requested final size
    (height, width) of each prediction. If left to None, predictions will not be resized.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '`List[torch.Tensor]`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: A list of length `batch_size`, where each item is a semantic segmentation map
    of shape (height, width) corresponding to the target_sizes entry (if `target_sizes`
    is specified). Each entry of each `torch.Tensor` correspond to a semantic class
    id.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Converts the output of [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    into semantic segmentation maps. Only supports PyTorch.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '#### `post_process_instance_segmentation`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L1016)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '`outputs` ([Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation))
    — Raw outputs of the model.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The probability score
    threshold to keep predicted instance masks.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — The
    overlap mask area threshold to merge or discard small disconnected parts within
    each binary instance mask.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_sizes` (`List[Tuple]`, *optional*) — List of length (batch_size), where
    each list item (`Tuple[int, int]]`) corresponds to the requested final size (height,
    width) of each prediction. If left to None, predictions will not be resized.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_coco_annotation` (`bool`, *optional*, defaults to `False`) — If set
    to `True`, segmentation maps are returned in COCO run-length encoding (RLE) format.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_binary_maps` (`bool`, *optional*, defaults to `False`) — If set to
    `True`, segmentation maps are returned as a concatenated tensor of binary segmentation
    maps (one per detected instance).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of dictionaries, one per image, each dictionary containing two keys:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '`segmentation` — A tensor of shape `(height, width)` where each pixel represents
    a `segment_id` or `List[List]` run-length encoding (RLE) of the segmentation map
    if return_coco_annotation is set to `True`. Set to `None` if no mask if found
    above `threshold`.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`segments_info` — A dictionary that contains additional information on each
    segment.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`id` — An integer representing the `segment_id`.'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`label_id` — An integer representing the label / semantic class id corresponding
    to `segment_id`.'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` — Prediction score of segment with `segment_id`.'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Converts the output of `Mask2FormerForUniversalSegmentationOutput` into instance
    segmentation predictions. Only supports PyTorch.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '#### `post_process_panoptic_segmentation`'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mask2former/image_processing_mask2former.py#L1135)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '`outputs` (`Mask2FormerForUniversalSegmentationOutput`) — The outputs from
    [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The probability score
    threshold to keep predicted instance masks.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_threshold` (`float`, *optional*, defaults to 0.5) — Threshold to use
    when turning the predicted masks into binary values.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`overlap_mask_area_threshold` (`float`, *optional*, defaults to 0.8) — The
    overlap mask area threshold to merge or discard small disconnected parts within
    each binary instance mask.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`label_ids_to_fuse` (`Set[int]`, *optional*) — The labels in this state will
    have all their instances be fused together. For instance we could say there can
    only be one sky in an image, but several persons, so the label ID for sky would
    be in that set, but not the one for person.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_sizes` (`List[Tuple]`, *optional*) — List of length (batch_size), where
    each list item (`Tuple[int, int]]`) corresponds to the requested final size (height,
    width) of each prediction in batch. If left to None, predictions will not be resized.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of dictionaries, one per image, each dictionary containing two keys:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '`segmentation` — a tensor of shape `(height, width)` where each pixel represents
    a `segment_id`, set to `None` if no mask if found above `threshold`. If `target_sizes`
    is specified, segmentation is resized to the corresponding `target_sizes` entry.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`segments_info` — A dictionary that contains additional information on each
    segment.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`id` — an integer representing the `segment_id`.'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`label_id` — An integer representing the label / semantic class id corresponding
    to `segment_id`.'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`was_fused` — a boolean, `True` if `label_id` was in `label_ids_to_fuse`, `False`
    otherwise. Multiple instances of the same class / label were fused and assigned
    a single `segment_id`.'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` — Prediction score of segment with `segment_id`.'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Converts the output of `Mask2FormerForUniversalSegmentationOutput` into image
    panoptic segmentation predictions. Only supports PyTorch.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
