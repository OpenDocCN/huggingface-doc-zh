- en: Utilities for Image Processors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/internal/image_processing_utils](https://huggingface.co/docs/transformers/v4.37.2/en/internal/image_processing_utils)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/28.7e553b55.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Tip.c2ecdbf4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Docstring.17db21ae.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/ExampleCodeBlock.4f515aa9.js">
  prefs: []
  type: TYPE_NORMAL
- en: This page lists all the utility functions used by the image processors, mainly
    the functional transformations used to process the images.
  prefs: []
  type: TYPE_NORMAL
- en: Most of those are only useful if you are studying the code of the image processors
    in the library.
  prefs: []
  type: TYPE_NORMAL
- en: Image Transformations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.center_crop'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L407)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image: ndarray size: Tuple data_format: Union = None input_data_format: Union
    = None return_numpy: Optional = None ) â†’ `np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image** (`np.ndarray`) â€” The image to crop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**size** (`Tuple[int, int]`) â€” The target size for the cropped image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data_format** (`str` or `ChannelDimension`, *optional*) â€” The channel dimension
    format for the output image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format. If unset, will use the inferred format of the input image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_data_format** (`str` or `ChannelDimension`, *optional*) â€” The channel
    dimension format for the input image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format. If unset, will use the inferred format of the input image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_numpy** (`bool`, *optional*) â€” Whether or not to return the cropped
    image as a numpy array. Used for backwards compatibility with the previous ImageFeatureExtractionMixin
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Unset: will return the same type as the input image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`True`: will return a numpy array.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`False`: will return a `PIL.Image.Image` object.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: The cropped image.
  prefs: []
  type: TYPE_NORMAL
- en: Crops the `image` to the specified `size` using a center crop. Note that if
    the image is too small to be cropped to the size given, it will be padded (so
    the returned result will always be of size `size`).
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.center_to_corners_format'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L537)'
  prefs: []
  type: TYPE_NORMAL
- en: '( bboxes_center: TensorType )'
  prefs: []
  type: TYPE_NORMAL
- en: Converts bounding boxes from center format to corners format.
  prefs: []
  type: TYPE_NORMAL
- en: 'center format: contains the coordinate for the center of the box and its width,
    height dimensions (center_x, center_y, width, height) corners format: contains
    the coodinates for the top-left and bottom-right corners of the box (top_left_x,
    top_left_y, bottom_right_x, bottom_right_y)'
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.corners_to_center_format'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L597)'
  prefs: []
  type: TYPE_NORMAL
- en: '( bboxes_corners: TensorType )'
  prefs: []
  type: TYPE_NORMAL
- en: Converts bounding boxes from corners format to center format.
  prefs: []
  type: TYPE_NORMAL
- en: 'corners format: contains the coordinates for the top-left and bottom-right
    corners of the box (top_left_x, top_left_y, bottom_right_x, bottom_right_y) center
    format: contains the coordinate for the center of the box and its the width, height
    dimensions (center_x, center_y, width, height)'
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.id_to_rgb'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L631)'
  prefs: []
  type: TYPE_NORMAL
- en: ( id_map )
  prefs: []
  type: TYPE_NORMAL
- en: Converts unique ID to RGB color.
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.normalize'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L347)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image: ndarray mean: Union std: Union data_format: Optional = None input_data_format:
    Union = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image** (`np.ndarray`) â€” The image to normalize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mean** (`float` or `Iterable[float]`) â€” The mean to use for normalization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**std** (`float` or `Iterable[float]`) â€” The standard deviation to use for
    normalization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data_format** (`ChannelDimension`, *optional*) â€” The channel dimension format
    of the output image. If unset, will use the inferred format from the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_data_format** (`ChannelDimension`, *optional*) â€” The channel dimension
    format of the input image. If unset, will use the inferred format from the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalizes `image` using the mean and standard deviation specified by `mean`
    and `std`.
  prefs: []
  type: TYPE_NORMAL
- en: image = (image - mean) / std
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.pad'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L661)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image: ndarray padding: Union mode: PaddingMode = <PaddingMode.CONSTANT:
    ''constant''> constant_values: Union = 0.0 data_format: Union = None input_data_format:
    Union = None ) â†’ `np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image** (`np.ndarray`) â€” The image to pad.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**padding** (`int` or `Tuple[int, int]` or `Iterable[Tuple[int, int]]`) â€” Padding
    to apply to the edges of the height, width axes. Can be one of three formats:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`((before_height, after_height), (before_width, after_width))` unique pad widths
    for each axis.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`((before, after),)` yields same before and after pad for height and width.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(pad,)` or int is a shortcut for before = after = pad width for all axes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mode** (`PaddingMode`) â€” The padding mode to use. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"constant"`: pads with a constant value.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"reflect"`: pads with the reflection of the vector mirrored on the first and
    last values of the vector along each axis.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"replicate"`: pads with the replication of the last value on the edge of the
    array along each axis.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"symmetric"`: pads with the reflection of the vector mirrored along the edge
    of the array.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**constant_values** (`float` or `Iterable[float]`, *optional*) â€” The value
    to use for the padding if `mode` is `"constant"`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data_format** (`str` or `ChannelDimension`, *optional*) â€” The channel dimension
    format for the output image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format. If unset, will use same as the input image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_data_format** (`str` or `ChannelDimension`, *optional*) â€” The channel
    dimension format for the input image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format. If unset, will use the inferred format of the input image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: The padded image.
  prefs: []
  type: TYPE_NORMAL
- en: Pads the `image` with the specified (height, width) `padding` and `mode`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.rgb_to_id'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L620)'
  prefs: []
  type: TYPE_NORMAL
- en: ( color )
  prefs: []
  type: TYPE_NORMAL
- en: Converts RGB color to unique ID.
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.rescale'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L92)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image: ndarray scale: float data_format: Optional = None dtype: dtype = <class
    ''numpy.float32''> input_data_format: Union = None ) â†’ `np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image** (`np.ndarray`) â€” The image to rescale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scale** (`float`) â€” The scale to use for rescaling the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data_format** (`ChannelDimension`, *optional*) â€” The channel dimension format
    of the image. If not provided, it will be the same as the input image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dtype** (`np.dtype`, *optional*, defaults to `np.float32`) â€” The dtype of
    the output image. Defaults to `np.float32`. Used for backwards compatibility with
    feature extractors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_data_format** (`ChannelDimension`, *optional*) â€” The channel dimension
    format of the input image. If not provided, it will be inferred from the input
    image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: The rescaled image.
  prefs: []
  type: TYPE_NORMAL
- en: Rescales `image` by `scale`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.resize'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L276)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image: ndarray size: Tuple resample: PILImageResampling = None reducing_gap:
    Optional = None data_format: Optional = None return_numpy: bool = True input_data_format:
    Union = None ) â†’ `np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image** (`np.ndarray`) â€” The image to resize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**size** (`Tuple[int, int]`) â€” The size to use for resizing the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resample** (`int`, *optional*, defaults to `PILImageResampling.BILINEAR`)
    â€” The filter to user for resampling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reducing_gap** (`int`, *optional*) â€” Apply optimization by resizing the image
    in two steps. The bigger `reducing_gap`, the closer the result to the fair resampling.
    See corresponding Pillow documentation for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data_format** (`ChannelDimension`, *optional*) â€” The channel dimension format
    of the output image. If unset, will use the inferred format from the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_numpy** (`bool`, *optional*, defaults to `True`) â€” Whether or not
    to return the resized image as a numpy array. If False a `PIL.Image.Image` object
    is returned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_data_format** (`ChannelDimension`, *optional*) â€” The channel dimension
    format of the input image. If unset, will use the inferred format from the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: The resized image.
  prefs: []
  type: TYPE_NORMAL
- en: Resizes `image` to `(height, width)` specified by `size` using the PIL library.
  prefs: []
  type: TYPE_NORMAL
- en: '#### transformers.image_transforms.to_pil_image'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_transforms.py#L157)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image: Union do_rescale: Optional = None input_data_format: Union = None
    ) â†’ `PIL.Image.Image`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image** (`PIL.Image.Image` or `numpy.ndarray` or `torch.Tensor` or `tf.Tensor`)
    â€” The image to convert to the `PIL.Image` format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**do_rescale** (`bool`, *optional*) â€” Whether or not to apply the scaling factor
    (to make pixel values integers between 0 and 255). Will default to `True` if the
    image type is a floating type and casting to `int` would result in a loss of precision,
    and `False` otherwise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_data_format** (`ChannelDimension`, *optional*) â€” The channel dimension
    format of the input image. If unset, will use the inferred format from the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`PIL.Image.Image`'
  prefs: []
  type: TYPE_NORMAL
- en: The converted image.
  prefs: []
  type: TYPE_NORMAL
- en: Converts `image` to a PIL Image. Optionally rescales it and puts the channel
    dimension back as the last axis if needed.
  prefs: []
  type: TYPE_NORMAL
- en: ImageProcessingMixin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.ImageProcessingMixin'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L68)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is an image processor mixin used to provide saving/loading functionality
    for sequential and image feature extractors.
  prefs: []
  type: TYPE_NORMAL
- en: '#### fetch_images'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L523)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image_url_or_urls: Union )'
  prefs: []
  type: TYPE_NORMAL
- en: Convert a single or a list of urls into the corresponding `PIL.Image` objects.
  prefs: []
  type: TYPE_NORMAL
- en: If a single url is passed, the return value will be a single object. If a list
    is passed a list of objects is returned.
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_dict'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L386)'
  prefs: []
  type: TYPE_NORMAL
- en: '( image_processor_dict: Dict **kwargs ) â†’ [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**image_processor_dict** (`Dict[str, Any]`) â€” Dictionary that will be used
    to instantiate the image processor object. Such a dictionary can be retrieved
    from a pretrained checkpoint by leveraging the [to_dict()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.to_dict)
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`) â€” Additional parameters from which to initialize
    the image processor object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)'
  prefs: []
  type: TYPE_NORMAL
- en: The image processor object instantiated from those parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Instantiates a type of [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    from a Python dictionary of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_json_file'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L443)'
  prefs: []
  type: TYPE_NORMAL
- en: '( json_file: Union ) â†’ A image processor of type [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**json_file** (`str` or `os.PathLike`) â€” Path to the JSON file containing the
    parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A image processor of type [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
  prefs: []
  type: TYPE_NORMAL
- en: The image_processor object instantiated from that JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: Instantiates a image processor of type [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    from the path to a JSON file of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L95)'
  prefs: []
  type: TYPE_NORMAL
- en: '( pretrained_model_name_or_path: Union cache_dir: Union = None force_download:
    bool = False local_files_only: bool = False token: Union = None revision: str
    = ''main'' **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) â€” This can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a string, the *model id* of a pretrained image_processor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path to a *directory* containing a image processor file saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path or url to a saved image processor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) â€” Path to a directory in
    which a downloaded pretrained model image processor should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force to (re-)download the image processor files and override the cached versions
    if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) â€” Whether or
    not to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`str` or `bool`, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) â€” The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a type of [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    from an image processor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#### get_image_processor_dict'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L271)'
  prefs: []
  type: TYPE_NORMAL
- en: '( pretrained_model_name_or_path: Union **kwargs ) â†’ `Tuple[Dict, Dict]`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) â€” The identifier
    of the pre-trained checkpoint from which we want the dictionary of parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**subfolder** (`str`, *optional*, defaults to `""`) â€” In case the relevant
    files are located inside a subfolder of the model repo on huggingface.co, you
    can specify the folder name here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Tuple[Dict, Dict]`'
  prefs: []
  type: TYPE_NORMAL
- en: The dictionary(ies) that will be used to instantiate the image processor object.
  prefs: []
  type: TYPE_NORMAL
- en: From a `pretrained_model_name_or_path`, resolve to a dictionary of parameters,
    to be used for instantiating a image processor of type `~image_processor_utils.ImageProcessingMixin`
    using `from_dict`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### push_to_hub'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
  prefs: []
  type: TYPE_NORMAL
- en: '( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None
    private: Optional = None token: Union = None max_shard_size: Union = ''5GB'' create_pr:
    bool = False safe_serialization: bool = True revision: str = None commit_description:
    str = None tags: Optional = None **deprecated_kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**repo_id** (`str`) â€” The name of the repository you want to push your image
    processor to. It should contain your organization name when pushing to a given
    organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_temp_dir** (`bool`, *optional*) â€” Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**commit_message** (`str`, *optional*) â€” Message to commit while pushing. Will
    default to `"Upload image processor"`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**private** (`bool`, *optional*) â€” Whether or not the repository created should
    be private.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`bool` or `str`, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_shard_size** (`int` or `str`, *optional*, defaults to `"5GB"`) â€” Only
    applicable for models. The maximum size for a checkpoint before being sharded.
    Checkpoints shard will then be each of size lower than this size. If expressed
    as a string, needs to be digits followed by a unit (like `"5MB"`). We default
    it to `"5GB"` so that users can easily load models on free-tier Google Colab instances
    without any CPU OOM issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**create_pr** (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    create a PR with the uploaded files or directly commit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**safe_serialization** (`bool`, *optional*, defaults to `True`) â€” Whether or
    not to convert the model weights in safetensors format for safer serialization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*) â€” Branch to push the uploaded files to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**commit_description** (`str`, *optional*) â€” The description of the commit
    that will be created'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tags** (`List[str]`, *optional*) â€” List of tags to push on the Hub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upload the image processor file to the ðŸ¤— Model Hub.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#### register_for_auto_class'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L497)'
  prefs: []
  type: TYPE_NORMAL
- en: ( auto_class = 'AutoImageProcessor' )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**auto_class** (`str` or `type`, *optional*, defaults to `"AutoImageProcessor
    "`) â€” The auto class to register this new image processor with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Register this class with a given auto class. This should only be used for custom
    image processors as the ones in the library are already mapped with `AutoImageProcessor`
    .
  prefs: []
  type: TYPE_NORMAL
- en: This API is experimental and may have some slight breaking changes in the next
    releases.
  prefs: []
  type: TYPE_NORMAL
- en: '#### save_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L210)'
  prefs: []
  type: TYPE_NORMAL
- en: '( save_directory: Union push_to_hub: bool = False **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**save_directory** (`str` or `os.PathLike`) â€” Directory where the image processor
    JSON file will be saved (will be created if it does not exist).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**push_to_hub** (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`, *optional*) â€” Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save an image processor object to the directory `save_directory`, so that it
    can be re-loaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: '#### to_dict'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L431)'
  prefs: []
  type: TYPE_NORMAL
- en: ( ) â†’ `Dict[str, Any]`
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, Any]`'
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary of all the attributes that make up this image processor instance.
  prefs: []
  type: TYPE_NORMAL
- en: Serializes this instance to a Python dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '#### to_json_file'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L483)'
  prefs: []
  type: TYPE_NORMAL
- en: '( json_file_path: Union )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**json_file_path** (`str` or `os.PathLike`) â€” Path to the JSON file in which
    this image_processor instanceâ€™s parameters will be saved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save this instance to a JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: '#### to_json_string'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L462)'
  prefs: []
  type: TYPE_NORMAL
- en: ( ) â†’ `str`
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  prefs: []
  type: TYPE_NORMAL
- en: String containing all the attributes that make up this feature_extractor instance
    in JSON format.
  prefs: []
  type: TYPE_NORMAL
- en: Serializes this instance to a JSON string.
  prefs: []
  type: TYPE_NORMAL
