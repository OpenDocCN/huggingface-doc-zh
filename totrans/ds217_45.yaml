- en: Load tabular data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载表格数据
- en: 'Original text: [https://huggingface.co/docs/datasets/tabular_load](https://huggingface.co/docs/datasets/tabular_load)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/tabular_load](https://huggingface.co/docs/datasets/tabular_load)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'A tabular dataset is a generic dataset used to describe any data stored in
    rows and columns, where the rows represent an example and the columns represent
    a feature (can be continuous or categorical). These datasets are commonly stored
    in CSV files, Pandas DataFrames, and in database tables. This guide will show
    you how to load and create a tabular dataset from:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据集是用于描述以行和列存储的任何数据的通用数据集，其中行代表一个示例，列代表一个特征（可以是连续的或分类的）。这些数据集通常存储在CSV文件、Pandas数据框和数据库表中。本指南将向您展示如何从以下内容加载和创建表格数据集：
- en: CSV files
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSV文件
- en: Pandas DataFrames
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas数据框
- en: Databases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库
- en: CSV files
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CSV文件
- en: '🤗 Datasets can read CSV files by specifying the generic `csv` dataset builder
    name in the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    method. To load more than one CSV file, pass them as a list to the `data_files`
    parameter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以通过在[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)方法中指定通用的`csv`数据集构建器名称来读取CSV文件。要加载多个CSV文件，将它们作为列表传递给`data_files`参数：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can also map specific CSV files to the train and test splits:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将特定的CSV文件映射到训练和测试拆分：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To load remote CSV files, pass the URLs instead:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载远程CSV文件，请传递URLs：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To load zipped CSV files:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载压缩的CSV文件：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Pandas DataFrames
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pandas数据框
- en: '🤗 Datasets also supports loading datasets from [Pandas DataFrames](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)
    with the [from_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_pandas)
    method:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗数据集还支持使用[from_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_pandas)方法从[Pandas数据框](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)加载数据集：
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Use the `splits` parameter to specify the name of the dataset split:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`splits`参数指定数据集拆分的名称：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If the dataset doesn’t look as expected, you should explicitly [specify your
    dataset features](loading#specify-features). A [pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)
    may not always carry enough information for Arrow to automatically infer a data
    type. For example, if a DataFrame is of length `0` or if the Series only contains
    `None/NaN` objects, the type is set to `null`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集看起来不如预期，您应该明确[指定数据集特征](loading#specify-features)。[pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)可能并不总是携带足够的信息，以便Arrow自动推断数据类型。例如，如果DataFrame的长度为`0`，或者Series只包含`None/NaN`对象，类型将被设置为`null`。
- en: Databases
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库
- en: Datasets stored in databases are typically accessed with SQL queries. With 🤗
    Datasets, you can connect to a database, query for the data you need, and create
    a dataset out of it. Then you can use all the processing features of 🤗 Datasets
    to prepare your dataset for training.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通常通过SQL查询访问存储在数据库中的数据集。使用🤗数据集，您可以连接到数据库，查询所需的数据，并创建一个数据集。然后，您可以使用🤗数据集的所有处理功能来准备您的数据集进行训练。
- en: SQLite
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SQLite
- en: SQLite is a small, lightweight database that is fast and easy to set up. You
    can use an existing database if you’d like, or follow along and start from scratch.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: SQLite是一个小型、轻量级的数据库，快速且易于设置。您可以使用现有的数据库，或者跟着开始从头开始。
- en: 'Start by creating a quick SQLite database with this [Covid-19 data](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)
    from the New York Times:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过这个[纽约时报的Covid-19数据](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)创建一个快速的SQLite数据库：
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This creates a `states` table in the `us_covid_data.db` database which you can
    now load into a dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在`us_covid_data.db`数据库中创建一个`states`表，您现在可以将其加载到数据集中。
- en: To connect to the database, you’ll need the [URI string](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)
    that identifies your database. Connecting to a database with a URI caches the
    returned dataset. The URI string differs for each database dialect, so be sure
    to check the [Database URLs](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)
    for whichever database you’re using.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要连接到数据库，您需要标识数据库的[URI字符串](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)。使用URI字符串连接到数据库会缓存返回的数据集。每个数据库方言的URI字符串都不同，因此请确保查看您使用的数据库的[数据库URL](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)。
- en: 'For SQLite, it is:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SQLite，是这样的：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Load the table by passing the table name and URI to [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将表名和URI传递给[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)来加载表格：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then you can use all of 🤗 Datasets process features like [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    for example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用所有🤗数据集处理功能，例如[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)：
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can also load a dataset from a SQL query instead of an entire table, which
    is useful for querying and joining multiple tables.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以从SQL查询而不是整个表加载数据集，这对于查询和连接多个表非常有用。
- en: 'Load the dataset by passing your query and URI to [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将查询和URI传递给[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)来加载数据集：
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then you can use all of 🤗 Datasets process features like [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    for example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用所有🤗数据集处理功能，例如[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)：
- en: '[PRE11]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: PostgreSQL
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PostgreSQL
- en: You can also connect and load a dataset from a PostgreSQL database, however
    we won’t directly demonstrate how in the documentation because the example is
    only meant to be run in a notebook. Instead, take a look at how to install and
    setup a PostgreSQL server in this [notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以连接并从PostgreSQL数据库加载数据集，但是我们不会在文档中直接演示如何操作，因为示例只能在笔记本中运行。相反，请查看如何在这个[notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)中安装和设置PostgreSQL服务器！
- en: After you’ve setup your PostgreSQL database, you can use the [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)
    method to load a dataset from a table or query.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好PostgreSQL数据库之后，您可以使用[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)方法从表格或查询中加载数据集。
