- en: Load tabular data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/datasets/tabular_load](https://huggingface.co/docs/datasets/tabular_load)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'A tabular dataset is a generic dataset used to describe any data stored in
    rows and columns, where the rows represent an example and the columns represent
    a feature (can be continuous or categorical). These datasets are commonly stored
    in CSV files, Pandas DataFrames, and in database tables. This guide will show
    you how to load and create a tabular dataset from:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: CSV files
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas DataFrames
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Databases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CSV files
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ğŸ¤— Datasets can read CSV files by specifying the generic `csv` dataset builder
    name in the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    method. To load more than one CSV file, pass them as a list to the `data_files`
    parameter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can also map specific CSV files to the train and test splits:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To load remote CSV files, pass the URLs instead:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To load zipped CSV files:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Pandas DataFrames
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ğŸ¤— Datasets also supports loading datasets from [Pandas DataFrames](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)
    with the [from_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_pandas)
    method:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Use the `splits` parameter to specify the name of the dataset split:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If the dataset doesnâ€™t look as expected, you should explicitly [specify your
    dataset features](loading#specify-features). A [pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)
    may not always carry enough information for Arrow to automatically infer a data
    type. For example, if a DataFrame is of length `0` or if the Series only contains
    `None/NaN` objects, the type is set to `null`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Databases
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Datasets stored in databases are typically accessed with SQL queries. With ğŸ¤—
    Datasets, you can connect to a database, query for the data you need, and create
    a dataset out of it. Then you can use all the processing features of ğŸ¤— Datasets
    to prepare your dataset for training.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: SQLite
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SQLite is a small, lightweight database that is fast and easy to set up. You
    can use an existing database if youâ€™d like, or follow along and start from scratch.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by creating a quick SQLite database with this [Covid-19 data](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)
    from the New York Times:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This creates a `states` table in the `us_covid_data.db` database which you can
    now load into a dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: To connect to the database, youâ€™ll need the [URI string](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)
    that identifies your database. Connecting to a database with a URI caches the
    returned dataset. The URI string differs for each database dialect, so be sure
    to check the [Database URLs](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)
    for whichever database youâ€™re using.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'For SQLite, it is:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Load the table by passing the table name and URI to [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then you can use all of ğŸ¤— Datasets process features like [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    for example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can also load a dataset from a SQL query instead of an entire table, which
    is useful for querying and joining multiple tables.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the dataset by passing your query and URI to [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then you can use all of ğŸ¤— Datasets process features like [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    for example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: PostgreSQL
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also connect and load a dataset from a PostgreSQL database, however
    we wonâ€™t directly demonstrate how in the documentation because the example is
    only meant to be run in a notebook. Instead, take a look at how to install and
    setup a PostgreSQL server in this [notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨ä¹Ÿå¯ä»¥è¿æ¥å¹¶ä»PostgreSQLæ•°æ®åº“åŠ è½½æ•°æ®é›†ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸ä¼šåœ¨æ–‡æ¡£ä¸­ç›´æ¥æ¼”ç¤ºå¦‚ä½•æ“ä½œï¼Œå› ä¸ºç¤ºä¾‹åªèƒ½åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œã€‚ç›¸åï¼Œè¯·æŸ¥çœ‹å¦‚ä½•åœ¨è¿™ä¸ª[notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)ä¸­å®‰è£…å’Œè®¾ç½®PostgreSQLæœåŠ¡å™¨ï¼
- en: After youâ€™ve setup your PostgreSQL database, you can use the [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)
    method to load a dataset from a table or query.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¾ç½®å¥½PostgreSQLæ•°æ®åº“ä¹‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)æ–¹æ³•ä»è¡¨æ ¼æˆ–æŸ¥è¯¢ä¸­åŠ è½½æ•°æ®é›†ã€‚
