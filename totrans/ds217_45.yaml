- en: Load tabular data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/datasets/tabular_load](https://huggingface.co/docs/datasets/tabular_load)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/datasets/v2.17.0/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/entry/start.146395b0.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/scheduler.bdbef820.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/singletons.98dc5b8b.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/index.8a885b74.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/paths.a483fec8.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/entry/app.e612c4fb.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/index.c0aea24a.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/nodes/0.5e8dbda6.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/nodes/47.f7ad6c12.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/CodeBlock.6ccca92e.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/Heading.2eb892cb.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'A tabular dataset is a generic dataset used to describe any data stored in
    rows and columns, where the rows represent an example and the columns represent
    a feature (can be continuous or categorical). These datasets are commonly stored
    in CSV files, Pandas DataFrames, and in database tables. This guide will show
    you how to load and create a tabular dataset from:'
  prefs: []
  type: TYPE_NORMAL
- en: CSV files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CSV files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ðŸ¤— Datasets can read CSV files by specifying the generic `csv` dataset builder
    name in the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    method. To load more than one CSV file, pass them as a list to the `data_files`
    parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also map specific CSV files to the train and test splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To load remote CSV files, pass the URLs instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To load zipped CSV files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Pandas DataFrames
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ðŸ¤— Datasets also supports loading datasets from [Pandas DataFrames](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)
    with the [from_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_pandas)
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `splits` parameter to specify the name of the dataset split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If the dataset doesnâ€™t look as expected, you should explicitly [specify your
    dataset features](loading#specify-features). A [pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)
    may not always carry enough information for Arrow to automatically infer a data
    type. For example, if a DataFrame is of length `0` or if the Series only contains
    `None/NaN` objects, the type is set to `null`.
  prefs: []
  type: TYPE_NORMAL
- en: Databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Datasets stored in databases are typically accessed with SQL queries. With ðŸ¤—
    Datasets, you can connect to a database, query for the data you need, and create
    a dataset out of it. Then you can use all the processing features of ðŸ¤— Datasets
    to prepare your dataset for training.
  prefs: []
  type: TYPE_NORMAL
- en: SQLite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SQLite is a small, lightweight database that is fast and easy to set up. You
    can use an existing database if youâ€™d like, or follow along and start from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by creating a quick SQLite database with this [Covid-19 data](https://github.com/nytimes/covid-19-data/blob/master/us-states.csv)
    from the New York Times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This creates a `states` table in the `us_covid_data.db` database which you can
    now load into a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: To connect to the database, youâ€™ll need the [URI string](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)
    that identifies your database. Connecting to a database with a URI caches the
    returned dataset. The URI string differs for each database dialect, so be sure
    to check the [Database URLs](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)
    for whichever database youâ€™re using.
  prefs: []
  type: TYPE_NORMAL
- en: 'For SQLite, it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the table by passing the table name and URI to [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you can use all of ðŸ¤— Datasets process features like [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can also load a dataset from a SQL query instead of an entire table, which
    is useful for querying and joining multiple tables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the dataset by passing your query and URI to [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you can use all of ðŸ¤— Datasets process features like [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: PostgreSQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also connect and load a dataset from a PostgreSQL database, however
    we wonâ€™t directly demonstrate how in the documentation because the example is
    only meant to be run in a notebook. Instead, take a look at how to install and
    setup a PostgreSQL server in this [notebook](https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/sql_with_huggingface_datasets.ipynb#scrollTo=d83yGQMPHGFi)!
  prefs: []
  type: TYPE_NORMAL
- en: After youâ€™ve setup your PostgreSQL database, you can use the [from_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_sql)
    method to load a dataset from a table or query.
  prefs: []
  type: TYPE_NORMAL
