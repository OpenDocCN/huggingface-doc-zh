["```py\npip install datasets\n```", "```py\n    pip install datasets[audio]\n    ```", "```py\n    pip install datasets[vision]\n    ```", "```py\npip install torch\n```", "```py\npip install tensorflow\n```", "```py\n>>> from datasets import load_dataset, Audio\n\n>>> dataset = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\")\n```", "```py\n>>> from transformers import AutoModelForAudioClassification, AutoFeatureExtractor\n\n>>> model = AutoModelForAudioClassification.from_pretrained(\"facebook/wav2vec2-base\")\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n```", "```py\n>>> dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n>>> dataset[0][\"audio\"]\n{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,\n         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n 'sampling_rate': 16000}\n```", "```py\n>>> def preprocess_function(examples):\n...     audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n...     inputs = feature_extractor(\n...         audio_arrays,\n...         sampling_rate=16000,\n...         padding=True,\n...         max_length=100000,\n...         truncation=True,\n...     )\n...     return inputs\n\n>>> dataset = dataset.map(preprocess_function, batched=True)\n```", "```py\n>>> dataset = dataset.rename_column(\"intent_class\", \"labels\")\n```", "```py\n>>> from torch.utils.data import DataLoader\n\n>>> dataset.set_format(type=\"torch\", columns=[\"input_values\", \"labels\"])\n>>> dataloader = DataLoader(dataset, batch_size=4)\n```", "```py\n>>> import tensorflow as tf\n\n>>> tf_dataset = model.prepare_tf_dataset(\n...     dataset,\n...     batch_size=4,\n...     shuffle=True,\n... )\n```", "```py\n>>> from datasets import load_dataset, Image\n\n>>> dataset = load_dataset(\"beans\", split=\"train\")\n```", "```py\n>>> from torchvision.transforms import Compose, ColorJitter, ToTensor\n\n>>> jitter = Compose(\n...     [ColorJitter(brightness=0.5, hue=0.5), ToTensor()]\n... )\n```", "```py\n>>> def transforms(examples):\n...     examples[\"pixel_values\"] = [jitter(image.convert(\"RGB\")) for image in examples[\"image\"]]\n...     return examples\n```", "```py\n>>> dataset = dataset.with_transform(transforms)\n```", "```py\n>>> from torch.utils.data import DataLoader\n\n>>> def collate_fn(examples):\n...     images = []\n...     labels = []\n...     for example in examples:\n...         images.append((example[\"pixel_values\"]))\n...         labels.append(example[\"labels\"])\n...         \n...     pixel_values = torch.stack(images)\n...     labels = torch.tensor(labels)\n...     return {\"pixel_values\": pixel_values, \"labels\": labels}\n>>> dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=4)\n```", "```py\npip install -U albumentations opencv-python\n```", "```py\n>>> import albumentations\n>>> import numpy as np\n\n>>> transform = albumentations.Compose([\n...     albumentations.RandomCrop(width=256, height=256),\n...     albumentations.HorizontalFlip(p=0.5),\n...     albumentations.RandomBrightnessContrast(p=0.2),\n... ])\n\n>>> def transforms(examples):\n...     examples[\"pixel_values\"] = [\n...         transform(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n...     ]\n...     return examples\n\n>>> dataset.set_transform(transforms)\n>>> tf_dataset = model.prepare_tf_dataset(\n...     dataset,\n...     batch_size=4,\n...     shuffle=True,\n... )\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\")\n```", "```py\n>>> from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") **3**. Create a function to tokenize the dataset, and you should also truncate and pad the text into tidy rectangular tensors. The tokenizer generates three new columns in the dataset: `input_ids`, `token_type_ids`, and an `attention_mask`. These are the model inputs. Use the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) function to speed up processing by applying your tokenization function to batches of examples in the dataset:  \n\n```", "```py\n\n**4**. Rename the `label` column to `labels`, which is the expected input name in [BertForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification):\n\n```", "```py\n\n**5**. Set the dataset format according to the machine learning framework you\u2019re using.\n\n   Pytorch  Hide Pytorch content  \n\nUse the [set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format) function to set the dataset format to `torch` and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):\n\n```", "```py\n\n   TensorFlow  Hide TensorFlow content  \n\nUse the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) method from \ud83e\udd17 Transformers to prepare the dataset to be compatible with\nTensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset) as a `tf.data.Dataset`\nwith collation and batching, so one can pass it directly to Keras methods like `fit()` without further modification.\n\n```", "```py\n\n**6**. Start training with your machine learning framework! Check out the \ud83e\udd17 Transformers [text classification guide](https://huggingface.co/docs/transformers/tasks/sequence_classification) for an end-to-end example of how to train a model on a text dataset.\n\n##   What\u2019s next?\n\nThis completes the \ud83e\udd17 Datasets quickstart! You can load any text, audio, or image dataset with a single function and get it ready for your model to train on.\n\nFor your next steps, take a look at our [How-to guides](./how_to) and learn how to do more specific things like loading different dataset formats, aligning labels, and streaming large datasets. If you\u2019re interested in learning more about \ud83e\udd17 Datasets core concepts, grab a cup of coffee and read our [Conceptual Guides](./about_arrow)!\n\n```"]