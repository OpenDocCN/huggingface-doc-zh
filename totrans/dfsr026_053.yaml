- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/diffusers/training/overview](https://huggingface.co/docs/diffusers/training/overview)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/145.a9521ff2.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: ü§ó Diffusers provides a collection of training scripts for you to train your
    own diffusion models. You can find all of our training scripts in [diffusers/examples](https://github.com/huggingface/diffusers/tree/main/examples).
  prefs: []
  type: TYPE_NORMAL
- en: 'Each training script is:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-contained**: the training script does not depend on any local files,
    and all packages required to run the script are installed from the `requirements.txt`
    file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy-to-tweak**: the training scripts are an example of how to train a diffusion
    model for a specific task and won‚Äôt work out-of-the-box for every training scenario.
    You‚Äôll likely need to adapt the training script for your specific use-case. To
    help you with that, we‚Äôve fully exposed the data preprocessing code and the training
    loop so you can modify it for your own use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Beginner-friendly**: the training scripts are designed to be beginner-friendly
    and easy to understand, rather than including the latest state-of-the-art methods
    to get the best and most competitive results. Any training methods we consider
    too complex are purposefully left out.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Single-purpose**: each training script is expressly designed for only one
    task to keep it readable and understandable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our current collection of training scripts include:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Training | SDXL-support | LoRA-support | Flax-support |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [unconditional image generation](https://github.com/huggingface/diffusers/tree/main/examples/unconditional_image_generation)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb)
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| [text-to-image](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image)
    | üëç | üëç | üëç |'
  prefs: []
  type: TYPE_TB
- en: '| [textual inversion](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb)
    |  |  | üëç |'
  prefs: []
  type: TYPE_TB
- en: '| [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb)
    | üëç | üëç | üëç |'
  prefs: []
  type: TYPE_TB
- en: '| [ControlNet](https://github.com/huggingface/diffusers/tree/main/examples/controlnet)
    | üëç |  | üëç |'
  prefs: []
  type: TYPE_TB
- en: '| [InstructPix2Pix](https://github.com/huggingface/diffusers/tree/main/examples/instruct_pix2pix)
    | üëç |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| [Custom Diffusion](https://github.com/huggingface/diffusers/tree/main/examples/custom_diffusion)
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| [T2I-Adapters](https://github.com/huggingface/diffusers/tree/main/examples/t2i_adapter)
    | üëç |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| [Kandinsky 2.2](https://github.com/huggingface/diffusers/tree/main/examples/kandinsky2_2/text_to_image)
    |  | üëç |  |'
  prefs: []
  type: TYPE_TB
- en: '| [Wuerstchen](https://github.com/huggingface/diffusers/tree/main/examples/wuerstchen/text_to_image)
    |  | üëç |  |'
  prefs: []
  type: TYPE_TB
- en: These examples are **actively** maintained, so please feel free to open an issue
    if they aren‚Äôt working as expected. If you feel like another training example
    should be included, you‚Äôre more than welcome to start a [Feature Request](https://github.com/huggingface/diffusers/issues/new?assignees=&labels=&template=feature_request.md&title=)
    to discuss your feature idea with us and whether it meets our criteria of being
    self-contained, easy-to-tweak, beginner-friendly, and single-purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Install
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Make sure you can successfully run the latest versions of the example scripts
    by installing the library from source in a new virtual environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then navigate to the folder of the training script (for example, [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth))
    and install the `requirements.txt` file. Some training scripts have a specific
    requirement file for SDXL, LoRA or Flax. If you‚Äôre using one of these scripts,
    make sure you install its corresponding requirements file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To speedup training and reduce memory-usage, we recommend:'
  prefs: []
  type: TYPE_NORMAL
- en: using PyTorch 2.0 or higher to automatically use [scaled dot product attention](../optimization/torch2.0#scaled-dot-product-attention)
    during training (you don‚Äôt need to make any changes to the training code)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: installing [xFormers](../optimization/xformers) to enable memory-efficient attention
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
