- en: LiLT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LiLT
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lilt](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lilt)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lilt](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lilt)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: 'The LiLT model was proposed in [LiLT: A Simple yet Effective Language-Independent
    Layout Transformer for Structured Document Understanding](https://arxiv.org/abs/2202.13669)
    by Jiapeng Wang, Lianwen Jin, Kai Ding. LiLT allows to combine any pre-trained
    RoBERTa text encoder with a lightweight Layout Transformer, to enable [LayoutLM](layoutlm)-like
    document understanding for many languages.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'LiLTæ¨¡å‹åœ¨[Jiapeng Wang, Lianwen Jin, Kai Dingæ’°å†™çš„ã€ŠLiLT: A Simple yet Effective
    Language-Independent Layout Transformer for Structured Document Understandingã€‹](https://arxiv.org/abs/2202.13669)ä¸­æå‡ºã€‚LiLTå…è®¸å°†ä»»ä½•é¢„è®­ç»ƒçš„RoBERTaæ–‡æœ¬ç¼–ç å™¨ä¸è½»é‡çº§çš„Layout
    Transformerç»“åˆèµ·æ¥ï¼Œä»¥å®ç°å¤šç§è¯­è¨€çš„[LayoutLM](layoutlm)ç±»ä¼¼æ–‡æ¡£ç†è§£ã€‚'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è®ºæ–‡æ‘˜è¦ä¸­å¾—å‡ºçš„ç»“è®ºæ˜¯ï¼š
- en: '*Structured document understanding has attracted considerable attention and
    made significant progress recently, owing to its crucial role in intelligent document
    processing. However, most existing related models can only deal with the document
    data of specific language(s) (typically English) included in the pre-training
    collection, which is extremely limited. To address this issue, we propose a simple
    yet effective Language-independent Layout Transformer (LiLT) for structured document
    understanding. LiLT can be pre-trained on the structured documents of a single
    language and then directly fine-tuned on other languages with the corresponding
    off-the-shelf monolingual/multilingual pre-trained textual models. Experimental
    results on eight languages have shown that LiLT can achieve competitive or even
    superior performance on diverse widely-used downstream benchmarks, which enables
    language-independent benefit from the pre-training of document layout structure.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç»“æ„åŒ–æ–‡æ¡£ç†è§£è¿‘å¹´æ¥å¼•èµ·äº†å¹¿æ³›å…³æ³¨å¹¶å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¿™å½’åŠŸäºå…¶åœ¨æ™ºèƒ½æ–‡æ¡£å¤„ç†ä¸­çš„å…³é”®ä½œç”¨ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„ç›¸å…³æ¨¡å‹åªèƒ½å¤„ç†ç‰¹å®šè¯­è¨€ï¼ˆé€šå¸¸æ˜¯è‹±è¯­ï¼‰çš„æ–‡æ¡£æ•°æ®ï¼Œè¿™äº›æ–‡æ¡£æ•°æ®åŒ…å«åœ¨é¢„è®­ç»ƒé›†åˆä¸­ï¼Œè¿™æ˜¯æå…¶æœ‰é™çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„Language-independent
    Layout Transformerï¼ˆLiLTï¼‰ç”¨äºç»“æ„åŒ–æ–‡æ¡£ç†è§£ã€‚LiLTå¯ä»¥åœ¨å•ä¸€è¯­è¨€çš„ç»“æ„åŒ–æ–‡æ¡£ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åç›´æ¥åœ¨å…¶ä»–è¯­è¨€ä¸Šè¿›è¡Œå¯¹åº”çš„ç°æˆçš„å•è¯­/å¤šè¯­é¢„è®­ç»ƒæ–‡æœ¬æ¨¡å‹çš„å¾®è°ƒã€‚åœ¨å…«ç§è¯­è¨€ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒLiLTå¯ä»¥åœ¨å„ç§å¹¿æ³›ä½¿ç”¨çš„ä¸‹æ¸¸åŸºå‡†æµ‹è¯•ä¸­å–å¾—ç«äº‰æ€§ç”šè‡³ä¼˜è¶Šçš„æ€§èƒ½ï¼Œè¿™ä½¿å¾—å¯ä»¥ä»æ–‡æ¡£å¸ƒå±€ç»“æ„çš„é¢„è®­ç»ƒä¸­è·ç›Šè€Œä¸å—è¯­è¨€é™åˆ¶ã€‚*'
- en: '![drawing](../Images/b7a4714ff512347c68b1404d0d624c5c.png) LiLT architecture.
    Taken from the [original paper](https://arxiv.org/abs/2202.13669).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/b7a4714ff512347c68b1404d0d624c5c.png) LiLTæ¶æ„ã€‚æ‘˜è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2202.13669)ã€‚'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/jpwang/lilt).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[æ­¤å¤„](https://github.com/jpwang/lilt)æ‰¾åˆ°ã€‚
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æç¤º
- en: 'To combine the Language-Independent Layout Transformer with a new RoBERTa checkpoint
    from the [hub](https://huggingface.co/models?search=roberta), refer to [this guide](https://github.com/jpWang/LiLT#or-generate-your-own-checkpoint-optional).
    The script will result in `config.json` and `pytorch_model.bin` files being stored
    locally. After doing this, one can do the following (assuming youâ€™re logged in
    with your HuggingFace account):'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†Language-Independent Layout Transformerä¸æ¥è‡ª[hub](https://huggingface.co/models?search=roberta)çš„æ–°RoBERTaæ£€æŸ¥ç‚¹ç»“åˆèµ·æ¥ï¼Œè¯·å‚è€ƒ[æ­¤æŒ‡å—](https://github.com/jpWang/LiLT#or-generate-your-own-checkpoint-optional)ã€‚è„šæœ¬å°†å¯¼è‡´`config.json`å’Œ`pytorch_model.bin`æ–‡ä»¶è¢«å­˜å‚¨åœ¨æœ¬åœ°ã€‚å®Œæˆæ­¤æ“ä½œåï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼ˆå‡è®¾æ‚¨å·²ç™»å½•æ‚¨çš„HuggingFaceå¸æˆ·ï¼‰ï¼š
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: When preparing data for the model, make sure to use the token vocabulary that
    corresponds to the RoBERTa checkpoint you combined with the Layout Transformer.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ®æ—¶ï¼Œè¯·ç¡®ä¿ä½¿ç”¨ä¸æ‚¨ä¸Layout Transformerç»“åˆçš„RoBERTaæ£€æŸ¥ç‚¹ç›¸å¯¹åº”çš„æ ‡è®°è¯æ±‡è¡¨ã€‚
- en: 'As [lilt-roberta-en-base](https://huggingface.co/SCUT-DLVCLab/lilt-roberta-en-base)
    uses the same vocabulary as [LayoutLMv3](layoutlmv3), one can use [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    to prepare data for the model. The same is true for [lilt-roberta-en-base](https://huggingface.co/SCUT-DLVCLab/lilt-infoxlm-base):
    one can use [LayoutXLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast)
    for that model.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äº[lilt-roberta-en-base](https://huggingface.co/SCUT-DLVCLab/lilt-roberta-en-base)ä½¿ç”¨ä¸[LayoutLMv3](layoutlmv3)ç›¸åŒçš„è¯æ±‡è¡¨ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)æ¥ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ®ã€‚å¯¹äº[lilt-roberta-en-base](https://huggingface.co/SCUT-DLVCLab/lilt-infoxlm-base)ä¹Ÿæ˜¯å¦‚æ­¤ï¼šå¯ä»¥ä½¿ç”¨[LayoutXLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast)æ¥ä¸ºè¯¥æ¨¡å‹å‡†å¤‡æ•°æ®ã€‚
- en: Resources
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started with LiLT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨LiLTã€‚
- en: Demo notebooks for LiLT can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/LiLT).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ä»¥åœ¨[æ­¤å¤„](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/LiLT)æ‰¾åˆ°LiLTçš„æ¼”ç¤ºç¬”è®°æœ¬ã€‚
- en: '**Documentation resources**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ–‡æ¡£èµ„æº**'
- en: '[Text classification task guide](../tasks/sequence_classification)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/sequence_classification)'
- en: '[Token classification task guide](../tasks/token_classification)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ ‡è®°åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/token_classification)'
- en: '[Question answering task guide](../tasks/question_answering)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[é—®ç­”ä»»åŠ¡æŒ‡å—](../tasks/question_answering)'
- en: If youâ€™re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and weâ€™ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€Pull Requestï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥å±•ç¤ºä¸€äº›æ–°å†…å®¹ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: LiltConfig
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LiltConfig
- en: '### `class transformers.LiltConfig`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LiltConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/configuration_lilt.py#L30)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/configuration_lilt.py#L30)'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) â€” Vocabulary size of the
    LiLT model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, é»˜è®¤ä¸º30522) â€” LiLTæ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰äº†åœ¨è°ƒç”¨[LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)æ—¶å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°æ•°é‡ã€‚'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) â€” Dimensionality of the
    encoder layers and the pooler layer. Should be a multiple of 24.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, é»˜è®¤ä¸º768) â€” ç¼–ç å™¨å±‚å’Œæ± åŒ–å™¨å±‚çš„ç»´åº¦ã€‚åº”ä¸º24çš„å€æ•°ã€‚'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) â€” Number of hidden
    layers in the Transformer encoder.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, é»˜è®¤ä¸º12) â€” Transformerç¼–ç å™¨ä¸­çš„éšè—å±‚æ•°é‡ã€‚'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) â€” Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, é»˜è®¤ä¸º12) â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°é‡ã€‚'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) â€” Dimensionality
    of the â€œintermediateâ€ (often named feed-forward) layer in the Transformer encoder.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, é»˜è®¤ä¸º3072) â€” Transformerç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`hidden_act` (`str` or `Callable`, *optional*, defaults to `"gelu"`) â€” The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` æˆ– `Callable`, *optional*, é»˜è®¤ä¸º`"gelu"`) â€” ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`,
    `"relu"`, `"silu"` å’Œ `"gelu_new"`ã€‚'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) â€” The dropout
    probability for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, é»˜è®¤ä¸º0.1) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„dropoutæ¦‚ç‡ã€‚'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) â€” The
    dropout ratio for the attention probabilities.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, é»˜è®¤ä¸º0.1) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„dropoutæ¯”ç‡ã€‚'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) â€” The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, é»˜è®¤ä¸º512) â€” è¯¥æ¨¡å‹å¯èƒ½ä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚é€šå¸¸è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚512ã€1024æˆ–2048ï¼‰ã€‚'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) â€” The vocabulary size
    of the `token_type_ids` passed when calling [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, é»˜è®¤ä¸º2) â€” åœ¨è°ƒç”¨[LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)æ—¶ä¼ é€’çš„`token_type_ids`çš„è¯æ±‡é‡ã€‚'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) â€” The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, é»˜è®¤ä¸º0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) â€” The epsilon used
    by the layer normalization layers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, é»˜è®¤ä¸º1e-12) â€” å±‚å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„epsilonã€‚'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"absolute"`) â€” Type
    of position embedding. Choose one of `"absolute"`, `"relative_key"`, `"relative_key_query"`.
    For positional embeddings use `"absolute"`. For more information on `"relative_key"`,
    please refer to [Self-Attention with Relative Position Representations (Shaw et
    al.)](https://arxiv.org/abs/1803.02155). For more information on `"relative_key_query"`,
    please refer to *Method 4* in [Improve Transformer Models with Better Relative
    Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *optional*, é»˜è®¤ä¸º`"absolute"`) â€” ä½ç½®åµŒå…¥çš„ç±»å‹ã€‚é€‰æ‹©`"absolute"`,
    `"relative_key"`, `"relative_key_query"`ä¹‹ä¸€ã€‚å¯¹äºä½ç½®åµŒå…¥ï¼Œè¯·ä½¿ç”¨`"absolute"`ã€‚æœ‰å…³`"relative_key"`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[Self-Attention
    with Relative Position Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)ã€‚æœ‰å…³`"relative_key_query"`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[Improve
    Transformer Models with Better Relative Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658)ä¸­çš„*Method
    4*ã€‚'
- en: '`classifier_dropout` (`float`, *optional*) â€” The dropout ratio for the classification
    head.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classifier_dropout` (`float`, *optional*) â€” åˆ†ç±»å¤´çš„dropoutæ¯”ç‡ã€‚'
- en: '`channel_shrink_ratio` (`int`, *optional*, defaults to 4) â€” The shrink ratio
    compared to the `hidden_size` for the channel dimension of the layout embeddings.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`channel_shrink_ratio` (`int`, *optional*, é»˜è®¤ä¸º4) â€” ä¸å¸ƒå±€åµŒå…¥çš„`hidden_size`ç›¸æ¯”ï¼Œé€šé“ç»´åº¦çš„æ”¶ç¼©æ¯”ç‡ã€‚'
- en: '`max_2d_position_embeddings` (`int`, *optional*, defaults to 1024) â€” The maximum
    value that the 2D position embedding might ever be used with. Typically set this
    to something large just in case (e.g., 1024).'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_2d_position_embeddings` (`int`, *optional*, é»˜è®¤ä¸º1024) â€” 2Dä½ç½®åµŒå…¥å¯èƒ½ä½¿ç”¨çš„æœ€å¤§å€¼ã€‚é€šå¸¸è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚1024ï¼‰ã€‚'
- en: This is the configuration class to store the configuration of a [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel).
    It is used to instantiate a LiLT model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the LiLT [SCUT-DLVCLab/lilt-roberta-en-base](https://huggingface.co/SCUT-DLVCLab/lilt-roberta-en-base)
    architecture. Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨[LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)çš„é…ç½®ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ªLiLTæ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿä¸LiLT
    [SCUT-DLVCLab/lilt-roberta-en-base](https://huggingface.co/SCUT-DLVCLab/lilt-roberta-en-base)æ¶æ„ç±»ä¼¼çš„é…ç½®ã€‚é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: 'Examples:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: LiltModel
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LiltModel
- en: '### `class transformers.LiltModel`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LiltModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L677)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L677)'
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare LiLT Model transformer outputting raw hidden-states without any specific
    head on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸LiLTæ¨¡å‹å˜å‹å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L709)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L709)'
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯input IDsï¼Ÿ](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯ä¸€ä¸ªè§„èŒƒåŒ–ç‰ˆæœ¬ï¼Œæ ¼å¼ä¸º(x0,
    y0, x1, y1)ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚æœ‰å…³è§„èŒƒåŒ–ï¼Œè¯·å‚è§[æ¦‚è¿°](#Overview)ã€‚'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºæœªè¢«`masked`çš„æ ‡è®°ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºè¢«`masked`çš„æ ‡è®°ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯attention masksï¼Ÿ](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” æ®µæ ‡è®°ç´¢å¼•ï¼ŒæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0å¯¹åº”äº*å¥å­A*æ ‡è®°ï¼Œ
- en: 1 corresponds to a *sentence B* token.
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1å¯¹åº”äº*å¥å­B*æ ‡è®°ã€‚
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯token type IDsï¼Ÿ](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯position IDsï¼Ÿ](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶æƒï¼Œä»¥ä¾¿å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    and inputs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼Œæˆ–è€…`return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`) â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    â€” Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, hidden_size)`) â€” åºåˆ—ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼Œåœ¨é€šè¿‡ç”¨äºè¾…åŠ©é¢„è®­ç»ƒä»»åŠ¡çš„å±‚è¿›ä¸€æ­¥å¤„ç†åã€‚ä¾‹å¦‚ï¼Œå¯¹äºBERTç³»åˆ—æ¨¡å‹ï¼Œè¿™è¿”å›ç»è¿‡çº¿æ€§å±‚å’Œtanhæ¿€æ´»å‡½æ•°å¤„ç†åçš„åˆ†ç±»æ ‡è®°ã€‚çº¿æ€§å±‚çš„æƒé‡åœ¨é¢„è®­ç»ƒæœŸé—´ä»ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡ºï¼Œå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œ+
    ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    forward method, overrides the `__call__` special method.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªå‡½æ•°ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: LiltForSequenceClassification
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LiltForSequenceClassification
- en: '### `class transformers.LiltForSequenceClassification`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LiltForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L823)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L823)'
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: LiLT Model transformer with a sequence classification/regression head on top
    (a linear layer on top of the pooled output) e.g. for GLUE tasks.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: LiLTæ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰ä¸€ä¸ªåºåˆ—åˆ†ç±»/å›å½’å¤´ï¼ˆæ± åŒ–è¾“å‡ºä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºGLUEä»»åŠ¡ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹è¿˜æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L843)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L843)'
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0,
    x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚æœ‰å…³å½’ä¸€åŒ–ï¼Œè¯·å‚é˜…[æ¦‚è¿°](#æ¦‚è¿°)ã€‚'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæœªè¢«`masked`çš„æ ‡è®°ä¸º1ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¢«`masked`çš„æ ‡è®°ä¸º0ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” æ®µæ ‡è®°ç´¢å¼•ï¼ŒæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0å¯¹åº”äº*å¥å­A*æ ‡è®°ï¼Œ
- en: 1 corresponds to a *sentence B* token.
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1å¯¹åº”äº*å¥å­B*æ ‡è®°ã€‚
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè¿™å°†éå¸¸æœ‰ç”¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss
    is computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`, *å¯é€‰çš„*) â€” ç”¨äºè®¡ç®—åºåˆ—åˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0,
    ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels == 1`ï¼Œåˆ™è®¡ç®—å›å½’æŸå¤±ï¼ˆå‡æ–¹æŸå¤±ï¼‰ï¼Œå¦‚æœ`config.num_labels
    > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚'
- en: Returns
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    and inputs.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå…·ä½“å–å†³äºé…ç½®ï¼ˆ[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)ï¼‰å’Œè¾“å…¥ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`, *å¯é€‰çš„*, å½“æä¾›`labels`æ—¶è¿”å›) â€” åˆ†ç±»ï¼ˆå¦‚æœconfig.num_labels==1åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) â€”
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`) â€” åˆ†ç±»ï¼ˆå¦‚æœconfig.num_labels==1åˆ™ä¸ºå›å½’ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰çš„*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡ºï¼Œå¦‚æœæ¨¡å‹æœ‰ä¸€ä¸ªåµŒå…¥å±‚ï¼Œ+
    ä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰çš„*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è‡ªæ³¨æ„åŠ›å¤´ä¸­ç”¨äºè®¡ç®—åŠ æƒå¹³å‡å€¼çš„æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ã€‚
- en: The [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªå‡½æ•°ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…åˆ™é»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE8]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: LiltForTokenClassification
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LiltForTokenClassification
- en: '### `class transformers.LiltForTokenClassification`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LiltForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L941)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L941)'
- en: '[PRE9]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: Lilt Model with a token classification head on top (a linear layer on top of
    the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¨¡å‹çš„æ¯ä¸€å±‚è¾“å‡ºä¹‹ä¸Šæœ‰ä¸€ä¸ªæ ‡è®°åˆ†ç±»å¤´çš„Liltæ¨¡å‹ï¼ˆåœ¨éšè—çŠ¶æ€è¾“å‡ºä¹‹ä¸Šæœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä»»åŠ¡ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L964)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L964)'
- en: '[PRE10]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`) â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`ï¼Œ*å¯é€‰*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚åœ¨èŒƒå›´`[0,
    config.max_2d_position_embeddings-1]`ä¸­é€‰æ‹©ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0,
    y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚æœ‰å…³å½’ä¸€åŒ–ï¼Œè¯·å‚é˜…[æ¦‚è§ˆ](#Overview)ã€‚'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*)
    â€” é¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äº`æœªå±è”½`çš„æ ‡è®°ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äº`è¢«å±è”½`çš„æ ‡è®°ï¼Œä¸º0ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*)
    â€” æŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†çš„æ®µæ ‡è®°ç´¢å¼•ã€‚ç´¢å¼•åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 å¯¹åº”äº *å¥å­A* æ ‡è®°ï¼Œ
- en: 1 corresponds to a *sentence B* token.
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 å¯¹åº”äº *å¥å­B* æ ‡è®°ã€‚
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*)
    â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`ï¼Œ*å¯é€‰*)
    â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨`æœªå±è”½`ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨`è¢«å±è”½`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*)
    â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Labels for computing the token classification loss. Indices should be in `[0,
    ..., config.num_labels - 1]`.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*) â€” ç”¨äºè®¡ç®—æ ‡è®°åˆ†ç±»æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0,
    ..., config.num_labels - 1]`ä¸­ã€‚'
- en: Returns
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    and inputs.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…æ‹¬æ ¹æ®é…ç½®ï¼ˆ[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Classification loss.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰â€” åˆ†ç±»æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    â€” Classification scores (before SoftMax).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, config.num_labels)`çš„`torch.FloatTensor`ï¼‰â€”
    åˆ†ç±»åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡ºå’Œæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºå¤„çš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE11]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: LiltForQuestionAnswering
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LiltForQuestionAnswering
- en: '### `class transformers.LiltForQuestionAnswering`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LiltForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L1067)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L1067)'
- en: '[PRE12]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)ï¼‰â€”
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: Lilt Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Liltæ¨¡å‹åœ¨é¡¶éƒ¨å…·æœ‰ä¸€ä¸ªè·¨åº¦åˆ†ç±»å¤´ï¼Œç”¨äºæå–å¼é—®ç­”ä»»åŠ¡ï¼Œå¦‚SQuADï¼ˆåœ¨éšè—çŠ¶æ€è¾“å‡ºçš„é¡¶éƒ¨æœ‰çº¿æ€§å±‚ï¼Œç”¨äºè®¡ç®—`span start logits`å’Œ`span
    end logits`ï¼‰ã€‚
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚
- en: '#### `forward`'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L1086)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lilt/modeling_lilt.py#L1086)'
- en: '[PRE13]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    â€” Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€”
    Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig))
    and inputs.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Total span extraction loss is the sum of a Cross-Entropy for the
    start and end positions.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Span-start scores (before SoftMax).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Span-end scores (before SoftMax).'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
