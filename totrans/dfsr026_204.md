# PNDMScheduler

> 原始文本：[`huggingface.co/docs/diffusers/api/schedulers/pndm`](https://huggingface.co/docs/diffusers/api/schedulers/pndm)

`PNDMScheduler`，或者用于扩散模型的伪数值方法，使用了更先进的 ODE 积分技术，如 Runge-Kutta 和线性多步方法。原始实现可以在[crowsonkb/k-diffusion](https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181)找到。

## PNDMScheduler

### `class diffusers.PNDMScheduler`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_pndm.py#L72)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Union = None skip_prk_steps: bool = False set_alpha_to_one: bool = False prediction_type: str = 'epsilon' timestep_spacing: str = 'leading' steps_offset: int = 0 )
```

参数

+   `num_train_timesteps`（`int`，默认为 1000）— 训练模型的扩散步骤数。

+   `beta_start`（`float`，默认为 0.0001）— 推理的起始`beta`值。

+   `beta_end`（`float`，默认为 0.02）— 最终的`beta`值。

+   `beta_schedule`（`str`，默认为`"linear"`）— beta 调度，从 beta 范围映射到用于步进模型的一系列 beta。可选择`linear`，`scaled_linear`或`squaredcos_cap_v2`。

+   `trained_betas`（`np.ndarray`，*可选*）— 直接传递一个 beta 数组给构造函数，以绕过`beta_start`和`beta_end`。

+   `skip_prk_steps`（`bool`，默认为`False`）— 允许调度程序跳过原始论文中定义的需要在 PLMS 步骤之前运行的 Runge-Kutta 步骤。

+   `set_alpha_to_one`（`bool`，默认为`False`）— 每个扩散步骤使用该步骤和上一个步骤的 alpha 乘积值。对于最后一步，没有先前的 alpha。当此选项为`True`时，前一个 alpha 乘积固定为`1`，否则使用步骤 0 处的 alpha 值。

+   `prediction_type`（`str`，默认为`epsilon`，*可选*）— 调度程序函数的预测类型；可以是`epsilon`（预测扩散过程的噪声）或`v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文第 2.4 节）。

+   `timestep_spacing`（`str`，默认为`"leading"`）— 时间步长应该如何缩放。有关更多信息，请参阅[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表 2。

+   `steps_offset`（`int`，默认为 0）— 添加到推理步骤的偏移量。您可以使用`offset=1`和`set_alpha_to_one=False`的组合，使最后一步使用前一个 alpha 乘积的步骤 0，就像在稳定扩散中一样。

`PNDMScheduler`使用伪数值方法来处理扩散模型，例如 Runge-Kutta 和线性多步方法。

该模型继承自 SchedulerMixin 和 ConfigMixin。查看超类文档以了解库为所有调度程序实现的通用方法，例如加载和保存。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_pndm.py#L392)

```py
( sample: FloatTensor *args **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample`（`torch.FloatTensor`）— 输入样本。

返回

`torch.FloatTensor`

一个缩放的输入样本。

确保与需要根据当前时间步长缩放去噪模型输入的调度程序可以互换。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_pndm.py#L168)

```py
( num_inference_steps: int device: Union = None )
```

参数

+   `num_inference_steps`（`int`）— 生成使用预训练模型的样本时使用的扩散步骤数。

+   `device`（`str`或`torch.device`，*可选*）— 应将时间步移动到的设备。如果为`None`，则不移动时间步。

设置用于扩散链的离散时间步长（在推理之前运行）。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_pndm.py#L228)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`int`) — 扩散链中的当前离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `return_dict` (`bool`) — 是否返回 SchedulerOutput 或`tuple`。

返回

SchedulerOutput 或`tuple`

如果 return_dict 为`True`，则返回 SchedulerOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 从上一个时间步预测样本。此函数从学习模型输出（通常是预测的噪声）传播扩散过程，并根据内部变量`counter`调用 step_prk()或 step_plms()。

#### `step_plms`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_pndm.py#L321)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`int`) — 扩散链中的当前离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `return_dict` (`bool`) — 是否返回 SchedulerOutput 或元组。

返回

SchedulerOutput 或`tuple`

如果 return_dict 为`True`，则返回 SchedulerOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 从上一个时间步预测样本。此函数使用线性多步方法传播样本。它多次执行一次前向传递以近似解决方案。

#### `step_prk`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_pndm.py#L261)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`int`) — 扩散链中的当前离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `return_dict` (`bool`) — 是否返回 SchedulerOutput 或元组。

返回

SchedulerOutput 或`tuple`

如果 return_dict 为`True`，则返回 SchedulerOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 从上一个时间步预测样本。此函数使用 Runge-Kutta 方法传播样本。它执行四次前向传递以近似微分方程的解。

## SchedulerOutput

### `class diffusers.schedulers.scheduling_utils.SchedulerOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_utils.py#L50)

```py
( prev_sample: FloatTensor )
```

参数

+   `prev_sample`（图像的形状为“（batch_size，num_channels，height，width）的 torch.FloatTensor”）- 上一个时间步的计算样本（x_{t-1}）。在去噪循环中，应该将`prev_sample`用作下一个模型输入。

调度程序`step`函数的输出的基类。
