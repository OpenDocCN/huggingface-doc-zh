- en: Conclusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit5/conclusion](https://huggingface.co/learn/deep-rl-course/unit5/conclusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/learn/deep-rl-course/unit5/conclusion](https://huggingface.co/learn/deep-rl-course/unit5/conclusion)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Congrats on finishing this unit! Youâ€™ve just trained your first ML-Agents and
    shared it to the Hub ğŸ¥³.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œä½ å®Œæˆäº†è¿™ä¸ªå•å…ƒï¼ä½ åˆšåˆšè®­ç»ƒäº†ä½ çš„ç¬¬ä¸€ä¸ªML-Agentså¹¶åˆ†äº«åˆ°äº†HubğŸ¥³ã€‚
- en: The best way to learn is to **practice and try stuff**. Why not try another
    environment? [ML-Agents has 18 different environments](https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ çš„æœ€ä½³æ–¹å¼æ˜¯**ç»ƒä¹ å’Œå°è¯•**ã€‚ä¸ºä»€ä¹ˆä¸å°è¯•å¦ä¸€ä¸ªç¯å¢ƒå‘¢ï¼Ÿ[ML-Agentsæœ‰18ä¸ªä¸åŒçš„ç¯å¢ƒ](https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md)ã€‚
- en: 'For instance:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼š
- en: '[Worm](https://singularite.itch.io/worm), where you teach a worm to crawl.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è •è™«](https://singularite.itch.io/worm)ï¼Œåœ¨è¿™é‡Œä½ æ•™ä¼šä¸€åªè •è™«çˆ¬è¡Œã€‚'
- en: '[Walker](https://singularite.itch.io/walker), where you teach an agent to walk
    towards a goal.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è¡Œèµ°è€…](https://singularite.itch.io/walker)ï¼Œåœ¨è¿™é‡Œä½ æ•™ä¸€ä¸ªä»£ç†å‘ç›®æ ‡è¡Œèµ°ã€‚'
- en: 'Check the documentation to find out how to train them and to see the list of
    already integrated MLAgents environments on the Hub: [https://github.com/huggingface/ml-agents#getting-started](https://github.com/huggingface/ml-agents#getting-started)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹æ–‡æ¡£ä»¥äº†è§£å¦‚ä½•è®­ç»ƒå®ƒä»¬ï¼Œå¹¶æŸ¥çœ‹Hubä¸Šå·²ç»é›†æˆçš„MLAgentsç¯å¢ƒåˆ—è¡¨ï¼š[https://github.com/huggingface/ml-agents#getting-started](https://github.com/huggingface/ml-agents#getting-started)
- en: '![Example envs](../Images/77b4170bed8e669351f9f15ec1ef34c1.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![ç¤ºä¾‹ç¯å¢ƒ](../Images/77b4170bed8e669351f9f15ec1ef34c1.png)'
- en: In the next unit, weâ€™re going to learn about multi-agents. Youâ€™re going to train
    your first multi-agents to compete in Soccer and Snowball fight against other
    classmateâ€™s agents.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å…³äºå¤šä»£ç†çš„çŸ¥è¯†ã€‚ä½ å°†è®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªå¤šä»£ç†æ¥å‚åŠ è¶³çƒæ¯”èµ›å’Œé›ªçƒå¤§æˆ˜ï¼Œä¸å…¶ä»–åŒå­¦çš„ä»£ç†ç«äº‰ã€‚
- en: '![Snownball fight](../Images/72372e440c960be9f642a47a648aae4d.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![é›ªçƒå¤§æˆ˜](../Images/72372e440c960be9f642a47a648aae4d.png)'
- en: Finally, we would love **to hear what you think of the course and how we can
    improve it**. If you have some feedback then please ğŸ‘‰ [fill this form](https://forms.gle/BzKXWzLAGZESGNaE9)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¾ˆæƒ³çŸ¥é“**ä½ å¯¹è¯¾ç¨‹çš„çœ‹æ³•ä»¥åŠæˆ‘ä»¬å¦‚ä½•æ”¹è¿›**ã€‚å¦‚æœä½ æœ‰åé¦ˆï¼Œè¯·ğŸ‘‰[å¡«å†™æ­¤è¡¨æ ¼](https://forms.gle/BzKXWzLAGZESGNaE9)
- en: Keep Learning, stay awesome ğŸ¤—
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»§ç»­å­¦ä¹ ï¼Œä¿æŒä¼˜ç§€ğŸ¤—
