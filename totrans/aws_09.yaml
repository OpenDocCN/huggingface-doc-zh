- en: Generate images with Stable Diffusion models on AWS Inferentia
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/optimum-neuron/tutorials/stable_diffusion](https://huggingface.co/docs/optimum-neuron/tutorials/stable_diffusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*There is a notebook version of that tutorial [here](https://github.com/huggingface/optimum-neuron/blob/main/notebooks/stable-diffusion/stable-diffusion-txt2img.ipynb)*.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 🤗 `Optimum` extends `Diffusers` to support inference on the second generation
    of Neuron devices(powering Trainium and Inferentia 2). It aims at inheriting the
    ease of Diffusers on Neuron.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, make sure you have [configured your inf2 / trn1 instance](../installation),
    and installed optimum:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Compile Stable Diffusion
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To deploy models, you will need to compile them to TorchScript optimized for
    AWS Neuron. In the case of Stable Diffusion, there are four components which need
    to be exported to the `.neuron` format to boost the performance:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Text encoder
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: U-Net
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAE encoder
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAE decoder
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can either compile and export a Stable Diffusion Checkpoint via CLI or `NeuronStableDiffusionPipeline`
    class.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '***Export via CLI***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of exporting stable diffusion components with `Optimum`
    CLI:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We recommend using a `inf2.8xlarge` or a larger instance for the model compilation.
    You will also be able to compile the model with the Optimum CLI on a CPU-only
    instance (needs ~35 GB memory), and then run the pre-compiled model on `inf2.xlarge`
    to reduce the expenses. In this case, don’t forget to disable validation of inference
    by adding the `--disable-validation` argument.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '***Export via Python API***'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of exporting stable diffusion components with `NeuronStableDiffusionPipeline`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: To apply optimized compute of Unet’s attention score, please configure your
    environment variable with `export NEURON_FUSE_SOFTMAX=1`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Besides, don’t hesitate to tweak the compilation configuration to find the best
    tradeoff between performance v.s accuracy in your use case. By default, we suggest
    casting FP32 matrix multiplication operations to BF16 which offers good performance
    with moderate sacrifice of the accuracy. Check out the guide from [AWS Neuron
    documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/appnotes/neuronx-cc/neuronx-cc-training-mixed-precision.html#neuronx-cc-training-mixed-precision)
    to better understand the options for your compilation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Text-to-Image
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`NeuronStableDiffusionPipeline` class allows you to generate images from a
    text prompt on neuron devices similar to the experience with `Diffusers`.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'With pre-compiled Stable Diffusion models, now generate an image with a prompt
    on Neuron:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![stable diffusion generated image](../Images/e9bdfbe61952c061089cfa95a2059afb.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Image-to-Image
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the `NeuronStableDiffusionImg2ImgPipeline` class, you can generate a new
    image conditioned on a text prompt and an initial image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '| `image` | `prompt` | output |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| ![landscape photo](../Images/a03c8be4cac347c435e8607dd6ced9a4.png) | ***ghibli
    style, a fantasy landscape with snowcapped mountains, trees, lake with detailed
    reflection. warm colors, 8K*** | ![drawing](../Images/9f3025ed17a13258842023d761eaee3c.png)
    |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: Inpaint
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the `NeuronStableDiffusionInpaintPipeline` class, you can edit specific
    parts of an image by providing a mask and a text prompt.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '| `image` | `mask_image` | `prompt` | output |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| ![drawing](../Images/ccaa29fadd7036eecdf16d6ed327b788.png) | ![drawing](../Images/845ec3d502fa4754b97332a095702af9.png)
    | ***Face of a yellow cat, high resolution, sitting on a park bench*** | ![drawing](../Images/229c5966ac3cee6ead365a6a1b86e209.png)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: Stable Diffusion XL
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*There is a notebook version of that tutorial [here](https://github.com/huggingface/optimum-neuron/blob/main/notebooks/stable-diffusion/stable-diffusion-xl-txt2img.ipynb)*.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion XL (SDXL) is a latent diffusion model for text-to-image. Compared
    to the previous versions of Stable Diffusion models, it improves the quality of
    generated images with a times larger UNet.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散XL（SDXL）是一种文本到图像的潜在扩散模型。与之前版本的稳定扩散模型相比，它通过一个比UNet大几倍的UNet提高了生成图像的质量。
- en: Compile Stable Diffusion XL
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译稳定扩散XL
- en: 'To deploy SDXL models, we will also start by compiling the models. We support
    the export of following components in the pipeline to boost the speed:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署SDXL模型，我们也将从编译模型开始。我们支持在流水线中导出以下组件以提高速度：
- en: Text encoder
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本编码器
- en: Second text encoder
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个文本编码器
- en: U-Net (a three times larger UNet than the one in Stable Diffusion pipeline)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: U-Net（比稳定扩散流水线中的UNet大三倍）
- en: VAE encoder
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAE编码器
- en: VAE decoder
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAE解码器
- en: '***Export via CLI***'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '***通过CLI导出***'
- en: 'Here is an example of exporting SDXL components with `Optimum` CLI:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`Optimum` CLI导出SDXL组件的示例：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We recommend using a `inf2.8xlarge` or a larger instance for the model compilation.
    You will also be able to compile the model with Optimum CLI on a CPU-only instance
    (needs ~92 GB memory), and then run the pre-compiled models on `inf2.xlarge` to
    reduce the expenses. In this case, don’t forget to disable validation of inference
    by adding the `--disable-validation` argument.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用`inf2.8xlarge`或更大的实例进行模型编译。您还可以在仅CPU实例上使用Optimum CLI编译模型（需要约92 GB内存），然后在`inf2.xlarge`上运行预编译的模型以减少费用。在这种情况下，不要忘记通过添加`--disable-validation`参数来禁用推理的验证。
- en: '***Export via Python API***'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '***通过Python API导出***'
- en: 'Here is an example of exporting stable diffusion components with `NeuronStableDiffusionXLPipeline`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`NeuronStableDiffusionXLPipeline`导出稳定扩散组件的示例：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Text-to-Image
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本到图像
- en: 'With pre-compiled SDXL models, now generate an image with a text prompt on
    Neuron:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预编译的SDXL模型，在Neuron上生成带有文本提示的图像：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![sdxl generated image](../Images/459955f189c918feb31cbea2635a34a6.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![sdxl 生成的图像](../Images/459955f189c918feb31cbea2635a34a6.png)'
- en: Image-to-Image
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像到图像
- en: 'With `NeuronStableDiffusionXLImg2ImgPipeline`, you can pass an initial image,
    and a text prompt to condition generated images:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`NeuronStableDiffusionXLImg2ImgPipeline`，您可以传递初始图像和文本提示来生成图像：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '| `image` | `prompt` | output |  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `图像` | `提示` | 输出 |  |'
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: | :-: | --: |'
- en: '| ![castle photo](../Images/e5215d4ce7ccbc07b76cb40644414686.png) | ***a dog
    running, lake, moat*** | ![castle with dog](../Images/29129c40c7a3a79920bce7731bc121d1.png)
    |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| ![城堡照片](../Images/e5215d4ce7ccbc07b76cb40644414686.png) | ***一只狗奔跑，湖泊，护城河***
    | ![带狗的城堡](../Images/29129c40c7a3a79920bce7731bc121d1.png) |  |'
- en: Inpaint
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修补
- en: With `NeuronStableDiffusionXLInpaintPipeline`, pass the original image and a
    mask of what you want to replace in the original image. Then replace the masked
    area with content described in a prompt.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`NeuronStableDiffusionXLInpaintPipeline`，传递原始图像和要替换的原始图像中的遮罩。然后用提示中描述的内容替换遮罩区域。
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '| `image` | `mask_image` | `prompt` | output |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| `图像` | `遮罩图像` | `提示` | 输出 |'
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: | :-: | --: |'
- en: '| ![drawing](../Images/47eb848e4e09fd8ca2c920b1f98d089d.png) | ![drawing](../Images/8b01e9765d5fea46006fd0c5b7114470.png)
    | ***A deep sea diver floating*** | ![drawing](../Images/6b61a673bfb3f2ec07bfa522a6e3a183.png)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| ![drawing](../Images/47eb848e4e09fd8ca2c920b1f98d089d.png) | ![drawing](../Images/8b01e9765d5fea46006fd0c5b7114470.png)
    | ***一名潜水员漂浮*** | ![drawing](../Images/6b61a673bfb3f2ec07bfa522a6e3a183.png) |'
- en: Refine Image Quality
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精化图像质量
- en: 'SDXL includes a [refiner model](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)
    to denoise low-noise stage images generated from the base model. There are two
    ways to use the refiner:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SDXL包括一个[精化模型](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)，用于去噪从基础模型生成的低噪声阶段图像。有两种使用精化模型的方式：
- en: use the base and refiner model together to produce a refined image.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将基础和精化模型一起使用以生成精化图像。
- en: use the base model to produce an image, and subsequently use the refiner model
    to add more details to the image.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用基础模型生成图像，然后使用精化模型为图像添加更多细节。
- en: Base + refiner model
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础 + 精化模型
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![sdxl base + refiner](../Images/59c8ddd276bac26aa0202d6cef205b32.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![sdxl 基础 + 精化器](../Images/59c8ddd276bac26aa0202d6cef205b32.png)'
- en: Base to refiner model
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础到精化模型
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '| `Base Image` | Refined Image |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `基础图像` | 精化图像 |'
- en: '| :-: | --: |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| :-: | --: |'
- en: '| ![drawing](../Images/40389db8dd5d1a686e6a53d11695fce3.png) | ![drawing](../Images/4e196d834fb8351ee9138956a8b23cd3.png)
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| ![drawing](../Images/40389db8dd5d1a686e6a53d11695fce3.png) | ![drawing](../Images/4e196d834fb8351ee9138956a8b23cd3.png)
    |'
- en: To avoid Neuron device out of memory, it’s suggested to finish all base inference
    and release the device memory before running the refiner.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为避免Neuron设备内存不足，建议在运行精化器之前完成所有基础推理并释放设备内存。
- en: Latent Consistency Models
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 潜在一致性模型
- en: 'Latent Consistency Models (LCMs) were proposed in [Latent Consistency Models:
    Synthesizing High-Resolution Images with Few-Step Inference by Simian Luo, Yiqin
    Tan, Longbo Huang, Jian Li, and Hang Zhao](https://huggingface.co/papers/2310.04378).
    LCMs enable inference with fewer steps on any pre-trained LDMs, including Stable
    Diffusion and SDXL.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在一致性模型（LCMs）是由Simian Luo、Yiqin Tan、Longbo Huang、Jian Li和Hang Zhao提出的[潜在一致性模型：通过少步推理合成高分辨率图像](https://huggingface.co/papers/2310.04378)。LCMs使得在任何预训练的LDM上进行推理时可以减少步骤，包括稳定扩散和SDXL。
- en: 'In `optimum-neuron`, you can:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在`optimum-neuron`中，您可以：
- en: Use the class `NeuronLatentConsistencyModelPipeline` to compile and run inference
    of LCMs distilled from Stable Diffusion (SD) models.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用类`NeuronLatentConsistencyModelPipeline`来编译和运行从稳定扩散（SD）模型中提炼的LCMs的推理。
- en: And continue to use the class `NeuronStableDiffusionXLPipeline` for LCMs distilled
    from SDXL models.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并继续使用从SDXL模型中提炼的LCM类`NeuronStableDiffusionXLPipeline`。
- en: 'Here are examples to compile the LCMs of Stable Diffusion ( [SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7)
    ) and Stable Diffusion XL( [latent-consistency/lcm-sdxl](https://huggingface.co/latent-consistency/lcm-sdxl)
    ), and then run inference on AWS Inferentia 2 :'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是编译稳定扩散的LCMs（[SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7)）和稳定扩散XL（[latent-consistency/lcm-sdxl](https://huggingface.co/latent-consistency/lcm-sdxl)）的示例，然后在AWS
    Inferentia 2上运行推理：
- en: Compile LCM
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译LCM
- en: '***LCM of Stable Diffusion***'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '***稳定扩散的LCM***'
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '***LCM of Stable Diffusion XL***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '***稳定扩散XL的LCM***'
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Text-to-Image
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本到图像
- en: 'Now we can generate images from text prompts on Inf2 using the pre-compiled
    model:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在Inf2上使用预编译模型从文本提示生成图像。
- en: '***LCM of Stable Diffusion***'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '***稳定扩散的LCM***'
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '***LCM of Stable Diffusion XL***'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '***稳定扩散XL的LCM***'
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Stable Diffusion XL Turbo
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散XL Turbo
- en: SDXL Turbo is an adversarial time-distilled Stable Diffusion XL (SDXL) model
    capable of running inference in as little as 1 step ([check `🤗diffusers` for more
    details](https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo)).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: SDXL Turbo是一种对抗时间蒸馏的稳定扩散XL（SDXL）模型，能够在仅1步骤中运行推断（[查看`🤗diffusers`获取更多详情](https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo)）。
- en: 'In `optimum-neuron`, you can:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`optimum-neuron`中，您可以：
- en: Use the class `NeuronStableDiffusionXLPipeline` to compile and run inference.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用类`NeuronStableDiffusionXLPipeline`来编译和运行推断。
- en: Here we will compile the [`stabilityai/sdxl-turbo`](https://huggingface.co/stabilityai/sdxl-turbo)
    model with Optimum CLI.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用Optimum CLI编译[`stabilityai/sdxl-turbo`](https://huggingface.co/stabilityai/sdxl-turbo)模型。
- en: Compile SDXL Turbo
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译SDXL Turbo
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Text-to-Image
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本到图像
- en: 'Now we can generate images from text prompts on Inf2 using the pre-compiled
    model:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在Inf2上使用预编译模型从文本提示生成图像：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Inf2 instances contain one or more Neuron devices, and each Neuron device includes
    2 NeuronCore-v2\. By default, we load the whole pipeline of LCM to both Neuron
    cores. It means that when the batch size is divisible by 2, you can fully leverage
    the compute power of both cores.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Inf2实例包含一个或多个神经元设备，每个神经元设备包括2个NeuronCore-v2。默认情况下，我们将LCM的整个流水线加载到两个神经元核心中。这意味着当批量大小可以被2整除时，您可以充分利用两个核心的计算能力。
- en: Are there any other stable diffusion features that you want us to support in
    🤗`Optimum-neuron`? Please file an issue to [`Optimum-neuron` Github repo](https://github.com/huggingface/optimum-neuron)
    or discuss with us on [HuggingFace’s community forum](https://discuss.huggingface.co/c/optimum/),
    cheers 🤗 !
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否希望我们支持🤗`Optimum-neuron`中的其他稳定扩散功能？请在[`Optimum-neuron` Github仓库](https://github.com/huggingface/optimum-neuron)上提交问题或在[HuggingFace的社区论坛](https://discuss.huggingface.co/c/optimum/)上与我们讨论，谢谢🤗！
