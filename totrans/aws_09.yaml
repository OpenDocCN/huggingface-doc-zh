- en: Generate images with Stable Diffusion models on AWS Inferentia
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/optimum-neuron/tutorials/stable_diffusion](https://huggingface.co/docs/optimum-neuron/tutorials/stable_diffusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*There is a notebook version of that tutorial [here](https://github.com/huggingface/optimum-neuron/blob/main/notebooks/stable-diffusion/stable-diffusion-txt2img.ipynb)*.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ¤— `Optimum` extends `Diffusers` to support inference on the second generation
    of Neuron devices(powering Trainium and Inferentia 2). It aims at inheriting the
    ease of Diffusers on Neuron.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, make sure you have [configured your inf2 / trn1 instance](../installation),
    and installed optimum:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Compile Stable Diffusion
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To deploy models, you will need to compile them to TorchScript optimized for
    AWS Neuron. In the case of Stable Diffusion, there are four components which need
    to be exported to the `.neuron` format to boost the performance:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Text encoder
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: U-Net
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAE encoder
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAE decoder
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can either compile and export a Stable Diffusion Checkpoint via CLI or `NeuronStableDiffusionPipeline`
    class.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '***Export via CLI***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of exporting stable diffusion components with `Optimum`
    CLI:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We recommend using a `inf2.8xlarge` or a larger instance for the model compilation.
    You will also be able to compile the model with the Optimum CLI on a CPU-only
    instance (needs ~35 GB memory), and then run the pre-compiled model on `inf2.xlarge`
    to reduce the expenses. In this case, donâ€™t forget to disable validation of inference
    by adding the `--disable-validation` argument.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '***Export via Python API***'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of exporting stable diffusion components with `NeuronStableDiffusionPipeline`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: To apply optimized compute of Unetâ€™s attention score, please configure your
    environment variable with `export NEURON_FUSE_SOFTMAX=1`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Besides, donâ€™t hesitate to tweak the compilation configuration to find the best
    tradeoff between performance v.s accuracy in your use case. By default, we suggest
    casting FP32 matrix multiplication operations to BF16 which offers good performance
    with moderate sacrifice of the accuracy. Check out the guide from [AWS Neuron
    documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/appnotes/neuronx-cc/neuronx-cc-training-mixed-precision.html#neuronx-cc-training-mixed-precision)
    to better understand the options for your compilation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Text-to-Image
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`NeuronStableDiffusionPipeline` class allows you to generate images from a
    text prompt on neuron devices similar to the experience with `Diffusers`.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'With pre-compiled Stable Diffusion models, now generate an image with a prompt
    on Neuron:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![stable diffusion generated image](../Images/e9bdfbe61952c061089cfa95a2059afb.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Image-to-Image
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the `NeuronStableDiffusionImg2ImgPipeline` class, you can generate a new
    image conditioned on a text prompt and an initial image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '| `image` | `prompt` | output |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| ![landscape photo](../Images/a03c8be4cac347c435e8607dd6ced9a4.png) | ***ghibli
    style, a fantasy landscape with snowcapped mountains, trees, lake with detailed
    reflection. warm colors, 8K*** | ![drawing](../Images/9f3025ed17a13258842023d761eaee3c.png)
    |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: Inpaint
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the `NeuronStableDiffusionInpaintPipeline` class, you can edit specific
    parts of an image by providing a mask and a text prompt.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '| `image` | `mask_image` | `prompt` | output |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| ![drawing](../Images/ccaa29fadd7036eecdf16d6ed327b788.png) | ![drawing](../Images/845ec3d502fa4754b97332a095702af9.png)
    | ***Face of a yellow cat, high resolution, sitting on a park bench*** | ![drawing](../Images/229c5966ac3cee6ead365a6a1b86e209.png)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: Stable Diffusion XL
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*There is a notebook version of that tutorial [here](https://github.com/huggingface/optimum-neuron/blob/main/notebooks/stable-diffusion/stable-diffusion-xl-txt2img.ipynb)*.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion XL (SDXL) is a latent diffusion model for text-to-image. Compared
    to the previous versions of Stable Diffusion models, it improves the quality of
    generated images with a times larger UNet.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰æ˜¯ä¸€ç§æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚ä¸ä¹‹å‰ç‰ˆæœ¬çš„ç¨³å®šæ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒé€šè¿‡ä¸€ä¸ªæ¯”UNetå¤§å‡ å€çš„UNetæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚
- en: Compile Stable Diffusion XL
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¼–è¯‘ç¨³å®šæ‰©æ•£XL
- en: 'To deploy SDXL models, we will also start by compiling the models. We support
    the export of following components in the pipeline to boost the speed:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¦éƒ¨ç½²SDXLæ¨¡å‹ï¼Œæˆ‘ä»¬ä¹Ÿå°†ä»ç¼–è¯‘æ¨¡å‹å¼€å§‹ã€‚æˆ‘ä»¬æ”¯æŒåœ¨æµæ°´çº¿ä¸­å¯¼å‡ºä»¥ä¸‹ç»„ä»¶ä»¥æé«˜é€Ÿåº¦ï¼š
- en: Text encoder
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–‡æœ¬ç¼–ç å™¨
- en: Second text encoder
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨
- en: U-Net (a three times larger UNet than the one in Stable Diffusion pipeline)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: U-Netï¼ˆæ¯”ç¨³å®šæ‰©æ•£æµæ°´çº¿ä¸­çš„UNetå¤§ä¸‰å€ï¼‰
- en: VAE encoder
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAEç¼–ç å™¨
- en: VAE decoder
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAEè§£ç å™¨
- en: '***Export via CLI***'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '***é€šè¿‡CLIå¯¼å‡º***'
- en: 'Here is an example of exporting SDXL components with `Optimum` CLI:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä½¿ç”¨`Optimum` CLIå¯¼å‡ºSDXLç»„ä»¶çš„ç¤ºä¾‹ï¼š
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We recommend using a `inf2.8xlarge` or a larger instance for the model compilation.
    You will also be able to compile the model with Optimum CLI on a CPU-only instance
    (needs ~92 GB memory), and then run the pre-compiled models on `inf2.xlarge` to
    reduce the expenses. In this case, donâ€™t forget to disable validation of inference
    by adding the `--disable-validation` argument.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å»ºè®®ä½¿ç”¨`inf2.8xlarge`æˆ–æ›´å¤§çš„å®ä¾‹è¿›è¡Œæ¨¡å‹ç¼–è¯‘ã€‚æ‚¨è¿˜å¯ä»¥åœ¨ä»…CPUå®ä¾‹ä¸Šä½¿ç”¨Optimum CLIç¼–è¯‘æ¨¡å‹ï¼ˆéœ€è¦çº¦92 GBå†…å­˜ï¼‰ï¼Œç„¶ååœ¨`inf2.xlarge`ä¸Šè¿è¡Œé¢„ç¼–è¯‘çš„æ¨¡å‹ä»¥å‡å°‘è´¹ç”¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸è¦å¿˜è®°é€šè¿‡æ·»åŠ `--disable-validation`å‚æ•°æ¥ç¦ç”¨æ¨ç†çš„éªŒè¯ã€‚
- en: '***Export via Python API***'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '***é€šè¿‡Python APIå¯¼å‡º***'
- en: 'Here is an example of exporting stable diffusion components with `NeuronStableDiffusionXLPipeline`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä½¿ç”¨`NeuronStableDiffusionXLPipeline`å¯¼å‡ºç¨³å®šæ‰©æ•£ç»„ä»¶çš„ç¤ºä¾‹ï¼š
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Text-to-Image
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ°å›¾åƒ
- en: 'With pre-compiled SDXL models, now generate an image with a text prompt on
    Neuron:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é¢„ç¼–è¯‘çš„SDXLæ¨¡å‹ï¼Œåœ¨Neuronä¸Šç”Ÿæˆå¸¦æœ‰æ–‡æœ¬æç¤ºçš„å›¾åƒï¼š
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![sdxl generated image](../Images/459955f189c918feb31cbea2635a34a6.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![sdxl ç”Ÿæˆçš„å›¾åƒ](../Images/459955f189c918feb31cbea2635a34a6.png)'
- en: Image-to-Image
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å›¾åƒåˆ°å›¾åƒ
- en: 'With `NeuronStableDiffusionXLImg2ImgPipeline`, you can pass an initial image,
    and a text prompt to condition generated images:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`NeuronStableDiffusionXLImg2ImgPipeline`ï¼Œæ‚¨å¯ä»¥ä¼ é€’åˆå§‹å›¾åƒå’Œæ–‡æœ¬æç¤ºæ¥ç”Ÿæˆå›¾åƒï¼š
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '| `image` | `prompt` | output |  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `å›¾åƒ` | `æç¤º` | è¾“å‡º |  |'
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: | :-: | --: |'
- en: '| ![castle photo](../Images/e5215d4ce7ccbc07b76cb40644414686.png) | ***a dog
    running, lake, moat*** | ![castle with dog](../Images/29129c40c7a3a79920bce7731bc121d1.png)
    |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| ![åŸå ¡ç…§ç‰‡](../Images/e5215d4ce7ccbc07b76cb40644414686.png) | ***ä¸€åªç‹—å¥”è·‘ï¼Œæ¹–æ³Šï¼ŒæŠ¤åŸæ²³***
    | ![å¸¦ç‹—çš„åŸå ¡](../Images/29129c40c7a3a79920bce7731bc121d1.png) |  |'
- en: Inpaint
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¿®è¡¥
- en: With `NeuronStableDiffusionXLInpaintPipeline`, pass the original image and a
    mask of what you want to replace in the original image. Then replace the masked
    area with content described in a prompt.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`NeuronStableDiffusionXLInpaintPipeline`ï¼Œä¼ é€’åŸå§‹å›¾åƒå’Œè¦æ›¿æ¢çš„åŸå§‹å›¾åƒä¸­çš„é®ç½©ã€‚ç„¶åç”¨æç¤ºä¸­æè¿°çš„å†…å®¹æ›¿æ¢é®ç½©åŒºåŸŸã€‚
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '| `image` | `mask_image` | `prompt` | output |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| `å›¾åƒ` | `é®ç½©å›¾åƒ` | `æç¤º` | è¾“å‡º |'
- en: '| :-: | :-: | :-: | --: |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: | :-: | --: |'
- en: '| ![drawing](../Images/47eb848e4e09fd8ca2c920b1f98d089d.png) | ![drawing](../Images/8b01e9765d5fea46006fd0c5b7114470.png)
    | ***A deep sea diver floating*** | ![drawing](../Images/6b61a673bfb3f2ec07bfa522a6e3a183.png)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| ![drawing](../Images/47eb848e4e09fd8ca2c920b1f98d089d.png) | ![drawing](../Images/8b01e9765d5fea46006fd0c5b7114470.png)
    | ***ä¸€åæ½œæ°´å‘˜æ¼‚æµ®*** | ![drawing](../Images/6b61a673bfb3f2ec07bfa522a6e3a183.png) |'
- en: Refine Image Quality
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç²¾åŒ–å›¾åƒè´¨é‡
- en: 'SDXL includes a [refiner model](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)
    to denoise low-noise stage images generated from the base model. There are two
    ways to use the refiner:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SDXLåŒ…æ‹¬ä¸€ä¸ª[ç²¾åŒ–æ¨¡å‹](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)ï¼Œç”¨äºå»å™ªä»åŸºç¡€æ¨¡å‹ç”Ÿæˆçš„ä½å™ªå£°é˜¶æ®µå›¾åƒã€‚æœ‰ä¸¤ç§ä½¿ç”¨ç²¾åŒ–æ¨¡å‹çš„æ–¹å¼ï¼š
- en: use the base and refiner model together to produce a refined image.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†åŸºç¡€å’Œç²¾åŒ–æ¨¡å‹ä¸€èµ·ä½¿ç”¨ä»¥ç”Ÿæˆç²¾åŒ–å›¾åƒã€‚
- en: use the base model to produce an image, and subsequently use the refiner model
    to add more details to the image.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œç„¶åä½¿ç”¨ç²¾åŒ–æ¨¡å‹ä¸ºå›¾åƒæ·»åŠ æ›´å¤šç»†èŠ‚ã€‚
- en: Base + refiner model
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åŸºç¡€ + ç²¾åŒ–æ¨¡å‹
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![sdxl base + refiner](../Images/59c8ddd276bac26aa0202d6cef205b32.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![sdxl åŸºç¡€ + ç²¾åŒ–å™¨](../Images/59c8ddd276bac26aa0202d6cef205b32.png)'
- en: Base to refiner model
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åŸºç¡€åˆ°ç²¾åŒ–æ¨¡å‹
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '| `Base Image` | Refined Image |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `åŸºç¡€å›¾åƒ` | ç²¾åŒ–å›¾åƒ |'
- en: '| :-: | --: |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| :-: | --: |'
- en: '| ![drawing](../Images/40389db8dd5d1a686e6a53d11695fce3.png) | ![drawing](../Images/4e196d834fb8351ee9138956a8b23cd3.png)
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| ![drawing](../Images/40389db8dd5d1a686e6a53d11695fce3.png) | ![drawing](../Images/4e196d834fb8351ee9138956a8b23cd3.png)
    |'
- en: To avoid Neuron device out of memory, itâ€™s suggested to finish all base inference
    and release the device memory before running the refiner.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºé¿å…Neuronè®¾å¤‡å†…å­˜ä¸è¶³ï¼Œå»ºè®®åœ¨è¿è¡Œç²¾åŒ–å™¨ä¹‹å‰å®Œæˆæ‰€æœ‰åŸºç¡€æ¨ç†å¹¶é‡Šæ”¾è®¾å¤‡å†…å­˜ã€‚
- en: Latent Consistency Models
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹
- en: 'Latent Consistency Models (LCMs) were proposed in [Latent Consistency Models:
    Synthesizing High-Resolution Images with Few-Step Inference by Simian Luo, Yiqin
    Tan, Longbo Huang, Jian Li, and Hang Zhao](https://huggingface.co/papers/2310.04378).
    LCMs enable inference with fewer steps on any pre-trained LDMs, including Stable
    Diffusion and SDXL.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ï¼ˆLCMsï¼‰æ˜¯ç”±Simian Luoã€Yiqin Tanã€Longbo Huangã€Jian Liå’ŒHang Zhaoæå‡ºçš„[æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ï¼šé€šè¿‡å°‘æ­¥æ¨ç†åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒ](https://huggingface.co/papers/2310.04378)ã€‚LCMsä½¿å¾—åœ¨ä»»ä½•é¢„è®­ç»ƒçš„LDMä¸Šè¿›è¡Œæ¨ç†æ—¶å¯ä»¥å‡å°‘æ­¥éª¤ï¼ŒåŒ…æ‹¬ç¨³å®šæ‰©æ•£å’ŒSDXLã€‚
- en: 'In `optimum-neuron`, you can:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨`optimum-neuron`ä¸­ï¼Œæ‚¨å¯ä»¥ï¼š
- en: Use the class `NeuronLatentConsistencyModelPipeline` to compile and run inference
    of LCMs distilled from Stable Diffusion (SD) models.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç±»`NeuronLatentConsistencyModelPipeline`æ¥ç¼–è¯‘å’Œè¿è¡Œä»ç¨³å®šæ‰©æ•£ï¼ˆSDï¼‰æ¨¡å‹ä¸­æç‚¼çš„LCMsçš„æ¨ç†ã€‚
- en: And continue to use the class `NeuronStableDiffusionXLPipeline` for LCMs distilled
    from SDXL models.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹¶ç»§ç»­ä½¿ç”¨ä»SDXLæ¨¡å‹ä¸­æç‚¼çš„LCMç±»`NeuronStableDiffusionXLPipeline`ã€‚
- en: 'Here are examples to compile the LCMs of Stable Diffusion ( [SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7)
    ) and Stable Diffusion XL( [latent-consistency/lcm-sdxl](https://huggingface.co/latent-consistency/lcm-sdxl)
    ), and then run inference on AWS Inferentia 2 :'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ç¼–è¯‘ç¨³å®šæ‰©æ•£çš„LCMsï¼ˆ[SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7)ï¼‰å’Œç¨³å®šæ‰©æ•£XLï¼ˆ[latent-consistency/lcm-sdxl](https://huggingface.co/latent-consistency/lcm-sdxl)ï¼‰çš„ç¤ºä¾‹ï¼Œç„¶ååœ¨AWS
    Inferentia 2ä¸Šè¿è¡Œæ¨ç†ï¼š
- en: Compile LCM
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¼–è¯‘LCM
- en: '***LCM of Stable Diffusion***'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '***ç¨³å®šæ‰©æ•£çš„LCM***'
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '***LCM of Stable Diffusion XL***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '***ç¨³å®šæ‰©æ•£XLçš„LCM***'
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Text-to-Image
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ°å›¾åƒ
- en: 'Now we can generate images from text prompts on Inf2 using the pre-compiled
    model:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨Inf2ä¸Šä½¿ç”¨é¢„ç¼–è¯‘æ¨¡å‹ä»æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒã€‚
- en: '***LCM of Stable Diffusion***'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '***ç¨³å®šæ‰©æ•£çš„LCM***'
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '***LCM of Stable Diffusion XL***'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '***ç¨³å®šæ‰©æ•£XLçš„LCM***'
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Stable Diffusion XL Turbo
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XL Turbo
- en: SDXL Turbo is an adversarial time-distilled Stable Diffusion XL (SDXL) model
    capable of running inference in as little as 1 step ([check `ğŸ¤—diffusers` for more
    details](https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo)).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: SDXL Turboæ˜¯ä¸€ç§å¯¹æŠ—æ—¶é—´è’¸é¦çš„ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ä»…1æ­¥éª¤ä¸­è¿è¡Œæ¨æ–­ï¼ˆ[æŸ¥çœ‹`ğŸ¤—diffusers`è·å–æ›´å¤šè¯¦æƒ…](https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo)ï¼‰ã€‚
- en: 'In `optimum-neuron`, you can:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨`optimum-neuron`ä¸­ï¼Œæ‚¨å¯ä»¥ï¼š
- en: Use the class `NeuronStableDiffusionXLPipeline` to compile and run inference.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç±»`NeuronStableDiffusionXLPipeline`æ¥ç¼–è¯‘å’Œè¿è¡Œæ¨æ–­ã€‚
- en: Here we will compile the [`stabilityai/sdxl-turbo`](https://huggingface.co/stabilityai/sdxl-turbo)
    model with Optimum CLI.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Optimum CLIç¼–è¯‘[`stabilityai/sdxl-turbo`](https://huggingface.co/stabilityai/sdxl-turbo)æ¨¡å‹ã€‚
- en: Compile SDXL Turbo
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¼–è¯‘SDXL Turbo
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Text-to-Image
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ°å›¾åƒ
- en: 'Now we can generate images from text prompts on Inf2 using the pre-compiled
    model:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨Inf2ä¸Šä½¿ç”¨é¢„ç¼–è¯‘æ¨¡å‹ä»æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒï¼š
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Inf2 instances contain one or more Neuron devices, and each Neuron device includes
    2 NeuronCore-v2\. By default, we load the whole pipeline of LCM to both Neuron
    cores. It means that when the batch size is divisible by 2, you can fully leverage
    the compute power of both cores.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Inf2å®ä¾‹åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªç¥ç»å…ƒè®¾å¤‡ï¼Œæ¯ä¸ªç¥ç»å…ƒè®¾å¤‡åŒ…æ‹¬2ä¸ªNeuronCore-v2ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†LCMçš„æ•´ä¸ªæµæ°´çº¿åŠ è½½åˆ°ä¸¤ä¸ªç¥ç»å…ƒæ ¸å¿ƒä¸­ã€‚è¿™æ„å‘³ç€å½“æ‰¹é‡å¤§å°å¯ä»¥è¢«2æ•´é™¤æ—¶ï¼Œæ‚¨å¯ä»¥å……åˆ†åˆ©ç”¨ä¸¤ä¸ªæ ¸å¿ƒçš„è®¡ç®—èƒ½åŠ›ã€‚
- en: Are there any other stable diffusion features that you want us to support in
    ğŸ¤—`Optimum-neuron`? Please file an issue to [`Optimum-neuron` Github repo](https://github.com/huggingface/optimum-neuron)
    or discuss with us on [HuggingFaceâ€™s community forum](https://discuss.huggingface.co/c/optimum/),
    cheers ğŸ¤— !
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨æ˜¯å¦å¸Œæœ›æˆ‘ä»¬æ”¯æŒğŸ¤—`Optimum-neuron`ä¸­çš„å…¶ä»–ç¨³å®šæ‰©æ•£åŠŸèƒ½ï¼Ÿè¯·åœ¨[`Optimum-neuron` Githubä»“åº“](https://github.com/huggingface/optimum-neuron)ä¸Šæäº¤é—®é¢˜æˆ–åœ¨[HuggingFaceçš„ç¤¾åŒºè®ºå›](https://discuss.huggingface.co/c/optimum/)ä¸Šä¸æˆ‘ä»¬è®¨è®ºï¼Œè°¢è°¢ğŸ¤—ï¼
