- en: Using TGI CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/text-generation-inference/basic_tutorials/using_cli](https://huggingface.co/docs/text-generation-inference/basic_tutorials/using_cli)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/text-generation-inference/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/entry/start.96d64f85.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/scheduler.9680c161.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/singletons.5632daf5.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/index.9d57cde4.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/paths.5eca520f.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/entry/app.48a2a24c.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/index.38d74ee1.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/nodes/0.c01ff294.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/nodes/7.bb2d221b.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/CodeBlock.1371964c.js">
    <link rel="modulepreload" href="/docs/text-generation-inference/main/en/_app/immutable/chunks/Heading.74c51a96.js">
  prefs: []
  type: TYPE_NORMAL
- en: You can use TGI command-line interface (CLI) to download weights, serve and
    quantize models, or get information on serving parameters. To install the CLI,
    please refer to [the installation section](../installation#install-cli).
  prefs: []
  type: TYPE_NORMAL
- en: '`text-generation-server` lets you download the model with `download-weights`
    command like below ðŸ‘‡'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can also use it to quantize models like below ðŸ‘‡
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can use `text-generation-launcher` to serve models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: There are many options and parameters you can pass to `text-generation-launcher`.
    The documentation for CLI is kept minimal and intended to rely on self-generating
    documentation, which can be found by running
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can also find it hosted in this [Swagger UI](https://huggingface.github.io/text-generation-inference/).
  prefs: []
  type: TYPE_NORMAL
- en: Same documentation can be found for `text-generation-server`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
