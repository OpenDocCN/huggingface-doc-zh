# 规范化器

> 原始文本: [https://huggingface.co/docs/tokenizers/api/normalizers](https://huggingface.co/docs/tokenizers/api/normalizers)

PythonRustNode

## Bert规范化器

### `class tokenizers.normalizers.BertNormalizer`

```py
( clean_text = True handle_chinese_chars = True strip_accents = None lowercase = True )
```

参数

+   `clean_text` (`bool`, *可选*, 默认为 `True`) — 是否清理文本，删除所有控制字符并用经典空格替换所有空白字符。

+   `handle_chinese_chars` (`bool`, *可选*, 默认为 `True`) — 是否处理中文字符，将空格放在它们周围。

+   `strip_accents` (`bool`, *可选*) — 是否去除所有重音符号。如果未指定此选项（即 == None），则将由*lowercase*的值确定（与原始Bert中的相同）。

+   `lowercase` (`bool`, *可选*, 默认为 `True`) — 是否小写。

Bert规范化器

在将原始文本提供给Bert模型之前对其进行规范化。这包括清理文本、处理重音符号、中文字符和小写化

## 小写

### `class tokenizers.normalizers.Lowercase`

```py
( )
```

小写规范化器

## NFC

### `class tokenizers.normalizers.NFC`

```py
( )
```

NFC Unicode规范化器

## NFD

### `class tokenizers.normalizers.NFD`

```py
( )
```

NFD Unicode规范化器

## NFKC

### `class tokenizers.normalizers.NFKC`

```py
( )
```

NFKC Unicode规范化器

## NFKD

### `class tokenizers.normalizers.NFKD`

```py
( )
```

NFKD Unicode规范化器

## Nmt

### `class tokenizers.normalizers.Nmt`

```py
( )
```

Nmt规范化器

## 规范化器

### `class tokenizers.normalizers.Normalizer`

```py
( )
```

所有规范化器的基类

这个类不应该直接实例化。相反，任何规范化器的实现在实例化时会返回这个类的一个实例。

#### `normalize`

```py
( normalized )
```

参数

+   `normalized` (`NormalizedString`) — 要应用此[规范化器](/docs/tokenizers/v0.13.4.rc2/en/api/normalizers#tokenizers.normalizers.Normalizer)的规范化字符串

原地规范化`NormalizedString`

这个方法允许修改`NormalizedString`以跟踪对齐信息。如果你只想看到原始字符串上规范化的结果，可以使用`normalize_str()`

#### `normalize_str`

```py
( sequence ) → str
```

参数

+   `sequence` (`str`) — 要规范化的字符串

返回

`str`

规范化后的字符串

规范化给定的字符串

这个方法提供了一种可视化[规范化器](/docs/tokenizers/v0.13.4.rc2/en/api/normalizers#tokenizers.normalizers.Normalizer)效果的方式，但不会跟踪对齐信息。如果需要获取/转换偏移量，可以使用`normalize()`

## 预编译

### `class tokenizers.normalizers.Precompiled`

```py
( precompiled_charsmap )
```

预编译规范化器 不要手动使用，它用于与SentencePiece的兼容性。

## 替换

### `class tokenizers.normalizers.Replace`

```py
( pattern content )
```

替换规范化器

## 序列

### `class tokenizers.normalizers.Sequence`

```py
( )
```

参数

+   `normalizers` (`List[Normalizer]`) — 要作为序列运行的规范化器列表

允许将多个其他规范化器连接为序列。所有规范化器按给定顺序依次运行

## 去除

### `class tokenizers.normalizers.Strip`

```py
( left = True right = True )
```

替换规范化器

## 去除重音符号

### `class tokenizers.normalizers.StripAccents`

```py
( )
```

StripAccents规范化器
