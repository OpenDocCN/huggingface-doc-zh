- en: Glossary
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ¯è¯­è¡¨
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit1/glossary](https://huggingface.co/learn/deep-rl-course/unit1/glossary)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/learn/deep-rl-course/unit1/glossary](https://huggingface.co/learn/deep-rl-course/unit1/glossary)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This is a community-created glossary. Contributions are welcomed!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç”±ç¤¾åŒºåˆ›å»ºçš„æœ¯è¯­è¡¨ã€‚æ¬¢è¿è´¡çŒ®ï¼
- en: Agent
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»£ç†
- en: An agent learns to **make decisions by trial and error, with rewards and punishments
    from the surroundings**.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç†é€šè¿‡ä¸å‘¨å›´ç¯å¢ƒçš„å¥–åŠ±å’Œæƒ©ç½šè¿›è¡Œè¯•é”™å­¦ä¹ **åšå‡ºå†³ç­–**ã€‚
- en: Environment
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¯å¢ƒ
- en: An environment is a simulated world **where an agent can learn by interacting
    with it**.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç¯å¢ƒæ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ä¸–ç•Œ**ä»£ç†å¯ä»¥é€šè¿‡ä¸ä¹‹äº’åŠ¨æ¥å­¦ä¹ **ã€‚
- en: Markov Property
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é©¬å°”å¯å¤«æ€§è´¨
- en: It implies that the action taken by our agent is **conditional solely on the
    present state and independent of the past states and actions**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æˆ‘ä»¬çš„ä»£ç†æ‰€é‡‡å–çš„è¡ŒåŠ¨**ä»…å–å†³äºå½“å‰çŠ¶æ€ï¼Œç‹¬ç«‹äºè¿‡å»çš„çŠ¶æ€å’Œè¡ŒåŠ¨**ã€‚
- en: Observations/State
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿ/çŠ¶æ€
- en: '**State**: Complete description of the state of the world.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**çŠ¶æ€**ï¼šä¸–ç•ŒçŠ¶æ€çš„å®Œæ•´æè¿°ã€‚'
- en: '**Observation**: Partial description of the state of the environment/world.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§‚å¯Ÿ**ï¼šç¯å¢ƒ/ä¸–ç•ŒçŠ¶æ€çš„éƒ¨åˆ†æè¿°ã€‚'
- en: Actions
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¡ŒåŠ¨
- en: '**Discrete Actions**: Finite number of actions, such as left, right, up, and
    down.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¦»æ•£è¡ŒåŠ¨**ï¼šæœ‰é™æ•°é‡çš„è¡ŒåŠ¨ï¼Œæ¯”å¦‚å·¦ã€å³ã€ä¸Šã€ä¸‹ã€‚'
- en: '**Continuous Actions**: Infinite possibility of actions; for example, in the
    case of self-driving cars, the driving scenario has an infinite possibility of
    actions occurring.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿ç»­è¡ŒåŠ¨**ï¼šè¡ŒåŠ¨çš„æ— é™å¯èƒ½æ€§ï¼›ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„æƒ…å†µä¸‹ï¼Œé©¾é©¶åœºæ™¯æœ‰æ— é™å¯èƒ½å‘ç”Ÿçš„è¡ŒåŠ¨ã€‚'
- en: Rewards and Discounting
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¥–åŠ±å’ŒæŠ˜æ‰£
- en: '**Rewards**: Fundamental factor in RL. Tells the agent whether the action taken
    is good/bad.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¥–åŠ±**ï¼šRLä¸­çš„åŸºæœ¬å› ç´ ã€‚å‘Šè¯‰ä»£ç†è¡ŒåŠ¨æ˜¯å¥½è¿˜æ˜¯åã€‚'
- en: RL algorithms are focused on maximizing the **cumulative reward**.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RLç®—æ³•ä¸“æ³¨äºæœ€å¤§åŒ–**ç´¯ç§¯å¥–åŠ±**ã€‚
- en: '**Reward Hypothesis**: RL problems can be formulated as a maximisation of (cumulative)
    return.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¥–åŠ±å‡è®¾**ï¼šRLé—®é¢˜å¯ä»¥è¢«åˆ¶å®šä¸ºï¼ˆç´¯ç§¯ï¼‰å›æŠ¥çš„æœ€å¤§åŒ–ã€‚'
- en: '**Discounting** is performed because rewards obtained at the start are more
    likely to happen as they are more predictable than long-term rewards.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æŠ˜æ‰£**æ˜¯å› ä¸ºåœ¨å¼€å§‹æ—¶è·å¾—çš„å¥–åŠ±æ›´æœ‰å¯èƒ½å‘ç”Ÿï¼Œå› ä¸ºå®ƒä»¬æ¯”é•¿æœŸå¥–åŠ±æ›´å¯é¢„æµ‹ã€‚'
- en: Tasks
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»»åŠ¡
- en: '**Episodic**: Has a starting point and an ending point.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æƒ…èŠ‚æ€§**ï¼šæœ‰ä¸€ä¸ªèµ·ç‚¹å’Œä¸€ä¸ªç»ˆç‚¹ã€‚'
- en: '**Continuous**: Has a starting point but no ending point.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿ç»­**ï¼šæœ‰ä¸€ä¸ªèµ·ç‚¹ä½†æ²¡æœ‰ç»ˆç‚¹ã€‚'
- en: Exploration v/s Exploitation Trade-Off
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¢ç´¢ä¸åˆ©ç”¨çš„æƒè¡¡
- en: '**Exploration**: Itâ€™s all about exploring the environment by trying random
    actions and receiving feedback/returns/rewards from the environment.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¢ç´¢**ï¼šè¿™å®Œå…¨æ˜¯å…³äºé€šè¿‡å°è¯•éšæœºè¡ŒåŠ¨æ¥æ¢ç´¢ç¯å¢ƒï¼Œå¹¶ä»ç¯å¢ƒä¸­è·å¾—åé¦ˆ/å›æŠ¥/å¥–åŠ±ã€‚'
- en: '**Exploitation**: Itâ€™s about exploiting what we know about the environment
    to gain maximum rewards.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åˆ©ç”¨**ï¼šè¿™æ˜¯å…³äºåˆ©ç”¨æˆ‘ä»¬å¯¹ç¯å¢ƒçš„äº†è§£æ¥è·å¾—æœ€å¤§å¥–åŠ±ã€‚'
- en: '**Exploration-Exploitation Trade-Off**: It balances how much we want to **explore**
    the environment and how much we want to **exploit** what we know about the environment.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¢ç´¢-åˆ©ç”¨æƒè¡¡**ï¼šå®ƒå¹³è¡¡äº†æˆ‘ä»¬æƒ³è¦**æ¢ç´¢**ç¯å¢ƒå’Œæˆ‘ä»¬æƒ³è¦**åˆ©ç”¨**å¯¹ç¯å¢ƒçš„äº†è§£çš„ç¨‹åº¦ã€‚'
- en: Policy
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç­–ç•¥
- en: '**Policy**: It is called the agentâ€™s brain. It tells us what action to take,
    given the state.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç­–ç•¥**ï¼šå®ƒè¢«ç§°ä¸ºä»£ç†çš„å¤§è„‘ã€‚å®ƒå‘Šè¯‰æˆ‘ä»¬åœ¨ç»™å®šçŠ¶æ€ä¸‹åº”è¯¥é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ã€‚'
- en: '**Optimal Policy**: Policy that **maximizes** the **expected return** when
    an agent acts according to it. It is learned through *training*.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœ€ä¼˜ç­–ç•¥**ï¼šå½“ä»£ç†æ ¹æ®å®ƒè¡ŒåŠ¨æ—¶**æœ€å¤§åŒ–**äº†**é¢„æœŸå›æŠ¥**çš„ç­–ç•¥ã€‚å®ƒæ˜¯é€šè¿‡*è®­ç»ƒ*å­¦ä¹ çš„ã€‚'
- en: 'Policy-based Methods:'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åŸºäºç­–ç•¥çš„æ–¹æ³•ï¼š
- en: An approach to solving RL problems.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§£å†³RLé—®é¢˜çš„ä¸€ç§æ–¹æ³•ã€‚
- en: In this method, the Policy is learned directly.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œç­–ç•¥æ˜¯ç›´æ¥å­¦ä¹ çš„ã€‚
- en: Will map each state to the best corresponding action at that state. Or a probability
    distribution over the set of possible actions at that state.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ¯ä¸ªçŠ¶æ€æ˜ å°„åˆ°è¯¥çŠ¶æ€çš„æœ€ä½³å¯¹åº”è¡ŒåŠ¨ã€‚æˆ–è€…åœ¨è¯¥çŠ¶æ€ä¸Šå¯èƒ½è¡ŒåŠ¨é›†åˆä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚
- en: 'Value-based Methods:'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åŸºäºä»·å€¼çš„æ–¹æ³•ï¼š
- en: Another approach to solving RL problems.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§£å†³RLé—®é¢˜çš„å¦ä¸€ç§æ–¹æ³•ã€‚
- en: Here, instead of training a policy, we train a **value function** that maps
    each state to the expected value of being in that state.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸æ˜¯è®­ç»ƒä¸€ä¸ªç­–ç•¥ï¼Œè€Œæ˜¯è®­ç»ƒä¸€ä¸ª**ä»·å€¼å‡½æ•°**ï¼Œå°†æ¯ä¸ªçŠ¶æ€æ˜ å°„åˆ°åœ¨è¯¥çŠ¶æ€ä¸‹çš„é¢„æœŸä»·å€¼ã€‚
- en: Contributions are welcomed ğŸ¤—
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿è´¡çŒ® ğŸ¤—
- en: If you want to improve the course, you can [open a Pull Request.](https://github.com/huggingface/deep-rl-class/pulls)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³æ”¹è¿›è¯¾ç¨‹ï¼Œä½ å¯ä»¥[å‘èµ·ä¸€ä¸ªæ‹‰å–è¯·æ±‚ã€‚](https://github.com/huggingface/deep-rl-class/pulls)
- en: 'This glossary was made possible thanks to:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæœ¯è¯­è¡¨å¾—ä»¥å®ç°ï¼Œæ„Ÿè°¢ï¼š
- en: '[@lucifermorningstar1305](https://github.com/lucifermorningstar1305)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[@lucifermorningstar1305](https://github.com/lucifermorningstar1305)'
- en: '[@daspartho](https://github.com/daspartho)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[@daspartho](https://github.com/daspartho)'
- en: '[@misza222](https://github.com/misza222)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[@misza222](https://github.com/misza222)'
