["```py\n>>> from transformers import OneFormerConfig, OneFormerModel\n\n>>> # Initializing a OneFormer shi-labs/oneformer_ade20k_swin_tiny configuration\n>>> configuration = OneFormerConfig()\n>>> # Initializing a model (with random weights) from the shi-labs/oneformer_ade20k_swin_tiny style configuration\n>>> model = OneFormerModel(configuration)\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from transformers import OneFormerProcessor, OneFormerModel\n\n>>> # download texting image\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> # load processor for preprocessing the inputs\n>>> processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_swin_tiny\")\n>>> model = OneFormerModel.from_pretrained(\"shi-labs/oneformer_ade20k_swin_tiny\")\n>>> inputs = processor(image, [\"semantic\"], return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> mask_predictions = outputs.transformer_decoder_mask_predictions\n>>> class_predictions = outputs.transformer_decoder_class_predictions\n\n>>> f\"\ud83d\udc49 Mask Predictions Shape: {list(mask_predictions.shape)}, Class Predictions Shape: {list(class_predictions.shape)}\"\n'\ud83d\udc49 Mask Predictions Shape: [1, 150, 128, 171], Class Predictions Shape: [1, 150, 151]'\n```", "```py\n>>> from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n>>> from PIL import Image\n>>> import requests\n>>> import torch\n\n>>> # load OneFormer fine-tuned on ADE20k for universal segmentation\n>>> processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_swin_tiny\")\n>>> model = OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_ade20k_swin_tiny\")\n\n>>> url = (\n...     \"https://huggingface.co/datasets/hf-internal-testing/fixtures_ade20k/resolve/main/ADE_val_00000001.jpg\"\n... )\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> # Semantic Segmentation\n>>> inputs = processor(image, [\"semantic\"], return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n>>> # model predicts class_queries_logits of shape `(batch_size, num_queries)`\n>>> # and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n>>> class_queries_logits = outputs.class_queries_logits\n>>> masks_queries_logits = outputs.masks_queries_logits\n\n>>> # you can pass them to processor for semantic postprocessing\n>>> predicted_semantic_map = processor.post_process_semantic_segmentation(\n...     outputs, target_sizes=[image.size[::-1]]\n... )[0]\n>>> f\"\ud83d\udc49 Semantic Predictions Shape: {list(predicted_semantic_map.shape)}\"\n'\ud83d\udc49 Semantic Predictions Shape: [512, 683]'\n\n>>> # Instance Segmentation\n>>> inputs = processor(image, [\"instance\"], return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n>>> # model predicts class_queries_logits of shape `(batch_size, num_queries)`\n>>> # and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n>>> class_queries_logits = outputs.class_queries_logits\n>>> masks_queries_logits = outputs.masks_queries_logits\n\n>>> # you can pass them to processor for instance postprocessing\n>>> predicted_instance_map = processor.post_process_instance_segmentation(\n...     outputs, target_sizes=[image.size[::-1]]\n... )[0][\"segmentation\"]\n>>> f\"\ud83d\udc49 Instance Predictions Shape: {list(predicted_instance_map.shape)}\"\n'\ud83d\udc49 Instance Predictions Shape: [512, 683]'\n\n>>> # Panoptic Segmentation\n>>> inputs = processor(image, [\"panoptic\"], return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n>>> # model predicts class_queries_logits of shape `(batch_size, num_queries)`\n>>> # and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n>>> class_queries_logits = outputs.class_queries_logits\n>>> masks_queries_logits = outputs.masks_queries_logits\n\n>>> # you can pass them to processor for panoptic postprocessing\n>>> predicted_panoptic_map = processor.post_process_panoptic_segmentation(\n...     outputs, target_sizes=[image.size[::-1]]\n... )[0][\"segmentation\"]\n>>> f\"\ud83d\udc49 Panoptic Predictions Shape: {list(predicted_panoptic_map.shape)}\"\n'\ud83d\udc49 Panoptic Predictions Shape: [512, 683]'\n```"]