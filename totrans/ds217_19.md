# 使用 TensorFlow 的数据集

> 原文链接：[https://huggingface.co/docs/datasets/use_with_tensorflow](https://huggingface.co/docs/datasets/use_with_tensorflow)

本文是关于如何在 TensorFlow 中使用 `datasets` 的快速介绍，特别关注如何从我们的数据集中获取 `tf.Tensor` 对象，以及如何将数据从 Hugging Face 的 `Dataset` 对象流式传输到 Keras 方法如 `model.fit()`。

## 数据集格式

默认情况下，数据集返回常规的 Python 对象：整数、浮点数、字符串、列表等。

要获取 TensorFlow 张量，您可以将数据集的格式设置为 `tf`：

```py
>>> from datasets import Dataset
>>> data = [[1, 2],[3, 4]]
>>> ds = Dataset.from_dict({"data": data})
>>> ds = ds.with_format("tf")
>>> ds[0]
{'data': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 2])>}
>>> ds[:2]
{'data': <tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[1, 2],
       [3, 4]])>}
```

[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset) 对象是 Arrow 表的包装器，允许从数据集中的数组快速读取到 TensorFlow 张量中。

这对于将数据集转换为 `Tensor` 对象的字典，或者编写一个生成器从中加载 TF 样本非常有用。如果您希望将整个数据集转换为 `Tensor`，只需查询完整数据集即可：

```py
>>> ds[:]
{'data': <tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[1, 2],
       [3, 4]])>}
```

## N 维数组

如果您的数据集由 N 维数组组成，您会发现默认情况下它们被视为嵌套列表。特别是，一个经过 TensorFlow 格式化的数据集会输出一个 `RaggedTensor` 而不是单个张量：

```py
>>> from datasets import Dataset
>>> data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
>>> ds = Dataset.from_dict({"data": data})
>>> ds = ds.with_format("tf")
>>> ds[0]
{'data': <tf.RaggedTensor [[1, 2], [3, 4]]>}
```

要获得单个张量，您必须显式使用 `Array` 特征类型并指定张量的形状：

```py
>>> from datasets import Dataset, Features, Array2D
>>> data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
>>> features = Features({"data": Array2D(shape=(2, 2), dtype='int32')})
>>> ds = Dataset.from_dict({"data": data}, features=features)
>>> ds = ds.with_format("tf")
>>> ds[0]
{'data': <tf.Tensor: shape=(2, 2), dtype=int64, numpy=
 array([[1, 2],
        [3, 4]])>}
>>> ds[:2]
{'data': <tf.Tensor: shape=(2, 2, 2), dtype=int64, numpy=
 array([[[1, 2],
         [3, 4]],

        [[5, 6],
         [7, 8]]])>}
```

## 其他特征类型

[ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel) 数据会被正确转换为张量：

```py
>>> from datasets import Dataset, Features, ClassLabel
>>> labels = [0, 0, 1]
>>> features = Features({"label": ClassLabel(names=["negative", "positive"])})
>>> ds = Dataset.from_dict({"label": labels}, features=features) 
>>> ds = ds.with_format("tf")  
>>> ds[:3]
{'label': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 1])>}
```

字符串和二进制对象也受支持：

```py
>>> from datasets import Dataset, Features 
>>> text = ["foo", "bar"]
>>> data = [0, 1] 
>>> ds = Dataset.from_dict({"text": text, "data": data})  
>>> ds = ds.with_format("tf") 
>>> ds[:2]
{'text': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'foo', b'bar'], dtype=object)>,
 'data': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>}
```

您还可以显式格式化某些列并保留其他列的格式：

```py
>>> ds = ds.with_format("tf", columns=["data"], output_all_columns=True)
>>> ds[:2]
{'data': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>,
 'text': ['foo', 'bar']}
```

字符串和二进制对象保持不变，因为 PyTorch 仅支持数字。

[Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image) 和 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) 特征类型也受支持。

要使用 [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image) 特征类型，您需要安装 `vision` 额外模块，命令为 `pip install datasets[vision]`。

```py
>>> from datasets import Dataset, Features, Audio, Image
>>> images = ["path/to/image.png"] * 10
>>> features = Features({"image": Image()})
>>> ds = Dataset.from_dict({"image": images}, features=features) 
>>> ds = ds.with_format("tf")  
>>> ds[0]
{'image': <tf.Tensor: shape=(512, 512, 4), dtype=uint8, numpy=
 array([[[255, 215, 106, 255],
         [255, 215, 106, 255],
         ...,
         [255, 255, 255, 255],
         [255, 255, 255, 255]]], dtype=uint8)>}
>>> ds[:2]
{'image': <tf.Tensor: shape=(2, 512, 512, 4), dtype=uint8, numpy=
 array([[[[255, 215, 106, 255],
          [255, 215, 106, 255],
          ...,
          [255, 255, 255, 255],
          [255, 255, 255, 255]]]], dtype=uint8)>}
```

使用 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) 特征类型，您需要安装 `audio` 额外模块，命令为 `pip install datasets[audio]`。

```py
>>> from datasets import Dataset, Features, Audio, Image
>>> audio = ["path/to/audio.wav"] * 10
>>> features = Features({"audio": Audio()})
>>> ds = Dataset.from_dict({"audio": audio}, features=features) 
>>> ds = ds.with_format("tf")  
>>> ds[0]["audio"]["array"]
<tf.Tensor: shape=(202311,), dtype=float32, numpy=
array([ 6.1035156e-05,  1.5258789e-05,  1.6784668e-04, ...,
       -1.5258789e-05, -1.5258789e-05,  1.5258789e-05], dtype=float32)>
>>> ds[0]["audio"]["sampling_rate"]
<tf.Tensor: shape=(), dtype=int32, numpy=44100>
```

## 数据加载

虽然您可以通过索引进入数据集来加载单个样本和批次，但如果您想使用 Keras 的方法如 `fit()` 和 `predict()`，这种方法就行不通了。您可以编写一个生成器函数，从数据集中洗牌并加载批次，然后在其上执行 `fit()`，但这听起来像是很多不必要的工作。相反，如果您想要从数据集中实时流式传输数据，我们建议使用 `to_tf_dataset()` 方法将数据集转换为 `tf.data.Dataset`。

`tf.data.Dataset` 类涵盖了各种用例 - 它通常是从内存中的张量创建的，或者使用加载函数从磁盘或外部存储器中读取文件。数据集可以通过 `map()` 方法任意转换，或者可以使用 `batch()` 和 `shuffle()` 等方法创建一个准备好用于训练的数据集。这些方法不会以任何方式修改存储的数据 - 相反，这些方法构建了一个数据管道图，当数据集被迭代时将执行该图，通常在模型训练或推断期间。这与 Hugging Face 的 `Dataset` 对象的 `map()` 方法不同，后者会立即运行 map 函数并保存新的或更改的列。

由于整个数据预处理流程可以在`tf.data.Dataset`中编译，这种方法允许进行大规模并行、异步数据加载和训练。然而，图形编译的要求可能是一个限制，特别是对于Hugging Face的分词器，通常不是（尚未！）可编译为TF图的一部分。因此，我们通常建议将数据集预处理为Hugging Face数据集，其中可以使用任意Python函数，然后使用`to_tf_dataset()`将其转换为`tf.data.Dataset`，以获得一个准备好进行训练的批处理数据集。要查看这种方法的示例，请参阅`transformers`的[examples](https://github.com/huggingface/transformers/tree/main/examples)或[notebooks](https://huggingface.co/docs/transformers/notebooks)。

### 使用to_tf_dataset()

使用`to_tf_dataset()`很简单。一旦您的数据集经过预处理并准备好，只需这样调用：

```py
>>> from datasets import Dataset
>>> data = {"inputs": [[1, 2],[3, 4]], "labels": [0, 1]}
>>> ds = Dataset.from_dict(data)
>>> tf_ds = ds.to_tf_dataset(
            columns=["inputs"],
            label_cols=["labels"],
            batch_size=2,
            shuffle=True
            )
```

这里返回的`tf_ds`对象现在已经完全准备好进行训练，并且可以直接传递给`model.fit()`。请注意，在创建数据集时设置批次大小，因此在调用`fit()`时不需要指定它：

```py
>>> model.fit(tf_ds, epochs=2)
```

有关参数的完整描述，请参阅[to_tf_dataset()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_tf_dataset)文档。在许多情况下，您还需要在调用中添加`collate_fn`。这是一个函数，它接受数据集的多个元素并将它们组合成一个批次。当所有元素具有相同长度时，内置的默认整理器就足够了，但对于更复杂的任务，可能需要一个自定义整理器。特别是，许多任务具有具有不同序列长度的样本，这将需要一个能够正确填充批次的[数据整理器](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator)。您可以在`transformers` NLP [examples](https://github.com/huggingface/transformers/tree/main/examples)和[notebooks](https://huggingface.co/docs/transformers/notebooks)中看到这种情况的示例，其中变长序列是非常常见的。

如果发现使用`to_tf_dataset`加载速度慢，您也可以使用`num_workers`参数。这会启动多个子进程并行加载数据。这个功能是最近添加的，仍然有些实验性 - 如果在使用过程中遇到任何错误，请提交问题！

### 何时使用to_tf_dataset

敏锐的读者可能已经注意到，我们在这一点上提供了两种方法来实现相同的目标 - 如果您想将数据集传递给TensorFlow模型，您可以将数据集转换为`Tensor`或`dict` of `Tensors`，使用`.with_format('tf')`，或者您可以使用`to_tf_dataset()`将数据集转换为`tf.data.Dataset`。这两者都可以传递给`model.fit()`，那么您应该选择哪一个呢？

识别的关键是，当您将整个数据集转换为`Tensor`时，它是静态的并完全加载到RAM中。这很简单和方便，但如果以下任何情况适用，您应该使用`to_tf_dataset()`：

+   您的数据集太大，无法放入RAM中。`to_tf_dataset()`一次只流式传输一个批次，因此即使是非常大的数据集也可以使用这种方法处理。

+   您想使用`dataset.with_transform()`或`collate_fn`应用随机转换。这在几种模态中很常见，例如在训练视觉模型时进行图像增强，或者在训练掩蔽语言模型时进行随机掩蔽。使用`to_tf_dataset()`将在加载批次时应用这些转换，这意味着每次加载时相同的样本将获得不同的增强。这通常是您想要的。

+   您的数据具有可变维度，例如自然语言处理中的输入文本，其中包含不同数量的标记。当您创建一个包含可变维度样本的批次时，标准解决方案是将较短的样本填充到最长样本的长度。当您从数据集中流式传输样本时，可以通过您的`collate_fn`将此填充应用于每个批次。但是，如果您想将这样的数据集转换为稠密的`Tensor`，那么您将不得不将样本填充到*整个数据集中最长样本的长度*！这可能导致大量的填充，浪费内存并降低模型的速度。

### 注意事项和限制

目前，`to_tf_dataset()`始终返回一个批处理的数据集 - 我们将很快添加对未批处理数据集的支持！
