["```py\n( metric_fn: Callable eval_dataset: Union output_cols: Optional = None label_cols: Optional = None batch_size: Optional = None predict_with_generate: bool = False use_xla_generation: bool = False generate_kwargs: Optional = None )\n```", "```py\nfrom datasets import load_metric\n\nrouge_metric = load_metric(\"rouge\")\n\ndef rouge_fn(predictions, labels):\n    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = rouge_metric.compute(predictions=decoded_predictions, references=decoded_labels)\n    return {key: value.mid.fmeasure * 100 for key, value in result.items()}\n```", "```py\n{'rouge1': 37.4199, 'rouge2': 13.9768, 'rougeL': 34.361, 'rougeLsum': 35.0781\n```", "```py\n( output_dir: Union save_strategy: Union = 'epoch' save_steps: Optional = None tokenizer: Optional = None hub_model_id: Optional = None hub_token: Optional = None checkpoint: bool = False **model_card_args )\n```", "```py\nfrom transformers.keras_callbacks import PushToHubCallback\n\npush_to_hub_callback = PushToHubCallback(\n    output_dir=\"./model_save\",\n    tokenizer=tokenizer,\n    hub_model_id=\"gpt5-7xlarge\",\n)\n\nmodel.fit(train_dataset, callbacks=[push_to_hub_callback])\n```"]