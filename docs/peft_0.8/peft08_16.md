# 适配器注入

> 原文链接：[`huggingface.co/docs/peft/developer_guides/low_level_api`](https://huggingface.co/docs/peft/developer_guides/low_level_api)

使用 PEFT，您可以将可训练的适配器注入到任何`torch`模块中，这使您可以在不依赖 PEFT 中的建模类的情况下使用适配器方法。目前，PEFT 支持将 LoRA、AdaLoRA 和 IA3 注入到模型中，因为对于这些适配器，对模型的原地修改足以进行微调。

查看下表，了解何时应该注入适配器。

| 优点 | 缺点 |
| --- | --- |
| 模型在原地修改，保留所有原始属性和方法 | 手动编写`from_pretrained`和`save_pretrained`实用函数，从 Hugging Face 保存和加载适配器 |
| 适用于任何`torch`模块和模态 | 不能与`PeftModel`提供的任何实用方法一起使用，如禁用和合并适配器 |

要执行适配器注入，请使用 inject_adapter_in_model() 方法。此方法接受 3 个参数，PEFT 配置、模型和一个可选的适配器名称。如果使用不同的适配器名称多次调用 inject_adapter_in_model()，还可以将多个适配器附加到模型上。

例如，将 LoRA 适配器注入到`DummyModel`模块的`linear`子模块中：

```py
import torch
from peft import inject_adapter_in_model, LoraConfig

class DummyModel(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.embedding = torch.nn.Embedding(10, 10)
        self.linear = torch.nn.Linear(10, 10)
        self.lm_head = torch.nn.Linear(10, 10)

    def forward(self, input_ids):
        x = self.embedding(input_ids)
        x = self.linear(x)
        x = self.lm_head(x)
        return x

lora_config = LoraConfig(
    lora_alpha=16,
    lora_dropout=0.1,
    r=64,
    bias="none",
    target_modules=["linear"],
)

model = DummyModel()
model = inject_adapter_in_model(lora_config, model)

dummy_inputs = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]])
dummy_outputs = model(dummy_inputs)
```

打印模型以查看适配器是否已正确注入。

```py
DummyModel(
  (embedding): Embedding(10, 10)
  (linear): Linear(
    in_features=10, out_features=10, bias=True
    (lora_dropout): ModuleDict(
      (default): Dropout(p=0.1, inplace=False)
    )
    (lora_A): ModuleDict(
      (default): Linear(in_features=10, out_features=64, bias=False)
    )
    (lora_B): ModuleDict(
      (default): Linear(in_features=64, out_features=10, bias=False)
    )
    (lora_embedding_A): ParameterDict()
    (lora_embedding_B): ParameterDict()
  )
  (lm_head): Linear(in_features=10, out_features=10, bias=True)
)
```

要仅保存适配器，请使用 get_peft_model_state_dict() 函数：

```py
from peft import get_peft_model_state_dict

peft_state_dict = get_peft_model_state_dict(model)
print(peft_state_dict)
```

否则，`model.state_dict()`将返回模型的完整状态字典。
