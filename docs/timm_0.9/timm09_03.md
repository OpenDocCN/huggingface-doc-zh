# 快速入门

> 原文链接：[`huggingface.co/docs/timm/quickstart`](https://huggingface.co/docs/timm/quickstart)

这个快速入门旨在为那些准备深入代码并查看如何将`timm`集成到他们的模型训练工作流程中的开发人员提供一个示例。

首先，您需要安装`timm`。有关安装的更多信息，请参阅 Installation。

```py
pip install timm
```

## 加载预训练模型

可以使用 create_model()加载预训练模型。

在这里，我们加载了预训练的`mobilenetv3_large_100`模型。

```py
>>> import timm

>>> m = timm.create_model('mobilenetv3_large_100', pretrained=True)
>>> m.eval()
```

注意：返回的 PyTorch 模型默认设置为训练模式，因此如果您计划用它进行推断，必须调用.eval()。

## 列出具有预训练权重的模型

要列出打包在`timm`中的模型，您可以使用 list_models()。如果指定`pretrained=True`，此函数将仅返回具有相关预训练权重的模型名称。

```py
>>> import timm
>>> from pprint import pprint
>>> model_names = timm.list_models(pretrained=True)
>>> pprint(model_names)
[
    'adv_inception_v3',
    'cspdarknet53',
    'cspresnext50',
    'densenet121',
    'densenet161',
    'densenet169',
    'densenet201',
    'densenetblur121d',
    'dla34',
    'dla46_c',
]
```

您还可以列出具有特定模式名称的模型。

```py
>>> import timm
>>> from pprint import pprint
>>> model_names = timm.list_models('*resne*t*')
>>> pprint(model_names)
[
    'cspresnet50',
    'cspresnet50d',
    'cspresnet50w',
    'cspresnext50',
    ...
]
```

## 微调预训练模型

只需更改分类器（最后一层），就可以微调任何预训练模型。

```py
>>> model = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)
```

要在自己的数据集上进行微调，您必须编写一个 PyTorch 训练循环或者调整`timm`的训练脚本以使用您的数据集。

## 使用预训练模型进行特征提取

在不修改网络的情况下，可以在任何模型上调用 model.forward_features(input)而不是通常的 model(input)。这将绕过网络的头分类器和全局池化。

要了解如何使用`timm`进行特征提取的更详细指南，请参阅 Feature Extraction。

```py
>>> import timm
>>> import torch
>>> x = torch.randn(1, 3, 224, 224)
>>> model = timm.create_model('mobilenetv3_large_100', pretrained=True)
>>> features = model.forward_features(x)
>>> print(features.shape)
torch.Size([1, 960, 7, 7])
```

## 图像增强

为了将图像转换为模型的有效输入，您可以使用 timm.data.create_transform()，提供模型期望的所需`input_size`。

这将返回一个使用合理默认值的通用转换。

```py
>>> timm.data.create_transform((3, 224, 224))
Compose(
    Resize(size=256, interpolation=bilinear, max_size=None, antialias=None)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
)
```

预训练模型在训练时应用了特定的转换，用于输入到模型中。如果您在图像上使用错误的转换，模型将无法理解它看到的内容！

要找出给定预训练模型使用了哪些转换，我们可以首先查看其`pretrained_cfg`

```py
>>> model.pretrained_cfg
{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth',
 'num_classes': 1000,
 'input_size': (3, 224, 224),
 'pool_size': (7, 7),
 'crop_pct': 0.875,
 'interpolation': 'bicubic',
 'mean': (0.485, 0.456, 0.406),
 'std': (0.229, 0.224, 0.225),
 'first_conv': 'conv_stem',
 'classifier': 'classifier',
 'architecture': 'mobilenetv3_large_100'}
```

我们可以通过使用 timm.data.resolve_data_config()来解决仅与数据相关的配置。

```py
>>> timm.data.resolve_data_config(model.pretrained_cfg)
{'input_size': (3, 224, 224),
 'interpolation': 'bicubic',
 'mean': (0.485, 0.456, 0.406),
 'std': (0.229, 0.224, 0.225),
 'crop_pct': 0.875}
```

我们可以将这些数据配置传递给 timm.data.create_transform()来初始化模型的相关转换。

```py
>>> data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)
>>> transform = timm.data.create_transform(**data_cfg)
>>> transform
Compose(
    Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
)
```

注意：在这里，预训练模型的配置恰好与我们之前制作的通用配置相同。这并不总是这样。因此，与使用通用转换不同，更安全的做法是使用数据配置来创建转换，就像我们在这里所做的那样。

## 使用预训练模型进行推断

在这里，我们将整合上述部分并使用一个预训练模型进行推断。

首先，我们需要一张图像进行推断。这里我们从网络上加载了一张叶子的图片：

```py
>>> import requests
>>> from PIL import Image
>>> from io import BytesIO
>>> url = 'https://datasets-server.huggingface.co/assets/imagenet-1k/--/default/test/12/image/image.jpg'
>>> image = Image.open(requests.get(url, stream=True).raw)
>>> image
```

这是我们加载的图像：

![来自链接的图像](img/044552025856bd5e75f92f37bef155ce.png)

现在，我们将再次创建我们的模型和转换。这次，我们确保将我们的模型设置为评估模式。

```py
>>> model = timm.create_model('mobilenetv3_large_100', pretrained=True).eval()
>>> transform = timm.data.create_transform(
    **timm.data.resolve_data_config(model.pretrained_cfg)
)
```

我们可以通过将图像传递给转换来为模型准备这个图像。

```py
>>> image_tensor = transform(image)
>>> image_tensor.shape
torch.Size([3, 224, 224])
```

现在我们可以将该图像传递给模型以获取预测。在这种情况下，我们使用`unsqueeze(0)`，因为模型期望有一个批次维度。

```py
>>> output = model(image_tensor.unsqueeze(0))
>>> output.shape
torch.Size([1, 1000])
```

要获取预测的概率，我们将 softmax 应用于输出。这将使我们得到一个形状为`(num_classes,)`的张量。

```py
>>> probabilities = torch.nn.functional.softmax(output[0], dim=0)
>>> probabilities.shape
torch.Size([1000])
```

现在我们将使用`torch.topk`找到前 5 个预测类别的索引和值。

```py
>>> values, indices = torch.topk(probabilities, 5)
>>> indices
tensor([162, 166, 161, 164, 167])
```

如果我们检查顶部索引的 imagenet 标签，我们可以看到模型预测的结果...

```py
>>> IMAGENET_1k_URL = 'https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt'
>>> IMAGENET_1k_LABELS = requests.get(IMAGENET_1k_URL).text.strip().split('\n')
>>> [{'label': IMAGENET_1k_LABELS[idx], 'value': val.item()} for val, idx in zip(values, indices)]
[{'label': 'beagle', 'value': 0.8486220836639404},
 {'label': 'Walker_hound, Walker_foxhound', 'value': 0.03753996267914772},
 {'label': 'basset, basset_hound', 'value': 0.024628572165966034},
 {'label': 'bluetick', 'value': 0.010317106731235981},
 {'label': 'English_foxhound', 'value': 0.006958036217838526}]
```
