# 脚本

> 原始文本：[`huggingface.co/docs/timm/training_script`](https://huggingface.co/docs/timm/training_script)

在 github 根文件夹中包含了训练、验证、推理和检查点清理脚本。这些脚本目前尚未打包在 pip 发布中。

训练和验证脚本是从早期版本的[PyTorch Imagenet Examples](https://github.com/pytorch/examples)演变而来。随着时间的推移，我添加了重要的功能，包括基于[NVIDIA 的 APEX 示例](https://github.com/NVIDIA/apex/tree/master/examples)的 CUDA 特定性能增强。

## 训练脚本

训练参数的种类很多，并且并非所有选项的组合（甚至选项）都经过充分测试。对于训练数据集文件夹，请指定包含`train`和`validation`文件夹的基础文件夹。

要在 ImageNet 上训练一个 SE-ResNet34，本地分布式，4 个 GPU，每个 GPU 一个进程，采用余弦调度，随机擦除概率为 50%，每像素随机值：

```py
./distributed_train.sh 4 /data/imagenet --model seresnet34 --sched cosine --epochs 150 --warmup-epochs 5 --lr 0.4 --reprob 0.5 --remode pixel --batch-size 256 --amp -j 4
```

建议使用 PyTorch 1.9+与 PyTorch 本机 AMP 和 DDP，而不是 APEX AMP。--amp 默认为 timmm ver 0.4.3 中的本机 AMP。--apex-amp 将强制使用 APEX 组件（如果已安装）。

## 验证/推理脚本

验证和推理脚本的使用方式类似。一个输出验证集上的指标，另一个输出 csv 中的 topk 类别 ID。请指定包含验证图像的文件夹，而不是像训练脚本中那样指定基础文件夹。

要使用模型的预训练权重进行验证（如果存在）：

```py
python validate.py /imagenet/validation/ --model seresnext26_32x4d --pretrained
```

要从检查点运行推理：

```py
python inference.py /imagenet/validation/ --model mobilenetv3_large_100 --checkpoint ./output/train/model_best.pth.tar
```

## 训练示例

### EfficientNet-B2 with RandAugment - 80.4 top-1, 95.1 top-5

这些参数适用于安装了 NVIDIA Apex 的双 Titan RTX 卡：

```py
./distributed_train.sh 2 /imagenet/ --model efficientnet_b2 -b 128 --sched step --epochs 450 --decay-epochs 2.4 --decay-rate .97 --opt rmsproptf --opt-eps .001 -j 8 --warmup-lr 1e-6 --weight-decay 1e-5 --drop 0.3 --drop-path 0.2 --model-ema --model-ema-decay 0.9999 --aa rand-m9-mstd0.5 --remode pixel --reprob 0.2 --amp --lr .016
```

### MixNet-XL with RandAugment - 80.5 top-1, 94.9 top-5

这些参数适用于安装了 NVIDIA Apex 的双 Titan RTX 卡：

```py
./distributed_train.sh 2 /imagenet/ --model mixnet_xl -b 128 --sched step --epochs 450 --decay-epochs 2.4 --decay-rate .969 --opt rmsproptf --opt-eps .001 -j 8 --warmup-lr 1e-6 --weight-decay 1e-5 --drop 0.3 --drop-path 0.2 --model-ema --model-ema-decay 0.9999 --aa rand-m9-mstd0.5 --remode pixel --reprob 0.3 --amp --lr .016 --dist-bn reduce
```

### SE-ResNeXt-26-D 和 SE-ResNeXt-26-T

这些超参数（或类似的）适用于各种 ResNet 架构，通常建议随着模型大小的增加增加 epoch 数量...例如，对于 ResNe(X)t50，大约为 180-200，对于更大的模型则为 220+。对于性能更好的 GPU 或启用 AMP，增加批量大小和 LR。这些参数适用于两张 1080Ti 卡：

```py
./distributed_train.sh 2 /imagenet/ --model seresnext26t_32x4d --lr 0.1 --warmup-epochs 5 --epochs 160 --weight-decay 1e-4 --sched cosine --reprob 0.4 --remode pixel -b 112
```

### EfficientNet-B3 with RandAugment - 81.5 top-1, 95.7 top-5

这个模型的训练从与上面的 EfficientNet-B2 w/ RA 相同的命令行开始。经过将近三周的训练，进程崩溃了。结果看起来并不令人惊讶，所以我多次恢复训练，并对一些参数进行了调整（增加 RE 概率，减少 rand-aug，增加 ema-decay）。没有什么看起来很好。我最终对所有重新启动的最佳检查点进行了平均。结果在默认的 res/crop 下一般，但在全图像测试裁剪为 1.0 时表现得更好。

### EfficientNet-B0 with RandAugment - 77.7 top-1, 95.3 top-5

[Michael Klachko](https://github.com/michaelklachko) 使用了适用于更大批量大小的 B2 命令行，并采用了推荐的 B0 丢失率为 0.2。

```py
./distributed_train.sh 2 /imagenet/ --model efficientnet_b0 -b 384 --sched step --epochs 450 --decay-epochs 2.4 --decay-rate .97 --opt rmsproptf --opt-eps .001 -j 8 --warmup-lr 1e-6 --weight-decay 1e-5 --drop 0.2 --drop-path 0.2 --model-ema --model-ema-decay 0.9999 --aa rand-m9-mstd0.5 --remode pixel --reprob 0.2 --amp --lr .048
```

### ResNet50 with JSD loss and RandAugment（干净+2x RA 增强）- 79.04 top-1, 94.39 top-5

在两张较旧的 1080Ti 卡上训练，这花了一些时间。与我第一次良好的 AugMix 训练相比，ImageNet 验证结果仅略有提高，达到了 78.99。然而，这些权重在 ImageNetV2、ImageNet-Sketch 等测试中更加稳健。与我的第一次 AugMix 运行不同，我启用了 SplitBatchNorm，关闭了干净分割上的随机擦除，并增加了两个增强路径上的随机擦除概率。

```py
./distributed_train.sh 2 /imagenet -b 64 --model resnet50 --sched cosine --epochs 200 --lr 0.05 --amp --remode pixel --reprob 0.6 --aug-splits 3 --aa rand-m9-mstd0.5-inc1 --resplit --split-bn --jsd --dist-bn reduce
```

### EfficientNet-ES（EdgeTPU-Small）with RandAugment - 78.066 top-1, 93.926 top-5

由[Andrew Lavin](https://github.com/andravin)使用 8 张 V100 卡进行训练。未使用模型 EMA，最终检查点是在训练期间 8 个最佳检查点的平均值。

```py
./distributed_train.sh 8 /imagenet --model efficientnet_es -b 128 --sched step --epochs 450 --decay-epochs 2.4 --decay-rate .97 --opt rmsproptf --opt-eps .001 -j 8 --warmup-lr 1e-6 --weight-decay 1e-5 --drop 0.2 --drop-path 0.2  --aa rand-m9-mstd0.5 --remode pixel --reprob 0.2 --amp --lr .064
```

### MobileNetV3-Large-100 - 75.766 top-1, 92,542 top-5

```py
./distributed_train.sh 2 /imagenet/ --model mobilenetv3_large_100 -b 512 --sched step --epochs 600 --decay-epochs 2.4 --decay-rate .973 --opt rmsproptf --opt-eps .001 -j 7 --warmup-lr 1e-6 --weight-decay 1e-5 --drop 0.2 --drop-path 0.2 --model-ema --model-ema-decay 0.9999 --aa rand-m9-mstd0.5 --remode pixel --reprob 0.2 --amp --lr .064 --lr-noise 0.42 0.9
```

### ResNeXt-50 32x4d w/ RandAugment - 79.762 top-1, 94.60 top-5

这些参数也适用于 SE-ResNeXt-50 和 SK-ResNeXt-50，可能也适用于 101。我用它们来训练 SK-ResNeXt-50 32x4d，使用 2 个 GPU，每个有效批次大小稍高的学习率（lr=0.18，b=192 每个 GPU）。下面的命令行针对 8 个 GPU 训练进行了调整。

```py
./distributed_train.sh 8 /imagenet --model resnext50_32x4d --lr 0.6 --warmup-epochs 5 --epochs 240 --weight-decay 1e-4 --sched cosine --reprob 0.4 --recount 3 --remode pixel --aa rand-m7-mstd0.5-inc1 -b 192 -j 6 --amp --dist-bn reduce
```
