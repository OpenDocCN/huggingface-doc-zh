# æ¨¡å‹

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/diffusers/api/models/overview`](https://huggingface.co/docs/diffusers/api/models/overview)

ğŸ¤— Diffusers ä¸ºæµè¡Œçš„ç®—æ³•å’Œæ¨¡å—æä¾›é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥åˆ›å»ºè‡ªå®šä¹‰æ‰©æ•£ç³»ç»Ÿã€‚æ¨¡å‹çš„ä¸»è¦åŠŸèƒ½æ˜¯å»å™ªè¾“å…¥æ ·æœ¬ï¼Œå…¶æ¨¡å‹ç”±åˆ†å¸ƒ<math><semantics><mrow><msub><mi>p</mi><mi>Î¸</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">âˆ£</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math>pÎ¸â€‹(xtâˆ’1â€‹âˆ£xtâ€‹)å»ºæ¨¡ã€‚

æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯ä»åŸºç¡€ ModelMixin ç±»æ„å»ºçš„ï¼Œè¯¥ç±»æ˜¯ä¸€ä¸ª[`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)ï¼Œæä¾›äº†ä¿å­˜å’ŒåŠ è½½æ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½ï¼Œå¯ä»¥åœ¨æœ¬åœ°å’Œä» Hugging Face Hub ä¸­åŠ è½½ã€‚

## ModelMixin

### `class diffusers.ModelMixin`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L186)

```py
( )
```

æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ã€‚

ModelMixin è´Ÿè´£å­˜å‚¨æ¨¡å‹é…ç½®ï¼Œå¹¶æä¾›äº†åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚

+   `config_name` (`str`) â€” åœ¨è°ƒç”¨ save_pretrained()æ—¶ä¿å­˜æ¨¡å‹çš„æ–‡ä»¶åã€‚

#### `disable_gradient_checkpointing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L238)

```py
( )
```

ä¸ºå½“å‰æ¨¡å‹åœç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆåœ¨å…¶ä»–æ¡†æ¶ä¸­å¯èƒ½è¢«ç§°ä¸º*æ¿€æ´»æ£€æŸ¥ç‚¹*æˆ–*æ£€æŸ¥ç‚¹æ¿€æ´»*ï¼‰ã€‚

#### `disable_xformers_memory_efficient_attention`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L299)

```py
( )
```

ä»[xFormers](https://facebookresearch.github.io/xformers/)ç¦ç”¨å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚

#### `enable_gradient_checkpointing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L229)

```py
( )
```

ä¸ºå½“å‰æ¨¡å‹æ¿€æ´»æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆåœ¨å…¶ä»–æ¡†æ¶ä¸­å¯èƒ½è¢«ç§°ä¸º*æ¿€æ´»æ£€æŸ¥ç‚¹*æˆ–*æ£€æŸ¥ç‚¹æ¿€æ´»*ï¼‰ã€‚

#### `enable_xformers_memory_efficient_attention`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L263)

```py
( attention_op: Optional = None )
```

å‚æ•°

+   `attention_op` (`Callable`, *optional*) â€” ç”¨ä½œ xFormers çš„[`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)å‡½æ•°çš„`op`å‚æ•°çš„é»˜è®¤`None`è¿ç®—ç¬¦çš„è¦†ç›–ã€‚

ä»[xFormers](https://facebookresearch.github.io/xformers/)å¯ç”¨å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚

å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°è¾ƒä½çš„ GPU å†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶ä¸”åœ¨æ¨æ–­æœŸé—´å¯èƒ½ä¼šåŠ é€Ÿã€‚ä¸èƒ½ä¿è¯åœ¨è®­ç»ƒæœŸé—´åŠ é€Ÿã€‚

âš ï¸ å½“å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ä¼˜å…ˆã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import UNet2DConditionModel
>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp

>>> model = UNet2DConditionModel.from_pretrained(
...     "stabilityai/stable-diffusion-2-1", subfolder="unet", torch_dtype=torch.float16
... )
>>> model = model.to("cuda")
>>> model.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)
```

#### `from_pretrained`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L393)

```py
( pretrained_model_name_or_path: Union **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`, *optional*) â€” å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ Hub ä¸Šæ‰˜ç®¡çš„*æ¨¡å‹ id*ï¼ˆä¾‹å¦‚`google/ddpm-celebahq-256`ï¼‰ã€‚

    +   ä¸€ä¸ª*ç›®å½•*è·¯å¾„ï¼ˆä¾‹å¦‚`./my_model_directory`ï¼‰ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨ save_pretrained()ä¿å­˜çš„æ¨¡å‹æƒé‡ã€‚

+   `cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” å¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ï¼Œåˆ™ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®å°†è¢«ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ã€‚

+   `torch_dtype` (`str` æˆ– `torch.dtype`, *å¯é€‰*) â€” è¦†ç›–é»˜è®¤çš„ `torch.dtype` å¹¶ä½¿ç”¨å¦ä¸€ç§ dtype åŠ è½½æ¨¡å‹ã€‚å¦‚æœä¼ é€’ `"auto"`ï¼Œdtype å°†è‡ªåŠ¨ä»æ¨¡å‹çš„æƒé‡ä¸­æ´¾ç”Ÿã€‚

+   `force_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚

+   `proxies` (`Dict[str, str]`, *å¯é€‰*) â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†å°†åœ¨æ¯ä¸ªè¯·æ±‚ä¸­ä½¿ç”¨ã€‚

+   `output_loading_info` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿˜è¿”å›ä¸€ä¸ªåŒ…å«ç¼ºå¤±é”®ã€æ„å¤–é”®å’Œé”™è¯¯æ¶ˆæ¯çš„å­—å…¸ã€‚

+   `local_files_only(bool,` *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™ä¸ä¼šä» Hub ä¸‹è½½æ¨¡å‹ã€‚

+   `token` (`str` æˆ– *bool*, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œåˆ™ä½¿ç”¨ä» `diffusers-cli login` ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚

+   `revision` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID æˆ– Git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

+   `from_flax` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” ä» Flax æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ã€‚

+   `subfolder` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `""`) â€” Hub æˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­æ¨¡å‹æ–‡ä»¶çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚

+   `mirror` (`str`, *å¯é€‰*) â€” é•œåƒæºä»¥è§£å†³åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶çš„å¯è®¿é—®æ€§é—®é¢˜ã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚

+   `device_map` (`str` æˆ– `Dict[str, Union[int, str, torch.device]]`, *å¯é€‰*) â€” ä¸€ä¸ªæŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥æ”¾åœ¨å“ªé‡Œçš„æ˜ å°„ã€‚ä¸éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°å®šä¹‰ï¼›ä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…éƒ¨ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚

    è®¾ç½® `device_map="auto"` ä»¥ä½¿ ğŸ¤— Accelerate è‡ªåŠ¨è®¡ç®—æœ€ä¼˜åŒ–çš„ `device_map`ã€‚æœ‰å…³æ¯ä¸ªé€‰é¡¹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[è®¾è®¡è®¾å¤‡æ˜ å°„](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)ã€‚

+   `max_memory` (`Dict`, *å¯é€‰*) â€” ç”¨äºæœ€å¤§å†…å­˜çš„è®¾å¤‡æ ‡è¯†ç¬¦å­—å…¸ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºæ¯ä¸ª GPU å’Œå¯ç”¨ CPU RAM çš„æœ€å¤§å†…å­˜ã€‚

+   `offload_folder` (`str` æˆ– `os.PathLike`, *å¯é€‰*) â€” å¦‚æœ `device_map` åŒ…å«å€¼ `"disk"`ï¼Œåˆ™æ˜¯å¸è½½æƒé‡çš„è·¯å¾„ã€‚

+   `offload_state_dict` (`bool`, *å¯é€‰*) â€” å¦‚æœä¸º `True`ï¼Œåˆ™ä¸´æ—¶å°† CPU çŠ¶æ€å­—å…¸è½¬ç§»åˆ°ç¡¬ç›˜ä»¥é¿å… CPU RAM ä¸è¶³ï¼Œå¦‚æœ CPU çŠ¶æ€å­—å…¸çš„é‡é‡ + æ£€æŸ¥ç‚¹çš„æœ€å¤§åˆ†ç‰‡çš„é‡é‡ä¸é€‚åˆã€‚å½“å­˜åœ¨ä¸€äº›ç£ç›˜å¸è½½æ—¶ï¼Œé»˜è®¤ä¸º `True`ã€‚

+   `low_cpu_mem_usage` (`bool`, *å¯é€‰*, å¦‚æœ torch ç‰ˆæœ¬ >= 1.9.0 åˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`) â€” åŠ é€Ÿæ¨¡å‹åŠ è½½ï¼Œä»…åŠ è½½é¢„è®­ç»ƒæƒé‡è€Œä¸åˆå§‹åŒ–æƒé‡ã€‚åœ¨åŠ è½½æ¨¡å‹æ—¶ï¼Œè¿˜å°è¯•ä¸ä½¿ç”¨è¶…è¿‡ CPU å†…å­˜ä¸­çš„ 1x æ¨¡å‹å¤§å°ï¼ˆåŒ…æ‹¬å³°å€¼å†…å­˜ï¼‰ã€‚ä»…æ”¯æŒ PyTorch >= 1.9.0ã€‚å¦‚æœæ‚¨ä½¿ç”¨è¾ƒæ—§ç‰ˆæœ¬çš„ PyTorchï¼Œå°†æ­¤å‚æ•°è®¾ç½®ä¸º `True` å°†å¼•å‘é”™è¯¯ã€‚

+   `variant` (`str`, *å¯é€‰*) â€” ä»æŒ‡å®šçš„ `variant` æ–‡ä»¶ååŠ è½½æƒé‡ï¼Œä¾‹å¦‚ `"fp16"` æˆ– `"ema"`ã€‚åœ¨åŠ è½½ `from_flax` æ—¶ä¼šè¢«å¿½ç•¥ã€‚

+   `use_safetensors` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `None`) â€” å¦‚æœè®¾ç½®ä¸º `None`ï¼Œåˆ™ä¼šä¸‹è½½ `safetensors` æƒé‡ï¼ˆå¦‚æœå¯ç”¨ä¸”å·²å®‰è£… `safetensors` åº“ï¼‰ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™ä¼šå¼ºåˆ¶ä» `safetensors` æƒé‡åŠ è½½æ¨¡å‹ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œåˆ™ä¸ä¼šåŠ è½½ `safetensors` æƒé‡ã€‚

ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–é¢„è®­ç»ƒçš„ PyTorch æ¨¡å‹ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼ - `model.eval()` - å¹¶ä¸”å…³é—­äº† dropout æ¨¡å—ã€‚è¦è®­ç»ƒæ¨¡å‹ï¼Œè¯·ä½¿ç”¨ `model.train()` å°†å…¶è®¾ç½®å›è®­ç»ƒæ¨¡å¼ã€‚

è¦ä½¿ç”¨ç§æœ‰æˆ–[é—¨æ§æ¨¡å‹](https://huggingface.co/docs/hub/models-gated#gated-models)ï¼Œè¯·ä½¿ç”¨ `huggingface-cli login` ç™»å½•ã€‚æ‚¨è¿˜å¯ä»¥æ¿€æ´»ç‰¹æ®Šçš„[â€œç¦»çº¿æ¨¡å¼â€](https://huggingface.co/diffusers/installation.html#offline-mode)ä»¥åœ¨å—é˜²ç«å¢™ä¿æŠ¤çš„ç¯å¢ƒä¸­ä½¿ç”¨æ­¤æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
from diffusers import UNet2DConditionModel

unet = UNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="unet")
```

å¦‚æœæ‚¨æ”¶åˆ°ä¸‹é¢çš„é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™éœ€è¦ä¸ºä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæƒé‡ï¼š

```py
Some weights of UNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:
- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 9, 3, 3]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

#### `num_parameters`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L893)

```py
( only_trainable: bool = False exclude_embeddings: bool = False ) â†’ export const metadata = 'undefined';int
```

å‚æ•°

+   `only_trainable` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…è¿”å›å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚

+   `exclude_embeddings` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…è¿”å›éåµŒå…¥å‚æ•°çš„æ•°é‡ã€‚

è¿”å›

`int`

å‚æ•°æ•°é‡ã€‚

è·å–æ¨¡å—ä¸­ï¼ˆå¯è®­ç»ƒæˆ–éåµŒå…¥ï¼‰å‚æ•°çš„æ•°é‡ã€‚

ç¤ºä¾‹ï¼š

```py
from diffusers import UNet2DConditionModel

model_id = "runwayml/stable-diffusion-v1-5"
unet = UNet2DConditionModel.from_pretrained(model_id, subfolder="unet")
unet.num_parameters(only_trainable=True)
859520964
```

#### `save_pretrained`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L305)

```py
( save_directory: Union is_main_process: bool = True save_function: Optional = None safe_serialization: bool = True variant: Optional = None push_to_hub: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†ä¼šåˆ›å»ºã€‚

+   `is_main_process` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½® `is_main_process=True` ä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚

+   `save_function` (`Callable`) â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢ `torch.save` æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡ `DIFFUSERS_SAVE_MODE` è¿›è¡Œé…ç½®ã€‚

+   `safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors` æˆ–ä¼ ç»Ÿçš„ PyTorch æ–¹æ³•ä¸ `pickle` ä¿å­˜æ¨¡å‹ã€‚

+   `variant` (`str`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥ `pytorch_model.<variant>.bin` æ ¼å¼ä¿å­˜ã€‚

+   `push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ° Hugging Face Hubã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained() ç±»æ–¹æ³•é‡æ–°åŠ è½½å®ƒã€‚

## FlaxModelMixin

### `class diffusers.FlaxModelMixin`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L50)

```py
( )
```

æ‰€æœ‰ Flax æ¨¡å‹çš„åŸºç±»ã€‚

FlaxModelMixin è´Ÿè´£å­˜å‚¨æ¨¡å‹é…ç½®ï¼Œå¹¶æä¾›åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚

+   `config_name` (`str`) â€” åœ¨è°ƒç”¨ save_pretrained() æ—¶ä¿å­˜æ¨¡å‹çš„æ–‡ä»¶åã€‚

#### `from_pretrained`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L203)

```py
( pretrained_model_name_or_path: Union dtype: dtype = <class 'jax.numpy.float32'> *model_args **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str` æˆ– `os.PathLike`) â€” å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ Hub ä¸Šæ‰˜ç®¡çš„*æ¨¡å‹ ID*ï¼ˆä¾‹å¦‚ `runwayml/stable-diffusion-v1-5`ï¼‰ã€‚

    +   æŒ‡å‘åŒ…å«ä½¿ç”¨ save_pretrained()ä¿å­˜çš„æ¨¡å‹æƒé‡çš„*ç›®å½•*çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `./my_model_directory`ï¼‰ã€‚

+   `dtype` (`jax.numpy.dtype`, *optional*, é»˜è®¤ä¸º `jax.numpy.float32`) â€” è®¡ç®—çš„æ•°æ®ç±»å‹ã€‚å¯ä»¥æ˜¯ `jax.numpy.float32`ã€`jax.numpy.float16`ï¼ˆåœ¨ GPU ä¸Šï¼‰å’Œ `jax.numpy.bfloat16`ï¼ˆåœ¨ TPU ä¸Šï¼‰ä¹‹ä¸€ã€‚

    è¿™å¯ç”¨äºåœ¨ GPU æˆ– TPU ä¸Šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒæˆ–åŠç²¾åº¦æ¨æ–­ã€‚å¦‚æœæŒ‡å®šï¼Œæ‰€æœ‰è®¡ç®—å°†ä½¿ç”¨ç»™å®šçš„ `dtype` æ‰§è¡Œã€‚

    è¿™ä»…æŒ‡å®š*è®¡ç®—*çš„æ•°æ®ç±»å‹ï¼Œä¸å½±å“æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ã€‚

    å¦‚æœè¦æ›´æ”¹æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ï¼Œè¯·å‚é˜… to_fp16()å’Œ to_bf16()ã€‚

+   `model_args`ï¼ˆä½ç½®å‚æ•°åºåˆ—ï¼Œ*optional*ï¼‰ â€” æ‰€æœ‰å‰©ä½™çš„ä½ç½®å‚æ•°éƒ½ä¼ é€’ç»™åŸºç¡€æ¨¡å‹çš„ `__init__` æ–¹æ³•ã€‚

+   `cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœæœªä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `force_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œåˆ™åˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚

+   `proxies` (`Dict[str, str]`, *optional*) â€” ç”¨äºæ¯ä¸ªè¯·æ±‚çš„åè®®æˆ–ç«¯ç‚¹çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†æœåŠ¡å™¨åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `local_files_only(bool,` *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™æ¨¡å‹ä¸ä¼šä» Hub ä¸‹è½½ã€‚

+   `revision` (`str`, *optional*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID æˆ– Git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

+   `from_pt` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” ä» PyTorch æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ã€‚

+   `kwargs`ï¼ˆå‰©ä½™çš„å…³é”®å­—å‚æ•°å­—å…¸ï¼Œ*optional*ï¼‰ â€” å¯ç”¨äºæ›´æ–°é…ç½®å¯¹è±¡ï¼ˆåŠ è½½åï¼‰å¹¶å¯åŠ¨æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ`output_attentions=True`ï¼‰ã€‚æ ¹æ®æ˜¯å¦æä¾›æˆ–è‡ªåŠ¨åŠ è½½äº† `config`ï¼Œè¡Œä¸ºä¸åŒã€‚

    +   å¦‚æœæä¾›äº† `config`ï¼Œåˆ™ `kwargs` ç›´æ¥ä¼ é€’ç»™åŸºç¡€æ¨¡å‹çš„ `__init__` æ–¹æ³•ï¼ˆæˆ‘ä»¬å‡è®¾é…ç½®çš„æ‰€æœ‰ç›¸å…³æ›´æ–°å·²ç»å®Œæˆï¼‰ã€‚

    +   å¦‚æœæœªæä¾›é…ç½®ï¼Œåˆ™é¦–å…ˆå°† `kwargs` ä¼ é€’ç»™é…ç½®ç±»åˆå§‹åŒ–å‡½æ•° from_config()ã€‚ä¸é…ç½®å±æ€§å¯¹åº”çš„ `kwargs` çš„æ¯ä¸ªé”®éƒ½ç”¨æä¾›çš„ `kwargs` å€¼è¦†ç›–è¯¥å±æ€§ã€‚ä¸å¯¹åº”ä»»ä½•é…ç½®å±æ€§çš„å‰©ä½™é”®å°†ä¼ é€’ç»™åŸºç¡€æ¨¡å‹çš„ `__init__` å‡½æ•°ã€‚

ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–é¢„è®­ç»ƒçš„ Flax æ¨¡å‹ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from diffusers import FlaxUNet2DConditionModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> # Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
>>> model, params = FlaxUNet2DConditionModel.from_pretrained("./test/saved_model/")
```

å¦‚æœæ‚¨æ”¶åˆ°ä¸‹é¢çš„é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™éœ€è¦ä¸ºæ‚¨çš„ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæƒé‡ï¼š

```py
Some weights of UNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:
- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 9, 3, 3]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

#### `save_pretrained`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L502)

```py
( save_directory: Union params: Union is_main_process: bool = True push_to_hub: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str`æˆ–`os.PathLike`) â€” è¦ä¿å­˜æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œå°†ä¼šåˆ›å»ºã€‚

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚

+   `is_main_process` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­éå¸¸æœ‰ç”¨ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®`is_main_process=True`ä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚

+   `push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨`repo_id`æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆé»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„`save_directory`åç§°ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ push_to_hub()æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained()ç±»æ–¹æ³•é‡æ–°åŠ è½½ã€‚

#### `to_bf16`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L95)

```py
( params: Union mask: Any = None )
```

å‚æ•°

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚

+   `mask` (`Union[Dict, FrozenDict]`) â€” ä¸€ä¸ªä¸`params`æ ‘ç»“æ„ç›¸åŒçš„`PyTree`ã€‚å¶å­èŠ‚ç‚¹åº”ä¸ºå¸ƒå°”å€¼ã€‚å¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º`True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º`False`ã€‚

å°†æµ®ç‚¹`params`è½¬æ¢ä¸º`jax.numpy.bfloat16`ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„`params`æ ‘ï¼Œä¸ä¼šç›´æ¥è½¬æ¢`params`ã€‚

è¿™ç§æ–¹æ³•å¯ä»¥åœ¨ TPU ä¸Šä½¿ç”¨ï¼Œæ˜¾å¼åœ°å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º bfloat16 ç²¾åº¦ï¼Œä»¥è¿›è¡Œå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒæˆ–è€…ä¿å­˜æƒé‡ä¸º bfloat16 ä»¥èŠ‚çœå†…å­˜å¹¶æé«˜é€Ÿåº¦ã€‚

ç¤ºä¾‹:

```py
>>> from diffusers import FlaxUNet2DConditionModel

>>> # load model
>>> model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> # By default, the model parameters will be in fp32 precision, to cast these to bfloat16 precision
>>> params = model.to_bf16(params)
>>> # If you don't want to cast certain parameters (for example layer norm bias and scale)
>>> # then pass the mask as follows
>>> from flax import traverse_util

>>> model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> flat_params = traverse_util.flatten_dict(params)
>>> mask = {
...     path: (path[-2] != ("LayerNorm", "bias") and path[-2:] != ("LayerNorm", "scale"))
...     for path in flat_params
... }
>>> mask = traverse_util.unflatten_dict(mask)
>>> params = model.to_bf16(params, mask)
```

#### `to_fp16`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L161)

```py
( params: Union mask: Any = None )
```

å‚æ•°

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚

+   `mask` (`Union[Dict, FrozenDict]`) â€” ä¸€ä¸ªä¸`params`æ ‘ç»“æ„ç›¸åŒçš„`PyTree`ã€‚å¶å­èŠ‚ç‚¹åº”ä¸ºå¸ƒå°”å€¼ã€‚å¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º`True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º`False`ã€‚

å°†æµ®ç‚¹`params`è½¬æ¢ä¸º`jax.numpy.float16`ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„`params`æ ‘ï¼Œä¸ä¼šç›´æ¥è½¬æ¢`params`ã€‚

è¿™ç§æ–¹æ³•å¯ä»¥åœ¨ GPU ä¸Šä½¿ç”¨ï¼Œæ˜¾å¼åœ°å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º float16 ç²¾åº¦ï¼Œä»¥è¿›è¡Œå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒæˆ–è€…ä¿å­˜æƒé‡ä¸º float16 ä»¥èŠ‚çœå†…å­˜å¹¶æé«˜é€Ÿåº¦ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from diffusers import FlaxUNet2DConditionModel

>>> # load model
>>> model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> # By default, the model params will be in fp32, to cast these to float16
>>> params = model.to_fp16(params)
>>> # If you want don't want to cast certain parameters (for example layer norm bias and scale)
>>> # then pass the mask as follows
>>> from flax import traverse_util

>>> model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> flat_params = traverse_util.flatten_dict(params)
>>> mask = {
...     path: (path[-2] != ("LayerNorm", "bias") and path[-2:] != ("LayerNorm", "scale"))
...     for path in flat_params
... }
>>> mask = traverse_util.unflatten_dict(mask)
>>> params = model.to_fp16(params, mask)
```

#### `to_fp32`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L134)

```py
( params: Union mask: Any = None )
```

å‚æ•°

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚

+   `mask` (`Union[Dict, FrozenDict]`) â€” ä¸€ä¸ªä¸`params`æ ‘ç»“æ„ç›¸åŒçš„`PyTree`ã€‚å¶å­èŠ‚ç‚¹åº”ä¸ºå¸ƒå°”å€¼ã€‚å¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º`True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º`False`ã€‚

å°†æµ®ç‚¹`params`è½¬æ¢ä¸º`jax.numpy.float32`ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ç”¨äºæ˜¾å¼åœ°å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º fp32 ç²¾åº¦ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„`params`æ ‘ï¼Œä¸ä¼šç›´æ¥è½¬æ¢`params`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from diffusers import FlaxUNet2DConditionModel

>>> # Download model and configuration from huggingface.co
>>> model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> # By default, the model params will be in fp32, to illustrate the use of this method,
>>> # we'll first cast to fp16 and back to fp32
>>> params = model.to_f16(params)
>>> # now cast back to fp32
>>> params = model.to_fp32(params)
```

## PushToHubMixin

### `class diffusers.utils.PushToHubMixin`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)

```py
( )
```

å°†æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–æµæ°´çº¿æ¨é€åˆ° Hugging Face Hub çš„ Mixinã€‚

`push_to_hub`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)

```py
( repo_id: str commit_message: Optional = None private: Optional = None token: Optional = None create_pr: bool = False safe_serialization: bool = True variant: Optional = None )
```

å‚æ•°

+   `repo_id` (`str`) â€” æ‚¨è¦æ¨é€æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–æµæ°´çº¿æ–‡ä»¶çš„å­˜å‚¨åº“åç§°ã€‚åœ¨æ¨é€åˆ°ç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚`repo_id`ä¹Ÿå¯ä»¥æ˜¯æœ¬åœ°ç›®å½•çš„è·¯å¾„ã€‚

+   `commit_message` (`str`, *optional*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º`"Upload {object}"`ã€‚

+   `private` (`bool`, *optional*) â€” æ˜¯å¦åº”å°†åˆ›å»ºçš„å­˜å‚¨åº“è®¾ç½®ä¸ºç§æœ‰ã€‚

+   `token` (`str`, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚åœ¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚

+   `create_pr` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º`safetensors`æ ¼å¼ã€‚

+   `variant` (`str`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥`pytorch_model.<variant>.bin`æ ¼å¼ä¿å­˜ã€‚

å°†æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–æµæ°´çº¿æ–‡ä»¶ä¸Šä¼ åˆ°ğŸ¤— Hugging Face Hubã€‚

ç¤ºä¾‹ï¼š

```py
from diffusers import UNet2DConditionModel

unet = UNet2DConditionModel.from_pretrained("stabilityai/stable-diffusion-2", subfolder="unet")

# Push the `unet` to your namespace with the name "my-finetuned-unet".
unet.push_to_hub("my-finetuned-unet")

# Push the `unet` to an organization with the name "my-finetuned-unet".
unet.push_to_hub("your-org/my-finetuned-unet")
```
