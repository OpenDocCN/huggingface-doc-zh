# DDIMInverseScheduler

> 原始文本：[`huggingface.co/docs/diffusers/api/schedulers/ddim_inverse`](https://huggingface.co/docs/diffusers/api/schedulers/ddim_inverse)

`DDIMInverseScheduler`是由 Jiaming Song、Chenlin Meng 和 Stefano Ermon 提出的[Denoising Diffusion Implicit Models](https://huggingface.co/papers/2010.02502)（DDIM）的反转调度器。该实现主要基于来自[Null-text Inversion for Editing Real Images using Guided Diffusion Models](https://huggingface.co/papers/2211.09794)的 DDIM 反转定义。

## DDIMInverseScheduler

### `class diffusers.DDIMInverseScheduler`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddim_inverse.py#L130)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Union = None clip_sample: bool = True set_alpha_to_one: bool = True steps_offset: int = 0 prediction_type: str = 'epsilon' clip_sample_range: float = 1.0 timestep_spacing: str = 'leading' rescale_betas_zero_snr: bool = False **kwargs )
```

参数

+   `num_train_timesteps` (`int`, 默认为 1000) — 训练模型的扩散步数。

+   `beta_start` (`float`, 默认为 0.0001) — 推断的起始`beta`值。

+   `beta_end` (`float`, 默认为 0.02) — 最终的`beta`值。

+   `beta_schedule` (`str`, 默认为`"linear"`) — beta 调度，从 beta 范围映射到用于模型步进的一系列 beta。可选择`linear`、`scaled_linear`或`squaredcos_cap_v2`。

+   `trained_betas` (`np.ndarray`, *可选*) — 直接传递一个 beta 数组给构造函数，以绕过`beta_start`和`beta_end`。

+   `clip_sample` (`bool`, 默认为`True`) — 为了数值稳定性而裁剪预测样本。

+   `clip_sample_range` (`float`, 默认为 1.0) — 样本裁剪的最大幅度。仅在`clip_sample=True`时有效。

+   `set_alpha_to_one` (`bool`, 默认为`True`) — 每个扩散步骤使用该步骤和前一个步骤的 alpha 乘积值。对于最后一步，没有前一个 alpha。当此选项为`True`时，前一个 alpha 乘积固定为 0，否则使用步骤`num_train_timesteps - 1`处的 alpha 值。

+   `steps_offset` (`int`, 默认为 0) — 添加到推断步骤的偏移量。您可以使用`offset=1`和`set_alpha_to_one=False`的组合，使最后一步使用`num_train_timesteps - 1`作为前一个 alpha 乘积。

+   `prediction_type` (`str`, 默认为`epsilon`, *可选*) — 调度函数的预测类型；可以是`epsilon`（预测扩散过程的噪声）、`sample`（直接预测有噪声的样本）或`v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文的第 2.4 节）。

+   `timestep_spacing` (`str`, 默认为`"leading"`) — 时间步长应该如何缩放。更多信息请参考[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表 2。

+   `rescale_betas_zero_snr` (`bool`, 默认为`False`) — 是否将 beta 重新缩放为零终端信噪比。这使模型能够生成非常明亮和非常暗的样本，而不是限制在中等亮度的样本。与[`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506) loosely 相关。

`DDIMInverseScheduler`是 DDIMScheduler 的反向调度器。

该模型继承自 SchedulerMixin 和 ConfigMixin。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddim_inverse.py#L236)

```py
( sample: FloatTensor timestep: Optional = None ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

+   `timestep` (`int`, *可选*) — 扩散链中的当前时间步。

返回

`torch.FloatTensor`

一个经过缩放的输入样本。

确保与需要根据当前时间步长调整去噪模型输入的调度器可互换。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddim_inverse.py#L253)

```py
( num_inference_steps: int device: Union = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步骤数。

设置用于扩散链的离散时间步长（在推理之前运行）。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddim_inverse.py#L291)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';~schedulers.scheduling_ddim_inverse.DDIMInverseSchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`float`) — 扩散链中的当前离散时间步长。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的当前样本实例。

+   `eta` (`float`) — 添加噪声在扩散步骤中的噪声权重。

+   `use_clipped_model_output` (`bool`，默认为`False`) — 如果为`True`，则从剪切预测的原始样本计算“校正的”`model_output`。当`self.config.clip_sample`为`True`时，必要，因为预测的原始样本被剪切为[-1, 1]。如果没有发生剪切，“校正的”`model_output`将与提供的输入一致，`use_clipped_model_output`不起作用。

+   `variance_noise` (`torch.FloatTensor`) — 通过直接提供方差本身的噪声，替代使用`generator`生成噪声。对于`CycleDiffusion`等方法非常有用。

+   `return_dict` (`bool`，*可选*，默认为`True`) — 是否返回`~schedulers.scheduling_ddim_inverse.DDIMInverseSchedulerOutput`或`tuple`。

返回

`~schedulers.scheduling_ddim_inverse.DDIMInverseSchedulerOutput`或`tuple`

如果`return_dict`为`True`，则返回`~schedulers.scheduling_ddim_inverse.DDIMInverseSchedulerOutput`，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 从上一个时间步预测样本。此函数从学习模型输出（通常是预测的噪声）传播扩散过程。
