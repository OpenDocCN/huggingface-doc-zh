# Shap-E

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/diffusers/using-diffusers/shap-e`](https://huggingface.co/docs/diffusers/using-diffusers/shap-e)

Shap-E æ˜¯ç”¨äºç”Ÿæˆ 3D èµ„äº§çš„æ¡ä»¶æ¨¡å‹ï¼Œå¯ç”¨äºè§†é¢‘æ¸¸æˆå¼€å‘ã€å®¤å†…è®¾è®¡å’Œå»ºç­‘ã€‚å®ƒåœ¨å¤§é‡ 3D èµ„äº§æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶è¿›è¡Œåå¤„ç†ä»¥æ¸²æŸ“æ¯ä¸ªå¯¹è±¡çš„æ›´å¤šè§†å›¾ï¼Œå¹¶ç”Ÿæˆ 16K è€Œä¸æ˜¯ 4K ç‚¹äº‘ã€‚Shap-E æ¨¡å‹ç»è¿‡ä¸¤æ­¥è®­ç»ƒï¼š

1.  ç¼–ç å™¨æ¥å—ç‚¹äº‘å’Œæ¸²æŸ“è§†å›¾çš„ 3D èµ„äº§ï¼Œå¹¶è¾“å‡ºè¡¨ç¤ºèµ„äº§çš„éšå¼å‡½æ•°çš„å‚æ•°

1.  æ‰©æ•£æ¨¡å‹åœ¨ç¼–ç å™¨äº§ç”Ÿçš„æ½œåœ¨å˜é‡ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥ç”Ÿæˆç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰æˆ–å¸¦çº¹ç†çš„ 3D ç½‘æ ¼ï¼Œä½¿å¾—æ›´å®¹æ˜“åœ¨ä¸‹æ¸¸åº”ç”¨ä¸­æ¸²æŸ“å’Œä½¿ç”¨ 3D èµ„äº§

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Shap-E å¼€å§‹ç”Ÿæˆæ‚¨è‡ªå·±çš„ 3D èµ„äº§ï¼

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š

```py
# uncomment to install the necessary libraries in Colab
#!pip install -q diffusers transformers accelerate trimesh
```

## æ–‡æœ¬åˆ° 3D

è¦ç”Ÿæˆ 3D å¯¹è±¡çš„ gifï¼Œè¯·å°†æ–‡æœ¬æç¤ºä¼ é€’ç»™ ShapEPipelineã€‚è¯¥ç®¡é“ç”Ÿæˆä¸€ç³»åˆ—å›¾åƒå¸§ï¼Œç”¨äºåˆ›å»º 3D å¯¹è±¡ã€‚

```py
import torch
from diffusers import ShapEPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16, variant="fp16")
pipe = pipe.to(device)

guidance_scale = 15.0
prompt = ["A firecracker", "A birthday cupcake"]

images = pipe(
    prompt,
    guidance_scale=guidance_scale,
    num_inference_steps=64,
    frame_size=256,
).images
```

ç°åœ¨ä½¿ç”¨ export_to_gif()å‡½æ•°å°†å›¾åƒå¸§åˆ—è¡¨è½¬æ¢ä¸º 3D å¯¹è±¡çš„ gifã€‚

```py
from diffusers.utils import export_to_gif

export_to_gif(images[0], "firecracker_3d.gif")
export_to_gif(images[1], "cake_3d.gif")
```

![](img/1731548e3bafd24f5633f1aa2dbba775.png)

æç¤º = "ä¸€ä¸ªé­ç‚®"

![](img/0e99b86ebe2171b5eec061e465ece01d.png)

æç¤º = "ä¸€ä¸ªç”Ÿæ—¥æ¯å­"

## å›¾åƒåˆ° 3D

ä»å¦ä¸€å¹…å›¾åƒç”Ÿæˆ 3D å¯¹è±¡ï¼Œè¯·ä½¿ç”¨ ShapEImg2ImgPipelineã€‚æ‚¨å¯ä»¥ä½¿ç”¨ç°æœ‰å›¾åƒæˆ–ç”Ÿæˆå…¨æ–°çš„å›¾åƒã€‚è®©æˆ‘ä»¬ä½¿ç”¨ Kandinsky 2.1 æ¨¡å‹æ¥ç”Ÿæˆä¸€ä¸ªæ–°å›¾åƒã€‚

```py
from diffusers import DiffusionPipeline
import torch

prior_pipeline = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipeline = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16, use_safetensors=True).to("cuda")

prompt = "A cheeseburger, white background"

image_embeds, negative_image_embeds = prior_pipeline(prompt, guidance_scale=1.0).to_tuple()
image = pipeline(
    prompt,
    image_embeds=image_embeds,
    negative_image_embeds=negative_image_embeds,
).images[0]

image.save("burger.png")
```

å°†å¥¶é…ªæ±‰å ¡ä¼ é€’ç»™ ShapEImg2ImgPipeline ä»¥ç”Ÿæˆå…¶çš„ 3D è¡¨ç¤ºã€‚

```py
from PIL import Image
from diffusers import ShapEImg2ImgPipeline
from diffusers.utils import export_to_gif

pipe = ShapEImg2ImgPipeline.from_pretrained("openai/shap-e-img2img", torch_dtype=torch.float16, variant="fp16").to("cuda")

guidance_scale = 3.0
image = Image.open("burger.png").resize((256, 256))

images = pipe(
    image,
    guidance_scale=guidance_scale,
    num_inference_steps=64,
    frame_size=256,
).images

gif_path = export_to_gif(images[0], "burger_3d.gif")
```

![](img/3bd8f6cd764240ee2dfdbf3d1d82155f.png)

å¥¶é…ªæ±‰å ¡åŒ…

![](img/13d040413cdeea82e213c9a300bb2e18.png)

3D å¥¶é…ªæ±‰å ¡åŒ…

## ç”Ÿæˆç½‘æ ¼

Shap-E æ˜¯ä¸€ä¸ªçµæ´»çš„æ¨¡å‹ï¼Œè¿˜å¯ä»¥ç”Ÿæˆçº¹ç†ç½‘æ ¼è¾“å‡ºä»¥ä¾›ä¸‹æ¸¸åº”ç”¨æ¸²æŸ“ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ‚¨å°†å°†è¾“å‡ºè½¬æ¢ä¸º`glb`æ–‡ä»¶ï¼Œå› ä¸ºğŸ¤—æ•°æ®é›†åº“æ”¯æŒ`glb`æ–‡ä»¶çš„ç½‘æ ¼å¯è§†åŒ–ï¼Œå¯ä»¥ç”±[æ•°æ®é›†æŸ¥çœ‹å™¨](https://huggingface.co/docs/hub/datasets-viewer#dataset-preview)æ¸²æŸ“ã€‚

æ‚¨å¯ä»¥é€šè¿‡å°†`output_type`å‚æ•°æŒ‡å®šä¸º`"mesh"`æ¥ä¸º ShapEPipeline å’Œ ShapEImg2ImgPipeline ç”Ÿæˆç½‘æ ¼è¾“å‡ºï¼š

```py
import torch
from diffusers import ShapEPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16, variant="fp16")
pipe = pipe.to(device)

guidance_scale = 15.0
prompt = "A birthday cupcake"

images = pipe(prompt, guidance_scale=guidance_scale, num_inference_steps=64, frame_size=256, output_type="mesh").images
```

ä½¿ç”¨`export_to_ply()`å‡½æ•°å°†ç½‘æ ¼è¾“å‡ºä¿å­˜ä¸º`ply`æ–‡ä»¶ï¼š

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨`export_to_obj()`å‡½æ•°å°†ç½‘æ ¼è¾“å‡ºä¿å­˜ä¸º`obj`æ–‡ä»¶ã€‚å°†ç½‘æ ¼è¾“å‡ºä¿å­˜ä¸ºå„ç§æ ¼å¼çš„èƒ½åŠ›ä½¿å…¶åœ¨ä¸‹æ¸¸ç”¨é€”ä¸­æ›´åŠ çµæ´»ï¼

```py
from diffusers.utils import export_to_ply

ply_path = export_to_ply(images[0], "3d_cake.ply")
print(f"Saved to folder: {ply_path}")
```

ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ trimesh åº“å°†`ply`æ–‡ä»¶è½¬æ¢ä¸º`glb`æ–‡ä»¶ï¼š

```py
import trimesh

mesh = trimesh.load("3d_cake.ply")
mesh_export = mesh.export("3d_cake.glb", file_type="glb")
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œç½‘æ ¼è¾“å‡ºæ˜¯ä»åº•éƒ¨è§†è§’èšç„¦çš„ï¼Œä½†æ‚¨å¯ä»¥é€šè¿‡åº”ç”¨æ—‹è½¬å˜æ¢æ¥æ›´æ”¹é»˜è®¤è§†è§’ï¼š

```py
import trimesh
import numpy as np

mesh = trimesh.load("3d_cake.ply")
rot = trimesh.transformations.rotation_matrix(-np.pi / 2, [1, 0, 0])
mesh = mesh.apply_transform(rot)
mesh_export = mesh.export("3d_cake.glb", file_type="glb")
```

å°†ç½‘æ ¼æ–‡ä»¶ä¸Šä¼ åˆ°æ•°æ®é›†å­˜å‚¨åº“ä»¥ä½¿ç”¨æ•°æ®é›†æŸ¥çœ‹å™¨è¿›è¡Œå¯è§†åŒ–ï¼

![](img/0289665c1f710f01cb60d1ad8a76f38c.png)
