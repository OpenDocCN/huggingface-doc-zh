# DeepFloyd IF

> 原始文本：[`huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if`](https://huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if)

## 概述

DeepFloyd IF 是一种新颖的最先进的开源文本到图像模型，具有高度的逼真度和语言理解能力。该模型是一个模块化的，由一个冻结的文本编码器和三个级联的像素扩散模块组成：

+   阶段 1：基于文本提示生成 64x64 像素图像的基础模型，

+   阶段 2：一个 64x64 像素=>256x256 像素超分辨率模型，

+   阶段 3：一个 256x256 像素=>1024x1024 像素超分辨率模型。阶段 1 和阶段 2 利用基于 T5 变压器的冻结文本编码器来提取文本嵌入，然后将其馈送到增强了交叉注意力和注意力池化的 UNet 架构中。阶段 3 是[Stability AI 的 x4 放大模型](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler)。结果是一个高效的模型，优于当前最先进的模型，实现了在 COCO 数据集上的零样本 FID 分数为 6.66。我们的工作强调了级联扩散模型中更大的 UNet 架构在第一阶段的潜力，并描绘了文本到图像合成的光明未来。

## 用法

在使用 IF 之前，您需要接受其使用条件。要这样做：

1.  确保拥有[Hugging Face 账户](https://huggingface.co/join)并已登录。

1.  在[DeepFloyd/IF-I-XL-v1.0](https://huggingface.co/DeepFloyd/IF-I-XL-v1.0)模型卡上接受许可。在阶段 I 模型卡上接受许可将自动接受其他 IF 模型的许可。

1.  确保在本地登录。安装`huggingface_hub`：

```py
pip install huggingface_hub --upgrade
```

在 Python shell 中运行登录函数：

```py
from huggingface_hub import login

login()
```

并输入您的[Hugging Face Hub 访问令牌](https://huggingface.co/docs/hub/security-tokens#what-are-user-access-tokens)。

接下来安装`diffusers`和依赖项：

```py
pip install -q diffusers accelerate transformers
```

以下部分提供了更详细的 IF 使用示例。具体来说：

+   文本到图像生成

+   图像到图像生成

+   修复

+   重用模型权重

+   速度优化

+   内存优化

**可用的检查点**

+   *阶段-1*

    +   [DeepFloyd/IF-I-XL-v1.0](https://huggingface.co/DeepFloyd/IF-I-XL-v1.0)

    +   [DeepFloyd/IF-I-L-v1.0](https://huggingface.co/DeepFloyd/IF-I-L-v1.0)

    +   [DeepFloyd/IF-I-M-v1.0](https://huggingface.co/DeepFloyd/IF-I-M-v1.0)

+   *阶段-2*

    +   [DeepFloyd/IF-II-L-v1.0](https://huggingface.co/DeepFloyd/IF-II-L-v1.0)

    +   [DeepFloyd/IF-II-M-v1.0](https://huggingface.co/DeepFloyd/IF-II-M-v1.0)

+   *阶段-3*

    +   [stabilityai/stable-diffusion-x4-upscaler](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler)

**Google Colab** ![在 Colab 中打开](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/deepfloyd_if_free_tier_google_colab.ipynb)

### 文本到图像生成

默认情况下，diffusers 利用 model cpu offloading 来运行整个 IF 管道，只需 14GB 的 VRAM。

```py
from diffusers import DiffusionPipeline
from diffusers.utils import pt_to_pil, make_image_grid
import torch

# stage 1
stage_1 = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
stage_1.enable_model_cpu_offload()

# stage 2
stage_2 = DiffusionPipeline.from_pretrained(
    "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
)
stage_2.enable_model_cpu_offload()

# stage 3
safety_modules = {
    "feature_extractor": stage_1.feature_extractor,
    "safety_checker": stage_1.safety_checker,
    "watermarker": stage_1.watermarker,
}
stage_3 = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-x4-upscaler", **safety_modules, torch_dtype=torch.float16
)
stage_3.enable_model_cpu_offload()

prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says "very deep learning"'
generator = torch.manual_seed(1)

# text embeds
prompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)

# stage 1
stage_1_output = stage_1(
    prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, generator=generator, output_type="pt"
).images
#pt_to_pil(stage_1_output)[0].save("./if_stage_I.png")

# stage 2
stage_2_output = stage_2(
    image=stage_1_output,
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    generator=generator,
    output_type="pt",
).images
#pt_to_pil(stage_2_output)[0].save("./if_stage_II.png")

# stage 3
stage_3_output = stage_3(prompt=prompt, image=stage_2_output, noise_level=100, generator=generator).images
#stage_3_output[0].save("./if_stage_III.png")
make_image_grid([pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0], stage_3_output[0]], rows=1, rows=3)
```

### 文本引导的图像到图像生成

相同的 IF 模型权重可以用于文本引导的图像到图像翻译或图像变化。在这种情况下，请确保使用 IFImg2ImgPipeline 和 IFImg2ImgSuperResolutionPipeline 管道加载权重。

**注意**：您还可以通过使用 components 参数直接将文本到图像管道的权重移动到图像到图像管道，而无需加载两次，如此处所述。

```py
from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline
from diffusers.utils import pt_to_pil, load_image, make_image_grid
import torch

# download image
url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
original_image = load_image(url)
original_image = original_image.resize((768, 512))

# stage 1
stage_1 = IFImg2ImgPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
stage_1.enable_model_cpu_offload()

# stage 2
stage_2 = IFImg2ImgSuperResolutionPipeline.from_pretrained(
    "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
)
stage_2.enable_model_cpu_offload()

# stage 3
safety_modules = {
    "feature_extractor": stage_1.feature_extractor,
    "safety_checker": stage_1.safety_checker,
    "watermarker": stage_1.watermarker,
}
stage_3 = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-x4-upscaler", **safety_modules, torch_dtype=torch.float16
)
stage_3.enable_model_cpu_offload()

prompt = "A fantasy landscape in style minecraft"
generator = torch.manual_seed(1)

# text embeds
prompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)

# stage 1
stage_1_output = stage_1(
    image=original_image,
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    generator=generator,
    output_type="pt",
).images
#pt_to_pil(stage_1_output)[0].save("./if_stage_I.png")

# stage 2
stage_2_output = stage_2(
    image=stage_1_output,
    original_image=original_image,
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    generator=generator,
    output_type="pt",
).images
#pt_to_pil(stage_2_output)[0].save("./if_stage_II.png")

# stage 3
stage_3_output = stage_3(prompt=prompt, image=stage_2_output, generator=generator, noise_level=100).images
#stage_3_output[0].save("./if_stage_III.png")
make_image_grid([original_image, pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0], stage_3_output[0]], rows=1, rows=4)
```

### 文本引导修补生成

相同的 IF 模型权重可用于文本引导的图像到图像翻译或图像变化。在这种情况下，请确保使用 IFInpaintingPipeline 和 IFInpaintingSuperResolutionPipeline 管道加载权重。

**注意**：您还可以通过使用`~DiffusionPipeline.components()`函数将文本到图像管道的权重直接移至图像到图像管道，而无需加载两次，具体方法请参见此处。

```py
from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline
from diffusers.utils import pt_to_pil, load_image, make_image_grid
import torch

# download image
url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png"
original_image = load_image(url)

# download mask
url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png"
mask_image = load_image(url)

# stage 1
stage_1 = IFInpaintingPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
stage_1.enable_model_cpu_offload()

# stage 2
stage_2 = IFInpaintingSuperResolutionPipeline.from_pretrained(
    "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
)
stage_2.enable_model_cpu_offload()

# stage 3
safety_modules = {
    "feature_extractor": stage_1.feature_extractor,
    "safety_checker": stage_1.safety_checker,
    "watermarker": stage_1.watermarker,
}
stage_3 = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-x4-upscaler", **safety_modules, torch_dtype=torch.float16
)
stage_3.enable_model_cpu_offload()

prompt = "blue sunglasses"
generator = torch.manual_seed(1)

# text embeds
prompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)

# stage 1
stage_1_output = stage_1(
    image=original_image,
    mask_image=mask_image,
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    generator=generator,
    output_type="pt",
).images
#pt_to_pil(stage_1_output)[0].save("./if_stage_I.png")

# stage 2
stage_2_output = stage_2(
    image=stage_1_output,
    original_image=original_image,
    mask_image=mask_image,
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    generator=generator,
    output_type="pt",
).images
#pt_to_pil(stage_1_output)[0].save("./if_stage_II.png")

# stage 3
stage_3_output = stage_3(prompt=prompt, image=stage_2_output, generator=generator, noise_level=100).images
#stage_3_output[0].save("./if_stage_III.png")
make_image_grid([original_image, mask_image, pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0], stage_3_output[0]], rows=1, rows=5)
```

### 在不同管道之间转换

除了使用`from_pretrained`加载外，管道还可以直接从彼此加载。

```py
from diffusers import IFPipeline, IFSuperResolutionPipeline

pipe_1 = IFPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0")
pipe_2 = IFSuperResolutionPipeline.from_pretrained("DeepFloyd/IF-II-L-v1.0")

from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline

pipe_1 = IFImg2ImgPipeline(**pipe_1.components)
pipe_2 = IFImg2ImgSuperResolutionPipeline(**pipe_2.components)

from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline

pipe_1 = IFInpaintingPipeline(**pipe_1.components)
pipe_2 = IFInpaintingSuperResolutionPipeline(**pipe_2.components)
```

### 速度优化

使 IF 更快的最简单优化方法是将所有模型组件移至 GPU。

```py
pipe = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
pipe.to("cuda")
```

您还可以将扩散过程运行更短的时间步数。

这可以使用`num_inference_steps`参数完成：

```py
pipe("<prompt>", num_inference_steps=30)
```

要么使用`timesteps`参数：

```py
from diffusers.pipelines.deepfloyd_if import fast27_timesteps

pipe("<prompt>", timesteps=fast27_timesteps)
```

在进行图像变化或修补时，您还可以通过强度参数减少时间步数。强度参数是要添加到输入图像中的噪声量，也决定了去噪过程中要运行多少步骤。较小的数字将使图像变化较小，但运行速度更快。

```py
pipe = IFImg2ImgPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
pipe.to("cuda")

image = pipe(image=image, prompt="<prompt>", strength=0.3).images
```

您还可以使用`torch.compile`。请注意，我们尚未对`torch.compile`与 IF 进行全面测试，可能无法产生预期的结果。

```py
from diffusers import DiffusionPipeline
import torch

pipe = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
pipe.to("cuda")

pipe.text_encoder = torch.compile(pipe.text_encoder, mode="reduce-overhead", fullgraph=True)
pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)
```

### 内存优化

在优化 GPU 内存时，我们可以使用标准的扩散 CPU 卸载 API。

要么基于模型的 CPU 卸载，

```py
pipe = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
pipe.enable_model_cpu_offload()
```

或更激进的基于层的 CPU 卸载。

```py
pipe = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
pipe.enable_sequential_cpu_offload()
```

此外，T5 可以以 8 位精度加载

```py
from transformers import T5EncoderModel

text_encoder = T5EncoderModel.from_pretrained(
    "DeepFloyd/IF-I-XL-v1.0", subfolder="text_encoder", device_map="auto", load_in_8bit=True, variant="8bit"
)

from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained(
    "DeepFloyd/IF-I-XL-v1.0",
    text_encoder=text_encoder,  # pass the previously instantiated 8bit text encoder
    unet=None,
    device_map="auto",
)

prompt_embeds, negative_embeds = pipe.encode_prompt("<prompt>")
```

对于 CPU RAM 受限的机器，如 Google Colab 免费层，我们无法一次性将所有模型组件加载到 CPU 中，因此在需要时可以手动仅加载具有文本编码器或 UNet 的管道。

```py
from diffusers import IFPipeline, IFSuperResolutionPipeline
import torch
import gc
from transformers import T5EncoderModel
from diffusers.utils import pt_to_pil, make_image_grid

text_encoder = T5EncoderModel.from_pretrained(
    "DeepFloyd/IF-I-XL-v1.0", subfolder="text_encoder", device_map="auto", load_in_8bit=True, variant="8bit"
)

# text to image
pipe = DiffusionPipeline.from_pretrained(
    "DeepFloyd/IF-I-XL-v1.0",
    text_encoder=text_encoder,  # pass the previously instantiated 8bit text encoder
    unet=None,
    device_map="auto",
)

prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says "very deep learning"'
prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)

# Remove the pipeline so we can re-load the pipeline with the unet
del text_encoder
del pipe
gc.collect()
torch.cuda.empty_cache()

pipe = IFPipeline.from_pretrained(
    "DeepFloyd/IF-I-XL-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16, device_map="auto"
)

generator = torch.Generator().manual_seed(0)
stage_1_output = pipe(
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    output_type="pt",
    generator=generator,
).images

#pt_to_pil(stage_1_output)[0].save("./if_stage_I.png")

# Remove the pipeline so we can load the super-resolution pipeline
del pipe
gc.collect()
torch.cuda.empty_cache()

# First super resolution

pipe = IFSuperResolutionPipeline.from_pretrained(
    "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16, device_map="auto"
)

generator = torch.Generator().manual_seed(0)
stage_2_output = pipe(
    image=stage_1_output,
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    output_type="pt",
    generator=generator,
).images

#pt_to_pil(stage_2_output)[0].save("./if_stage_II.png")
make_image_grid([pt_to_pil(stage_1_output)[0], pt_to_pil(stage_2_output)[0]], rows=1, rows=2)
```

## 可用管道：

| 管道 | 任务 | Colab |
| --- | --- | :-: |
| [pipeline_if.py](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/deepfloyd_if/pipeline_if.py) | *文本到图像生成* | - |
| [pipeline_if_superresolution.py](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/deepfloyd_if/pipeline_if_superresolution.py) | *文本到图像生成* | - |
| [pipeline_if_img2img.py](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img.py) | *图像到图像生成* | - |
| [pipeline_if_img2img_superresolution.py](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img_superresolution.py) | *图像到图像生成* | - |
| [pipeline_if_inpainting.py](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting.py) | *图像到图像生成* | - |
| [pipeline_if_inpainting_superresolution.py](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting_superresolution.py) | *图像到图像生成* | - |

## IFPipeline

### `class diffusers.IFPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if.py#L88)

```py
( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: UNet2DConditionModel scheduler: DDPMScheduler safety_checker: Optional feature_extractor: Optional watermarker: Optional requires_safety_checker: bool = True )
```

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if.py#L555)

```py
( prompt: Union = None num_inference_steps: int = 100 timesteps: List = None guidance_scale: float = 7.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 height: Optional = None width: Optional = None eta: float = 0.0 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 clean_caption: bool = True cross_attention_kwargs: Optional = None ) → export const metadata = 'undefined';~pipelines.stable_diffusion.IFPipelineOutput or tuple
```

参数

+   `prompt`（`str`或`List[str]`，*可选*）—用于指导图像生成的提示或提示。如果未定义，则必须传递`prompt_embeds`。

+   `num_inference_steps`（`int`，*可选*，默认为 100）—去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `timesteps` (`List[int]`, *optional*) — 用于去噪过程的自定义时间步。如果未定义，将使用等间距的 `num_inference_steps` 时间步。必须按降序排列。

+   `guidance_scale` (`float`, *optional*, defaults to 7.0) — 在 [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598) 中定义的指导比例。`guidance_scale` 定义为 [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf) 中方程式 2 的 `w`。通过设置 `guidance_scale > 1` 启用指导比例。更高的指导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。

+   `negative_prompt` (`str` or `List[str]`, *optional*) — 不指导图像生成的提示或提示。如果未定义，则必须传递 `negative_prompt_embeds`。不使用指导时将被忽略（即如果 `guidance_scale` 小于 `1` 则被忽略）。

+   `num_images_per_prompt` (`int`, *optional*, defaults to 1) — 每个提示生成的图像数量。

+   `height` (`int`, *optional*, defaults to self.unet.config.sample_size) — 生成图像的像素高度。

+   `width` (`int`, *optional*, defaults to self.unet.config.sample_size) — 生成图像的像素宽度。

+   `eta` (`float`, *optional*, defaults to 0.0) — 对应于 DDIM 论文中的参数 eta (η)：[`arxiv.org/abs/2010.02502`](https://arxiv.org/abs/2010.02502)。仅适用于 schedulers.DDIMScheduler，对其他情况将被忽略。

+   `generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — 一个或多个 [torch 生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `prompt` 输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `negative_prompt` 输入参数生成负提示嵌入。

+   `output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择 `PIL.Image.Image` 或 `np.array` 之间的格式。

+   `return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回 `~pipelines.stable_diffusion.IFPipelineOutput` 而不是普通元组。

+   `callback` (`Callable`, *optional*) — 在推理过程中每 `callback_steps` 步调用的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *optional*, defaults to 1) — `callback` 函数将被调用的频率。如果未指定，将在每一步调用回调函数。

+   `clean_caption` (`bool`, *optional*, defaults to `True`) — 在创建嵌入之前是否清理标题。需要安装 `beautifulsoup4` 和 `ftfy`。如果未安装依赖项，将从原始提示创建嵌入。

+   `cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给 `AttentionProcessor` 中的 `self.processor` 中定义的 kwargs 字典，详情请参阅 [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)。

返回

`~pipelines.stable_diffusion.IFPipelineOutput` 或 `tuple`

如果 `return_dict` 为 True，则返回 `~pipelines.stable_diffusion.IFPipelineOutput`，否则返回一个 `tuple`。当返回一个元组时，第一个元素是生成的图像列表，第二个元素是一个列表，表示相应生成的图像是否可能代表“不适宜工作”（nsfw）或带水印的内容，根据 `safety_checker`。

调用管道生成时调用的函数。

示例:

```py
>>> from diffusers import IFPipeline, IFSuperResolutionPipeline, DiffusionPipeline
>>> from diffusers.utils import pt_to_pil
>>> import torch

>>> pipe = IFPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
>>> pipe.enable_model_cpu_offload()

>>> prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says "very deep learning"'
>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)

>>> image = pipe(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, output_type="pt").images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> super_res_1_pipe = IFSuperResolutionPipeline.from_pretrained(
...     "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
... )
>>> super_res_1_pipe.enable_model_cpu_offload()

>>> image = super_res_1_pipe(
...     image=image, prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, output_type="pt"
... ).images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> safety_modules = {
...     "feature_extractor": pipe.feature_extractor,
...     "safety_checker": pipe.safety_checker,
...     "watermarker": pipe.watermarker,
... }
>>> super_res_2_pipe = DiffusionPipeline.from_pretrained(
...     "stabilityai/stable-diffusion-x4-upscaler", **safety_modules, torch_dtype=torch.float16
... )
>>> super_res_2_pipe.enable_model_cpu_offload()

>>> image = super_res_2_pipe(
...     prompt=prompt,
...     image=image,
... ).images
>>> image[0].save("./if_stage_II.png")
```

#### `encode_prompt`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if.py#L173)

```py
( prompt: Union do_classifier_free_guidance: bool = True num_images_per_prompt: int = 1 device: Optional = None negative_prompt: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None clean_caption: bool = False )
```

参数

+   `prompt` (`str` 或 `List[str]`, *可选*) — 要编码的提示

+   `do_classifier_free_guidance` (`bool`, *可选*, 默认为 `True`) — 是否使用无分类器指导。

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示应生成的图像数量。设备 — (`torch.device`, *可选*): 放置生成的嵌入的 torch 设备

+   `negative_prompt` (`str` 或 `List[str]`, *可选*) — 不指导图像生成的提示。如果未定义，则必须传递 `negative_prompt_embeds`。如果未定义，则必须传递 `negative_prompt_embeds`。如果不使用指导（即如果 `guidance_scale` 小于 `1`，则忽略）。

+   `prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `prompt` 输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `negative_prompt` 输入参数生成 `negative_prompt_embeds`。

+   `clean_caption` (布尔值，默认为 `False`) — 如果为 `True`，则函数将在编码之前对提供的标题进行预处理和清理。

将提示编码为文本编码器隐藏状态。

## IFSuperResolutionPipeline

### `class diffusers.IFSuperResolutionPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_superresolution.py#L73)

```py
( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: UNet2DConditionModel scheduler: DDPMScheduler image_noising_scheduler: DDPMScheduler safety_checker: Optional feature_extractor: Optional watermarker: Optional requires_safety_checker: bool = True )
```

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_superresolution.py#L622)

```py
( prompt: Union = None height: int = None width: int = None image: Union = None num_inference_steps: int = 50 timesteps: List = None guidance_scale: float = 4.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None noise_level: int = 250 clean_caption: bool = True ) → export const metadata = 'undefined';~pipelines.stable_diffusion.IFPipelineOutput or tuple
```

参数

+   `prompt` (`str` 或 `List[str]`, *可选*) — 指导图像生成的提示。如果未定义，则必须传递 `prompt_embeds`。

+   `height` (`int`, *可选*, 默认为 None) — 生成图像的像素高度。

+   `width` (`int`, *可选*, 默认为 None) — 生成图像的像素宽度。

+   `image` (`PIL.Image.Image`, `np.ndarray`, `torch.FloatTensor`) — 要放大的图像。

+   `num_inference_steps` (`int`, *可选*, 默认为 50) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `timesteps` (`List[int]`, *可选*, 默认为 None) — 用于去噪过程的自定义时间步。如果未定义，则使用等间距的 `num_inference_steps` 时间步。必须按降序排列。

+   `guidance_scale` (`float`, *可选*, 默认为 4.0) — 在[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale` 在[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)的方程式 2 中定义为 `w`。通过设置 `guidance_scale > 1` 来启用指导比例。更高的指导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。

+   `negative_prompt` (`str` 或 `List[str]`, *可选*) — 不指导图像生成的提示。如果未定义，则必须传递 `negative_prompt_embeds`。如果不使用指导（即如果 `guidance_scale` 小于 `1`，则忽略）。

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。

+   `eta` (`float`, *可选*, 默认为 0.0) — 对应于 DDIM 论文中的参数 eta (η)：[`arxiv.org/abs/2010.02502`](https://arxiv.org/abs/2010.02502)。仅适用于 schedulers.DDIMScheduler，对于其他情况将被忽略。

+   `generator` (`torch.Generator`或`List[torch.Generator]`, *可选*) — 一个或多个[torch 生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)以使生成结果确定性。

+   `prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，*例如*提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，*例如*提示加权。如果未提供，将从`negative_prompt`输入参数生成 negative_prompt_embeds。

+   `output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。在[PIL](https://pillow.readthedocs.io/en/stable/)之间选择：`PIL.Image.Image`或`np.array`。

+   `return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回`~pipelines.stable_diffusion.IFPipelineOutput`而不是普通元组。

+   `callback` (`Callable`, *可选*) — 在推断过程中每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *可选*, 默认为 1) — `callback`函数将被调用的频率。如果未指定，将在每一步调用回调。

+   `cross_attention_kwargs` (`dict`, *可选*) — 如果指定，则将传递给`AttentionProcessor`的 kwargs 字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中所定义。

+   `noise_level` (`int`, *可选*, 默认为 250) — 添加到放大图像的噪声量。必须在范围`[0, 1000)`内

+   `clean_caption` (`bool`, *可选*, 默认为`True`) — 在创建嵌入之前是否清理标题。需要安装`beautifulsoup4`和`ftfy`。如果未安装依赖项，则将从原始提示创建嵌入。

返回

`~pipelines.stable_diffusion.IFPipelineOutput`或`tuple`

如果`return_dict`为 True，则为`~pipelines.stable_diffusion.IFPipelineOutput`，否则为`tuple`。返回元组时，第一个元素是生成的图像列表，第二个元素是一个`bool`列表，表示相应生成的图像是否可能代表“不适宜工作”（nsfw）或带有水印的内容，根据`safety_checker`。

调用管道生成时调用的函数。

示例：

```py
>>> from diffusers import IFPipeline, IFSuperResolutionPipeline, DiffusionPipeline
>>> from diffusers.utils import pt_to_pil
>>> import torch

>>> pipe = IFPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16)
>>> pipe.enable_model_cpu_offload()

>>> prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says "very deep learning"'
>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)

>>> image = pipe(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, output_type="pt").images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> super_res_1_pipe = IFSuperResolutionPipeline.from_pretrained(
...     "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
... )
>>> super_res_1_pipe.enable_model_cpu_offload()

>>> image = super_res_1_pipe(
...     image=image, prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds
... ).images
>>> image[0].save("./if_stage_II.png")
```

#### `encode_prompt`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_superresolution.py#L307)

```py
( prompt: Union do_classifier_free_guidance: bool = True num_images_per_prompt: int = 1 device: Optional = None negative_prompt: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None clean_caption: bool = False )
```

参数

+   `prompt` (`str`或`List[str]`, *可选*) — 要编码的提示

+   `do_classifier_free_guidance` (`bool`, *可选*, 默认为`True`) — 是否使用无分类器指导

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示应生成的图像数量 设备 — (`torch.device`, *可选*): 放置生成的嵌入结果的 torch 设备

+   `negative_prompt` (`str`或`List[str]`, *可选*) — 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。而不是。如果未定义，则必须传递`negative_prompt_embeds`。而不是。在不使用指导时被忽略（即，如果`guidance_scale`小于`1`，则被忽略）。

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `prompt` 输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `negative_prompt` 输入参数生成 negative_prompt_embeds。

+   `clean_caption` (bool, 默认为 `False`) — 如果为 `True`，函数将在编码之前预处理和清理提供的标题。

将提示编码为文本编码器隐藏状态。

## IFImg2ImgPipeline

### `class diffusers.IFImg2ImgPipeline`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img.py#L112)

```py
( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: UNet2DConditionModel scheduler: DDPMScheduler safety_checker: Optional feature_extractor: Optional watermarker: Optional requires_safety_checker: bool = True )
```

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img.py#L667)

```py
( prompt: Union = None image: Union = None strength: float = 0.7 num_inference_steps: int = 80 timesteps: List = None guidance_scale: float = 10.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 clean_caption: bool = True cross_attention_kwargs: Optional = None ) → export const metadata = 'undefined';~pipelines.stable_diffusion.IFPipelineOutput or tuple
```

参数

+   `prompt` (`str` 或 `List[str]`, *optional*) — 用于引导图像生成的提示或提示。如果未定义，则必须传递 `prompt_embeds`。

+   `image` (`torch.FloatTensor` 或 `PIL.Image.Image`) — 将用作过程起点的 `Image`，或表示图像批次的张量。

+   `strength` (`float`, *optional*, 默认为 0.7) — 在概念上，指示要转换参考 `image` 的程度。必须介于 0 和 1 之间。`image` 将被用作起点，添加的噪声越大，`strength` 越大。去噪步骤的数量取决于最初添加的噪声量。当 `strength` 为 1 时，添加的噪声将达到最大值，并且去噪过程将运行指定的 `num_inference_steps` 次迭代。因此，值为 1 基本上忽略了 `image`。

+   `num_inference_steps` (`int`, *optional*, 默认为 80) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `timesteps` (`List[int]`, *optional*) — 用于去噪过程的自定义时间步。如果未定义，则使用等间距的 `num_inference_steps` 个时间步。必须按降序排列。

+   `guidance_scale` (`float`, *optional*, 默认为 10.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale` 定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2 中的 `w`。通过设置 `guidance_scale > 1` 来启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。

+   `negative_prompt` (`str` 或 `List[str]`, *optional*) — 不用于引导图像生成的提示或提示。如果未定义，则必须传递 `negative_prompt_embeds`。如果不使用引导（即如果 `guidance_scale` 小于 `1`，则忽略）。

+   `num_images_per_prompt` (`int`, *optional*, 默认为 1) — 每个提示生成的图像数量。

+   `eta` (`float`, *optional*, 默认为 0.0) — 对应于 DDIM 论文中的参数 eta (η)：[`arxiv.org/abs/2010.02502`](https://arxiv.org/abs/2010.02502)。仅适用于 schedulers.DDIMScheduler，对其他情况将被忽略。

+   `generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 一个或多个[torch 生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，使生成过程确定性。

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从 `prompt` 输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负面文本嵌入。可以用来轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。

+   `output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。在[PIL](https://pillow.readthedocs.io/en/stable/)之间选择：`PIL.Image.Image`或`np.array`。

+   `return_dict` (`bool`, *optional*, 默认为`True`) — 是否返回`~pipelines.stable_diffusion.IFPipelineOutput`而不是普通元组。

+   `callback` (`Callable`, *optional*) — 在推理过程中每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *optional*，默认为 1) — 调用`callback`函数的频率。如果未指定，将在每一步调用回调函数。

+   `clean_caption` (`bool`, *optional*, 默认为`True`) — 在创建嵌入之前是否清理标题。需要安装`beautifulsoup4`和`ftfy`。如果未安装依赖项，将从原始提示创建嵌入。

+   `cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给`AttentionProcessor`的 kwargs 字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中定义。

返回

`~pipelines.stable_diffusion.IFPipelineOutput`或`tuple`

如果`return_dict`为 True，则为`~pipelines.stable_diffusion.IFPipelineOutput`，否则为元组。返回元组时，第一个元素是生成的图像列表，第二个元素是一个`bool`列表，表示相应生成的图像是否可能代表“不适宜工作”(nsfw)或带有水印的内容，根据`safety_checker`。

在生成时调用管道时调用的函数。

示例：

```py
>>> from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline
>>> from diffusers.utils import pt_to_pil
>>> import torch
>>> from PIL import Image
>>> import requests
>>> from io import BytesIO

>>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
>>> response = requests.get(url)
>>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
>>> original_image = original_image.resize((768, 512))

>>> pipe = IFImg2ImgPipeline.from_pretrained(
...     "DeepFloyd/IF-I-XL-v1.0",
...     variant="fp16",
...     torch_dtype=torch.float16,
... )
>>> pipe.enable_model_cpu_offload()

>>> prompt = "A fantasy landscape in style minecraft"
>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)

>>> image = pipe(
...     image=original_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
...     output_type="pt",
... ).images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> super_res_1_pipe = IFImg2ImgSuperResolutionPipeline.from_pretrained(
...     "DeepFloyd/IF-II-L-v1.0",
...     text_encoder=None,
...     variant="fp16",
...     torch_dtype=torch.float16,
... )
>>> super_res_1_pipe.enable_model_cpu_offload()

>>> image = super_res_1_pipe(
...     image=image,
...     original_image=original_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
... ).images
>>> image[0].save("./if_stage_II.png")
```

#### `encode_prompt`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img.py#L198)

```py
( prompt: Union do_classifier_free_guidance: bool = True num_images_per_prompt: int = 1 device: Optional = None negative_prompt: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None clean_caption: bool = False )
```

参数

+   `prompt` (`str`或`List[str]`, *optional*) — 要编码的提示

+   `do_classifier_free_guidance` (`bool`, *optional*, 默认为`True`) — 是否使用分类器自由指导

+   `num_images_per_prompt` (`int`, *optional*, 默认为 1) — 每个提示生成的图像数量。设备 — (`torch.device`, *optional*): 放置生成的嵌入的 torch 设备

+   `negative_prompt` (`str`或`List[str]`, *optional*) — 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。而不是。如果未定义，则必须传递`negative_prompt_embeds`。而不是。在不使用指导时被忽略(即，如果`guidance_scale`小于`1`，则被忽略)。

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可以用来轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负面文本嵌入。可以用来轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。

+   `clean_caption` (bool，默认为`False`) — 如果为`True`，则在编码之前对提供的标题进行预处理和清理。

将提示编码为文本编码器隐藏状态。

## IFImg2ImgSuperResolutionPipeline

### `class diffusers.IFImg2ImgSuperResolutionPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img_superresolution.py#L115)

```py
( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: UNet2DConditionModel scheduler: DDPMScheduler image_noising_scheduler: DDPMScheduler safety_checker: Optional feature_extractor: Optional watermarker: Optional requires_safety_checker: bool = True )
```

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img_superresolution.py#L750)

```py
( image: Union original_image: Union = None strength: float = 0.8 prompt: Union = None num_inference_steps: int = 50 timesteps: List = None guidance_scale: float = 4.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None noise_level: int = 250 clean_caption: bool = True ) → export const metadata = 'undefined';~pipelines.stable_diffusion.IFPipelineOutput or tuple
```

参数

+   `image` (`torch.FloatTensor` 或 `PIL.Image.Image`) — 作为过程起点使用的`Image`或表示图像批次的张量。

+   `original_image` (`torch.FloatTensor` 或 `PIL.Image.Image`) — `image`变化的原始图像。

+   `strength` (`float`, *可选*, 默认为 0.8) — 在概念上，指示要转换参考`image`的程度。必须在 0 和 1 之间。`image`将被用作起点，添加更多的噪音，`strength`越大。去噪步数取决于最初添加的噪音量。当`strength`为 1 时，添加的噪音将达到最大，并且去噪过程将运行指定的`num_inference_steps`的全部迭代次数。因此，值为 1 基本上忽略了`image`。

+   `prompt` (`str` 或 `List[str]`, *可选*) — 用于引导图像生成的提示。如果未定义，则必须传递`prompt_embeds`。

+   `num_inference_steps` (`int`, *可选*, 默认为 50) — 去噪步数。更多的去噪步通常会导致图像质量更高，但推理速度较慢。

+   `timesteps` (`List[int]`, *可选*) — 用于去噪过程的自定义时间步。如果未定义，则使用等间距的`num_inference_steps`时间步。必须按降序排列。

+   `guidance_scale` (`float`, *可选*, 默认为 4.0) — 在[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程 2 的`w`。通过设置`guidance_scale > 1`启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。

+   `negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用来引导图像生成的提示。如果未定义，则必须传递`negative_prompt_embeds`。在不使用引导时被忽略（即如果`guidance_scale`小于`1`，则被忽略）。

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。

+   `eta` (`float`, *可选*, 默认为 0.0) — 对应于 DDIM 论文中的参数 eta（η）：[`arxiv.org/abs/2010.02502`](https://arxiv.org/abs/2010.02502)。仅适用于 schedulers.DDIMScheduler，对其他情况将被忽略。

+   `generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch 生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，使生成过程确定性。

+   `prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，文本嵌入将从`prompt`输入参数生成。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。

+   `output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。在[PIL](https://pillow.readthedocs.io/en/stable/)中选择：`PIL.Image.Image`或`np.array`。

+   `return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回`~pipelines.stable_diffusion.IFPipelineOutput`而不是普通元组。

+   `callback` (`Callable`, *可选*) — 在推理过程中每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *可选*, 默认为 1) — `callback`函数将被调用的频率。如果未指定，将在每一步调用回调。

+   `cross_attention_kwargs` (`dict`, *可选*) — 如果指定，将传递给`AttentionProcessor`的 kwargs 字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`中定义。

+   `noise_level` (`int`, *可选*, 默认为 250) — 添加到放大图像中的噪声量。必须在范围`[0, 1000)`内

+   `clean_caption` (`bool`, *可选*, 默认为`True`) — 在创建嵌入之前是否清理标题。需要安装`beautifulsoup4`和`ftfy`。如果未安装依赖项，嵌入将从原始提示创建。

返回

`~pipelines.stable_diffusion.IFPipelineOutput` 或 `tuple`

`~pipelines.stable_diffusion.IFPipelineOutput` 如果`return_dict`为 True，否则为一个`tuple`。当返回一个元组时，第一个元素是生成的图像列表，第二个元素是一个`bool`列表，表示相应生成的图像是否可能代表“不安全的工作”（nsfw）或带水印的内容，根据`safety_checker`。

调用生成管道时调用的函数。

示例：

```py
>>> from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline
>>> from diffusers.utils import pt_to_pil
>>> import torch
>>> from PIL import Image
>>> import requests
>>> from io import BytesIO

>>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
>>> response = requests.get(url)
>>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
>>> original_image = original_image.resize((768, 512))

>>> pipe = IFImg2ImgPipeline.from_pretrained(
...     "DeepFloyd/IF-I-XL-v1.0",
...     variant="fp16",
...     torch_dtype=torch.float16,
... )
>>> pipe.enable_model_cpu_offload()

>>> prompt = "A fantasy landscape in style minecraft"
>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)

>>> image = pipe(
...     image=original_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
...     output_type="pt",
... ).images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> super_res_1_pipe = IFImg2ImgSuperResolutionPipeline.from_pretrained(
...     "DeepFloyd/IF-II-L-v1.0",
...     text_encoder=None,
...     variant="fp16",
...     torch_dtype=torch.float16,
... )
>>> super_res_1_pipe.enable_model_cpu_offload()

>>> image = super_res_1_pipe(
...     image=image,
...     original_image=original_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
... ).images
>>> image[0].save("./if_stage_II.png")
```

#### `encode_prompt`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img_superresolution.py#L349)

```py
( prompt: Union do_classifier_free_guidance: bool = True num_images_per_prompt: int = 1 device: Optional = None negative_prompt: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None clean_caption: bool = False )
```

参数

+   `prompt` (`str` 或 `List[str]`, *可选*) — 要编码的提示

+   `do_classifier_free_guidance` (`bool`, *可选*, 默认为`True`) — 是否使用无分类器指导

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示应生成的图像数量 设备 — (`torch.device`, *可选*): 放置生成的嵌入的 torch 设备

+   `negative_prompt` (`str` 或 `List[str]`, *可选*) — 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。而不是。当不使用指导时被忽略（即，如果`guidance_scale`小于`1`，则被忽略）。

+   `prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，文本嵌入将从`prompt`输入参数生成。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负面文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。

+   `clean_caption` (bool, 默认为`False`) — 如果为`True`，则函数将在编码之前预处理和清理提供的标题。

将提示编码为文本编码器隐藏状态。

## IFInpaintingPipeline

### `class diffusers.IFInpaintingPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting.py#L115)

```py
( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: UNet2DConditionModel scheduler: DDPMScheduler safety_checker: Optional feature_extractor: Optional watermarker: Optional requires_safety_checker: bool = True )
```

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting.py#L760)

```py
( prompt: Union = None image: Union = None mask_image: Union = None strength: float = 1.0 num_inference_steps: int = 50 timesteps: List = None guidance_scale: float = 7.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 clean_caption: bool = True cross_attention_kwargs: Optional = None ) → export const metadata = 'undefined';~pipelines.stable_diffusion.IFPipelineOutput or tuple
```

参数

+   `prompt` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成的提示或提示。如果未定义，则必须传递`prompt_embeds`。而不是。

+   `image` (`torch.FloatTensor` 或 `PIL.Image.Image`) — 用作过程起点的`Image`或表示图像批次的张量。

+   `mask_image` (`PIL.Image.Image`) — 用于遮罩`image`的`Image`或表示图像批次的张量。遮罩中的白色像素将被重新绘制，而黑色像素将被保留。如果`mask_image`是 PIL 图像，它将在使用之前转换为单通道（亮度）。如果是张量，则应包含一个颜色通道（L）而不是 3，因此预期形状将是`(B, H, W, 1)`。

+   `strength` (`float`, *可选*, 默认为 1.0) — 在概念上，指示要转换参考`image`的程度。必须介于 0 和 1 之间。`image`将被用作起点，添加的噪声越大，`strength`越大。降噪步骤的数量取决于最初添加的噪声量。当`strength`为 1 时，添加的噪声将达到最大值，并且降噪过程将运行指定的`num_inference_steps`次迭代。因此，值为 1 基本上忽略了`image`。

+   `num_inference_steps` (`int`, *可选*, 默认为 50) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。

+   `timesteps` (`List[int]`, *可选*) — 用于去噪过程的自定义时间步长。如果未定义，则使用等间距的`num_inference_steps`时间步长。必须按降序排列。

+   `guidance_scale` (`float`, *可选*, 默认为 7.0) — 在[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale`被定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2 的`w`。通过设置`guidance_scale > 1`启用指导比例。更高的指导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。

+   `negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用指导（即，如果`guidance_scale`小于`1`，则将被忽略）。

+   `num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。

+   `eta` (`float`, *可选*, 默认为 0.0) — 对应于 DDIM 论文中的参数 eta（η）：[`arxiv.org/abs/2010.02502`](https://arxiv.org/abs/2010.02502)。仅适用于 schedulers.DDIMScheduler，对其他情况将被忽略。

+   `generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch 生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)列表，用于使生成过程确定性。

+   `prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如权重提示。如果未提供，文本嵌入将从`prompt`输入参数生成。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如权重提示。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。

+   `output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。可选择[PIL](https://pillow.readthedocs.io/en/stable/)：`PIL.Image.Image` 或 `np.array`。

+   `return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回`~pipelines.stable_diffusion.IFPipelineOutput`而不是普通元组。

+   `callback` (`Callable`, *可选*) — 推理过程中每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *可选*, 默认为 1) — `callback`函数将被调用的频率。如果未指定，将在每一步调用回调。

+   `clean_caption`（`bool`，*可选*，默认为`True`）- 在创建嵌入之前是否清理标题。需要安装`beautifulsoup4`和`ftfy`。如果未安装依赖项，将从原始提示创建嵌入。

+   `cross_attention_kwargs`（`dict`，*可选*）- 如果指定，将传递给`AttentionProcessor`的 kwargs 字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`中定义。

返回

`~pipelines.stable_diffusion.IFPipelineOutput`或`tuple`

`~pipelines.stable_diffusion.IFPipelineOutput`如果`return_dict`为`True`，否则为`tuple`。当返回一个元组时，第一个元素是生成的图像列表，第二个元素是一个`bool`列表，表示相应生成的图像是否可能代表“不适宜工作”（nsfw）或带水印的内容，根据`safety_checker`。

调用生成管道时调用的函数。

示例：

```py
>>> from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline
>>> from diffusers.utils import pt_to_pil
>>> import torch
>>> from PIL import Image
>>> import requests
>>> from io import BytesIO

>>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png"
>>> response = requests.get(url)
>>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
>>> original_image = original_image

>>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png"
>>> response = requests.get(url)
>>> mask_image = Image.open(BytesIO(response.content))
>>> mask_image = mask_image

>>> pipe = IFInpaintingPipeline.from_pretrained(
...     "DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16
... )
>>> pipe.enable_model_cpu_offload()

>>> prompt = "blue sunglasses"
>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)

>>> image = pipe(
...     image=original_image,
...     mask_image=mask_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
...     output_type="pt",
... ).images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> super_res_1_pipe = IFInpaintingSuperResolutionPipeline.from_pretrained(
...     "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
... )
>>> super_res_1_pipe.enable_model_cpu_offload()

>>> image = super_res_1_pipe(
...     image=image,
...     mask_image=mask_image,
...     original_image=original_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
... ).images
>>> image[0].save("./if_stage_II.png")
```

#### `encode_prompt`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting.py#L201)

```py
( prompt: Union do_classifier_free_guidance: bool = True num_images_per_prompt: int = 1 device: Optional = None negative_prompt: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None clean_caption: bool = False )
```

参数

+   `prompt`（`str`或`List[str]`，*可选*）- 要编码的提示

+   `do_classifier_free_guidance`（`bool`，*可选*，默认为`True`）- 是否使用分类器自由指导

+   `num_images_per_prompt`（`int`，*可选*，默认为 1）- 每个提示生成的图像数量设备-（`torch.device`，*可选*）：将生成的嵌入放置在的 torch 设备

+   `negative_prompt`（`str`或`List[str]`，*可选*）- 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。而不是。如果未定义，则必须传递`negative_prompt_embeds`。而不是。在不使用指导时被忽略（即，如果`guidance_scale`小于`1`，则被忽略）。

+   `prompt_embeds`（`torch.FloatTensor`，*可选*）- 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，文本嵌入将从`prompt`输入参数生成。

+   `negative_prompt_embeds`（`torch.FloatTensor`，*可选*）- 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成 negative_prompt_embeds。

+   `clean_caption`（布尔值，默认为`False`）- 如果为`True`，则函数将在编码之前对提供的标题进行预处理和清理。

将提示编码为文本编码器隐藏状态。

## IFInpaintingSuperResolutionPipeline

### `class diffusers.IFInpaintingSuperResolutionPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting_superresolution.py#L117)

```py
( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: UNet2DConditionModel scheduler: DDPMScheduler image_noising_scheduler: DDPMScheduler safety_checker: Optional feature_extractor: Optional watermarker: Optional requires_safety_checker: bool = True )
```

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting_superresolution.py#L838)

```py
( image: Union original_image: Union = None mask_image: Union = None strength: float = 0.8 prompt: Union = None num_inference_steps: int = 100 timesteps: List = None guidance_scale: float = 4.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None noise_level: int = 0 clean_caption: bool = True ) → export const metadata = 'undefined';~pipelines.stable_diffusion.IFPipelineOutput or tuple
```

参数

+   `image`（`torch.FloatTensor`或`PIL.Image.Image`）- 将用作过程的起点的`Image`或表示图像批次的张量。

+   `original_image`（`torch.FloatTensor`或`PIL.Image.Image`）- `image`变化的原始图像。

+   `mask_image`（`PIL.Image.Image`）- 要遮罩`image`的`Image`或表示图像批次的张量。掩码中的白色像素将被重新绘制，而黑色像素将被保留。如果`mask_image`是 PIL 图像，则在使用之前将其转换为单通道（亮度）。如果是张量，则应包含一个颜色通道（L）而不是 3，因此预期形状将是`(B, H, W, 1)`。

+   `strength` (`float`, *optional*, defaults to 0.8) — 概念上，指示了要如何转换参考`image`的程度。必须在 0 和 1 之间。`image`将被用作起点，随着`strength`的增加，将会向其添加更多噪音。去噪步骤的数量取决于最初添加的噪音量。当`strength`为 1 时，添加的噪音将达到最大值，并且去噪过程将在`num_inference_steps`中指定的迭代次数内运行。因此，值为 1 基本上忽略了`image`。

+   `prompt` (`str`或`List[str]`, *optional*) — 指导图像生成的提示或提示。如果未定义，则必须传递`prompt_embeds`。

+   `num_inference_steps` (`int`, *optional*, defaults to 100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `timesteps` (`List[int]`, *optional*) — 用于去噪过程的自定义时间步。如果未定义，则使用等间距的`num_inference_steps`时间步。必须按降序排列。

+   `guidance_scale` (`float`, *optional*, defaults to 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2 的`w`。通过设置`guidance_scale > 1`来启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。

+   `negative_prompt` (`str`或`List[str]`, *optional*) — 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用引导（即，如果`guidance_scale`小于`1`，则将被忽略）。

+   `num_images_per_prompt` (`int`, *optional*, defaults to 1) — 每个提示生成的图像数量。

+   `eta` (`float`, *optional*, defaults to 0.0) — 对应于 DDIM 论文中的参数 eta (η)：[`arxiv.org/abs/2010.02502`](https://arxiv.org/abs/2010.02502)。仅适用于 schedulers.DDIMScheduler，对其他情况将被忽略。

+   `generator` (`torch.Generator`或`List[torch.Generator]`, *optional*) — 一个或多个[torch 生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。

+   `prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。

+   `negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成负提示嵌入。

+   `output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择[PIL](https://pillow.readthedocs.io/en/stable/)之间的：`PIL.Image.Image`或`np.array`。

+   `return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回`~pipelines.stable_diffusion.IFPipelineOutput`而不是普通元组。

+   `callback` (`Callable`, *optional*) — 一个在推理过程中每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *optional*, defaults to 1) — `callback`函数将被调用的频率。如果未指定，将在每一步调用回调。

+   `cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给`AttentionProcessor`的 kwargs 字典，如[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`中定义的那样。

+   `noise_level`（`int`，*可选*，默认为 0）— 添加到放大图像的噪声量。必须在范围`[0, 1000)`内

+   `clean_caption`（`bool`，*可选*，默认为`True`）— 在创建嵌入之前是否清除标题。需要安装`beautifulsoup4`和`ftfy`。如果未安装依赖项，则将从原始提示创建嵌入。

返回

`~pipelines.stable_diffusion.IFPipelineOutput`或`tuple`

`~pipelines.stable_diffusion.IFPipelineOutput`如果`return_dict`为 True，否则为`tuple`。当返回一个元组时，第一个元素是生成的图像列表，第二个元素是一个`bool`列表，表示相应生成的图像是否可能代表“不适宜工作”（nsfw）或带有水印的内容，根据`safety_checker`。

调用管道生成时调用的函数。

示例：

```py
>>> from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline
>>> from diffusers.utils import pt_to_pil
>>> import torch
>>> from PIL import Image
>>> import requests
>>> from io import BytesIO

>>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png"
>>> response = requests.get(url)
>>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
>>> original_image = original_image

>>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png"
>>> response = requests.get(url)
>>> mask_image = Image.open(BytesIO(response.content))
>>> mask_image = mask_image

>>> pipe = IFInpaintingPipeline.from_pretrained(
...     "DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16
... )
>>> pipe.enable_model_cpu_offload()

>>> prompt = "blue sunglasses"

>>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)
>>> image = pipe(
...     image=original_image,
...     mask_image=mask_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
...     output_type="pt",
... ).images

>>> # save intermediate image
>>> pil_image = pt_to_pil(image)
>>> pil_image[0].save("./if_stage_I.png")

>>> super_res_1_pipe = IFInpaintingSuperResolutionPipeline.from_pretrained(
...     "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
... )
>>> super_res_1_pipe.enable_model_cpu_offload()

>>> image = super_res_1_pipe(
...     image=image,
...     mask_image=mask_image,
...     original_image=original_image,
...     prompt_embeds=prompt_embeds,
...     negative_prompt_embeds=negative_embeds,
... ).images
>>> image[0].save("./if_stage_II.png")
```

#### `encode_prompt`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting_superresolution.py#L351)

```py
( prompt: Union do_classifier_free_guidance: bool = True num_images_per_prompt: int = 1 device: Optional = None negative_prompt: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None clean_caption: bool = False )
```

参数

+   `prompt`（`str`或`List[str]`，*可选*）— 要编码的提示

+   `do_classifier_free_guidance`（`bool`，*可选*，默认为`True`）— 是否使用分类器自由指导

+   `num_images_per_prompt`（`int`，*可选*，默认为 1）— 每个提示生成的图像数量设备 —（`torch.device`，*可选*）：将生成的嵌入放置在的 torch 设备上

+   `negative_prompt`（`str`或`List[str]`，*可选*）— 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。而不是。当不使用指导时被忽略（即，如果`guidance_scale`小于`1`，则被忽略）。

+   `prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的文本嵌入。可用于轻松调整文本输入，*例如*提示加权。如果未提供，文本嵌入将从`prompt`输入参数生成。

+   `negative_prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的负文本嵌入。可用于轻松调整文本输入，*例如*提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。

+   `clean_caption`（布尔值，默认为`False`）— 如果为`True`，则函数将在编码之前对提供的标题进行预处理和清理。

将提示编码为文本编码器隐藏状态。
