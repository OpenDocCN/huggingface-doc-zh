# UNet

> 原始文本：[`huggingface.co/docs/diffusers/api/loaders/unet`](https://huggingface.co/docs/diffusers/api/loaders/unet)

一些训练方法 - 如 LoRA 和自定义扩散 - 通常针对 UNet 的注意力层，但这些训练方法也可以针对其他非注意力层。与训练模型的所有参数不同，只训练参数的子集，这样更快更高效。如果您*只*需要将权重加载到 UNet 中，则此类非常有用。如果您需要将权重加载到文本编码器或文本编码器和 UNet 中，请尝试使用 load_lora_weights()函数。

`UNet2DConditionLoadersMixin`类提供了用于加载和保存权重、融合和解除 LoRA、禁用和启用 LoRA 以及设置和删除适配器的函数。

要了解如何加载 LoRA 权重的更多信息，请参阅 LoRA 加载指南。

## UNet2DConditionLoadersMixin

### `class diffusers.loaders.UNet2DConditionLoadersMixin`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L64)

```py
( )
```

将 LoRA 层加载到`UNet2DCondtionModel`中。

#### `delete_adapters`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L661)

```py
( adapter_names: Union )
```

参数

+   `adapter_names`（`Union[List[str], str]`）—要删除的适配器的名称（单个字符串或字符串列表）。

从 UNet 中删除适配器的 LoRA 层。

示例：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
).to("cuda")
pipeline.load_lora_weights(
    "jbilcke-hf/sdxl-cinematic-1", weight_name="pytorch_lora_weights.safetensors", adapter_names="cinematic"
)
pipeline.delete_adapters("cinematic")
```

#### `disable_lora`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L615)

```py
( )
```

禁用 UNet 的活动 LoRA 层。

示例：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
).to("cuda")
pipeline.load_lora_weights(
    "jbilcke-hf/sdxl-cinematic-1", weight_name="pytorch_lora_weights.safetensors", adapter_name="cinematic"
)
pipeline.disable_lora()
```

#### `enable_lora`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L638)

```py
( )
```

启用 UNet 的活动 LoRA 层。

示例：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
).to("cuda")
pipeline.load_lora_weights(
    "jbilcke-hf/sdxl-cinematic-1", weight_name="pytorch_lora_weights.safetensors", adapter_name="cinematic"
)
pipeline.enable_lora()
```

#### `load_attn_procs`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L72)

```py
( pretrained_model_name_or_path_or_dict: Union **kwargs )
```

参数

+   `pretrained_model_name_or_path_or_dict`（`str`或`os.PathLike`或`dict`）—可以是以下之一：

    +   一个字符串，托管在 Hub 上的预训练模型的模型 ID（例如`google/ddpm-celebahq-256`）。

    +   一个目录路径（例如`./my_model_directory`），其中包含使用 ModelMixin.save_pretrained()保存的模型权重。

    +   一个[torch 状态字典](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)。

+   `cache_dir`（`Union[str, os.PathLike]`，*可选*）—下载的预训练模型配置缓存在其中的目录路径，如果未使用标准缓存。

+   `force_download`（`bool`，*可选*，默认为`False`）—是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `resume_download`（`bool`，*可选*，默认为`False`）—是否恢复下载模型权重和配置文件。如果设置为`False`，则删除任何未完全下载的文件。

+   `proxies`（`Dict[str, str]`，*可选*）—要使用的代理服务器的协议或端点的字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。每个请求都会使用代理。

+   `local_files_only`（`bool`，*可选*，默认为`False`）—是否仅加载本地模型权重和配置文件。如果设置为`True`，则模型不会从 Hub 下载。

+   `token`（`str`或*bool*，*可选*）—用作远程文件的 HTTP bearer 授权的令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`中）。

+   `low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version >= 1.9.0 else `False`) — 加速模型加载，仅加载预训练权重而不初始化权重。在加载模型时，尝试不使用超过 1 倍模型大小的 CPU 内存（包括峰值内存）。仅支持 PyTorch >= 1.9.0。如果您使用较旧版本的 PyTorch，将此参数设置为`True`将引发错误。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `subfolder` (`str`, *optional*, defaults to `""`) — 在 Hub 或本地的较大模型存储库中，模型文件的子文件夹位置。

+   `mirror` (`str`, *optional*) — 如果您在中国下载模型时遇到访问问题，可以使用镜像源解决。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。

将预训练的注意力处理器层加载到 UNet2DConditionModel 中。注意力处理器层必须在[`attention_processor.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中定义，并且必须是`torch.nn.Module`类。

示例：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
).to("cuda")
pipeline.unet.load_attn_procs(
    "jbilcke-hf/sdxl-cinematic-1", weight_name="pytorch_lora_weights.safetensors", adapter_name="cinematic"
)
```

#### `save_attn_procs`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L413)

```py
( save_directory: Union is_main_process: bool = True weight_name: str = None save_function: Callable = None safe_serialization: bool = True **kwargs )
```

参数

+   `save_directory` (`str` or `os.PathLike`) — 保存注意力处理器的目录（如果不存在将被创建）。

+   `is_main_process` (`bool`, *optional*, defaults to `True`) — 调用此函数的进程是否为主进程。在分布式训练期间很有用，当您需要在所有进程上调用此函数时。在这种情况下，仅在主进程上设置`is_main_process=True`以避免竞争条件。

+   `save_function` (`Callable`) — 用于保存状态字典的函数。在分布式训练期间很有用，当您需要用另一种方法替换`torch.save`时。可以使用环境变量`DIFFUSERS_SAVE_MODE`进行配置。

+   `safe_serialization` (`bool`, *optional*, defaults to `True`) — 是否使用`safetensors`或`pickle`保存模型。

将注意力处理器层保存到目录中，以便可以使用 load_attn_procs()方法重新加载。

示例：

```py
import torch
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4",
    torch_dtype=torch.float16,
).to("cuda")
pipeline.unet.load_attn_procs("path-to-save-model", weight_name="pytorch_custom_diffusion_weights.bin")
pipeline.unet.save_attn_procs("path-to-save-model", weight_name="pytorch_custom_diffusion_weights.bin")
```

#### `set_adapters`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/unet.py#L567)

```py
( adapter_names: Union weights: Union = None )
```

参数

+   `adapter_names` (`List[str]` or `str`) — 要使用的适配器的名称。

+   `adapter_weights` (`Union[List[float], float]`, *optional*) — 用于 UNet 的适配器权重。如果为`None`，则所有适配器的权重设置为`1.0`。

设置 UNet 中当前活动的适配器。

示例：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
).to("cuda")
pipeline.load_lora_weights(
    "jbilcke-hf/sdxl-cinematic-1", weight_name="pytorch_lora_weights.safetensors", adapter_name="cinematic"
)
pipeline.load_lora_weights("nerijs/pixel-art-xl", weight_name="pixel-art-xl.safetensors", adapter_name="pixel")
pipeline.set_adapters(["cinematic", "pixel"], adapter_weights=[0.5, 0.5])
```
