# ä¿®å¤

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/diffusers/using-diffusers/inpaint`](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)

ä¿®å¤æ›¿æ¢æˆ–ç¼–è¾‘å›¾åƒçš„ç‰¹å®šåŒºåŸŸã€‚è¿™ä½¿å¾—å®ƒæˆä¸ºåƒå»é™¤ç¼ºé™·å’Œä¼ªå½±ï¼Œç”šè‡³ç”¨å…¨æ–°å†…å®¹æ›¿æ¢å›¾åƒåŒºåŸŸç­‰å›¾åƒæ¢å¤çš„æœ‰ç”¨å·¥å…·ã€‚ä¿®å¤ä¾èµ–äºè’™ç‰ˆæ¥ç¡®å®šè¦å¡«å……å›¾åƒçš„å“ªäº›åŒºåŸŸï¼›è¦ä¿®å¤çš„åŒºåŸŸç”±ç™½è‰²åƒç´ è¡¨ç¤ºï¼Œè¦ä¿ç•™çš„åŒºåŸŸç”±é»‘è‰²åƒç´ è¡¨ç¤ºã€‚ç™½è‰²åƒç´ ç”±æç¤ºå¡«å……ã€‚

ä½¿ç”¨ğŸ¤— Diffusersï¼Œä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥è¿›è¡Œä¿®å¤çš„æ–¹æ³•ï¼š

1.  ä½¿ç”¨ AutoPipelineForInpainting ç±»åŠ è½½ä¿®å¤æ£€æŸ¥ç‚¹ã€‚è¿™å°†æ ¹æ®æ£€æŸ¥ç‚¹è‡ªåŠ¨æ£€æµ‹è¦åŠ è½½çš„é€‚å½“ç®¡é“ç±»ï¼š

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()
```

åœ¨æ•´ä¸ªæŒ‡å—ä¸­ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°æˆ‘ä»¬ä½¿ç”¨ enable_model_cpu_offload()å’Œ enable_xformers_memory_efficient_attention()ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶æé«˜æ¨ç†é€Ÿåº¦ã€‚å¦‚æœæ‚¨ä½¿ç”¨ PyTorch 2.0ï¼Œåˆ™ä¸éœ€è¦åœ¨ç®¡é“ä¸Šè°ƒç”¨ enable_xformers_memory_efficient_attention()ï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 çš„æœ¬æœº scaled-dot product attentionã€‚

1.  åŠ è½½åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒï¼š

```py
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")
```

1.  åˆ›å»ºä¸€ä¸ªç”¨äºä¿®å¤å›¾åƒçš„æç¤ºï¼Œå¹¶å°†å…¶ä¼ é€’ç»™å…·æœ‰åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒçš„ç®¡é“ï¼š

```py
prompt = "a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k"
negative_prompt = "bad anatomy, deformed, ugly, disfigured"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

![](img/e54493b4e03ab58931aa2b35535a314d.png)

åŸºç¡€å›¾åƒ

![](img/50397365c167c77e28b112edb22eb879.png)

è’™ç‰ˆå›¾åƒ

![](img/53b76ec0efb1b6851d4c8b23347a3f52.png)

ç”Ÿæˆçš„å›¾åƒ

## åˆ›å»ºä¸€ä¸ªè’™ç‰ˆå›¾åƒ

åœ¨æ•´ä¸ªæŒ‡å—ä¸­ï¼Œè’™ç‰ˆå›¾åƒåœ¨æ‰€æœ‰ä»£ç ç¤ºä¾‹ä¸­éƒ½æä¾›äº†ï¼Œä»¥æ–¹ä¾¿ä½¿ç”¨ã€‚æ‚¨å¯ä»¥å¯¹è‡ªå·±çš„å›¾åƒè¿›è¡Œä¿®å¤ï¼Œä½†éœ€è¦ä¸ºå…¶åˆ›å»ºä¸€ä¸ªè’™ç‰ˆå›¾åƒã€‚ä½¿ç”¨ä¸‹é¢çš„ç©ºé—´è½»æ¾åˆ›å»ºä¸€ä¸ªè’™ç‰ˆå›¾åƒã€‚

ä¸Šä¼ ä¸€ä¸ªåŸºç¡€å›¾åƒè¿›è¡Œä¿®å¤ï¼Œå¹¶ä½¿ç”¨è‰å›¾å·¥å…·ç»˜åˆ¶è’™ç‰ˆã€‚å®Œæˆåï¼Œç‚¹å‡»**è¿è¡Œ**ç”Ÿæˆå¹¶ä¸‹è½½è’™ç‰ˆå›¾åƒã€‚

[`stevhliu-inpaint-mask-maker.hf.space`](https://stevhliu-inpaint-mask-maker.hf.space)

### è’™ç‰ˆæ¨¡ç³Š

`~VaeImageProcessor.blur`æ–¹æ³•æä¾›äº†å¦‚ä½•æ··åˆåŸå§‹å›¾åƒå’Œä¿®å¤åŒºåŸŸçš„é€‰é¡¹ã€‚æ¨¡ç³Šç¨‹åº¦ç”±`blur_factor`å‚æ•°ç¡®å®šã€‚å¢åŠ `blur_factor`ä¼šå¢åŠ åº”ç”¨äºè’™ç‰ˆè¾¹ç¼˜çš„æ¨¡ç³Šé‡ï¼Œè½¯åŒ–åŸå§‹å›¾åƒå’Œä¿®å¤åŒºåŸŸä¹‹é—´çš„è¿‡æ¸¡ã€‚ä½æˆ–é›¶çš„`blur_factor`ä¼šä¿ç•™è’™ç‰ˆçš„æ›´æ¸…æ™°è¾¹ç¼˜ã€‚

è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨å›¾åƒå¤„ç†å™¨åˆ›å»ºä¸€ä¸ªæ¨¡ç³Šçš„è’™ç‰ˆã€‚

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
from PIL import Image

pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to('cuda')

mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png")
blurred_mask = pipeline.mask_processor.blur(mask, blur_factor=33)
blurred_mask
```

![](img/bd4255378e4be6f2da63ef7b2951ac46.png)

æ— æ¨¡ç³Šçš„è’™ç‰ˆ

![](img/8a2ec7820a1b085328cbab8c7625a7d0.png)

åº”ç”¨äº†æ¨¡ç³Šçš„è’™ç‰ˆ

## çƒ­é—¨æ¨¡å‹

[ç¨³å®šæ‰©æ•£ä¿®å¤](https://huggingface.co/runwayml/stable-diffusion-inpainting)ã€[ç¨³å®šæ‰©æ•£ XLï¼ˆSDXLï¼‰ä¿®å¤](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1)å’Œ[Kandinsky 2.2 ä¿®å¤](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint)æ˜¯ä¿®å¤ä¸­æœ€å—æ¬¢è¿çš„æ¨¡å‹ä¹‹ä¸€ã€‚SDXL é€šå¸¸æ¯”ç¨³å®šæ‰©æ•£ v1.5 ç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒï¼Œè€Œ Kandinsky 2.2 ä¹Ÿèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚

### ç¨³å®šæ‰©æ•£ä¿®å¤

ç¨³å®šæ‰©æ•£ä¿®å¤æ˜¯ä¸€ä¸ªåœ¨ä¿®å¤ä¸Šè¿›è¡Œå¾®è°ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œé€‚ç”¨äº 512x512 å›¾åƒã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œå› ä¸ºå®ƒç›¸å¯¹å¿«é€Ÿå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚è¦å°†æ­¤æ¨¡å‹ç”¨äºä¿®å¤ï¼Œæ‚¨éœ€è¦å°†æç¤ºã€åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒä¼ é€’ç»™ç®¡é“ï¼š

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### ç¨³å®šæ‰©æ•£ XLï¼ˆSDXLï¼‰ä¿®å¤

SDXL æ˜¯ç¨³å®šæ‰©æ•£ v1.5 çš„æ›´å¤§æ›´å¼ºå¤§çš„ç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹å¯ä»¥éµå¾ªä¸¤é˜¶æ®µæ¨¡å‹è¿‡ç¨‹ï¼ˆå°½ç®¡æ¯ä¸ªæ¨¡å‹ä¹Ÿå¯ä»¥å•ç‹¬ä½¿ç”¨ï¼‰ï¼›åŸºç¡€æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œç²¾åŒ–æ¨¡å‹æ¥æ”¶è¯¥å›¾åƒå¹¶è¿›ä¸€æ­¥å¢å¼ºå…¶ç»†èŠ‚å’Œè´¨é‡ã€‚æŸ¥çœ‹ SDXL æŒ‡å—ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨ SDXL å¹¶é…ç½®å…¶å‚æ•°çš„æ›´å…¨é¢æŒ‡å—ã€‚

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "diffusers/stable-diffusion-xl-1.0-inpainting-0.1", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### Kandinsky 2.2 ä¿®å¤

Kandinsky æ¨¡å‹ç³»åˆ—ç±»ä¼¼äº SDXLï¼Œå› ä¸ºå®ƒä¹Ÿä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹ï¼›å›¾åƒå…ˆéªŒæ¨¡å‹åˆ›å»ºå›¾åƒåµŒå…¥ï¼Œæ‰©æ•£æ¨¡å‹ä»ä¸­ç”Ÿæˆå›¾åƒã€‚æ‚¨å¯ä»¥åˆ†åˆ«åŠ è½½å›¾åƒå…ˆéªŒå’Œæ‰©æ•£æ¨¡å‹ï¼Œä½†ä½¿ç”¨ Kandinsky 2.2 çš„æœ€ç®€å•æ–¹æ³•æ˜¯å°†å…¶åŠ è½½åˆ° AutoPipelineForInpainting ç±»ä¸­ï¼Œè¯¥ç±»åœ¨åº•å±‚ä½¿ç”¨ KandinskyV22InpaintCombinedPipelineã€‚

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

![](img/e54493b4e03ab58931aa2b35535a314d.png)

åŸºç¡€å›¾åƒ

![](img/09fbce513beddef5b655c0a444a3c86c.png)

ç¨³å®šæ‰©æ•£ä¿®å¤

![](img/2489c89cec0d33d1acc14b3011bf03c9.png)

ç¨³å®šæ‰©æ•£ XL ä¿®å¤

![](img/44c50c30f2c0b8b5adb606ae538dbb54.png)

Kandinsky 2.2 ä¿®å¤

## éä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæœ¬æŒ‡å—å·²ä½¿ç”¨ä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹ï¼Œå¦‚[runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)ã€‚ä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œå¦‚[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)ã€‚è®©æˆ‘ä»¬æ¯”è¾ƒè¿™ä¸¤ä¸ªæ£€æŸ¥ç‚¹çš„ç»“æœã€‚

å·¦ä¾§çš„å›¾åƒæ˜¯ä»å¸¸è§„æ£€æŸ¥ç‚¹ç”Ÿæˆçš„ï¼Œå³ä¾§çš„å›¾åƒæ˜¯ä»ä¿®å¤æ£€æŸ¥ç‚¹ç”Ÿæˆçš„ã€‚æ‚¨ä¼šç«‹å³æ³¨æ„åˆ°å·¦ä¾§çš„å›¾åƒä¸å¤Ÿæ¸…æ™°ï¼Œä»ç„¶å¯ä»¥çœ‹åˆ°æ¨¡å‹åº”è¯¥ä¿®å¤çš„åŒºåŸŸçš„è½®å»“ã€‚å³ä¾§çš„å›¾åƒæ›´æ¸…æ™°ï¼Œä¿®å¤åŒºåŸŸçœ‹èµ·æ¥æ›´è‡ªç„¶ã€‚

runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpainting

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](img/5a890789342f9e1a86868211a7896271.png)

runwayml/stable-diffusion-v1-5

![](img/aecbb44542e32cda8ce2bb2da3d692e3.png)

runwayml/stable-diffusion-inpainting

ç„¶è€Œï¼Œå¯¹äºæ›´åŸºæœ¬çš„ä»»åŠ¡ï¼Œæ¯”å¦‚ä»å›¾åƒä¸­æ“¦é™¤ä¸€ä¸ªå¯¹è±¡ï¼ˆæ¯”å¦‚é“è·¯ä¸Šçš„å²©çŸ³ï¼‰ï¼Œå¸¸è§„æ£€æŸ¥ç‚¹ä¼šäº§ç”Ÿç›¸å½“ä¸é”™çš„ç»“æœã€‚å¸¸è§„æ£€æŸ¥ç‚¹å’Œä¿®å¤æ£€æŸ¥ç‚¹ä¹‹é—´çš„å·®å¼‚ä¸å¤ªæ˜æ˜¾ã€‚

runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpaint

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png")

image = pipeline(prompt="road", image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](img/f49798dfa50ce8a7c46fe18a6da38589.png)

runwayml/stable-diffusion-v1-5

![](img/c59fac74bc905b0800d717d2ce675c20.png)

runwayml/stable-diffusion-inpainting

ä½¿ç”¨éä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹çš„æŠ˜è¡·æ˜¯æ•´ä½“å›¾åƒè´¨é‡å¯èƒ½è¾ƒä½ï¼Œä½†é€šå¸¸å€¾å‘äºä¿ç•™è’™ç‰ˆåŒºåŸŸï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨å¯ä»¥çœ‹åˆ°è’™ç‰ˆè½®å»“ï¼‰ã€‚ä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹ç»è¿‡æœ‰æ„è®­ç»ƒï¼Œä»¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„ä¿®å¤å›¾åƒï¼Œè¿™åŒ…æ‹¬åœ¨è’™ç‰ˆå’Œéè’™ç‰ˆåŒºåŸŸä¹‹é—´åˆ›å»ºæ›´è‡ªç„¶çš„è¿‡æ¸¡ã€‚å› æ­¤ï¼Œè¿™äº›æ£€æŸ¥ç‚¹æ›´æœ‰å¯èƒ½æ”¹å˜æ‚¨çš„éè’™ç‰ˆåŒºåŸŸã€‚

å¦‚æœä¿ç•™éè’™ç‰ˆåŒºåŸŸå¯¹æ‚¨çš„ä»»åŠ¡å¾ˆé‡è¦ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`VaeImageProcessor.apply_overlay`æ–¹æ³•ï¼Œå¼ºåˆ¶å›¾åƒçš„éè’™ç‰ˆåŒºåŸŸä¿æŒä¸å˜ï¼Œä½†ä¼šä»¥ä¸€äº›æ›´ä¸è‡ªç„¶çš„è¿‡æ¸¡ä¸ºä»£ä»·ã€‚

```py
import PIL
import numpy as np
import torch

from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

device = "cuda"
pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    torch_dtype=torch.float16,
)
pipeline = pipeline.to(device)

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
repainted_image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]
repainted_image.save("repainted_image.png")

unmasked_unchanged_image = pipeline.image_processor.apply_overlay(mask_image, init_image, repainted_image)
unmasked_unchanged_image.save("force_unmasked_unchanged.png")
make_image_grid([init_image, mask_image, repainted_image, unmasked_unchanged_image], rows=2, cols=2)
```

## é…ç½®ç®¡é“å‚æ•°

å›¾åƒç‰¹å¾ - å¦‚è´¨é‡å’Œâ€œåˆ›é€ åŠ›â€ - å–å†³äºç®¡é“å‚æ•°ã€‚äº†è§£è¿™äº›å‚æ•°çš„ä½œç”¨å¯¹äºè·å¾—æƒ³è¦çš„ç»“æœå¾ˆé‡è¦ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æœ€é‡è¦çš„å‚æ•°ï¼Œå¹¶äº†è§£æ›´æ”¹å®ƒä»¬å¦‚ä½•å½±å“è¾“å‡ºã€‚

### å¼ºåº¦

`å¼ºåº¦`æ˜¯è¡¡é‡å‘åŸºç¡€å›¾åƒæ·»åŠ å¤šå°‘å™ªéŸ³çš„æŒ‡æ ‡ï¼Œè¿™å½±å“è¾“å‡ºä¸åŸºç¡€å›¾åƒçš„ç›¸ä¼¼ç¨‹åº¦ã€‚

+   ğŸ“ˆ é«˜`å¼ºåº¦`å€¼æ„å‘³ç€å‘å›¾åƒæ·»åŠ æ›´å¤šå™ªéŸ³ï¼Œå»å™ªè¿‡ç¨‹éœ€è¦æ›´é•¿æ—¶é—´ï¼Œä½†æ‚¨å°†è·å¾—è´¨é‡æ›´é«˜ä¸”ä¸åŸºç¡€å›¾åƒä¸åŒçš„å›¾åƒ

+   ğŸ“‰ ä½`å¼ºåº¦`å€¼æ„å‘³ç€å‘å›¾åƒæ·»åŠ çš„å™ªéŸ³è¾ƒå°‘ï¼Œå»å™ªè¿‡ç¨‹æ›´å¿«ï¼Œä½†å›¾åƒè´¨é‡å¯èƒ½ä¸ä¼šå¾ˆå¥½ï¼Œç”Ÿæˆçš„å›¾åƒæ›´ç±»ä¼¼äºåŸºç¡€å›¾åƒ

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.6).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

![](img/39f952b5e61ce473b5fc8dab92c18466.png)

å¼ºåº¦ = 0.6

![](img/ba1cef420a7d6632e8dad96029906868.png)

å¼ºåº¦ = 0.8

![](img/b42b3e014dc563c0005c55a35f02fba9.png)

å¼ºåº¦ = 1.0

### å¼•å¯¼æ¯”ä¾‹

`guidance_scale`å½±å“æ–‡æœ¬æç¤ºå’Œç”Ÿæˆå›¾åƒçš„å¯¹é½ç¨‹åº¦ã€‚

+   ğŸ“ˆ é«˜`guidance_scale`å€¼æ„å‘³ç€æç¤ºå’Œç”Ÿæˆçš„å›¾åƒç´§å¯†å¯¹é½ï¼Œå› æ­¤è¾“å‡ºæ˜¯å¯¹æç¤ºçš„æ›´ä¸¥æ ¼è§£é‡Š

+   ğŸ“‰ ä½`guidance_scale`å€¼æ„å‘³ç€æç¤ºå’Œç”Ÿæˆçš„å›¾åƒæ›´æ¾æ•£å¯¹é½ï¼Œå› æ­¤è¾“å‡ºå¯èƒ½ä¸æç¤ºæ›´ä¸ºä¸åŒ

æ‚¨å¯ä»¥åŒæ—¶ä½¿ç”¨`å¼ºåº¦`å’Œ`guidance_scale`æ¥æ›´å¥½åœ°æ§åˆ¶æ¨¡å‹çš„è¡¨ç°ã€‚ä¾‹å¦‚ï¼Œé«˜`å¼ºåº¦`å’Œ`guidance_scale`å€¼çš„ç»„åˆç»™äºˆæ¨¡å‹æœ€å¤§çš„åˆ›é€ è‡ªç”±åº¦ã€‚

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, guidance_scale=2.5).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

![](img/363406b3094071baef896b0e11a247cb.png)

guidance_scale = 2.5

![](img/0d10a98f98590aa92471ef3aabf758c6.png)

guidance_scale = 7.5

![](img/e32bf623e4fd55de7bce1266f480fffb.png)

guidance_scale = 12.5

### è´Ÿæç¤º

è´Ÿæç¤ºæ‰®æ¼”ä¸æç¤ºç›¸åè§’è‰²çš„ä½œç”¨ï¼›å®ƒå¼•å¯¼æ¨¡å‹è¿œç¦»åœ¨å›¾åƒä¸­ç”ŸæˆæŸäº›å†…å®¹ã€‚è¿™å¯¹äºå¿«é€Ÿæ”¹å–„å›¾åƒè´¨é‡å¹¶é˜²æ­¢æ¨¡å‹ç”Ÿæˆæ‚¨ä¸æƒ³è¦çš„å†…å®¹éå¸¸æœ‰ç”¨ã€‚

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
negative_prompt = "bad architecture, unstable, poor details, blurry"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

![](img/a9e6a070339236ad42e15252d8be37a7.png)

negative_prompt = "bad architecture, unstable, poor details, blurry"

### å¡«å……è’™ç‰ˆè£å‰ª

å¢åŠ ä¿®å¤å›¾åƒè´¨é‡çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨[`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop)å‚æ•°ã€‚å¯ç”¨æ­¤é€‰é¡¹åï¼Œè¯¥é€‰é¡¹å°†ä½¿ç”¨ä¸€äº›ç”¨æˆ·æŒ‡å®šçš„å¡«å……è£å‰ªæ©ç åŒºåŸŸï¼Œå¹¶ä¸”è¿˜å°†ä»åŸå§‹å›¾åƒä¸­è£å‰ªç›¸åŒåŒºåŸŸã€‚å›¾åƒå’Œæ©ç éƒ½å°†è¢«æ”¾å¤§åˆ°æ›´é«˜çš„åˆ†è¾¨ç‡è¿›è¡Œä¿®å¤ï¼Œç„¶åè¦†ç›–åœ¨åŸå§‹å›¾åƒä¸Šã€‚è¿™æ˜¯ä¸€ç§å¿«é€Ÿç®€ä¾¿çš„æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸ä½¿ç”¨å•ç‹¬çš„ç®¡é“ï¼ˆå¦‚ StableDiffusionUpscalePipelineï¼‰çš„æƒ…å†µä¸‹æ”¹å–„å›¾åƒè´¨é‡ã€‚

åœ¨ç®¡é“è°ƒç”¨ä¸­æ·»åŠ `padding_mask_crop`å‚æ•°ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºæ‰€éœ€çš„å¡«å……å€¼ã€‚

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
from PIL import Image

generator = torch.Generator(device='cuda').manual_seed(0)
pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to('cuda')

base = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore.png")
mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png")

image = pipeline("boat", image=base, mask_image=mask, strength=0.75, generator=generator, padding_mask_crop=32).images[0]
image
```

![](img/1770d17f089e4087ecdf844bc2f75ad6.png)

é»˜è®¤ä¿®å¤å›¾åƒ

![](img/f4ef40443043de12e889be5caf4c9289.png)

å¯ç”¨`padding_mask_crop`å¯¹å›¾åƒè¿›è¡Œä¿®å¤

## é“¾æ¥ä¿®å¤ç®¡é“

AutoPipelineForInpainting å¯ä»¥ä¸å…¶ä»–ğŸ¤— Diffusers ç®¡é“é“¾æ¥ä»¥ç¼–è¾‘å®ƒä»¬çš„è¾“å‡ºã€‚è¿™é€šå¸¸å¯¹äºæ”¹å–„å…¶ä»–æ‰©æ•£ç®¡é“çš„è¾“å‡ºè´¨é‡å¾ˆæœ‰ç”¨ï¼Œå¦‚æœæ‚¨ä½¿ç”¨å¤šä¸ªç®¡é“ï¼Œåˆ™å°†å®ƒä»¬é“¾æ¥åœ¨ä¸€èµ·ä»¥ä¿æŒè¾“å‡ºåœ¨æ½œåœ¨ç©ºé—´ä¸­å¹¶é‡å¤ä½¿ç”¨ç›¸åŒçš„ç®¡é“ç»„ä»¶å¯èƒ½æ›´èŠ‚çœå†…å­˜ã€‚

### æ–‡æœ¬åˆ°å›¾åƒåˆ°ä¿®å¤

é“¾æ¥æ–‡æœ¬åˆ°å›¾åƒå’Œä¿®å¤ç®¡é“å…è®¸æ‚¨ä¿®å¤ç”Ÿæˆçš„å›¾åƒï¼Œè€Œæ— éœ€æä¾›åŸºç¡€å›¾åƒã€‚è¿™ä½¿å¾—ç¼–è¾‘æ‚¨å–œæ¬¢çš„æ–‡æœ¬åˆ°å›¾åƒè¾“å‡ºå˜å¾—æ›´åŠ æ–¹ä¾¿ï¼Œè€Œæ— éœ€ç”Ÿæˆå…¨æ–°çš„å›¾åƒã€‚

ä»æ–‡æœ¬åˆ°å›¾åƒç®¡é“å¼€å§‹åˆ›å»ºä¸€ä¸ªåŸå ¡ï¼š

```py
import torch
from diffusers import AutoPipelineForText2Image, AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k").images[0]
```

åŠ è½½ä¸Šè¿°è¾“å‡ºçš„è’™ç‰ˆå›¾åƒï¼š

```py
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_text-chain-mask.png")
```

ç„¶åè®©æˆ‘ä»¬ç”¨ç€‘å¸ƒå¡«è¡¥è’™ç‰ˆåŒºåŸŸï¼š

```py
pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "digital painting of a fantasy waterfall, cloudy"
image = pipeline(prompt=prompt, image=text2image, mask_image=mask_image).images[0]
make_image_grid([text2image, mask_image, image], rows=1, cols=3)
```

![](img/2cc5fc0f54d60ce54294305f4a65f5b2.png)

æ–‡æœ¬åˆ°å›¾åƒ

![](img/b685c42746dfa11241d879c1e331fac2.png)

ä¿®å¤

### ä¿®å¤åˆ°å›¾åƒåˆ°å›¾åƒ

æ‚¨è¿˜å¯ä»¥åœ¨å¦ä¸€ä¸ªç®¡é“ä¹‹å‰é“¾æ¥ä¸€ä¸ªä¿®å¤ç®¡é“ï¼Œå¦‚å›¾åƒåˆ°å›¾åƒæˆ–ä¸€ä¸ªæ”¾å¤§å™¨ï¼Œä»¥æé«˜è´¨é‡ã€‚

ä»ä¿®å¤å›¾åƒå¼€å§‹ï¼š

```py
import torch
from diffusers import AutoPipelineForInpainting, AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image_inpainting = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]

# resize image to 1024x1024 for SDXL
image_inpainting = image_inpainting.resize((1024, 1024))
```

ç°åœ¨è®©æˆ‘ä»¬å°†å›¾åƒä¼ é€’ç»™å¦ä¸€ä¸ªä¿®å¤ç®¡é“ï¼Œä½¿ç”¨ SDXL çš„ç»†åŒ–æ¨¡å‹å¢å¼ºå›¾åƒçš„ç»†èŠ‚å’Œè´¨é‡ï¼š

```py
pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image_inpainting, mask_image=mask_image, output_type="latent").images[0]
```

åœ¨ç®¡é“ä¸­æŒ‡å®š`output_type="latent"`éå¸¸é‡è¦ï¼Œä»¥å°†æ‰€æœ‰è¾“å‡ºä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œé¿å…ä¸å¿…è¦çš„è§£ç -ç¼–ç æ­¥éª¤ã€‚è¿™ä»…åœ¨é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„ VAE æ—¶æ‰æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼Œåœ¨ Text-to-image-to-inpaint éƒ¨åˆ†ä¸­ï¼ŒKandinsky 2.2 ä½¿ç”¨ä¸ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸åŒçš„ VAE ç±»ï¼Œå› æ­¤ä¸èµ·ä½œç”¨ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨å¯¹ä¸¤ä¸ªç®¡é“éƒ½ä½¿ç”¨ç¨³å®šæ‰©æ•£ v1.5ï¼Œåˆ™å¯ä»¥å°†æ‰€æœ‰å†…å®¹ä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä½¿ç”¨ AutoencoderKLã€‚

æœ€åï¼Œæ‚¨å¯ä»¥å°†æ­¤å›¾åƒä¼ é€’ç»™å›¾åƒåˆ°å›¾åƒç®¡é“ï¼Œä»¥å®Œæˆæœ€åçš„æ¶¦è‰²ã€‚æœ€å¥½ä½¿ç”¨ from_pipe()æ–¹æ³•æ¥é‡ç”¨ç°æœ‰çš„ç®¡é“ç»„ä»¶ï¼Œé¿å…å†æ¬¡å°†æ‰€æœ‰ç®¡é“ç»„ä»¶åŠ è½½åˆ°å†…å­˜ä¸­ã€‚

```py
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline)
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image_inpainting, image], rows=2, cols=2)
```

![](img/e54493b4e03ab58931aa2b35535a314d.png)

åˆå§‹å›¾åƒ

![](img/5fec6ffc8bfc87edf18dd2bfa1e68bb5.png)

ä¿®å¤

![](img/ba2bb2403b87d4b1fb495bae370dc1c4.png)

å›¾åƒåˆ°å›¾åƒ

å›¾åƒåˆ°å›¾åƒå’Œä¿®å¤å®é™…ä¸Šæ˜¯éå¸¸ç›¸ä¼¼çš„ä»»åŠ¡ã€‚å›¾åƒåˆ°å›¾åƒç”Ÿæˆä¸€ä¸ªç±»ä¼¼äºæä¾›çš„ç°æœ‰å›¾åƒçš„æ–°å›¾åƒã€‚ä¿®å¤ä¹Ÿæ˜¯åŒæ ·çš„æ“ä½œï¼Œä½†å®ƒåªè½¬æ¢ç”±è’™ç‰ˆå®šä¹‰çš„å›¾åƒåŒºåŸŸï¼Œå…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜ã€‚æ‚¨å¯ä»¥å°†ä¿®å¤è§†ä¸ºè¿›è¡Œç‰¹å®šæ›´æ”¹çš„æ›´ç²¾ç¡®å·¥å…·ï¼Œè€Œå›¾åƒåˆ°å›¾åƒåˆ™å…·æœ‰è¿›è¡Œæ›´å¹¿æ³›æ›´æ”¹çš„æ›´å¹¿æ³›èŒƒå›´ã€‚

## æ§åˆ¶å›¾åƒç”Ÿæˆ

è®©å›¾åƒçœ‹èµ·æ¥å®Œå…¨ç¬¦åˆæ‚¨çš„è¦æ±‚æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºå»å™ªè¿‡ç¨‹æ˜¯éšæœºçš„ã€‚è™½ç„¶æ‚¨å¯ä»¥é€šè¿‡é…ç½®è¯¸å¦‚`negative_prompt`ä¹‹ç±»çš„å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆçš„æŸäº›æ–¹é¢ï¼Œä½†æœ‰æ›´å¥½æ›´æœ‰æ•ˆçš„æ–¹æ³•æ¥æ§åˆ¶å›¾åƒç”Ÿæˆã€‚

### æç¤ºåŠ æƒ

æç¤ºåŠ æƒæä¾›äº†ä¸€ç§å¯é‡åŒ–çš„æ–¹å¼æ¥è°ƒæ•´æç¤ºä¸­æ¦‚å¿µçš„è¡¨ç¤ºã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥å¢åŠ æˆ–å‡å°‘æç¤ºä¸­æ¯ä¸ªæ¦‚å¿µçš„æ–‡æœ¬åµŒå…¥å‘é‡çš„å¤§å°ï¼Œä»è€Œç¡®å®šç”Ÿæˆæ¯ä¸ªæ¦‚å¿µçš„æ•°é‡ã€‚[Compel](https://github.com/damian0815/compel)åº“æä¾›äº†ä¸€ç§ç›´è§‚çš„è¯­æ³•ï¼Œç”¨äºè°ƒæ•´æç¤ºæƒé‡å¹¶ç”ŸæˆåµŒå…¥ã€‚äº†è§£å¦‚ä½•åœ¨ Prompt weighting æŒ‡å—ä¸­åˆ›å»ºåµŒå…¥ã€‚

ç”ŸæˆåµŒå…¥åï¼Œå°†å®ƒä»¬ä¼ é€’ç»™ AutoPipelineForInpainting ä¸­çš„`prompt_embeds`ï¼ˆå¦‚æœæ‚¨ä½¿ç”¨è´Ÿæç¤ºï¼Œåˆ™è¿˜æœ‰`negative_prompt_embeds`ï¼‰å‚æ•°ã€‚åµŒå…¥æ›¿æ¢äº†`prompt`å‚æ•°ï¼š

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, # generated from Compel
    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel
    image=init_image,
    mask_image=mask_image
).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### ControlNet

ControlNet æ¨¡å‹ä¸å…¶ä»–æ‰©æ•£æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼Œå¦‚ç¨³å®šæ‰©æ•£ï¼Œå®ƒä»¬æä¾›äº†ä¸€ç§æ›´çµæ´»å’Œå‡†ç¡®çš„æ–¹å¼æ¥æ§åˆ¶å›¾åƒçš„ç”Ÿæˆæ–¹å¼ã€‚ControlNet æ¥å—é¢å¤–çš„æ¡ä»¶å›¾åƒè¾“å…¥ï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹ä¿ç•™å…¶ä¸­çš„ç‰¹å¾ã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨åœ¨ä¿®å¤å›¾åƒä¸Šé¢„è®­ç»ƒçš„ ControlNet å¯¹å›¾åƒè¿›è¡Œæ¡ä»¶å¤„ç†ï¼š

```py
import torch
import numpy as np
from diffusers import ControlNetModel, StableDiffusionControlNetInpaintPipeline
from diffusers.utils import load_image, make_image_grid

# load ControlNet
controlnet = ControlNetModel.from_pretrained("lllyasviel/control_v11p_sd15_inpaint", torch_dtype=torch.float16, variant="fp16")

# pass ControlNet to the pipeline
pipeline = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

# prepare control image
def make_inpaint_condition(init_image, mask_image):
    init_image = np.array(init_image.convert("RGB")).astype(np.float32) / 255.0
    mask_image = np.array(mask_image.convert("L")).astype(np.float32) / 255.0

    assert init_image.shape[0:1] == mask_image.shape[0:1], "image and image_mask must have the same image size"
    init_image[mask_image > 0.5] = -1.0  # set as masked pixel
    init_image = np.expand_dims(init_image, 0).transpose(0, 3, 1, 2)
    init_image = torch.from_numpy(init_image)
    return init_image

control_image = make_inpaint_condition(init_image, mask_image)
```

ç°åœ¨ä»åŸºç¡€ã€è’™ç‰ˆå’Œæ§åˆ¶å›¾åƒç”Ÿæˆå›¾åƒã€‚æ‚¨ä¼šæ³¨æ„åˆ°ç”Ÿæˆçš„å›¾åƒä¸­å¼ºçƒˆä¿ç•™äº†åŸºç¡€å›¾åƒçš„ç‰¹å¾ã€‚

```py
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, control_image=control_image).images[0]
make_image_grid([init_image, mask_image, PIL.Image.fromarray(np.uint8(control_image[0][0])).convert('RGB'), image], rows=2, cols=2)
```

ä½ å¯ä»¥è¿›ä¸€æ­¥å°†å…¶ä¸å›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥èµ·æ¥ï¼Œåº”ç”¨ä¸€ä¸ªæ–°çš„[é£æ ¼](https://huggingface.co/nitrosocke/elden-ring-diffusion)ï¼š

```py
from diffusers import AutoPipelineForImage2Image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style castle" # include the token "elden ring style" in the prompt
negative_prompt = "bad architecture, deformed, disfigured, poor details"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image, image_elden_ring], rows=2, cols=2)
```

![](img/e54493b4e03ab58931aa2b35535a314d.png)

åˆå§‹å›¾åƒ

![](img/916b854bd12a25f80f4e9acf9e6601b6.png)

ControlNet inpaint

![](img/a9594334cac8c0320fd63c03f321d2de.png)

å›¾åƒåˆ°å›¾åƒ

## ä¼˜åŒ–

è¿è¡Œæ‰©æ•£æ¨¡å‹å¯èƒ½ä¼šå¾ˆå›°éš¾å’Œç¼“æ…¢ï¼Œå¦‚æœä½ çš„èµ„æºå—é™ï¼Œä½†é€šè¿‡ä¸€äº›ä¼˜åŒ–æŠ€å·§ï¼Œå°±ä¸å¿…å¦‚æ­¤ã€‚å…¶ä¸­ä¸€ä¸ªæœ€å¤§ï¼ˆä¹Ÿæ˜¯æœ€ç®€å•ï¼‰çš„ä¼˜åŒ–æ˜¯åˆ‡æ¢åˆ°å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶ã€‚å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ PyTorch 2.0ï¼Œç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ä¼šè‡ªåŠ¨å¯ç”¨ï¼Œä½ ä¸éœ€è¦åšå…¶ä»–ä»»ä½•äº‹æƒ…ã€‚å¯¹äºé PyTorch 2.0 ç”¨æˆ·ï¼Œä½ å¯ä»¥å®‰è£…å¹¶ä½¿ç”¨ xFormers çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å®ç°ã€‚è¿™ä¸¤ä¸ªé€‰é¡¹éƒ½å¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨é‡å¹¶åŠ é€Ÿæ¨æ–­ã€‚

ä½ è¿˜å¯ä»¥å°†æ¨¡å‹è½¬ç§»åˆ° CPU ä»¥èŠ‚çœæ›´å¤šå†…å­˜ï¼š

```py
+ pipeline.enable_xformers_memory_efficient_attention()
+ pipeline.enable_model_cpu_offload()
```

ä¸ºäº†è¿›ä¸€æ­¥åŠ å¿«æ¨æ–­ä»£ç çš„é€Ÿåº¦ï¼Œè¯·ä½¿ç”¨`torch_compile`ã€‚ä½ åº”è¯¥å°†`torch.compile`åŒ…è£…åœ¨ç®¡é“ä¸­æœ€å¯†é›†çš„ç»„ä»¶å‘¨å›´ï¼Œé€šå¸¸æ˜¯ UNetï¼š

```py
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```

åœ¨å‡å°‘å†…å­˜ä½¿ç”¨å’Œ Torch 2.0 æŒ‡å—ä¸­äº†è§£æ›´å¤šã€‚
