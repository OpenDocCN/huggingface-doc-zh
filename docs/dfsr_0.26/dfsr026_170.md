# æ½œåœ¨æ”¾å¤§å™¨

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale)

ç¨³å®šæ‰©æ•£æ½œåœ¨æ”¾å¤§å™¨æ¨¡å‹æ˜¯ç”±[Katherine Crowson](https://github.com/crowsonkb/k-diffusion)ä¸[Stability AI](https://stability.ai/)åˆä½œåˆ›å»ºçš„ã€‚å®ƒç”¨äºé€šè¿‡ 2 å€å¢åŠ è¾“å‡ºå›¾åƒçš„åˆ†è¾¨ç‡ï¼ˆæŸ¥çœ‹æ­¤æ¼”ç¤º[ç¬”è®°æœ¬](https://colab.research.google.com/drive/1o1qYJcFeywzCIdkfKJy7cTpgZTCM2EI4)ä»¥äº†è§£åŸå§‹å®ç°çš„æ¼”ç¤ºï¼‰ã€‚

è¯·ç¡®ä¿æŸ¥çœ‹ç¨³å®šæ‰©æ•£ Tips éƒ¨åˆ†ï¼Œä»¥äº†è§£å¦‚ä½•åœ¨è°ƒåº¦å™¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œå¹¶å¦‚ä½•æœ‰æ•ˆåœ°é‡ç”¨ç®¡é“ç»„ä»¶ï¼

å¦‚æœæ‚¨æœ‰å…´è¶£ä½¿ç”¨å®˜æ–¹æ£€æŸ¥ç‚¹æ¥æ‰§è¡Œä»»åŠ¡ï¼Œè¯·æ¢ç´¢[CompVis](https://huggingface.co/CompVis)ã€[Runway](https://huggingface.co/runwayml)å’Œ[Stability AI](https://huggingface.co/stabilityai) Hub ç»„ç»‡ï¼

## StableDiffusionLatentUpscalePipeline

### `class diffusers.StableDiffusionLatentUpscalePipeline`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L63)

```py
( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: EulerDiscreteScheduler )
```

å‚æ•°

+   `vae`ï¼ˆAutoencoderKLï¼‰â€”å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚

+   `text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)ï¼‰â€”å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚

+   `tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)ï¼‰â€”ä¸€ä¸ª`CLIPTokenizer`ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ã€‚

+   `unet`ï¼ˆUNet2DConditionModelï¼‰â€”ä¸€ä¸ª`UNet2DConditionModel`ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚

+   `scheduler`ï¼ˆSchedulerMixinï¼‰â€”ä¸`unet`ç»“åˆä½¿ç”¨çš„ EulerDiscreteSchedulerã€‚

é€šè¿‡å› å­ 2 æ”¾å¤§ç¨³å®šæ‰©æ•£è¾“å‡ºå›¾åƒåˆ†è¾¨ç‡çš„ç®¡é“ã€‚

è¯¥æ¨¡å‹ç»§æ‰¿è‡ª DiffusionPipelineã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£ä¸ºæ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚

è¯¥ç®¡é“è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š

+   from_single_file()ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L289)

```py
( prompt: Union image: Union = None num_inference_steps: int = 75 guidance_scale: float = 9.0 negative_prompt: Union = None generator: Union = None latents: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 ) â†’ export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple
```

å‚æ•°

+   `prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼‰â€”æŒ‡å¯¼å›¾åƒæ”¾å¤§çš„æç¤ºæˆ–æç¤ºã€‚

+   `image`ï¼ˆ`torch.FloatTensor`ï¼Œ`PIL.Image.Image`ï¼Œ`np.ndarray`ï¼Œ`List[torch.FloatTensor]`ï¼Œ`List[PIL.Image.Image]`æˆ–`List[np.ndarray]`ï¼‰â€”è¡¨ç¤ºè¦æ”¾å¤§çš„å›¾åƒæ‰¹æ¬¡çš„`Image`æˆ–å¼ é‡ã€‚å¦‚æœæ˜¯å¼ é‡ï¼Œåˆ™å¯ä»¥æ˜¯ç¨³å®šæ‰©æ•£æ¨¡å‹çš„æ½œåœ¨è¾“å‡ºï¼Œä¹Ÿå¯ä»¥æ˜¯èŒƒå›´ä¸º`[-1, 1]`çš„å›¾åƒå¼ é‡ã€‚å¦‚æœ`image.shape[1]`ä¸º`4`ï¼Œåˆ™è¢«è§†ä¸º`latent`ï¼›å¦åˆ™ï¼Œè¢«è§†ä¸ºå›¾åƒè¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨æ­¤ç®¡é“çš„`vae`ç¼–ç å™¨è¿›è¡Œç¼–ç ã€‚

+   `num_inference_steps`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 50ï¼‰â€”å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚

+   `guidance_scale` (`float`, *optional*, defaults to 7.5) â€” æ›´é«˜çš„æŒ‡å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ `prompt` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“ `guidance_scale > 1` æ—¶å¯ç”¨æŒ‡å¯¼æ¯”ä¾‹ã€‚

+   `negative_prompt` (`str` or `List[str]`, *optional*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…å«çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’ `negative_prompt_embeds`ã€‚å½“ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶ï¼ˆ`guidance_scale < 1` æ—¶ï¼‰ï¼Œå°†è¢«å¿½ç•¥ã€‚

+   `eta` (`float`, *optional*, defaults to 0.0) â€” å¯¹åº”äº [DDIM](https://arxiv.org/abs/2010.02502) è®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ã€‚ä»…é€‚ç”¨äº DDIMSchedulerï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚

+   `generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„ [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚

+   `latents` (`torch.FloatTensor`, *optional*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„é¢„ç”Ÿæˆå™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™å°†ä½¿ç”¨æä¾›çš„éšæœº `generator` è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚

+   `output_type` (`str`, *optional*, defaults to `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹© `PIL.Image` æˆ– `np.array` ä¹‹é—´çš„ä¸€ä¸ªã€‚

+   `return_dict` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¿”å› StableDiffusionPipelineOutput è€Œä¸æ˜¯æ™®é€šçš„ tupleã€‚

+   `callback` (`Callable`, *optional*) â€” ä¸€ä¸ªåœ¨æ¨æ–­è¿‡ç¨‹ä¸­æ¯ `callback_steps` æ­¥è°ƒç”¨ä¸€æ¬¡çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback(step: int, timestep: int, latents: torch.FloatTensor)`ã€‚

+   `callback_steps` (`int`, *optional*, defaults to 1) â€” `callback` å‡½æ•°è¢«è°ƒç”¨çš„é¢‘ç‡ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™åœ¨æ¯ä¸€æ­¥éƒ½ä¼šè°ƒç”¨å›è°ƒå‡½æ•°ã€‚

è¿”å›

StableDiffusionPipelineOutput æˆ– `tuple`

å¦‚æœ `return_dict` ä¸º `True`ï¼Œåˆ™è¿”å› StableDiffusionPipelineOutputï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª `tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ã€‚

ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from diffusers import StableDiffusionLatentUpscalePipeline, StableDiffusionPipeline
>>> import torch

>>> pipeline = StableDiffusionPipeline.from_pretrained(
...     "CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16
... )
>>> pipeline.to("cuda")

>>> model_id = "stabilityai/sd-x2-latent-upscaler"
>>> upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)
>>> upscaler.to("cuda")

>>> prompt = "a photo of an astronaut high resolution, unreal engine, ultra realistic"
>>> generator = torch.manual_seed(33)

>>> low_res_latents = pipeline(prompt, generator=generator, output_type="latent").images

>>> with torch.no_grad():
...     image = pipeline.decode_latents(low_res_latents)
>>> image = pipeline.numpy_to_pil(image)[0]

>>> image.save("../images/a1.png")

>>> upscaled_image = upscaler(
...     prompt=prompt,
...     image=low_res_latents,
...     num_inference_steps=20,
...     guidance_scale=0,
...     generator=generator,
... ).images[0]

>>> upscaled_image.save("../images/a2.png")
```

#### `enable_sequential_cpu_offload`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)

```py
( gpu_id: Optional = None device: Union = 'cuda' )
```

å‚æ•°

+   `gpu_id` (`int`, *optional*) â€” æ¨æ–­ä¸­è¦ä½¿ç”¨çš„åŠ é€Ÿå™¨çš„ IDã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º 0ã€‚

+   `device` (`torch.Device` or `str`, *optional*, defaults to â€œcudaâ€) â€” æ¨æ–­ä¸­è¦ä½¿ç”¨çš„åŠ é€Ÿå™¨çš„ PyTorch è®¾å¤‡ç±»å‹ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸ºâ€œcudaâ€ã€‚

ä½¿ç”¨ ğŸ¤— Accelerate å°†æ‰€æœ‰æ¨¡å‹è½¬ç§»åˆ° CPUï¼Œæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚è°ƒç”¨æ—¶ï¼Œæ‰€æœ‰ `torch.nn.Module` ç»„ä»¶çš„çŠ¶æ€å­—å…¸ï¼ˆé™¤äº† `self._exclude_from_cpu_offload` ä¸­çš„ç»„ä»¶ï¼‰å°†ä¿å­˜åˆ° CPUï¼Œç„¶åç§»åŠ¨åˆ° `torch.device('meta')`ï¼Œä»…åœ¨å…¶ç‰¹å®šå­æ¨¡å—è°ƒç”¨ `forward` æ–¹æ³•æ—¶æ‰åŠ è½½åˆ° GPUã€‚å¸è½½æ˜¯åŸºäºå­æ¨¡å—çš„ã€‚å†…å­˜èŠ‚çœé«˜äº `enable_model_cpu_offload`ï¼Œä½†æ€§èƒ½è¾ƒä½ã€‚

#### `enable_attention_slicing`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)

```py
( slice_size: Union = 'auto' )
```

å‚æ•°

+   `slice_size` (`str` æˆ– `int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"auto"`) â€” å½“ä¸º `"auto"` æ—¶ï¼Œå°†è¾“å…¥å‡åŠåˆ°æ³¨æ„åŠ›å¤´éƒ¨ï¼Œå› æ­¤æ³¨æ„åŠ›å°†åˆ†ä¸¤æ­¥è®¡ç®—ã€‚å¦‚æœä¸º `"max"`ï¼Œå°†é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥èŠ‚çœæœ€å¤§å†…å­˜é‡ã€‚å¦‚æœæä¾›ä¸€ä¸ªæ•°å­—ï¼Œåˆ™ä½¿ç”¨ `attention_head_dim // slice_size` ä½œä¸ºåˆ‡ç‰‡æ•°é‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`attention_head_dim` å¿…é¡»æ˜¯ `slice_size` çš„å€æ•°ã€‚

å¯ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆåˆ‡ç‰‡ï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—å°†æŒ‰é¡ºåºåœ¨æ¯ä¸ªå¤´ä¸Šæ‰§è¡Œã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜ä»¥æ¢å–å°å¹…åº¦é€Ÿåº¦é™ä½å¾ˆæœ‰ç”¨ã€‚

âš ï¸ å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 æˆ– xFormers ä¸­çš„ `scaled_dot_product_attention`ï¼ˆSDPAï¼‰ï¼Œè¯·ä¸è¦å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ã€‚è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸å†…å­˜é«˜æ•ˆï¼Œå› æ­¤æ‚¨ä¸éœ€è¦å¯ç”¨æ­¤åŠŸèƒ½ã€‚å¦‚æœæ‚¨åœ¨ä½¿ç”¨ SDPA æˆ– xFormers æ—¶å¯ç”¨äº†æ³¨æ„åŠ›åˆ‡ç‰‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡å‡é€Ÿï¼

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> pipe = StableDiffusionPipeline.from_pretrained(
...     "runwayml/stable-diffusion-v1-5",
...     torch_dtype=torch.float16,
...     use_safetensors=True,
... )

>>> prompt = "a photo of an astronaut riding a horse on mars"
>>> pipe.enable_attention_slicing()
>>> image = pipe(prompt).images[0]
```

#### `disable_attention_slicing`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)

```py
( )
```

ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº† `enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚

#### `enable_xformers_memory_efficient_attention`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)

```py
( attention_op: Optional = None )
```

å‚æ•°

+   `attention_op` (`Callable`, *å¯é€‰*) â€” ç”¨ä½œ `xFormers` çš„ [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention) å‡½æ•°çš„ `op` å‚æ•°çš„é»˜è®¤ `None` æ“ä½œç¬¦çš„è¦†ç›–ã€‚

å¯ç”¨æ¥è‡ª[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°æ›´ä½çš„ GPU å†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶ä¸”åœ¨æ¨æ–­æœŸé—´å¯èƒ½ä¼šåŠ é€Ÿã€‚è®­ç»ƒæœŸé—´çš„åŠ é€Ÿä¸è¢«ä¿è¯ã€‚

âš ï¸ å½“å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from diffusers import DiffusionPipeline
>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp

>>> pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16)
>>> pipe = pipe.to("cuda")
>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)
>>> # Workaround for not accepting attention shape using VAE for Flash Attention
>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)
```

#### `disable_xformers_memory_efficient_attention`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)

```py
( )
```

ç¦ç”¨æ¥è‡ª[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚

#### `disable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L285)

```py
( )
```

å¦‚æœå·²å¯ç”¨ï¼Œåˆ™ç¦ç”¨ FreeU æœºåˆ¶ã€‚

#### `enable_freeu`

[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L262)

```py
( s1: float s2: float b1: float b2: float )
```

å‚æ•°

+   `s1` (`float`) â€” ç”¨äºå‡å¼±è·³è·ƒç‰¹å¾è´¡çŒ®çš„ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚

+   `s2` (`float`) â€” ç”¨äºå‡å¼±è·³è·ƒç‰¹å¾è´¡çŒ®çš„ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚

+   `b1` (`float`) â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„ç¬¬ 1 é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚

+   `b2` (`float`) â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„ç¬¬ 2 é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚

å¯ç”¨ FreeU æœºåˆ¶ï¼Œå¦‚[`arxiv.org/abs/2309.11497`](https://arxiv.org/abs/2309.11497)ã€‚

ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬è¢«åº”ç”¨çš„é˜¶æ®µã€‚

è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion v1ã€v2 å’Œ Stable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚

## StableDiffusionPipelineOutput

### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)

```py
( images: Union nsfw_content_detected: Optional )
```

å‚æ•°

+   `images` (`List[PIL.Image.Image]` æˆ– `np.ndarray`) â€” é•¿åº¦ä¸º `batch_size` çš„å»å™ª PIL å›¾åƒåˆ—è¡¨æˆ–å½¢çŠ¶ä¸º `(batch_size, height, width, num_channels)` çš„ NumPy æ•°ç»„ã€‚

+   `nsfw_content_detected` (`List[bool]`) â€” åˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ï¼Œå¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º `None`ã€‚

ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚
