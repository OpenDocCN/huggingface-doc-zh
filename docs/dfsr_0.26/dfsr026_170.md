# 潜在放大器

> 原始文本：[`huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale)

稳定扩散潜在放大器模型是由[Katherine Crowson](https://github.com/crowsonkb/k-diffusion)与[Stability AI](https://stability.ai/)合作创建的。它用于通过 2 倍增加输出图像的分辨率（查看此演示[笔记本](https://colab.research.google.com/drive/1o1qYJcFeywzCIdkfKJy7cTpgZTCM2EI4)以了解原始实现的演示）。

请确保查看稳定扩散 Tips 部分，以了解如何在调度器速度和质量之间进行权衡，并如何有效地重用管道组件！

如果您有兴趣使用官方检查点来执行任务，请探索[CompVis](https://huggingface.co/CompVis)、[Runway](https://huggingface.co/runwayml)和[Stability AI](https://huggingface.co/stabilityai) Hub 组织！

## StableDiffusionLatentUpscalePipeline

### `class diffusers.StableDiffusionLatentUpscalePipeline`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L63)

```py
( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: EulerDiscreteScheduler )
```

参数

+   `vae`（AutoencoderKL）—变分自动编码器（VAE）模型，用于将图像编码和解码为潜在表示。

+   `text_encoder`（[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)）—冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。

+   `tokenizer`（[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)）—一个`CLIPTokenizer`用于对文本进行标记化。

+   `unet`（UNet2DConditionModel）—一个`UNet2DConditionModel`，用于去噪编码图像潜在特征。

+   `scheduler`（SchedulerMixin）—与`unet`结合使用的 EulerDiscreteScheduler。

通过因子 2 放大稳定扩散输出图像分辨率的管道。

该模型继承自 DiffusionPipeline。查看超类文档以了解为所有管道实现的通用方法（下载、保存、在特定设备上运行等）。

该管道还继承了以下加载方法：

+   from_single_file()用于加载`.ckpt`文件

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L289)

```py
( prompt: Union image: Union = None num_inference_steps: int = 75 guidance_scale: float = 9.0 negative_prompt: Union = None generator: Union = None latents: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 ) → export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple
```

参数

+   `prompt`（`str`或`List[str]`）—指导图像放大的提示或提示。

+   `image`（`torch.FloatTensor`，`PIL.Image.Image`，`np.ndarray`，`List[torch.FloatTensor]`，`List[PIL.Image.Image]`或`List[np.ndarray]`）—表示要放大的图像批次的`Image`或张量。如果是张量，则可以是稳定扩散模型的潜在输出，也可以是范围为`[-1, 1]`的图像张量。如果`image.shape[1]`为`4`，则被视为`latent`；否则，被视为图像表示，并使用此管道的`vae`编码器进行编码。

+   `num_inference_steps`（`int`，*可选*，默认为 50）—去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `guidance_scale` (`float`, *optional*, defaults to 7.5) — 更高的指导比例值鼓励模型生成与文本 `prompt` 密切相关的图像，但会降低图像质量。当 `guidance_scale > 1` 时启用指导比例。

+   `negative_prompt` (`str` or `List[str]`, *optional*) — 指导图像生成中不包含的提示。如果未定义，则需要传递 `negative_prompt_embeds`。当不使用指导时（`guidance_scale < 1` 时），将被忽略。

+   `eta` (`float`, *optional*, defaults to 0.0) — 对应于 [DDIM](https://arxiv.org/abs/2010.02502) 论文中的参数 eta (η)。仅适用于 DDIMScheduler，在其他调度程序中将被忽略。

+   `generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — 用于使生成过程确定性的 [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。

+   `latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中采样的预生成噪声潜变量，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则将使用提供的随机 `generator` 进行采样生成潜变量张量。

+   `output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择 `PIL.Image` 或 `np.array` 之间的一个。

+   `return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回 StableDiffusionPipelineOutput 而不是普通的 tuple。

+   `callback` (`Callable`, *optional*) — 一个在推断过程中每 `callback_steps` 步调用一次的函数。该函数将使用以下参数调用：`callback(step: int, timestep: int, latents: torch.FloatTensor)`。

+   `callback_steps` (`int`, *optional*, defaults to 1) — `callback` 函数被调用的频率。如果未指定，则在每一步都会调用回调函数。

返回

StableDiffusionPipelineOutput 或 `tuple`

如果 `return_dict` 为 `True`，则返回 StableDiffusionPipelineOutput，否则返回一个 `tuple`，其中第一个元素是包含生成图像的列表。

用于生成的管道的调用函数。

示例：

```py
>>> from diffusers import StableDiffusionLatentUpscalePipeline, StableDiffusionPipeline
>>> import torch

>>> pipeline = StableDiffusionPipeline.from_pretrained(
...     "CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16
... )
>>> pipeline.to("cuda")

>>> model_id = "stabilityai/sd-x2-latent-upscaler"
>>> upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)
>>> upscaler.to("cuda")

>>> prompt = "a photo of an astronaut high resolution, unreal engine, ultra realistic"
>>> generator = torch.manual_seed(33)

>>> low_res_latents = pipeline(prompt, generator=generator, output_type="latent").images

>>> with torch.no_grad():
...     image = pipeline.decode_latents(low_res_latents)
>>> image = pipeline.numpy_to_pil(image)[0]

>>> image.save("../images/a1.png")

>>> upscaled_image = upscaler(
...     prompt=prompt,
...     image=low_res_latents,
...     num_inference_steps=20,
...     guidance_scale=0,
...     generator=generator,
... ).images[0]

>>> upscaled_image.save("../images/a2.png")
```

#### `enable_sequential_cpu_offload`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)

```py
( gpu_id: Optional = None device: Union = 'cuda' )
```

参数

+   `gpu_id` (`int`, *optional*) — 推断中要使用的加速器的 ID。如果未指定，将默认为 0。

+   `device` (`torch.Device` or `str`, *optional*, defaults to “cuda”) — 推断中要使用的加速器的 PyTorch 设备类型。如果未指定，将默认为“cuda”。

使用 🤗 Accelerate 将所有模型转移到 CPU，显著减少内存使用。调用时，所有 `torch.nn.Module` 组件的状态字典（除了 `self._exclude_from_cpu_offload` 中的组件）将保存到 CPU，然后移动到 `torch.device('meta')`，仅在其特定子模块调用 `forward` 方法时才加载到 GPU。卸载是基于子模块的。内存节省高于 `enable_model_cpu_offload`，但性能较低。

#### `enable_attention_slicing`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)

```py
( slice_size: Union = 'auto' )
```

参数

+   `slice_size` (`str` 或 `int`，*可选*，默认为 `"auto"`) — 当为 `"auto"` 时，将输入减半到注意力头部，因此注意力将分两步计算。如果为 `"max"`，将通过一次只运行一个切片来节省最大内存量。如果提供一个数字，则使用 `attention_head_dim // slice_size` 作为切片数量。在这种情况下，`attention_head_dim` 必须是 `slice_size` 的倍数。

启用切片注意力计算。启用此选项时，注意力模块将输入张量分割成切片，以便在多个步骤中计算注意力。对于多个注意力头，计算将按顺序在每个头上执行。这对于节省一些内存以换取小幅度速度降低很有用。

⚠️ 如果您已经在使用 PyTorch 2.0 或 xFormers 中的 `scaled_dot_product_attention`（SDPA），请不要启用注意力切片。这些注意力计算已经非常内存高效，因此您不需要启用此功能。如果您在使用 SDPA 或 xFormers 时启用了注意力切片，可能会导致严重减速！

示例：

```py
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> pipe = StableDiffusionPipeline.from_pretrained(
...     "runwayml/stable-diffusion-v1-5",
...     torch_dtype=torch.float16,
...     use_safetensors=True,
... )

>>> prompt = "a photo of an astronaut riding a horse on mars"
>>> pipe.enable_attention_slicing()
>>> image = pipe(prompt).images[0]
```

#### `disable_attention_slicing`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)

```py
( )
```

禁用切片注意力计算。如果之前调用了 `enable_attention_slicing`，则注意力将在一步中计算。

#### `enable_xformers_memory_efficient_attention`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)

```py
( attention_op: Optional = None )
```

参数

+   `attention_op` (`Callable`, *可选*) — 用作 `xFormers` 的 [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention) 函数的 `op` 参数的默认 `None` 操作符的覆盖。

启用来自[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。启用此选项时，您应该观察到更低的 GPU 内存使用量，并且在推断期间可能会加速。训练期间的加速不被保证。

⚠️ 当内存高效注意力和切片注意力都启用时，内存高效注意力优先。

示例：

```py
>>> import torch
>>> from diffusers import DiffusionPipeline
>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp

>>> pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16)
>>> pipe = pipe.to("cuda")
>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)
>>> # Workaround for not accepting attention shape using VAE for Flash Attention
>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)
```

#### `disable_xformers_memory_efficient_attention`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)

```py
( )
```

禁用来自[xFormers](https://facebookresearch.github.io/xformers/)的内存高效注意力。

#### `disable_freeu`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L285)

```py
( )
```

如果已启用，则禁用 FreeU 机制。

#### `enable_freeu`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L262)

```py
( s1: float s2: float b1: float b2: float )
```

参数

+   `s1` (`float`) — 用于减弱跳跃特征贡献的第 1 阶段的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效应”。

+   `s2` (`float`) — 用于减弱跳跃特征贡献的第 2 阶段的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效应”。

+   `b1` (`float`) — 用于放大骨干特征贡献的第 1 阶段的缩放因子。

+   `b2` (`float`) — 用于放大骨干特征贡献的第 2 阶段的缩放因子。

启用 FreeU 机制，如[`arxiv.org/abs/2309.11497`](https://arxiv.org/abs/2309.11497)。

缩放因子后缀表示它们被应用的阶段。

请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同管道（如 Stable Diffusion v1、v2 和 Stable Diffusion XL）的值组合。

## StableDiffusionPipelineOutput

### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)

```py
( images: Union nsfw_content_detected: Optional )
```

参数

+   `images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为 `batch_size` 的去噪 PIL 图像列表或形状为 `(batch_size, height, width, num_channels)` 的 NumPy 数组。

+   `nsfw_content_detected` (`List[bool]`) — 列表，指示相应生成的图像是否包含“不安全内容”（nsfw），如果无法执行安全检查，则为 `None`。

稳定扩散管道的输出类。
