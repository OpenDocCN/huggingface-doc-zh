# ScoreSdeVeScheduler

> 原文：[`huggingface.co/docs/diffusers/api/schedulers/score_sde_ve`](https://huggingface.co/docs/diffusers/api/schedulers/score_sde_ve)

`ScoreSdeVeScheduler` 是一个方差爆炸的随机微分方程（SDE）调度器。它在 Yang Song、Jascha Sohl-Dickstein、Diederik P. Kingma、Abhishek Kumar、Stefano Ermon、Ben Poole 的论文[通过随机微分方程进行基于得分的生成建模](https://huggingface.co/papers/2011.13456)中介绍。

论文摘要为：

*从数据中创建噪声很容易；从噪声中创建数据是生成建模。我们提出了一种随机微分方程（SDE），通过缓慢注入噪声，将复杂数据分布平滑地转换为已知的先验分布，并且通过缓慢去除噪声的相应逆向时间 SDE，将先验分布转换回数据分布。关键是，逆向时间 SDE 仅取决于扰动数据分布的时间相关梯度场（即得分）。通过利用得分为基础的生成建模的进展，我们可以使用神经网络准确估计这些得分，并使用数值 SDE 求解器生成样本。我们展示了这个框架封装了得分为基础的生成建模和扩散概率建模中的先前方法，允许新的采样过程和新的建模能力。特别是，我们引入了一个预测校正框架，用于纠正离散化逆向时间 SDE 演变中的错误。我们还推导出一个等效的神经 ODE，从与 SDE 相同的分布中采样，但另外还能实现精确的似然计算和改进的采样效率。此外，我们提供了一种使用基于得分的模型解决逆问题的新方法，通过在类条件生成、图像修补和着色方面的实验进行演示。结合多个架构改进，我们在 CIFAR-10 上实现了无条件图像生成的创纪录性性能，Inception 得分为 9.89，FID 为 2.20，竞争性似然度为 2.99 bits/dim，并首次展示了对 1024 x 1024 图像的高保真生成，这是从基于得分的生成模型中实现的。*

## ScoreSdeVeScheduler

### `class diffusers.ScoreSdeVeScheduler`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L46)

```py
( num_train_timesteps: int = 2000 snr: float = 0.15 sigma_min: float = 0.01 sigma_max: float = 1348.0 sampling_eps: float = 1e-05 correct_steps: int = 1 )
```

参数

+   `num_train_timesteps` (`int`，默认为 1000）— 训练模型的扩散步数。

+   `snr` (`float`，默认为 0.15）— 一个系数，用于加权从`model_output`样本（来自网络）到随机噪声的步骤。

+   `sigma_min` (`float`，默认为 0.01）— 采样过程中 sigma 序列的初始噪声尺度。最小的 sigma 应该反映数据的分布。

+   `sigma_max` (`float`，默认为 1348.0）— 用于传递给模型的连续时间步范围的最大值。

+   `sampling_eps` (`float`，默认为 1e-5）— 采样的结束值，其中时间步从 1 逐渐减少到 epsilon。

+   `correct_steps` (`int`，默认为 1）— 在生成的样本上执行的校正步数。

`ScoreSdeVeScheduler` 是一个方差爆炸的随机微分方程（SDE）调度器。

该模型继承自 SchedulerMixin 和 ConfigMixin。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L89)

```py
( sample: FloatTensor timestep: Optional = None ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

+   `timestep` (`int`，*可选*) — 扩散链中的当前时间步。

返回

`torch.FloatTensor`

一个缩放的输入样本。

确保与需要根据当前时间步长缩放去噪模型输入的调度程序可以互换。

#### `set_sigmas`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L125)

```py
( num_inference_steps: int sigma_min: float = None sigma_max: float = None sampling_eps: float = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步骤数。

+   `sigma_min` (`float`, optional) — 初始噪声尺度值（覆盖调度程序实例化时给定的值）。

+   `sigma_max` (`float`, optional) — 最终噪声尺度值（覆盖调度程序实例化时给定的值）。

+   `sampling_eps` (`float`, optional) — 最终时间步长值（覆盖调度程序实例化时给定的值）。

设置用于扩散链的噪声尺度（在推理之前运行）。sigma 控制样本更新的 `drift` 和 `diffusion` 组件的权重。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L106)

```py
( num_inference_steps: int sampling_eps: float = None device: Union = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步骤数。

+   `sampling_eps` (`float`, *optional*) — 最终时间步长值（覆盖调度程序实例化时给定的值）。

+   `device` (`str` 或 `torch.device`, *optional*) — 应将时间步移动到的设备。如果为 `None`，则不移动时间步。

设置用于扩散链的连续时间步长（在推理之前运行）。

#### `step_correct`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L228)

```py
( model_output: FloatTensor sample: FloatTensor generator: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';SdeVeOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的当前样本实例。

+   `generator` (`torch.Generator`, *optional*) — 一个随机数生成器。

+   `return_dict` (`bool`, *optional*, 默认为 `True`) — 是否返回 SdeVeOutput 或 `tuple`。

返回

SdeVeOutput 或 `tuple`

如果 return_dict 为 `True`，则返回 SdeVeOutput，否则返回一个元组，其中第一个元素是样本张量。

根据网络的 `model_output` 对预测的样本进行校正。通常在为上一个时间步骤做出预测后重复运行。

#### `step_pred`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L160)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor generator: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';SdeVeOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。

+   `timestep` (`int`) — 扩散链中当前的离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的当前样本实例。

+   `generator` (`torch.Generator`, *optional*) — 一个随机数生成器。

+   `return_dict` (`bool`, *optional*, 默认为 `True`) — 是否返回 SdeVeOutput 或 `tuple`。

返回

SdeVeOutput 或 `tuple`

如果 return_dict 为 `True`，则返回 SdeVeOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 来预测上一个时间步骤的样本。此函数从学习模型输出（通常是预测的噪声）中传播扩散过程。

## SdeVeOutput

### `class diffusers.schedulers.scheduling_sde_ve.SdeVeOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_sde_ve.py#L29)

```py
( prev_sample: FloatTensor prev_sample_mean: FloatTensor )
```

参数

+   `prev_sample` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height, width)`，用于图像) — 先前时间步的计算样本 `(x_{t-1})`。`prev_sample` 应该在去噪循环中作为下一个模型输入使用。

+   `prev_sample_mean` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height, width)`，用于图像) — 在先前时间步上对 `prev_sample` 进行平均的均值。

调度程序 `step` 函数输出的输出类。
