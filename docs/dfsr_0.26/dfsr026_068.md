# LoRA

> 原始文本：[`huggingface.co/docs/diffusers/training/lora`](https://huggingface.co/docs/diffusers/training/lora)

这是实验性的，API 可能会在将来更改。

[LoRA（大型语言模型的低秩适应）](https://hf.co/papers/2106.09685)是一种流行且轻量级的训练技术，可以显著减少可训练参数的数量。它通过向模型插入较少数量的新权重，并仅对这些权重进行训练来工作。这使得使用 LoRA 进行训练更快速、内存效率更高，并且产生更小的模型权重（几百 MB），更容易存储和共享。LoRA 还可以与其他训练技术（如 DreamBooth）结合以加快训练速度。

LoRA 非常灵活，并支持[DreamBooth](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py)、[Kandinsky 2.2](https://github.com/huggingface/diffusers/blob/main/examples/kandinsky2_2/text_to_image/train_text_to_image_lora_decoder.py)、[Stable Diffusion XL](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora_sdxl.py)、[text-to-image](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)和[Wuerstchen](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_lora_prior.py)。

这个指南将探讨[train_text_to_image_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)脚本，帮助您更熟悉它，以及如何为自己的用例进行调整。

在运行脚本之前，请确保您从源代码安装库：

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

导航到包含训练脚本的示例文件夹，并安装您正在使用的脚本所需的依赖项：

PyTorchFlax

```py
cd examples/text_to_image
pip install -r requirements.txt
```

🤗 Accelerate 是一个帮助您在多个 GPU/TPU 上进行训练或使用混合精度的库。它将根据您的硬件和环境自动配置您的训练设置。查看🤗 Accelerate [快速入门](https://huggingface.co/docs/accelerate/quicktour)以了解更多。

初始化🤗 Accelerate 环境：

```py
accelerate config
```

要设置默认的🤗 Accelerate 环境而不选择任何配置：

```py
accelerate config default
```

或者如果您的环境不支持交互式 shell，比如笔记本，您可以使用：

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

最后，如果您想在自己的数据集上训练模型，请查看创建用于训练的数据集指南，了解如何创建与训练脚本兼容的数据集。

以下部分突出显示了训练脚本的一些重要部分，以帮助您了解如何修改它，但并未详细涵盖脚本的每个方面。如果您有兴趣了解更多，请随时阅读[脚本](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py)，并告诉我们您是否有任何问题或疑虑。

## 脚本参数

训练脚本有许多参数可帮助您自定义训练运行。所有参数及其描述都可以在[`parse_args()`](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L85)函数中找到。大多数参数都提供了默认值，但如果您愿意，也可以在训练命令中设置自己的值。

例如，要增加训练的时代数：

```py
accelerate launch train_text_to_image_lora.py \
  --num_train_epochs=150 \
```

许多基本和重要的参数在 Text-to-image 训练指南中有描述，因此本指南只关注与 LoRA 相关的参数：

+   `--rank`：要训练的低秩矩阵的内部维度；更高的秩意味着更多的可训练参数

+   `--learning_rate`：默认学习率为 1e-4，但使用 LoRA 时，您可以使用更高的学习率

## 训练脚本

数据集预处理代码和训练循环可以在 [`main()`](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L371) 函数中找到，如果您需要调整训练脚本，这就是您需要进行更改的地方。

与脚本参数一样，文本到图像训练指南中提供了训练脚本的详细步骤。而这份指南则着眼于脚本中与 LoRA 相关的部分。

脚本首先通过将 [新的 LoRA 权重](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L447) 添加到注意力层来开始。这涉及正确配置 UNet 中每个块的权重大小。您会看到 `rank` 参数被用来创建 LoRAAttnProcessor：

```py
lora_attn_procs = {}
for name in unet.attn_processors.keys():
    cross_attention_dim = None if name.endswith("attn1.processor") else unet.config.cross_attention_dim
    if name.startswith("mid_block"):
        hidden_size = unet.config.block_out_channels[-1]
    elif name.startswith("up_blocks"):
        block_id = int(name[len("up_blocks.")])
        hidden_size = list(reversed(unet.config.block_out_channels))[block_id]
    elif name.startswith("down_blocks"):
        block_id = int(name[len("down_blocks.")])
        hidden_size = unet.config.block_out_channels[block_id]

    lora_attn_procs[name] = LoRAAttnProcessor(
        hidden_size=hidden_size,
        cross_attention_dim=cross_attention_dim,
        rank=args.rank,
    )

unet.set_attn_processor(lora_attn_procs)
lora_layers = AttnProcsLayers(unet.attn_processors)
```

[优化器](https://github.com/huggingface/diffusers/blob/dd9a5caf61f04d11c0fa9f3947b69ab0010c9a0f/examples/text_to_image/train_text_to_image_lora.py#L519) 使用 `lora_layers` 进行初始化，因为这些是唯一会被优化的权重：

```py
optimizer = optimizer_cls(
    lora_layers.parameters(),
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```

除了设置 LoRA 层之外，训练脚本基本上与 train_text_to_image.py 相同！

## 启动脚本

一旦您完成了所有更改或者您对默认配置满意，您就可以启动训练脚本！🚀

让我们在 [Pokémon BLIP 标题](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions) 数据集上进行训练，以生成我们自己的 Pokémon。将环境变量 `MODEL_NAME` 和 `DATASET_NAME` 分别设置为模型和数据集。您还应该指定在 `OUTPUT_DIR` 中保存模型的位置，并使用 `HUB_MODEL_ID` 指定要保存到 Hub 上的模型的名称。脚本将创建并保存以下文件到您的存储库中：

+   保存的模型检查点

+   `pytorch_lora_weights.safetensors`（训练的 LoRA 权重）

如果您在多个 GPU 上进行训练，请在 `accelerate launch` 命令中添加 `--multi_gpu` 参数。

在拥有 11GB VRAM 的 2080 Ti GPU 上进行完整训练大约需要 5 小时。

```py
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="/sddata/finetune/lora/pokemon"
export HUB_MODEL_ID="pokemon-lora"
export DATASET_NAME="lambdalabs/pokemon-blip-captions"

accelerate launch --mixed_precision="fp16"  train_text_to_image_lora.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$DATASET_NAME \
  --dataloader_num_workers=8 \
  --resolution=512 \
  --center_crop \
  --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --max_train_steps=15000 \
  --learning_rate=1e-04 \
  --max_grad_norm=1 \
  --lr_scheduler="cosine" \
  --lr_warmup_steps=0 \
  --output_dir=${OUTPUT_DIR} \
  --push_to_hub \
  --hub_model_id=${HUB_MODEL_ID} \
  --report_to=wandb \
  --checkpointing_steps=500 \
  --validation_prompt="A pokemon with blue eyes." \
  --seed=1337
```

训练完成后，您可以使用您的模型进行推理：

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to("cuda")
pipeline.load_lora_weights("path/to/lora/model", weight_name="pytorch_lora_weights.safetensors")
image = pipeline("A pokemon with blue eyes").images[0]
```

## 下一步

恭喜您使用 LoRA 训练了一个新模型！要了解如何使用您的新模型，以下指南可能会有所帮助：

+   学习如何 加载不同的 LoRA 格式 ，这些格式是使用 Kohya 和 TheLastBen 等社区训练者训练的。

+   学习如何使用 结合多个 LoRA 与 PEFT 进行推理。
