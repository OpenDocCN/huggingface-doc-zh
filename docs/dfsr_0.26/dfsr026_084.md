# JAX/Flax

> 原始文本：[`huggingface.co/docs/diffusers/using-diffusers/stable_diffusion_jax_how_to`](https://huggingface.co/docs/diffusers/using-diffusers/stable_diffusion_jax_how_to)

🤗 Diffusers 支持 Flax 在 Google TPU 上进行超快推理，例如在 Colab、Kaggle 或 Google Cloud Platform 上可用的 TPU。本指南向您展示如何使用 JAX/Flax 运行稳定扩散的推理。

在开始之前，请确保已安装必要的库：

```py
# uncomment to install the necessary libraries in Colab
#!pip install -q jax==0.3.25 jaxlib==0.3.25 flax transformers ftfy
#!pip install -q diffusers
```

您还应确保您正在使用 TPU 后端。虽然 JAX 并不专门在 TPU 上运行，但在 TPU 上会获得最佳性能，因为每台服务器都有 8 个 TPU 加速器并行工作。

如果您在 Colab 中运行此指南，请在上面的菜单中选择*运行时*，选择*更改运行时类型*选项，然后在*硬件加速器*设置下选择*TPU*。导入 JAX 并快速检查是否正在使用 TPU：

```py
import jax
import jax.tools.colab_tpu
jax.tools.colab_tpu.setup_tpu()

num_devices = jax.device_count()
device_type = jax.devices()[0].device_kind

print(f"Found {num_devices} JAX devices of type {device_type}.")
assert (
    "TPU" in device_type,
    "Available device is not a TPU, please select TPU from Runtime > Change runtime type > Hardware accelerator"
)
# Found 8 JAX devices of type Cloud TPU.
```

现在，您可以导入所需的其余依赖项：

```py
import jax.numpy as jnp
from jax import pmap
from flax.jax_utils import replicate
from flax.training.common_utils import shard

from diffusers import FlaxStableDiffusionPipeline
```

## 加载模型

Flax 是一个功能性框架，因此模型是无状态的，参数存储在模型之外。加载预训练的 Flax 管道会返回*管道和模型权重（或参数）*。在本指南中，您将使用`bfloat16`，这是一种更高效的半浮点类型，受到 TPU 支持（如果需要，也可以使用`float32`进行完整精度）。

```py
dtype = jnp.bfloat16
pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4",
    revision="bf16",
    dtype=dtype,
)
```

## 推理

通常 TPU 有 8 个设备并行工作，因此让我们为每个设备使用相同的提示。这意味着您可以同时在 8 个设备上执行推理，每个设备生成一个图像。因此，您将在相同的时间内获得 8 张图像，就像一块芯片生成一张单个图像所需的时间一样！

在并行化工作原理是什么？部分了解更多细节。

在复制提示后，通过在管道上调用`prepare_inputs`函数来获取标记化文本 id。标记化文本的长度设置为 77 个标记，这是基础 CLIP 文本模型配置所要求的。

```py
prompt = "A cinematic film still of Morgan Freeman starring as Jimi Hendrix, portrait, 40mm lens, shallow depth of field, close up, split lighting, cinematic"
prompt = [prompt] * jax.device_count()
prompt_ids = pipeline.prepare_inputs(prompt)
prompt_ids.shape
# (8, 77)
```

模型参数和输入必须在 8 个并行设备上复制。参数字典使用[`flax.jax_utils.replicate`](https://flax.readthedocs.io/en/latest/api_reference/flax.jax_utils.html#flax.jax_utils.replicate)进行复制，该函数遍历字典并更改权重的形状，使其重复 8 次。数组使用`shard`进行复制。

```py
# parameters
p_params = replicate(params)

# arrays
prompt_ids = shard(prompt_ids)
prompt_ids.shape
# (8, 1, 77)
```

这个形状意味着每个 8 个设备都接收一个形状为`(1, 77)`的`jnp`数组作为输入，其中`1`是每个设备的批量大小。在具有足够内存的 TPU 上，如果要一次生成多个图像（每个芯片），可以使用大于`1`的批量大小。

接下来，创建一个随机数生成器传递给生成函数。这是 Flax 中的标准程序，Flax 对随机数非常严肃和有见地。所有处理随机数的函数都应该接收一个生成器，以确保可重现性，即使在跨多个分布式设备进行训练时也是如此。

下面的辅助函数使用种子来初始化随机数生成器。只要使用相同的种子，您将获得完全相同的结果。在后续指南中探索结果时，可以随意使用不同的种子。

```py
def create_key(seed=0):
    return jax.random.PRNGKey(seed)
```

辅助函数，或`rng`，被分成 8 次，因此每个设备接收不同的生成器并生成不同的图像。

```py
rng = create_key(0)
rng = jax.random.split(rng, jax.device_count())
```

为了利用 JAX 在 TPU 上的优化速度，将`jit=True`传递给管道，将 JAX 代码编译成高效的表示，并确保模型在 8 个设备上并行运行。

您需要确保所有输入在后续调用中具有相同的形状，否则 JAX 将需要重新编译代码，这会更慢。

第一次推理运行需要更多时间，因为需要编译代码，但后续调用（即使使用不同的输入）会快得多。例如，在 TPU v2-8 上编译需要超过一分钟，但在未来的推理运行中大约需要**7 秒**！

```py
%%time
images = pipeline(prompt_ids, p_params, rng, jit=True)[0]

# CPU times: user 56.2 s, sys: 42.5 s, total: 1min 38s
# Wall time: 1min 29s
```

返回的数组形状为`(8, 1, 512, 512, 3)`，应该重新整形以去除第二维，并获得`512 × 512 × 3`的 8 个图像。然后，您可以使用 numpy_to_pil()函数将数组转换为图像。

```py
from diffusers.utils import make_image_grid

images = images.reshape((images.shape[0] * images.shape[1],) + images.shape[-3:])
images = pipeline.numpy_to_pil(images)
make_image_grid(images, rows=2, cols=4)
```

![img](img/ae26c49256edf5470277710762edc407.png)

## 使用不同的提示符

您不一定需要在所有设备上使用相同的提示。例如，要生成 8 个不同的提示：

```py
prompts = [
    "Labrador in the style of Hokusai",
    "Painting of a squirrel skating in New York",
    "HAL-9000 in the style of Van Gogh",
    "Times Square under water, with fish and a dolphin swimming around",
    "Ancient Roman fresco showing a man working on his laptop",
    "Close-up photograph of young black woman against urban background, high quality, bokeh",
    "Armchair in the shape of an avocado",
    "Clown astronaut in space, with Earth in the background",
]

prompt_ids = pipeline.prepare_inputs(prompts)
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, p_params, rng, jit=True).images
images = images.reshape((images.shape[0] * images.shape[1],) + images.shape[-3:])
images = pipeline.numpy_to_pil(images)

make_image_grid(images, 2, 4)
```

![img](img/aca4bd3a07a58b9a81031e0734d47ed3.png)

## 并行化是如何工作的？

🤗 Diffusers 中的 Flax 管道会自动编译模型并在所有可用设备上并行运行。让我们更仔细地看看这个过程是如何工作的。

JAX 并行化可以通过多种方式实现。最简单的方法是使用[`jax.pmap`](https://jax.readthedocs.io/en/latest/_autosummary/jax.pmap.html)函数来实现单程序多数据（SPMD）并行化。这意味着在不同数据输入上运行相同代码的多个副本。还有更复杂的方法，如果您感兴趣，可以查看 JAX 的[文档](https://jax.readthedocs.io/en/latest/index.html)以更详细地探讨这个主题！

`jax.pmap`做了两件事：

1.  编译（或“`jit`s”）类似于`jax.jit()`的代码。当您调用`pmap`时，不会发生这种情况，只有第一次调用`pmap`函数时才会发生。

1.  确保编译的代码在所有可用设备上并行运行。

为了演示，在管道的`_generate`方法上调用`pmap`（这是一个生成图像的私有方法，在未来的🤗 Diffusers 版本中可能会被重命名或删除）：

```py
p_generate = pmap(pipeline._generate)
```

调用`pmap`后，准备好的函数`p_generate`将：

1.  在每个设备上复制基础函数`pipeline._generate`。

1.  向每个设备发送不同部分的输入参数（这就是为什么需要调用*shard*函数）。在这种情况下，`prompt_ids`的形状为`(8, 1, 77, 768)`，因此数组被分成 8 部分，每个`_generate`的副本接收形状为`(1, 77, 768)`的输入。

在这里要注意的最重要的事情是批量大小（在本例中为 1）和适合您代码的输入维度。您不必更改其他任何内容即可使代码并行工作。

第一次调用管道需要更多时间，但之后的调用速度要快得多。使用`block_until_ready`函数来正确测量推理时间，因为 JAX 使用异步调度，并尽快将控制返回给 Python 循环。您不需要在代码中使用它；当您想要使用尚未实现的计算结果时，阻塞会自动发生。

```py
%%time
images = p_generate(prompt_ids, p_params, rng)
images = images.block_until_ready()

# CPU times: user 1min 15s, sys: 18.2 s, total: 1min 34s
# Wall time: 1min 15s
```

检查您的图像维度是否正确：

```py
images.shape
# (8, 1, 512, 512, 3)
```
