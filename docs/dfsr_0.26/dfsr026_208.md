# UniPCMultistepScheduler

> 原文链接：[`huggingface.co/docs/diffusers/api/schedulers/unipc`](https://huggingface.co/docs/diffusers/api/schedulers/unipc)

`UniPCMultistepScheduler`是一个无需训练的框架，旨在快速采样扩散模型。它在文献[UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models](https://huggingface.co/papers/2302.04867)中由 Wenliang Zhao、Lujia Bai、Yongming Rao、Jie Zhou、Jiwen Lu 引入。

它由一个校正器（UniC）和一个预测器（UniP）组成，二者共享统一的分析形式，并支持任意阶数。UniPC 是设计为模型无关的，支持像素空间/潜在空间 DPMs 的无条件/有条件采样。它还可以应用于噪声预测和数据预测模型。校正器 UniC 也可以应用于任何现成的求解器之后，以提高准确度的阶数。

该论文的摘要是：

*扩散概率模型（DPMs）在高分辨率图像合成中表现出非常有前途的能力。然而，从预训练的 DPM 中采样耗时，因为需要多次评估去噪网络，因此加速 DPM 采样变得越来越重要。尽管在设计快速采样器方面取得了最近的进展，但现有方法仍无法在许多应用中生成令人满意的图像，这些应用更倾向于较少的步骤（例如<10）。在本文中，我们开发了一个统一的校正器（UniC），可以在任何现有的 DPM 采样器之后应用，以提高准确度而无需额外的模型评估，并推导出一个支持任意阶数的统一预测器（UniP）作为副产品。结合 UniP 和 UniC，我们提出了一个名为 UniPC 的统一预测器-校正器框架，用于快速采样 DPMs，它具有任何阶数的统一分析形式，并且可以显著提高采样质量，特别是在极少的步骤中。我们通过广泛的实验评估我们的方法，包括使用像素空间和潜在空间 DPMs 进行无条件和有条件采样。我们的 UniPC 可以在 CIFAR10（无条件）上实现 3.87 FID，在 ImageNet 256×256（有条件）上实现 7.51 FID，仅需 10 次函数评估。代码可在[此 https URL](https://github.com/wl-zhao/UniPC)上找到。*

## 提示

建议将`solver_order`设置为 2 以进行引导采样，将`solver_order=3`用于无条件采样。

支持来自[Imagen](https://huggingface.co/papers/2205.11487)的动态阈值，对于像素空间扩散模型，您可以设置`predict_x0=True`和`thresholding=True`来使用动态阈值。这种阈值方法不适用于稳定扩散等潜在空间扩散模型。

## UniPCMultistepScheduler

### `class diffusers.UniPCMultistepScheduler`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_unipc_multistep.py#L74)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Union = None solver_order: int = 2 prediction_type: str = 'epsilon' thresholding: bool = False dynamic_thresholding_ratio: float = 0.995 sample_max_value: float = 1.0 predict_x0: bool = True solver_type: str = 'bh2' lower_order_final: bool = True disable_corrector: List = [] solver_p: SchedulerMixin = None use_karras_sigmas: Optional = False timestep_spacing: str = 'linspace' steps_offset: int = 0 )
```

参数

+   `num_train_timesteps`（`int`，默认为 1000）— 训练模型的扩散步数。

+   `beta_start`（`float`，默认为 0.0001）— 推断的起始`beta`值。

+   `beta_end`（`float`，默认为 0.02）— 最终的`beta`值。

+   `beta_schedule`（`str`，默认为`"linear"`）— beta 调度，从 beta 范围到用于步进模型的一系列 beta 的映射。可选择`linear`、`scaled_linear`或`squaredcos_cap_v2`。

+   `trained_betas`（`np.ndarray`，*可选*）— 直接传递一个 beta 数组给构造函数，以绕过`beta_start`和`beta_end`。

+   `solver_order`（`int`，默认为`2`）— UniPC 阶数，可以是任何正整数。由于 UniC，准确度的有效阶数为`solver_order + 1`。建议对于引导采样使用`solver_order=2`，对于无条件采样使用`solver_order=3`。

+   `prediction_type` (`str`, 默认为 `epsilon`, *可选*) — 调度器函数的预测类型；可以是 `epsilon`（预测扩散过程的噪声）、`sample`（直接预测嘈杂的样本）或 `v_prediction`（参见 [Imagen Video](https://imagen.research.google/video/paper.pdf) 论文的第 2.4 节）。

+   `thresholding` (`bool`, 默认为 `False`) — 是否使用“动态阈值”方法。这不适用于稳定扩散等潜在空间扩散模型。

+   `dynamic_thresholding_ratio` (`float`, 默认为 0.995) — 动态阈值方法的比率。仅在 `thresholding=True` 时有效。

+   `sample_max_value` (`float`, 默认为 1.0) — 动态阈值的阈值值。仅在 `thresholding=True` 和 `predict_x0=True` 时有效。

+   `predict_x0` (`bool`, 默认为 `True`) — 是否在预测的 x0 上使用更新算法。

+   `solver_type` (`str`, 默认为 `bh2`) — UniPC 的求解器类型。建议在步骤 < 10 时使用 `bh1` 进行无条件采样，否则使用 `bh2`。

+   `lower_order_final` (`bool`, 默认为 `True`) — 是否在最后几步使用低阶求解器。仅适用于 < 15 推断步骤。这可以稳定 DPMSolver 对于步骤 < 15 的采样，特别是对于步骤 <= 10。

+   `disable_corrector` (`list`, 默认为 `[]`) — 决定在哪一步禁用校正器以减轻 `epsilon_theta(x_t, c)` 和 `epsilon_theta(x_t^c, c)` 之间的不对齐，这可能会影响大指导尺度的收敛性。通常在前几步中禁用校正器。

+   `solver_p` (`SchedulerMixin`, 默认为 `None`) — 任何其他指定的调度器，如果指定，则算法变为 `solver_p + UniC`。

+   `use_karras_sigmas` (`bool`, *可选*, 默认为 `False`) — 是否在采样过程中使用 Karras sigmas 作为噪声计划中步长的序列。如果为 `True`，则根据噪声级别 {σi} 确定 sigmas。

+   `timestep_spacing` (`str`, 默认为 `"linspace"`) — 时间步长应该如何缩放的方式。有关更多信息，请参考 [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891) 的表 2。

+   `steps_offset` (`int`, 默认为 0) — 添加到推断步骤的偏移量。您可以使用 `offset=1` 和 `set_alpha_to_one=False` 的组合，使最后一步使用步骤 0 用于先前 alpha 乘积，就像 Stable Diffusion 中一样。

`UniPCMultistepScheduler` 是一个无需训练的框架，旨在快速采样扩散模型。

该模型继承自 SchedulerMixin 和 ConfigMixin。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。

#### `convert_model_output`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_unipc_multistep.py#L365)

```py
( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。

+   `timestep` (`int`) — 扩散链中的当前离散时间步长。

+   `sample` (`torch.FloatTensor`) — 扩散过程创建的样本的当前实例。

返回

`torch.FloatTensor`

转换后的模型输出。

将模型输出转换为 UniPC 算法需要的相应类型。

#### `multistep_uni_c_bh_update`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_unipc_multistep.py#L564)

```py
( this_model_output: FloatTensor *args last_sample: FloatTensor = None this_sample: FloatTensor = None order: int = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `this_model_output` (`torch.FloatTensor`) — 模型在 `x_t` 处的输出。

+   `this_timestep` (`int`) — 当前时间步 `t`。

+   `last_sample` (`torch.FloatTensor`) — 最后一个预测器 `x_{t-1}` 之前生成的样本。

+   `this_sample` (`torch.FloatTensor`) — 最后一个预测器 `x_{t}` 之后生成的样本。

+   `order` (`int`) — 此步骤中 UniC-p 的`p`。准确度的有效顺序应为`order + 1`。

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_unipc_multistep.py#L801)

`torch.FloatTensor`

当前时间步的校正样本张量。

UniC（B(h)版本）的一步。

#### `multistep_uni_p_bh_update`

`model_output` (`torch.FloatTensor`) — 当前时间步从学习扩散模型直接输出。

```py
( model_output: FloatTensor *args sample: FloatTensor = None order: int = None **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   [< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_unipc_multistep.py#L435)

+   `prev_timestep` (`int`) — 扩散链中的上一个离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的当前样本实例。

+   `order` (`int`) — UniP 在此时间步的顺序（对应于 UniPC-p 中的*p*）。

返回

`torch.FloatTensor`

上一个时间步的样本张量。

UniP（B(h)版本）的一步。或者，如果指定了，则使用`self.solver_p`。

#### `scale_model_input`

返回

```py
( sample: FloatTensor *args **kwargs ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

返回

`torch.FloatTensor`

缩放的输入样本。

确保与需要根据当前时间步缩放去噪模型输入的调度程序可互换。

#### `set_timesteps`

返回

```py
( num_inference_steps: int device: Union = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步数。

+   `device` (`str` 或 `torch.device`，*可选*) — 时间步应移动到的设备。如果为`None`，则不移动时间步。

设置用于扩散链的离散时间步（在推断之前运行）。

#### `step`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_unipc_multistep.py#L720)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出。

+   `timestep` (`int`) — 扩散链中的当前离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的当前样本实例。

+   `return_dict` (`bool`) — 是否返回 SchedulerOutput 或`tuple`。

返回

SchedulerOutput 或 `tuple`

如果`return_dict`为`True`，则返回 SchedulerOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 从上一个时间步预测样本。此函数使用多步 UniPC 传播样本。

## SchedulerOutput

### `class diffusers.schedulers.scheduling_utils.SchedulerOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_utils.py#L50)

```py
( prev_sample: FloatTensor )
```

参数

+   `prev_sample`（对于图像，形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`） — 上一个时间步的计算样本`(x_{t-1})`。`prev_sample`应在去噪循环中作为下一个模型输入使用。

调度程序`step`函数的输出的基类。
