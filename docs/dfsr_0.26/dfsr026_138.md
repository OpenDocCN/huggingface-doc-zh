# Dance Diffusion

> 原文链接：[`huggingface.co/docs/diffusers/api/pipelines/dance_diffusion`](https://huggingface.co/docs/diffusers/api/pipelines/dance_diffusion)

[Dance Diffusion](https://github.com/Harmonai-org/sample-generator) 是由 Zach Evans 制作的。

Dance Diffusion 是由 [Harmonai](https://github.com/Harmonai-org) 发布的一套面向制作人和音乐家的生成音频工具套件中的第一个工具。

请确保查看调度器指南以了解如何在调度器速度和质量之间进行权衡，并查看 跨管道重用组件 部分，以了解如何有效地将相同组件加载到多个管道中。

## DanceDiffusionPipeline

### `class diffusers.DanceDiffusionPipeline`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dance_diffusion/pipeline_dance_diffusion.py#L28)

```py
( unet scheduler )
```

参数

+   `unet` (UNet1DModel) — 用于去噪编码音频的 `UNet1DModel`。

+   `scheduler` (SchedulerMixin) — 一个调度器，用于与 `unet` 结合使用以去噪编码音频潜在特征。可以是 IPNDMScheduler 中的一个。

用于音频生成的管道。

该模型继承自 DiffusionPipeline。查看超类文档以了解为所有管道实现的通用方法（下载、保存、在特定设备上运行等）。

#### `__call__`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dance_diffusion/pipeline_dance_diffusion.py#L49)

```py
( batch_size: int = 1 num_inference_steps: int = 100 generator: Union = None audio_length_in_s: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';AudioPipelineOutput or tuple
```

参数

+   `batch_size` (`int`, *可选*, 默认为 1) — 要生成的音频样本数量。

+   `num_inference_steps` (`int`, *可选*, 默认为 50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的音频样本，但会降低推理速度。

+   `generator` (`torch.Generator`, *可选*) — 用于使生成过程确定性的 [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。

+   `audio_length_in_s` (`float`, *可选*, 默认为 `self.unet.config.sample_size/self.unet.config.sample_rate`) — 生成的音频样本的长度（以秒为单位）。

+   `return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 AudioPipelineOutput 而不是一个普通的 tuple。

返回

AudioPipelineOutput 或 `tuple`

如果 `return_dict` 为 `True`，则返回 AudioPipelineOutput，否则返回一个 `tuple`，其中第一个元素是生成的音频列表。

用于生成的管道的调用函数。

示例：

```py
from diffusers import DiffusionPipeline
from scipy.io.wavfile import write

model_id = "harmonai/maestro-150k"
pipe = DiffusionPipeline.from_pretrained(model_id)
pipe = pipe.to("cuda")

audios = pipe(audio_length_in_s=4.0).audios

# To save locally
for i, audio in enumerate(audios):
    write(f"maestro_test_{i}.wav", pipe.unet.sample_rate, audio.transpose())

# To dislay in google colab
import IPython.display as ipd

for audio in audios:
    display(ipd.Audio(audio, rate=pipe.unet.sample_rate))
```

## AudioPipelineOutput

### `class diffusers.AudioPipelineOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L130)

```py
( audios: ndarray )
```

参数

+   `audios` (`np.ndarray`) — 一个形状为 `(batch_size, num_channels, sample_rate)` 的 NumPy 数组，包含去噪后的音频样本列表。

音频管道的输出类。
