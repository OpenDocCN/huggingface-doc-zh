# 使用 FreeU 提高生成质量

> 原始文本：[`huggingface.co/docs/diffusers/using-diffusers/freeu`](https://huggingface.co/docs/diffusers/using-diffusers/freeu)

UNet 在反向扩散过程中负责去噪，其架构中有两个不同的特征：

1.  骨干特征主要用于去噪过程

1.  跳过特征主要将高频特征引入解码器模块，可能会使网络忽略骨干特征中的语义

然而，跳过连接有时可能会引入不自然的图像细节。[FreeU](https://hf.co/papers/2309.11497)是一种通过重新平衡 UNet 的跳过连接和骨干特征图的贡献来改善图像质量的技术。

FreeU 应用于推理过程中，不需要额外的训练。该技术适用于不同任务，如文本到图像、图像到图像和文本到视频。

在本指南中，您将在 StableDiffusionPipeline、StableDiffusionXLPipeline 和 TextToVideoSDPipeline 中应用 FreeU。您需要从源代码安装 Diffusers 以运行下面的示例。

## StableDiffusionPipeline

加载管道：

```py
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, safety_checker=None
).to("cuda")
```

然后使用 FreeU 特定的超参数启用 FreeU 机制。这些值是用于骨干和跳过特征的缩放因子。

```py
pipeline.enable_freeu(s1=0.9, s2=0.2, b1=1.2, b2=1.4)
```

上述数值来自官方 FreeU [代码库](https://github.com/ChenyangSi/FreeU)，您还可以在那里找到不同模型的[参考超参数](https://github.com/ChenyangSi/FreeU#range-for-more-parameters)。

通过在管道上调用`disable_freeu()`来禁用 FreeU 机制。

然后运行推理：

```py
prompt = "A squirrel eating a burger"
seed = 2023
image = pipeline(prompt, generator=torch.manual_seed(seed)).images[0]
image
```

下图分别比较了使用相同超参数（`prompt`和`seed`）的非 FreeU 和 FreeU 结果：

![](img/14f4849619dc951e6957a5ba77ca9e0f.png)

让我们看看稳定扩散 2 的结果受到了什么影响：

```py
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16, safety_checker=None
).to("cuda")

prompt = "A squirrel eating a burger"
seed = 2023

pipeline.enable_freeu(s1=0.9, s2=0.2, b1=1.1, b2=1.2)
image = pipeline(prompt, generator=torch.manual_seed(seed)).images[0]
image
```

![](img/871db7b4ddca876aa8031f54e2830a97.png)

## 稳定扩散 XL

最后，让我们看看 FreeU 如何影响稳定扩散 XL 的结果：

```py
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16,
).to("cuda")

prompt = "A squirrel eating a burger"
seed = 2023

# Comes from
# https://wandb.ai/nasirk24/UNET-FreeU-SDXL/reports/FreeU-SDXL-Optimal-Parameters--Vmlldzo1NDg4NTUw
pipeline.enable_freeu(s1=0.6, s2=0.4, b1=1.1, b2=1.2)
image = pipeline(prompt, generator=torch.manual_seed(seed)).images[0]
image
```

![](img/f5c6276e60b4304789966e7f79551b89.png)

## 文本到视频生成

FreeU 也可以用于提高视频质量：

```py
from diffusers import DiffusionPipeline
from diffusers.utils import export_to_video
import torch

model_id = "cerspense/zeroscope_v2_576w"
pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

prompt = "an astronaut riding a horse on mars"
seed = 2023

# The values come from
# https://github.com/lyn-rgb/FreeU_Diffusers#video-pipelines
pipe.enable_freeu(b1=1.2, b2=1.4, s1=0.9, s2=0.2)
video_frames = pipe(prompt, height=320, width=576, num_frames=30, generator=torch.manual_seed(seed)).frames
export_to_video(video_frames, "astronaut_rides_horse.mp4")
```

感谢[kadirnar](https://github.com/kadirnar/)帮助整合该功能，以及[justindujardin](https://github.com/justindujardin)提供的有益讨论。
