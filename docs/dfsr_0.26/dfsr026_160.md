# 稳定扩散管道

> 原始文本：[`huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)

稳定扩散是由[CompVis](https://github.com/CompVis)、[Stability AI](https://stability.ai/)和[LAION](https://laion.ai/)的研究人员和工程师创建的文本到图像潜在扩散模型。潜在扩散将扩散过程应用于较低维度的潜在空间，以减少内存和计算复杂性。这种特定类型的扩散模型是由 Robin Rombach、Andreas Blattmann、Dominik Lorenz、Patrick Esser、Björn Ommer 在《使用潜在扩散模型进行高分辨率图像合成》中提出的。

稳定扩散是在 LAION-5B 数据集的 512x512 图像上训练的。该模型使用冻结的 CLIP ViT-L/14 文本编码器来根据文本提示对模型进行条件化。该模型具有 860M 的 UNet 和 123M 的文本编码器，相对轻量级，可以在消费者 GPU 上运行。

有关稳定扩散的工作原理及其与基本潜在扩散模型的区别的更多详细信息，请查看 Stability AI 的[公告](https://stability.ai/blog/stable-diffusion-announcement)和我们自己的[博客文章](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work)以获取更多技术细节。

您可以在[CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)找到稳定扩散 v1.0 的原始代码库，以及在[Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)找到稳定扩散 v2.0 的原始代码库，以及它们各自的各种任务的原始脚本。不同稳定扩散版本和任务的额外官方检查点可以在[CompVis](https://huggingface.co/CompVis)、[Runway](https://huggingface.co/runwayml)和[Stability AI](https://huggingface.co/stabilityai) Hub 组织中找到。探索这些组织，找到适合您用例的最佳检查点！

下表总结了可用的稳定扩散管道、它们支持的任务以及交互式演示：

| 管道 | 支持的任务 | 🤗 空间 |
| --- | --- | --- |
| StableDiffusion | 文本到图像 | ![](https://huggingface.co/spaces/stabilityai/stable-diffusion) |
| StableDiffusionImg2Img | 图像到图像 | ![](https://huggingface.co/spaces/huggingface/diffuse-the-rest) |
| StableDiffusionInpaint | 补全 | ![](https://huggingface.co/spaces/runwayml/stable-diffusion-inpainting) |
| StableDiffusionDepth2Img | 深度到图像 | ![](https://huggingface.co/spaces/radames/stable-diffusion-depth2img) |
| StableDiffusionImageVariation | 图像变化 | ![](https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations) |
| StableDiffusionPipelineSafe | 过滤的文本到图像 | ![](https://huggingface.co/spaces/AIML-TUDA/unsafe-vs-safe-stable-diffusion) |
| StableDiffusion2 | 文本到图像、补全、深度到图像、超分辨率 | ![](https://huggingface.co/spaces/stabilityai/stable-diffusion) |
| StableDiffusionXL | 文本到图像、图像到图像 | ![](https://huggingface.co/spaces/RamAnanth1/stable-diffusion-xl) |
| StableDiffusionLatentUpscale | 超分辨率 | ![](https://huggingface.co/spaces/huggingface-projects/stable-diffusion-latent-upscaler) |
| StableDiffusionUpscale | 超分辨率 |
| StableDiffusionLDM3D | 文本到 RGB，文本到深度，文本到全景 | ![](https://huggingface.co/spaces/r23/ldm3d-space) |
| StableDiffusionUpscaleLDM3D | ldm3d 超分辨率 |

## 提示

为了帮助您充分利用稳定扩散管道，这里有一些改善性能和可用性的提示。这些提示适用于所有稳定扩散管道。

### 在速度和质量之间进行权衡

StableDiffusionPipeline 默认使用 PNDMScheduler，但🤗 Diffusers 提供许多其他调度器（其中一些更快或输出质量更好），这些调度器是兼容的。例如，如果您想使用 EulerDiscreteScheduler 而不是默认值：

```py
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler

pipeline = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)

# or
euler_scheduler = EulerDiscreteScheduler.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="scheduler")
pipeline = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", scheduler=euler_scheduler)
```

### 重复使用管道组件以节省内存

为了节省内存并在多个管道中使用相同的组件，请使用`.components`方法，以避免将权重加载到 RAM 中超过一次。

```py
from diffusers import (
    StableDiffusionPipeline,
    StableDiffusionImg2ImgPipeline,
    StableDiffusionInpaintPipeline,
)

text2img = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
img2img = StableDiffusionImg2ImgPipeline(**text2img.components)
inpaint = StableDiffusionInpaintPipeline(**text2img.components)

# now you can use text2img(...), img2img(...), inpaint(...) just like the call methods of each respective pipeline
```
