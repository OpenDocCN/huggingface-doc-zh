# 加载 safetensors

> 更多原文：[`huggingface.co/docs/diffusers/using-diffusers/using_safetensors`](https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors)

[safetensors](https://github.com/huggingface/safetensors)是一种安全且快速的文件格式，用于存储和加载张量。通常，PyTorch 模型权重会使用 Python 的[`pickle`](https://docs.python.org/3/library/pickle.html)实用程序保存或*pickled*为`.bin`文件。但是，`pickle`不安全，pickled 文件可能包含可以执行的恶意代码。safetensors 是`pickle`的安全替代品，非常适合共享模型权重。

本指南将向您展示如何加载`.safetensor`文件，以及如何将存储在其他格式中的稳定扩散模型权重转换为`.safetensor`。在开始之前，请确保您已安装 safetensors：

```py
# uncomment to install the necessary libraries in Colab
#!pip install safetensors
```

如果您查看[`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)存储库，您会看到`text_encoder`、`unet`和`vae`子文件夹中存储的权重以`.safetensors`格式存储。默认情况下，🤗 Diffusers 会自动从模型存储库中的子文件夹加载这些`.safetensors`文件，如果可用。

为了更明确地控制，您可以选择设置`use_safetensors=True`（如果未安装`safetensors`，您将收到一条错误消息，要求您安装它）：

```py
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", use_safetensors=True)
```

但是，模型权重不一定像上面的示例那样存储在单独的子文件夹中。有时，所有权重都存储在单个`.safetensors`文件中。在这种情况下，如果权重是稳定扩散权重，您可以使用 from_single_file()方法直接加载文件：

```py
from diffusers import StableDiffusionPipeline

pipeline = StableDiffusionPipeline.from_single_file(
    "https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors"
)
```

## 转换为 safetensors

Hub 上并非所有权重都以`.safetensors`格式可用，您可能会遇到存储为`.bin`的权重。在这种情况下，请使用[Convert Space](https://huggingface.co/spaces/diffusers/convert)将权重转换为`.safetensors`。Convert Space 会下载 pickled 权重，转换它们，并打开一个拉取请求，以上传新转换的`.safetensors`文件到 Hub 上。这样，如果 pickled 文件中包含任何恶意代码，它们将被上传到 Hub 上 - Hub 上有一个[安全扫描器](https://huggingface.co/docs/hub/security-pickle#hubs-security-scanner)来检测不安全的文件和可疑的 pickle 导入 - 而不是上传到您的计算机上。

您可以通过在`revision`参数中指定对拉取请求的引用（您还可以在 Hub 上的此[Check PR](https://huggingface.co/spaces/diffusers/check_pr) Space 中测试它），例如`refs/pr/22`，使用新的`.safetensors`权重的模型。

```py
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1", revision="refs/pr/22", use_safetensors=True
)
```

## 为什么使用 safetensors？

使用 safetensors 有几个原因：

+   安全性是使用 safetensors 的首要原因。随着开源和模型分发的增长，能够信任您下载的模型权重不包含任何恶意代码变得至关重要。safetensors 中标头的当前大小防止解析极大的 JSON 文件。

+   在切换模型之间的加载速度是使用 safetensors 的另一个原因，它执行张量的零拷贝。与`pickle`相比，如果您将权重加载到 CPU（默认情况），加载速度特别快，如果直接将权重加载到 GPU，则与`pickle`一样快甚至更快。只有在模型已加载时才会注意到性能差异，如果您正在下载权重或首次加载模型，则不会注意到。

    加载整个管道所需的时间：

    ```py
    from diffusers import StableDiffusionPipeline

    pipeline = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1", use_safetensors=True)
    "Loaded in safetensors 0:00:02.033658"
    "Loaded in PyTorch 0:00:02.663379"
    ```

    但加载 500MB 模型权重实际所需的时间仅为：

    ```py
    safetensors: 3.4873ms
    PyTorch: 172.7537ms
    ```

+   在 safetensors 中也支持延迟加载，这在分布式环境中非常有用，可以只加载部分张量。这种格式使得[BLOOM](https://huggingface.co/bigscience/bloom)模型在 8 个 GPU 上仅用 45 秒加载完成，而使用常规的 PyTorch 权重则需要 10 分钟。
