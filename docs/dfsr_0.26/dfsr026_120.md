# 微型自动编码器

> 原文：[`huggingface.co/docs/diffusers/api/models/autoencoder_tiny`](https://huggingface.co/docs/diffusers/api/models/autoencoder_tiny)

稳定扩散的微型自动编码器（TAESD）由 Ollin Boer Bohan 在 [madebyollin/taesd](https://github.com/madebyollin/taesd) 中引入。它是稳定扩散 VAE 的微型精炼版本，可以快速解码 StableDiffusionPipeline 或 StableDiffusionXLPipeline 中的潜在表示。

使用稳定扩散 v-2.1 版本：

```py
import torch
from diffusers import DiffusionPipeline, AutoencoderTiny

pipe = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1-base", torch_dtype=torch.float16
)
pipe.vae = AutoencoderTiny.from_pretrained("madebyollin/taesd", torch_dtype=torch.float16)
pipe = pipe.to("cuda")

prompt = "slice of delicious New York-style berry cheesecake"
image = pipe(prompt, num_inference_steps=25).images[0]
image
```

用于稳定扩散 XL 1.0 版本

```py
import torch
from diffusers import DiffusionPipeline, AutoencoderTiny

pipe = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
)
pipe.vae = AutoencoderTiny.from_pretrained("madebyollin/taesdxl", torch_dtype=torch.float16)
pipe = pipe.to("cuda")

prompt = "slice of delicious New York-style berry cheesecake"
image = pipe(prompt, num_inference_steps=25).images[0]
image
```

## AutoencoderTiny

### `class diffusers.AutoencoderTiny`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L41)

```py
( in_channels: int = 3 out_channels: int = 3 encoder_block_out_channels: Tuple = (64, 64, 64, 64) decoder_block_out_channels: Tuple = (64, 64, 64, 64) act_fn: str = 'relu' latent_channels: int = 4 upsampling_scaling_factor: int = 2 num_encoder_blocks: Tuple = (1, 3, 3, 3) num_decoder_blocks: Tuple = (3, 3, 3, 1) latent_magnitude: int = 3 latent_shift: float = 0.5 force_upcast: bool = False scaling_factor: float = 1.0 )
```

参数

+   `in_channels`（`int`，*可选*，默认为 3）— 输入图像中的通道数。

+   `out_channels`（`int`，*可选*，默认为 3）— 输出中的通道数。

+   `encoder_block_out_channels`（`Tuple[int]`，*可选*，默认为 `(64, 64, 64, 64)`）— 代表每个编码器块的输出通道数的整数元组。元组的长度应等于编码器块的数量。

+   `decoder_block_out_channels`（`Tuple[int]`，*可选*，默认为 `(64, 64, 64, 64)`）— 代表每个解码器块的输出通道数的整数元组。元组的长度应等于解码器块的数量。

+   `act_fn`（`str`，*可选*，默认为 `"relu"`）— 用于整个模型的激活函数。

+   `latent_channels`（`int`，*可选*，默认为 4）— 潜在表示中的通道数。潜在空间充当输入图像的压缩表示。

+   `upsampling_scaling_factor`（`int`，*可选*，默认为 2）— 解码器中上采样的缩放因子。它确定上采样过程中输出图像的大小。

+   `num_encoder_blocks`（`Tuple[int]`，*可选*，默认为 `(1, 3, 3, 3)`）— 代表编码过程中每个阶段的编码器块数量的整数元组。元组的长度应等于编码器中的阶段数。每个阶段具有不同数量的编码器块。

+   `num_decoder_blocks`（`Tuple[int]`，*可选*，默认为 `(3, 3, 3, 1)`）— 代表解码过程中每个阶段的解码器块数量的整数元组。元组的长度应等于解码器中的阶段数。每个阶段具有不同数量的解码器块。

+   `latent_magnitude`（`float`，*可选*，默认为 3.0）— 潜在表示的幅度。此参数将潜在表示值缩放以控制信息保留的程度。

+   `latent_shift`（浮点数，*可选*，默认为 0.5）— 应用于潜在表示的偏移。此参数控制潜在空间的中心。

+   `scaling_factor`（`float`，*可选*，默认为 1.0）— 使用训练集的第一批计算的训练潜在空间的分量标准差。在训练扩散模型时，用于将潜在空间缩放为具有单位方差。在传递给扩散模型之前，潜在表示将使用公式 `z = z * scaling_factor` 进行缩放。在解码时，潜在表示将使用公式缩放回原始比例：`z = 1 / scaling_factor * z`。有关更多详细信息，请参阅 [高分辨率图像合成与潜在扩散模型](https://arxiv.org/abs/2112.10752) 论文的 4.3.2 和 D.1 部分。然而，对于此自动编码器，没有使用此类缩放因子，因此默认值为 1.0。

+   `force_upcast`（`bool`，*可选*，默认为`False`）— 如果启用，它将强制 VAE 在高图像分辨率管道（如 SD-XL）中以 float32 运行。 VAE 可以在不损失太多精度的情况下被微调/训练到较低范围，此时`force_upcast`可以设置为`False`（请参阅此 fp16 友好的[AutoEncoder](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)）。

用于将图像编码为潜变量并将潜变量表示解码为图像的微型精馏 VAE 模型。

AutoencoderTiny 是对`TAESD`原始实现的包装。

此模型继承自 ModelMixin。查看超类文档以了解为所有模型实现的通用方法（如下载或保存）。

#### `disable_slicing`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L173)

```py
( )
```

禁用切片 VAE 解码。如果之前启用了`enable_slicing`，则此方法将返回到一步计算解码。

#### `disable_tiling`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L188)

```py
( )
```

禁用平铺 VAE 解码。如果之前启用了`enable_tiling`，则此方法将返回到一步计算解码。

#### `enable_slicing`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L166)

```py
( )
```

启用切片 VAE 解码。当启用此选项时，VAE 将将输入张量分割成片段以在几个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。

#### `enable_tiling`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L180)

```py
( use_tiling: bool = True )
```

启用平铺 VAE 解码。当启用此选项时，VAE 将将输入张量分割成瓦片，以便在几个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。

#### `forward`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L320)

```py
( sample: FloatTensor return_dict: bool = True )
```

参数

+   `sample`（`torch.FloatTensor`）— 输入样本。

+   `return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`DecoderOutput`而不是普通元组。

#### `scale_latents`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L158)

```py
( x: FloatTensor )
```

原始潜变量 -> [0, 1]

#### `unscale_latents`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L162)

```py
( x: FloatTensor )
```

[0, 1] -> 原始潜变量

## AutoencoderTinyOutput

### `class diffusers.models.autoencoders.autoencoder_tiny.AutoencoderTinyOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_tiny.py#L28)

```py
( latents: Tensor )
```

参数

+   `latents`（`torch.Tensor`）— 编码器的编码输出。

AutoencoderTiny 编码方法的输出。
