# Keras 回调

> [原文链接](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/keras_callbacks)

在使用 Keras 训练 Transformers 模型时，有一些特定于库的回调可用于自动化常见任务：

## KerasMetricCallback

### `class transformers.KerasMetricCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/keras_callbacks.py#L20)

```py
( metric_fn: Callable eval_dataset: Union output_cols: Optional = None label_cols: Optional = None batch_size: Optional = None predict_with_generate: bool = False use_xla_generation: bool = False generate_kwargs: Optional = None )
```

参数

+   `metric_fn`（`Callable`）- 用户提供的度量函数。它将使用两个参数调用-`predictions`和`labels`。这些包含数据集中模型的输出和匹配标签。它应返回一个将度量名称映射到数值的字典。

+   `eval_dataset`（`tf.data.Dataset`或`dict`或`tuple`或`np.ndarray`或`tf.Tensor`）- 用于生成`metric_fn`预测的验证数据。

+   `output_cols`（`List[str]`，*可选*）- 从模型输出中保留的列的列表作为预测。默认为全部。

+   `label_cols`（`List[str]`，*可选*）- 从输入数据集中保留的列的列表作为标签。如果未提供，则将自动检测。

+   `batch_size`（`int`，*可选*）- 批量大小。仅在数据不是预先批处理的`tf.data.Dataset`时使用。

+   `predict_with_generate`（`bool`，*可选*，默认为`False`）- 是否应使用`model.generate()`来获取模型的输出。

+   `use_xla_generation`（`bool`，*可选*，默认为`False`）- 如果我们正在生成，是否使用 XLA 编译模型生成。这可以大大提高生成速度（最多提高 100 倍），但将需要为每个输入形状进行新的 XLA 编译。在使用 XLA 生成时，最好将输入填充到相同大小，或者在您的`tokenizer`或`DataCollator`中使用`pad_to_multiple_of`参数，这将减少唯一输入形状的数量并节省大量编译时间。如果`predict_with_generate`为`False`，则此选项不起作用。

+   `generate_kwargs`（`dict`，*可选*）- 生成时传递给`model.generate()`的关键字参数。如果`predict_with_generate`为`False`，则不起作用。

在每个时代结束时计算指标的回调。与普通的 Keras 指标不同，这些指标不需要由 TF 编译。对于像 BLEU 和 ROUGE 这样需要字符串操作或无法编译的生成循环的常见 NLP 指标，这是特别有用的。在将预测（或生成）传递给`metric_fn`之前，将在`eval_dataset`上计算预测（或生成）并以`np.ndarray`格式传递给`metric_fn`。`metric_fn`应计算指标并返回将度量名称映射到度量值的字典。

我们在下面提供了一个适合的 metric_fn 示例，用于计算摘要模型的 ROUGE 分数。请注意，为了可读性和简单起见，此示例跳过了一些后处理步骤，可能不应直接使用！

```py
from datasets import load_metric

rouge_metric = load_metric("rouge")

def rouge_fn(predictions, labels):
    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    result = rouge_metric.compute(predictions=decoded_predictions, references=decoded_labels)
    return {key: value.mid.fmeasure * 100 for key, value in result.items()}
```

上述函数将返回一个包含值的字典，这些值将像其他 Keras 指标一样被记录：

```py
{'rouge1': 37.4199, 'rouge2': 13.9768, 'rougeL': 34.361, 'rougeLsum': 35.0781
```

## PushToHubCallback

### `class transformers.PushToHubCallback`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/keras_callbacks.py#L268)

```py
( output_dir: Union save_strategy: Union = 'epoch' save_steps: Optional = None tokenizer: Optional = None hub_model_id: Optional = None hub_token: Optional = None checkpoint: bool = False **model_card_args )
```

参数

+   `output_dir`（`str`）- 模型预测和检查点将被写入并与 Hub 上的存储库同步的输出目录。

+   `save_strategy`（`str`或 IntervalStrategy，*可选*，默认为`"epoch"`）- 训练期间采用的检查点保存策略。可能的值为：

    +   `"no"`：保存在训练结束时完成。

    +   `"epoch"`：在每个时代结束时完成保存。

    +   `"steps"`：每`save_steps`完成保存

+   `save_steps`（`int`，*可选*）- 使用“steps”`save_strategy`时保存之间的步数。

+   `tokenizer`（`PreTrainedTokenizerBase`，*可选*）—模型使用的分词器。如果提供，将与权重一起上传到存储库。

+   `hub_model_id`（`str`，*可选*）—要与本地`output_dir`同步的存储库的名称。它可以是一个简单的模型 ID，此时模型将被推送到您的命名空间。否则，它应该是整个存储库名称，例如`"user_name/model"`，这样您就可以推送到您所属的组织，例如`"organization_name/model"`。

    将默认为`output_dir`的名称。

+   `hub_token`（`str`，*可选*）—用于将模型推送到 Hub 的令牌。将默认为使用`huggingface-cli login`获取的缓存文件夹中的令牌。

+   `checkpoint`（`bool`，*可选*，默认为`False`）—是否保存完整的训练检查点（包括 epoch 和优化器状态），以允许恢复训练。仅在`save_strategy`为`"epoch"`时可用。

回调函数将定期保存并推送模型到 Hub。默认情况下，它每个 epoch 推送一次，但可以使用`save_strategy`参数进行更改。推送的模型可以像 Hub 上的任何其他模型一样访问，例如使用`from_pretrained`方法。

```py
from transformers.keras_callbacks import PushToHubCallback

push_to_hub_callback = PushToHubCallback(
    output_dir="./model_save",
    tokenizer=tokenizer,
    hub_model_id="gpt5-7xlarge",
)

model.fit(train_dataset, callbacks=[push_to_hub_callback])
```
