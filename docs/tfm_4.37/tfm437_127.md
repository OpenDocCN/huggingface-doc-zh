# 特征提取器

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/main_classes/feature_extractor`](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/feature_extractor)

特征提取器负责为音频或视觉模型准备输入特征。这包括从序列中提取特征，例如，对音频文件进行预处理以生成 Log-Mel Spectrogram 特征，从图像中提取特征，例如，裁剪图像文件，但也包括填充、归一化和转换为 NumPy、PyTorch 和 TensorFlow 张量。

## FeatureExtractionMixin

### `class transformers.FeatureExtractionMixin`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L240)

```py
( **kwargs )
```

这是一个特征提取混合类，用于为序列和图像特征提取器提供保存/加载功能。

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L264)

```py
( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 这可以是：

    +   一个字符串，预训练特征提取器的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间，如 `dbmdz/bert-base-german-cased`。

    +   一个指向包含使用 save_pretrained() 方法保存的特征提取器文件的 *目录* 的路径，例如 `./my_model_directory/`。

    +   一个保存的特征提取器 JSON *文件* 的路径或 URL，例如 `./my_model_directory/preprocessor_config.json`。

+   `cache_dir` (`str` 或 `os.PathLike`, *可选*) — 下载的预训练模型特征提取器应该缓存在其中的目录路径，如果不使用标准缓存。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载特征提取器文件并覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理将在每个请求中使用。

+   `token` (`str` 或 `bool`, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，或未指定，将使用运行 `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。

+   `revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。

从特征提取器实例化一种类型的 FeatureExtractionMixin，*例如* SequenceFeatureExtractor 的派生类。

示例：

```py
# We can't instantiate directly the base class *FeatureExtractionMixin* nor *SequenceFeatureExtractor* so let's show the examples on a
# derived class: *Wav2Vec2FeatureExtractor*
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base-960h"
)  # Download feature_extraction_config from huggingface.co and cache.
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "./test/saved_model/"
)  # E.g. feature_extractor (or model) was saved using *save_pretrained('./test/saved_model/')*
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained("./test/saved_model/preprocessor_config.json")
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base-960h", return_attention_mask=False, foo=False
)
assert feature_extractor.return_attention_mask is False
feature_extractor, unused_kwargs = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base-960h", return_attention_mask=False, foo=False, return_unused_kwargs=True
)
assert feature_extractor.return_attention_mask is False
assert unused_kwargs == {"foo": False}
```

#### `save_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L377)

```py
( save_directory: Union push_to_hub: bool = False **kwargs )
```

参数

+   `save_directory` (`str` 或 `os.PathLike`) — 特征提取器 JSON 文件将保存在的目录（如果不存在将被创建）。

+   `push_to_hub` (`bool`, *可选*, 默认为 `False`) — 在保存模型后是否将其推送到 Hugging Face 模型中心。您可以使用 `repo_id` 指定要推送到的存储库（将默认为您的命名空间中的 `save_directory` 的名称）。

+   `kwargs` (`Dict[str, Any]`, *可选*) — 传递给 push_to_hub() 方法的额外关键字参数。

将 feature_extractor 对象保存到目录 `save_directory`，以便可以使用 from_pretrained() 类方法重新加载。

## SequenceFeatureExtractor

### `class transformers.SequenceFeatureExtractor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_sequence_utils.py#L29)

```py
( feature_size: int sampling_rate: int padding_value: float **kwargs )
```

参数

+   `feature_size` (`int`) — 提取特征的特征维度。

+   `sampling_rate` (`int`) — 应以赫兹（Hz）表示的音频文件数字化的采样率。

+   `padding_value` (`float`) — 用于填充填充值/向量的值。

这是一个用于语音识别的通用特征提取类。

#### `pad`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_sequence_utils.py#L52)

```py
( processed_features: Union padding: Union = True max_length: Optional = None truncation: bool = False pad_to_multiple_of: Optional = None return_attention_mask: Optional = None return_tensors: Union = None )
```

参数

+   `processed_features` (BatchFeature、BatchFeature 列表、`Dict[str, List[float]]`、`Dict[str, List[List[float]]` 或 `List[Dict[str, List[float]]`) — 处理后的输入。可以表示一个输入（BatchFeature 或 `Dict[str, List[float]]`）或一批输入值/向量（BatchFeature 列表、*Dict[str, List[List[float]]]* 或 *List[Dict[str, List[float]]*），因此您可以在预处理期间以及在 PyTorch Dataloader 收集函数中使用此方法。

    您可以使用张量（numpy 数组、PyTorch 张量或 TensorFlow 张量）代替 `List[float]`，请参阅上面的返回类型说明。

+   `padding` (`bool`、`str` 或 PaddingStrategy, *可选*, 默认为 `True`) — 选择一种策略来填充返回的序列（根据模型的填充方向和填充索引）:

    +   `True` 或 `'longest'`: 填充到批次中最长的序列（如果只提供单个序列，则不填充）。

    +   `'max_length'`: 填充到指定的最大长度参数 `max_length` 或模型的最大可接受输入长度（如果未提供该参数）。

    +   `False` 或 `'do_not_pad'` (默认): 无填充（即，可以输出具有不同长度序列的批次）。

+   `max_length` (`int`, *可选*) — 返回列表的最大长度和可选填充长度（见上文）。

+   `截断` (`bool`) — 激活截断以将输入序列长度超过 `max_length` 的部分截断为 `max_length`。

+   `pad_to_multiple_of` (`int`, *可选*) — 如果设置，将序列填充到提供的值的倍数。

    这对于在具有计算能力 `>= 7.5`（Volta）的 NVIDIA 硬件上启用 Tensor Cores，或者在受益于序列长度为 128 的 TPUs 上使用特别有用。

+   `return_attention_mask` (`bool`, *可选*) — 是否返回注意力掩码。如果保持默认值，将根据特定 feature_extractor 的默认值返回注意力掩码。

    什么是注意力掩码？

+   `return_tensors` (`str` 或 TensorType, *可选*) — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为:

    +   `'tf'`: 返回 TensorFlow `tf.constant` 对象。

    +   `'pt'`: 返回 PyTorch `torch.Tensor` 对象。

    +   `'np'`: 返回 Numpy `np.ndarray` 对象。

填充输入值/输入向量或一批输入值/输入向量到预定义长度或批次中的最大序列长度。

填充侧（左/右）填充值在特征提取器级别定义（使用`self.padding_side`，`self.padding_value`）

如果传递的`processed_features`是 numpy 数组、PyTorch 张量或 TensorFlow 张量的字典，则结果将使用相同类型，除非您使用`return_tensors`提供不同的张量类型。在 PyTorch 张量的情况下，您将丢失张量的特定设备。

## BatchFeature

### `class transformers.BatchFeature`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L61)

```py
( data: Optional = None tensor_type: Union = None )
```

参数

+   `data`（`dict`，*可选*）-由**call**/pad 方法返回的列表/数组/张量的字典（'input_values'，'attention_mask'等）。

+   `tensor_type`（`Union[None, str, TensorType]`，*可选*）-您可以在此处提供一个 tensor_type，以在初始化时将整数列表转换为 PyTorch/TensorFlow/Numpy 张量。

保存 pad()和特征提取器特定的`__call__`方法的输出。

此类派生自 Python 字典，可用作字典。

#### `convert_to_tensors`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L164)

```py
( tensor_type: Union = None )
```

参数

+   `tensor_type`（`str`或 TensorType，*可选*）-要使用的张量类型。如果是`str`，应该是枚举 TensorType 值之一。如果是`None`，则不进行修改。

将内部内容转换为张量。

#### `to`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L195)

```py
( *args **kwargs ) → export const metadata = 'undefined';BatchFeature
```

参数

+   `args`（`Tuple`）-将传递给张量的`to(...)`函数。

+   `kwargs`（`Dict`，*可选*）-将传递给张量的`to(...)`函数。

返回

BatchFeature

修改后的相同实例。

通过调用`v.to(*args, **kwargs)`将所有值发送到设备（仅适用于 PyTorch）。这应该支持在不同的`dtypes`中进行转换，并将`BatchFeature`发送到不同的`device`。

## ImageFeatureExtractionMixin

### `class transformers.ImageFeatureExtractionMixin`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L341)

```py
( )
```

包含准备图像特征的实用程序的 Mixin。

#### `center_crop`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L569)

```py
( image size ) → export const metadata = 'undefined';new_image
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`，形状为（n_channels，height，width）或（height，width，n_channels））-要调整大小的图像。

+   `size`（`int`或`Tuple[int, int]`）-要裁剪图像的大小。

返回

new_image

中心裁剪的`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`的形状：（n_channels，height，width）。

使用中心裁剪将`image`裁剪到给定大小。请注意，如果图像太小而无法裁剪到给定大小，则将进行填充（因此返回的结果具有所需的大小）。

#### `convert_rgb`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L383)

```py
( image )
```

参数

+   `image`（`PIL.Image.Image`）-要转换的图像。

将`PIL.Image.Image`转换为 RGB 格式。

#### `expand_dims`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L436)

```py
( image )
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`）-要扩展的图像。

将二维`image`扩展为三维。

#### `flip_channel_order`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L644)

```py
( image )
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`）- 要翻转颜色通道的图像。如果是`np.ndarray`或`torch.Tensor`，通道维度应该在前面。

将`image`的通道顺序从 RGB 翻转为 BGR，或反之。请注意，如果`image`是 PIL 图像，则这将触发将其转换为 NumPy 数组。

#### `normalize`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L456)

```py
( image mean std rescale = False )
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`）- 要归一化的图像。

+   `mean`（`List[float]`或`np.ndarray`或`torch.Tensor`）- 用于归一化的均值（每个通道）。

+   `std`（`List[float]`或`np.ndarray`或`torch.Tensor`）- 用于归一化的标准差（每个通道）。

+   `rescale`（`bool`，*可选*，默认为`False`）- 是否将图像重新缩放为 0 到 1 之间。如果提供了 PIL 图像，缩放将自动发生。

使用`mean`和`std`对`image`进行归一化。请注意，如果`image`是 PIL 图像，则这将触发将其转换为 NumPy 数组。

#### `rescale`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L397)

```py
( image: ndarray scale: Union )
```

按比例缩放 numpy 图像

#### `resize`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L502)

```py
( image size resample = None default_to_square = True max_size = None ) → export const metadata = 'undefined';image
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`）- 要调整大小的图像。

+   `size`（`int`或`Tuple[int, int]`）- 用于调整图像大小的大小。如果`size`是一个类似（h，w）的序列，输出大小将与此匹配。

    如果`size`是一个整数且`default_to_square`为`True`，则图像将被调整为（size，size）。如果`size`是一个整数且`default_to_square`为`False`，则图像的较小边将与此数字匹配。即，如果高度>宽度，则图像将被调整为（size * height / width，size）。

+   `resample`（`int`，*可选*，默认为`PILImageResampling.BILINEAR`）- 用于重采样的滤波器。

+   `default_to_square`（`bool`，*可选*，默认为`True`）- 当`size`是单个整数时如何转换`size`。如果设置为`True`，`size`将被转换为正方形（`size`，`size`）。如果设置为`False`，将复制[`torchvision.transforms.Resize`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Resize)，支持仅调整最小边并提供可选的`max_size`。

+   `max_size`（`int`，*可选*，默认为`None`）- 调整大小后图像较长边的最大允许值：如果图像的较长边大于`max_size`，则根据`size`再次调整图像，使较长边等于`max_size`。因此，`size`可能会被覆盖，即较小的边可能会比`size`短。仅在`default_to_square`为`False`时使用。

返回

图像

一个调整大小的`PIL.Image.Image`。

调整`image`的大小。强制将输入转换为 PIL.Image。

#### `rotate`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L661)

```py
( image angle resample = None expand = 0 center = None translate = None fillcolor = None ) → export const metadata = 'undefined';image
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`）- 要旋转的图像。如果是`np.ndarray`或`torch.Tensor`，将在旋转之前转换为`PIL.Image.Image`。

返回

图像

一个旋转后的`PIL.Image.Image`。

返回旋转后的`image`的副本。此方法返回`image`的副本，将其围绕中心逆时针旋转给定角度。

#### `to_numpy_array`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L404)

```py
( image rescale = None channel_first = True )
```

参数

+   `image`（`PIL.Image.Image`或`np.ndarray`或`torch.Tensor`）- 要转换为 NumPy 数组的图像。

+   `rescale` (`bool`, *optional*) — 是否应用缩放因子（使像素值为 0 到 1 之间的浮点数）。如果图像是 PIL 图像或整数数组/张量，则默认为`True`，否则为`False`。

+   `channel_first` (`bool`, *optional*，默认为`True`) — 是否重新排列图像的维度以将通道维度放在第一维。

将`image`转换为 numpy 数组。可选择重新缩放并将通道维度作为第一维。

#### `to_pil_image`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_utils.py#L353)

```py
( image rescale = None )
```

参数

+   `image` (`PIL.Image.Image`或`numpy.ndarray`或`torch.Tensor`) — 要转换为 PIL 图像格式的图像。

+   `rescale` (`bool`, *optional*) — 是否应用缩放因子（使像素值为 0 到 255 之间的整数）。如果图像类型为浮点类型，则默认为`True`，否则为`False`。

将`image`转换为 PIL 图像。可选择重新缩放并在需要时将通道维度放回最后一个轴。
