# å¯¼å‡ºåˆ° TorchScript

> åŸæ–‡ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/torchscript`](https://huggingface.co/docs/transformers/v4.37.2/en/torchscript)

è¿™æ˜¯æˆ‘ä»¬ä½¿ç”¨ TorchScript çš„å®éªŒçš„å¼€å§‹ï¼Œæˆ‘ä»¬ä»åœ¨æ¢ç´¢å…¶å¯¹äºå¯å˜è¾“å…¥å¤§å°æ¨¡å‹çš„èƒ½åŠ›ã€‚è¿™æ˜¯æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç„¦ç‚¹ï¼Œæˆ‘ä»¬å°†åœ¨å³å°†å‘å¸ƒçš„ç‰ˆæœ¬ä¸­æ·±å…¥åˆ†æï¼Œæä¾›æ›´å¤šä»£ç ç¤ºä¾‹ï¼Œæ›´çµæ´»çš„å®ç°ä»¥åŠå°† Python ä»£ç ä¸ç¼–è¯‘åçš„ TorchScript è¿›è¡Œæ¯”è¾ƒçš„åŸºå‡†æµ‹è¯•ã€‚

æ ¹æ®[TorchScript æ–‡æ¡£](https://pytorch.org/docs/stable/jit.html)ï¼š

> TorchScript æ˜¯ä¸€ç§ä» PyTorch ä»£ç åˆ›å»ºå¯åºåˆ—åŒ–å’Œå¯ä¼˜åŒ–æ¨¡å‹çš„æ–¹æ³•ã€‚

æœ‰ä¸¤ä¸ª PyTorch æ¨¡å—[JIT å’Œ TRACE](https://pytorch.org/docs/stable/jit.html)ï¼Œå…è®¸å¼€å‘äººå‘˜å°†ä»–ä»¬çš„æ¨¡å‹å¯¼å‡ºä»¥ä¾¿åœ¨å…¶ä»–ç¨‹åºä¸­é‡å¤ä½¿ç”¨ï¼Œæ¯”å¦‚é¢å‘æ•ˆç‡çš„ C++ç¨‹åºã€‚

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ¥å£ï¼Œå…è®¸æ‚¨å°†ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºåˆ° TorchScriptï¼Œä»¥ä¾¿åœ¨ä¸åŸºäº PyTorch çš„ Python ç¨‹åºä¸åŒçš„ç¯å¢ƒä¸­é‡å¤ä½¿ç”¨ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨ TorchScript å¯¼å‡ºå’Œä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚

å¯¼å‡ºæ¨¡å‹éœ€è¦ä¸¤ä»¶äº‹ï¼š

+   ä½¿ç”¨`torchscript`æ ‡å¿—å®ä¾‹åŒ–æ¨¡å‹

+   ä½¿ç”¨è™šæ‹Ÿè¾“å…¥è¿›è¡Œå‰å‘ä¼ é€’

è¿™äº›å¿…éœ€å“æ„å‘³ç€å¼€å‘äººå‘˜åº”è¯¥æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ã€‚

## TorchScript æ ‡å¿—å’Œç»‘å®šæƒé‡

`torchscript`æ ‡å¿—æ˜¯å¿…éœ€çš„ï¼Œå› ä¸ºå¤§å¤šæ•°ğŸ¤— Transformers è¯­è¨€æ¨¡å‹çš„`Embedding`å±‚å’Œ`Decoding`å±‚ä¹‹é—´æœ‰ç»‘å®šæƒé‡ã€‚TorchScript ä¸å…è®¸æ‚¨å¯¼å‡ºå…·æœ‰ç»‘å®šæƒé‡çš„æ¨¡å‹ï¼Œå› æ­¤éœ€è¦åœ¨æ­¤ä¹‹å‰è§£å¼€å¹¶å…‹éš†æƒé‡ã€‚

ä½¿ç”¨`torchscript`æ ‡å¿—å®ä¾‹åŒ–çš„æ¨¡å‹å°†å®ƒä»¬çš„`Embedding`å±‚å’Œ`Decoding`å±‚åˆ†å¼€ï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸åº”è¯¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒä¼šä½¿è¿™ä¸¤å±‚ä¸åŒæ­¥ï¼Œå¯¼è‡´æ„å¤–ç»“æœã€‚

å¯¹äºæ²¡æœ‰è¯­è¨€æ¨¡å‹å¤´çš„æ¨¡å‹ï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹æ²¡æœ‰ç»‘å®šæƒé‡ã€‚è¿™äº›æ¨¡å‹å¯ä»¥å®‰å…¨åœ°å¯¼å‡ºè€Œä¸ä½¿ç”¨`torchscript`æ ‡å¿—ã€‚

## è™šæ‹Ÿè¾“å…¥å’Œæ ‡å‡†é•¿åº¦

è™šæ‹Ÿè¾“å…¥ç”¨äºæ¨¡å‹çš„å‰å‘ä¼ é€’ã€‚å½“è¾“å…¥çš„å€¼é€šè¿‡å±‚ä¼ æ’­æ—¶ï¼ŒPyTorch ä¼šè·Ÿè¸ªæ¯ä¸ªå¼ é‡ä¸Šæ‰§è¡Œçš„ä¸åŒæ“ä½œã€‚ç„¶åä½¿ç”¨è¿™äº›è®°å½•çš„æ“ä½œæ¥åˆ›å»ºæ¨¡å‹çš„*trace*ã€‚

è·Ÿè¸ªæ˜¯ç›¸å¯¹äºè¾“å…¥ç»´åº¦åˆ›å»ºçš„ã€‚å› æ­¤ï¼Œå®ƒå—è™šæ‹Ÿè¾“å…¥ç»´åº¦çš„é™åˆ¶ï¼Œå¹¶ä¸”å¯¹äºä»»ä½•å…¶ä»–åºåˆ—é•¿åº¦æˆ–æ‰¹é‡å¤§å°éƒ½ä¸èµ·ä½œç”¨ã€‚å½“å°è¯•ä½¿ç”¨ä¸åŒå¤§å°æ—¶ï¼Œä¼šå¼•å‘ä»¥ä¸‹é”™è¯¯ï¼š

```py
`The expanded size of the tensor (3) must match the existing size (7) at non-singleton dimension 2`
```

æˆ‘ä»¬å»ºè®®æ‚¨ä½¿ç”¨è‡³å°‘ä¸æ¨ç†è¿‡ç¨‹ä¸­å°†é¦ˆé€åˆ°æ¨¡å‹çš„æœ€å¤§è¾“å…¥ä¸€æ ·å¤§çš„è™šæ‹Ÿè¾“å…¥å¤§å°æ¥è·Ÿè¸ªæ¨¡å‹ã€‚å¡«å……å¯ä»¥å¸®åŠ©å¡«è¡¥ç¼ºå¤±çš„å€¼ã€‚ç„¶è€Œï¼Œç”±äºæ¨¡å‹æ˜¯ä½¿ç”¨è¾ƒå¤§çš„è¾“å…¥å¤§å°è·Ÿè¸ªçš„ï¼ŒçŸ©é˜µçš„ç»´åº¦ä¹Ÿä¼šå¾ˆå¤§ï¼Œå¯¼è‡´æ›´å¤šçš„è®¡ç®—ã€‚

è¦æ³¨æ„æ¯ä¸ªè¾“å…¥ä¸Šæ‰§è¡Œçš„æ€»æ“ä½œæ•°ï¼Œå¹¶åœ¨å¯¼å‡ºä¸åŒåºåˆ—é•¿åº¦æ¨¡å‹æ—¶å¯†åˆ‡å…³æ³¨æ€§èƒ½ã€‚

## åœ¨ Python ä¸­ä½¿ç”¨ TorchScript

æœ¬èŠ‚æ¼”ç¤ºäº†å¦‚ä½•ä¿å­˜å’ŒåŠ è½½æ¨¡å‹ä»¥åŠå¦‚ä½•ä½¿ç”¨è·Ÿè¸ªè¿›è¡Œæ¨ç†ã€‚

### ä¿å­˜æ¨¡å‹

è¦å¯¼å‡ºå¸¦æœ‰ TorchScript çš„`BertModel`ï¼Œè¯·ä»`BertConfig`ç±»å®ä¾‹åŒ–`BertModel`ï¼Œç„¶åå°†å…¶ä¿å­˜åˆ°ç£ç›˜ä¸Šçš„æ–‡ä»¶åä¸º`traced_bert.pt`ï¼š

```py
from transformers import BertModel, BertTokenizer, BertConfig
import torch

enc = BertTokenizer.from_pretrained("bert-base-uncased")

# Tokenizing input text
text = "[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]"
tokenized_text = enc.tokenize(text)

# Masking one of the input tokens
masked_index = 8
tokenized_text[masked_index] = "[MASK]"
indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)
segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]

# Creating a dummy input
tokens_tensor = torch.tensor([indexed_tokens])
segments_tensors = torch.tensor([segments_ids])
dummy_input = [tokens_tensor, segments_tensors]

# Initializing the model with the torchscript flag
# Flag set to True even though it is not necessary as this model does not have an LM Head.
config = BertConfig(
    vocab_size_or_config_json_file=32000,
    hidden_size=768,
    num_hidden_layers=12,
    num_attention_heads=12,
    intermediate_size=3072,
    torchscript=True,
)

# Instantiating the model
model = BertModel(config)

# The model needs to be in evaluation mode
model.eval()

# If you are instantiating the model with *from_pretrained* you can also easily set the TorchScript flag
model = BertModel.from_pretrained("bert-base-uncased", torchscript=True)

# Creating the trace
traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])
torch.jit.save(traced_model, "traced_bert.pt")
```

### åŠ è½½æ¨¡å‹

ç°åœ¨ï¼Œæ‚¨å¯ä»¥åŠ è½½å…ˆå‰ä¿å­˜çš„`BertModel`ï¼Œ`traced_bert.pt`ï¼Œä»ç£ç›˜ä¸Šå¹¶åœ¨å…ˆå‰åˆå§‹åŒ–çš„`dummy_input`ä¸Šä½¿ç”¨å®ƒï¼š

```py
loaded_model = torch.jit.load("traced_bert.pt")
loaded_model.eval()

all_encoder_layers, pooled_output = loaded_model(*dummy_input)
```

### ä½¿ç”¨è·Ÿè¸ªæ¨¡å‹è¿›è¡Œæ¨ç†

é€šè¿‡ä½¿ç”¨å…¶`__call__` dunder æ–¹æ³•å¯¹æ¨ç†ä½¿ç”¨è·Ÿè¸ªæ¨¡å‹ï¼š

```py
traced_model(tokens_tensor, segments_tensors)
```

## ä½¿ç”¨ Neuron SDK å°† Hugging Face TorchScript æ¨¡å‹éƒ¨ç½²åˆ° AWS

AWS æ¨å‡ºäº†[Amazon EC2 Inf1](https://aws.amazon.com/ec2/instance-types/inf1/)å®ä¾‹ç³»åˆ—ï¼Œç”¨äºåœ¨äº‘ä¸­è¿›è¡Œä½æˆæœ¬ã€é«˜æ€§èƒ½çš„æœºå™¨å­¦ä¹ æ¨ç†ã€‚Inf1 å®ä¾‹ç”± AWS Inferentia èŠ¯ç‰‡æä¾›åŠ¨åŠ›ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºæ·±åº¦å­¦ä¹ æ¨ç†å·¥ä½œè´Ÿè½½çš„å®šåˆ¶ç¡¬ä»¶åŠ é€Ÿå™¨ã€‚[AWS Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/#)æ˜¯ç”¨äº Inferentia çš„ SDKï¼Œæ”¯æŒè·Ÿè¸ªå’Œä¼˜åŒ– transformers æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨ Inf1 ä¸Šéƒ¨ç½²ã€‚Neuron SDK æä¾›ï¼š

1.  æ˜“äºä½¿ç”¨çš„ APIï¼Œåªéœ€æ›´æ”¹ä¸€è¡Œä»£ç å³å¯è·Ÿè¸ªå’Œä¼˜åŒ– TorchScript æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨äº‘ä¸­è¿›è¡Œæ¨ç†ã€‚

1.  é’ˆå¯¹[æ”¹è¿›çš„æˆæœ¬æ€§èƒ½](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/benchmark/%3E)è¿›è¡Œå³æ’å³ç”¨çš„æ€§èƒ½ä¼˜åŒ–ã€‚

1.  æ”¯æŒä½¿ç”¨[PyTorch](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.html)æˆ–[TensorFlow](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/tensorflow/huggingface_bert/huggingface_bert.html)æ„å»ºçš„ Hugging Face transformers æ¨¡å‹ã€‚

### å½±å“

åŸºäº[BERTï¼ˆæ¥è‡ª Transformers çš„åŒå‘ç¼–ç å™¨è¡¨ç¤ºï¼‰](https://huggingface.co/docs/transformers/main/model_doc/bert)æ¶æ„çš„ transformers æ¨¡å‹ï¼Œæˆ–å…¶å˜ä½“ï¼Œå¦‚[distilBERT](https://huggingface.co/docs/transformers/main/model_doc/distilbert)å’Œ[roBERTa](https://huggingface.co/docs/transformers/main/model_doc/roberta)åœ¨éç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚æå–å¼é—®ç­”ã€åºåˆ—åˆ†ç±»å’Œæ ‡è®°åˆ†ç±»ï¼‰ä¸Šåœ¨ Inf1 ä¸Šè¿è¡Œæ•ˆæœæœ€ä½³ã€‚ç„¶è€Œï¼Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä»å¯ä»¥æ ¹æ®æ­¤[AWS Neuron MarianMT æ•™ç¨‹](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/transformers-marianmt.html)è¿›è¡Œé€‚åº”ä»¥åœ¨ Inf1 ä¸Šè¿è¡Œã€‚æœ‰å…³å¯ä»¥ç›´æ¥åœ¨ Inferentia ä¸Šè½¬æ¢çš„æ¨¡å‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… Neuron æ–‡æ¡£çš„[æ¨¡å‹æ¶æ„é€‚é…](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/models/models-inferentia.html#models-inferentia)éƒ¨åˆ†ã€‚

### ä¾èµ–

ä½¿ç”¨ AWS Neuron è½¬æ¢æ¨¡å‹éœ€è¦ä¸€ä¸ª[Neuron SDK ç¯å¢ƒ](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/pytorch-neuron/index.html#installation-guide)ï¼Œè¯¥ç¯å¢ƒé¢„å…ˆé…ç½®åœ¨[AWS æ·±åº¦å­¦ä¹  AMI](https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-inferentia-launching.html)ä¸Šã€‚

### å°†æ¨¡å‹è½¬æ¢ä¸º AWS Neuron

ä½¿ç”¨ä¸åœ¨ Python ä¸­ä½¿ç”¨ TorchScript ç›¸åŒçš„ä»£ç æ¥ä¸º AWS NEURON è½¬æ¢æ¨¡å‹ï¼Œä»¥è·Ÿè¸ª`BertModel`ã€‚å¯¼å…¥`torch.neuron`æ¡†æ¶æ‰©å±•ä»¥é€šè¿‡ Python API è®¿é—® Neuron SDK çš„ç»„ä»¶ï¼š

```py
from transformers import BertModel, BertTokenizer, BertConfig
import torch
import torch.neuron
```

æ‚¨åªéœ€è¦ä¿®æ”¹ä»¥ä¸‹è¡Œï¼š

```py
- torch.jit.trace(model, [tokens_tensor, segments_tensors])
+ torch.neuron.trace(model, [token_tensor, segments_tensors])
```

è¿™ä½¿å¾— Neuron SDK èƒ½å¤Ÿè·Ÿè¸ªæ¨¡å‹å¹¶ä¸º Inf1 å®ä¾‹è¿›è¡Œä¼˜åŒ–ã€‚

è¦äº†è§£æœ‰å…³ AWS Neuron SDK åŠŸèƒ½ã€å·¥å…·ã€ç¤ºä¾‹æ•™ç¨‹å’Œæœ€æ–°æ›´æ–°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[AWS NeuronSDK æ–‡æ¡£](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html)ã€‚
