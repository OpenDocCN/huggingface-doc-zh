# DePlot

> 原文：[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/deplot`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deplot)

## 概述

DePlot 是由 Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun 在论文[DePlot: One-shot visual language reasoning by plot-to-table translation](https://arxiv.org/abs/2212.10505)中提出的。

该论文的摘要如下：

*图表等视觉语言在人类世界中无处不在。理解图表和图表需要强大的推理能力。先前的最先进（SOTA）模型至少需要数万个训练示例，它们的推理能力仍然非常有限，特别是对于复杂的人类编写的查询。本文提出了视觉语言推理的第一个一次性解决方案。我们将视觉语言推理的挑战分解为两个步骤：（1）图表到文本的翻译，以及（2）对翻译文本进行推理。该方法的关键是一个名为 DePlot 的模态转换模块，它将图表或图表的图像转换为线性化表格。然后可以直接使用 DePlot 的输出来提示预训练的大型语言模型（LLM），利用 LLM 的少量推理能力。为了获得 DePlot，我们通过建立统一的任务格式和度量标准，对绘图到表格任务进行了标准化，并在此任务上端到端地训练 DePlot。然后可以将 DePlot 与 LLM 一起以即插即用的方式使用。与在超过 28k 数据点上微调的 SOTA 模型相比，DePlot+LLM 仅通过一次提示就实现了对人类编写查询的图表 QA 任务的微调 SOTA 的 24.0%的改进。*

DePlot 是使用`Pix2Struct`架构训练的模型。您可以在[Pix2Struct 文档](https://huggingface.co/docs/transformers/main/en/model_doc/pix2struct)中找到有关`Pix2Struct`的更多信息。DePlot 是`Pix2Struct`架构的视觉问答子集。它在图像上呈现输入问题并预测答案。

## 使用示例

目前 DePlot 有一个检查点可用：

+   `google/deplot`：在 ChartQA 数据集上微调的 DePlot

```py
from transformers import AutoProcessor, Pix2StructForConditionalGeneration
import requests
from PIL import Image

model = Pix2StructForConditionalGeneration.from_pretrained("google/deplot")
processor = AutoProcessor.from_pretrained("google/deplot")
url = "https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png"
image = Image.open(requests.get(url, stream=True).raw)

inputs = processor(images=image, text="Generate underlying data table of the figure below:", return_tensors="pt")
predictions = model.generate(**inputs, max_new_tokens=512)
print(processor.decode(predictions[0], skip_special_tokens=True))
```

## 微调

要微调 DePlot，请参考 pix2struct 的[fine-tuning 笔记本](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_pix2struct.ipynb)。对于`Pix2Struct`模型，我们发现使用 Adafactor 和余弦学习率调度程序对模型进行微调可以实现更快的收敛：

```py
from transformers.optimization import Adafactor, get_cosine_schedule_with_warmup

optimizer = Adafactor(self.parameters(), scale_parameter=False, relative_step=False, lr=0.01, weight_decay=1e-05)
scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=40000)
```

DePlot 是使用`Pix2Struct`架构训练的模型。有关 API 参考，请参阅`Pix2Struct`文档。
