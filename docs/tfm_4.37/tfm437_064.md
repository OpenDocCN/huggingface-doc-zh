# æ•…éšœæŽ’é™¤

> åŽŸæ–‡é“¾æŽ¥ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/troubleshooting`](https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting)

æœ‰æ—¶ä¼šå‡ºçŽ°é”™è¯¯ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œå¸®åŠ©æ‚¨ï¼æœ¬æŒ‡å—æ¶µç›–äº†æˆ‘ä»¬è§è¿‡çš„ä¸€äº›æœ€å¸¸è§é—®é¢˜ä»¥åŠæ‚¨å¯ä»¥å¦‚ä½•è§£å†³å®ƒä»¬ã€‚ä½†æ˜¯ï¼Œæœ¬æŒ‡å—å¹¶ä¸æ—¨åœ¨æˆä¸ºæ¯ä¸ªðŸ¤— Transformers é—®é¢˜çš„å…¨é¢é›†åˆã€‚å¦‚éœ€æ›´å¤šæœ‰å…³æ•…éšœæŽ’é™¤çš„å¸®åŠ©ï¼Œè¯·å°è¯•ï¼š

[`www.youtube-nocookie.com/embed/S2EEG3JIt2A`](https://www.youtube-nocookie.com/embed/S2EEG3JIt2A)

1.  åœ¨[è®ºå›](https://discuss.huggingface.co/)ä¸Šå¯»æ±‚å¸®åŠ©ã€‚æ‚¨å¯ä»¥å°†é—®é¢˜å‘å¸ƒåˆ°ç‰¹å®šç±»åˆ«ï¼Œå¦‚[åˆå­¦è€…](https://discuss.huggingface.co/c/beginners/5)æˆ–[ðŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9)ã€‚è¯·ç¡®ä¿ç¼–å†™ä¸€ä¸ªå…·æœ‰ä¸€äº›å¯é‡çŽ°ä»£ç çš„è‰¯å¥½æè¿°æ€§è®ºå›å¸–å­ï¼Œä»¥æœ€å¤§ç¨‹åº¦åœ°æé«˜è§£å†³é—®é¢˜çš„å¯èƒ½æ€§ï¼

[`www.youtube-nocookie.com/embed/_PAli-V4wj0`](https://www.youtube-nocookie.com/embed/_PAli-V4wj0)

1.  å¦‚æžœæ˜¯ä¸Žåº“ç›¸å…³çš„é”™è¯¯ï¼Œè¯·åœ¨ðŸ¤— Transformers å­˜å‚¨åº“ä¸Šåˆ›å»ºä¸€ä¸ª[Issue](https://github.com/huggingface/transformers/issues/new/choose)ã€‚å°½é‡åŒ…å«å°½å¯èƒ½å¤šæè¿°é”™è¯¯çš„ä¿¡æ¯ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ä»¥åŠå¦‚ä½•ä¿®å¤å®ƒã€‚

1.  å¦‚æžœæ‚¨ä½¿ç”¨è¾ƒæ—§ç‰ˆæœ¬çš„ðŸ¤— Transformersï¼Œè¯·æŸ¥çœ‹è¿ç§»æŒ‡å—ï¼Œå› ä¸ºåœ¨ç‰ˆæœ¬ä¹‹é—´å¼•å…¥äº†ä¸€äº›é‡è¦æ›´æ”¹ã€‚

æœ‰å…³æ•…éšœæŽ’é™¤å’ŒèŽ·å–å¸®åŠ©çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Hugging Face è¯¾ç¨‹çš„[ç¬¬å…«ç« ](https://huggingface.co/course/chapter8/1?fw=pt)ã€‚

## é˜²ç«å¢™çŽ¯å¢ƒ

ä¸€äº›äº‘ç«¯å’Œå†…éƒ¨è®¾ç½®çš„ GPU å®žä¾‹è¢«é˜²ç«å¢™é˜»æ­¢å¯¹å¤–éƒ¨è¿žæŽ¥ï¼Œå¯¼è‡´è¿žæŽ¥é”™è¯¯ã€‚å½“æ‚¨çš„è„šæœ¬å°è¯•ä¸‹è½½æ¨¡åž‹æƒé‡æˆ–æ•°æ®é›†æ—¶ï¼Œä¸‹è½½å°†æŒ‚èµ·ï¼Œç„¶åŽè¶…æ—¶å¹¶æ˜¾ç¤ºä»¥ä¸‹æ¶ˆæ¯ï¼š

```py
ValueError: Connection error, and we cannot find the requested files in the cached path.
Please try again or make sure your Internet connection is on.
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥å°è¯•åœ¨ç¦»çº¿æ¨¡å¼ä¸‹è¿è¡ŒðŸ¤— Transformers ä»¥é¿å…è¿žæŽ¥é”™è¯¯ã€‚

## CUDA å†…å­˜ä¸è¶³

åœ¨æ²¡æœ‰é€‚å½“ç¡¬ä»¶çš„æƒ…å†µä¸‹è®­ç»ƒæ‹¥æœ‰æ•°ç™¾ä¸‡å‚æ•°çš„å¤§åž‹æ¨¡åž‹å¯èƒ½ä¼šå¾ˆå…·æŒ‘æˆ˜æ€§ã€‚å½“ GPU å†…å­˜ä¸è¶³æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°çš„å¸¸è§é”™è¯¯æ˜¯ï¼š

```py
CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)
```

ä»¥ä¸‹æ˜¯ä¸€äº›æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆï¼Œæ‚¨å¯ä»¥å°è¯•å‡å°‘å†…å­˜ä½¿ç”¨ï¼š

+   å‡å°‘ TrainingArguments ä¸­çš„`per_device_train_batch_size`å€¼ã€‚

+   å°è¯•åœ¨ TrainingArguments ä¸­ä½¿ç”¨`gradient_accumulation_steps`æ¥æœ‰æ•ˆå¢žåŠ æ€»ä½“æ‰¹é‡å¤§å°ã€‚

æœ‰å…³èŠ‚çœå†…å­˜æŠ€æœ¯çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒæ€§èƒ½æŒ‡å—ã€‚

## æ— æ³•åŠ è½½ä¿å­˜çš„ TensorFlow æ¨¡åž‹

TensorFlow çš„[model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)æ–¹æ³•å°†æ•´ä¸ªæ¨¡åž‹ï¼ˆæž¶æž„ã€æƒé‡ã€è®­ç»ƒé…ç½®ï¼‰ä¿å­˜åœ¨å•ä¸ªæ–‡ä»¶ä¸­ã€‚ç„¶è€Œï¼Œå½“æ‚¨å†æ¬¡åŠ è½½æ¨¡åž‹æ–‡ä»¶æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°é”™è¯¯ï¼Œå› ä¸ºðŸ¤— Transformers å¯èƒ½ä¸ä¼šåŠ è½½æ¨¡åž‹æ–‡ä»¶ä¸­çš„æ‰€æœ‰ä¸Ž TensorFlow ç›¸å…³çš„å¯¹è±¡ã€‚ä¸ºé¿å…ä¿å­˜å’ŒåŠ è½½ TensorFlow æ¨¡åž‹æ—¶å‡ºçŽ°é—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ï¼š

+   ä½¿ç”¨[`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)å°†æ¨¡åž‹æƒé‡ä¿å­˜ä¸º`h5`æ–‡ä»¶æ‰©å±•åï¼Œç„¶åŽä½¿ç”¨ from_pretrained()é‡æ–°åŠ è½½æ¨¡åž‹ï¼š

```py
>>> from transformers import TFPreTrainedModel
>>> from tensorflow import keras

>>> model.save_weights("some_folder/tf_model.h5")
>>> model = TFPreTrainedModel.from_pretrained("some_folder")
```

+   ä½¿ç”¨`~TFPretrainedModel.save_pretrained`ä¿å­˜æ¨¡åž‹ï¼Œç„¶åŽä½¿ç”¨ from_pretrained()å†æ¬¡åŠ è½½å®ƒï¼š

```py
>>> from transformers import TFPreTrainedModel

>>> model.save_pretrained("path_to/model")
>>> model = TFPreTrainedModel.from_pretrained("path_to/model")
```

## ImportError

æ‚¨å¯èƒ½ä¼šé‡åˆ°å¦ä¸€ç§å¸¸è§é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯å¯¹äºŽæ–°å‘å¸ƒçš„æ¨¡åž‹ï¼Œå³`ImportError`ï¼š

```py
ImportError: cannot import name 'ImageGPTImageProcessor' from 'transformers' (unknown location)
```

å¯¹äºŽè¿™äº›é”™è¯¯ç±»åž‹ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ðŸ¤— Transformers ä»¥è®¿é—®æœ€æ–°çš„æ¨¡åž‹ï¼š

```py
pip install transformers --upgrade
```

## CUDA error: device-side assert triggered

æœ‰æ—¶æ‚¨å¯èƒ½ä¼šé‡åˆ°æœ‰å…³è®¾å¤‡ä»£ç é”™è¯¯çš„é€šç”¨ CUDA é”™è¯¯ã€‚

```py
RuntimeError: CUDA error: device-side assert triggered
```

æ‚¨åº”è¯¥é¦–å…ˆå°è¯•åœ¨ CPU ä¸Šè¿è¡Œä»£ç ï¼Œä»¥èŽ·å¾—æ›´è¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯ã€‚å°†ä»¥ä¸‹çŽ¯å¢ƒå˜é‡æ·»åŠ åˆ°æ‚¨çš„ä»£ç å¼€å¤´ä»¥åˆ‡æ¢åˆ° CPUï¼š

```py
>>> import os

>>> os.environ["CUDA_VISIBLE_DEVICES"] = ""
```

å¦ä¸€ä¸ªé€‰é¡¹æ˜¯ä»Ž GPU èŽ·å–æ›´å¥½çš„å›žæº¯ã€‚å°†ä»¥ä¸‹çŽ¯å¢ƒå˜é‡æ·»åŠ åˆ°æ‚¨çš„ä»£ç å¼€å¤´ï¼Œä»¥ä½¿å›žæº¯æŒ‡å‘é”™è¯¯æºï¼š

```py
>>> import os

>>> os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
```

## å½“å¡«å……æ ‡è®°æœªè¢«å±è”½æ—¶è¾“å‡ºä¸æ­£ç¡®

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æžœ`input_ids`åŒ…å«å¡«å……æ ‡è®°ï¼Œåˆ™è¾“å‡ºçš„`hidden_state`å¯èƒ½æ˜¯ä¸æ­£ç¡®çš„ã€‚ä¸ºäº†æ¼”ç¤ºï¼ŒåŠ è½½ä¸€ä¸ªæ¨¡åž‹å’Œåˆ†è¯å™¨ã€‚æ‚¨å¯ä»¥è®¿é—®æ¨¡åž‹çš„`pad_token_id`ä»¥æŸ¥çœ‹å…¶å€¼ã€‚å¯¹äºŽä¸€äº›æ¨¡åž‹ï¼Œ`pad_token_id`å¯èƒ½ä¸º`None`ï¼Œä½†æ‚¨æ€»æ˜¯å¯ä»¥æ‰‹åŠ¨è®¾ç½®å®ƒã€‚

```py
>>> from transformers import AutoModelForSequenceClassification
>>> import torch

>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> model.config.pad_token_id
0
```

ä»¥ä¸‹ç¤ºä¾‹æ˜¾ç¤ºäº†ä¸å±è”½å¡«å……æ ‡è®°æ—¶çš„è¾“å‡ºï¼š

```py
>>> input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [ 0.1317, -0.1683]], grad_fn=<AddmmBackward0>)
```

ä»¥ä¸‹æ˜¯ç¬¬äºŒä¸ªåºåˆ—çš„å®žé™…è¾“å‡ºï¼š

```py
>>> input_ids = torch.tensor([[7592]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥ä¸ºæ‚¨çš„æ¨¡åž‹æä¾›ä¸€ä¸ª`attention_mask`æ¥å¿½ç•¥å¡«å……æ ‡è®°ï¼Œä»¥é¿å…è¿™ç§æ½œåœ¨é”™è¯¯ã€‚çŽ°åœ¨ç¬¬äºŒä¸ªåºåˆ—çš„è¾“å‡ºä¸Žå…¶å®žé™…è¾“å‡ºåŒ¹é…ï¼š

é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ†è¯å™¨æ ¹æ®ç‰¹å®šåˆ†è¯å™¨çš„é»˜è®¤å€¼ä¸ºæ‚¨åˆ›å»º`attention_mask`ã€‚

```py
>>> attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])
>>> output = model(input_ids, attention_mask=attention_mask)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

ðŸ¤— Transformers ä¸ä¼šè‡ªåŠ¨åˆ›å»º`attention_mask`æ¥å±è”½å¡«å……æ ‡è®°ï¼Œå¦‚æžœæä¾›äº†å¡«å……æ ‡è®°ï¼Œå› ä¸ºï¼š

+   ä¸€äº›æ¨¡åž‹æ²¡æœ‰å¡«å……æ ‡è®°ã€‚

+   å¯¹äºŽæŸäº›ç”¨ä¾‹ï¼Œç”¨æˆ·å¸Œæœ›æ¨¡åž‹å…³æ³¨å¡«å……æ ‡è®°ã€‚

## ValueError: Unrecognized configuration class XYZ for this kind of AutoModel

é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ AutoModel ç±»æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡åž‹çš„å®žä¾‹ã€‚è¿™ä¸ªç±»å¯ä»¥æ ¹æ®é…ç½®è‡ªåŠ¨æŽ¨æ–­å’ŒåŠ è½½ç»™å®šæ£€æŸ¥ç‚¹ä¸­çš„æ­£ç¡®æž¶æž„ã€‚å¦‚æžœåœ¨ä»Žæ£€æŸ¥ç‚¹åŠ è½½æ¨¡åž‹æ—¶çœ‹åˆ°`ValueError`ï¼Œè¿™æ„å‘³ç€ Auto ç±»æ— æ³•ä»Žç»™å®šæ£€æŸ¥ç‚¹ä¸­çš„é…ç½®æ‰¾åˆ°åˆ°æ‚¨å°è¯•åŠ è½½çš„æ¨¡åž‹ç±»åž‹çš„æ˜ å°„ã€‚æœ€å¸¸è§çš„æƒ…å†µæ˜¯ï¼Œå½“æ£€æŸ¥ç‚¹ä¸æ”¯æŒç»™å®šä»»åŠ¡æ—¶ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚ä¾‹å¦‚ï¼Œåœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°æ­¤é”™è¯¯ï¼Œå› ä¸ºæ²¡æœ‰ç”¨äºŽé—®ç­”çš„ GPT2ï¼š

```py
>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering

>>> processor = AutoProcessor.from_pretrained("gpt2-medium")
>>> model = AutoModelForQuestionAnswering.from_pretrained("gpt2-medium")
ValueError: Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForQuestionAnswering.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, ...
```
