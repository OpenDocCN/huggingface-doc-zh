# XLNet

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/xlnet`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xlnet)

![模型](https://huggingface.co/models?filter=xlnet) ![空间](https://huggingface.co/spaces/docs-demos/xlnet-base-cased)

## 概述

XLNet 模型是由 Zhilin Yang、Zihang Dai、Yiming Yang、Jaime Carbonell、Ruslan Salakhutdinov、Quoc V. Le 提出的，其论文名为《XLNet: Generalized Autoregressive Pretraining for Language Understanding》(https://arxiv.org/abs/1906.08237)。XLNet 是 Transformer-XL 模型的扩展，使用自回归方法进行预训练，通过最大化输入序列分解顺序的所有排列的期望似然来学习双向上下文。

论文摘要如下：

*具有建模双向上下文的能力，基于去噪自编码的 BERT 比基于自回归语言建模的预训练方法表现更好。然而，BERT 依赖于用掩码损坏输入，忽略了掩码位置之间的依赖关系，并且存在预训练和微调之间的差异。鉴于这些优缺点，我们提出了 XLNet，一种广义的自回归预训练方法，它(1)通过最大化分解顺序的所有排列的期望似然来实现学习双向上下文，(2)通过其自回归公式克服了 BERT 的局限性。此外，XLNet 将 Transformer-XL 的思想整合到预训练中。在可比的实验设置下，XLNet 在 20 个任务中表现优于 BERT，通常差距很大，包括问答、自然语言推理、情感分析和文档排名。*

该模型由[thomwolf](https://huggingface.co/thomwolf)贡献。原始代码可以在[这里](https://github.com/zihangdai/xlnet/)找到。

## 使用提示

+   特定的注意力模式可以通过`perm_mask`输入在训练和测试时进行控制。

+   由于在各种分解顺序上训练完全自回归模型的困难，XLNet 仅使用一部分输出令牌作为目标进行预训练，这些令牌是使用`target_mapping`输入选择的。

+   要将 XLNet 用于顺序解码(即不在完全双向设置中)，请使用`perm_mask`和`target_mapping`输入来控制注意力范围和输出(请参见*examples/pytorch/text-generation/run_generation.py*中的示例)

+   XLNet 是少数没有序列长度限制的模型之一。

+   XLNet 不是传统的自回归模型，而是使用建立在其基础上的训练策略。它对句子中的令牌进行排列，然后允许模型使用最后 n 个令牌来预测第 n+1 个令牌。由于这一切都是通过掩码完成的，因此实际上是以正确顺序将句子输入模型，但是 XLNet 使用一个掩码，隐藏了给定排列中 1,…，序列长度之间的先前令牌，而不是为 n+1 掩码前 n 个令牌。

+   XLNet 还使用与 Transformer-XL 相同的循环机制来构建长期依赖关系。

## 资源

+   文本分类任务指南

+   标记分类任务指南

+   问答任务指南

+   因果语言建模任务指南

+   多项选择任务指南

## XLNetConfig

### `class transformers.XLNetConfig`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/configuration_xlnet.py#L32)

```py
( vocab_size = 32000 d_model = 1024 n_layer = 24 n_head = 16 d_inner = 4096 ff_activation = 'gelu' untie_r = True attn_type = 'bi' initializer_range = 0.02 layer_norm_eps = 1e-12 dropout = 0.1 mem_len = 512 reuse_len = None use_mems_eval = True use_mems_train = False bi_data = False clamp_len = -1 same_length = False summary_type = 'last' summary_use_proj = True summary_activation = 'tanh' summary_last_dropout = 0.1 start_n_top = 5 end_n_top = 5 pad_token_id = 5 bos_token_id = 1 eos_token_id = 2 **kwargs )
```

参数

+   `vocab_size` (`int`, *optional*, defaults to 32000) — XLNet 模型的词汇量。定义了在调用 XLNetModel 或 TFXLNetModel 时可以表示的不同标记数量。

+   `d_model` (`int`, *optional*, defaults to 1024) — 编码器层和池化层的维度。

+   `n_layer` (`int`, *optional*, defaults to 24) — Transformer 编码器中的隐藏层数。

+   `n_head` (`int`, *optional*, defaults to 16) — Transformer 编码器中每个注意力层的注意力头数。

+   `d_inner` (`int`, *optional*, defaults to 4096) — Transformer 编码器中“中间”（通常称为前馈）层的维度。

+   `ff_activation` (`str` or `Callable`, *optional*, defaults to `"gelu"`) — 在 Transformer 编码器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。

+   `untie_r` (`bool`, *optional*, defaults to `True`) — 是否解开相对位置偏差

+   `attn_type` (`str`, *optional*, defaults to `"bi"`) — 模型使用的注意力类型。为 XLNet 设置`"bi"`，为 Transformer-XL 设置`"uni"`。

+   `initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。

+   `layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的 epsilon。

+   `dropout` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的丢失概率。

+   `mem_len` (`int` or `None`, *optional*) — 要缓存的标记数。已经在先前的前向传递中预先计算的键/值对不会重新计算。有关更多信息，请参阅[快速入门](https://huggingface.co/transformers/quickstart.html#using-the-past)。

+   `reuse_len` (`int`, *optional*) — 当前批次中要缓存和将来重复使用的标记数。

+   `bi_data` (`bool`, *optional*, defaults to `False`) — 是否使用双向输入管道。通常在预训练期间设置为`True`，在微调期间设置为`False`。

+   `clamp_len` (`int`, *optional*, defaults to -1) — 将大于 clamp_len 的所有相对距离限制。将此属性设置为-1 表示不限制。

+   `same_length` (`bool`, *optional*, defaults to `False`) — 是否对每个标记使用相同的注意力长度。

+   `summary_type` (`str`, *optional*, defaults to “last”) — 在进行序列摘要时使用的参数。用于序列分类和多选模型。

    必须是以下选项之一：

    +   `"last"`: 取最后一个标记的隐藏状态（类似于 XLNet）。

    +   `"first"`: 取第一个标记的隐藏状态（类似于 BERT）。

    +   `"mean"`: 取所有标记隐藏状态的平均值。

    +   `"cls_index"`: 提供分类标记位置的张量（类似于 GPT/GPT-2）。

    +   `"attn"`: 目前未实现，使用多头注意力。

+   `summary_use_proj` (`bool`, *optional*, defaults to `True`) — 在进行序列摘要时使用的参数。用于序列分类和多选模型。

    是否在向量提取后添加投影。

+   `summary_activation` (`str`, *optional*) — 在进行序列摘要时使用的参数。用于序列分类和多选模型。

    将输出传递给 tanh 激活以获得 tanh 激活，其他任何值都将导致无激活。

+   `summary_proj_to_labels` (`boo`, *optional*, defaults to `True`) — 用于序列分类和多选模型。

    投影输出应具有`config.num_labels`或`config.hidden_size`类。

+   `summary_last_dropout` (`float`, *optional*, defaults to 0.1) — 用于序列分类和多选模型。

    在投影和激活之后要使用的丢失比率。

+   `start_n_top` (`int`, *optional*, defaults to 5) — 在 SQuAD 评估脚本中使用。

+   `end_n_top` (`int`, *optional*, defaults to 5) — 在 SQuAD 评估脚本中使用。

+   `use_mems_eval` (`bool`, *optional*, defaults to `True`) — 模型在评估模式下是否应使用循环记忆机制。

+   `use_mems_train` (`bool`, *optional*, defaults to `False`) — 模型在训练模式下是否应使用循环记忆机制。

    对于预训练，建议将 `use_mems_train` 设置为 `True`。对于微调，建议将 `use_mems_train` 设置为 `False`，如[此处](https://github.com/zihangdai/xlnet/issues/41#issuecomment-505102587)所述。如果将 `use_mems_train` 设置为 `True`，则必须确保训练批次已正确预处理，例如 `batch_1 = [[This line is], [This is the]]` 和 `batch_2 = [[ the first line], [ second line]]`，并且所有批次大小相等。

这是用于存储 XLNetModel 或 TFXLNetModel 配置的类。根据指定的参数实例化 XLNet 模型，定义模型架构。使用默认值实例化配置将产生类似于 [xlnet-large-cased](https://huggingface.co/xlnet-large-cased) 架构的配置。

配置对象继承自 PretrainedConfig，可用于控制模型输出。阅读来自 PretrainedConfig 的文档以获取更多信息。

示例：

```py
>>> from transformers import XLNetConfig, XLNetModel

>>> # Initializing a XLNet configuration
>>> configuration = XLNetConfig()

>>> # Initializing a model (with random weights) from the configuration
>>> model = XLNetModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## XLNetTokenizer

### `class transformers.XLNetTokenizer`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet.py#L53)

```py
( vocab_file do_lower_case = False remove_space = True keep_accents = False bos_token = '<s>' eos_token = '</s>' unk_token = '<unk>' sep_token = '<sep>' pad_token = '<pad>' cls_token = '<cls>' mask_token = '<mask>' additional_special_tokens = ['<eop>', '<eod>'] sp_model_kwargs: Optional = None **kwargs )
```

参数

+   `vocab_file` (`str`) — 包含实例化标记器所需词汇的 [SentencePiece](https://github.com/google/sentencepiece) 文件（通常具有 .spm 扩展名）。

+   `do_lower_case` (`bool`, *optional*, defaults to `False`) — 是否在标记化时将输入转换为小写。

+   `remove_space` (`bool`, *optional*, defaults to `True`) — 在标记化时是否去除文本中的空格（删除字符串前后的多余空格）。

+   `keep_accents` (`bool`, *optional*, defaults to `False`) — 在标记化时是否保留重音。

+   `bos_token` (`str`, *optional*, defaults to `"<s>"`) — 在预训练期间使用的序列开始标记。可用作序列分类器标记。

    构建序列时，这不是用于序列开头的标记。使用的标记是 `cls_token`。

+   `eos_token` (`str`, *optional*, defaults to `"</s>"`) — 序列结束标记。

    构建序列时，这不是用于序列结尾的标记。使用的标记是 `sep_token`。

+   `unk_token` (`str`, *optional*, defaults to `"<unk>"`) — 未知标记。词汇表中不存在的标记无法转换为 ID，而是设置为此标记。

+   `sep_token` (`str`, *optional*, defaults to `"<sep>"`) — 分隔符标记，用于从多个序列构建序列，例如用于序列分类的两个序列或用于文本和问题的问题回答。还用作使用特殊标记构建的序列的最后一个标记。

+   `pad_token` (`str`, *optional*, defaults to `"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。

+   `cls_token` (`str`, *可选*, 默认为 `"<cls>"`) — 在进行序列分类（对整个序列进行分类而不是每个标记的分类）时使用的分类器标记。在构建带有特殊标记的序列时，它是序列的第一个标记。

+   `mask_token` (`str`, *可选*, 默认为 `"<mask>"`) — 用于屏蔽值的标记。在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。

+   `additional_special_tokens` (`List[str]`, *可选*, 默认为 `['<eop>', '<eod>']`) — 分词器使用的额外特殊标记。

+   `sp_model_kwargs` (`dict`, *可选*) — 将传递给`SentencePieceProcessor.__init__()`方法。[SentencePiece 的 Python 包装器](https://github.com/google/sentencepiece/tree/master/python)可用于设置：

    +   `enable_sampling`: 启用子词正则化。

    +   `nbest_size`: 单字采样参数。对于 BPE-Dropout 无效。

        +   `nbest_size = {0,1}`: 不执行采样。

        +   `nbest_size > 1`: 从 nbest_size 结果中进行采样。

        +   `nbest_size < 0`: 假设 nbest_size 为无限，并使用前向过滤和后向采样算法从所有假设（格）中进行采样。

    +   `alpha`: 用于单字采样的平滑参数，以及用于 BPE-dropout 合并操作的丢弃概率。

+   `sp_model` (`SentencePieceProcessor`) — 用于每次转换（字符串、标记和 ID）的*SentencePiece*处理器。

构建一个 XLNet 分词器。基于[SentencePiece](https://github.com/google/sentencepiece)。

此分词器继承自 PreTrainedTokenizer，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。

#### `build_inputs_with_special_tokens`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet.py#L298)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — 将添加特殊标记的 ID 列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的第二个 ID 列表（可选）。

返回

`List[int]`

带有适当特殊标记的输入 ID 列表。

通过连接和添加特殊标记从序列或序列对构建用于序列分类任务的模型输入。一个 XLNet 序列的格式如下：

+   单个序列: `X <sep> <cls>`

+   序列对：`A <sep> B <sep> <cls>`

#### `get_special_tokens_mask`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet.py#L323)

```py
( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — ID 列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的第二个 ID 列表（可选）。

+   `already_has_special_tokens` (`bool`, *可选*, 默认为 `False`) — 标记列表是否已经使用特殊标记格式化为模型。

返回

`List[int]`

一个整数列表，范围为[0, 1]：1 表示特殊标记，0 表示序列标记。

从没有添加特殊标记的标记列表中检索序列 ID。在使用分词器的`prepare_for_model`方法添加特殊标记时调用此方法。

#### `create_token_type_ids_from_sequences`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet.py#L351)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0` (`List[int]`) — ID 列表。

+   `token_ids_1` (`List[int]`, *可选*) — 序列对的第二个 ID 列表（可选）。

返回

`List[int]`

根据给定序列的标记类型 ID 列表。

从传递的两个序列创建一个用于序列对分类任务的掩码。一个 XLNet

序列对掩码的格式如下：

```py
0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
| first sequence    | second sequence |
```

如果`token_ids_1`为`None`，则此方法仅返回掩码的第一部分（0s）。

#### `save_vocabulary`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet.py#L381)

```py
( save_directory: str filename_prefix: Optional = None )
```

## XLNetTokenizerFast

### `class transformers.XLNetTokenizerFast`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet_fast.py#L63)

```py
( vocab_file = None tokenizer_file = None do_lower_case = False remove_space = True keep_accents = False bos_token = '<s>' eos_token = '</s>' unk_token = '<unk>' sep_token = '<sep>' pad_token = '<pad>' cls_token = '<cls>' mask_token = '<mask>' additional_special_tokens = ['<eop>', '<eod>'] **kwargs )
```

参数

+   `vocab_file`（`str`）— [SentencePiece](https://github.com/google/sentencepiece) 文件（通常具有.spm 扩展名），其中包含实例化标记器所需的词汇。

+   `do_lower_case`（`bool`，*可选*，默认为`True`）— 在标记化时是否将输入转换为小写。

+   `remove_space`（`bool`，*可选*，默认为`True`）— 在标记化时是否去除文本（删除字符串前后的多余空格）。

+   `keep_accents`（`bool`，*可选*，默认为`False`）— 在标记化时是否保留重音。

+   `bos_token`（`str`，*可选*，默认为`"<s>"`）— 在预训练期间使用的序列开始标记。可用作序列分类器标记。

    在使用特殊标记构建序列时，这不是用于序列开始的标记。使用的标记是`cls_token`。

+   `eos_token`（`str`，*可选*，默认为`"</s>"`）— 序列结束标记。

    在使用特殊标记构建序列时，这不是用于序列结束的标记。使用的标记是`sep_token`。

+   `unk_token`（`str`，*可选*，默认为`"<unk>"`）— 未知标记。词汇表中不存在的标记无法转换为 ID，而是设置为此标记。

+   `sep_token`（`str`，*可选*，默认为`"<sep>"`）— 分隔符标记，在构建来自多个序列的序列时使用，例如用于序列分类的两个序列或用于问题回答的文本和问题。它还用作使用特殊标记构建的序列的最后一个标记。

+   `pad_token`（`str`，*可选*，默认为`"<pad>"`）— 用于填充的标记，例如在批处理不同长度的序列时使用。

+   `cls_token`（`str`，*可选*，默认为`"<cls>"`）— 在进行序列分类（整个序列的分类而不是每个标记的分类）时使用的分类器标记。在使用特殊标记构建时，它是序列的第一个标记。

+   `mask_token`（`str`，*可选*，默认为`"<mask>"`）— 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。

+   `additional_special_tokens`（`List[str]`，*可选*，默认为`["<eop>", "<eod>"]`）— 标记器使用的其他特殊标记。

+   `sp_model`（`SentencePieceProcessor`）— 用于每次转换（字符串、标记和 ID）的*SentencePiece*处理器。

构建“快速”XLNet 标记器（由 HuggingFace 的*tokenizers*库支持）。基于[Unigram](https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=unigram#models)。

此标记器继承自 PreTrainedTokenizerFast，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。

#### `build_inputs_with_special_tokens`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet_fast.py#L177)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）— 将添加特殊标记的 ID 列表。

+   `token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个 ID 列表。

返回

`List[int]`

具有适当特殊标记的 input IDs 列表。

通过连接和添加特殊标记，为序列分类任务构建来自序列或序列对的模型输入。XLNet 序列的格式如下：

+   单个序列：`X <sep> <cls>`

+   序列对：`A <sep> B <sep> <cls>`

#### `create_token_type_ids_from_sequences`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/tokenization_xlnet_fast.py#L202)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）- ID 列表。

+   `token_ids_1`（`List[int]`，*可选*）- 序列对的第二个 ID 列表（可选）。

返回

`List[int]`

根据给定的序列，列出令牌类型 ID。

从传递的两个序列创建一个用于序列对分类任务的掩码。一个 XLNet

序列对掩码的格式如下：

```py
0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
| first sequence    | second sequence |
```

如果`token_ids_1`为`None`，则此方法仅返回掩码的第一部分（0）。

## XLNet 特定的输出

### `class transformers.models.xlnet.modeling_xlnet.XLNetModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L578)

```py
( last_hidden_state: FloatTensor mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, num_predict, hidden_size)`的`torch.FloatTensor`）- 模型最后一层的隐藏状态序列。

    `num_predict`对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去传递给此模型的令牌 ID 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetModel 的输出类型。

### `class transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L612)

```py
( loss: Optional = None logits: FloatTensor = None mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss`（形状为*(1,)*的`torch.FloatTensor`，*可选*，当提供`labels`时返回）- 语言建模损失（用于下一个令牌预测）。

+   `logits`（形状为`(batch_size, num_predict, config.vocab_size)`的`torch.FloatTensor`）- 语言建模头的预测分数（SoftMax 之前每个词汇令牌的分数）。

    `num_predict`对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去传递给此模型的令牌 ID 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重在注意力 softmax 之后，用于计算自注意力头中的加权平均值。

XLNetLMHeadModel 的输出类型。

### `class transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassificationOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L649)

```py
( loss: Optional = None logits: FloatTensor = None mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*, 当提供`label`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax 之前）。

+   `mems` (`List[torch.FloatTensor]`，长度为`config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码。将过去给定给该模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重在注意力 softmax 之后，用于计算自注意力头中的加权平均值。

XLNetForSequenceClassification 的输出类型。

### `class transformers.models.xlnet.modeling_xlnet.XLNetForMultipleChoiceOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L717)

```py
( loss: Optional = None logits: FloatTensor = None mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为*(1,)*，*可选*, 当提供`labels`时返回) — 分类损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, num_choices)`) — *num_choices*是输入张量的第二维度。（参见上面的*input_ids*）。

    分类得分（SoftMax 之前）。

+   `mems` (`List[torch.FloatTensor]`，长度为`config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码。将过去给定给该模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力权重在注意力 softmax 之后，用于计算自注意力头中的加权平均值。

XLNetForMultipleChoice 的输出类型。

### `class transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassificationOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L683)

```py
( loss: Optional = None logits: FloatTensor = None mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类损失。

+   `logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.num_labels)`) — 分类分数（SoftMax 之前）。

+   `mems` (`List[torch.FloatTensor]`，长度为`config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去传递给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

`XLNetForTokenClassificationOutput`的输出类型。

### `class transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringSimpleOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L753)

```py
( loss: Optional = None start_logits: FloatTensor = None end_logits: FloatTensor = None mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 总跨度提取损失是开始和结束位置的交叉熵之和。

+   `start_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,)`) — 跨度开始分数（SoftMax 之前）。

+   `end_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,)`) — 跨度结束分数（SoftMax 之前）。

+   `mems` (`List[torch.FloatTensor]`，长度为`config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去传递给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForQuestionAnsweringSimple 的输出类型。

### `class transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L790)

```py
( loss: Optional = None start_top_log_probs: Optional = None start_top_index: Optional = None end_top_log_probs: Optional = None end_top_index: Optional = None cls_logits: Optional = None mems: Optional = None hidden_states: Optional = None attentions: Optional = None )
```

参数

+   `loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，如果提供了`start_positions`和`end_positions`则返回) — 分类损失，作为开始标记、结束标记（如果提供）的分类损失之和。

+   `start_top_log_probs`（形状为`(batch_size, config.start_n_top)`的`torch.FloatTensor`，*可选*，如果未提供`start_positions`或`end_positions`则返回）- 顶部`config.start_n_top`开始标记可能性（波束搜索）的对数概率。

+   `start_top_index`（形状为`(batch_size, config.start_n_top)`的`torch.LongTensor`，*可选*，如果未提供`start_positions`或`end_positions`则返回）- 顶部`config.start_n_top`开始标记可能性（波束搜索）的索引。

+   `end_top_log_probs`（形状为`(batch_size, config.start_n_top * config.end_n_top)`的`torch.FloatTensor`，*可选*，如果未提供`start_positions`或`end_positions`则返回）- 顶部`config.start_n_top * config.end_n_top`结束标记可能性（波束搜索）的对数概率。

+   `end_top_index`（形状为`(batch_size, config.start_n_top * config.end_n_top)`的`torch.LongTensor`，*可选*，如果未提供`start_positions`或`end_positions`则返回）- 顶部`config.start_n_top * config.end_n_top`结束标记可能性（波束搜索）的索引。

+   `cls_logits`（形状为`(batch_size,)`的`torch.FloatTensor`，*可选*，如果未提供`start_positions`或`end_positions`则返回）- 答案的`is_impossible`标签的对数概率。

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（查看`mems`输入）。将其过去给予该模型的标记 id 不应作为`input_ids`传递，因为它们已经被计算过。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForQuestionAnswering 的输出类型。

### `class transformers.models.xlnet.modeling_tf_xlnet.TFXLNetModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L844)

```py
( last_hidden_state: tf.Tensor = None mems: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `last_hidden_state`（形状为`(batch_size, num_predict, hidden_size)`的`tf.Tensor`）- 模型最后一层的隐藏状态序列。

    `num_predict`对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems`（长度为`config.n_layers`的`List[tf.Tensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（查看`mems`输入）。将其过去给予该模型的标记 id 不应作为`input_ids`传递，因为它们已经被计算过。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetModel 的输出类型。

### `class transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModelOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L878)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None mems: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`形状为*(1,)*的 tf.Tensor`，*可选*，当提供`labels`时返回) — 语言建模损失（用于下一个标记预测）。

+   `logits` (`形状为`(batch_size, num_predict, config.vocab_size)`的 tf.Tensor`) — 语言建模头的预测分数（SoftMax 之前每个词汇标记的分数）。

    `num_predict`对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems` (`长度为`config.n_layers`的 List[tf.Tensor]`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去给定给该模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetLMHeadModel 的输出类型。

### `class transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForSequenceClassificationOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L915)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None mems: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`tf.Tensor`，形状为`(1,)`，*可选*，当提供`label`时返回) — 分类（如果 config.num_labels==1 则为回归）损失。

+   `logits` (`形状为`(batch_size, config.num_labels)`的 tf.Tensor`) — 分类（如果 config.num_labels==1 则为回归）分数（SoftMax 之前）。

+   `mems` (`长度为`config.n_layers`的 List[tf.Tensor]`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去给定给该模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetForSequenceClassification 的输出类型。

### `class transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForMultipleChoiceOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L983)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None mems: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`形状为`(1,)`的`tf.Tensor`, *optional*, 当提供`labels`时返回) — 分类损失。

+   `logits` (`形状为`(batch_size, num_choices)`的`tf.Tensor`) — *num_choices*是输入张量的第二维度。（参见上面的*input_ids*）。

    分类分数（SoftMax 之前）。

+   `mems` (`长度为`config.n_layers`的`List[tf.Tensor]`) — 包含预先计算的隐藏状态。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每层的输出）。

    模型每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetForMultipleChoice 的输出类型。

### `class transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassificationOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L949)

```py
( loss: tf.Tensor | None = None logits: tf.Tensor = None mems: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`形状为`(1,)`的`tf.Tensor`, *optional*, 当提供`labels`时返回) — 分类损失。

+   `logits` (`形状为`(batch_size, sequence_length, config.num_labels)`的`tf.Tensor`) — 分类分数（SoftMax 之前）。

+   `mems` (`长度为`config.n_layers`的`List[tf.Tensor]`) — 包含预先计算的隐藏状态。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每层的输出）。

    模型每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

`TFXLNetForTokenClassificationOutput`的输出类型。

### `class transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimpleOutput`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1019)

```py
( loss: tf.Tensor | None = None start_logits: tf.Tensor = None end_logits: tf.Tensor = None mems: List[tf.Tensor] | None = None hidden_states: Tuple[tf.Tensor] | None = None attentions: Tuple[tf.Tensor] | None = None )
```

参数

+   `loss` (`形状为`(1,)`的`tf.Tensor`, *optional*, 当提供`labels`时返回) — 总跨度提取损失是起始和结束位置的交叉熵之和。

+   `start_logits` (`形状为`(batch_size, sequence_length,)`的`tf.Tensor`) — 跨度起始分数（SoftMax 之前）。

+   `end_logits` (`形状为`(batch_size, sequence_length,)`的`tf.Tensor`) — 跨度结束分数（SoftMax 之前）。

+   `mems` (`长度为`config.n_layers`的`List[tf.Tensor]`) — 包含预先计算的隐藏状态。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递 `output_hidden_states=True` 或 `config.output_hidden_states=True` 时返回） — 形状为 `(batch_size, sequence_length, hidden_size)` 的 `tf.Tensor` 元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递 `output_attentions=True` 或 `config.output_attentions=True` 时返回） — 形状为 `(batch_size, num_heads, sequence_length, sequence_length)` 的 `tf.Tensor` 元组（每个层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetForQuestionAnsweringSimple 的输出类型。

PytorchHide Pytorch 内容

## XLNetModel

### `class transformers.XLNetModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L927)

```py
( config )
```

参数

+   `config`（XLNetConfig） — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained() 方法以加载模型权重。

裸的 XLNet 模型变压器输出原始隐藏状态，没有特定的头部。

这个模型继承自 PreTrainedModel。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。

这个模型也是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) 子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有信息。

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1059)

```py
( input_ids: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None token_type_ids: Optional = None input_mask: Optional = None head_mask: Optional = None inputs_embeds: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetModelOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids`（形状为 `(batch_size, sequence_length)` 的 `torch.LongTensor`） — 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。查看 PreTrainedTokenizer.encode() 和 PreTrainedTokenizer.`call`() 以获取详细信息。

    什么是输入 ID？

+   `attention_mask`（形状为 `(batch_size, sequence_length)` 的 `torch.FloatTensor`，*可选*） — 避免在填充标记索引上执行注意力的掩码。掩码值选在 `[0, 1]`：

    +   对于未被 `masked` 的标记为 1，

    +   对于被 `masked` 的标记为 0。

    什么是注意力掩码？

+   `mems`（长度为 `config.n_layers` 的 `List[torch.FloatTensor]`） — 包含预先计算的隐藏状态（参见下面的 `mems` 输出）。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为 `input_ids` 传递，因为它们已经计算过了。

    `use_mems` 必须设置为 `True` 才能使用 `mems`。

+   `perm_mask`（形状为 `(batch_size, sequence_length, sequence_length)` 的 `torch.FloatTensor`，*可选*） — 用于指示每个输入标记的注意力模式的掩码，值选在 `[0, 1]`：

    +   如果 `perm_mask[k, i, j] = 0`，则在批次 k 中我关注 j；

    +   如果 `perm_mask[k, i, j] = 1`，则在批次 k 中 i 不关注 j。

    如果未设置，每个标记都会关注其他所有标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于指示要使用的输出标记的掩码。如果`target_mapping[k, i, j] = 1`，则第 k 批次中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）- 段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应一个*句子 A*标记，

    +   1 对应一个*句子 B*标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, sequence_length`的`torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。负的`attention_mask`，即对于真实标记为 0，对于填充为 1，这保留了与原始代码库的兼容性。

    选择的掩码值在`[0, 1]`中：

    +   1 用于被`masked`的标记，

    +   0 用于未被`masked`的标记。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）- 用于使自注意力模块的选定头部失效的掩码。选择的掩码值在`[0, 1]`中：

    +   1 表示头部未被`masked`，

    +   0 表示头部被`masked`。

+   `inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）- 可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制权来将`input_ids`索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。

+   `output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量中的`attentions`。

+   `output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量中的`hidden_states`。

+   `return_dict`（`bool`，*可选*）- 是否返回一个 ModelOutput 而不是一个普通元组。

返回

transformers.models.xlnet.modeling_xlnet.XLNetModelOutput 或`tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetModelOutput 或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（XLNetConfig）和输入的各种元素。

+   `last_hidden_state`（形状为`(batch_size, num_predict, hidden_size)`的`torch.FloatTensor`）- 模型最后一层的隐藏状态序列。

    `num_predict` 对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（请参见`mems`输入）。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每层输出的隐藏状态以及初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetModel 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行前后处理步骤，而后者会默默忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, XLNetModel
>>> import torch

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetModel.from_pretrained("xlnet-base-cased")

>>> inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
>>> outputs = model(**inputs)

>>> last_hidden_states = outputs.last_hidden_state
```

## XLNetLMHeadModel

### `class transformers.XLNetLMHeadModel`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1288)

```py
( config )
```

参数

+   `config`（XLNetConfig） — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained()方法以加载模型权重。

在顶部带有语言建模头的 XLNet 模型（线性层，权重与输入嵌入绑定）。

此模型继承自 PreTrainedModel。检查超类文档以获取库为其所有模型实现的通用方法（例如下载或保存，调整输入嵌入，修剪头等）。

此模型也是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取与一般用法和行为相关的所有内容。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1356)

```py
( input_ids: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None token_type_ids: Optional = None input_mask: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModelOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`） — 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。查看 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()以获取详细信息。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*） — 避免在填充标记索引上执行注意力的掩码。掩码值在`[0, 1]`中选择：

    +   对于`not masked`的标记为 1。

    +   对于被`masked`的标记为 0。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`） — 包含预先计算的隐藏状态（参见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*） — 用于指示每个输入标记的注意力模式的掩码，值在`[0, 1]`中选择：

    +   如果`perm_mask[k, i, j] = 0`，则在批次 k 中，i 参与 j；

    +   如果`perm_mask[k, i, j] = 1`，则在批次 k 中，i 不参与 j。

    如果未设置，则每个标记都会关注其他所有标记（完全双向注意力）。仅在预训练期间使用（用于定义分解顺序）或用于顺序解码（生成）。

+   `target_mapping` (`torch.FloatTensor`，形状为 `(batch_size, num_predict, sequence_length)`，*可选*) — 用于指示要使用的输出标记。如果 `target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`，*可选*) — 段标记索引，指示输入的第一部分和第二部分。索引选择在 `[0, 1]`：

    +   0 对应于 *句子 A* 的标记，

    +   1 对应于 *句子 B* 的标记。

    什么是标记类型 ID？

+   `input_mask` (`torch.FloatTensor`，形状为 `batch_size, sequence_length`，*可选*) — 用于避免在填充标记索引上执行注意力的掩码。是 `attention_mask` 的负值，即对于真实标记为 0，对于填充标记为 1，这是为了与原始代码基础保持兼容性。

    掩码值选择在 `[0, 1]`：

    +   1 表示被掩盖的标记，

    +   0 表示未被掩盖的标记。

    您只能使用 `input_mask` 和 `attention_mask` 中的一个。

+   `head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*) — 用于使自注意力模块的选定头部失效的掩码。掩码值选择在 `[0, 1]`：

    +   1 表示头部未被掩盖，

    +   0 表示头部被掩盖。

+   `inputs_embeds` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*可选*) — 可选地，您可以选择直接传递嵌入表示而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids` 索引转换为关联向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。

+   `output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回的张量下的 `attentions`。

+   `output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回的张量下的 `hidden_states`。

+   `return_dict` (`bool`, *可选*) — 是否返回一个 ModelOutput 而不是一个普通的元组。

+   `labels` (`torch.LongTensor`，形状为 `(batch_size, num_predict)`，*可选*) — 用于掩盖语言建模的标签。`num_predict` 对应于 `target_mapping.shape[1]`。如果 `target_mapping` 为 `None`，则 `num_predict` 对应于 `sequence_length`。

    标签应该对应于应该被预测的被掩盖输入词，并取决于 `target_mapping`。请注意，为了执行标准的自回归语言建模，必须向 `input_ids` 添加一个 *<mask></mask>* 标记（请参见 `prepare_inputs_for_generation` 函数和下面的示例）

    索引选择在 `[-100, 0, ..., config.vocab_size]` 所有标签设置为 `-100` 的将被忽略，损失仅计算标签在 `[0, ..., config.vocab_size]` 中的标签

返回

transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModelOutput 或 `tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModelOutput 或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False` 时）包含根据配置（XLNetConfig）和输入的不同元素。

+   `loss` (`torch.FloatTensor`，形状为 *(1,)*，*可选*，当提供 `labels` 时返回) 语言建模损失（用于下一个标记预测）。

+   `logits` (`torch.FloatTensor`，形状为 `(batch_size, num_predict, config.vocab_size)`) — 语言建模头的预测分数（SoftMax 之前每个词汇标记的分数）。

    `num_predict` 对应于 `target_mapping.shape[1]`。如果 `target_mapping` 是 `None`，那么 `num_predict` 对应于 `sequence_length`。

+   `mems` (`List[torch.FloatTensor]`，长度为 `config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为 `input_ids` 传递，因为它们已经计算过了。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递 `output_hidden_states=True` 或 `config.output_hidden_states=True` 时返回） — 形状为 `(batch_size, sequence_length, hidden_size)` 的 `torch.FloatTensor` 元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出以及初始嵌入输出的隐藏状态。 

+   `attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递 `output_attentions=True` 或 `config.output_attentions=True` 时返回） — 形状为 `(batch_size, num_heads, sequence_length, sequence_length)` 的 `torch.FloatTensor` 元组（每个层一个）。

    注意力权重在注意力 softmax 之后，用于计算自注意力头中的加权平均值。

XLNetLMHeadModel 的前向方法，覆盖了 `__call__` 特殊方法。

虽然前向传递的方法需要在此函数内定义，但应该在此之后调用 `Module` 实例而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, XLNetLMHeadModel
>>> import torch

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-large-cased")
>>> model = XLNetLMHeadModel.from_pretrained("xlnet-large-cased")

>>> # We show how to setup inputs to predict a next token using a bi-directional context.
>>> input_ids = torch.tensor(
...     tokenizer.encode("Hello, my dog is very <mask>", add_special_tokens=False)
... ).unsqueeze(
...     0
... )  # We will predict the masked token
>>> perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)
>>> perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token
>>> target_mapping = torch.zeros(
...     (1, 1, input_ids.shape[1]), dtype=torch.float
... )  # Shape [1, 1, seq_length] => let's predict one token
>>> target_mapping[
...     0, 0, -1
... ] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)

>>> outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)
>>> next_token_logits = outputs[
...     0
... ]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]

>>> # The same way can the XLNetLMHeadModel be used to be trained by standard auto-regressive language modeling.
>>> input_ids = torch.tensor(
...     tokenizer.encode("Hello, my dog is very <mask>", add_special_tokens=False)
... ).unsqueeze(
...     0
... )  # We will predict the masked token
>>> labels = torch.tensor(tokenizer.encode("cute", add_special_tokens=False)).unsqueeze(0)
>>> assert labels.shape[0] == 1, "only one word will be predicted"
>>> perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)
>>> perm_mask[
...     :, :, -1
... ] = 1.0  # Previous tokens don't see last token as is done in standard auto-regressive lm training
>>> target_mapping = torch.zeros(
...     (1, 1, input_ids.shape[1]), dtype=torch.float
... )  # Shape [1, 1, seq_length] => let's predict one token
>>> target_mapping[
...     0, 0, -1
... ] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)

>>> outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping, labels=labels)
>>> loss = outputs.loss
>>> next_token_logits = (
...     outputs.logits
... )  # Logits have shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]
```

## XLNetForSequenceClassification

### `class transformers.XLNetForSequenceClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1493)

```py
( config )
```

参数

+   `config`（XLNetConfig） — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained() 方法以加载模型权重。

在顶部具有序列分类/回归头的 XLNet 模型（在汇总输出的顶部有一个线性层），例如用于 GLUE 任务。

此模型继承自 PreTrainedModel。检查超类文档以获取库实现的所有模型的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。

此模型也是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) 子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1513)

```py
( input_ids: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None token_type_ids: Optional = None input_mask: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassificationOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode() 和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为 `(batch_size, sequence_length)` 的 `torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：

    +   1 表示未被 `masked` 的标记，

    +   0 表示被 `masked` 的标记。

    什么是注意力掩码？

+   `mems`（长度为 `config.n_layers` 的 `List[torch.FloatTensor]`）— 包含预先计算的隐藏状态（参见下面的 `mems` 输出）。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为 `input_ids` 传递，因为它们已经计算过。

    `use_mems` 必须设置为 `True` 才能使用 `mems`。

+   `perm_mask`（形状为 `(batch_size, sequence_length, sequence_length)` 的 `torch.FloatTensor`，*可选*）— 用于指示每个输入标记的注意力模式的掩码，值在 `[0, 1]` 中选择：

    +   如果 `perm_mask[k, i, j] = 0`，则在批次 k 中，i 关注 j；

    +   如果 `perm_mask[k, i, j] = 1`，则在批次 k 中，i 不关注 j。

    如果未设置，则每个标记都关注所有其他标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping`（形状为 `(batch_size, num_predict, sequence_length)` 的 `torch.FloatTensor`，*可选*）— 用于指示要使用的输出标记的掩码。如果 `target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为 `(batch_size, sequence_length)` 的 `torch.LongTensor`，*可选*）— 段标记索引，指示输入的第一部分和第二部分。索引在 `[0, 1]` 中选择：

    +   0 对应于 *sentence A* 标记，

    +   1 对应于 *sentence B* 标记。

    什么是标记类型 ID？

+   `input_mask`（形状为 `batch_size, sequence_length` 的 `torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。`attention_mask` 的负值，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    掩码值在 `[0, 1]` 中选择：

    +   1 表示被 `masked` 的标记，

    +   0 表示未被 `masked` 的标记。

    您只能使用 `input_mask` 和 `attention_mask` 中的一个。

+   `head_mask`（形状为 `(num_heads,)` 或 `(num_layers, num_heads)` 的 `torch.FloatTensor`，*可选*）— 用于使自注意力模块的选定头部失效的掩码。掩码值在 `[0, 1]` 中选择：

    +   1 表示头部未被 `masked`，

    +   0 表示头部被 `masked`。

+   `inputs_embeds`（形状为 `(batch_size, sequence_length, hidden_size)` 的 `torch.FloatTensor`，*可选*）— 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制权，以便将 `input_ids` 索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。

+   `output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的 `attentions`。

+   `output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的 `hidden_states`。

+   `return_dict`（`bool`，*可选*）— 是否返回 ModelOutput 而不是普通元组。

+   `labels`（形状为 `(batch_size,)` 的 `torch.LongTensor`，*可选*）— 用于计算序列分类/回归损失的标签。索引应在 `[0, ..., config.num_labels - 1]` 中。如果 `config.num_labels == 1`，则计算回归损失（均方损失），如果 `config.num_labels > 1`，则计算分类损失（交叉熵）。

返回

transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassificationOutput 或`tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassificationOutput 或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或当`config.return_dict=False`时）包含根据配置（XLNetConfig）和输入的各种元素。

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`label`时返回）- 分类（如果 config.num_labels==1 则为回归）损失。

+   `logits`（形状为`(batch_size, config.num_labels)`的`torch.FloatTensor`）- 分类（如果 config.num_labels==1 则为回归）分数（SoftMax 之前）。

+   `mems`（`List[torch.FloatTensor]`，长度为`config.n_layers`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去传递给该模型的令牌 id 不应作为`input_ids`传递，因为它们已经被计算过。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层的输出处的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每一层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForSequenceClassification 前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。

单标签分类示例：

```py
>>> import torch
>>> from transformers import AutoTokenizer, XLNetForSequenceClassification

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetForSequenceClassification.from_pretrained("xlnet-base-cased")

>>> inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")

>>> with torch.no_grad():
...     logits = model(**inputs).logits

>>> predicted_class_id = logits.argmax().item()

>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
>>> num_labels = len(model.config.id2label)
>>> model = XLNetForSequenceClassification.from_pretrained("xlnet-base-cased", num_labels=num_labels)

>>> labels = torch.tensor([1])
>>> loss = model(**inputs, labels=labels).loss
```

多标签分类示例：

```py
>>> import torch
>>> from transformers import AutoTokenizer, XLNetForSequenceClassification

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetForSequenceClassification.from_pretrained("xlnet-base-cased", problem_type="multi_label_classification")

>>> inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")

>>> with torch.no_grad():
...     logits = model(**inputs).logits

>>> predicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) > 0.5]

>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
>>> num_labels = len(model.config.id2label)
>>> model = XLNetForSequenceClassification.from_pretrained(
...     "xlnet-base-cased", num_labels=num_labels, problem_type="multi_label_classification"
... )

>>> labels = torch.sum(
...     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1
... ).to(torch.float)
>>> loss = model(**inputs, labels=labels).loss
```

## XLNetForMultipleChoice

### `class transformers.XLNetForMultipleChoice`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1689)

```py
( config )
```

参数

+   `config`（XLNetConfig）- 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained()方法以加载模型权重。

在顶部具有多选分类头的 XLNet 模型（池化输出上的线性层和 softmax），例如用于 RACE/SWAG 任务。

该模型继承自 PreTrainedModel。检查超类文档以获取库为其所有模型实现的通用方法（例如下载或保存，调整输入嵌入，修剪头等）。

该模型还是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取与一般用法和行为相关的所有内容。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1707)

```py
( input_ids: Optional = None token_type_ids: Optional = None input_mask: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetForMultipleChoiceOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids`（形状为`(batch_size, num_choices, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, num_choices, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。在`[0, 1]`中选择的掩码值：

    +   对于未被“masked”的标记为 1，

    +   对于被`masked`的标记为 0。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态（参见下面的`mems`输出）。可用于加速顺序解码。将其过去提供给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于指示每个输入标记的注意力模式的掩码，选择的值在`[0, 1]`中：

    +   如果`perm_mask[k, i, j] = 0`，则在批次 k 中，i 参与 j；

    +   如果`perm_mask[k, i, j] = 1`，则在批次 k 中，i 不参与 j。

    如果未设置，则每个标记都会关注其他所有标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于指示要使用的输出标记的掩码。如果`target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测在第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为`(batch_size, num_choices, sequence_length)`的`torch.LongTensor`，*可选*）- 段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应于*句子 A*标记，

    +   1 对应于*句子 B*标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, num_choices, sequence_length`的`torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。`attention_mask`的负值，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    在`[0, 1]`中选择的掩码值：

    +   对于被`masked`的标记为 1，

    +   对于未被“masked”的标记为 0。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）- 用于使自注意力模块的选定头部失效的掩码。在`[0, 1]`中选择的掩码值：

    +   1 表示头部未被“masked”，

    +   0 表示头部被`masked`。

+   `inputs_embeds`（形状为`(batch_size, num_choices, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）- 可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制权，以便将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。

+   `output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的`attentions`。

+   `output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。

+   `return_dict`（`bool`，*可选*）— 是否返回一个 ModelOutput 而不是一个普通元组。

+   `labels`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算多项选择分类损失的标签。索引应在`[0, ..., num_choices-1]`范围内，其中`num_choices`是输入张量的第二维的大小。（见上面的`input_ids`）

返回

transformers.models.xlnet.modeling_xlnet.XLNetForMultipleChoiceOutput 或`tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetForMultipleChoiceOutput 或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（XLNetConfig）和输入的不同元素。

+   `loss`（形状为*(1,)*的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 分类损失。

+   `logits`（形状为`(batch_size, num_choices)`的`torch.FloatTensor`）— *num_choices*是输入张量的第二维。（参见上面的*input_ids*）。

    SoftMax 之前的分类分数。

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）— 包含预计算的隐藏状态。可以用于加速顺序解码。将过去给定给该模型的令牌 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出处的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForMultipleChoice 的前向方法，覆盖了`__call__`特殊方法。

尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, XLNetForMultipleChoice
>>> import torch

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetForMultipleChoice.from_pretrained("xlnet-base-cased")

>>> prompt = "In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced."
>>> choice0 = "It is eaten with a fork and a knife."
>>> choice1 = "It is eaten while held in the hand."
>>> labels = torch.tensor(0).unsqueeze(0)  # choice0 is correct (according to Wikipedia ;)), batch size 1

>>> encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors="pt", padding=True)
>>> outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()}, labels=labels)  # batch size is 1

>>> # the linear classifier still needs to be trained
>>> loss = outputs.loss
>>> logits = outputs.logits
```

## XLNetForTokenClassification

### `class transformers.XLNetForTokenClassification`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1602)

```py
( config )
```

参数

+   `config`（XLNetConfig）— 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained()方法以加载模型权重。

在顶部带有令牌分类头的 XLNet 模型（隐藏状态输出的顶部线性层），例如用于命名实体识别（NER）任务。

此模型继承自 PreTrainedModel。查看超类文档，了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头部等）。

此模型还是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取与一般用法和行为相关的所有信息。

`前进`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1620)

```py
( input_ids: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None token_type_ids: Optional = None input_mask: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassificationOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值在`[0, 1]`中选择：

    +   1 表示未被`masked`的标记，

    +   0 表示被`masked`的标记。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）— 包含预先计算的隐藏状态（参见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

    必须将`use_mems`设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示每个输入标记的注意力模式的掩码，值在`[0, 1]`中选择：

    +   如果`perm_mask[k, i, j] = 0`，则第 k 批次中的 i 关注 j；

    +   如果`perm_mask[k, i, j] = 1`，则第 k 批次中的 i 不会关注 j。

    如果未设置，则每个标记都关注所有其他标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示要使用的输出标记的掩码。如果`target_mapping[k, i, j] = 1`，则第 k 批次中第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应于*句子 A*的标记，

    +   1 对应于*句子 B*的标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, sequence_length`的`torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。`attention_mask`的负值，即对于真实标记为 0，对于填充标记为 1，这是为了与原始代码库保持兼容性。

    掩码值在`[0, 1]`中选择：

    +   1 表示被`masked`的标记，

    +   0 表示未被`masked`的标记。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）— 用于使自注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：

    +   1 表示头部未被`masked`，

    +   0 表示头部被`masked`。

+   `inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）— 可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果您希望更多地控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。

+   `output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。

+   `output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。

+   `return_dict`（`bool`，*可选*）— 是否返回一个 ModelOutput 而不是一个普通元组。

+   `labels`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算多项选择分类损失的标签。索引应在`[0, ..., num_choices]`范围内，其中*num_choices*是输入张量第二维的大小（参见上面的*input_ids*）。

返回

transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassificationOutput 或`tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassificationOutput 或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含各种元素，具体取决于配置（XLNetConfig）和输入。

+   `loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 分类损失。

+   `logits`（形状为`(batch_size, sequence_length, config.num_labels)`的`torch.FloatTensor`）— 分类分数（SoftMax 之前）。

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）— 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去给予该模型的标记 id 不应作为`input_ids`传递，因为它们已经被计算。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForTokenClassification 的前向方法覆盖了`__call__`特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行前后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, XLNetForTokenClassification
>>> import torch

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetForTokenClassification.from_pretrained("xlnet-base-cased")

>>> inputs = tokenizer(
...     "HuggingFace is a company based in Paris and New York", add_special_tokens=False, return_tensors="pt"
... )

>>> with torch.no_grad():
...     logits = model(**inputs).logits

>>> predicted_token_class_ids = logits.argmax(-1)

>>> # Note that tokens are classified rather then input words which means that
>>> # there might be more predicted token classes than words.
>>> # Multiple token classes might account for the same word
>>> predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]

>>> labels = predicted_token_class_ids
>>> loss = model(**inputs, labels=labels).loss
```

## XLNetForQuestionAnsweringSimple

### `class transformers.XLNetForQuestionAnsweringSimple`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1792)

```py
( config )
```

参数

+   `config` (XLNetConfig) — 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看 from_pretrained() 方法来加载模型权重。

XLNet 模型在顶部具有一个用于提取式问答任务（如 SQuAD）的跨度分类头（在隐藏状态输出的顶部有线性层，用于计算 `span start logits` 和 `span end logits`）。

这个模型继承自 PreTrainedModel。查看超类文档，了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。

这个模型也是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) 子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1810)

```py
( input_ids: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None token_type_ids: Optional = None input_mask: Optional = None head_mask: Optional = None inputs_embeds: Optional = None start_positions: Optional = None end_positions: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringSimpleOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。查看 PreTrainedTokenizer.encode() 和 PreTrainedTokenizer.`call`() 获取详细信息。

    什么是输入 ID？

+   `attention_mask` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length)`，*可选*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：

    +   1 用于未被屏蔽的标记，

    +   0 用于被屏蔽的标记。

    什么是注意力掩码？

+   `mems` (`List[torch.FloatTensor]`，长度为 `config.n_layers`) — 包含预先计算的隐藏状态（参见下面的 `mems` 输出）。可用于加速顺序解码。将其过去传递给该模型的标记 id 不应作为 `input_ids` 传递，因为它们已经计算过。

    `use_mems` 必须设置为 `True` 才能使用 `mems`。

+   `perm_mask` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, sequence_length)`，*可选*) — 用于指示每个输入标记的注意力模式的掩码，值在 `[0, 1]` 中选择：

    +   如果 `perm_mask[k, i, j] = 0`，则 i 在第 k 批次中关注 j；

    +   如果 `perm_mask[k, i, j] = 1`，则 i 在第 k 批次中不会关注 j。

    如果未设置，每个标记都会关注所有其他标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping` (`torch.FloatTensor`，形状为 `(batch_size, num_predict, sequence_length)`，*可选*) — 用于指示要使用的输出标记的掩码。如果 `target_mapping[k, i, j] = 1`，则第 k 批次中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`，*可选*) — 段标记索引，指示输入的第一部分和第二部分。索引在 `[0, 1]` 中选择：

    +   0 对应于一个 *句子 A* 标记，

    +   1 对应于一个 *句子 B* 标记。

    什么是标记类型 ID？

+   `input_mask` (`torch.FloatTensor` of shape `batch_size, sequence_length`, *optional*) — 用于避免在填充标记索引上执行注意力的掩码。`attention_mask`的负值，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    在`[0, 1]`中选择的掩码值：

    +   1 表示被`masked`的标记，

    +   0 表示未被`masked`的标记。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) — 用于使自注意力模块中选择的头部失效的掩码。在`[0, 1]`中选择的掩码值：

    +   1 表示头部未被`masked`，

    +   0 表示头部被`masked`。

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制权来将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。

+   `output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的`attentions`。

+   `output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量下的`hidden_states`。

+   `return_dict` (`bool`, *optional*) — 是否返回 ModelOutput 而不是普通元组。

+   `start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — 用于计算标记分类损失的标记范围起始位置的位置（索引）标签。位置被夹紧到序列的长度（`sequence_length`）。超出序列范围的位置不会被考虑在内计算损失。

+   `end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — 用于计算标记范围结束位置的位置（索引）标签，以计算标记分类损失。位置被夹紧到序列的长度（`sequence_length`）。超出序列范围的位置不会被考虑在内计算损失。

返回

transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringSimpleOutput 或`tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringSimpleOutput 或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含各种元素，这取决于配置（XLNetConfig）和输入。

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) — 总跨度提取损失是起始位置和结束位置的交叉熵之和。

+   `start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,)`) — 跨度起始分数（SoftMax 之前）。

+   `end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,)`) — 跨度结束分数（SoftMax 之前）。

+   `mems` (`List[torch.FloatTensor]` of length `config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（见`mems`输入）。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForQuestionAnsweringSimple 的前向方法，覆盖了`__call__`特殊方法。

尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, XLNetForQuestionAnsweringSimple
>>> import torch

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetForQuestionAnsweringSimple.from_pretrained("xlnet-base-cased")

>>> question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"

>>> inputs = tokenizer(question, text, return_tensors="pt")
>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> answer_start_index = outputs.start_logits.argmax()
>>> answer_end_index = outputs.end_logits.argmax()

>>> predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]

>>> # target is "nice puppet"
>>> target_start_index = torch.tensor([14])
>>> target_end_index = torch.tensor([15])

>>> outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)
>>> loss = outputs.loss
```

## XLNetForQuestionAnswering

### `class transformers.XLNetForQuestionAnswering`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1902)

```py
( config )
```

参数

+   `config` (XLNetConfig) — 模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 from_pretrained()方法来加载模型权重。

XLNet 模型在顶部具有用于提取式问答任务（如 SQuAD）的跨度分类头（在隐藏状态输出的线性层上计算`span start logits`和`span end logits`）。

此模型继承自 PreTrainedModel。查看超类文档以了解库为其所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。

此模型也是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_xlnet.py#L1923)

```py
( input_ids: Optional = None attention_mask: Optional = None mems: Optional = None perm_mask: Optional = None target_mapping: Optional = None token_type_ids: Optional = None input_mask: Optional = None head_mask: Optional = None inputs_embeds: Optional = None start_positions: Optional = None end_positions: Optional = None is_impossible: Optional = None cls_index: Optional = None p_mask: Optional = None use_mems: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringOutput or tuple(torch.FloatTensor)
```

参数

+   `input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`，*可选*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`之间：

    +   1 表示`未被掩码`的标记，

    +   0 表示`被掩码`的标记。

    什么是注意力掩码？

+   `mems` (`List[torch.FloatTensor]`，长度为`config.n_layers`) — 包含预先计算的隐藏状态（见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示每个输入标记的注意力模式的掩码，值在`[0, 1]`中选择：

    +   如果`perm_mask[k, i, j] = 0`，则 i 在批次 k 中关注 j;

    +   如果`perm_mask[k, i, j] = 1`，则 i 在批次 k 中不参与 j。

    如果未设置，则每个标记都会关注其他所有标记（完全双向关注）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示要使用的输出标记的掩码。如果`target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应于*句子 A*的标记，

    +   1 对应于*句子 B*的标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, sequence_length`的`torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。`attention_mask`的负值，即对于真实标记为 0，对于填充标记为 1，这保持与原始代码库的兼容性。

    掩码值在`[0, 1]`中选择：

    +   1 表示被屏蔽的标记，

    +   0 表示未被屏蔽的标记。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）— 用于使自注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：

    +   1 表示头部未被屏蔽，

    +   0 表示头部被屏蔽。

+   `inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）— 可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您希望更多地控制如何将`input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。

+   `output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。

+   `output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。

+   `return_dict`（`bool`，*可选*）— 是否返回 ModelOutput 而不是普通元组。

+   `start_positions`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算标记跨度起始位置的标签（索引）的标签。位置被夹紧到序列的长度（`sequence_length`）。序列外的位置不会计入损失计算。

+   `end_positions`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算标记分类损失的标记跨度结束位置（索引）的标签。位置被夹紧到序列的长度（`sequence_length`）。序列外的位置不会计入损失计算。

+   `is_impossible`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 标签，指示问题是否有答案或无答案（SQuAD 2.0）

+   `cls_index`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算答案可信度的分类标记（索引）的标签。

+   `p_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*) — 不能包含在答案中的标记的可选掩码（例如 [CLS]，[PAD]，...）。1.0 表示应该屏蔽标记。0.0 表示标记未被屏蔽。

返回

transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringOutput 或者 `tuple(torch.FloatTensor)`

一个 transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringOutput 或者一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或者 `config.return_dict=False`）包含各种元素，取决于配置（XLNetConfig）和输入。

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned if both `start_positions` and `end_positions` are provided) — 分类损失，作为开始标记、结束标记（如果提供的话还有 is_impossible）分类损失的总和。

+   `start_top_log_probs` (`torch.FloatTensor` of shape `(batch_size, config.start_n_top)`, *optional*, returned if `start_positions` or `end_positions` is not provided) — 顶部 config.start_n_top 开始标记可能性的对数概率（波束搜索）。

+   `start_top_index` (`torch.LongTensor` of shape `(batch_size, config.start_n_top)`, *optional*, returned if `start_positions` or `end_positions` is not provided) — 顶部 config.start_n_top 开始标记可能性的索引（波束搜索）。

+   `end_top_log_probs` (`torch.FloatTensor` of shape `(batch_size, config.start_n_top * config.end_n_top)`, *optional*, returned if `start_positions` or `end_positions` is not provided) — 顶部 `config.start_n_top * config.end_n_top` 结束标记可能性的对数概率（波束搜索）。

+   `end_top_index` (`torch.LongTensor` of shape `(batch_size, config.start_n_top * config.end_n_top)`, *optional*, returned if `start_positions` or `end_positions` is not provided) — 顶部 `config.start_n_top * config.end_n_top` 结束标记可能性的索引（波束搜索）。

+   `cls_logits` (`torch.FloatTensor` of shape `(batch_size,)`, *optional*, returned if `start_positions` or `end_positions` is not provided) — 答案的 `is_impossible` 标签的对数概率。

+   `mems` (`List[torch.FloatTensor]` of length `config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（参见 `mems` 输入）。将其过去传递给此模型的标记 id 不应作为 `input_ids` 传递，因为它们已经计算过了。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) — `torch.FloatTensor` 元组（一个用于嵌入的输出 + 一个用于每个层的输出）的元组，形状为 `(batch_size, sequence_length, hidden_size)`。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) — `torch.FloatTensor` 元组（每层一个）的元组，形状为 `(batch_size, num_heads, sequence_length, sequence_length)`。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

XLNetForQuestionAnswering 的前向方法，覆盖了 `__call__` 特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用 `Module` 实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, XLNetForQuestionAnswering
>>> import torch

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = XLNetForQuestionAnswering.from_pretrained("xlnet-base-cased")

>>> input_ids = torch.tensor(tokenizer.encode("Hello, my dog is cute", add_special_tokens=True)).unsqueeze(
...     0
... )  # Batch size 1
>>> start_positions = torch.tensor([1])
>>> end_positions = torch.tensor([3])
>>> outputs = model(input_ids, start_positions=start_positions, end_positions=end_positions)

>>> loss = outputs.loss
```

TensorFlowHide TensorFlow 内容

## TFXLNetModel

### `class transformers.TFXLNetModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1171)

```py
( config *inputs **kwargs )
```

参数

+   `config`（XLNetConfig）- 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained() 方法以加载模型权重。

裸的 XLNet 模型变换器输出原始隐藏状态，没有特定的头部。

此模型继承自 TFPreTrainedModel。查看超类文档以了解库为所有模型实现的通用方法（例如下载或保存，调整输入嵌入，修剪头等）。

此模型也是 [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) 的子类。将其用作常规的 TF 2.0 Keras 模型，并参考 TF 2.0 文档以获取与一般用法和行为相关的所有信息。

TensorFlow 模型和 `transformers` 中的层接受两种格式作为输入：

+   将所有输入作为关键字参数（类似于 PyTorch 模型），或者

+   将所有输入作为列表、元组或字典放在第一个位置参数中。

支持第二种格式的原因是 Keras 方法在将输入传递给模型和层时更喜欢这种格式。由于有了这种支持，当使用像 `model.fit()` 这样的方法时，对你来说应该“只需工作” - 只需以 `model.fit()` 支持的任何格式传递你的输入和标签！但是，如果你想在 Keras 方法之外使用第二种格式，比如在使用 Keras `Functional` API 创建自己的层或模型时，有三种可能性可以用来收集所有输入张量在第一个位置参数中：

+   只有一个 `input_ids` 的单个张量，没有其他内容：`model(input_ids)`

+   一个长度可变的列表，其中包含一个或多个输入张量，按照文档字符串中给定的顺序：`model([input_ids, attention_mask])` 或 `model([input_ids, attention_mask, token_type_ids])`

+   一个字典，其中包含与文档字符串中给定的输入名称相关联的一个或多个输入张量：`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

请注意，当使用 [子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) 创建模型和层时，你不需要担心这些问题，因为你可以像对待任何其他 Python 函数一样传递输入！

#### `call`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1180)

```py
( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None mems: np.ndarray | tf.Tensor | None = None perm_mask: np.ndarray | tf.Tensor | None = None target_mapping: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None input_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None use_mems: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_tf_xlnet.TFXLNetModelOutput or tuple(tf.Tensor)
```

参数

+   `input_ids`（形状为 `(batch_size, sequence_length)` 的 `torch.LongTensor`）- 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。查看 PreTrainedTokenizer.encode() 和 PreTrainedTokenizer.`call`() 以获取详细信息。

    什么是输入 ID？

+   `attention_mask`（形状为 `(batch_size, sequence_length)` 的 `torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。 选择在 `[0, 1]` 中的掩码值：

    +   1 表示那些“未被掩码”的标记，

    +   0 表示那些“被掩码”的标记。

    什么是注意力掩码？

+   `mems` (`List[torch.FloatTensor]`，长度为 `config.n_layers`) — 包含预先计算的隐藏状态（参见下面的 `mems` 输出）。可用于加速顺序解码。将其过去传递给此模型的标记 ID 不应作为 `input_ids` 传递，因为它们已经计算过。

    `use_mems` 必须设置为 `True` 才能使用 `mems`。

+   `perm_mask` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, sequence_length)`，*可选*) — 用于指示每个输入标记的注意力模式的掩码，值选择在 `[0, 1]`：

    +   如果 `perm_mask[k, i, j] = 0`，则 i 在批次 k 中关注 j；

    +   如果 `perm_mask[k, i, j] = 1`，则 i 在批次 k 中不会关注 j。

    如果未设置，每个标记都会关注其他所有标记（完全双向注意力）。仅在预训练期间使用（用于定义分解顺序）或用于顺序解码（生成）。

+   `target_mapping` (`torch.FloatTensor`，形状为 `(batch_size, num_predict, sequence_length)`，*可选*) — 用于指示要使用的输出标记的掩码。如果 `target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`，*可选*) — 指示输入的第一部分和第二部分的段标记索引。索引选择在 `[0, 1]`：

    +   0 对应于 *句子 A* 标记，

    +   1 对应于 *句子 B* 标记。

    什么是标记类型 ID？

+   `input_mask` (`torch.FloatTensor`，形状为 `batch_size, sequence_length`，*可选*) — 用于避免在填充标记索引上执行注意力。负的 `attention_mask`，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    遮蔽值选择在 `[0, 1]`：

    +   1 表示被遮蔽的标记，

    +   0 表示未被遮蔽的标记。

    您只能使用 `input_mask` 和 `attention_mask` 中的一个。

+   `head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*) — 用于使自注意力模块的选定头部失效的掩码。掩码值选择在 `[0, 1]`：

    +   1 表示头部未被遮蔽，

    +   0 表示头部被遮蔽。

+   `inputs_embeds` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*可选*) — 可选地，您可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids` 索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。

+   `output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的 `attentions`。

+   `output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的 `hidden_states`。

+   `return_dict` (`bool`，*可选*) — 是否返回 ModelOutput 而不是普通元组。

返回

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetModelOutput 或 `tuple(tf.Tensor)`

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetModelOutput 或 `tf.Tensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False` 时）包含各种元素，这取决于配置（XLNetConfig）和输入。

+   `last_hidden_state` (`tf.Tensor`，形状为 `(batch_size, num_predict, hidden_size)`) — 模型最后一层的隐藏状态序列。

    `num_predict`对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems`（长度为`config.n_layers`的`List[tf.Tensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。已经计算过的 token id 不应该作为`input_ids`传递，因为它们已经被计算过。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态以及初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetModel 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, TFXLNetModel
>>> import tensorflow as tf

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = TFXLNetModel.from_pretrained("xlnet-base-cased")

>>> inputs = tokenizer("Hello, my dog is cute", return_tensors="tf")
>>> outputs = model(inputs)

>>> last_hidden_states = outputs.last_hidden_state
```

## TFXLNetLMHeadModel

### `class transformers.TFXLNetLMHeadModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1232)

```py
( config *inputs **kwargs )
```

参数

+   `config`（XLNetConfig）- 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看 from_pretrained()方法来加载模型权重。

在顶部带有语言建模头的 XLNet 模型（线性层，其权重与输入嵌入相关联）。

此模型继承自 TFPreTrainedModel。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。

此模型也是[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)的子类。将其用作常规的 TF 2.0 Keras 模型，并参考 TF 2.0 文档以获取有关一般用法和行为的所有相关信息。

TensorFlow 模型和层在`transformers`中接受两种格式的输入：

+   将所有输入作为关键字参数（类似于 PyTorch 模型），或

+   将所有输入作为列表、元组或字典放在第一个位置参数中。

支持第二种格式的原因是 Keras 方法在将输入传递给模型和层时更喜欢这种格式。由于这种支持，当使用`model.fit()`等方法时，应该“只需传递”您的输入和标签，以任何`model.fit()`支持的格式！然而，如果您想在 Keras 方法之外使用第二种格式，比如在使用 Keras`Functional`API 创建自己的层或模型时，有三种可能性可以用来收集第一个位置参数中的所有输入张量：

+   只有一个包含`input_ids`的张量，没有其他内容：`model(input_ids)`

+   一个长度可变的列表，其中包含一个或多个输入张量，按照文档字符串中给定的顺序：`model([input_ids, attention_mask])`或`model([input_ids, attention_mask, token_type_ids])`

+   一个带有与文档字符串中给定的输入名称相关联的一个或多个输入张量的字典：`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

请注意，当使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心任何这些，因为您可以像对待任何其他 Python 函数一样传递输入！

#### `call`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1292)

```py
( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None mems: np.ndarray | tf.Tensor | None = None perm_mask: np.ndarray | tf.Tensor | None = None target_mapping: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None input_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None use_mems: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: bool = False ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModelOutput or tuple(tf.Tensor)
```

参数

+   `input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力。掩码值选定在`[0, 1]`中：

    +   1 表示未被屏蔽的标记，

    +   0 表示被屏蔽的标记。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态（请参见下面的`mems`输出）。可用于加速顺序解码。将其过去提供给此模型的标记 id 不应作为`input_ids`传递，因为它们已经被计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于指示每个输入标记的注意力模式的掩码，值选定在`[0, 1]`中：

    +   如果`perm_mask[k, i, j] = 0`，则在批次 k 中 i 关注 j;

    +   如果`perm_mask[k, i, j] = 1`，则在批次 k 中 i 不会关注 j。

    如果未设置，则每个标记都会关注其他所有标记（完全双向注意力）。仅在预训练（用于定义分解顺序）或顺序解码（生成）期间使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于指示要使用的输出标记。如果`target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）- 段标记索引，指示输入的第一部分和第二部分。索引选定在`[0, 1]`中：

    +   0 对应于*句子 A*标记，

    +   1 对应于*句子 B*标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, sequence_length`的`torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力。`attention_mask`的负值，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    掩码值选定在`[0, 1]`中：

    +   1 表示被屏蔽的标记，

    +   0 表示未被屏蔽的标记。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）- 用于使自注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`中：

    +   1 表示头部未被屏蔽，

    +   0 表示头部被屏蔽。

+   `inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*optional*) — 可选地，可以直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵。

+   `output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。

+   `output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。

+   `return_dict` (`bool`, *optional*) — 是否返回一个 ModelOutput 而不是一个普通元组。

+   `labels` (`tf.Tensor`，形状为`(batch_size, sequence_length)`，*optional*) — 用于计算交叉熵分类损失的标签。索引应在`[0, ..., config.vocab_size - 1]`范围内。

返回

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModelOutput 或`tuple(tf.Tensor)`

一个 transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModelOutput 或一个`tf.Tensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（XLNetConfig）和输入的各种元素。

+   `loss` (`tf.Tensor`，形状为*(1,)*，*optional*，当提供`labels`时返回) — 语言建模损失（用于下一个标记预测）。

+   `logits` (`tf.Tensor`，形状为`(batch_size, num_predict, config.vocab_size)`） — 语言建模头的预测分数（SoftMax 之前每个词汇标记的分数）。

    `num_predict`对应于`target_mapping.shape[1]`。如果`target_mapping`为`None`，则`num_predict`对应于`sequence_length`。

+   `mems` (`List[tf.Tensor]` of length `config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    每个层输出的模型的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetLMHeadModel 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> import tensorflow as tf
>>> import numpy as np
>>> from transformers import AutoTokenizer, TFXLNetLMHeadModel

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-large-cased")
>>> model = TFXLNetLMHeadModel.from_pretrained("xlnet-large-cased")

>>> # We show how to setup inputs to predict a next token using a bi-directional context.
>>> input_ids = tf.constant(tokenizer.encode("Hello, my dog is very <mask>", add_special_tokens=True))[
...     None, :
... ]  # We will predict the masked token

>>> perm_mask = np.zeros((1, input_ids.shape[1], input_ids.shape[1]))
>>> perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token

>>> target_mapping = np.zeros(
...     (1, 1, input_ids.shape[1])
... )  # Shape [1, 1, seq_length] => let's predict one token
>>> target_mapping[
...     0, 0, -1
... ] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)

>>> outputs = model(
...     input_ids,
...     perm_mask=tf.constant(perm_mask, dtype=tf.float32),
...     target_mapping=tf.constant(target_mapping, dtype=tf.float32),
... )

>>> next_token_logits = outputs[
...     0
... ]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]
```

## TFXLNetForSequenceClassification

### `class transformers.TFXLNetForSequenceClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1402)

```py
( config *inputs **kwargs )
```

参数

+   `config`（XLNetConfig）- 模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 from_pretrained()方法以加载模型权重。

XLNet 模型在顶部具有序列分类/回归头（池化输出的顶部线性层），例如用于 GLUE 任务。

此模型继承自 TFPreTrainedModel。检查超类文档以获取库为其所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。

此模型还是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的 TF 2.0 Keras 模型，并参考 TF 2.0 文档以获取有关一般用法和行为的所有相关信息。

`transformers`中的 TensorFlow 模型和层接受两种格式的输入：

+   将所有输入作为关键字参数（类似于 PyTorch 模型），或

+   将所有输入作为列表、元组或字典的第一个位置参数。

支持第二种格式的原因是 Keras 方法在将输入传递给模型和层时更喜欢这种格式。由于有此支持，当使用`model.fit()`等方法时，应该可以“正常工作” - 只需传递您的输入和标签，以任何`model.fit()`支持的格式！但是，如果您想在 Keras 方法之外使用第二种格式，例如在使用 Keras`Functional`API 创建自己的层或模型时，有三种可能性可用于收集所有输入张量在第一个位置参数中：

+   只有包含`input_ids`的单个张量，没有其他内容：`model(input_ids)`

+   一个长度可变的列表，其中包含一个或多个输入张量，按照文档字符串中给定的顺序：`model([input_ids, attention_mask])`或`model([input_ids, attention_mask, token_type_ids])`

+   一个字典，其中包含一个或多个与文档字符串中给定的输入名称相关联的输入张量：`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

请注意，当使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心任何这些，因为您可以像对待任何其他 Python 函数一样传递输入！

#### `call`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1423)

```py
( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None mems: np.ndarray | tf.Tensor | None = None perm_mask: np.ndarray | tf.Tensor | None = None target_mapping: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None input_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None use_mems: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: bool = False ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForSequenceClassificationOutput or tuple(tf.Tensor)
```

参数

+   `input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）- 避免在填充标记索引上执行注意力的掩码。选择在`[0, 1]`中的掩码值：

    +   对于未被屏蔽的标记为 1，

    +   对于被屏蔽的标记为 0。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态（参见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length, sequence_length)`, *optional*) — 用于指示每个输入标记的注意力模式的掩码，其值在`[0, 1]`中选择：

    +   如果`perm_mask[k, i, j] = 0`，则 i 在批次 k 中关注 j;

    +   如果`perm_mask[k, i, j] = 1`，则 i 在批次 k 中不会关注 j。

    如果未设置，每个标记都关注所有其他标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping` (`torch.FloatTensor` of shape `(batch_size, num_predict, sequence_length)`, *optional*) — 用于指示要使用的输出标记的掩码。如果`target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) — 段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应于*句子 A*标记，

    +   1 对应于*句子 B*标记。

    什么是标记类型 ID？

+   `input_mask` (`torch.FloatTensor` of shape `batch_size, sequence_length`, *optional*) — 用于避免在填充标记索引上执行注意力的掩码。`attention_mask`的负值，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    掩码值在`[0, 1]`中选择：

    +   1 表示标记被`masked`，

    +   0 表示标记未被`masked`。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) — 用于使自注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：

    +   1 表示头部未被`masked`，

    +   0 表示头部被`masked`。

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制权，以便将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。

+   `output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。

+   `output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。

+   `return_dict` (`bool`, *optional*) — 是否返回一个 ModelOutput 而不是一个普通元组。

+   `labels` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — 用于计算序列分类/回归损失的标签。索引应在`[0, ..., config.num_labels - 1]`中。如果`config.num_labels == 1`，则计算回归损失（均方损失），如果`config.num_labels > 1`，则计算分类损失（交叉熵）。

返回

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForSequenceClassificationOutput 或`tuple(tf.Tensor)`

一个 transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForSequenceClassificationOutput 或一个`tf.Tensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含根据配置（XLNetConfig）和输入的不同元素。

+   `loss`（形状为`(1,)`的`tf.Tensor`，*可选*，当提供`label`时返回）- 分类（如果`config.num_labels==1`则为回归）损失。

+   `logits`（形状为`(batch_size, config.num_labels)`的`tf.Tensor`）- 分类（如果`config.num_labels==1`则为回归）分数（SoftMax 之前）。

+   `mems`（长度为`config.n_layers`的`List[tf.Tensor]`）- 包含预先计算的隐藏状态。可以用于加速顺序解码（查看`mems`输入）。将其过去给予此模型的标记 id 不应作为`input_ids`传递，因为它们已经被计算。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）- 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    每层输出的模型的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）- 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均。

TFXLNetForSequenceClassification 的前向方法，覆盖`__call__`特殊方法。

尽管前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, TFXLNetForSequenceClassification
>>> import tensorflow as tf

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = TFXLNetForSequenceClassification.from_pretrained("xlnet-base-cased")

>>> inputs = tokenizer("Hello, my dog is cute", return_tensors="tf")

>>> logits = model(**inputs).logits

>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
```

```py
>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
>>> num_labels = len(model.config.id2label)
>>> model = TFXLNetForSequenceClassification.from_pretrained("xlnet-base-cased", num_labels=num_labels)

>>> labels = tf.constant(1)
>>> loss = model(**inputs, labels=labels).loss
```

## TFLNetForMultipleChoice

### `class transformers.TFXLNetForMultipleChoice`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1504)

```py
( config *inputs **kwargs )
```

参数

+   `config`（XLNetConfig）- 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained()方法以加载模型权重。

XLNET 模型在顶部具有多选分类头（池化输出顶部的线性层和 softmax），例如用于 RocStories/SWAG 任务。

这个模型继承自 TFPreTrainedModel。查看超类文档以获取库实现的所有模型的通用方法（例如下载或保存，调整输入嵌入大小，修剪头等）。

这个模型也是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的 TF 2.0 Keras 模型，并参考 TF 2.0 文档以获取与一般用法和行为相关的所有内容。

`transformers`中的 TensorFlow 模型和层接受两种格式的输入：

+   将所有输入作为关键字参数（类似于 PyTorch 模型），或

+   将所有输入作为列表、元组或字典放在第一个位置参数中。

支持第二种格式的原因是 Keras 方法在将输入传递给模型和层时更喜欢这种格式。由于这种支持，当使用`model.fit()`等方法时，应该“只需工作” - 只需以`model.fit()`支持的任何格式传递输入和标签！然而，如果要在 Keras 方法之外使用第二种格式，例如在使用 Keras`Functional`API 创建自己的层或模型时，有三种可能性可用于收集第一个位置参数中的所有输入张量：

+   一个仅包含`input_ids`的单个张量，没有其他内容：`model(input_ids)`

+   一个长度可变的列表，其中包含一个或多个输入张量，按照文档字符串中给定的顺序：`model([input_ids, attention_mask])`或`model([input_ids, attention_mask, token_type_ids])`

+   一个字典，其中包含一个或多个与文档字符串中给定的输入名称相关联的输入张量：`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

请注意，当使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心任何这些，因为您可以像对待任何其他 Python 函数一样传递输入！

#### `call`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1524)

```py
( input_ids: TFModelInputType | None = None token_type_ids: np.ndarray | tf.Tensor | None = None input_mask: np.ndarray | tf.Tensor | None = None attention_mask: np.ndarray | tf.Tensor | None = None mems: np.ndarray | tf.Tensor | None = None perm_mask: np.ndarray | tf.Tensor | None = None target_mapping: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None use_mems: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: bool = False ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForMultipleChoiceOutput or tuple(tf.Tensor)
```

参数

+   `input_ids`（形状为`(batch_size, num_choices, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, num_choices, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于避免对填充标记索引执行注意力。掩码值在`[0, 1]`中选择：

    +   1 表示那些“未被掩盖”的标记，

    +   0 表示那些“被掩盖”的标记。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）— 包含预先计算的隐藏状态（参见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示每个输入标记的注意力模式的掩码，其值在`[0, 1]`中选择：

    +   如果`perm_mask[k, i, j] = 0`，则在批次 k 中，i 关注 j；

    +   如果`perm_mask[k, i, j] = 1`，则在批次 k 中，i 不会关注 j。

    如果未设置，每个标记都会关注所有其他标记（完全双向注意力）。仅在预训练期间（用于定义分解顺序）或用于顺序解码（生成）时使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示要使用的输出标记。如果`target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练中用于部分预测或用于顺序解码（生成）时使用。

+   `token_type_ids`（形状为`(batch_size, num_choices, sequence_length)`的`torch.LongTensor`，*可选*）— 段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应于*句子 A*的标记，

    +   1 对应于*句子 B*的标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, num_choices, sequence_length`的`torch.FloatTensor`，*可选*）— 用于避免对填充标记索引执行注意力。`attention_mask`的负值，即对于真实标记为 0，对于填充为 1，这是为了与原始代码库保持兼容性。

    掩码值在`[0, 1]`中选择：

    +   1 表示那些“被掩盖”的标记，

    +   0 表示那些“未被掩盖”的标记。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）— 用于使自注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：

    +   1 表示头部“未被掩盖”，

    +   0 表示头部被`masked`。

+   `inputs_embeds`（形状为`(batch_size, num_choices, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）— 可选地，可以直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为关联向量，而不是模型的内部嵌入查找矩阵，则这很有用。

+   `output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。

+   `output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。

+   `return_dict`（`bool`，*可选*）— 是否返回 ModelOutput 而不是普通元组。

+   `labels`（形状为`(batch_size,)`的`tf.Tensor`，*可选*）— 用于计算多项选择分类损失的标签。索引应在`[0, ..., num_choices]`范围内，其中`num_choices`是输入张量的第二维的大小。（参见上面的`input_ids`）

返回

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForMultipleChoiceOutput 或者`tuple(tf.Tensor)`

一个 transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForMultipleChoiceOutput 或者一个`tf.Tensor`元组（如果传递了`return_dict=False`或者`config.return_dict=False`）包含各种元素，取决于配置（XLNetConfig）和输入。

+   `loss`（形状为*(1,)*的`tf.Tensor`，*可选*，当提供`labels`时返回）— 分类损失。

+   `logits`（形状为`(batch_size, num_choices)`的`tf.Tensor`）— *num_choices*是输入张量的第二维。（参见上面的*input_ids*）。

    SoftMax 之前的分类分数。

+   `mems`（长度为`config.n_layers`的`List[tf.Tensor]`）— 包含预先计算的隐藏状态。可以用于加速顺序解码（参见`mems`输入）。将其过去给定给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或者`config.output_hidden_states=True`时返回）— 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。

    模型在每个层的输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或者`config.output_attentions=True`时返回）— 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetForMultipleChoice 的前向方法，覆盖了`__call__`特殊方法。

尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, TFXLNetForMultipleChoice
>>> import tensorflow as tf

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = TFXLNetForMultipleChoice.from_pretrained("xlnet-base-cased")

>>> prompt = "In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced."
>>> choice0 = "It is eaten with a fork and a knife."
>>> choice1 = "It is eaten while held in the hand."

>>> encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors="tf", padding=True)
>>> inputs = {k: tf.expand_dims(v, 0) for k, v in encoding.items()}
>>> outputs = model(inputs)  # batch size is 1

>>> # the linear classifier still needs to be trained
>>> logits = outputs.logits
```

## TFXLNetForTokenClassification

### `class transformers.TFXLNetForTokenClassification`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1620)

```py
( config *inputs **kwargs )
```

参数

+   `config`（XLNetConfig）- 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained()方法以加载模型权重。

在顶部带有令牌分类头的 XLNet 模型（隐藏状态输出的顶部线性层），例如用于命名实体识别（NER）任务。

此模型继承自 TFPreTrainedModel。查看超类文档以获取库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。

此模型还是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的 TF 2.0 Keras 模型，并参考 TF 2.0 文档以获取与一般用法和行为相关的所有内容。

`transformers`中的 TensorFlow 模型和层接受两种格式的输入：

+   将所有输入作为关键字参数（类似于 PyTorch 模型），或

+   将所有输入作为列表、元组或字典传递给第一个位置参数。

支持第二种格式的原因是，当将输入传递给模型和层时，Keras 方法更喜欢这种格式。由于有了这种支持，当使用`model.fit()`等方法时，应该可以正常工作-只需传递您的输入和标签，以任何`model.fit()`支持的格式！但是，如果您想在 Keras 方法之外使用第二种格式，例如在使用 Keras`Functional` API 创建自己的层或模型时，您可以使用三种可能性来收集所有输入张量：

+   只有`input_ids`的单个张量，没有其他内容：`model(input_ids)`

+   按照文档字符串中给定的顺序，具有不同长度的一个或多个输入张量的列表：`model([input_ids, attention_mask])`或`model([input_ids, attention_mask, token_type_ids])`

+   一个字典，其中包含与文档字符串中给定的输入名称相关联的一个或多个输入张量：`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

请注意，当使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心任何这些，因为您可以像将输入传递给任何其他 Python 函数一样传递输入！

#### `call`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1638)

```py
( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None mems: np.ndarray | tf.Tensor | None = None perm_mask: np.ndarray | tf.Tensor | None = None target_mapping: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None input_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None use_mems: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: bool = False ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassificationOutput or tuple(tf.Tensor)
```

参数

+   `input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 来获取索引。查看 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()获取详细信息。

    输入 ID 是什么？

+   `attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。选择的掩码值在`[0, 1]`之间：

    +   1 表示`未屏蔽`的标记，

    +   0 表示`已屏蔽`的标记。

    注意力掩码是什么？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）- 包含预先计算的隐藏状态（请参见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的令牌 ID 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems` 必须设置为 `True` 才能使用 `mems`。

+   `perm_mask`（形状为 `(batch_size, sequence_length, sequence_length)` 的 `torch.FloatTensor`，*可选*） — 用于指示每个输入标记的注意力模式的掩码，值在 `[0, 1]` 中选择：

    +   如果 `perm_mask[k, i, j] = 0`，则第 k 批次中的第 i 个关注第 j 个。

    +   如果 `perm_mask[k, i, j] = 1`，则第 k 批次中的第 i 个不关注第 j 个。

    如果未设置，每个标记都会关注其他所有标记（完全双向关注）。仅在预训练期间（用于定义分解顺序）或顺序解码（生成）时使用。

+   `target_mapping`（形状为 `(batch_size, num_predict, sequence_length)` 的 `torch.FloatTensor`，*可选*） — 用于指示要使用的输出标记的掩码。如果 `target_mapping[k, i, j] = 1`，则第 k 批次中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或顺序解码（生成）。

+   `token_type_ids`（形状为 `(batch_size, sequence_length)` 的 `torch.LongTensor`，*可选*） — 段标记索引，指示输入的第一部分和第二部分。索引在 `[0, 1]` 中选择：

    +   0 对应于 *句子 A* 标记，

    +   1 对应于 *句子 B* 标记。

    什么是标记类型 ID？

+   `input_mask`（形状为 `batch_size, sequence_length` 的 `torch.FloatTensor`，*可选*） — 避免在填充标记索引上执行注意力的掩码。与原始代码库兼容性保留填充标记的 `attention_mask` 的负值，即对于真实标记为 0，对于填充为 1。

    掩码值在 `[0, 1]` 中选择：

    +   对于被`masked`掩盖的标记，

    +   0 对应于未被“masked”的标记。

    只能使用 `input_mask` 和 `attention_mask` 中的一个。

+   `head_mask`（形状为 `(num_heads,)` 或 `(num_layers, num_heads)` 的 `torch.FloatTensor`，*可选*） — 用于使自注意力模块的选定头部失效的掩码。掩码值在 `[0, 1]` 中选择：

    +   1 表示头部未被“masked”，

    +   0 表示头部被`masked`。

+   `inputs_embeds`（形状为 `(batch_size, sequence_length, hidden_size)` 的 `torch.FloatTensor`，*可选*） — 可选地，可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids` 索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。

+   `output_attentions`（`bool`，*可选*） — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的 `attentions`。

+   `output_hidden_states`（`bool`，*可选*） — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的 `hidden_states`。

+   `return_dict`（`bool`，*可选*） — 是否返回 ModelOutput 而不是普通元组。

+   `labels`（形状为 `(batch_size, sequence_length)` 的 `tf.Tensor`，*可选*） — 用于计算标记分类损失的标签。索引应在 `[0, ..., config.num_labels - 1]` 范围内。

返回

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassificationOutput 或 `tuple(tf.Tensor)`

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassificationOutput 或者一个 `tf.Tensor` 元组（如果传递了 `return_dict=False` 或者 `config.return_dict=False` 时）包含根据配置（XLNetConfig）和输入而异的各种元素。

+   `loss`（形状为 `(1,)` 的 `tf.Tensor`，*可选*，在提供 `labels` 时返回） — 分类损失。

+   `logits`（形状为 `(batch_size, sequence_length, config.num_labels)` 的 `tf.Tensor`） — 分类分数（SoftMax 之前）。

+   `mems`（长度为`config.n_layers`的`List[tf.Tensor]`） - 包含预先计算的隐藏状态。可以使用（参见`mems`输入）以加速顺序解码。将其过去传递给该模型的标记 id 不应作为`input_ids`传递，因为它们已经计算过。

+   `hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回） - 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回） - 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    在注意力 softmax 之后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetForTokenClassification 的前向方法重写了`__call__`特殊方法。

尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, TFXLNetForTokenClassification
>>> import tensorflow as tf

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = TFXLNetForTokenClassification.from_pretrained("xlnet-base-cased")

>>> inputs = tokenizer(
...     "HuggingFace is a company based in Paris and New York", add_special_tokens=False, return_tensors="tf"
... )

>>> logits = model(**inputs).logits
>>> predicted_token_class_ids = tf.math.argmax(logits, axis=-1)

>>> # Note that tokens are classified rather then input words which means that
>>> # there might be more predicted token classes than words.
>>> # Multiple token classes might account for the same word
>>> predicted_tokens_classes = [model.config.id2label[t] for t in predicted_token_class_ids[0].numpy().tolist()]
```

```py
>>> labels = predicted_token_class_ids
>>> loss = tf.math.reduce_mean(model(**inputs, labels=labels).loss)
```

## TFXLNetForQuestionAnsweringSimple

### `class transformers.TFXLNetForQuestionAnsweringSimple`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1712)

```py
( config *inputs **kwargs )
```

参数

+   `config`（XLNetConfig） - 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 from_pretrained()方法以加载模型权重。

XLNet 模型在顶部带有一个跨度分类头，用于提取式问答任务，如 SQuAD（在隐藏状态输出的顶部添加线性层以计算“跨度起始 logits”和“跨度结束 logits”）。

该模型继承自 TFPreTrainedModel。查看超类文档，了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。

该模型也是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的 TF 2.0 Keras 模型，并参考 TF 2.0 文档以获取与一般用法和行为相关的所有内容。

`transformers`中的 TensorFlow 模型和层接受两种格式的输入：

+   将所有输入作为关键字参数（类似于 PyTorch 模型），或

+   将所有输入作为列表、元组或字典的第一个位置参数。

支持第二种格式的原因是 Keras 方法在将输入传递给模型和层时更喜欢这种格式。由于有了这种支持，当使用`model.fit()`等方法时，应该“只需工作” - 只需以`model.fit()`支持的任何格式传递输入和标签即可！但是，如果您想在 Keras 方法之外使用第二种格式，比如在使用 Keras`Functional` API 创建自己的层或模型时，有三种可能性可以用来收集第一个位置参数中的所有输入张量：

+   只有包含`input_ids`的单个张量，没有其他内容：`model(input_ids)`

+   一个长度可变的列表，其中包含一个或多个输入张量，按照文档字符串中给定的顺序：`model([input_ids, attention_mask])`或`model([input_ids, attention_mask, token_type_ids])`

+   一个带有与文档字符串中给定的输入名称相关联的一个或多个输入张量的字典：`model({"input_ids": input_ids, "token_type_ids": token_type_ids})`

请注意，当使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心任何这些，因为您可以像对待任何其他 Python 函数一样传递输入！

#### `call`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlnet/modeling_tf_xlnet.py#L1728)

```py
( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None mems: np.ndarray | tf.Tensor | None = None perm_mask: np.ndarray | tf.Tensor | None = None target_mapping: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None input_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None use_mems: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None start_positions: np.ndarray | tf.Tensor | None = None end_positions: np.ndarray | tf.Tensor | None = None training: bool = False ) → export const metadata = 'undefined';transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimpleOutput or tuple(tf.Tensor)
```

参数

+   `input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。

    可以使用 AutoTokenizer 获取索引。有关详细信息，请参阅 PreTrainedTokenizer.encode()和 PreTrainedTokenizer.`call`()。

    什么是输入 ID？

+   `attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值在`[0, 1]`中选择：

    +   对于未被“masked”的标记为 1，

    +   对于被`masked`的标记为 0。

    什么是注意力掩码？

+   `mems`（长度为`config.n_layers`的`List[torch.FloatTensor]`）— 包含预先计算的隐藏状态（参见下面的`mems`输出）。可用于加速顺序解码。将其过去传递给此模型的标记 ID 不应作为`input_ids`传递，因为它们已经计算过。

    `use_mems`必须设置为`True`才能使用`mems`。

+   `perm_mask`（形状为`(batch_size, sequence_length, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示每个输入标记的注意力模式的掩码，值在`[0, 1]`中选择：

    +   如果`perm_mask[k, i, j] = 0`，则 i 在批次 k 中关注 j；

    +   如果`perm_mask[k, i, j] = 1`，则 i 在批次 k 中不参与 j。

    如果未设置，则每个标记都会关注其他所有标记（完全双向关注）。仅在预训练（用于定义分解顺序）或顺序解码（生成）期间使用。

+   `target_mapping`（形状为`(batch_size, num_predict, sequence_length)`的`torch.FloatTensor`，*可选*）— 用于指示要使用的输出标记的掩码。如果`target_mapping[k, i, j] = 1`，则批次 k 中的第 i 个预测位于第 j 个标记上。仅在预训练期间用于部分预测或用于顺序解码（生成）。

+   `token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：

    +   0 对应于*句子 A*标记，

    +   1 对应于*句子 B*标记。

    什么是标记类型 ID？

+   `input_mask`（形状为`batch_size, sequence_length`的`torch.FloatTensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。负的`attention_mask`，即对于真实标记为 0，对于保留与原始代码库兼容性的填充为 1。

    掩码值在`[0, 1]`中选择：

    +   对于被`masked`的标记为 1。

    +   对于未被“masked”的标记为 0。

    您只能使用`input_mask`和`attention_mask`中的一个。

+   `head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）— 用于使自注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：

    +   1 表示头部未被“masked”。

    +   0 表示头部被`masked`。

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) — 可选地，可以直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。

+   `output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量中的`attentions`。

+   `output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量中的`hidden_states`。

+   `return_dict` (`bool`, *optional*) — 是否返回 ModelOutput 而不是普通元组。

+   `start_positions` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — 用于计算标记范围开始位置的位置（索引）标签，以计算标记分类损失。位置被夹紧到序列的长度（`sequence_length`）。超出序列范围的位置不会被考虑在内以计算损失。

+   `end_positions` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — 用于计算标记分类损失的标记范围结束位置的位置（索引）标签。位置被夹紧到序列的长度（`sequence_length`）。超出序列范围的位置不会被考虑在内以计算损失。

返回

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimpleOutput 或 `tuple(tf.Tensor)`

transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimpleOutput 或一个`tf.Tensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（XLNetConfig）和输入的各种元素。

+   `loss` (`tf.Tensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) — 总跨度提取损失是开始和结束位置的交叉熵之和。

+   `start_logits` (`tf.Tensor` of shape `(batch_size, sequence_length,)`) — 跨度开始分数（SoftMax 之前）。

+   `end_logits` (`tf.Tensor` of shape `(batch_size, sequence_length,)`) — 跨度结束分数（SoftMax 之前）。

+   `mems` (`List[tf.Tensor]` of length `config.n_layers`) — 包含预先计算的隐藏状态。可以用于加速顺序解码（见`mems`输入）。将其过去传递给此模型的标记 id 不应作为`input_ids`传递，因为它们已经被计算过。

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出，一个用于每一层的输出）。

    模型在每一层输出的隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。

    注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。

TFXLNetForQuestionAnsweringSimple 的前向方法，覆盖`__call__`特殊方法。

尽管前向传播的配方需要在这个函数内定义，但应该在此之后调用`Module`实例，而不是这个函数，因为前者负责运行预处理和后处理步骤，而后者则会默默地忽略它们。

示例：

```py
>>> from transformers import AutoTokenizer, TFXLNetForQuestionAnsweringSimple
>>> import tensorflow as tf

>>> tokenizer = AutoTokenizer.from_pretrained("xlnet-base-cased")
>>> model = TFXLNetForQuestionAnsweringSimple.from_pretrained("xlnet-base-cased")

>>> question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"

>>> inputs = tokenizer(question, text, return_tensors="tf")
>>> outputs = model(**inputs)

>>> answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])
>>> answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])

>>> predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
```

```py
>>> # target is "nice puppet"
>>> target_start_index = tf.constant([14])
>>> target_end_index = tf.constant([15])

>>> outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)
>>> loss = tf.math.reduce_mean(outputs.loss)
```
