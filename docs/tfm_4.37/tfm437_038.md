# è®¡ç®—æœºè§†è§‰çŸ¥è¯†è’¸é¦

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/tasks/knowledge_distillation_for_image_classification`](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/knowledge_distillation_for_image_classification)

çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œç”¨äºå°†çŸ¥è¯†ä»ä¸€ä¸ªæ›´å¤§ã€æ›´å¤æ‚çš„æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰è½¬ç§»åˆ°ä¸€ä¸ªæ›´å°ã€æ›´ç®€å•çš„æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰ã€‚ä¸ºäº†ä»ä¸€ä¸ªæ¨¡å‹ä¸­æå–çŸ¥è¯†åˆ°å¦ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªåœ¨ç‰¹å®šä»»åŠ¡ä¸Šï¼ˆæœ¬ä¾‹ä¸­ä¸ºå›¾åƒåˆ†ç±»ï¼‰è®­ç»ƒè¿‡çš„é¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œå¹¶éšæœºåˆå§‹åŒ–ä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹ç”¨äºå›¾åƒåˆ†ç±»è®­ç»ƒã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ä»¥æœ€å°åŒ–å…¶è¾“å‡ºä¸æ•™å¸ˆè¾“å‡ºä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œä½¿å…¶æ¨¡ä»¿è¡Œä¸ºã€‚è¿™æœ€åˆæ˜¯ç”± [Hinton ç­‰äººåœ¨ç¥ç»ç½‘ç»œä¸­æå–çŸ¥è¯†](https://arxiv.org/abs/1503.02531) ä¸­é¦–æ¬¡å¼•å…¥çš„ã€‚åœ¨è¿™ä¸ªæŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†è¿›è¡Œç‰¹å®šä»»åŠ¡çš„çŸ¥è¯†è’¸é¦ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [beans æ•°æ®é›†](https://huggingface.co/datasets/beans)ã€‚

è¿™ä¸ªæŒ‡å—æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ ğŸ¤— Transformers çš„ [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) å°†ä¸€ä¸ª [fine-tuned ViT æ¨¡å‹](https://huggingface.co/merve/vit-mobilenet-beans-224)ï¼ˆæ•™å¸ˆæ¨¡å‹ï¼‰è’¸é¦åˆ°ä¸€ä¸ª [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224)ï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰ã€‚

è®©æˆ‘ä»¬å®‰è£…è¿›è¡Œè’¸é¦å’Œè¯„ä¼°è¿‡ç¨‹æ‰€éœ€çš„åº“ã€‚

```py
pip install transformers datasets accelerate tensorboard evaluate --upgrade
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `merve/beans-vit-224` æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäº `google/vit-base-patch16-224-in21k` åœ¨ beans æ•°æ®é›†ä¸Šå¾®è°ƒçš„å›¾åƒåˆ†ç±»æ¨¡å‹ã€‚æˆ‘ä»¬å°†å°†è¿™ä¸ªæ¨¡å‹è’¸é¦åˆ°ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„ MobileNetV2ã€‚

æˆ‘ä»¬ç°åœ¨å°†åŠ è½½æ•°æ®é›†ã€‚

```py
from datasets import load_dataset

dataset = load_dataset("beans")
```

æˆ‘ä»¬å¯ä»¥ä»ä»»ä¸€æ¨¡å‹ä¸­ä½¿ç”¨å›¾åƒå¤„ç†å™¨ï¼Œå› ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹å®ƒä»¬è¿”å›ç›¸åŒåˆ†è¾¨ç‡çš„ç›¸åŒè¾“å‡ºã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `dataset` çš„ `map()` æ–¹æ³•å°†é¢„å¤„ç†åº”ç”¨äºæ•°æ®é›†çš„æ¯ä¸ªæ‹†åˆ†ã€‚

```py
from transformers import AutoImageProcessor
teacher_processor = AutoImageProcessor.from_pretrained("merve/beans-vit-224")

def process(examples):
    processed_inputs = teacher_processor(examples["image"])
    return processed_inputs

processed_datasets = dataset.map(process, batched=True)
```

åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›å­¦ç”Ÿæ¨¡å‹ï¼ˆéšæœºåˆå§‹åŒ–çš„ MobileNetï¼‰æ¨¡ä»¿æ•™å¸ˆæ¨¡å‹ï¼ˆå¾®è°ƒçš„è§†è§‰å˜æ¢å™¨ï¼‰ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆä»æ•™å¸ˆå’Œå­¦ç”Ÿä¸­è·å– logits è¾“å‡ºã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å®ƒä»¬ä¸­çš„æ¯ä¸€ä¸ªé™¤ä»¥æ§åˆ¶æ¯ä¸ªè½¯ç›®æ ‡é‡è¦æ€§çš„å‚æ•° `temperature`ã€‚ä¸€ä¸ªç§°ä¸º `lambda` çš„å‚æ•°æƒè¡¡äº†è’¸é¦æŸå¤±çš„é‡è¦æ€§ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `temperature=5` å’Œ `lambda=0.5`ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Kullback-Leibler æ•£åº¦æŸå¤±æ¥è®¡ç®—å­¦ç”Ÿå’Œæ•™å¸ˆä¹‹é—´çš„å·®å¼‚ã€‚ç»™å®šä¸¤ä¸ªæ•°æ® P å’Œ Qï¼ŒKL æ•£åº¦è§£é‡Šäº†æˆ‘ä»¬éœ€è¦å¤šå°‘é¢å¤–ä¿¡æ¯æ¥ç”¨ Q è¡¨ç¤º Pã€‚å¦‚æœä¸¤è€…ç›¸åŒï¼Œå®ƒä»¬çš„ KL æ•£åº¦ä¸ºé›¶ï¼Œå› ä¸ºä¸éœ€è¦å…¶ä»–ä¿¡æ¯æ¥è§£é‡Š Pã€‚å› æ­¤ï¼Œåœ¨çŸ¥è¯†è’¸é¦çš„èƒŒæ™¯ä¸‹ï¼ŒKL æ•£åº¦æ˜¯æœ‰ç”¨çš„ã€‚

```py
from transformers import TrainingArguments, Trainer
import torch
import torch.nn as nn
import torch.nn.functional as F

class ImageDistilTrainer(Trainer):
    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):
        super().__init__(model=student_model, *args, **kwargs)
        self.teacher = teacher_model
        self.student = student_model
        self.loss_function = nn.KLDivLoss(reduction="batchmean")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.teacher.to(device)
        self.teacher.eval()
        self.temperature = temperature
        self.lambda_param = lambda_param

    def compute_loss(self, student, inputs, return_outputs=False):
        student_output = self.student(**inputs)

        with torch.no_grad():
          teacher_output = self.teacher(**inputs)

        # Compute soft targets for teacher and student
        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)
        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)

        # Compute the loss
        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)

        # Compute the true label loss
        student_target_loss = student_output.loss

        # Calculate final loss
        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss
        return (loss, student_output) if return_outputs else loss
```

æˆ‘ä»¬ç°åœ¨å°†ç™»å½•åˆ° Hugging Face Hubï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥é€šè¿‡ `Trainer` å°†æˆ‘ä»¬çš„æ¨¡å‹æ¨é€åˆ° Hugging Face Hubã€‚

```py
from huggingface_hub import notebook_login

notebook_login()
```

è®©æˆ‘ä»¬è®¾ç½® `TrainingArguments`ã€æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ã€‚

```py
from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification

training_args = TrainingArguments(
    output_dir="my-awesome-model",
    num_train_epochs=30,
    fp16=True,
    logging_dir=f"{repo_name}/logs",
    logging_strategy="epoch",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="tensorboard",
    push_to_hub=True,
    hub_strategy="every_save",
    hub_model_id=repo_name,
    )

num_labels = len(processed_datasets["train"].features["labels"].names)

# initialize models
teacher_model = AutoModelForImageClassification.from_pretrained(
    "merve/beans-vit-224",
    num_labels=num_labels,
    ignore_mismatched_sizes=True
)

# training MobileNetV2 from scratch
student_config = MobileNetV2Config()
student_config.num_labels = num_labels
student_model = MobileNetV2ForImageClassification(student_config)
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `compute_metrics` å‡½æ•°åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚è¿™ä¸ªå‡½æ•°å°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”¨äºè®¡ç®—æˆ‘ä»¬æ¨¡å‹çš„ `å‡†ç¡®ç‡` å’Œ `f1`ã€‚

```py
import evaluate
import numpy as np

accuracy = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))
    return {"accuracy": acc["accuracy"]}
```

è®©æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬å®šä¹‰çš„è®­ç»ƒå‚æ•°åˆå§‹åŒ– `Trainer`ã€‚æˆ‘ä»¬è¿˜å°†åˆå§‹åŒ–æˆ‘ä»¬çš„æ•°æ®æ”¶é›†å™¨ã€‚

```py
from transformers import DefaultDataCollator

data_collator = DefaultDataCollator()
trainer = ImageDistilTrainer(
    student_model=student_model,
    teacher_model=teacher_model,
    training_args=training_args,
    train_dataset=processed_datasets["train"],
    eval_dataset=processed_datasets["validation"],
    data_collator=data_collator,
    tokenizer=teacher_processor,
    compute_metrics=compute_metrics,
    temperature=5,
    lambda_param=0.5
)
```

æˆ‘ä»¬ç°åœ¨å¯ä»¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

```py
trainer.train()
```

æˆ‘ä»¬å¯ä»¥åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ã€‚

```py
trainer.evaluate(processed_datasets["test"])
```

åœ¨æµ‹è¯•é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¾¾åˆ°äº† 72ï¼…çš„å‡†ç¡®ç‡ã€‚ä¸ºäº†å¯¹è’¸é¦æ•ˆç‡è¿›è¡Œåˆç†æ€§æ£€æŸ¥ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ç›¸åŒçš„è¶…å‚æ•°ä»å¤´å¼€å§‹åœ¨è±†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒ MobileNetï¼Œå¹¶è§‚å¯Ÿåˆ°æµ‹è¯•é›†ä¸Šçš„ 63ï¼…å‡†ç¡®ç‡ã€‚æˆ‘ä»¬é‚€è¯·è¯»è€…å°è¯•ä¸åŒçš„é¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹ã€å­¦ç”Ÿæ¶æ„ã€è’¸é¦å‚æ•°ï¼Œå¹¶æŠ¥å‘Šä»–ä»¬çš„å‘ç°ã€‚è’¸é¦æ¨¡å‹çš„è®­ç»ƒæ—¥å¿—å’Œæ£€æŸ¥ç‚¹å¯ä»¥åœ¨[æ­¤å­˜å‚¨åº“](https://huggingface.co/merve/vit-mobilenet-beans-224)ä¸­æ‰¾åˆ°ï¼Œä»å¤´å¼€å§‹è®­ç»ƒçš„ MobileNetV2 å¯ä»¥åœ¨æ­¤[å­˜å‚¨åº“](https://huggingface.co/merve/resnet-mobilenet-beans-5)ä¸­æ‰¾åˆ°ã€‚
