# DETR

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/detr`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/detr)

## æ¦‚è¿°

DETR æ¨¡å‹æ˜¯ç”± Nicolas Carionã€Francisco Massaã€Gabriel Synnaeveã€Nicolas Usunierã€Alexander Kirillov å’Œ Sergey Zagoruyko åœ¨[ä½¿ç”¨å˜å‹å™¨è¿›è¡Œç«¯åˆ°ç«¯ç›®æ ‡æ£€æµ‹](https://arxiv.org/abs/2005.12872)ä¸­æå‡ºçš„ã€‚DETR ç”±ä¸€ä¸ªå·ç§¯ä¸»å¹²åé¢è·Ÿç€ä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨å˜å‹å™¨ç»„æˆï¼Œå¯ä»¥è¿›è¡Œç«¯åˆ°ç«¯çš„ç›®æ ‡æ£€æµ‹è®­ç»ƒã€‚å®ƒæå¤§åœ°ç®€åŒ–äº†åƒ Faster-R-CNN å’Œ Mask-R-CNN è¿™æ ·çš„æ¨¡å‹çš„å¤æ‚æ€§ï¼Œè¿™äº›æ¨¡å‹ä½¿ç”¨åŒºåŸŸæè®®ã€éæå¤§å€¼æŠ‘åˆ¶ç¨‹åºå’Œé”šç‚¹ç”Ÿæˆç­‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼ŒDETR è¿˜å¯ä»¥è‡ªç„¶åœ°æ‰©å±•åˆ°æ‰§è¡Œå…¨æ™¯åˆ†å‰²ï¼Œåªéœ€åœ¨è§£ç å™¨è¾“å‡ºä¹‹ä¸Šæ·»åŠ ä¸€ä¸ªè’™ç‰ˆå¤´ã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*æˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†ç›®æ ‡æ£€æµ‹è§†ä¸ºç›´æ¥é›†åˆé¢„æµ‹é—®é¢˜çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç®€åŒ–äº†æ£€æµ‹æµç¨‹ï¼Œæœ‰æ•ˆåœ°æ¶ˆé™¤äº†è®¸å¤šæ‰‹å·¥è®¾è®¡çš„ç»„ä»¶ï¼Œå¦‚éæå¤§å€¼æŠ‘åˆ¶ç¨‹åºæˆ–æ˜ç¡®ç¼–ç æˆ‘ä»¬å¯¹ä»»åŠ¡çš„å…ˆéªŒçŸ¥è¯†çš„é”šç‚¹ç”Ÿæˆã€‚æ–°æ¡†æ¶ DEtection TRansformer æˆ– DETR çš„ä¸»è¦ç»„æˆéƒ¨åˆ†æ˜¯é€šè¿‡äºŒéƒ¨åŒ¹é…å¼ºåˆ¶å”¯ä¸€é¢„æµ‹çš„åŸºäºé›†åˆçš„å…¨å±€æŸå¤±ï¼Œä»¥åŠä¸€ä¸ªå˜å‹å™¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ã€‚ç»™å®šä¸€ç»„å›ºå®šçš„å­¦ä¹ ç›®æ ‡æŸ¥è¯¢ï¼ŒDETR æ¨ç†å¯¹è±¡ä¹‹é—´çš„å…³ç³»å’Œå…¨å±€å›¾åƒä¸Šä¸‹æ–‡ï¼Œç›´æ¥å¹¶è¡Œè¾“å‡ºæœ€ç»ˆçš„é¢„æµ‹é›†ã€‚è¿™ä¸ªæ–°æ¨¡å‹åœ¨æ¦‚å¿µä¸Šç®€å•ï¼Œä¸éœ€è¦ä¸“é—¨çš„åº“ï¼Œä¸åƒè®¸å¤šå…¶ä»–ç°ä»£æ£€æµ‹å™¨ã€‚DETR åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ COCO ç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¸ç»è¿‡å……åˆ†ä¼˜åŒ–çš„ Faster RCNN åŸºçº¿ç›¸å½“çš„å‡†ç¡®æ€§å’Œè¿è¡Œæ—¶æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒDETR å¯ä»¥è½»æ¾æ¨å¹¿ä¸ºä»¥ç»Ÿä¸€æ–¹å¼äº§ç”Ÿå…¨æ™¯åˆ†å‰²ã€‚æˆ‘ä»¬å±•ç¤ºå®ƒæ˜æ˜¾ä¼˜äºç«äº‰åŸºçº¿ã€‚*

è¿™ä¸ªæ¨¡å‹æ˜¯ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®çš„ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/facebookresearch/detr)æ‰¾åˆ°ã€‚

## DETR çš„å·¥ä½œåŸç†

ä»¥ä¸‹æ˜¯è§£é‡Š DetrForObjectDetection å·¥ä½œåŸç†çš„ TLDRï¼š

é¦–å…ˆï¼Œå°†å›¾åƒé€šè¿‡é¢„è®­ç»ƒçš„å·ç§¯ä¸»å¹²ï¼ˆåœ¨è®ºæ–‡ä¸­ï¼Œä½œè€…ä½¿ç”¨ ResNet-50/ResNet-101ï¼‰ã€‚å‡è®¾æˆ‘ä»¬ä¹Ÿæ·»åŠ äº†ä¸€ä¸ªæ‰¹å¤„ç†ç»´åº¦ã€‚è¿™æ„å‘³ç€ä¸»å¹²çš„è¾“å…¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º`(batch_size, 3, height, width)`çš„å¼ é‡ï¼Œå‡è®¾å›¾åƒæœ‰ 3 ä¸ªé¢œè‰²é€šé“ï¼ˆRGBï¼‰ã€‚CNN ä¸»å¹²è¾“å‡ºä¸€ä¸ªæ–°çš„ä½åˆ†è¾¨ç‡ç‰¹å¾å›¾ï¼Œé€šå¸¸å½¢çŠ¶ä¸º`(batch_size, 2048, height/32, width/32)`ã€‚ç„¶åï¼Œå°†å…¶æŠ•å½±åˆ° DETR å˜å‹å™¨çš„éšè—ç»´åº¦ï¼Œè¯¥ç»´åº¦é»˜è®¤ä¸º`256`ï¼Œä½¿ç”¨`nn.Conv2D`å±‚ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå½¢çŠ¶ä¸º`(batch_size, 256, height/32, width/32)`çš„å¼ é‡ã€‚æ¥ä¸‹æ¥ï¼Œç‰¹å¾å›¾è¢«å±•å¹³å¹¶è½¬ç½®ï¼Œä»¥è·å¾—å½¢çŠ¶ä¸º`(batch_size, seq_len, d_model)` = `(batch_size, width/32*height/32, 256)`çš„å¼ é‡ã€‚å› æ­¤ï¼Œä¸ NLP æ¨¡å‹çš„ä¸€ä¸ªåŒºåˆ«æ˜¯ï¼Œåºåˆ—é•¿åº¦å®é™…ä¸Šæ¯”é€šå¸¸æ›´é•¿ï¼Œä½†`d_model`è¾ƒå°ï¼ˆåœ¨ NLP ä¸­é€šå¸¸ä¸º 768 æˆ–æ›´é«˜ï¼‰ã€‚

æ¥ä¸‹æ¥ï¼Œè¿™é€šè¿‡ç¼–ç å™¨å‘é€ï¼Œè¾“å‡ºç›¸åŒå½¢çŠ¶çš„`encoder_hidden_states`ï¼ˆæ‚¨å¯ä»¥å°†è¿™äº›è§†ä¸ºå›¾åƒç‰¹å¾ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œæ‰€è°“çš„**å¯¹è±¡æŸ¥è¯¢**é€šè¿‡è§£ç å™¨å‘é€ã€‚è¿™æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_queries, d_model)`çš„å¼ é‡ï¼Œå…¶ä¸­`num_queries`é€šå¸¸è®¾ç½®ä¸º 100ï¼Œå¹¶ç”¨é›¶åˆå§‹åŒ–ã€‚è¿™äº›è¾“å…¥åµŒå…¥æ˜¯å­¦ä¹ çš„ä½ç½®ç¼–ç ï¼Œä½œè€…å°†å…¶ç§°ä¸ºå¯¹è±¡æŸ¥è¯¢ï¼Œç±»ä¼¼äºç¼–ç å™¨ï¼Œå®ƒä»¬è¢«æ·»åŠ åˆ°æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„è¾“å…¥ä¸­ã€‚æ¯ä¸ªå¯¹è±¡æŸ¥è¯¢å°†åœ¨å›¾åƒä¸­å¯»æ‰¾ç‰¹å®šå¯¹è±¡ã€‚è§£ç å™¨é€šè¿‡å¤šä¸ªè‡ªæ³¨æ„åŠ›å’Œç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›å±‚æ›´æ–°è¿™äº›åµŒå…¥ï¼Œä»¥è¾“å‡ºç›¸åŒå½¢çŠ¶çš„`decoder_hidden_states`ï¼š`(batch_size, num_queries, d_model)`ã€‚æ¥ä¸‹æ¥ï¼Œé¡¶éƒ¨æ·»åŠ äº†ä¸¤ä¸ªå¤´ç”¨äºå¯¹è±¡æ£€æµ‹ï¼šä¸€ä¸ªçº¿æ€§å±‚ç”¨äºå°†æ¯ä¸ªå¯¹è±¡æŸ¥è¯¢åˆ†ç±»ä¸ºå¯¹è±¡æˆ–â€œæ— å¯¹è±¡â€ä¹‹ä¸€ï¼Œä»¥åŠä¸€ä¸ª MLP ç”¨äºé¢„æµ‹æ¯ä¸ªæŸ¥è¯¢çš„è¾¹ç•Œæ¡†ã€‚

è¯¥æ¨¡å‹ä½¿ç”¨**äºŒéƒ¨åŒ¹é…æŸå¤±**è¿›è¡Œè®­ç»ƒï¼šå®é™…ä¸Šæˆ‘ä»¬æ¯”è¾ƒæ¯ä¸ª N = 100 ä¸ªå¯¹è±¡æŸ¥è¯¢çš„é¢„æµ‹ç±»åˆ«+è¾¹ç•Œæ¡†ä¸åœ°é¢çœŸå®æ³¨é‡Šï¼Œå¡«å……åˆ°ç›¸åŒé•¿åº¦ Nï¼ˆå› æ­¤å¦‚æœå›¾åƒä»…åŒ…å« 4 ä¸ªå¯¹è±¡ï¼Œåˆ™ 96 ä¸ªæ³¨é‡Šå°†åªæœ‰ä¸€ä¸ªâ€œæ— å¯¹è±¡â€ä½œä¸ºç±»åˆ«å’Œä¸€ä¸ªâ€œæ— è¾¹ç•Œæ¡†â€ä½œä¸ºè¾¹ç•Œæ¡†ï¼‰ã€‚ä½¿ç”¨[åŒˆç‰™åˆ©åŒ¹é…ç®—æ³•](https://en.wikipedia.org/wiki/Hungarian_algorithm)æ‰¾åˆ°æ¯ä¸ª N æŸ¥è¯¢ä¸æ¯ä¸ª N æ³¨é‡Šçš„æœ€ä½³ä¸€å¯¹ä¸€æ˜ å°„ã€‚æ¥ä¸‹æ¥ï¼Œä½¿ç”¨æ ‡å‡†äº¤å‰ç†µï¼ˆç”¨äºç±»åˆ«ï¼‰å’Œ L1 çš„çº¿æ€§ç»„åˆä»¥åŠ[å¹¿ä¹‰ IoU æŸå¤±](https://giou.stanford.edu/)ï¼ˆç”¨äºè¾¹ç•Œæ¡†ï¼‰æ¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ã€‚

DETR å¯ä»¥è‡ªç„¶æ‰©å±•ä»¥æ‰§è¡Œå…¨æ™¯åˆ†å‰²ï¼ˆå°†è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ç»Ÿä¸€èµ·æ¥ï¼‰ã€‚DetrForSegmentation åœ¨ DetrForObjectDetection çš„é¡¶éƒ¨æ·»åŠ äº†ä¸€ä¸ªåˆ†å‰²æ©ç å¤´ã€‚æ©ç å¤´å¯ä»¥åŒæ—¶è®­ç»ƒï¼Œæˆ–è€…åœ¨ä¸¤ä¸ªæ­¥éª¤çš„è¿‡ç¨‹ä¸­è®­ç»ƒï¼Œé¦–å…ˆè®­ç»ƒä¸€ä¸ª DetrForObjectDetection æ¨¡å‹æ¥æ£€æµ‹â€œäº‹ç‰©â€ï¼ˆå®ä¾‹ï¼‰å’Œâ€œç‰©å“â€ï¼ˆèƒŒæ™¯ç‰©å“ï¼Œå¦‚æ ‘æœ¨ã€é“è·¯ã€å¤©ç©ºï¼‰å‘¨å›´çš„è¾¹ç•Œæ¡†ï¼Œç„¶åå†»ç»“æ‰€æœ‰æƒé‡ï¼Œä»…è®­ç»ƒæ©ç å¤´ 25 ä¸ªæ—¶ä»£ã€‚å®éªŒä¸Šï¼Œè¿™ä¸¤ç§æ–¹æ³•ç»™å‡ºäº†ç±»ä¼¼çš„ç»“æœã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†ä½¿è®­ç»ƒæˆä¸ºå¯èƒ½ï¼Œé¢„æµ‹æ¡†æ˜¯å¿…éœ€çš„ï¼Œå› ä¸ºåŒˆç‰™åˆ©åŒ¹é…æ˜¯ä½¿ç”¨æ¡†ä¹‹é—´çš„è·ç¦»è®¡ç®—çš„ã€‚

## ä½¿ç”¨æç¤º

+   DETR ä½¿ç”¨æ‰€è°“çš„**å¯¹è±¡æŸ¥è¯¢**æ¥æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡ã€‚æŸ¥è¯¢çš„æ•°é‡ç¡®å®šäº†å•ä¸ªå›¾åƒä¸­å¯ä»¥æ£€æµ‹åˆ°çš„å¯¹è±¡çš„æœ€å¤§æ•°é‡ï¼Œé»˜è®¤è®¾ç½®ä¸º 100ï¼ˆè¯·å‚é˜… DetrConfig çš„å‚æ•°`num_queries`ï¼‰ã€‚è¯·æ³¨æ„ï¼Œæœ€å¥½æœ‰ä¸€äº›ä½™åœ°ï¼ˆåœ¨ COCO ä¸­ï¼Œä½œè€…ä½¿ç”¨äº† 100ï¼Œè€Œ COCO å›¾åƒä¸­çš„æœ€å¤§å¯¹è±¡æ•°é‡çº¦ä¸º 70ï¼‰ã€‚

+   DETR çš„è§£ç å™¨å¹¶è¡Œæ›´æ–°æŸ¥è¯¢åµŒå…¥ã€‚è¿™ä¸åƒ GPT-2 è¿™æ ·ä½¿ç”¨è‡ªå›å½’è§£ç è€Œä¸æ˜¯å¹¶è¡Œçš„è¯­è¨€æ¨¡å‹ä¸åŒã€‚å› æ­¤ï¼Œä¸ä½¿ç”¨å› æœå…³æ³¨æ©ç ã€‚

+   åœ¨å°†éšè—çŠ¶æ€æŠ•å½±åˆ°æŸ¥è¯¢å’Œé”®ä¹‹å‰ï¼ŒDETR åœ¨æ¯ä¸ªè‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›å±‚ä¸­æ·»åŠ ä½ç½®åµŒå…¥ã€‚å¯¹äºå›¾åƒçš„ä½ç½®åµŒå…¥ï¼Œå¯ä»¥åœ¨å›ºå®šæ­£å¼¦æˆ–å­¦ä¹ çš„ç»å¯¹ä½ç½®åµŒå…¥ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒDetrConfig çš„å‚æ•°`position_embedding_type`è®¾ç½®ä¸º`"sine"`ã€‚

+   åœ¨è®­ç»ƒæœŸé—´ï¼ŒDETR çš„ä½œè€…ç¡®å®å‘ç°åœ¨è§£ç å™¨ä¸­ä½¿ç”¨è¾…åŠ©æŸå¤±æ˜¯æœ‰å¸®åŠ©çš„ï¼Œç‰¹åˆ«æ˜¯ä¸ºäº†å¸®åŠ©æ¨¡å‹è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ­£ç¡®å¯¹è±¡æ•°é‡ã€‚å¦‚æœå°† DetrConfig çš„å‚æ•°`auxiliary_loss`è®¾ç½®ä¸º`True`ï¼Œåˆ™åœ¨æ¯ä¸ªè§£ç å™¨å±‚ä¹‹åæ·»åŠ é¢„æµ‹å‰é¦ˆç¥ç»ç½‘ç»œå’ŒåŒˆç‰™åˆ©æŸå¤±ï¼ˆFFN å…±äº«å‚æ•°ï¼‰ã€‚

+   å¦‚æœæ‚¨æƒ³åœ¨è·¨å¤šä¸ªèŠ‚ç‚¹çš„åˆ†å¸ƒå¼ç¯å¢ƒä¸­è®­ç»ƒæ¨¡å‹ï¼Œåˆ™åº”è¯¥åœ¨*modeling_detr.py*ä¸­çš„*DetrLoss*ç±»ä¸­æ›´æ–°*num_boxes*å˜é‡ã€‚åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šè®­ç»ƒæ—¶ï¼Œåº”å°†å…¶è®¾ç½®ä¸ºæ‰€æœ‰èŠ‚ç‚¹ä¸Šç›®æ ‡æ¡†çš„å¹³å‡æ•°é‡ï¼Œå¯ä»¥åœ¨åŸå§‹å®ç°ä¸­çœ‹åˆ°[è¿™é‡Œ](https://github.com/facebookresearch/detr/blob/a54b77800eb8e64e3ad0d8237789fcbf2f8350c5/models/detr.py#L227-L232)ã€‚

+   DetrForObjectDetection å’Œ DetrForSegmentation å¯ä»¥ä½¿ç”¨[timm åº“](https://github.com/rwightman/pytorch-image-models)ä¸­å¯ç”¨çš„ä»»ä½•å·ç§¯éª¨å¹²è¿›è¡Œåˆå§‹åŒ–ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡å°† DetrConfig çš„`backbone`å±æ€§è®¾ç½®ä¸º`"tf_mobilenetv3_small_075"`ï¼Œç„¶åä½¿ç”¨è¯¥é…ç½®åˆå§‹åŒ–æ¨¡å‹æ¥ä½¿ç”¨ MobileNet éª¨å¹²ã€‚

+   DETR è°ƒæ•´è¾“å…¥å›¾åƒçš„å¤§å°ï¼Œä½¿æœ€çŸ­è¾¹è‡³å°‘ä¸ºä¸€å®šæ•°é‡çš„åƒç´ ï¼Œè€Œæœ€é•¿è¾¹è‡³å¤šä¸º 1333 åƒç´ ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œä½¿ç”¨å°ºåº¦å¢å¼ºï¼Œä½¿æœ€çŸ­è¾¹éšæœºè®¾ç½®ä¸ºè‡³å°‘ 480 åƒç´ ï¼Œæœ€å¤š 800 åƒç´ ã€‚åœ¨æ¨æ–­æ—¶ï¼Œæœ€çŸ­è¾¹è®¾ç½®ä¸º 800ã€‚å¯ä»¥ä½¿ç”¨ DetrImageProcessor ä¸ºæ¨¡å‹å‡†å¤‡å›¾åƒï¼ˆä»¥åŠå¯é€‰çš„ä»¥ COCO æ ¼å¼çš„æ³¨é‡Šï¼‰ã€‚ç”±äºè¿™ç§è°ƒæ•´å¤§å°ï¼Œæ‰¹å¤„ç†ä¸­çš„å›¾åƒå¯èƒ½å…·æœ‰ä¸åŒçš„å¤§å°ã€‚DETR é€šè¿‡å°†å›¾åƒå¡«å……åˆ°æ‰¹å¤„ç†ä¸­çš„æœ€å¤§å¤§å°ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªåƒç´ æ©ç æ¥æŒ‡ç¤ºå“ªäº›åƒç´ æ˜¯çœŸå®çš„/å“ªäº›æ˜¯å¡«å……æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦å¤–ï¼Œä¹Ÿå¯ä»¥å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„`collate_fn`æ¥æ‰¹å¤„ç†å›¾åƒï¼Œä½¿ç”¨`~transformers.DetrImageProcessor.pad_and_create_pixel_mask`ã€‚

+   å›¾åƒçš„å¤§å°å°†å†³å®šæ‰€ä½¿ç”¨çš„å†…å­˜é‡ï¼Œä»è€Œç¡®å®š`batch_size`ã€‚å»ºè®®æ¯ä¸ª GPU ä½¿ç”¨æ‰¹é‡å¤§å°ä¸º 2ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æ­¤ Github çº¿ç¨‹](https://github.com/facebookresearch/detr/issues/150)ã€‚

æœ‰ä¸‰ç§å®ä¾‹åŒ– DETR æ¨¡å‹çš„æ–¹æ³•ï¼ˆå–å†³äºæ‚¨çš„åå¥½ï¼‰ï¼š

é€‰é¡¹ 1ï¼šä½¿ç”¨æ•´ä¸ªæ¨¡å‹çš„é¢„è®­ç»ƒæƒé‡å®ä¾‹åŒ– DETR

```py
>>> from transformers import DetrForObjectDetection

>>> model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")
```

é€‰é¡¹ 2ï¼šä½¿ç”¨éšæœºåˆå§‹åŒ–çš„ Transformer æƒé‡å®ä¾‹åŒ– DETRï¼Œä½†ä½¿ç”¨éª¨å¹²çš„é¢„è®­ç»ƒæƒé‡

```py
>>> from transformers import DetrConfig, DetrForObjectDetection

>>> config = DetrConfig()
>>> model = DetrForObjectDetection(config)
```

é€‰é¡¹ 3ï¼šä½¿ç”¨éšæœºåˆå§‹åŒ–çš„éª¨å¹²+Transformer å®ä¾‹åŒ– DETR

```py
>>> config = DetrConfig(use_pretrained_backbone=False)
>>> model = DetrForObjectDetection(config)
```

æ€»ä¹‹ï¼Œè¯·å‚è€ƒä»¥ä¸‹è¡¨æ ¼ï¼š

| ä»»åŠ¡ | ç›®æ ‡æ£€æµ‹ | å®ä¾‹åˆ†å‰² | å…¨æ™¯åˆ†å‰² |
| --- | --- | --- | --- |
| **æè¿°** | é¢„æµ‹å›¾åƒä¸­ç‰©ä½“å‘¨å›´çš„è¾¹ç•Œæ¡†å’Œç±»æ ‡ç­¾ | é¢„æµ‹å›¾åƒä¸­ç‰©ä½“ï¼ˆå³å®ä¾‹ï¼‰å‘¨å›´çš„æ©æ¨¡ | é¢„æµ‹å›¾åƒä¸­ç‰©ä½“ï¼ˆå³å®ä¾‹ï¼‰ä»¥åŠâ€œç‰©è´¨â€ï¼ˆå³èƒŒæ™¯ç‰©å“å¦‚æ ‘æœ¨å’Œé“è·¯ï¼‰å‘¨å›´çš„æ©æ¨¡ |
| **æ¨¡å‹** | DetrForObjectDetection | DetrForSegmentation | DetrForSegmentation |
| **ç¤ºä¾‹æ•°æ®é›†** | COCO æ£€æµ‹ | COCO æ£€æµ‹ï¼ŒCOCO å…¨æ™¯ | COCO å…¨æ™¯ |
| æä¾›ç»™ DetrImageProcessor çš„æ³¨é‡Šæ ¼å¼ | {â€˜image_idâ€™: `int`, â€˜annotationsâ€™: `List[Dict]`}ï¼Œæ¯ä¸ª Dict æ˜¯ä¸€ä¸ª COCO å¯¹è±¡æ³¨é‡Š | {â€˜image_idâ€™: `int`, â€˜annotationsâ€™: `List[Dict]`}ï¼ˆåœ¨ COCO æ£€æµ‹çš„æƒ…å†µä¸‹ï¼‰æˆ–{â€˜file_nameâ€™: `str`, â€˜image_idâ€™: `int`, â€˜segments_infoâ€™: `List[Dict]`}ï¼ˆåœ¨ COCO å…¨æ™¯çš„æƒ…å†µä¸‹ï¼‰ | {â€˜file_nameâ€™: `str`, â€˜image_idâ€™: `int`, â€˜segments_infoâ€™: `List[Dict]`}å’Œ masks_pathï¼ˆåŒ…å« PNG æ–‡ä»¶çš„æ©æ¨¡ç›®å½•çš„è·¯å¾„ï¼‰ |
| **åå¤„ç†**ï¼ˆå³å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸º Pascal VOC æ ¼å¼ï¼‰ | `post_process()` | `post_process_segmentation()` | `post_process_segmentation()`, `post_process_panoptic()` |
| **è¯„ä¼°å™¨** | `CocoEvaluator` with `iou_types="bbox"` | `CocoEvaluator` with `iou_types="bbox"` or `"segm"` | `CocoEvaluator` with `iou_tupes="bbox"` or `"segm"`, `PanopticEvaluator` |

ç®€è€Œè¨€ä¹‹ï¼Œåº”è¯¥å‡†å¤‡æ•°æ®ä»¥ COO æ£€æµ‹æˆ– COO å…¨æ™¯æ ¼å¼ï¼Œç„¶åä½¿ç”¨ DetrImageProcessor åˆ›å»º`pixel_values`ã€`pixel_mask`å’Œå¯é€‰çš„`labels`ï¼Œç„¶åå¯ä»¥ç”¨äºè®­ç»ƒï¼ˆæˆ–å¾®è°ƒï¼‰æ¨¡å‹ã€‚å¯¹äºè¯„ä¼°ï¼Œåº”è¯¥é¦–å…ˆä½¿ç”¨ DetrImageProcessor çš„å…¶ä¸­ä¸€ç§åå¤„ç†æ–¹æ³•è½¬æ¢æ¨¡å‹çš„è¾“å‡ºã€‚è¿™äº›å¯ä»¥æä¾›ç»™`CocoEvaluator`æˆ–`PanopticEvaluator`ï¼Œè¿™äº›è¯„ä¼°å™¨å…è®¸æ‚¨è®¡ç®—åƒå¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰å’Œå…¨æ™¯è´¨é‡ï¼ˆPQï¼‰è¿™æ ·çš„æŒ‡æ ‡ã€‚åè€…å¯¹è±¡åœ¨[åŸå§‹å­˜å‚¨åº“](https://github.com/facebookresearch/detr)ä¸­å®ç°ã€‚æœ‰å…³è¯„ä¼°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[ç¤ºä¾‹ç¬”è®°æœ¬](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/DETR)ã€‚

## èµ„æº

ä¸€ä¸ªå®˜æ–¹ Hugging Face å’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨ DETRã€‚

ç›®æ ‡æ£€æµ‹

+   æ‰€æœ‰ç¤ºä¾‹ç¬”è®°æœ¬è¯´æ˜åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šå¯¹ DetrForObjectDetection å’Œ DetrForSegmentation è¿›è¡Œå¾®è°ƒçš„ç¤ºä¾‹å¯ä»¥åœ¨[æ­¤å¤„](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/DETR)æ‰¾åˆ°ã€‚

+   å‚è§ï¼šç›®æ ‡æ£€æµ‹ä»»åŠ¡æŒ‡å—

å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ª Pull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥å±•ç¤ºä¸€äº›æ–°ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚

## DetrConfig

### `class transformers.DetrConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/configuration_detr.py#L36)

```py
( use_timm_backbone = True backbone_config = None num_channels = 3 num_queries = 100 encoder_layers = 6 encoder_ffn_dim = 2048 encoder_attention_heads = 8 decoder_layers = 6 decoder_ffn_dim = 2048 decoder_attention_heads = 8 encoder_layerdrop = 0.0 decoder_layerdrop = 0.0 is_encoder_decoder = True activation_function = 'relu' d_model = 256 dropout = 0.1 attention_dropout = 0.0 activation_dropout = 0.0 init_std = 0.02 init_xavier_std = 1.0 auxiliary_loss = False position_embedding_type = 'sine' backbone = 'resnet50' use_pretrained_backbone = True dilation = False class_cost = 1 bbox_cost = 5 giou_cost = 2 mask_loss_coefficient = 1 dice_loss_coefficient = 1 bbox_loss_coefficient = 5 giou_loss_coefficient = 2 eos_coefficient = 0.1 **kwargs )
```

å‚æ•°

+   `use_timm_backbone`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä½¿ç”¨`timm`åº“ä½œä¸ºéª¨å¹²ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œå°†ä½¿ç”¨`AutoBackbone` APIã€‚

+   `backbone_config`ï¼ˆ`PretrainedConfig`æˆ–`dict`ï¼Œ*å¯é€‰*ï¼‰â€” éª¨å¹²æ¨¡å‹çš„é…ç½®ã€‚ä»…åœ¨`use_timm_backbone`è®¾ç½®ä¸º`False`æ—¶ä½¿ç”¨ï¼Œé»˜è®¤ä¸º`ResNetConfig()`ã€‚

+   `num_channels`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 3ï¼‰â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚

+   `num_queries`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 100ï¼‰â€” å¯¹è±¡æŸ¥è¯¢çš„æ•°é‡ï¼Œå³æ£€æµ‹æ§½çš„æ•°é‡ã€‚è¿™æ˜¯ DetrModel åœ¨å•ä¸ªå›¾åƒä¸­å¯ä»¥æ£€æµ‹çš„å¯¹è±¡çš„æœ€å¤§æ•°é‡ã€‚å¯¹äº COCOï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ 100 ä¸ªæŸ¥è¯¢ã€‚

+   `d_model`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 256ï¼‰â€” å±‚çš„ç»´åº¦ã€‚

+   `encoder_layers`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 6ï¼‰â€” ç¼–ç å™¨å±‚æ•°ã€‚

+   `decoder_layers`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 6ï¼‰â€” è§£ç å™¨å±‚æ•°ã€‚

+   `encoder_attention_heads`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 8ï¼‰â€” Transformer ç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `decoder_attention_heads` (`int`, *optional*, defaults to 8) â€” Transformer è§£ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `decoder_ffn_dim` (`int`, *optional*, defaults to 2048) â€” è§£ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `encoder_ffn_dim` (`int`, *optional*, defaults to 2048) â€” è§£ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `activation_function` (`str` or `function`, *optional*, defaults to `"relu"`) â€” ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`ã€`"relu"`ã€`"silu"`å’Œ`"gelu_new"`ã€‚

+   `dropout` (`float`, *optional*, defaults to 0.1) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ dropout æ¦‚ç‡ã€‚

+   `attention_dropout` (`float`, *optional*, defaults to 0.0) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„ dropout æ¯”ç‡ã€‚

+   `activation_dropout` (`float`, *optional*, defaults to 0.0) â€” å…¨è¿æ¥å±‚å†…æ¿€æ´»çš„ dropout æ¯”ç‡ã€‚

+   `init_std` (`float`, *optional*, defaults to 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `init_xavier_std` (`float`, *optional*, defaults to 1) â€” ç”¨äº HM Attention map æ¨¡å—ä¸­ Xavier åˆå§‹åŒ–å¢ç›Šçš„ç¼©æ”¾å› å­ã€‚

+   `encoder_layerdrop` (`float`, *optional*, defaults to 0.0) â€” ç¼–ç å™¨çš„ LayerDrop æ¦‚ç‡ã€‚æ›´å¤šç»†èŠ‚è¯·å‚é˜…[LayerDrop paper](https://arxiv.org/abs/1909.11556)ã€‚

+   `decoder_layerdrop` (`float`, *optional*, defaults to 0.0) â€” è§£ç å™¨çš„ LayerDrop æ¦‚ç‡ã€‚æ›´å¤šç»†èŠ‚è¯·å‚é˜…[LayerDrop paper](https://arxiv.org/abs/1909.11556)ã€‚

+   `auxiliary_loss` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨è¾…åŠ©è§£ç æŸå¤±ï¼ˆæ¯ä¸ªè§£ç å™¨å±‚çš„æŸå¤±ï¼‰ã€‚

+   `position_embedding_type` (`str`, *optional*, defaults to `"sine"`) â€” åœ¨å›¾åƒç‰¹å¾ä¹‹ä¸Šä½¿ç”¨çš„ä½ç½®åµŒå…¥çš„ç±»å‹ã€‚å¯ä»¥æ˜¯`"sine"`æˆ–`"learned"`ä¹‹ä¸€ã€‚

+   `backbone` (`str`, *optional*, defaults to `"resnet50"`) â€” åœ¨`use_timm_backbone` = `True`æ—¶è¦ä½¿ç”¨çš„å·ç§¯éª¨å¹²ç½‘ç»œçš„åç§°ã€‚æ”¯æŒ timm åŒ…ä¸­çš„ä»»ä½•å·ç§¯éª¨å¹²ç½‘ç»œã€‚æœ‰å…³æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨ï¼Œè¯·å‚é˜…[æ­¤é¡µé¢](https://rwightman.github.io/pytorch-image-models/#load-a-pretrained-model)ã€‚

+   `use_pretrained_backbone` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦åœ¨éª¨å¹²ç½‘ç»œä¸­ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ã€‚ä»…åœ¨`use_timm_backbone` = `True`æ—¶æ”¯æŒã€‚

+   `dilation` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨æœ€åçš„å·ç§¯å—ï¼ˆDC5ï¼‰ä¸­ç”¨æ‰©å¼ æ›¿æ¢æ­¥å¹…ã€‚ä»…åœ¨`use_timm_backbone` = `True`æ—¶æ”¯æŒã€‚

+   `class_cost` (`float`, *optional*, defaults to 1) â€” åŒˆç‰™åˆ©åŒ¹é…æˆæœ¬ä¸­åˆ†ç±»é”™è¯¯çš„ç›¸å¯¹æƒé‡ã€‚

+   `bbox_cost` (`float`, *optional*, defaults to 5) â€” ç›¸å¯¹äºåŒˆç‰™åˆ©åŒ¹é…æˆæœ¬ä¸­è¾¹ç•Œæ¡†åæ ‡çš„ L1 è¯¯å·®çš„æƒé‡ã€‚

+   `giou_cost` (`float`, *optional*, defaults to 2) â€” ç›¸å¯¹äºåŒˆç‰™åˆ©åŒ¹é…æˆæœ¬ä¸­è¾¹ç•Œæ¡†å¹¿ä¹‰ IoU æŸå¤±çš„æƒé‡ã€‚

+   `mask_loss_coefficient` (`float`, *optional*, defaults to 1) â€” æ³›å…‰åˆ†å‰²æŸå¤±ä¸­ Focal æŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `dice_loss_coefficient` (`float`, *optional*, defaults to 1) â€” æ³›å…‰åˆ†å‰²æŸå¤±ä¸­ DICE/F-1 æŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `bbox_loss_coefficient` (`float`, *optional*, defaults to 5) â€” ç›®æ ‡æ£€æµ‹æŸå¤±ä¸­ L1 è¾¹ç•Œæ¡†æŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `giou_loss_coefficient` (`float`, *optional*, defaults to 2) â€” ç›®æ ‡æ£€æµ‹æŸå¤±ä¸­å¹¿ä¹‰ IoU æŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `eos_coefficient` (`float`, *optional*, defaults to 0.1) â€” ç›®æ ‡æ£€æµ‹æŸå¤±ä¸­â€œæ— å¯¹è±¡â€ç±»åˆ«çš„ç›¸å¯¹åˆ†ç±»æƒé‡ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ DetrModel çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ª DETR æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº DETR [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª PretrainedConfigï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»æ¥è‡ª PretrainedConfig çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import DetrConfig, DetrModel

>>> # Initializing a DETR facebook/detr-resnet-50 style configuration
>>> configuration = DetrConfig()

>>> # Initializing a model (with random weights) from the facebook/detr-resnet-50 style configuration
>>> model = DetrModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

#### `from_backbone_config`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/configuration_detr.py#L239)

```py
( backbone_config: PretrainedConfig **kwargs ) â†’ export const metadata = 'undefined';DetrConfig
```

å‚æ•°

+   `backbone_config` (PretrainedConfig) â€” éª¨å¹²é…ç½®ã€‚

è¿”å›

DetrConfig

é…ç½®å¯¹è±¡çš„å®ä¾‹

ä»é¢„è®­ç»ƒçš„éª¨å¹²æ¨¡å‹é…ç½®å®ä¾‹åŒ–ä¸€ä¸ª DetrConfigï¼ˆæˆ–æ´¾ç”Ÿç±»ï¼‰ã€‚

## DetrImageProcessor

### `class transformers.DetrImageProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L742)

```py
( format: Union = <AnnotationFormat.COCO_DETECTION: 'coco_detection'> do_resize: bool = True size: Dict = None resample: Resampling = <Resampling.BILINEAR: 2> do_rescale: bool = True rescale_factor: Union = 0.00392156862745098 do_normalize: bool = True image_mean: Union = None image_std: Union = None do_pad: bool = True **kwargs )
```

å‚æ•°

+   `format` (`str`, *optional*, é»˜è®¤ä¸º`"coco_detection"`) â€” æ³¨é‡Šçš„æ•°æ®æ ¼å¼ã€‚å¯ä»¥æ˜¯`"coco_detection"`æˆ–â€œcoco_panopticâ€ä¹‹ä¸€ã€‚

+   `do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ§åˆ¶æ˜¯å¦å°†å›¾åƒçš„`(height, width)`ç»´åº¦è°ƒæ•´ä¸ºæŒ‡å®šçš„`size`ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`do_resize`å‚æ•°è¦†ç›–ã€‚

+   `size` (`Dict[str, int]` *optional*, é»˜è®¤ä¸º `{"shortest_edge" -- 800, "longest_edge": 1333}`): è°ƒæ•´å¤§å°åçš„å›¾åƒçš„`(height, width)`ç»´åº¦å¤§å°ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`size`å‚æ•°è¦†ç›–ã€‚

+   `resample` (`PILImageResampling`, *optional*, é»˜è®¤ä¸º `PILImageResampling.BILINEAR`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™è¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚

+   `do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ§åˆ¶æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹å› å­`rescale_factor`é‡æ–°ç¼©æ”¾å›¾åƒã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`do_rescale`å‚æ•°è¦†ç›–ã€‚

+   `rescale_factor` (`int` æˆ– `float`, *optional*, é»˜è®¤ä¸º `1/255`) â€” å¦‚æœé‡æ–°è°ƒæ•´å›¾åƒï¼Œåˆ™è¦ä½¿ç”¨çš„æ¯”ä¾‹å› å­ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`rescale_factor`å‚æ•°è¦†ç›–ã€‚do_normalize â€” æ§åˆ¶æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`do_normalize`å‚æ•°è¦†ç›–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `IMAGENET_DEFAULT_MEAN`) â€” åœ¨å½’ä¸€åŒ–å›¾åƒæ—¶ä½¿ç”¨çš„å‡å€¼ã€‚å¯ä»¥æ˜¯å•ä¸ªå€¼æˆ–æ¯ä¸ªé€šé“çš„å€¼åˆ—è¡¨ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`image_mean`å‚æ•°è¦†ç›–ã€‚

+   `image_std` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `IMAGENET_DEFAULT_STD`) â€” åœ¨å½’ä¸€åŒ–å›¾åƒæ—¶ä½¿ç”¨çš„æ ‡å‡†å·®å€¼ã€‚å¯ä»¥æ˜¯å•ä¸ªå€¼æˆ–æ¯ä¸ªé€šé“çš„å€¼åˆ—è¡¨ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`image_std`å‚æ•°è¦†ç›–ã€‚

+   `do_pad` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ§åˆ¶æ˜¯å¦å°†å›¾åƒå¡«å……åˆ°æ‰¹å¤„ç†ä¸­æœ€å¤§çš„å›¾åƒå¹¶åˆ›å»ºåƒç´ æ©ç ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`do_pad`å‚æ•°è¦†ç›–ã€‚

æ„é€ ä¸€ä¸ª Detr å›¾åƒå¤„ç†å™¨ã€‚

#### `preprocess`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1070)

```py
( images: Union annotations: Union = None return_segmentation_masks: bool = None masks_path: Union = None do_resize: Optional = None size: Optional = None resample = None do_rescale: Optional = None rescale_factor: Union = None do_normalize: Optional = None image_mean: Union = None image_std: Union = None do_pad: Optional = None format: Union = None return_tensors: Union = None data_format: Union = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )
```

å‚æ•°

+   `images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚æœŸæœ›å•ä¸ªæˆ–æ‰¹é‡åƒç´ å€¼èŒƒå›´ä» 0 åˆ° 255 çš„å›¾åƒã€‚å¦‚æœä¼ å…¥åƒç´ å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´çš„å›¾åƒï¼Œè¯·è®¾ç½®`do_rescale=False`ã€‚

+   `annotations` (`AnnotationType` or `List[AnnotationType]`, *optional*) â€” ä¸å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ç›¸å…³è”çš„æ³¨é‡Šåˆ—è¡¨ã€‚å¦‚æœæ³¨é‡Šæ˜¯ç”¨äºå¯¹è±¡æ£€æµ‹çš„ï¼Œåˆ™æ³¨é‡Šåº”è¯¥æ˜¯ä¸€ä¸ªå¸¦æœ‰ä»¥ä¸‹é”®çš„å­—å…¸ï¼š

    +   â€œimage_idâ€ (`int`): å›¾åƒ idã€‚

    +   â€œannotationsâ€ (`List[Dict]`): å›¾åƒçš„æ³¨é‡Šåˆ—è¡¨ã€‚æ¯ä¸ªæ³¨é‡Šåº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ã€‚ä¸€ä¸ªå›¾åƒå¯ä»¥æ²¡æœ‰æ³¨é‡Šï¼Œæ­¤æ—¶åˆ—è¡¨åº”ä¸ºç©ºã€‚å¦‚æœæ³¨é‡Šæ˜¯ç”¨äºåˆ†å‰²çš„ï¼Œæ³¨é‡Šåº”è¯¥æ˜¯ä¸€ä¸ªå¸¦æœ‰ä»¥ä¸‹é”®çš„å­—å…¸ï¼š

    +   â€œimage_idâ€ (`int`): å›¾åƒ idã€‚

    +   â€œsegments_infoâ€ (`List[Dict]`): å›¾åƒçš„æ®µåˆ—è¡¨ã€‚æ¯ä¸ªæ®µåº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ã€‚ä¸€ä¸ªå›¾åƒå¯ä»¥æ²¡æœ‰æ®µï¼Œæ­¤æ—¶åˆ—è¡¨åº”ä¸ºç©ºã€‚

    +   â€œfile_nameâ€ (`str`): å›¾åƒçš„æ–‡ä»¶åã€‚

+   `return_segmentation_masks` (`bool`, *optional*, é»˜è®¤ä¸º self.return_segmentation_masks) â€” æ˜¯å¦è¿”å›åˆ†å‰²è’™ç‰ˆã€‚

+   `masks_path` (`str` or `pathlib.Path`, *optional*) â€” åŒ…å«åˆ†å‰²è’™ç‰ˆçš„ç›®å½•è·¯å¾„ã€‚

+   `do_resize` (`bool`, *optional*, é»˜è®¤ä¸º self.do_resize) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º self.size) â€” è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚

+   `resample` (`PILImageResampling`, *optional*, é»˜è®¤ä¸º self.resample) â€” è°ƒæ•´å›¾åƒå¤§å°æ—¶ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚

+   `do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º self.do_rescale) â€” æ˜¯å¦é‡æ–°ç¼©æ”¾å›¾åƒã€‚

+   `rescale_factor` (`float`, *optional*, é»˜è®¤ä¸º self.rescale_factor) â€” è°ƒæ•´å›¾åƒæ—¶ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚

+   `do_normalize` (`bool`, *optional*, é»˜è®¤ä¸º self.do_normalize) â€” æ˜¯å¦è§„èŒƒåŒ–å›¾åƒã€‚

+   `image_mean` (`float` or `List[float]`, *optional*, é»˜è®¤ä¸º self.image_mean) â€” åœ¨è§„èŒƒåŒ–å›¾åƒæ—¶ä½¿ç”¨çš„å‡å€¼ã€‚

+   `image_std` (`float` or `List[float]`, *optional*, é»˜è®¤ä¸º self.image_std) â€” åœ¨è§„èŒƒåŒ–å›¾åƒæ—¶ä½¿ç”¨çš„æ ‡å‡†å·®ã€‚

+   `do_pad` (`bool`, *optional*, é»˜è®¤ä¸º self.do_pad) â€” æ˜¯å¦å¡«å……å›¾åƒã€‚

+   `format` (`str` or `AnnotationFormat`, *optional*, é»˜è®¤ä¸º self.format) â€” æ³¨é‡Šçš„æ ¼å¼ã€‚

+   `return_tensors` (`str` or `TensorType`, *optional*, é»˜è®¤ä¸º self.return_tensors) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¦‚æœä¸º`None`ï¼Œå°†è¿”å›å›¾åƒåˆ—è¡¨ã€‚

+   `data_format` (`ChannelDimension` or `str`, *optional*, é»˜è®¤ä¸º`ChannelDimension.FIRST`) â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`: å›¾åƒä»¥ï¼ˆé€šé“æ•°ï¼Œé«˜åº¦ï¼Œå®½åº¦ï¼‰æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`: å›¾åƒä»¥ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼Œé€šé“æ•°ï¼‰æ ¼å¼ã€‚

    +   æœªè®¾ç½®ï¼šä½¿ç”¨è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚

+   `input_data_format` (`ChannelDimension` or `str`, *optional*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`: å›¾åƒä»¥ï¼ˆé€šé“æ•°ï¼Œé«˜åº¦ï¼Œå®½åº¦ï¼‰æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`: å›¾åƒä»¥ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼Œé€šé“æ•°ï¼‰æ ¼å¼ã€‚

    +   `"none"` æˆ– `ChannelDimension.NONE`: å›¾åƒä»¥ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰æ ¼å¼ã€‚

é¢„å¤„ç†å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥ä½¿ç”¨ã€‚

#### `post_process_object_detection`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1572)

```py
( outputs threshold: float = 0.5 target_sizes: Union = None ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs` (`DetrObjectDetectionOutput`) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `threshold` (`float`, *optional*) â€” ä¿ç•™å¯¹è±¡æ£€æµ‹é¢„æµ‹çš„åˆ†æ•°é˜ˆå€¼ã€‚

+   `target_sizes` (`torch.Tensor`æˆ–`åˆ—è¡¨[å…ƒç»„[int, int]]`, *å¯é€‰*) â€” å½¢çŠ¶ä¸º`(batch_size, 2)`çš„å¼ é‡æˆ–åŒ…å«æ¯ä¸ªå›¾åƒçš„ç›®æ ‡å¤§å°`(é«˜åº¦ï¼Œå®½åº¦)`çš„å…ƒç»„åˆ—è¡¨(`å…ƒç»„[int, int]`)ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

è¿”å›

`åˆ—è¡¨[å­—å…¸]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«æ¨¡å‹é¢„æµ‹çš„æ‰¹æ¬¡ä¸­å›¾åƒçš„åˆ†æ•°ã€æ ‡ç­¾å’Œæ¡†ã€‚

å°† DetrForObjectDetection çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºæœ€ç»ˆçš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸ºï¼ˆå·¦ä¸Šè§’ _xï¼Œå·¦ä¸Šè§’ _yï¼Œå³ä¸‹è§’ _xï¼Œå³ä¸‹è§’ _yï¼‰ã€‚ä»…æ”¯æŒ PyTorchã€‚

#### `åå¤„ç†è¯­ä¹‰åˆ†å‰²`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1625)

```py
( outputs target_sizes: List = None ) â†’ export const metadata = 'undefined';List[torch.Tensor]
```

å‚æ•°

+   `outputs` (DetrForSegmentation) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `target_sizes` (`åˆ—è¡¨[å…ƒç»„[int, int]]`, *å¯é€‰*) â€” ä¸€ä¸ªå…ƒç»„åˆ—è¡¨(`å…ƒç»„[int, int]`)ï¼ŒåŒ…å«æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„ç›®æ ‡å¤§å°ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

è¿”å›

`åˆ—è¡¨[torch.Tensor]`

ä¸€ä¸ªé•¿åº¦ä¸º`batch_size`çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªé¡¹æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(é«˜åº¦ï¼Œå®½åº¦)çš„è¯­ä¹‰åˆ†å‰²åœ°å›¾ï¼Œå¯¹åº”äºç›®æ ‡å¤§å°æ¡ç›®ï¼ˆå¦‚æœæŒ‡å®šäº†`target_sizes`ï¼‰ã€‚æ¯ä¸ª`torch.Tensor`çš„æ¯ä¸ªæ¡ç›®å¯¹åº”äºä¸€ä¸ªè¯­ä¹‰ç±»åˆ« idã€‚

å°† DetrForSegmentation çš„è¾“å‡ºè½¬æ¢ä¸ºè¯­ä¹‰åˆ†å‰²åœ°å›¾ã€‚ä»…æ”¯æŒ PyTorchã€‚

#### `åå¤„ç†å®ä¾‹åˆ†å‰²`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1673)

```py
( outputs threshold: float = 0.5 mask_threshold: float = 0.5 overlap_mask_area_threshold: float = 0.8 target_sizes: Optional = None return_coco_annotation: Optional = False ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs` (DetrForSegmentation) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `threshold` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.5) â€” ä¿ç•™é¢„æµ‹å®ä¾‹æ©æ¨¡çš„æ¦‚ç‡åˆ†æ•°é˜ˆå€¼ã€‚

+   `mask_threshold` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.5) â€” å°†é¢„æµ‹çš„æ©æ¨¡è½¬æ¢ä¸ºäºŒè¿›åˆ¶å€¼æ—¶ä½¿ç”¨çš„é˜ˆå€¼ã€‚

+   `overlap_mask_area_threshold` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.8) â€” åˆå¹¶æˆ–ä¸¢å¼ƒæ¯ä¸ªäºŒè¿›åˆ¶å®ä¾‹æ©æ¨¡ä¸­çš„å°ä¸è¿ç»­éƒ¨åˆ†çš„é‡å æ©æ¨¡åŒºåŸŸé˜ˆå€¼ã€‚

+   `target_sizes` (`åˆ—è¡¨[å…ƒç»„]`, *å¯é€‰*) â€” é•¿åº¦ä¸º(batch_size)çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªåˆ—è¡¨é¡¹(`å…ƒç»„[int, int]]`)å¯¹åº”äºæ¯ä¸ªé¢„æµ‹çš„è¯·æ±‚æœ€ç»ˆå¤§å°(é«˜åº¦ï¼Œå®½åº¦)ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

+   `return_coco_annotation` (`bool`, *å¯é€‰*) â€” é»˜è®¤ä¸º`False`ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ä»¥ COCO è¿è¡Œé•¿åº¦ç¼–ç ï¼ˆRLEï¼‰æ ¼å¼è¿”å›åˆ†å‰²åœ°å›¾ã€‚

è¿”å›

`åˆ—è¡¨[å­—å…¸]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå›¾åƒä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä¸¤ä¸ªé”®ï¼š

+   `segmentation` â€” å½¢çŠ¶ä¸º`(é«˜åº¦ï¼Œå®½åº¦)`çš„å¼ é‡ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ ä»£è¡¨`segment_id`æˆ–`åˆ—è¡¨[åˆ—è¡¨]`çš„è¿è¡Œé•¿åº¦ç¼–ç ï¼ˆRLEï¼‰çš„åˆ†å‰²åœ°å›¾ï¼Œå¦‚æœ return_coco_annotation è®¾ç½®ä¸º`True`ã€‚å¦‚æœæœªæ‰¾åˆ°é«˜äº`threshold`çš„æ©æ¨¡ï¼Œåˆ™è®¾ç½®ä¸º`None`ã€‚

+   `segments_info` â€” åŒ…å«æ¯ä¸ªæ®µçš„é™„åŠ ä¿¡æ¯çš„å­—å…¸ã€‚

    +   `id` â€” ä»£è¡¨`segment_id`çš„æ•´æ•°ã€‚

    +   `label_id` â€” ä»£è¡¨ä¸`segment_id`å¯¹åº”çš„æ ‡ç­¾/è¯­ä¹‰ç±»åˆ« id çš„æ•´æ•°ã€‚

    +   `score` â€” å…·æœ‰`segment_id`çš„æ®µçš„é¢„æµ‹åˆ†æ•°ã€‚

å°† DetrForSegmentation çš„è¾“å‡ºè½¬æ¢ä¸ºå®ä¾‹åˆ†å‰²é¢„æµ‹ã€‚ä»…æ”¯æŒ PyTorchã€‚

#### `åå¤„ç†å…¨æ™¯åˆ†å‰²`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1757)

```py
( outputs threshold: float = 0.5 mask_threshold: float = 0.5 overlap_mask_area_threshold: float = 0.8 label_ids_to_fuse: Optional = None target_sizes: Optional = None ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs` (DetrForSegmentation) â€” æ¥è‡ª DetrForSegmentation çš„è¾“å‡ºã€‚

+   `threshold` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.5) â€” ä¿ç•™é¢„æµ‹å®ä¾‹æ©æ¨¡çš„æ¦‚ç‡åˆ†æ•°é˜ˆå€¼ã€‚

+   `mask_threshold` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.5) â€” åœ¨å°†é¢„æµ‹çš„æ©æ¨¡è½¬æ¢ä¸ºäºŒè¿›åˆ¶å€¼æ—¶ä½¿ç”¨çš„é˜ˆå€¼ã€‚

+   `overlap_mask_area_threshold` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.8) â€” åˆå¹¶æˆ–ä¸¢å¼ƒæ¯ä¸ªäºŒè¿›åˆ¶å®ä¾‹æ©æ¨¡ä¸­çš„å°æ–­å¼€éƒ¨åˆ†çš„é‡å æ©æ¨¡é¢ç§¯é˜ˆå€¼ã€‚

+   `label_ids_to_fuse` (`Set[int]`, *å¯é€‰*) â€” æ­¤çŠ¶æ€ä¸­çš„æ ‡ç­¾å°†ä½¿å…¶æ‰€æœ‰å®ä¾‹è¢«èåˆåœ¨ä¸€èµ·ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ä¸€å¼ å›¾åƒä¸­åªèƒ½æœ‰ä¸€ä¸ªå¤©ç©ºï¼Œä½†å¯ä»¥æœ‰å‡ ä¸ªäººï¼Œå› æ­¤å¤©ç©ºçš„æ ‡ç­¾ ID å°†åœ¨è¯¥é›†åˆä¸­ï¼Œä½†äººçš„æ ‡ç­¾ ID ä¸åœ¨å…¶ä¸­ã€‚

+   `target_sizes` (`List[Tuple]`, *å¯é€‰*) â€” é•¿åº¦ä¸º(batch_size)çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªåˆ—è¡¨é¡¹(`Tuple[int, int]]`)å¯¹åº”äºæ‰¹æ¬¡ä¸­æ¯ä¸ªé¢„æµ‹çš„è¯·æ±‚æœ€ç»ˆå¤§å°(é«˜åº¦ã€å®½åº¦)ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

è¿”å›

`List[Dict]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå›¾åƒä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä¸¤ä¸ªé”®ï¼š

+   `segmentation` â€” å½¢çŠ¶ä¸º`(height, width)`çš„å¼ é‡ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ è¡¨ç¤ºä¸€ä¸ª`segment_id`ï¼Œå¦‚æœåœ¨`threshold`ä»¥ä¸Šæ‰¾ä¸åˆ°æ©æ¨¡ï¼Œåˆ™è¡¨ç¤ºä¸º`None`ã€‚å¦‚æœæŒ‡å®šäº†`target_sizes`ï¼Œåˆ™å°†åˆ†å‰²è°ƒæ•´ä¸ºç›¸åº”çš„`target_sizes`æ¡ç›®ã€‚

+   `segments_info` â€” ä¸€ä¸ªåŒ…å«æ¯ä¸ªæ®µçš„é¢å¤–ä¿¡æ¯çš„å­—å…¸ã€‚

    +   `id` â€” ä»£è¡¨`segment_id`çš„æ•´æ•°ã€‚

    +   `label_id` â€” ä»£è¡¨ä¸`segment_id`å¯¹åº”çš„æ ‡ç­¾/è¯­ä¹‰ç±»åˆ« id çš„æ•´æ•°ã€‚

    +   `was_fused` â€” ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå¦‚æœ`label_id`åœ¨`label_ids_to_fuse`ä¸­ï¼Œåˆ™ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚åŒä¸€ç±»åˆ«/æ ‡ç­¾çš„å¤šä¸ªå®ä¾‹è¢«èåˆå¹¶åˆ†é…ä¸€ä¸ªå•ç‹¬çš„`segment_id`ã€‚

    +   `score` â€” å¸¦æœ‰`segment_id`çš„æ®µçš„é¢„æµ‹åˆ†æ•°ã€‚

å°† DetrForSegmentation çš„è¾“å‡ºè½¬æ¢ä¸ºå›¾åƒå…¨æ™¯åˆ†å‰²é¢„æµ‹ã€‚ä»…æ”¯æŒ PyTorchã€‚

## DetrFeatureExtractor

### `class transformers.DetrFeatureExtractor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/feature_extraction_detr.py#L36)

```py
( *args **kwargs )
```

#### `__call__`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)

```py
( images **kwargs )
```

é¢„å¤„ç†ä¸€å¼ å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒã€‚

#### `post_process_object_detection`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1572)

```py
( outputs threshold: float = 0.5 target_sizes: Union = None ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs` (`DetrObjectDetectionOutput`) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `threshold` (`float`, *å¯é€‰*) â€” ä¿ç•™å¯¹è±¡æ£€æµ‹é¢„æµ‹çš„åˆ†æ•°é˜ˆå€¼ã€‚

+   `target_sizes` (`torch.Tensor`æˆ–`List[Tuple[int, int]]`, *å¯é€‰*) â€” å½¢çŠ¶ä¸º`(batch_size, 2)`çš„å¼ é‡æˆ–åŒ…å«æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„ç›®æ ‡å¤§å°`(height, width)`çš„å…ƒç»„åˆ—è¡¨(`Tuple[int, int]`)ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

è¿”å›

`List[Dict]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«æ¨¡å‹é¢„æµ‹çš„æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„åˆ†æ•°ã€æ ‡ç­¾å’Œæ¡†ã€‚

å°† DetrForObjectDetection çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸º(top_left_x, top_left_y, bottom_right_x, bottom_right_y)æ ¼å¼çš„æœ€ç»ˆè¾¹ç•Œæ¡†ã€‚ä»…æ”¯æŒ PyTorchã€‚

#### `post_process_semantic_segmentation`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1625)

```py
( outputs target_sizes: List = None ) â†’ export const metadata = 'undefined';List[torch.Tensor]
```

å‚æ•°

+   `outputs` (DetrForSegmentation) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `target_sizes`ï¼ˆ`List[Tuple[int, int]]`ï¼Œ*å¯é€‰*ï¼‰ - ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ï¼ˆ`Tuple[int, int]`ï¼‰ï¼ŒåŒ…å«æ‰¹å¤„ç†ä¸­æ¯ä¸ªå›¾åƒçš„ç›®æ ‡å¤§å°ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

è¿”å›

`List[torch.Tensor]`

ä¸€ä¸ªé•¿åº¦ä¸º`batch_size`çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªé¡¹ç›®éƒ½æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰çš„è¯­ä¹‰åˆ†å‰²åœ°å›¾ï¼Œå¯¹åº”äº`target_sizes`æ¡ç›®ï¼ˆå¦‚æœæŒ‡å®šäº†`target_sizes`ï¼‰ã€‚æ¯ä¸ª`torch.Tensor`çš„æ¡ç›®å¯¹åº”äºä¸€ä¸ªè¯­ä¹‰ç±»åˆ« idã€‚

å°† DetrForSegmentation çš„è¾“å‡ºè½¬æ¢ä¸ºè¯­ä¹‰åˆ†å‰²åœ°å›¾ã€‚ä»…æ”¯æŒ PyTorchã€‚

#### `post_process_instance_segmentation`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1673)

```py
( outputs threshold: float = 0.5 mask_threshold: float = 0.5 overlap_mask_area_threshold: float = 0.8 target_sizes: Optional = None return_coco_annotation: Optional = False ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs`ï¼ˆDetrForSegmentationï¼‰ - æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `threshold`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.5ï¼‰ - ä¿ç•™é¢„æµ‹å®ä¾‹æ©ç çš„æ¦‚ç‡åˆ†æ•°é˜ˆå€¼ã€‚

+   `mask_threshold`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.5ï¼‰ - åœ¨å°†é¢„æµ‹çš„æ©ç è½¬æ¢ä¸ºäºŒè¿›åˆ¶å€¼æ—¶ä½¿ç”¨çš„é˜ˆå€¼ã€‚

+   `overlap_mask_area_threshold`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.8ï¼‰ - åˆå¹¶æˆ–ä¸¢å¼ƒæ¯ä¸ªäºŒè¿›åˆ¶å®ä¾‹æ©ç ä¸­çš„å°æ–­å¼€éƒ¨åˆ†çš„é‡å æ©ç åŒºåŸŸé˜ˆå€¼ã€‚

+   `target_sizes`ï¼ˆ`List[Tuple]`ï¼Œ*å¯é€‰*ï¼‰ - é•¿åº¦ä¸ºï¼ˆbatch_sizeï¼‰çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªåˆ—è¡¨é¡¹ï¼ˆ`Tuple[int, int]`ï¼‰å¯¹åº”äºæ¯ä¸ªé¢„æµ‹çš„è¯·æ±‚æœ€ç»ˆå¤§å°ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

+   `return_coco_annotation`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰ - é»˜è®¤ä¸º`False`ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ä»¥ COCO è¿è¡Œé•¿åº¦ç¼–ç ï¼ˆRLEï¼‰æ ¼å¼è¿”å›åˆ†å‰²åœ°å›¾ã€‚

è¿”å›

`List[Dict]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå›¾åƒä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä¸¤ä¸ªé”®ï¼š

+   `segmentation` - ä¸€ä¸ªå½¢çŠ¶ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰çš„å¼ é‡ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ è¡¨ç¤º`segment_id`æˆ–åˆ†å‰²åœ°å›¾çš„`List[List]`è¿è¡Œé•¿åº¦ç¼–ç ï¼ˆRLEï¼‰ï¼Œå¦‚æœ`return_coco_annotation`è®¾ç½®ä¸º`True`ã€‚å¦‚æœæœªæ‰¾åˆ°é«˜äº`threshold`çš„æ©ç ï¼Œåˆ™è®¾ç½®ä¸º`None`ã€‚

+   `segments_info` - åŒ…å«æ¯ä¸ªæ®µçš„é™„åŠ ä¿¡æ¯çš„å­—å…¸ã€‚

    +   `id` - è¡¨ç¤º`segment_id`çš„æ•´æ•°ã€‚

    +   `label_id` - è¡¨ç¤ºä¸`segment_id`å¯¹åº”çš„æ ‡ç­¾/è¯­ä¹‰ç±»åˆ« id çš„æ•´æ•°ã€‚

    +   `score` - å…·æœ‰`segment_id`çš„æ®µçš„é¢„æµ‹åˆ†æ•°ã€‚

å°† DetrForSegmentation çš„è¾“å‡ºè½¬æ¢ä¸ºå®ä¾‹åˆ†å‰²é¢„æµ‹ã€‚ä»…æ”¯æŒ PyTorchã€‚

#### `post_process_panoptic_segmentation`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/image_processing_detr.py#L1757)

```py
( outputs threshold: float = 0.5 mask_threshold: float = 0.5 overlap_mask_area_threshold: float = 0.8 label_ids_to_fuse: Optional = None target_sizes: Optional = None ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs`ï¼ˆDetrForSegmentationï¼‰ - æ¥è‡ª DetrForSegmentation çš„è¾“å‡ºã€‚

+   `threshold`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.5ï¼‰ - ä¿ç•™é¢„æµ‹å®ä¾‹æ©ç çš„æ¦‚ç‡åˆ†æ•°é˜ˆå€¼ã€‚

+   `mask_threshold`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.5ï¼‰ - åœ¨å°†é¢„æµ‹çš„æ©ç è½¬æ¢ä¸ºäºŒè¿›åˆ¶å€¼æ—¶ä½¿ç”¨çš„é˜ˆå€¼ã€‚

+   `overlap_mask_area_threshold`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.8ï¼‰ - åˆå¹¶æˆ–ä¸¢å¼ƒæ¯ä¸ªäºŒè¿›åˆ¶å®ä¾‹æ©ç ä¸­çš„å°æ–­å¼€éƒ¨åˆ†çš„é‡å æ©ç åŒºåŸŸé˜ˆå€¼ã€‚

+   `label_ids_to_fuse`ï¼ˆ`Set[int]`ï¼Œ*å¯é€‰*ï¼‰ - æ­¤çŠ¶æ€ä¸­çš„æ ‡ç­¾å°†ä½¿å…¶æ‰€æœ‰å®ä¾‹è¢«èåˆåœ¨ä¸€èµ·ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¯´å›¾åƒä¸­åªèƒ½æœ‰ä¸€ä¸ªå¤©ç©ºï¼Œä½†å¯ä»¥æœ‰å‡ ä¸ªäººï¼Œå› æ­¤å¤©ç©ºçš„æ ‡ç­¾ ID å°†åœ¨è¯¥é›†åˆä¸­ï¼Œä½†äººçš„æ ‡ç­¾ ID ä¸åœ¨å…¶ä¸­ã€‚

+   `target_sizes` (`List[Tuple]`, *optional*) â€” é•¿åº¦ä¸º`(batch_size)`çš„åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ—è¡¨é¡¹(`Tuple[int, int]]`)å¯¹åº”äºæ‰¹å¤„ç†ä¸­æ¯ä¸ªé¢„æµ‹çš„è¯·æ±‚æœ€ç»ˆå¤§å°(é«˜åº¦ï¼Œå®½åº¦)ã€‚å¦‚æœæœªè®¾ç½®ï¼Œé¢„æµ‹å°†ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

è¿”å›å€¼

`List[Dict]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå›¾åƒä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä¸¤ä¸ªé”®:

+   `segmentation` â€” å½¢çŠ¶ä¸º`(height, width)`çš„å¼ é‡ï¼Œæ¯ä¸ªåƒç´ ä»£è¡¨ä¸€ä¸ª`segment_id`ï¼Œå¦‚æœæ‰¾ä¸åˆ°é®ç½©ï¼Œåˆ™ä¸º`None`ã€‚å¦‚æœæŒ‡å®šäº†`target_sizes`ï¼Œåˆ™å°†åˆ†å‰²è°ƒæ•´ä¸ºç›¸åº”çš„`target_sizes`æ¡ç›®ã€‚

+   `segments_info` â€” åŒ…å«æ¯ä¸ªæ®µçš„é™„åŠ ä¿¡æ¯çš„å­—å…¸ã€‚

    +   `id` â€” ä»£è¡¨`segment_id`çš„æ•´æ•°ã€‚

    +   `label_id` â€” ä»£è¡¨ä¸`segment_id`å¯¹åº”çš„æ ‡ç­¾/è¯­ä¹‰ç±»åˆ« id çš„æ•´æ•°ã€‚

    +   `was_fused` â€” ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå¦‚æœ`label_id`åœ¨`label_ids_to_fuse`ä¸­ï¼Œåˆ™ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚ç›¸åŒç±»åˆ«/æ ‡ç­¾çš„å¤šä¸ªå®ä¾‹è¢«èåˆå¹¶åˆ†é…ä¸€ä¸ªå•ä¸€çš„`segment_id`ã€‚

    +   `score` â€” å…·æœ‰`segment_id`çš„æ®µçš„é¢„æµ‹åˆ†æ•°ã€‚

å°† DetrForSegmentation çš„è¾“å‡ºè½¬æ¢ä¸ºå›¾åƒå…¨æ™¯åˆ†å‰²é¢„æµ‹ã€‚ä»…æ”¯æŒ PyTorchã€‚

## DETR ç‰¹å®šè¾“å‡º

### `class transformers.models.detr.modeling_detr.DetrModelOutput`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L94)

```py
( last_hidden_state: FloatTensor = None past_key_values: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None intermediate_hidden_states: Optional = None )
```

å‚æ•°

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ª`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ã€‚æ¯å±‚è§£ç å™¨çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ª`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ª`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚è§£ç å™¨äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ª`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ã€‚æ¯å±‚ç¼–ç å™¨çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ª`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `intermediate_hidden_states`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(config.decoder_layers, batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼Œå½“`config.auxiliary_loss=True`æ—¶è¿”å›ï¼‰â€” ä¸­é—´è§£ç å™¨æ¿€æ´»ï¼Œå³æ¯ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºï¼Œæ¯ä¸ªè¾“å‡ºéƒ½ç»è¿‡äº† layernormã€‚

DETR ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹è¾“å‡ºçš„åŸºç±»ã€‚è¯¥ç±»åœ¨ Seq2SeqModelOutput ä¸­æ·»åŠ äº†ä¸€ä¸ªå±æ€§ï¼Œå³ä¸€ä¸ªå¯é€‰çš„ä¸­é—´è§£ç å™¨æ¿€æ´»å †æ ˆï¼Œå³æ¯ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºï¼Œæ¯ä¸ªè¾“å‡ºéƒ½ç»è¿‡äº† layernormã€‚åœ¨ä½¿ç”¨è¾…åŠ©è§£ç æŸå¤±è®­ç»ƒæ¨¡å‹æ—¶ï¼Œè¿™æ˜¯æœ‰ç”¨çš„ã€‚

### `class transformers.models.detr.modeling_detr.DetrObjectDetectionOutput`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L134)

```py
( loss: Optional = None loss_dict: Optional = None logits: FloatTensor = None pred_boxes: FloatTensor = None auxiliary_outputs: Optional = None last_hidden_state: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

å‚æ•°

+   `loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰â€” æ€»æŸå¤±ï¼Œä½œä¸ºç±»é¢„æµ‹çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆäº¤å‰ç†µï¼‰å’Œè¾¹ç•Œæ¡†æŸå¤±çš„çº¿æ€§ç»„åˆã€‚åè€…å®šä¹‰ä¸º L1 æŸå¤±å’Œå¹¿ä¹‰æ¯”ä¾‹ä¸å˜ IoU æŸå¤±çš„çº¿æ€§ç»„åˆã€‚

+   `loss_dict`ï¼ˆ`Dict`ï¼Œ*å¯é€‰*ï¼‰â€” åŒ…å«å„ä¸ªæŸå¤±çš„å­—å…¸ã€‚ç”¨äºè®°å½•æ—¥å¿—ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_queries, num_classes + 1)`çš„`torch.FloatTensor`ï¼‰â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†ç±» logitsï¼ˆåŒ…æ‹¬æ— å¯¹è±¡ï¼‰ã€‚

+   `pred_boxes`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_queries, 4)`çš„`torch.FloatTensor`ï¼‰â€” æ‰€æœ‰æŸ¥è¯¢çš„å½’ä¸€åŒ–æ¡†åæ ‡ï¼Œè¡¨ç¤ºä¸ºï¼ˆä¸­å¿ƒ _xï¼Œä¸­å¿ƒ _yï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰ã€‚è¿™äº›å€¼åœ¨[0, 1]èŒƒå›´å†…å½’ä¸€åŒ–ï¼Œç›¸å¯¹äºæ‰¹å¤„ç†ä¸­æ¯ä¸ªå•ç‹¬å›¾åƒçš„å¤§å°ï¼ˆå¿½ç•¥å¯èƒ½çš„å¡«å……ï¼‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ post_process_object_detection()æ¥æ£€ç´¢æœªå½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†ã€‚

+   `auxiliary_outputs`ï¼ˆ`list[Dict]`ï¼Œ*å¯é€‰*ï¼‰â€” ä»…åœ¨æ¿€æ´»è¾…åŠ©æŸå¤±ï¼ˆå³`config.auxiliary_loss`è®¾ç½®ä¸º`True`ï¼‰å¹¶æä¾›æ ‡ç­¾æ—¶è¿”å›ã€‚å®ƒæ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªä¸Šè¿°é”®ï¼ˆ`logits`å’Œ`pred_boxes`ï¼‰çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸å¯¹åº”ä¸€ä¸ªè§£ç å™¨å±‚ã€‚

+   `last_hidden_state`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `decoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚æ¯ä¸ªå±‚çš„è§£ç å™¨çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚ç¼–ç å™¨åœ¨æ¯ä¸€å±‚çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

DetrForObjectDetection çš„è¾“å‡ºç±»å‹ã€‚

### `class transformers.models.detr.modeling_detr.DetrSegmentationOutput`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L197)

```py
( loss: Optional = None loss_dict: Optional = None logits: FloatTensor = None pred_boxes: FloatTensor = None pred_masks: FloatTensor = None auxiliary_outputs: Optional = None last_hidden_state: Optional = None decoder_hidden_states: Optional = None decoder_attentions: Optional = None cross_attentions: Optional = None encoder_last_hidden_state: Optional = None encoder_hidden_states: Optional = None encoder_attentions: Optional = None )
```

å‚æ•°

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, å½“æä¾›`labels`æ—¶è¿”å›) â€” ä½œä¸ºè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆäº¤å‰ç†µï¼‰å’Œè¾¹ç•Œæ¡†æŸå¤±çš„çº¿æ€§ç»„åˆçš„æ€»æŸå¤±ã€‚åè€…å®šä¹‰ä¸º L1 æŸå¤±å’Œå¹¿ä¹‰å°ºåº¦ä¸å˜ IoU æŸå¤±çš„çº¿æ€§ç»„åˆã€‚

+   `loss_dict` (`Dict`, *optional*) â€” åŒ…å«å„ä¸ªæŸå¤±çš„å­—å…¸ã€‚ç”¨äºè®°å½•æ—¥å¿—ã€‚

+   `logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes + 1)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†ç±» logitsï¼ˆåŒ…æ‹¬æ— å¯¹è±¡ï¼‰ã€‚

+   `pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„å½’ä¸€åŒ–æ¡†åæ ‡ï¼Œè¡¨ç¤ºä¸ºï¼ˆä¸­å¿ƒ _xï¼Œä¸­å¿ƒ _yï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰ã€‚è¿™äº›å€¼åœ¨[0, 1]èŒƒå›´å†…å½’ä¸€åŒ–ï¼Œç›¸å¯¹äºæ‰¹å¤„ç†ä¸­æ¯ä¸ªå•ç‹¬å›¾åƒçš„å¤§å°ï¼ˆå¿½ç•¥å¯èƒ½çš„å¡«å……ï¼‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ post_process_object_detection()æ¥æ£€ç´¢æœªå½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†ã€‚

+   `pred_masks` (`torch.FloatTensor` of shape `(batch_size, num_queries, height/4, width/4)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†å‰²æ©æ¨¡ logitsã€‚å¦è¯·å‚é˜… post_process_semantic_segmentation()æˆ– post_process_instance_segmentation()post_process_panoptic_segmentation()åˆ†åˆ«è¯„ä¼°è¯­ä¹‰ã€å®ä¾‹å’Œå…¨æ™¯åˆ†å‰²æ©æ¨¡ã€‚

+   `auxiliary_outputs` (`list[Dict]`, *optional*) â€” å¯é€‰ï¼Œä»…åœ¨æ¿€æ´»è¾…åŠ©æŸå¤±ï¼ˆå³`config.auxiliary_loss`è®¾ç½®ä¸º`True`ï¼‰å¹¶æä¾›æ ‡ç­¾æ—¶è¿”å›ã€‚å®ƒæ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªè§£ç å™¨å±‚çš„ä¸Šè¿°ä¸¤ä¸ªé”®ï¼ˆ`logits`å’Œ`pred_boxes`ï¼‰çš„å­—å…¸åˆ—è¡¨ã€‚

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚è§£ç å™¨åœ¨æ¯ä¸€å±‚çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯å±‚çš„è¾“å‡ºï¼‰ã€‚ç¼–ç å™¨åœ¨æ¯å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

DetrForSegmentation çš„è¾“å‡ºç±»å‹ã€‚

## DetrModel

### `class transformers.DetrModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L1296)

```py
( config: DetrConfig )
```

å‚æ•°

+   `config` (DetrConfig) â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸çš„ DETR æ¨¡å‹ï¼ˆç”±éª¨å¹²å’Œç¼–ç å™¨-è§£ç å™¨ Transformer ç»„æˆï¼‰ï¼Œè¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚

è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª PreTrainedModelã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L1337)

```py
( pixel_values: FloatTensor pixel_mask: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.models.detr.modeling_detr.DetrModelOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚

    å¯ä»¥ä½¿ç”¨ AutoImageProcessor è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… DetrImageProcessor.`call`()ã€‚

+   `pixel_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, height, width)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¿å…åœ¨å¡«å……åƒç´ å€¼ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„é®ç½©ã€‚é®ç½©å€¼é€‰æ‹©åœ¨`[0, 1]`ä¸­ï¼š

    +   å¯¹äºçœŸå®çš„åƒç´ ï¼ˆå³`æœªè¢«é®ç½©`ï¼‰ï¼Œ

    +   å¯¹äºå¡«å……åƒç´ ï¼ˆå³`è¢«é®ç½©`ï¼‰ä¸º 0ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›é®ç½©ï¼Ÿ

+   `decoder_attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_queries)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é»˜è®¤æƒ…å†µä¸‹ä¸ä½¿ç”¨ã€‚å¯ç”¨äºå±è”½å¯¹è±¡æŸ¥è¯¢ã€‚

+   `encoder_outputs`ï¼ˆ`tuple(tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼‰â€” å…ƒç»„åŒ…æ‹¬ï¼ˆ`last_hidden_state`ï¼Œ*å¯é€‰*ï¼š`hidden_states`ï¼Œ*å¯é€‰*ï¼š`attentions`ï¼‰`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼‰æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚

+   `inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’ä¸€ä¸ªå›¾åƒçš„æ‰å¹³è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’æ‰å¹³ç‰¹å¾å›¾ï¼ˆéª¨å¹²ç½‘ç»œè¾“å‡º+æŠ•å½±å±‚çš„è¾“å‡ºï¼‰ã€‚

+   `decoder_inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_queries, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’ä¸€ä¸ªåµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ç”¨é›¶å¼ é‡åˆå§‹åŒ–æŸ¥è¯¢ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›ä¸€ä¸ª ModelOutput è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚

è¿”å›

transformers.models.detr.modeling_detr.DetrModelOutput æˆ–`tuple(torch.FloatTensor)`

ä¸€ä¸ª transformers.models.detr.modeling_detr.DetrModelOutput æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…æ‹¬æ ¹æ®é…ç½®ï¼ˆDetrConfigï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚

+   `last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼‰â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—çš„è¾“å‡ºã€‚

+   `decoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å…ƒç»„åŒ…æ‹¬ï¼ˆæ¯ä¸ªå±‚çš„åµŒå…¥è¾“å‡º+æ¯ä¸ªå±‚çš„è¾“å‡ºçš„`torch.FloatTensor`ï¼‰å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ã€‚è§£ç å™¨åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºéšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–å½“`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–å½“`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å…ƒç»„åŒ…æ‹¬ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€”æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€”ç¼–ç å™¨çš„éšè—çŠ¶æ€å…ƒç»„ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚æ¯å±‚çš„ç¼–ç å™¨éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `encoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡å…ƒç»„ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚ç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼çš„ç¼–ç å™¨çš„æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ã€‚

+   `intermediate_hidden_states`ï¼ˆå½¢çŠ¶ä¸º`(config.decoder_layers, batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“`config.auxiliary_loss=True`æ—¶è¿”å›ï¼‰â€”ä¸­é—´è§£ç å™¨æ¿€æ´»ï¼Œå³æ¯ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºï¼Œæ¯ä¸ªéƒ½ç»è¿‡ä¸€ä¸ª layernormã€‚

DetrModel çš„å‰å‘æ–¹æ³•è¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œå‰å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, DetrModel
>>> from PIL import Image
>>> import requests

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/detr-resnet-50")
>>> model = DetrModel.from_pretrained("facebook/detr-resnet-50")

>>> # prepare image for the model
>>> inputs = image_processor(images=image, return_tensors="pt")

>>> # forward pass
>>> outputs = model(**inputs)

>>> # the last hidden states are the final query embeddings of the Transformer decoder
>>> # these are of shape (batch_size, num_queries, hidden_size)
>>> last_hidden_states = outputs.last_hidden_state
>>> list(last_hidden_states.shape)
[1, 100, 256]
```

## DetrForObjectDetection

### `class transformers.DetrForObjectDetection`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L1464)

```py
( config: DetrConfig )
```

å‚æ•°

+   `config`ï¼ˆDetrConfigï¼‰â€”æ¨¡å‹çš„æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

DETR æ¨¡å‹ï¼ˆç”±éª¨å¹²å’Œç¼–ç å™¨-è§£ç å™¨ Transformer ç»„æˆï¼‰ï¼Œé¡¶éƒ¨å¸¦æœ‰ç›®æ ‡æ£€æµ‹å¤´ï¼Œç”¨äºè¯¸å¦‚ COCO æ£€æµ‹ä¹‹ç±»çš„ä»»åŠ¡ã€‚

è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª PreTrainedModelã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“å®ç°çš„æ‰€æœ‰æ¨¡å‹çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L1497)

```py
( pixel_values: FloatTensor pixel_mask: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.models.detr.modeling_detr.DetrObjectDetectionOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰â€”åƒç´ å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœæä¾›å¡«å……ï¼Œåˆ™å°†å¿½ç•¥å¡«å……ã€‚

    åƒç´ å€¼å¯ä»¥ä½¿ç”¨ AutoImageProcessor è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… DetrImageProcessor.`call`()ã€‚

+   `pixel_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, height, width)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨äºé¿å…åœ¨å¡«å……åƒç´ å€¼ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š

    +   1 è¡¨ç¤ºçœŸå®åƒç´ ï¼ˆå³`æœªå±è”½`ï¼‰ï¼Œ

    +   0 è¡¨ç¤ºå¡«å……åƒç´ ï¼ˆå³`å±è”½`ï¼‰ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ

+   `decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`, *optional*) â€” é»˜è®¤æƒ…å†µä¸‹ä¸ä½¿ç”¨ã€‚å¯ç”¨äºå±è”½å¯¹è±¡æŸ¥è¯¢ã€‚

+   `encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” å…ƒç»„ç”±(`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)ç»„æˆï¼Œ`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*optional*)æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’å›¾åƒçš„æ‰å¹³åŒ–ç‰¹å¾å›¾ï¼ˆéª¨å¹²ç½‘ç»œ+æŠ•å½±å±‚çš„è¾“å‡ºï¼‰ï¼Œè€Œä¸æ˜¯ä¼ é€’æ‰å¹³åŒ–è¡¨ç¤ºã€‚

+   `decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ç”¨é›¶å¼ é‡åˆå§‹åŒ–æŸ¥è¯¢ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› ModelOutput è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels` (`List[Dict]` of len `(batch_size,)`, *optional*) â€” ç”¨äºè®¡ç®—äºŒéƒ¨åŒ¹é…æŸå¤±çš„æ ‡ç­¾ã€‚å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸è‡³å°‘åŒ…å«ä»¥ä¸‹ 2 ä¸ªé”®ï¼š'class_labels'å’Œ'boxes'ï¼ˆåˆ†åˆ«æ˜¯æ‰¹å¤„ç†ä¸­å›¾åƒçš„ç±»åˆ«æ ‡ç­¾å’Œè¾¹ç•Œæ¡†ï¼‰ã€‚ç±»åˆ«æ ‡ç­¾æœ¬èº«åº”è¯¥æ˜¯é•¿åº¦ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†æ•°é‡,)`çš„`torch.LongTensor`ï¼Œè€Œè¾¹ç•Œæ¡†åº”è¯¥æ˜¯å½¢çŠ¶ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†æ•°é‡, 4)`çš„`torch.FloatTensor`ã€‚

è¿”å›

transformers.models.detr.modeling_detr.DetrObjectDetectionOutput æˆ– `tuple(torch.FloatTensor)`

transformers.models.detr.modeling_detr.DetrObjectDetectionOutput æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œè¿™å–å†³äºé…ç½®ï¼ˆDetrConfigï¼‰å’Œè¾“å…¥ã€‚

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` are provided)) â€” ä½œä¸ºç±»åˆ«é¢„æµ‹çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆäº¤å‰ç†µï¼‰å’Œè¾¹ç•Œæ¡†æŸå¤±çš„çº¿æ€§ç»„åˆçš„æ€»æŸå¤±ã€‚åè€…è¢«å®šä¹‰ä¸º L1 æŸå¤±å’Œå¹¿ä¹‰å°ºåº¦ä¸å˜ IoU æŸå¤±çš„çº¿æ€§ç»„åˆã€‚

+   `loss_dict` (`Dict`, *optional*) â€” åŒ…å«å„ä¸ªæŸå¤±çš„å­—å…¸ã€‚ç”¨äºè®°å½•æ—¥å¿—ã€‚

+   `logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes + 1)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†ç±» logitsï¼ˆåŒ…æ‹¬æ— å¯¹è±¡ï¼‰ã€‚

+   `pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„å½’ä¸€åŒ–æ¡†åæ ‡ï¼Œè¡¨ç¤ºä¸ºï¼ˆä¸­å¿ƒ _xï¼Œä¸­å¿ƒ _yï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰ã€‚è¿™äº›å€¼åœ¨[0, 1]èŒƒå›´å†…å½’ä¸€åŒ–ï¼Œç›¸å¯¹äºæ‰¹å¤„ç†ä¸­æ¯ä¸ªå•ç‹¬å›¾åƒçš„å¤§å°ï¼ˆå¿½ç•¥å¯èƒ½çš„å¡«å……ï¼‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ post_process_object_detection()æ¥æ£€ç´¢æœªå½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†ã€‚

+   `auxiliary_outputs` (`list[Dict]`, *optional*) â€” å¯é€‰ï¼Œä»…åœ¨æ¿€æ´»è¾…åŠ©æŸå¤±ï¼ˆå³`config.auxiliary_loss`è®¾ç½®ä¸º`True`ï¼‰å¹¶æä¾›æ ‡ç­¾æ—¶è¿”å›ã€‚å®ƒæ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªè§£ç å™¨å±‚çš„ä¸Šè¿°ä¸¤ä¸ªé”®ï¼ˆ`logits`å’Œ`pred_boxes`ï¼‰çš„å­—å…¸åˆ—è¡¨ã€‚

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” è§£ç å™¨çš„éšè—çŠ¶æ€å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ªï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ã€‚æ¯å±‚è§£ç å™¨çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ªï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ªï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” ç¼–ç å™¨çš„éšè—çŠ¶æ€å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ªï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ã€‚æ¯å±‚ç¼–ç å™¨çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡å…ƒç»„ï¼Œæ¯å±‚ä¸€ä¸ªï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

DetrForObjectDetection çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤ä¹‹åè°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, DetrForObjectDetection
>>> import torch
>>> from PIL import Image
>>> import requests

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/detr-resnet-50")
>>> model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")

>>> inputs = image_processor(images=image, return_tensors="pt")
>>> outputs = model(**inputs)

>>> # convert outputs (bounding boxes and class logits) to Pascal VOC format (xmin, ymin, xmax, ymax)
>>> target_sizes = torch.tensor([image.size[::-1]])
>>> results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[
...     0
... ]

>>> for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
...     box = [round(i, 2) for i in box.tolist()]
...     print(
...         f"Detected {model.config.id2label[label.item()]} with confidence "
...         f"{round(score.item(), 3)} at location {box}"
...     )
Detected remote with confidence 0.998 at location [40.16, 70.81, 175.55, 117.98]
Detected remote with confidence 0.996 at location [333.24, 72.55, 368.33, 187.66]
Detected couch with confidence 0.995 at location [-0.02, 1.15, 639.73, 473.76]
Detected cat with confidence 0.999 at location [13.24, 52.05, 314.02, 470.93]
Detected cat with confidence 0.999 at location [345.4, 23.85, 640.37, 368.72]
```

## DetrForSegmentation

### `class transformers.DetrForSegmentation`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L1637)

```py
( config: DetrConfig )
```

å‚æ•°

+   `config` (DetrConfig) â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

DETR æ¨¡å‹ï¼ˆç”±éª¨å¹²å’Œç¼–ç å™¨-è§£ç å™¨ Transformer ç»„æˆï¼‰ï¼Œé¡¶éƒ¨å¸¦æœ‰åˆ†å‰²å¤´ï¼Œç”¨äºè¯¸å¦‚ COCO å…¨æ™¯ç­‰ä»»åŠ¡ã€‚

æ­¤æ¨¡å‹ç»§æ‰¿è‡ª PreTrainedModelã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼Œè°ƒæ•´è¾“å…¥åµŒå…¥å¤§å°ï¼Œä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹è¿˜æ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/detr/modeling_detr.py#L1667)

```py
( pixel_values: FloatTensor pixel_mask: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.models.detr.modeling_detr.DetrSegmentationOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰â€” åƒç´ å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚

    å¯ä»¥ä½¿ç”¨ AutoImageProcessor è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… DetrImageProcessor.`call`()ã€‚

+   `pixel_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, height, width)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¿å…åœ¨å¡«å……åƒç´ å€¼ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é€‰æ‹©çš„æ©ç å€¼åœ¨`[0, 1]`ä¸­ï¼š

    +   å¯¹äºçœŸå®çš„åƒç´ ï¼ˆå³`æœªè¢«é®ç½©`ï¼‰ï¼Œ

    +   å¯¹äºå¡«å……åƒç´ ï¼ˆå³`é®ç½©`ï¼‰çš„åƒç´ ä¸º 0ã€‚

    ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›é®ç½©ï¼Ÿ

+   `decoder_attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_queries)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é»˜è®¤æƒ…å†µä¸‹ä¸ä½¿ç”¨ã€‚å¯ç”¨äºå±è”½å¯¹è±¡æŸ¥è¯¢ã€‚

+   `encoder_outputs`ï¼ˆ`tuple(tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼‰â€” å…ƒç»„åŒ…æ‹¬ï¼ˆ`last_hidden_state`ï¼Œ*å¯é€‰*ï¼š`hidden_states`ï¼Œ*å¯é€‰*ï¼š`attentions`ï¼‰`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚

+   `inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’å›¾åƒçš„æ‰å¹³ç‰¹å¾å›¾ï¼ˆéª¨å¹²+æŠ•å½±å±‚çš„è¾“å‡ºï¼‰è€Œä¸æ˜¯ä¼ é€’å®ƒã€‚

+   `decoder_inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_queries, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºæ¥åˆå§‹åŒ–æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ä½¿ç”¨é›¶å¼ é‡ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å› ModelOutput è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels`ï¼ˆé•¿åº¦ä¸º`(batch_size,)`çš„`List[Dict]`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—äºŒéƒ¨åŒ¹é…æŸå¤±ã€DICE/F-1 æŸå¤±å’Œ Focal æŸå¤±çš„æ ‡ç­¾ã€‚å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸è‡³å°‘åŒ…å«ä»¥ä¸‹ 3 ä¸ªé”®ï¼šâ€˜class_labelsâ€™ã€â€˜boxesâ€™å’Œâ€˜masksâ€™ï¼ˆåˆ†åˆ«æ˜¯æ‰¹æ¬¡ä¸­å›¾åƒçš„ç±»æ ‡ç­¾ã€è¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç ï¼‰ã€‚ç±»æ ‡ç­¾æœ¬èº«åº”è¯¥æ˜¯é•¿åº¦ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†çš„æ•°é‡,)`çš„`torch.LongTensor`ï¼Œè¾¹ç•Œæ¡†æ˜¯å½¢çŠ¶ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†çš„æ•°é‡, 4)`çš„`torch.FloatTensor`ï¼Œæ©ç æ˜¯å½¢çŠ¶ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†çš„æ•°é‡, height, width)`çš„`torch.FloatTensor`ã€‚

è¿”å›

transformers.models.detr.modeling_detr.DetrSegmentationOutput æˆ–`tuple(torch.FloatTensor)`

ä¸€ä¸ª transformers.models.detr.modeling_detr.DetrSegmentationOutput æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆDetrConfigï¼‰å’Œè¾“å…¥ã€‚

+   `loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`ï¼Œ*optional*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰ â€” æ€»æŸå¤±ï¼Œä½œä¸ºè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆäº¤å‰ç†µï¼‰å’Œè¾¹ç•Œæ¡†æŸå¤±çš„çº¿æ€§ç»„åˆã€‚åè€…è¢«å®šä¹‰ä¸º L1 æŸå¤±å’Œå¹¿ä¹‰å°ºåº¦ä¸å˜ IoU æŸå¤±çš„çº¿æ€§ç»„åˆã€‚

+   `loss_dict` (`Dict`ï¼Œ*optional*) â€” åŒ…å«å„ä¸ªæŸå¤±çš„å­—å…¸ã€‚ç”¨äºè®°å½•ã€‚

+   `logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_queries, num_classes + 1)`ï¼‰ â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†ç±» logitsï¼ˆåŒ…æ‹¬æ— å¯¹è±¡ï¼‰ã€‚

+   `pred_boxes` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_queries, 4)`ï¼‰ â€” æ‰€æœ‰æŸ¥è¯¢çš„å½’ä¸€åŒ–æ¡†åæ ‡ï¼Œè¡¨ç¤ºä¸ºï¼ˆä¸­å¿ƒ _xï¼Œä¸­å¿ƒ _yï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰ã€‚è¿™äº›å€¼åœ¨[0, 1]èŒƒå›´å†…å½’ä¸€åŒ–ï¼Œç›¸å¯¹äºæ‰¹å¤„ç†ä¸­æ¯ä¸ªå•ç‹¬å›¾åƒçš„å¤§å°ï¼ˆå¿½ç•¥å¯èƒ½çš„å¡«å……ï¼‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ post_process_object_detection()æ¥æ£€ç´¢æœªå½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†ã€‚

+   `pred_masks` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_queries, height/4, width/4)`ï¼‰ â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†å‰²æ©æ¨¡ logitsã€‚å¦è¯·å‚é˜… post_process_semantic_segmentation()æˆ– post_process_instance_segmentation()post_process_panoptic_segmentation()åˆ†åˆ«è¯„ä¼°è¯­ä¹‰ã€å®ä¾‹å’Œå…¨æ™¯åˆ†å‰²æ©æ¨¡ã€‚

+   `auxiliary_outputs` (`list[Dict]`, *optional*) â€” å½“è¾…åŠ©æŸå¤±è¢«æ¿€æ´»æ—¶ï¼ˆå³`config.auxiliary_loss`è®¾ç½®ä¸º`True`ï¼‰å¹¶ä¸”æä¾›äº†æ ‡ç­¾æ—¶æ‰è¿”å›ã€‚è¿™æ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªè§£ç å™¨å±‚çš„ä¸¤ä¸ªä¸Šè¿°é”®ï¼ˆ`logits`å’Œ`pred_boxes`ï¼‰çš„å­—å…¸åˆ—è¡¨ã€‚

+   `last_hidden_state` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*optional*) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚è§£ç å™¨åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚ç¼–ç å™¨æ¯ä¸€å±‚çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ› softmax ä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

DetrForSegmentation çš„å‰å‘æ–¹æ³•é‡å†™äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import io
>>> import requests
>>> from PIL import Image
>>> import torch
>>> import numpy

>>> from transformers import AutoImageProcessor, DetrForSegmentation
>>> from transformers.image_transforms import rgb_to_id

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/detr-resnet-50-panoptic")
>>> model = DetrForSegmentation.from_pretrained("facebook/detr-resnet-50-panoptic")

>>> # prepare image for the model
>>> inputs = image_processor(images=image, return_tensors="pt")

>>> # forward pass
>>> outputs = model(**inputs)

>>> # Use the `post_process_panoptic_segmentation` method of the `image_processor` to retrieve post-processed panoptic segmentation maps
>>> # Segmentation results are returned as a list of dictionaries
>>> result = image_processor.post_process_panoptic_segmentation(outputs, target_sizes=[(300, 500)])

>>> # A tensor of shape (height, width) where each value denotes a segment id, filled with -1 if no segment is found
>>> panoptic_seg = result[0]["segmentation"]
>>> # Get prediction score and segment_id to class_id mapping of each segment
>>> panoptic_segments_info = result[0]["segments_info"]
```
