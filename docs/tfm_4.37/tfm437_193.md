# MADLAD-400

> 原文链接：[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/madlad-400`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/madlad-400)

## 概述

MADLAD-400 模型在论文 MADLAD-400: A Multilingual And Document-Level Large Audited Dataset 中发布。

论文摘要如下：

我们介绍了 MADLAD-400，这是一个基于 CommonCrawl 的手动审核的通用领域 3T 令牌单语数据集，涵盖了 419 种语言。我们讨论了自我审核 MADLAD-400 所揭示的限制，以及数据审核在数据集创建过程中的作用。然后，我们使用公开可用的数据训练并发布了一个覆盖 450 多种语言、共计 2500 亿令牌的 10.7B 参数多语言机器翻译模型，并发现它与规模更大的模型竞争力相当，并在不同领域报告了结果。此外，我们训练了一个 8B 参数的语言模型，并评估了少样本翻译的结果。我们将基线模型提供给研究社区。

此模型由[Juarez Bochi](https://huggingface.co/jbochi)添加。原始检查点可以在[这里](https://github.com/google-research/google-research/tree/master/madlad_400)找到。

这是一个支持许多低资源语言的机器翻译模型，并且与规模更大的模型具有竞争力。

可以直接使用 MADLAD-400 权重而无需微调模型：

```py
>>> from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

>>> model = AutoModelForSeq2SeqLM.from_pretrained("google/madlad400-3b-mt")
>>> tokenizer = AutoTokenizer.from_pretrained("google/madlad400-3b-mt")

>>> inputs = tokenizer("<2pt> I love pizza!", return_tensors="pt")
>>> outputs = model.generate(**inputs)
>>> print(tokenizer.batch_decode(outputs, skip_special_tokens=True))
['Eu amo pizza!']
```

Google 发布了以下变体：

+   [google/madlad400-3b-mt](https://huggingface.co/google/madlad400-3b-mt)

+   [google/madlad400-7b-mt](https://huggingface.co/google/madlad400-7b-mt)

+   [google/madlad400-7b-mt-bt](https://huggingface.co/google/madlad400-7b-mt-bt)

+   [google/madlad400-10b-mt](https://huggingface.co/google/madlad400-10b-mt)

原始检查点可以在[这里](https://github.com/google-research/google-research/tree/master/madlad_400)找到。

有关所有 API 参考、代码示例和笔记本，请参考 T5 的文档页面。有关 MADLAD-400 的训练和评估的更多详细信息，请参考模型卡片。
