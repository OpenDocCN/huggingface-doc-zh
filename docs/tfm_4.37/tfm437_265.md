# DiT

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/dit`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/dit)

## 概述

DiT 是由 Junlong Li、Yiheng Xu、Tengchao Lv、Lei Cui、Cha Zhang、Furu Wei 在[DiT: Self-supervised Pre-training for Document Image Transformer](https://arxiv.org/abs/2203.02378)中提出的。DiT 将 BEiT（图像变换器的 BERT 预训练）的自监督目标应用于 4200 万个文档图像，从而在包括以下任务在内的任务上取得了最先进的结果：

+   文档图像分类：[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)数据集（包含 40 万张属于 16 个类别之一的图像）。

+   文档布局分析：[PubLayNet](https://github.com/ibm-aur-nlp/PubLayNet)数据集（由自动解析 PubMed XML 文件构建的超过 36 万个文档图像的集合）。

+   表格检测：[ICDAR 2019 cTDaR](https://github.com/cndplab-founder/ICDAR2019_cTDaR)数据集（包含 600 个训练图像和 240 个测试图像）。

论文摘要如下：

*最近，图像变换器在自然图像理解方面取得了显著进展，无论是使用监督（ViT，DeiT 等）还是自监督（BEiT，MAE 等）的预训练技术。在本文中，我们提出了 DiT，这是一个自监督预训练的文档图像变换器模型，使用大规模未标记的文本图像进行文档 AI 任务，这是必不可少的，因为由于缺乏人工标记的文档图像，不存在任何监督对应物。我们将 DiT 作为各种基于视觉的文档 AI 任务的骨干网络，包括文档图像分类、文档布局分析以及表格检测。实验结果表明，自监督预训练的 DiT 模型在这些下游任务上取得了新的最先进结果，例如文档图像分类（91.11 → 92.69）、文档布局分析（91.0 → 94.9）和表格检测（94.23 → 96.55）。*

![drawing](img/bbda80fb2e34234d199a63b7903bf9de.png) 方法概述。摘自[原始论文](https://arxiv.org/abs/2203.02378)。

这个模型是由[nielsr](https://huggingface.co/nielsr)贡献的。原始代码可以在[这里](https://github.com/microsoft/unilm/tree/master/dit)找到。

## 使用提示

可以直接使用 AutoModel API 中的 DiT 权重：

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("microsoft/dit-base")
```

这将加载在遮蔽图像建模上预训练的模型。请注意，这不会包括顶部的语言建模头，用于预测视觉标记。

要包含头部，可以将权重加载到`BeitForMaskedImageModeling`模型中，如下所示：

```py
from transformers import BeitForMaskedImageModeling

model = BeitForMaskedImageModeling.from_pretrained("microsoft/dit-base")
```

您还可以从[hub](https://huggingface.co/models?other=dit)加载一个经过微调的模型，如下所示：

```py
from transformers import AutoModelForImageClassification

model = AutoModelForImageClassification.from_pretrained("microsoft/dit-base-finetuned-rvlcdip")
```

这个特定的检查点在[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)上进行了微调，这是文档图像分类的重要基准。一个展示文档图像分类推理的笔记本可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DiT/Inference_with_DiT_(Document_Image_Transformer)_for_document_image_classification.ipynb)找到。

## 资源

Hugging Face 官方和社区（🌎表示）资源列表，帮助您开始使用 DiT。

图像分类

+   BeitForImageClassification 由这个[示例脚本](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)和[笔记本](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)支持。

如果您有兴趣提交一个资源以包含在这里，请随时打开一个 Pull Request，我们将对其进行审查！资源应该理想地展示一些新东西，而不是重复现有资源。

由于 DiT 的架构与 BEiT 相当，因此可以参考 BEiT 的文档页面 获取所有提示、代码示例和笔记本。
