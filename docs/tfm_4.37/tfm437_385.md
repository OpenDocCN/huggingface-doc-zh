# PatchTSMixer

> 原文链接：[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/patchtsmixer`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/patchtsmixer)

## 概述

PatchTSMixer 模型是由 Vijay Ekambaram、Arindam Jati、Nam Nguyen、Phanwadee Sinthong 和 Jayant Kalagnanam 在[TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting](https://arxiv.org/pdf/2306.09364.pdf)中提出的。

PatchTSMixer 是基于 MLP-Mixer 架构的轻量级时间序列建模方法。在这个 HuggingFace 实现中，我们提供了 PatchTSMixer 的功能，以轻松促进跨补丁、通道和隐藏特征的轻量级混合，以实现有效的多变量时间序列建模。它还支持各种注意机制，从简单的门控注意力到更复杂的自注意力块，可以根据需要进行定制。该模型可以进行预训练，随后用于各种下游任务，如预测、分类和回归。

论文摘要如下：

*TSMixer 是一种轻量级的神经架构，专门由多层感知器（MLP）模块组成，设计用于修补时间序列上的多变量预测和表示学习。我们的模型受到 MLP-Mixer 模型在计算机视觉中的成功启发。我们展示了将视觉 MLP-Mixer 调整为时间序列时涉及的挑战，并引入了经验验证的组件来提高准确性。这包括一种新颖的设计范式，将在线协调头附加到 MLP-Mixer 骨干上，以明确地建模时间序列的属性，如层次结构和通道相关性。我们还提出了一种混合通道建模方法，以有效处理嘈杂的通道交互和跨多样数据集的泛化，这是现有补丁通道混合方法中的一个常见挑战。此外，在骨干中引入了一个简单的门控注意机制，以优先处理重要特征。通过整合这些轻量级组件，我们显著增强了简单 MLP 结构的学习能力，优于具有最小计算使用的复杂 Transformer 模型。此外，TSMixer 的模块化设计使其与监督和掩蔽自监督学习方法兼容，使其成为时间序列基础模型的有前途的构建模块。TSMixer 在预测方面的表现明显优于最先进的 MLP 和 Transformer 模型，差距为 8-60%。它还在内存和运行时间上优于最新的强大基准 Patch-Transformer 模型（提高了 1-2%），同时显著减少了内存和运行时间（2-3 倍）。*

该模型由[ajati](https://huggingface.co/ajati), [vijaye12](https://huggingface.co/vijaye12), [gsinthong](https://huggingface.co/gsinthong), [namctin](https://huggingface.co/namctin), [wmgifford](https://huggingface.co/wmgifford), [kashif](https://huggingface.co/kashif)贡献。

## 示例用法

```py

from transformers import PatchTSMixerConfig, PatchTSMixerForPrediction
from transformers import Trainer, TrainingArguments,

config = PatchTSMixerConfig(context_length = 512, prediction_length = 96)
model = PatchTSMixerForPrediction(config)
trainer = Trainer(model=model, args=training_args, 
            train_dataset=train_dataset,
            eval_dataset=valid_dataset)
trainer.train()
results = trainer.evaluate(test_dataset)
```

## 使用提示

该模型还可用于时间序列分类和时间序列回归。请查看相应的 PatchTSMixerForTimeSeriesClassification 和 PatchTSMixerForRegression 类。

## PatchTSMixerConfig

### `class transformers.PatchTSMixerConfig`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/configuration_patchtsmixer.py#L30)

```py
( context_length: int = 32 patch_len: int = 8 num_input_channels: int = 1 patch_stride: int = 8 num_parallel_samples: int = 100 d_model: int = 8 expansion_factor: int = 2 num_layers: int = 3 dropout: float = 0.2 mode: str = 'common_channel' gated_attn: bool = True norm_mlp: str = 'LayerNorm' self_attn: bool = False self_attn_heads: int = 1 use_positional_encoding: bool = False positional_encoding_type: str = 'sincos' scaling: Union = 'std' loss: str = 'mse' init_std: float = 0.02 post_init: bool = False norm_eps: float = 1e-05 mask_type: str = 'random' random_mask_ratio: float = 0.5 num_forecast_mask_patches: Union = [2] mask_value: int = 0 masked_loss: bool = True channel_consistent_masking: bool = True unmasked_channel_indices: Optional = None head_dropout: float = 0.2 distribution_output: str = 'student_t' prediction_length: int = 16 prediction_channel_indices: list = None num_targets: int = 3 output_range: list = None head_aggregation: str = 'max_pool' **kwargs )
```

参数

+   `context_length` (`int`, *可选*, 默认为 32) — 输入序列的上下文/历史长度。

+   `patch_len` (`int`, *可选*, 默认为 8) — 输入序列的补丁长度。

+   `num_input_channels` (`int`, *可选*, 默认为 1) — 输入变量的数量。对于单变量，将其设置为 1。

+   `patch_stride` (`int`, *optional*, 默认为 8) — 确定两个连续补丁之间的重叠。如果我们想要非重叠的补丁，则将其设置为 patch_length（或更大）。

+   `num_parallel_samples` (`int`, *optional*, 默认为 100) — 用于概率预测并行生成的样本数量。

+   `d_model` (`int`, *optional*, 默认为 8) — 模型的隐藏维度。建议将其设置为 patch_length 的倍数（即 patch_len 的 2-5 倍）。较大的值表示更复杂的模型。

+   `expansion_factor` (`int`, *optional*, 默认为 2) — 在 MLP 内部使用的扩展因子。推荐范围为 2-5。较大的值表示更复杂的模型。

+   `num_layers` (`int`, *optional*, 默认为 3) — 要使用的层数。推荐范围为 3-15。较大的值表示更复杂的模型。

+   `dropout` (`float`, *optional*, 默认为 0.2) — `PatchTSMixer`主干的丢失概率。推荐范围为 0.2-0.7

+   `mode` (`str`, *optional*, 默认为`"common_channel"`) — Mixer 模式。确定如何处理通道。允许的值：`"common_channel"`、“mix_channel”。在`"common_channel"`模式中，我们遵循独立于通道的建模，没有显式的通道混合。通道混合通过跨通道共享权重以隐式方式发生。（首选第一种方法）在“mix_channel”模式中，我们遇到显式的通道混合以及补丁和特征混合。（当通道相关性对模型非常重要时，首选方法）

+   `gated_attn` (`bool`, *optional*, 默认为`True`) — 启用门控注意力。

+   `norm_mlp` (`str`, *optional*, 默认为`"LayerNorm"`) — 归一化层（BatchNorm 或 LayerNorm）。

+   `self_attn` (`bool`, *optional*, 默认为`False`) — 在补丁之间启用小型自注意力。当 Vanilla PatchTSMixer 的门控注意力的输出不理想时，可以启用此功能。启用此功能会导致显式的成对注意力和跨补丁建模。

+   `self_attn_heads` (`int`, *optional*, 默认为 1) — 自注意力头的数量。仅当`self_attn`设置为`True`时才有效。

+   `use_positional_encoding` (`bool`, *optional*, 默认为`False`) — 启用小型自注意力层的位置嵌入使用。仅当`self_attn`设置为`True`时才有效。

+   `positional_encoding_type` (`str`, *optional*, 默认为`"sincos"`) — 位置编码。支持选项`"random"`和`"sincos"`。仅当`use_positional_encoding`设置为`True`时才有效。

+   `scaling` (`string`或`bool`, *optional*, 默认为`"std"`) — 是否通过“mean”缩放器、`"std"`缩放器或如果为`None`则不缩放输入目标。如果为`True`，则缩放器设置为“mean”。

+   `loss` (`string`, *optional*, 默认为`"mse"`) — 与`distribution_output`头对应的模型的损失函数。对于参数分布，它是负对数似然（“nll”），对于点估计，它是均方误差`"mse"`。

+   `init_std` (`float`, *optional*, 默认为 0.02) — 截断正态权重初始化分布的标准差。

+   `post_init` (`bool`, *optional*, 默认为`False`) — 是否使用`transformers`库中的自定义权重初始化，或者使用`PyTorch`中的默认初始化。将其设置为`False`执行`PyTorch`权重初始化。

+   `norm_eps` (`float`, *optional*, 默认为 1e-05) — 用于归一化的分母的数值稳定性的值。

+   `mask_type` (`str`, *optional*, 默认为`"random"`) — 用于掩码预训练模式的掩码类型。允许的值为`"random"`、“forecast”。在随机掩码中，点被随机掩盖。在预测掩码中，点被朝向末尾掩盖。

+   `random_mask_ratio` (`float`, *optional*, 默认为 0.5) — 当`mask_type`为`random`时使用的掩码比例。较高的值表示更多的掩码。

+   `num_forecast_mask_patches` (`int` or `list`, *optional*, defaults to `[2]`) — 每个批次样本末尾要屏蔽的补丁数量。如果是整数，则批次中的所有样本将具有相同数量的屏蔽补丁。如果是列表，则批次中的样本将随机屏蔽列表中定义的数字。此参数仅用于预测预训练。

+   `mask_value` (`float`, *optional*, defaults to `0.0`) — 要使用的屏蔽值。

+   `masked_loss` (`bool`, *optional*, defaults to `True`) — 是否仅在屏蔽部分计算预训练损失，还是在整个输出上计算。

+   `channel_consistent_masking` (`bool`, *optional*, defaults to `True`) — 当为 True 时，屏蔽将在时间序列的所有通道上相同。否则，屏蔽位置将在通道之间变化。

+   `unmasked_channel_indices` (`list`, *optional*) — 预训练期间未屏蔽的通道。

+   `head_dropout` (`float`, *optional*, defaults to 0.2) — `PatchTSMixer` 头部的 dropout 概率。

+   `distribution_output` (`string`, *optional*, defaults to `"student_t"`) — 当损失为“nll”时，模型的分布发射头。可以是`"student_t"`、“normal”或“negative_binomial”。

+   `prediction_length` (`int`, *optional*, defaults to 16) — 用于预测任务的预测时间步数。也称为预测视野。

+   `prediction_channel_indices` (`list`, *optional*) — 要预测的通道索引列表。如果为 None，则预测所有通道。目标数据预期具有所有通道，我们在损失计算之前明确过滤预测和目标中的通道。

+   `num_targets` (`int`, *optional*, defaults to 3) — 回归任务的目标数量（回归变量的维度）。

+   `output_range` (`list`, *optional*) — 用于限制回归任务的输出范围。默认为 None。

+   `head_aggregation` (`str`, *optional*, defaults to `"max_pool"`) — 用于分类或回归任务的聚合模式。允许的值为 `None`、"use_last"、"max_pool"、"avg_pool"。

这是一个配置类，用于存储 PatchTSMixerModel 的配置。根据指定的参数实例化一个 PatchTSMixer 模型，定义模型架构。使用默认值实例化配置将产生与 PatchTSMixer [ibm/patchtsmixer-etth1-pretrain](https://huggingface.co/ibm/patchtsmixer-etth1-pretrain) 架构类似的配置。

配置对象继承自 PretrainedConfig，可用于控制模型输出。阅读 PretrainedConfig 的文档以获取更多信息。

示例：

```py
>>> from transformers import PatchTSMixerConfig, PatchTSMixerModel

>>> # Initializing a default PatchTSMixer configuration
>>> configuration = PatchTSMixerConfig()

>>> # Randomly initializing a model (with random weights) from the configuration
>>> model = PatchTSMixerModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## PatchTSMixerModel

### `class transformers.PatchTSMixerModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1299)

```py
( config: PatchTSMixerConfig mask_input: bool = False )
```

参数

+   `config` (PatchTSMixerConfig) — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 from_pretrained() 方法以加载模型权重。

+   `mask_input` (`bool`, *optional*, defaults to `False`) — 如果为 True，则启用屏蔽。否则为 False。

用于时间序列预测的 PatchTSMixer 模型。

此模型继承自 PreTrainedModel。检查超类文档，了解库为其所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。

此模型也是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取与一般用法和行为相关的所有事项。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1327)

```py
( past_values: Tensor observed_mask: Optional = None output_hidden_states: Optional = False return_dict: Optional = None ) → export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerModelOutput or tuple(torch.FloatTensor)
```

参数

+   `past_values` (`torch.FloatTensor`，形状为`(batch_size, seq_length, num_input_channels)`) — 时间序列的上下文值。对于预训练任务，这表示要预测掩码部分的输入时间序列。对于预测任务，这表示历史/过去的时间序列值。同样，对于分类或回归任务，它表示时间序列的适当上下文值。

    对于单变量时间序列，`num_input_channels`维度应为 1。对于多变量时间序列，它大于 1。

+   `output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。

+   `return_dict` (`bool`, *可选*) — 是否返回一个 ModelOutput 而不是一个普通元组。

+   `observed_mask` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, num_input_channels)`，*可选*) — 布尔蒙版，指示哪些`past_values`是观察到的，哪些是缺失的。蒙版值选择在`[0, 1]`之间：

    +   1 表示`observed`的值，

    +   0 表示`missing`的值（即被零替换的 NaN）。

返回

`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerModelOutput`或`tuple(torch.FloatTensor)`

一个`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerModelOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（PatchTSMixerConfig）和输入的各种元素。

+   `last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels, num_patches, d_model)`) — 模型最后一层的隐藏状态。

+   `hidden_states` (`tuple(torch.FloatTensor)`，*可选*) — 模型在每一层输出的隐藏状态。

+   `patch_input` (`torch.FloatTensor`，形状为`(batch_size, num_channels, num_patches, patch_length)`) — 输入到模型的补丁化数据。

+   `mask:` (`torch.FloatTensor`，形状为`(batch_size, num_channels, num_patches)`，*可选*) — 布尔张量，指示掩码补丁中的 True 和其他地方的 False。

+   `loc:` (`torch.FloatTensor`，形状为`(batch_size, 1, num_channels)`，*可选*) — 给出每个通道上下文窗口的均值。如果启用了 revin，则用于模型外的 revin 反归一化。

+   `scale:` (`torch.FloatTensor`，形状为`(batch_size, 1, num_channels)`，*可选*) — 给出每个通道上下文窗口的标准差。如果启用了 revin，则用于模型外的 revin 反归一化。

PatchTSMixerModel 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。

## PatchTSMixerForPrediction

### `class transformers.PatchTSMixerForPrediction`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1597)

```py
( config: PatchTSMixerConfig )
```

参数

+   `config` (`PatchTSMixerConfig`, *required*) — 配置。

用于预测应用的 `PatchTSMixer`。

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1641)

```py
( past_values: Tensor observed_mask: Optional = None future_values: Optional = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) → export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPredictionOutput or tuple(torch.FloatTensor)
```

参数

+   `past_values` (`torch.FloatTensor` of shape `(batch_size, seq_length, num_input_channels)`) — 时间序列的上下文值。对于预训练任务，这表示用于预测被屏蔽部分的输入时间序列。对于预测任务，这表示历史/过去的时间序列值。同样，对于分类或回归任务，它表示时间序列的适当上下文值。

    对于单变量时间序列，`num_input_channels` 维度应为 1。对于多变量时间序列，它大于 1。

+   `output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。

+   `return_dict` (`bool`, *optional*) — 是否返回 ModelOutput 而不是普通元组。

+   `observed_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length, num_input_channels)`, *optional*) — 布尔掩码，指示哪些 `past_values` 是观察到的，哪些是缺失的。掩码值选在 `[0, 1]`：

    +   对于 `observed` 的值为 1，

    +   对于 `missing` 的值为 0（即被零替换的 NaN）。

+   `future_values` (`torch.FloatTensor` of shape `(batch_size, target_len, num_input_channels)` 用于预测， — `(batch_size, num_targets)` 用于回归，或 `(batch_size,)` 用于分类， *optional*): 时间序列的目标值，作为模型的标签。`future_values` 是训练期间 Transformer 需要的，以学习在给定 `past_values` 时输出。请注意，这对于预训练任务并非必需。

    对于预测任务，形状为 `(batch_size, target_len, num_input_channels)`。即使我们想通过在 `prediction_channel_indices` 参数中设置索引来仅预测特定通道，也要传递带有所有通道的目标数据，因为在损失计算之前，预测和目标的通道过滤将手动应用。

+   `return_loss` (`bool`, *optional*) — 是否在 `forward` 调用中返回损失。

返回

`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPredictionOutput` 或 `tuple(torch.FloatTensor)`

一个 `transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPredictionOutput` 或 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False` 时）包含根据配置（PatchTSMixerConfig）和输入的不同元素。

+   `prediction_outputs` (`torch.FloatTensor` of shape `(batch_size, prediction_length, num_input_channels)`) — 预测头部的预测输出。

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_input_channels, num_patches, d_model)`) — 通过头部之前的主干嵌入。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*) — 模型在每一层输出处的隐藏状态，加上可选的初始嵌入输出。

+   `loss` (*optional*, 当提供 `y` 时返回，形状为 `()` 的 `torch.FloatTensor`) — 总损失。

+   `loc` (`torch.FloatTensor`, *optional* of shape `(batch_size, 1, num_input_channels)`) — 输入均值

+   `scale` (`torch.FloatTensor`, *optional* of shape `(batch_size, 1, num_input_channels)`) — 输入标准差

PatchTSMixerForPrediction 的前向方法，覆盖了 `__call__` 特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行前处理和后处理步骤，而后者会默默地忽略它们。

## PatchTSMixerForTimeSeriesClassification

### `class transformers.PatchTSMixerForTimeSeriesClassification`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1830)

```py
( config: PatchTSMixerConfig )
```

参数

+   `config` (`PatchTSMixerConfig`, *必需*) — 配置。

用于分类应用的`PatchTSMixer`。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1859)

```py
( past_values: Tensor future_values: Tensor = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) → export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForTimeSeriesClassificationOutput or tuple(torch.FloatTensor)
```

参数

+   `past_values` (`torch.FloatTensor` of shape `(batch_size, seq_length, num_input_channels)`) — 时间序列的上下文值。对于预训练任务，这表示要预测掩码部分的输入时间序列。对于预测任务，这表示历史/过去的时间序列值。类似地，对于分类或回归任务，它表示时间序列的适当上下文值。

    对于单变量时间序列，`num_input_channels`维度应为 1。对于多变量时间序列，它大于 1。

+   `output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。

+   `return_dict` (`bool`, *可选*) — 是否返回一个 ModelOutput 而不是一个普通元组。

+   `future_values` (`torch.FloatTensor` of shape `(batch_size, target_len, num_input_channels)` 用于预测，— `(batch_size, num_targets)` 用于回归，或 `(batch_size,)` 用于分类，*可选*): 时间序列的目标值，作为模型的标签。`future_values`是 Transformer 在训练期间需要的，以便学习如何输出，给定`past_values`。请注意，这对于预训练任务并不是必需的。

    对于预测任务，形状为`(batch_size, target_len, num_input_channels)`。即使我们只想通过在`prediction_channel_indices`参数中设置索引来预测特定通道，也要传递带有所有通道的目标数据，因为在计算损失之前，预测和目标的通道过滤将手动应用。

    对于分类任务，形状为`(batch_size,)`。

    对于回归任务，形状为`(batch_size, num_targets)`。

+   `return_loss` (`bool`, *可选*) — 是否在`forward`调用中返回损失。

返回

`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForTimeSeriesClassificationOutput` 或 `tuple(torch.FloatTensor)`

一个`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForTimeSeriesClassificationOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（PatchTSMixerConfig）和输入的各种元素。

+   `prediction_outputs` (`torch.FloatTensor` of shape `(batch_size, num_labels)`) — 分类头部的预测输出。

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_input_channels, num_patches, d_model)`) — 通过头部之前的主干嵌入。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *可选*) — 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。

+   `loss` (*可选*, 当提供`y`时返回, `torch.FloatTensor` of shape `()`) — 总损失。

PatchTSMixerForTimeSeriesClassification 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。

## PatchTSMixerForPretraining

### `class transformers.PatchTSMixerForPretraining`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1415)

```py
( config: PatchTSMixerConfig )
```

参数

+   `config`（`PatchTSMixerConfig`，*必需*）— 配置。

`PatchTSMixer`用于掩码预训练。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L1438)

```py
( past_values: Tensor observed_mask: Optional = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) → export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPreTrainingOutput or tuple(torch.FloatTensor)
```

参数

+   `past_values`（形状为`(batch_size, seq_length, num_input_channels)`的`torch.FloatTensor`）— 时间序列的上下文值。对于预训练任务，这表示要预测掩码部分的输入时间序列。对于预测任务，这表示历史/过去的时间序列值。同样，对于分类或回归任务，它表示时间序列的适当上下文值。

    对于单变量时间序列，`num_input_channels`维度应为 1。对于多变量时间序列，它大于 1。

+   `output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。

+   `return_dict`（`bool`，*可选*）— 是否返回 ModelOutput 而不是普通元组。

+   `observed_mask`（形状为`(batch_size, sequence_length, num_input_channels)`的`torch.FloatTensor`，*可选*）— 布尔掩码，指示哪些`past_values`是观察到的，哪些是缺失的。掩码值选在`[0, 1]`之间：

    +   1 表示`observed`的值，

    +   0 表示`missing`的值（即被零替换的 NaN）。

+   `return_loss`（`bool`，*可选*）— 是否在`forward`调用中返回损失。

返回

`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPreTrainingOutput`或`tuple(torch.FloatTensor)`

一个`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForPreTrainingOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含各种元素，取决于配置（PatchTSMixerConfig）和输入。

+   `prediction_outputs`（形状为`(batch_size, num_input_channels, num_patches, patch_length)`的`torch.FloatTensor`）— 来自预训练头部的预测输出。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*）— 模型在每一层输出的隐藏状态。

+   `last_hidden_state`（形状为`(batch_size, num_input_channels, num_patches, d_model)`的`torch.FloatTensor`）— 通过头部之前的主干嵌入。

+   `loss`（*可选*，在提供`y`时返回，形状为`()`的`torch.FloatTensor`）— 总损失

PatchTSMixerForPretraining 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。

## PatchTSMixerForRegression

### `class transformers.PatchTSMixerForRegression`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L2001)

```py
( config: PatchTSMixerConfig )
```

参数

+   `config`（`PatchTSMixerConfig`，*必需*）— 配置。

`PatchTSMixer`用于回归应用。

#### `forward`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/patchtsmixer/modeling_patchtsmixer.py#L2052)

```py
( past_values: Tensor future_values: Tensor = None output_hidden_states: Optional = False return_loss: bool = True return_dict: Optional = None ) → export const metadata = 'undefined';transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForRegressionOutput or tuple(torch.FloatTensor)
```

参数

+   `past_values`（形状为`(batch_size, seq_length, num_input_channels)`的`torch.FloatTensor`）：时间序列的上下文值。对于预训练任务，这表示要预测掩码部分的输入时间序列。对于预测任务，这表示历史/过去的时间序列值。同样，对于分类或回归任务，它表示时间序列的适当上下文值。

    对于单变量时间序列，`num_input_channels`维度应为 1。对于多变量时间序列，它大于 1。

+   `output_hidden_states`（`bool`，*可选*）：是否返回所有层的隐藏状态。

+   `return_dict`（`bool`，*可选*）：是否返回一个 ModelOutput 而不是一个普通的元组。

+   `future_values`（形状为`(batch_size, target_len, num_input_channels)`的`torch.FloatTensor`用于预测，形状为`(batch_size, num_targets)`用于回归，或形状为`(batch_size,)`用于分类，*可选*）：时间序列的目标值，作为模型的标签。`future_values`是 Transformer 在训练期间需要的，以便学习在给定`past_values`时输出。请注意，这对于预训练任务是不需要的。

    对于一个预测任务，形状应为`(batch_size, target_len, num_input_channels)`。即使我们只想通过在`prediction_channel_indices`参数中设置索引来预测特定通道，也要传递带有所有通道的目标数据，因为在损失计算之前，预测和目标的通道过滤将手动应用。

    对于分类任务，形状为`(batch_size,)`。

    对于回归任务，形状为`(batch_size, num_targets)`。

+   `return_loss`（`bool`，*可选*）：是否在`forward`调用中返回损失。

返回值

`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForRegressionOutput`或`tuple(torch.FloatTensor)`

一个`transformers.models.patchtsmixer.modeling_patchtsmixer.PatchTSMixerForRegressionOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（PatchTSMixerConfig）和输入的不同元素。

+   `prediction_outputs`（形状为`(batch_size, num_targets)`的`torch.FloatTensor`）：回归头部的预测输出。

+   `last_hidden_state`（形状为`(batch_size, num_input_channels, num_patches, d_model)`的`torch.FloatTensor`）：通过头部之前的主干嵌入。

+   `hidden_states`（`tuple(torch.FloatTensor)`，*可选*）：模型在每一层输出的隐藏状态以及可选的初始嵌入输出。

+   `loss`（*可选*，在提供`y`时返回，形状为`()`的`torch.FloatTensor`）：总损失。

PatchTSMixerForRegression 的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
