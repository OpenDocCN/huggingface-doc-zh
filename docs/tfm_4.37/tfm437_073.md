# 多 CPU 高效训练

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/perf_train_cpu_many`](https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_cpu_many)

当在单个 CPU 上训练速度太慢时，我们可以使用多个 CPU。本指南侧重于基于 PyTorch 的 DDP，可以在 bare metal 和 Kubernetes 上有效地启用分布式 CPU 训练。

## Intel® oneCCL 绑定的 PyTorch

[Intel® oneCCL](https://github.com/oneapi-src/oneCCL)（集体通信库）是一个用于实现 allreduce、allgather、alltoall 等集体通信的高效分布式深度学习训练的库。有关 oneCCL 的更多信息，请参考[oneCCL 文档](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html)和[oneCCL 规范](https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html)。

模块`oneccl_bindings_for_pytorch`（在 1.12 版本之前为`torch_ccl`）实现了 PyTorch C10D ProcessGroup API，并且可以作为外部 ProcessGroup 动态加载，目前仅在 Linux 平台上可用。

查看更多关于[oneccl_bind_pt](https://github.com/intel/torch-ccl)的详细信息。

### Intel® oneCCL 绑定的 PyTorch 安装

以下 Python 版本的 Wheel 文件可用：

| 扩展版本 | Python 3.6 | Python 3.7 | Python 3.8 | Python 3.9 | Python 3.10 |
| :-: | :-: | :-: | :-: | :-: | :-: |
| 2.1.0 |  | √ | √ | √ | √ |
| 2.0.0 |  | √ | √ | √ | √ |
| 1.13.0 |  | √ | √ | √ | √ |
| 1.12.100 |  | √ | √ | √ | √ |
| 1.12.0 |  | √ | √ | √ | √ |

请运行`pip list | grep torch`以获取您的`pytorch_version`。

```py
pip install oneccl_bind_pt=={pytorch_version} -f https://developer.intel.com/ipex-whl-stable-cpu
```

其中`{pytorch_version}`应该是您的 PyTorch 版本，例如 2.1.0。查看更多关于[oneccl_bind_pt 安装](https://github.com/intel/torch-ccl)的方法。oneCCL 和 PyTorch 的版本必须匹配。

oneccl_bindings_for_pytorch 1.12.0 预构建的 Wheel 文件与 PyTorch 1.12.1 不兼容（适用于 PyTorch 1.12.0）。PyTorch 1.12.1 应该与 oneccl_bindings_for_pytorch 1.12.100 兼容。

## Intel® MPI 库

使用这个基于标准的 MPI 实现来在 Intel®架构上提供灵活、高效、可扩展的集群消息传递。这个组件是 Intel® oneAPI HPC Toolkit 的一部分。

oneccl_bindings_for_pytorch 是与 MPI 工具集一起安装的。在使用之前需要设置环境。

对于 Intel® oneCCL >= 1.12.0

```py
oneccl_bindings_for_pytorch_path=$(python -c "from oneccl_bindings_for_pytorch import cwd; print(cwd)")
source $oneccl_bindings_for_pytorch_path/env/setvars.sh
```

对于版本< 1.12.0 的 Intel® oneCCL

```py
torch_ccl_path=$(python -c "import torch; import torch_ccl; import os;  print(os.path.abspath(os.path.dirname(torch_ccl.__file__)))")
source $torch_ccl_path/env/setvars.sh
```

#### Intel® PyTorch 扩展安装

Intel PyTorch 扩展（IPEX）为使用 Float32 和 BFloat16 进行 CPU 训练提供了性能优化（请参考单 CPU 部分以了解更多信息）。

以下“Trainer 中的用法”以 Intel® MPI 库中的 mpirun 为例。

## 在 Trainer 中的用法

要在 Trainer 中使用 ccl 后端启用多 CPU 分布式训练，用户应在命令参数中添加**`--ddp_backend ccl`**。

让我们看一个例子，使用[问答示例](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering)

以下命令在一个 Xeon 节点上启用了使用 2 个进程进行训练，每个进程在一个插槽上运行。OMP_NUM_THREADS/CCL_WORKER_COUNT 变量可以调整以获得最佳性能。

```py
 export CCL_WORKER_COUNT=1
 export MASTER_ADDR=127.0.0.1
 mpirun -n 2 -genv OMP_NUM_THREADS=23 \
 python3 run_qa.py \
 --model_name_or_path bert-large-uncased \
 --dataset_name squad \
 --do_train \
 --do_eval \
 --per_device_train_batch_size 12  \
 --learning_rate 3e-5  \
 --num_train_epochs 2  \
 --max_seq_length 384 \
 --doc_stride 128  \
 --output_dir /tmp/debug_squad/ \
 --no_cuda \
 --ddp_backend ccl \
 --use_ipex
```

以下命令在两个 Xeon 上（node0 和 node1，以 node0 为主进程）启用了总共四个进程的训练，ppn（每个节点的进程数）设置为 2，每个插槽上运行一个进程。OMP_NUM_THREADS/CCL_WORKER_COUNT 变量可以调整以获得最佳性能。

在 node0 中，您需要创建一个包含每个节点的 IP 地址的配置文件（例如 hostfile），并将该配置文件路径作为参数传递。

```py
 cat hostfile
 xxx.xxx.xxx.xxx #node0 ip
 xxx.xxx.xxx.xxx #node1 ip
```

现在，在 node0 中运行以下命令，将在 node0 和 node1 中启用 4DDP，并使用 BF16 自动混合精度：

```py
 export CCL_WORKER_COUNT=1
 export MASTER_ADDR=xxx.xxx.xxx.xxx #node0 ip
 mpirun -f hostfile -n 4 -ppn 2 \
 -genv OMP_NUM_THREADS=23 \
 python3 run_qa.py \
 --model_name_or_path bert-large-uncased \
 --dataset_name squad \
 --do_train \
 --do_eval \
 --per_device_train_batch_size 12  \
 --learning_rate 3e-5  \
 --num_train_epochs 2  \
 --max_seq_length 384 \
 --doc_stride 128  \
 --output_dir /tmp/debug_squad/ \
 --no_cuda \
 --ddp_backend ccl \
 --use_ipex \
 --bf16
```

## 在 Kubernetes 中的用法

可以使用[Kubeflow PyTorchJob 训练操作符](https://www.kubeflow.org/docs/components/training/pytorch/)将前一节中的相同分布式训练作业部署到 Kubernetes 集群。

### 设置

此示例假定您已经：

+   访问已安装[Kubeflow 的 Kubernetes 集群](https://www.kubeflow.org/docs/started/installing-kubeflow/)

+   已安装并配置[`kubectl`](https://kubernetes.io/docs/tasks/tools/)以访问 Kubernetes 集群

+   可以用于存储数据集和模型文件的[Persistent Volume Claim (PVC)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)。设置 PVC 的多种选项，包括使用 NFS [storage class](https://kubernetes.io/docs/concepts/storage/storage-classes/)或云存储桶。

+   一个包含您的模型训练脚本和运行脚本所需的所有依赖项的 Docker 容器。对于分布式 CPU 训练作业，这通常包括 PyTorch、Transformers、Intel Extension for PyTorch、Intel oneCCL Bindings for PyTorch 和 OpenSSH 以在容器之间进行通信。

下面的片段是一个使用支持分布式 CPU 训练的基础镜像的 Dockerfile 示例，然后将 Transformers 发布提取到`/workspace`目录中，以便示例脚本包含在镜像中：

```py
FROM intel/ai-workflows:torch-2.0.1-huggingface-multinode-py3.9

WORKDIR /workspace

# Download and extract the transformers code
ARG HF_TRANSFORMERS_VER="4.35.2"
RUN mkdir transformers && \
    curl -sSL --retry 5 https://github.com/huggingface/transformers/archive/refs/tags/v${HF_TRANSFORMERS_VER}.tar.gz | tar -C transformers --strip-components=1 -xzf -
```

在将 PyTorchJob 部署到集群之前，需要构建并将镜像复制到集群的节点或推送到容器注册表。

### PyTorchJob 规范文件

[Kubeflow PyTorchJob](https://www.kubeflow.org/docs/components/training/pytorch/)用于在集群上运行分布式训练作业。PyTorchJob 的 yaml 文件定义了参数，例如：

+   PyTorchJob 的名称

+   副本数（workers）的数量

+   将用于运行训练作业的 Python 脚本及其参数

+   每个 worker 所需的资源类型（节点选择器、内存和 CPU）

+   Docker 容器使用的图像/标签

+   环境变量

+   PVC 的卷挂载

卷挂载定义了 PVC 将在每个 worker pod 的容器中挂载的路径。此位置可用于数据集、检查点文件以及训练完成后保存的模型。

下面的片段是一个 PyTorchJob 的 yaml 文件示例，其中有 4 个 worker 运行[问答示例](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering)。

```py
apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: transformers-pytorchjob
  namespace: kubeflow
spec:
  elasticPolicy:
    rdzvBackend: c10d
    minReplicas: 1
    maxReplicas: 4
    maxRestarts: 10
  pytorchReplicaSpecs:
    Worker:
      replicas: 4  # The number of worker pods
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: pytorch
              image: <image name>:<tag>  # Specify the docker image to use for the worker pods
              imagePullPolicy: IfNotPresent
              command:
                - torchrun
                - /workspace/transformers/examples/pytorch/question-answering/run_qa.py
                - --model_name_or_path
                - "bert-large-uncased"
                - --dataset_name
                - "squad"
                - --do_train
                - --do_eval
                - --per_device_train_batch_size
                - "12"
                - --learning_rate
                - "3e-5"
                - --num_train_epochs
                - "2"
                - --max_seq_length
                - "384"
                - --doc_stride
                - "128"
                - --output_dir
                - "/tmp/pvc-mount/output"
                - --no_cuda
                - --ddp_backend
                - "ccl"
                - --use_ipex
                - --bf16  # Specify --bf16 if your hardware supports bfloat16
              env:
              - name: LD_PRELOAD
                value: "/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9:/usr/local/lib/libiomp5.so"
              - name: TRANSFORMERS_CACHE
                value: "/tmp/pvc-mount/transformers_cache"
              - name: HF_DATASETS_CACHE
                value: "/tmp/pvc-mount/hf_datasets_cache"
              - name: LOGLEVEL
                value: "INFO"
              - name: CCL_WORKER_COUNT
                value: "1"
              - name: OMP_NUM_THREADS  # Can be tuned for optimal performance
-                value: "56"
              resources:
                limits:
                  cpu: 200  # Update the CPU and memory limit values based on your nodes
                  memory: 128Gi
                requests:
                  cpu: 200  # Update the CPU and memory request values based on your nodes
                  memory: 128Gi
              volumeMounts:
              - name: pvc-volume
                mountPath: /tmp/pvc-mount
              - mountPath: /dev/shm
                name: dshm
          restartPolicy: Never
          nodeSelector:  #  Optionally use the node selector to specify what types of nodes to use for the workers
            node-type: spr
          volumes:
          - name: pvc-volume
            persistentVolumeClaim:
              claimName: transformers-pvc
          - name: dshm
            emptyDir:
              medium: Memory
```

要运行此示例，请根据您的训练脚本和集群中的节点更新 yaml。

yaml 中的 CPU 资源限制/请求是以[CPU 单位](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu)定义的，其中 1 个 CPU 单位等同于 1 个物理 CPU 核心或 1 个虚拟核心（取决于节点是物理主机还是虚拟机）。在 yaml 中定义的 CPU 和内存限制/请求量应小于单台机器上可用 CPU/内存容量的量。通常最好不要使用整个机器的容量，以便为 kubelet 和操作系统留下一些资源。为了为 worker pods 获得[“guaranteed”](https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/#guaranteed)[服务质量](https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/)，请为资源限制和请求设置相同的 CPU 和内存量。

### 部署

在为您的集群和训练作业更新了适当的值后，可以使用以下命令将 PyTorchJob 部署到集群中：

```py
kubectl create -f pytorchjob.yaml
```

然后可以使用`kubectl get pods -n kubeflow`命令来列出`kubeflow`命名空间中的 pod。您应该看到刚刚部署的 PyTorchJob 的 worker pods。起初，它们可能会显示“Pending”状态，因为容器正在被拉取和创建，然后状态应该会变为“Running”。

```py
NAME                                                     READY   STATUS                  RESTARTS          AGE
...
transformers-pytorchjob-worker-0                         1/1     Running                 0                 7m37s
transformers-pytorchjob-worker-1                         1/1     Running                 0                 7m37s
transformers-pytorchjob-worker-2                         1/1     Running                 0                 7m37s
transformers-pytorchjob-worker-3                         1/1     Running                 0                 7m37s
...
```

可以使用 `kubectl logs -n kubeflow <pod name>` 查看工作节点的日志。添加 `-f` 来实时查看日志，例如：

```py
kubectl logs -n kubeflow transformers-pytorchjob-worker-0 -f
```

训练作业完成后，训练好的模型可以从 PVC 或存储位置复制。当作业完成后，可以使用 `kubectl delete -f pytorchjob.yaml` 命令从集群中删除 PyTorchJob 资源。

## 摘要

本指南涵盖了在裸金属和 Kubernetes 集群上使用多个 CPU 运行分布式 PyTorch 训练作业。这两种情况都利用了 Intel Extension for PyTorch 和 Intel oneCCL Bindings for PyTorch 来实现最佳的训练性能，并可以作为在多个节点上运行自己工作负载的模板。
