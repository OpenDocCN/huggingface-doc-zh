# 处理器

> 原文：[`huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors`](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors)

在 Transformers 库中，处理器可以有两种不同的含义：

+   为多模态模型预处理输入的对象，如 Wav2Vec2（语音和文本）或 CLIP（文本和视觉）

+   在库的旧版本中用于预处理 GLUE 或 SQUAD 数据的已弃用对象。

## 多模态处理器

任何多模态模型都需要一个对象来编码或解码将多个模态（文本、视觉和音频）组合在一起的数据。这由称为处理器的对象处理，这些对象将多个处理对象（如文本模态的分词器、视觉的图像处理器和音频的特征提取器）组合在一起。

这些处理器继承自实现保存和加载功能的以下基类：

### `class transformers.ProcessorMixin`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L56)

```py
( *args **kwargs )
```

这是一个混合类，用于为所有处理器类提供保存/加载功能。

#### `from_args_and_dict`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L365)

```py
( args processor_dict: Dict **kwargs ) → export const metadata = 'undefined';~processing_utils.ProcessingMixin
```

参数

+   `processor_dict` (`Dict[str, Any]`) — 将用于实例化处理器对象的字典。可以通过利用`~processing_utils.ProcessingMixin.to_dict`方法从预训练检查点中检索这样的字典。

+   `kwargs` (`Dict[str, Any]`) — 用于初始化处理器对象的其他参数。

返回

`~processing_utils.ProcessingMixin`

从这些参数实例化的处理器对象。

从 Python 参数字典中实例化`~processing_utils.ProcessingMixin`类型。

#### `from_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)

```py
( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str`或`os.PathLike`) — 这可以是：

    +   一个字符串，预训练特征提取器的*模型标识*，托管在 huggingface.co 上的模型仓库内。有效的模型标识可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用 save_pretrained()方法保存的特征提取器文件，例如，`./my_model_directory/`。

    +   保存的特征提取器 JSON *文件*的路径或 URL，例如，`./my_model_directory/preprocessor_config.json`。**kwargs — 传递给 from_pretrained()和`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`的其他关键字参数。

实例化与预训练模型相关联的处理器。

这个类方法只是调用特征提取器 from_pretrained()、图像处理器 ImageProcessingMixin 和分词器`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`方法。请参考上述方法的文档字符串以获取更多信息。

#### `get_processor_dict`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L256)

```py
( pretrained_model_name_or_path: Union **kwargs ) → export const metadata = 'undefined';Tuple[Dict, Dict]
```

参数

+   `pretrained_model_name_or_path` (`str`或`os.PathLike`) — 我们想要参数字典的预训练检查点的标识符。

+   `subfolder` (`str`，*可选*，默认为 `""`) — 如果相关文件位于 huggingface.co 上模型存储库的子文件夹中，可以在此处指定文件夹名称。

返回

`Tuple[Dict, Dict]`

将用于实例化处理器对象的字典。

从 `pretrained_model_name_or_path`，解析为参数字典，用于使用 `from_args_and_dict` 实例化类型为 `~processing_utils.ProcessingMixin` 的处理器。

#### `push_to_hub`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)

```py
( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )
```

参数

+   `repo_id` (`str`) — 要将处理器推送到的存储库的名称。在推送到给定组织时，应包含您的组织名称。

+   `use_temp_dir` (`bool`，*可选*) — 是否使用临时目录来存储在推送到 Hub 之前保存的文件。如果没有名为 `repo_id` 的目录，则默认为 `True`，否则为 `False`。

+   `commit_message` (`str`，*可选*) — 推送时要提交的消息。默认为 `"Upload processor"`。

+   `private` (`bool`，*可选*) — 是否应该创建的存储库是私有的。

+   `token` (`bool` 或 `str`，*可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，将使用运行 `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface`）。如果未指定 `repo_url`，则默认为 `True`。

+   `max_shard_size` (`int` 或 `str`，*可选*，默认为 `"5GB"`) — 仅适用于模型。在分片之前的检查点的最大大小。然后，检查点分片的大小将小于此大小。如果表示为字符串，需要是数字后跟一个单位（如 `"5MB"`）。我们将其默认为 `"5GB"`，以便用户可以在免费的 Google Colab 实例上轻松加载模型，而不会出现任何 CPU OOM 问题。

+   `create_pr` (`bool`，*可选*，默认为 `False`) — 是否创建一个包含上传文件的 PR 或直接提交。

+   `safe_serialization` (`bool`，*可选*，默认为 `True`) — 是否将模型权重转换为 safetensors 格式以进行更安全的序列化。

+   `revision` (`str`，*可选*) — 要将上传的文件推送到的分支。

+   `commit_description` (`str`，*可选*) — 将创建的提交的描述

+   `tags` (`List[str]`，*可选*) — 要推送到 Hub 上的标签列表。

将处理器文件上传到 🤗 模型中心。

示例：

```py
from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("bert-base-cased")

# Push the processor to your namespace with the name "my-finetuned-bert".
processor.push_to_hub("my-finetuned-bert")

# Push the processor to an organization with the name "my-finetuned-bert".
processor.push_to_hub("huggingface/my-finetuned-bert")
```

#### `register_for_auto_class`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L471)

```py
( auto_class = 'AutoProcessor' )
```

参数

+   `auto_class` (`str` 或 `type`，*可选*，默认为 `"AutoProcessor"`) — 要将此新特征提取器注册到的自动类。

将此类注册到给定的自动类中。这应该仅用于自定义特征提取器，因为库中的特征提取器已经与 `AutoProcessor` 映射。

此 API 是实验性的，可能在下一个版本中有一些轻微的破坏性更改。

#### `save_pretrained`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)

```py
( save_directory push_to_hub: bool = False **kwargs )
```

参数

+   `save_directory` (`str` 或 `os.PathLike`) — 将保存特征提取器 JSON 文件和分词器文件的目录（如果目录不存在，则将创建该目录）。

+   `push_to_hub` (`bool`，*可选*，默认为 `False`) — 保存模型后是否将模型推送到 Hugging Face 模型中心。您可以使用 `repo_id` 指定要推送到的存储库（将默认为您的命名空间中的 `save_directory` 的名称）。

+   `kwargs` (`Dict[str, Any]`，*可选*) — 传递给 push_to_hub() 方法的其他关键字参数。

保存此处理器的属性（特征提取器、分词器等）到指定目录，以便可以使用 from_pretrained() 方法重新加载。

这个类方法只是调用 save_pretrained() 和 save_pretrained()。请参考上述方法的文档字符串以获取更多信息。

#### `to_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L102)

```py
( ) → export const metadata = 'undefined';Dict[str, Any]
```

返回值

`Dict[str, Any]`

包含构成此处理器实例的所有属性的字典。

将此实例序列化为 Python 字典。

#### `to_json_file`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L151)

```py
( json_file_path: Union )
```

参数

+   `json_file_path` (`str` 或 `os.PathLike`) — 保存此处理器实例参数的 JSON 文件路径。

将此实例保存到 JSON 文件中。

#### `to_json_string`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L140)

```py
( ) → export const metadata = 'undefined';str
```

返回值

`str`

以 JSON 格式包含构成此 feature_extractor 实例的所有属性的字符串。

将此实例序列化为 JSON 字符串。

## 已弃用的处理器

所有处理器都遵循相同的架构，即 DataProcessor 的架构。处理器返回一个 InputExample 列表。这些 InputExample 可以转换为 InputFeatures，以便馈送到模型中。

### `class transformers.DataProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L80)

```py
( )
```

用于序列分类数据集的数据转换器的基类。

#### `get_dev_examples`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L97)

```py
( data_dir )
```

为开发集获取一组 InputExample。

#### `get_example_from_tensor_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L83)

```py
( tensor_dict )
```

从带有 tensorflow 张量的字典中获取一个示例。

#### `get_labels`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L105)

```py
( )
```

获取此数据集的标签列表。

#### `get_test_examples`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L101)

```py
( data_dir )
```

为测试集获取一组 InputExample。

#### `get_train_examples`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L93)

```py
( data_dir )
```

为训练集获取一组 InputExample。

#### `tfds_map`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L109)

```py
( example )
```

某些 tensorflow_datasets 数据集的格式与 GLUE 数据集不同。此方法将示例转换为正确的格式。

### `class transformers.InputExample`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L29)

```py
( guid: str text_a: str text_b: Optional = None label: Optional = None )
```

用于简单序列分类的单个训练/测试示例。

#### `to_json_string`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L49)

```py
( )
```

将此实例序列化为 JSON 字符串。

### `class transformers.InputFeatures`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L54)

```py
( input_ids: List attention_mask: Optional = None token_type_ids: Optional = None label: Union = None )
```

数据的一组特征。属性名称与模型的相应输入名称相同。

#### `to_json_string`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L75)

```py
( )
```

将此实例序列化为 JSON 字符串。

## GLUE

[通用语言理解评估（GLUE）](https://gluebenchmark.com/)是一个基准，评估模型在各种现有 NLU 任务上的表现。它与论文[GLUE：自然语言理解的多任务基准和分析平台](https://openreview.net/pdf?id=rJ4km2R5t7)一起发布

这个库为以下任务提供了总共 10 个处理器：MRPC，MNLI，MNLI（不匹配），CoLA，SST2，STSB，QQP，QNLI，RTE 和 WNLI。

这些处理器是：

+   `~data.processors.utils.MrpcProcessor`

+   `~data.processors.utils.MnliProcessor`

+   `~data.processors.utils.MnliMismatchedProcessor`

+   `~data.processors.utils.Sst2Processor`

+   `~data.processors.utils.StsbProcessor`

+   `~data.processors.utils.QqpProcessor`

+   `~data.processors.utils.QnliProcessor`

+   `~data.processors.utils.RteProcessor`

+   `~data.processors.utils.WnliProcessor`

此外，以下方法可用于从数据文件加载值并将其转换为 InputExample 列表。

#### `transformers.glue_convert_examples_to_features`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/glue.py#L41)

```py
( examples: Union tokenizer: PreTrainedTokenizer max_length: Optional = None task = None label_list = None output_mode = None )
```

将数据文件加载到`InputFeatures`列表中

## XNLI

[跨语言 NLI 语料库（XNLI）](https://www.nyu.edu/projects/bowman/xnli/)是一个基准，评估跨语言文本表示的质量。XNLI 是基于[*MultiNLI*](http://www.nyu.edu/projects/bowman/multinli/)的众包数据集：文本对使用 15 种不同语言（包括高资源语言如英语和低资源语言如斯瓦希里语）进行文本蕴涵注释。

它与论文[XNLI：评估跨语言句子表示](https://arxiv.org/abs/1809.05053)一起发布

这个库提供了加载 XNLI 数据的处理器：

+   `~data.processors.utils.XnliProcessor`

请注意，由于测试集上有金标签，评估是在测试集上进行的。

在[run_xnli.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification/run_xnli.py)脚本中提供了使用这些处理器的示例。

## SQuAD

[斯坦福问答数据集（SQuAD）](https://rajpurkar.github.io/SQuAD-explorer//)是一个基准，评估模型在问答上的表现。有两个版本可用，v1.1 和 v2.0。第一个版本（v1.1）与论文[SQuAD：文本机器理解的 10 万+问题](https://arxiv.org/abs/1606.05250)一起发布。第二个版本（v2.0）与论文[知道你不知道的：SQuAD 的无法回答问题](https://arxiv.org/abs/1806.03822)一起发布。

这个库为两个版本中的每个版本提供了处理器：

### 处理器

这些处理器是：

+   `~data.processors.utils.SquadV1Processor`

+   `~data.processors.utils.SquadV2Processor`

它们都继承自抽象类`~data.processors.utils.SquadProcessor`

### `class transformers.data.processors.squad.SquadProcessor`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L541)

```py
( )
```

SQuAD 数据集的处理器。被 SquadV1Processor 和 SquadV2Processor 覆盖，分别由 SQuAD 的版本 1.1 和版本 2.0 使用。

#### `get_dev_examples`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L629)

```py
( data_dir filename = None )
```

从数据目录返回评估示例。

#### `get_examples_from_dataset`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L574)

```py
( dataset evaluate = False )
```

使用 TFDS 数据集创建`SquadExample`列表。

示例：

```py
>>> import tensorflow_datasets as tfds

>>> dataset = tfds.load("squad")

>>> training_examples = get_examples_from_dataset(dataset, evaluate=False)
>>> evaluation_examples = get_examples_from_dataset(dataset, evaluate=True)
```

#### `get_train_examples`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L607)

```py
( data_dir filename = None )
```

从数据目录返回训练示例。

此外，以下方法可用于将 SQuAD 示例转换为可用作模型输入的`~data.processors.utils.SquadFeatures`。

#### `transformers.squad_convert_examples_to_features`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L316)

```py
( examples tokenizer max_seq_length doc_stride max_query_length is_training padding_strategy = 'max_length' return_dataset = False threads = 1 tqdm_enabled = True )
```

将示例列表转换为可以直接作为模型输入的特征列表。它取决于模型，并利用许多分词器的特性来创建模型的输入。

例子：

```py
processor = SquadV2Processor()
examples = processor.get_dev_examples(data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=args.max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=args.max_query_length,
    is_training=not evaluate,
)
```

这些处理器以及前述方法可以与包含数据的文件以及*tensorflow_datasets*包一起使用。下面给出了示例。

### 示例用法

以下是一个示例，使用处理器以及使用数据文件的转换方法：

```py
# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
)
```

使用*tensorflow_datasets*就像使用数据文件一样简单：

```py
# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
)
```

另一个使用这些处理器的示例在[run_squad.py](https://github.com/huggingface/transformers/tree/main/examples/legacy/question-answering/run_squad.py)脚本中给出。
