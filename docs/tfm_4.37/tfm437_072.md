# 在 CPU 上高效训练

> 原文：[`huggingface.co/docs/transformers/v4.37.2/en/perf_train_cpu`](https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_cpu)

本指南侧重于在 CPU 上高效训练大型模型。

## 使用 IPEX 的混合精度

IPEX 优化了 AVX-512 或更高版本的 CPU，并且在仅具有 AVX2 的 CPU 上也可以正常工作。因此，预计在具有 AVX-512 或更高版本的英特尔 CPU 世代中，IPEX 将带来性能优势，而仅具有 AVX2 的 CPU（例如 AMD CPU 或较旧的英特尔 CPU）在 IPEX 下可能会获得更好的性能，但不能保证。IPEX 为使用 Float32 和 BFloat16 进行 CPU 训练提供了性能优化。以下部分的主要重点是使用 BFloat16。

低精度数据类型 BFloat16 已经在第三代 Xeon® Scalable Processors（又称 Cooper Lake）上本地支持，具有 AVX512 指令集，并将在下一代英特尔® Xeon® Scalable Processors 上支持，该处理器具有 Intel® Advanced Matrix Extensions（Intel® AMX）指令集，进一步提升性能。自 PyTorch-1.10 以来，已启用了 CPU 后端的自动混合精度。同时，Intel® Extension for PyTorch 大规模启用了 CPU 和 BFloat16 优化运算符的自动混合精度，并部分上游到 PyTorch 主分支。用户可以通过 IPEX 自动混合精度获得更好的性能和用户体验。

查看更多关于 [自动混合精度](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/features/amp.html) 的详细信息。

### IPEX 安装：

IPEX 发布遵循 PyTorch，可以通过 pip 安装：

| PyTorch 版本 | IPEX 版本 |
| :-: | :-: |
| 2.1.x | 2.1.100+cpu |
| 2.0.x | 2.0.100+cpu |
| 1.13 | 1.13.0+cpu |
| 1.12 | 1.12.300+cpu |

请运行 `pip list | grep torch` 以获取您的 `pytorch_version`，这样您就可以获得 `IPEX version_name`。

```py
pip install intel_extension_for_pytorch==<version_name> -f https://developer.intel.com/ipex-whl-stable-cpu
```

如果需要，您可以在 [ipex-whl-stable-cpu](https://developer.intel.com/ipex-whl-stable-cpu) 中查看最新版本。

查看更多关于 [IPEX 安装](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/installation.html) 的方法。

### Trainer 中的用法

要在 Trainer 中启用 IPEX 的自动混合精度，用户应该在训练命令参数中添加 `use_ipex`、`bf16` 和 `no_cuda`。

以 [Transformers 问答](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering) 用例为例

+   使用 BF16 自动混合精度在 CPU 上进行 IPEX 训练：

    ```py
     python run_qa.py \
    --model_name_or_path bert-base-uncased \
    --dataset_name squad \
    --do_train \
    --do_eval \
    --per_device_train_batch_size 12 \
    --learning_rate 3e-5 \
    --num_train_epochs 2 \
    --max_seq_length 384 \
    --doc_stride 128 \
    --output_dir /tmp/debug_squad/ \
    --use_ipex \
    --bf16 \
    --use_cpu
    ```

如果要在脚本中启用 `use_ipex` 和 `bf16`，请像这样将这些参数添加到 `TrainingArguments` 中：

```py
training_args = TrainingArguments(
    output_dir=args.output_path,
+   bf16=True,
+   use_ipex=True,
+   use_cpu=True,
    **kwargs
)
```

### 实践示例

博客：[使用英特尔 Sapphire Rapids 加速 PyTorch Transformers](https://huggingface.co/blog/intel-sapphire-rapids)
