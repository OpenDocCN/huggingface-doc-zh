# UPerNet

> [`huggingface.co/docs/transformers/v4.37.2/en/model_doc/upernet`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/upernet)

## æ¦‚è¿°

UPerNet æ¨¡å‹æ˜¯ç”±è‚–ç‰¹ã€åˆ˜è‹±æˆã€å‘¨åšç£Šã€å§œç‰å®ã€å­™åšåœ¨[ç»Ÿä¸€æ„ŸçŸ¥è§£æç”¨äºåœºæ™¯ç†è§£](https://arxiv.org/abs/1807.10221)ä¸­æå‡ºçš„ã€‚UPerNet æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä»å›¾åƒä¸­åˆ†å‰²å„ç§æ¦‚å¿µï¼Œåˆ©ç”¨ä»»ä½•è§†è§‰éª¨å¹²ï¼Œå¦‚ ConvNeXt æˆ– Swinã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*äººç±»åœ¨å¤šä¸ªå±‚æ¬¡ä¸Šè¯†åˆ«è§†è§‰ä¸–ç•Œï¼šæˆ‘ä»¬è½»æ¾åœ°å¯¹åœºæ™¯è¿›è¡Œåˆ†ç±»ï¼Œå¹¶æ£€æµ‹å…¶ä¸­çš„å¯¹è±¡ï¼ŒåŒæ—¶è¿˜è¯†åˆ«å¯¹è±¡çš„çº¹ç†å’Œè¡¨é¢ä»¥åŠå®ƒä»¬ä¸åŒçš„ç»„æˆéƒ¨åˆ†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸€ä¸ªç§°ä¸ºç»Ÿä¸€æ„ŸçŸ¥è§£æçš„æ–°ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡è¦æ±‚æœºå™¨è§†è§‰ç³»ç»Ÿä»ç»™å®šå›¾åƒä¸­å°½å¯èƒ½è¯†åˆ«å°½å¯èƒ½å¤šçš„è§†è§‰æ¦‚å¿µã€‚å¼€å‘äº†ä¸€ä¸ªåä¸º UPerNet çš„å¤šä»»åŠ¡æ¡†æ¶å’Œè®­ç»ƒç­–ç•¥ï¼Œä»¥ä»å¼‚æ„å›¾åƒæ³¨é‡Šä¸­å­¦ä¹ ã€‚æˆ‘ä»¬åœ¨ç»Ÿä¸€æ„ŸçŸ¥è§£æä¸Šå¯¹æˆ‘ä»¬çš„æ¡†æ¶è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå¹¶å±•ç¤ºå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°ä»å›¾åƒä¸­åˆ†å‰²å„ç§æ¦‚å¿µã€‚è®­ç»ƒçš„ç½‘ç»œè¿›ä¸€æ­¥åº”ç”¨äºå‘ç°è‡ªç„¶åœºæ™¯ä¸­çš„è§†è§‰çŸ¥è¯†ã€‚*

![å›¾ç¤º](img/a144fe8a7a6a0326f562f0adcb5e8255.png) UPerNet æ¡†æ¶ã€‚å–è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/1807.10221)ã€‚

è¯¥æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚åŸå§‹ä»£ç åŸºäº OpenMMLab çš„ mmsegmentation [è¿™é‡Œ](https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/uper_head.py)ã€‚

## ä½¿ç”¨ç¤ºä¾‹

UPerNet æ˜¯è¯­ä¹‰åˆ†å‰²çš„é€šç”¨æ¡†æ¶ã€‚å¯ä»¥ä¸ä»»ä½•è§†è§‰éª¨å¹²ä¸€èµ·ä½¿ç”¨ï¼Œå¦‚ï¼š

```py
from transformers import SwinConfig, UperNetConfig, UperNetForSemanticSegmentation

backbone_config = SwinConfig(out_features=["stage1", "stage2", "stage3", "stage4"])

config = UperNetConfig(backbone_config=backbone_config)
model = UperNetForSemanticSegmentation(config)
```

è¦ä½¿ç”¨å¦ä¸€ä¸ªè§†è§‰éª¨å¹²ï¼Œå¦‚ ConvNeXtï¼Œåªéœ€ä½¿ç”¨é€‚å½“çš„éª¨å¹²å®ä¾‹åŒ–æ¨¡å‹ï¼š

```py
from transformers import ConvNextConfig, UperNetConfig, UperNetForSemanticSegmentation

backbone_config = ConvNextConfig(out_features=["stage1", "stage2", "stage3", "stage4"])

config = UperNetConfig(backbone_config=backbone_config)
model = UperNetForSemanticSegmentation(config)
```

è¯·æ³¨æ„ï¼Œè¿™å°†éšæœºåˆå§‹åŒ–æ¨¡å‹çš„æ‰€æœ‰æƒé‡ã€‚

## èµ„æº

å®˜æ–¹ Hugging Face å’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨ UPerNetã€‚

+   UPerNet çš„æ¼”ç¤ºç¬”è®°æœ¬å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/UPerNet)æ‰¾åˆ°ã€‚

+   UperNetForSemanticSegmentation ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/semantic-segmentation)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)æ”¯æŒã€‚

+   å¦è¯·å‚é˜…ï¼šè¯­ä¹‰åˆ†å‰²ä»»åŠ¡æŒ‡å—

å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ª Pull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥å±•ç¤ºä¸€äº›æ–°å†…å®¹ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚

## UperNetConfig

### `class transformers.UperNetConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/upernet/configuration_upernet.py#L26)

```py
( backbone_config = None hidden_size = 512 initializer_range = 0.02 pool_scales = [1, 2, 3, 6] use_auxiliary_head = True auxiliary_loss_weight = 0.4 auxiliary_in_channels = 384 auxiliary_channels = 256 auxiliary_num_convs = 1 auxiliary_concat_input = False loss_ignore_index = 255 **kwargs )
```

å‚æ•°

+   `backbone_config` (`PretrainedConfig`æˆ–`dict`, *å¯é€‰*, é»˜è®¤ä¸º`ResNetConfig()`) â€” éª¨å¹²æ¨¡å‹çš„é…ç½®ã€‚

+   `hidden_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 512) â€” å·ç§¯å±‚ä¸­éšè—å•å…ƒçš„æ•°é‡ã€‚

+   `initializer_range` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `pool_scales` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º`[1, 2, 3, 6]`) â€” åº”ç”¨äºæœ€åç‰¹å¾å›¾çš„ Pooling Pyramid Module ä¸­ä½¿ç”¨çš„æ± åŒ–å°ºåº¦ã€‚

+   `use_auxiliary_head` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`True`) â€” è®­ç»ƒæœŸé—´æ˜¯å¦ä½¿ç”¨è¾…åŠ©å¤´ã€‚

+   `auxiliary_loss_weight` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.4) â€” è¾…åŠ©å¤´çš„äº¤å‰ç†µæŸå¤±çš„æƒé‡ã€‚

+   `auxiliary_channels` (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 256) â€” è¾…åŠ©å¤´ä¸­è¦ä½¿ç”¨çš„é€šé“æ•°ã€‚

+   `auxiliary_num_convs` (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 1) â€” è¾…åŠ©å¤´ä¸­è¦ä½¿ç”¨çš„å·ç§¯å±‚æ•°ã€‚

+   `auxiliary_concat_input` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” æ˜¯å¦åœ¨åˆ†ç±»å±‚ä¹‹å‰å°†è¾…åŠ©å¤´çš„è¾“å‡ºä¸è¾“å…¥è¿æ¥ã€‚

+   `loss_ignore_index` (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 255) â€” æŸå¤±å‡½æ•°å¿½ç•¥çš„ç´¢å¼•ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ UperNetForSemanticSegmentation çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ª UperNet æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº UperNet [openmmlab/upernet-convnext-tiny](https://huggingface.co/openmmlab/upernet-convnext-tiny)æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª PretrainedConfigï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯» PretrainedConfig çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import UperNetConfig, UperNetForSemanticSegmentation

>>> # Initializing a configuration
>>> configuration = UperNetConfig()

>>> # Initializing a model (with random weights) from the configuration
>>> model = UperNetForSemanticSegmentation(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## UperNetForSemanticSegmentation

### `class transformers.UperNetForSemanticSegmentation`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/upernet/modeling_upernet.py#L343)

```py
( config )
```

å‚æ•°

+   `This`æ¨¡å‹æ˜¯ PyTorch torch.nn.Module å­ç±»ã€‚ä½¿ç”¨

+   `it`ä½œä¸ºå¸¸è§„çš„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚é…ç½®(UperNetConfig)ï¼šæ¨¡å‹é…ç½®ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ from_pretrained()æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

UperNet æ¡†æ¶åˆ©ç”¨ä»»ä½•è§†è§‰éª¨å¹²ï¼Œä¾‹å¦‚ ADE20kï¼ŒCityScapesã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/upernet/modeling_upernet.py#L360)

```py
( pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None labels: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.SemanticSegmenterOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹ä¼šå¿½ç•¥å¡«å……ã€‚å¯ä»¥ä½¿ç”¨ AutoImageProcessor è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… SegformerImageProcessor.`call`()ã€‚

+   `output_attentions` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›éª¨å¹²å…·æœ‰æ³¨æ„åŠ›å¼ é‡çš„æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›éª¨å¹²çš„æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å› ModelOutput è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, height, width)`ï¼Œ*å¯é€‰*) â€” ç”¨äºè®¡ç®—æŸå¤±çš„åœ°é¢çœŸå®è¯­ä¹‰åˆ†å‰²åœ°å›¾ã€‚ç´¢å¼•åº”åœ¨`[0, ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚

è¿”å›

transformers.modeling_outputs.SemanticSegmenterOutput æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª transformers.modeling_outputs.SemanticSegmenterOutput æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆUperNetConfigï¼‰å’Œè¾“å…¥è€Œå¼‚çš„å„ç§å…ƒç´ ã€‚

+   `loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`, *å¯é€‰çš„*, å½“æä¾›`labels`æ—¶è¿”å›) â€” åˆ†ç±»ï¼ˆå¦‚æœ config.num_labels==1 åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚

+   `logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, config.num_labels, logits_height, logits_width)`) â€” æ¯ä¸ªåƒç´ çš„åˆ†ç±»åˆ†æ•°ã€‚

    <tip warning="{true}">è¿”å›çš„ logits ä¸ä¸€å®šä¸ä½œä¸ºè¾“å…¥ä¼ é€’çš„`pixel_values`å…·æœ‰ç›¸åŒçš„å¤§å°ã€‚è¿™æ˜¯ä¸ºäº†é¿å…è¿›è¡Œä¸¤æ¬¡æ’å€¼å¹¶åœ¨ç”¨æˆ·éœ€è¦å°† logits è°ƒæ•´ä¸ºåŸå§‹å›¾åƒå¤§å°æ—¶ä¸¢å¤±ä¸€äº›è´¨é‡ã€‚æ‚¨åº”å§‹ç»ˆæ£€æŸ¥ logits çš„å½¢çŠ¶å¹¶æ ¹æ®éœ€è¦è°ƒæ•´å¤§å°ã€‚</tip>

+   `hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰çš„*, å½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, patch_size, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡ºï¼Œå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œ+ ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸ªå±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰çš„*, å½“ä¼ é€’`output_attentions=True`æˆ–å½“`config.output_attentions=True`æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚

    æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

UperNetForSemanticSegmentation çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹:

```py
>>> from transformers import AutoImageProcessor, UperNetForSemanticSegmentation
>>> from PIL import Image
>>> from huggingface_hub import hf_hub_download

>>> image_processor = AutoImageProcessor.from_pretrained("openmmlab/upernet-convnext-tiny")
>>> model = UperNetForSemanticSegmentation.from_pretrained("openmmlab/upernet-convnext-tiny")

>>> filepath = hf_hub_download(
...     repo_id="hf-internal-testing/fixtures_ade20k", filename="ADE_val_00000001.jpg", repo_type="dataset"
... )
>>> image = Image.open(filepath).convert("RGB")

>>> inputs = image_processor(images=image, return_tensors="pt")

>>> outputs = model(**inputs)

>>> logits = outputs.logits  # shape (batch_size, num_labels, height, width)
>>> list(logits.shape)
[1, 150, 512, 512]
```
