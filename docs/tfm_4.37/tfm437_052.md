# 创建自定义架构

> 原文链接: [`huggingface.co/docs/transformers/v4.37.2/en/create_a_model`](https://huggingface.co/docs/transformers/v4.37.2/en/create_a_model)

`AutoClass`会自动推断模型架构并下载预训练配置和权重。通常，我们建议使用`AutoClass`生成与检查点无关的代码。但是，希望对特定模型参数有更多控制的用户可以从几个基类创建一个自定义🤗 Transformers 模型。这对于任何对研究、训练或实验🤗 Transformers 模型感兴趣的人特别有用。在本指南中，深入了解如何创建一个自定义模型而不使用`AutoClass`。学习如何：

+   加载并自定义模型配置。

+   创建模型架构。

+   为文本创建慢速和快速分词器。

+   为视觉任务创建图像处理器。

+   为音频任务创建特征提取器。

+   为多模态任务创建处理器。

## 配置

configuration 指的是模型的特定属性。每个模型配置都有不同的属性；例如，所有 NLP 模型都共有`hidden_size`、`num_attention_heads`、`num_hidden_layers`和`vocab_size`属性。这些属性指定了构建模型所需的注意力头或隐藏层的数量。

通过访问 DistilBertConfig 来查看其属性，进一步了解 DistilBERT：

```py
>>> from transformers import DistilBertConfig

>>> config = DistilBertConfig()
>>> print(config)
DistilBertConfig {
  "activation": "gelu",
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "transformers_version": "4.16.2",
  "vocab_size": 30522
}
```

DistilBertConfig 显示了用于构建基本 DistilBertModel 的所有默认属性。所有属性都是可定制的，为实验创造了空间。例如，您可以自定义一个默认模型：

+   使用`activation`参数尝试不同的激活函数。

+   使用`attention_dropout`参数为注意力概率设置更高的 dropout 比率。

```py
>>> my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
>>> print(my_config)
DistilBertConfig {
  "activation": "relu",
  "attention_dropout": 0.4,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "transformers_version": "4.16.2",
  "vocab_size": 30522
}
```

预训练模型属性可以在 from_pretrained()函数中修改：

```py
>>> my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)
```

一旦您满意您的模型配置，您可以用 save_pretrained()保存它。您的配置文件将以 JSON 文件的形式存储在指定的保存目录中：

```py
>>> my_config.save_pretrained(save_directory="./your_model_save_path")
```

要重用配置文件，请使用 from_pretrained()加载它：

```py
>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/config.json")
```

您还可以将配置文件保存为字典，甚至只保存自定义配置属性与默认配置属性之间的差异！查看 configuration 文档以获取更多详细信息。

## 模型

下一步是创建一个 model。模型 - 也宽泛地称为架构 - 定义了每个层正在做什么以及正在发生的操作。像`num_hidden_layers`这样的配置属性用于定义架构。每个模型都共享基类 PreTrainedModel 和一些常见方法，如调整输入嵌入和修剪自注意力头。此外，所有模型也是[`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)、[`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)或[`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)的子类。这意味着模型与各自框架的使用是兼容的。

Pytorch 隐藏 Pytorch 内容

将您的自定义配置属性加载到模型中：

```py
>>> from transformers import DistilBertModel

>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/config.json")
>>> model = DistilBertModel(my_config)
```

这将创建一个具有随机值而不是预训练权重的模型。在训练之前，您无法将此模型用于任何有用的目的。训练是一个昂贵且耗时的过程。通常最好使用预训练模型以更快地获得更好的结果，同时仅使用训练所需资源的一小部分。

使用 from_pretrained()创建一个预训练模型：

```py
>>> model = DistilBertModel.from_pretrained("distilbert-base-uncased")
```

当加载预训练权重时，如果模型由🤗 Transformers 提供，则默认模型配置会自动加载。但是，如果您愿意，仍然可以替换 - 一些或全部 - 默认模型配置属性为您自己的属性：

```py
>>> model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)
```

TensorFlow 隐藏 TensorFlow 内容

将您的自定义配置属性加载到模型中：

```py
>>> from transformers import TFDistilBertModel

>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
>>> tf_model = TFDistilBertModel(my_config)
```

这将创建一个具有随机值而不是预训练权重的模型。在训练之前，您无法将此模型用于任何有用的目的。训练是一个昂贵且耗时的过程。通常最好使用预训练模型以更快地获得更好的结果，同时仅使用训练所需资源的一小部分。

使用 from_pretrained()创建一个预训练模型：

```py
>>> tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")
```

当加载预训练权重时，如果模型由🤗 Transformers 提供，则默认模型配置会自动加载。但是，如果您愿意，仍然可以替换 - 一些或全部 - 默认模型配置属性为您自己的属性：

```py
>>> tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)
```

### 模型头

此时，您有一个输出*隐藏状态*的基础 DistilBERT 模型。隐藏状态作为输入传递给模型头，以产生最终输出。只要模型支持任务（即，您不能将 DistilBERT 用于像翻译这样的序列到序列任务），🤗 Transformers 为每个任务提供不同的模型头。

Pytorch 隐藏 Pytorch 内容

例如，DistilBertForSequenceClassification 是一个带有序列分类头的基础 DistilBERT 模型。序列分类头是在汇总输出之上的线性层。

```py
>>> from transformers import DistilBertForSequenceClassification

>>> model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

通过切换到不同的模型头轻松地为另一个任务重用此检查点。对于问答任务，您将使用 DistilBertForQuestionAnswering 模型头。问答头类似于序列分类头，只是它是在隐藏状态输出之上的线性层。

```py
>>> from transformers import DistilBertForQuestionAnswering

>>> model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")
```

TensorFlow 隐藏 TensorFlow 内容

例如，TFDistilBertForSequenceClassification 是一个带有序列分类头的基础 DistilBERT 模型。序列分类头是在汇总输出之上的线性层。

```py
>>> from transformers import TFDistilBertForSequenceClassification

>>> tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

通过切换到不同的模型头轻松地为另一个任务重用此检查点。对于问答任务，您将使用 TFDistilBertForQuestionAnswering 模型头。问答头类似于序列分类头，只是它是在隐藏状态输出之上的线性层。

```py
>>> from transformers import TFDistilBertForQuestionAnswering

>>> tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")
```

## Tokenizer

在使用模型处理文本数据之前，您需要的最后一个基类是 tokenizer 将原始文本转换为张量。您可以使用🤗 Transformers 的两种类型的 tokenizer：

+   PreTrainedTokenizer：一个 tokenizer 的 Python 实现。

+   PreTrainedTokenizerFast：来自我们基于 Rust 的[🤗 Tokenizer](https://huggingface.co/docs/tokenizers/python/latest/)库的一个分词器。这种分词器类型速度明显更快 - 特别是在批量分词时 - 这是由于其 Rust 实现。快速分词器还提供了额外的方法，比如*偏移映射*，将标记映射到它们的原始单词或字符。

两种分词器都支持常见方法，如编码和解码、添加新标记和管理特殊标记。

并非每个模型都支持快速分词器。查看这个 table 以检查模型是否支持快速分词器。

如果您训练了自己的分词器，可以从您的*vocabulary*文件创建一个：

```py
>>> from transformers import DistilBertTokenizer

>>> my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")
```

重要的是要记住，自定义分词器的词汇表与预训练模型的分词器生成的词汇表是不同的。如果您使用预训练模型，则需要使用预训练模型的词汇表，否则输入将没有意义。使用 DistilBertTokenizer 类创建一个带有预训练模型词汇表的分词器：

```py
>>> from transformers import DistilBertTokenizer

>>> slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
```

使用 DistilBertTokenizerFast 类创建一个快速分词器：

```py
>>> from transformers import DistilBertTokenizerFast

>>> fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")
```

默认情况下，AutoTokenizer 将尝试加载一个快速分词器。您可以通过在`from_pretrained`中设置`use_fast=False`来禁用此行为。

## 图像处理器

图像处理器处理视觉输入。它继承自基础 ImageProcessingMixin 类。

要使用，创建一个与您正在使用的模型相关联的图像处理器。例如，如果您正在使用 ViT 进行图像分类，则创建一个默认的 ViTImageProcessor：

```py
>>> from transformers import ViTImageProcessor

>>> vit_extractor = ViTImageProcessor()
>>> print(vit_extractor)
ViTImageProcessor {
  "do_normalize": true,
  "do_resize": true,
  "image_processor_type": "ViTImageProcessor",
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": 2,
  "size": 224
}
```

如果您不需要任何自定义，只需使用`from_pretrained`方法加载模型的默认图像处理器参数。

修改任何 ViTImageProcessor 参数以创建您自定义的图像处理器：

```py
>>> from transformers import ViTImageProcessor

>>> my_vit_extractor = ViTImageProcessor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
>>> print(my_vit_extractor)
ViTImageProcessor {
  "do_normalize": false,
  "do_resize": true,
  "image_processor_type": "ViTImageProcessor",
  "image_mean": [
    0.3,
    0.3,
    0.3
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": "PIL.Image.BOX",
  "size": 224
}
```

## 特征提取器

特征提取器处理音频输入。它继承自基础 FeatureExtractionMixin 类，并且还可以继承自 SequenceFeatureExtractor 类来处理音频输入。

要使用，创建一个与您正在使用的模型相关联的特征提取器。例如，如果您正在使用 Wav2Vec2 进行音频分类，则创建一个默认的 Wav2Vec2FeatureExtractor：

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> w2v2_extractor = Wav2Vec2FeatureExtractor()
>>> print(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}
```

如果您不需要任何自定义，只需使用`from_pretrained`方法加载模型的默认特征提取器参数。

修改任何 Wav2Vec2FeatureExtractor 参数以创建您自定义的特征提取器：

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> w2v2_extractor = Wav2Vec2FeatureExtractor(sampling_rate=8000, do_normalize=False)
>>> print(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  "do_normalize": false,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 8000
}
```

## 处理器

对于支持多模态任务的模型，🤗 Transformers 提供了一个处理器类，方便地将处理类（如特征提取器和分词器）包装成一个单一对象。例如，让我们使用 Wav2Vec2Processor 来进行自动语音识别任务（ASR）。ASR 将音频转录为文本，因此您将需要一个特征提取器和一个分词器。

创建一个特征提取器来处理音频输入：

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)
```

创建一个分词器来处理文本输入：

```py
>>> from transformers import Wav2Vec2CTCTokenizer

>>> tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")
```

将特征提取器和分词器组合在 Wav2Vec2Processor 中：

```py
>>> from transformers import Wav2Vec2Processor

>>> processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)
```

通过两个基本类 - 配置和模型 - 以及额外的预处理类（分词器、图像处理器、特征提取器或处理器），您可以创建🤗 Transformers 支持的任何模型。这些基本类都是可配置的，允许您使用您想要的特定属性。您可以轻松设置一个用于训练的模型或修改现有的预训练模型进行微调。
