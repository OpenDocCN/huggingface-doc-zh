# Nougat

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat`](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat)

## æ¦‚è¿°

Nougat æ¨¡å‹æ˜¯ç”± Lukas Blecherã€Guillem Cucurullã€Thomas Scialomã€Robert Stojnic æå‡ºçš„[Nougat: ç”¨äºå­¦æœ¯æ–‡æ¡£çš„ç¥ç»å…‰å­¦ç†è§£](https://arxiv.org/abs/2308.13418)ã€‚Nougat ä½¿ç”¨ä¸ Donut ç›¸åŒçš„æ¶æ„ï¼Œå³å›¾åƒ Transformer ç¼–ç å™¨å’Œè‡ªå›å½’æ–‡æœ¬ Transformer è§£ç å™¨ï¼Œå°†ç§‘å­¦ PDF è½¬æ¢ä¸ºæ ‡è®°ï¼Œä½¿å…¶æ›´æ˜“äºè®¿é—®ã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*ç§‘å­¦çŸ¥è¯†ä¸»è¦å­˜å‚¨åœ¨ä¹¦ç±å’Œç§‘å­¦æœŸåˆŠä¸­ï¼Œé€šå¸¸ä»¥ PDF å½¢å¼å­˜åœ¨ã€‚ç„¶è€Œï¼ŒPDF æ ¼å¼ä¼šå¯¼è‡´è¯­ä¹‰ä¿¡æ¯çš„ä¸¢å¤±ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ•°å­¦è¡¨è¾¾å¼ã€‚æˆ‘ä»¬æå‡ºäº† Nougatï¼ˆç”¨äºå­¦æœ¯æ–‡æ¡£çš„ç¥ç»å…‰å­¦ç†è§£ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè§†è§‰ Transformer æ¨¡å‹ï¼Œç”¨äºå°†ç§‘å­¦æ–‡æ¡£è¿›è¡Œå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ä»»åŠ¡ï¼Œè½¬æ¢ä¸ºæ ‡è®°è¯­è¨€ï¼Œå¹¶å±•ç¤ºäº†æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ–°çš„ç§‘å­¦æ–‡æ¡£æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ºå¢å¼ºæ•°å­—æ—¶ä»£ç§‘å­¦çŸ¥è¯†çš„å¯è®¿é—®æ€§æä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡å¼¥åˆäººç±»å¯è¯»æ–‡æ¡£å’Œæœºå™¨å¯è¯»æ–‡æœ¬ä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬å‘å¸ƒäº†æ¨¡å‹å’Œä»£ç ï¼Œä»¥åŠ é€Ÿæœªæ¥å…³äºç§‘å­¦æ–‡æœ¬è¯†åˆ«çš„å·¥ä½œã€‚*

![å›¾ç¤º](img/815b74c6366c16cb9cb90a9d9b246b4c.png) Nougat é«˜å±‚æ¦‚è¿°ã€‚æ‘˜è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2308.13418)ã€‚

è¯¥æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯åœ¨[æ­¤å¤„](https://github.com/facebookresearch/nougat)æ‰¾åˆ°ã€‚

## ä½¿ç”¨æç¤º

+   å¼€å§‹ä½¿ç”¨ Nougat çš„æœ€å¿«æ–¹æ³•æ˜¯æŸ¥çœ‹[æ•™ç¨‹ç¬”è®°æœ¬](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Nougat)ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨æ¨ç†æ—¶ä½¿ç”¨æ¨¡å‹ä»¥åŠåœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚

+   Nougat å§‹ç»ˆåœ¨ VisionEncoderDecoder æ¡†æ¶å†…ä½¿ç”¨ã€‚è¯¥æ¨¡å‹åœ¨æ¶æ„ä¸Šä¸ Donut ç›¸åŒã€‚

## æ¨ç†

Nougat çš„`VisionEncoderDecoder`æ¨¡å‹æ¥å—å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶åˆ©ç”¨ generate()æ¥è‡ªåŠ¨å›å½’ç”Ÿæˆç»™å®šè¾“å…¥å›¾åƒçš„æ–‡æœ¬ã€‚

NougatImageProcessor ç±»è´Ÿè´£é¢„å¤„ç†è¾“å…¥å›¾åƒï¼ŒNougatTokenizerFast è§£ç ç”Ÿæˆçš„ç›®æ ‡æ ‡è®°ä¸ºç›®æ ‡å­—ç¬¦ä¸²ã€‚NougatProcessor å°† NougatImageProcessor å’Œ NougatTokenizerFast ç±»å°è£…ä¸ºå•ä¸ªå®ä¾‹ï¼Œç”¨äºæå–è¾“å…¥ç‰¹å¾å’Œè§£ç é¢„æµ‹çš„æ ‡è®° IDã€‚

+   é€æ­¥ PDF è½¬å½•

```py
>>> from huggingface_hub import hf_hub_download
>>> import re
>>> from PIL import Image

>>> from transformers import NougatProcessor, VisionEncoderDecoderModel
>>> from datasets import load_dataset
>>> import torch

>>> processor = NougatProcessor.from_pretrained("facebook/nougat-base")
>>> model = VisionEncoderDecoderModel.from_pretrained("facebook/nougat-base")

>>> device = "cuda" if torch.cuda.is_available() else "cpu"
>>> model.to(device)
>>> # prepare PDF image for the model
>>> filepath = hf_hub_download(repo_id="hf-internal-testing/fixtures_docvqa", filename="nougat_paper.png", repo_type="dataset")
>>> image = Image.open(filepath)
>>> pixel_values = processor(image, return_tensors="pt").pixel_values

>>> # generate transcription (here we only generate 30 tokens)
>>> outputs = model.generate(
...     pixel_values.to(device),
...     min_length=1,
...     max_new_tokens=30,
...     bad_words_ids=[[processor.tokenizer.unk_token_id]],
... )

>>> sequence = processor.batch_decode(outputs, skip_special_tokens=True)[0]
>>> sequence = processor.post_process_generation(sequence, fix_markdown=False)
>>> # note: we're using repr here such for the sake of printing the \n characters, feel free to just print the sequence
>>> print(repr(sequence))
'\n\n# Nougat: Neural Optical Understanding for Academic Documents\n\n Lukas Blecher\n\nCorrespondence to: lblecher@'
```

è¯·æŸ¥çœ‹[æ¨¡å‹ä¸­å¿ƒ](https://huggingface.co/models?filter=nougat)ä»¥æŸ¥æ‰¾ Nougat æ£€æŸ¥ç‚¹ã€‚

è¯¥æ¨¡å‹åœ¨æ¶æ„ä¸Šä¸ Donut ç›¸åŒã€‚

## NougatImageProcessor

### `class transformers.NougatImageProcessor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L57)

```py
( do_crop_margin: bool = True do_resize: bool = True size: Dict = None resample: Resampling = <Resampling.BILINEAR: 2> do_thumbnail: bool = True do_align_long_axis: bool = False do_pad: bool = True do_rescale: bool = True rescale_factor: Union = 0.00392156862745098 do_normalize: bool = True image_mean: Union = None image_std: Union = None **kwargs )
```

å‚æ•°

+   `do_crop_margin`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦è£å‰ªå›¾åƒè¾¹è·ã€‚

+   `do_resize`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦å°†å›¾åƒçš„ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šçš„`size`ã€‚å¯ä»¥åœ¨`preprocess`æ–¹æ³•ä¸­é€šè¿‡`do_resize`è¿›è¡Œè¦†ç›–ã€‚

+   `size` (`Dict[str, int]` *å¯é€‰*, é»˜è®¤ä¸º `{"height" -- 896, "width": 672}`): è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `size` è¦†ç›–ã€‚

+   `resample` (`PILImageResampling`, *å¯é€‰*, é»˜è®¤ä¸º `Resampling.BILINEAR`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `resample` è¦†ç›–ã€‚

+   `do_thumbnail` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä½¿ç”¨ç¼©ç•¥å›¾æ–¹æ³•è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `do_align_long_axis` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦é€šè¿‡æ—‹è½¬ 90 åº¦æ¥ä½¿å›¾åƒçš„é•¿è½´ä¸ `size` çš„é•¿è½´å¯¹é½ã€‚

+   `do_pad` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†å›¾åƒå¡«å……åˆ°æ‰¹å¤„ç†ä¸­æœ€å¤§çš„å›¾åƒå°ºå¯¸ã€‚

+   `do_rescale` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor` é‡æ–°ç¼©æ”¾å›¾åƒã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_rescale` å‚æ•°è¦†ç›–ã€‚

+   `rescale_factor` (`int` æˆ– `float`, *å¯é€‰*, é»˜è®¤ä¸º `1/255`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `rescale_factor` å‚æ•°è¦†ç›–ã€‚

+   `do_normalize` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_normalize` è¦†ç›–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `IMAGENET_DEFAULT_MEAN`) â€” å¦‚æœå½’ä¸€åŒ–å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„å‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_mean` å‚æ•°è¦†ç›–ã€‚

+   `image_std` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `IMAGENET_DEFAULT_STD`) â€” å›¾åƒæ ‡å‡†å·®ã€‚

æ„å»º Nougat å›¾åƒå¤„ç†å™¨ã€‚

#### `preprocess`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L358)

```py
( images: Union do_crop_margin: bool = None do_resize: bool = None size: Dict = None resample: Resampling = None do_thumbnail: bool = None do_align_long_axis: bool = None do_pad: bool = None do_rescale: bool = None rescale_factor: Union = None do_normalize: bool = None image_mean: Union = None image_std: Union = None return_tensors: Union = None data_format: Optional = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )
```

å‚æ•°

+   `images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒã€‚æœŸæœ›å•ä¸ªå›¾åƒæˆ–æ‰¹å¤„ç†å›¾åƒï¼Œåƒç´ å€¼èŒƒå›´ä¸º 0 åˆ° 255ã€‚

+   `do_crop_margin` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_crop_margin`) â€” æ˜¯å¦è£å‰ªå›¾åƒè¾¹ç¼˜ã€‚

+   `do_resize` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_resize`) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `size` (`Dict[str, int]`, *å¯é€‰*, é»˜è®¤ä¸º `self.size`) â€” è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚å›¾åƒçš„æœ€çŸ­è¾¹è°ƒæ•´ä¸º min(size[â€œheightâ€], size[â€œwidthâ€])ï¼Œæœ€é•¿è¾¹è°ƒæ•´ä»¥ä¿æŒè¾“å…¥çš„é•¿å®½æ¯”ã€‚

+   `resample` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.resample`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚è¿™å¯ä»¥æ˜¯æšä¸¾ `PILImageResampling` ä¸­çš„ä¸€ä¸ªã€‚ä»…å½“ `do_resize` è®¾ç½®ä¸º `True` æ—¶æ‰ä¼šç”Ÿæ•ˆã€‚

+   `do_thumbnail` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_thumbnail`) â€” æ˜¯å¦ä½¿ç”¨ç¼©ç•¥å›¾æ–¹æ³•è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `do_align_long_axis` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_align_long_axis`) â€” æ˜¯å¦é€šè¿‡æ—‹è½¬ 90 åº¦æ¥ä½¿å›¾åƒçš„é•¿è½´ä¸ `size` çš„é•¿è½´å¯¹é½ã€‚

+   `do_pad` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_pad`) â€” æ˜¯å¦å°†å›¾åƒå¡«å……åˆ°æ‰¹å¤„ç†ä¸­æœ€å¤§çš„å›¾åƒå°ºå¯¸ã€‚

+   `do_rescale` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_rescale`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor` é‡æ–°ç¼©æ”¾å›¾åƒã€‚

+   `rescale_factor` (`int` æˆ– `float`, *å¯é€‰*, é»˜è®¤ä¸º `self.rescale_factor`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚

+   `do_normalize` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `self.do_normalize`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `self.image_mean`) â€” ç”¨äºå½’ä¸€åŒ–çš„å›¾åƒå‡å€¼ã€‚

+   `image_std` (`float` æˆ– `List[float]`, *å¯é€‰*, é»˜è®¤ä¸º `self.image_std`) â€” ç”¨äºå½’ä¸€åŒ–çš„å›¾åƒæ ‡å‡†å·®ã€‚

+   `return_tensors` (`str` æˆ– `TensorType`, *å¯é€‰*) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€:

    +   æœªè®¾ç½®: è¿”å› `np.ndarray` çš„åˆ—è¡¨ã€‚

    +   `TensorType.TENSORFLOW` æˆ– `'tf'`: è¿”å›ç±»å‹ä¸º `tf.Tensor` çš„æ‰¹å¤„ç†ã€‚

    +   `TensorType.PYTORCH` æˆ– `'pt'`: è¿”å›ç±»å‹ä¸º `torch.Tensor` çš„æ‰¹å¤„ç†ã€‚

    +   `TensorType.NUMPY` æˆ– `'np'`: è¿”å›ç±»å‹ä¸º `np.ndarray` çš„æ‰¹å¤„ç†ã€‚

    +   `TensorType.JAX` æˆ– `'jax'`: è¿”å›ç±»å‹ä¸º `jax.numpy.ndarray` çš„æ‰¹å¤„ç†ã€‚

+   `data_format` (`ChannelDimension` æˆ– `str`, *optional*, é»˜è®¤ä¸º `ChannelDimension.FIRST`) â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `ChannelDimension.FIRST`: å›¾åƒæ ¼å¼ä¸º (num_channels, height, width)ã€‚

    +   `ChannelDimension.LAST`: å›¾åƒæ ¼å¼ä¸º (height, width, num_channels)ã€‚

    +   æœªè®¾ç½®ï¼šé»˜è®¤ä¸ºè¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚

+   `input_data_format` (`ChannelDimension` æˆ– `str`, *optional*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`: å›¾åƒæ ¼å¼ä¸º (num_channels, height, width)ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`: å›¾åƒæ ¼å¼ä¸º (height, width, num_channels)ã€‚

    +   `"none"` æˆ– `ChannelDimension.NONE`: å›¾åƒæ ¼å¼ä¸º (height, width)ã€‚

é¢„å¤„ç†ä¸€å¼ å›¾ç‰‡æˆ–ä¸€æ‰¹å›¾ç‰‡ã€‚

## NougatTokenizerFast

### `class transformers.NougatTokenizerFast`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L376)

```py
( vocab_file = None tokenizer_file = None clean_up_tokenization_spaces = False unk_token = '<unk>' bos_token = '<s>' eos_token = '</s>' pad_token = '<pad>' **kwargs )
```

å‚æ•°

+   `vocab_file` (`str`, *optional*) â€” [SentencePiece](https://github.com/google/sentencepiece) æ–‡ä»¶ï¼ˆé€šå¸¸å…·æœ‰ .model æ‰©å±•åï¼‰ï¼Œå…¶ä¸­åŒ…å«å®ä¾‹åŒ–åˆ†è¯å™¨æ‰€éœ€çš„è¯æ±‡è¡¨ã€‚

+   `tokenizer_file` (`str`, *optional*) â€” [tokenizers](https://github.com/huggingface/tokenizers) æ–‡ä»¶ï¼ˆé€šå¸¸å…·æœ‰ .json æ‰©å±•åï¼‰ï¼Œå…¶ä¸­åŒ…å«åŠ è½½åˆ†è¯å™¨æ‰€éœ€çš„æ‰€æœ‰å†…å®¹ã€‚

+   `clean_up_tokenization_spaces` (`str`, *optional*, é»˜è®¤ä¸º `False`) â€” è§£ç åæ˜¯å¦æ¸…é™¤ç©ºæ ¼ï¼Œæ¸…é™¤åŒ…æ‹¬åˆ é™¤é¢å¤–ç©ºæ ¼ç­‰æ½œåœ¨ç‘•ç–µã€‚

+   `unk_token` (`str`, *optional*, é»˜è®¤ä¸º `"<unk>"`) â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­ä¸å­˜åœ¨çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸º IDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚

+   `bos_token` (`str`, *optional*, é»˜è®¤ä¸º `"<s>"`) â€” åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨çš„åºåˆ—å¼€å§‹æ ‡è®°ã€‚å¯ç”¨ä½œåºåˆ—åˆ†ç±»å™¨æ ‡è®°ã€‚

+   `eos_token` (`str`, *optional*, é»˜è®¤ä¸º `"</s>"`) â€” åºåˆ—ç»“æŸæ ‡è®°ã€‚

+   `pad_token` (`str`, *optional*, é»˜è®¤ä¸º `"<pad>"`) â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚

+   `model_max_length` (`int`, *optional*) â€” è½¬æ¢å™¨æ¨¡å‹è¾“å…¥çš„æœ€å¤§é•¿åº¦ï¼ˆä»¥æ ‡è®°æ•°è®¡ï¼‰ã€‚å½“ä½¿ç”¨ from_pretrained() åŠ è½½åˆ†è¯å™¨æ—¶ï¼Œå°†è®¾ç½®ä¸ºå­˜å‚¨åœ¨ `max_model_input_sizes` ä¸­çš„ç›¸å…³æ¨¡å‹çš„å€¼ï¼ˆè¯·å‚è§ä¸Šæ–‡ï¼‰ã€‚å¦‚æœæœªæä¾›å€¼ï¼Œå°†é»˜è®¤ä¸º VERY_LARGE_INTEGER (`int(1e30)`ï¼‰ã€‚

+   `padding_side` (`str`, *optional*) â€” æ¨¡å‹åº”ç”¨å¡«å……çš„ä¾§é¢ã€‚åº”åœ¨ ['right', 'left'] ä¸­é€‰æ‹©ã€‚é»˜è®¤å€¼ä»åŒåçš„ç±»å±æ€§ä¸­é€‰æ‹©ã€‚

+   `truncation_side` (`str`, *optional*) â€” æ¨¡å‹åº”ç”¨æˆªæ–­çš„ä¾§é¢ã€‚åº”åœ¨ ['right', 'left'] ä¸­é€‰æ‹©ã€‚é»˜è®¤å€¼ä»åŒåçš„ç±»å±æ€§ä¸­é€‰æ‹©ã€‚

+   `chat_template` (`str`, *optional*) â€” ä¸€ä¸ª Jinja æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–èŠå¤©æ¶ˆæ¯åˆ—è¡¨ã€‚è¯¦ç»†æè¿°è¯·å‚è§ [`huggingface.co/docs/transformers/chat_templating`](https://huggingface.co/docs/transformers/chat_templating)ã€‚

+   `model_input_names` (`List[string]`, *optional*) â€” æ¨¡å‹å‰å‘ä¼ é€’æ¥å—çš„è¾“å…¥åˆ—è¡¨ï¼ˆå¦‚ `"token_type_ids"` æˆ– `"attention_mask"`ï¼‰ã€‚é»˜è®¤å€¼ä»åŒåçš„ç±»å±æ€§ä¸­é€‰æ‹©ã€‚

+   `bos_token` (`str` æˆ– `tokenizers.AddedToken`, *optional*) â€” è¡¨ç¤ºå¥å­å¼€å¤´çš„ç‰¹æ®Šæ ‡è®°ã€‚å°†ä¸ `self.bos_token` å’Œ `self.bos_token_id` å…³è”ã€‚

+   `eos_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨å¥å­ç»“æŸçš„ç‰¹æ®Šæ ‡è®°ã€‚å°†ä¸`self.eos_token`å’Œ`self.eos_token_id`ç›¸å…³è”ã€‚

+   `unk_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨è¯æ±‡å¤–æ ‡è®°çš„ç‰¹æ®Šæ ‡è®°ã€‚å°†ä¸`self.unk_token`å’Œ`self.unk_token_id`ç›¸å…³è”ã€‚

+   `sep_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºåœ¨åŒä¸€è¾“å…¥ä¸­åˆ†éš”ä¸¤ä¸ªä¸åŒå¥å­çš„ç‰¹æ®Šæ ‡è®°ï¼ˆä¾‹å¦‚ BERT ä½¿ç”¨ï¼‰ã€‚å°†ä¸`self.sep_token`å’Œ`self.sep_token_id`ç›¸å…³è”ã€‚

+   `pad_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿æ ‡è®°æ•°ç»„å¤§å°ç›¸åŒä»¥è¿›è¡Œæ‰¹å¤„ç†çš„ç‰¹æ®Šæ ‡è®°ã€‚ç„¶åå°†è¢«æ³¨æ„æœºåˆ¶æˆ–æŸå¤±è®¡ç®—å¿½ç•¥ã€‚å°†ä¸`self.pad_token`å’Œ`self.pad_token_id`ç›¸å…³è”ã€‚

+   `cls_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨è¾“å…¥ç±»åˆ«çš„ç‰¹æ®Šæ ‡è®°ï¼ˆä¾‹å¦‚ BERT ä½¿ç”¨ï¼‰ã€‚å°†ä¸`self.cls_token`å’Œ`self.cls_token_id`ç›¸å…³è”ã€‚

+   `mask_token`ï¼ˆ`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä»£è¡¨æ©ç æ ‡è®°çš„ç‰¹æ®Šæ ‡è®°ï¼ˆç”¨äºæ©ç è¯­è¨€å»ºæ¨¡é¢„è®­ç»ƒç›®æ ‡ï¼Œå¦‚ BERTï¼‰ã€‚å°†ä¸`self.mask_token`å’Œ`self.mask_token_id`ç›¸å…³è”ã€‚

+   `additional_special_tokens`ï¼ˆå…ƒç»„æˆ–`str`æˆ–`tokenizers.AddedToken`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ç»„é¢å¤–çš„ç‰¹æ®Šæ ‡è®°ã€‚åœ¨è¿™é‡Œæ·»åŠ å®ƒä»¬ä»¥ç¡®ä¿åœ¨å°†`skip_special_tokens`è®¾ç½®ä¸º True æ—¶è§£ç æ—¶è·³è¿‡å®ƒä»¬ã€‚å¦‚æœå®ƒä»¬ä¸æ˜¯è¯æ±‡çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒä»¬å°†è¢«æ·»åŠ åˆ°è¯æ±‡çš„æœ«å°¾ã€‚

+   `clean_up_tokenization_spaces`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ¨¡å‹æ˜¯å¦åº”æ¸…é™¤åœ¨æ ‡è®°åŒ–è¿‡ç¨‹ä¸­æ‹†åˆ†è¾“å…¥æ–‡æœ¬æ—¶æ·»åŠ çš„ç©ºæ ¼ã€‚

+   `split_special_tokens`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦åœ¨æ ‡è®°åŒ–è¿‡ç¨‹ä¸­æ‹†åˆ†ç‰¹æ®Šæ ‡è®°ã€‚é»˜è®¤è¡Œä¸ºæ˜¯ä¸æ‹†åˆ†ç‰¹æ®Šæ ‡è®°ã€‚è¿™æ„å‘³ç€å¦‚æœ`<s>`æ˜¯`bos_token`ï¼Œé‚£ä¹ˆ`tokenizer.tokenize("<s>") = ['<s>`]`ã€‚å¦åˆ™ï¼Œå¦‚æœ`split_special_tokens=True`ï¼Œé‚£ä¹ˆ`tokenizer.tokenize("<s>")`å°†ç»™å‡º`['<', 's', '>']`ã€‚æ­¤å‚æ•°ç›®å‰ä»…æ”¯æŒ`slow`åˆ†è¯å™¨ã€‚

+   `tokenizer_object`ï¼ˆ`tokenizers.Tokenizer`ï¼‰â€” æ¥è‡ªğŸ¤— tokenizers çš„`tokenizers.Tokenizer`å¯¹è±¡ï¼Œç”¨äºå®ä¾‹åŒ–ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ä½¿ç”¨ğŸ¤— tokenizers ä¸­çš„åˆ†è¯å™¨ã€‚

+   `tokenizer_file`ï¼ˆ`str`ï¼‰â€” ä»£è¡¨ä»¥å‰åºåˆ—åŒ–çš„`tokenizers.Tokenizer`å¯¹è±¡çš„æœ¬åœ° JSON æ–‡ä»¶çš„è·¯å¾„ã€‚

Nougat çš„å¿«é€Ÿåˆ†è¯å™¨ï¼ˆç”± HuggingFace åˆ†è¯å™¨åº“æ”¯æŒï¼‰ã€‚

è¿™ä¸ªåˆ†è¯å™¨ç»§æ‰¿è‡ª PreTrainedTokenizerFastï¼Œå…¶ä¸­åŒ…å«å¤§å¤šæ•°ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒè¿™ä¸ªè¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚è¿™ä¸ªç±»ä¸»è¦ä¸ºåå¤„ç†ç”Ÿæˆçš„æ–‡æœ¬æ·»åŠ äº† Nougat ç‰¹å®šçš„æ–¹æ³•ã€‚

ç±»å±æ€§ï¼ˆç”±æ´¾ç”Ÿç±»è¦†ç›–ï¼‰

+   `vocab_files_names`ï¼ˆ`Dict[str, str]`ï¼‰â€” ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®æ˜¯æ¨¡å‹æ‰€éœ€çš„æ¯ä¸ªè¯æ±‡æ–‡ä»¶çš„`__init__`å…³é”®å­—åç§°ï¼Œå…¶ç›¸å…³å€¼æ˜¯ç”¨äºä¿å­˜ç›¸å…³æ–‡ä»¶çš„æ–‡ä»¶åï¼ˆå­—ç¬¦ä¸²ï¼‰ã€‚

+   `pretrained_vocab_files_map`ï¼ˆ`Dict[str, Dict[str, str]]`ï¼‰â€” ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é«˜çº§é”®æ˜¯æ¨¡å‹æ‰€éœ€çš„æ¯ä¸ªè¯æ±‡æ–‡ä»¶çš„`__init__`å…³é”®å­—åç§°ï¼Œä½çº§åˆ«æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„`short-cut-names`ï¼Œä½œä¸ºç›¸å…³å€¼ï¼Œæ˜¯ä¸ç›¸å…³é¢„è®­ç»ƒè¯æ±‡æ–‡ä»¶ç›¸å…³è”çš„`url`ã€‚

+   `max_model_input_sizes`ï¼ˆ`Dict[str, Optional[int]]`ï¼‰â€” ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„`short-cut-names`ï¼Œå…¶ç›¸å…³å€¼æ˜¯è¯¥æ¨¡å‹çš„åºåˆ—è¾“å…¥çš„æœ€å¤§é•¿åº¦ï¼Œå¦‚æœæ¨¡å‹æ²¡æœ‰æœ€å¤§è¾“å…¥å¤§å°ï¼Œåˆ™ä¸º`None`ã€‚

+   `pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) â€” ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºé¢„è®­ç»ƒæ¨¡å‹çš„`short-cut-names`ï¼Œå€¼ä¸ºä¼ é€’ç»™åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æ—¶ tokenizer ç±»çš„`__init__`æ–¹æ³•çš„ç‰¹å®šå‚æ•°çš„å­—å…¸ã€‚

+   `model_input_names` (`List[str]`) â€” æ¨¡å‹å‰å‘ä¼ é€’ä¸­é¢„æœŸçš„è¾“å…¥åˆ—è¡¨ã€‚

+   `padding_side` (`str`) â€” æ¨¡å‹åº”è¯¥åº”ç”¨å¡«å……çš„é»˜è®¤å€¼ã€‚åº”ä¸º`'right'`æˆ–`'left'`ã€‚

+   `truncation_side` (`str`) â€” æ¨¡å‹åº”è¯¥åº”ç”¨æˆªæ–­çš„é»˜è®¤å€¼ã€‚åº”ä¸º`'right'`æˆ–`'left'`ã€‚

#### `correct_tables`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L470)

```py
( generation: str ) â†’ export const metadata = 'undefined';str
```

å‚æ•°

+   `generation` (str) â€” è¦è¿›è¡Œåå¤„ç†çš„ç”Ÿæˆæ–‡æœ¬ã€‚

è¿”å›

str

åå¤„ç†çš„æ–‡æœ¬ã€‚

æ¥å—ä¸€ä¸ªç”Ÿæˆçš„å­—ç¬¦ä¸²ï¼Œå¹¶ä¿®å¤è¡¨æ ¼/è¡¨æ ¼ï¼Œä½¿å…¶ç¬¦åˆæ‰€éœ€çš„ Markdown æ ¼å¼ã€‚

ç¤ºä¾‹ï¼š

```py
correct_tables("\begin{table} \begin{tabular}{l l} & \ \end{tabular} \end{table}")
"\begin{table}
abular}{l l} & \ \end{tabular}
le}"
```

#### `post_process_generation`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L600)

```py
( generation: Union fix_markdown: bool = True num_workers: int = None ) â†’ export const metadata = 'undefined';Union[str, List[str]]
```

å‚æ•°

+   `generation` (Union[str, List[str]]) â€” ç”Ÿæˆçš„æ–‡æœ¬æˆ–ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨ã€‚

+   `fix_markdown` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æ‰§è¡Œ Markdown æ ¼å¼ä¿®å¤ã€‚

+   `num_workers` (`int`, *å¯é€‰*) â€” ä¼ é€’ç»™åˆ©ç”¨å¤šè¿›ç¨‹çš„å·¥ä½œäººå‘˜æ•°é‡ï¼ˆå¹¶è¡Œåå¤„ç†å¤šä¸ªæ–‡æœ¬ï¼‰ã€‚

è¿”å›

Union[str, List[str]]

åå¤„ç†çš„æ–‡æœ¬æˆ–åå¤„ç†æ–‡æœ¬åˆ—è¡¨ã€‚

åå¤„ç†ç”Ÿæˆçš„æ–‡æœ¬æˆ–ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨ã€‚

æ­¤å‡½æ•°å¯ç”¨äºå¯¹ç”Ÿæˆçš„æ–‡æœ¬æ‰§è¡Œåå¤„ç†ï¼Œä¾‹å¦‚ä¿®å¤ Markdown æ ¼å¼ã€‚

åå¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨å¤šè¿›ç¨‹åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚

#### `post_process_single`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L505)

```py
( generation: str fix_markdown: bool = True ) â†’ export const metadata = 'undefined';str
```

å‚æ•°

+   `generation` (str) â€” è¦è¿›è¡Œåå¤„ç†çš„ç”Ÿæˆæ–‡æœ¬ã€‚

+   `fix_markdown` (bool, optional) â€” æ˜¯å¦æ‰§è¡Œ Markdown æ ¼å¼ä¿®å¤ã€‚é»˜è®¤ä¸º Trueã€‚

è¿”å›

str

åå¤„ç†çš„æ–‡æœ¬ã€‚

åå¤„ç†å•ä¸ªç”Ÿæˆçš„æ–‡æœ¬ã€‚æ­¤å¤„ä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥æ¥è‡ª Nougat æ–‡ç« ä½œè€…ã€‚è¿™äº›è¡¨è¾¾å¼å·²ç»è¿‡æ³¨é‡Šä»¥ç¡®ä¿æ¸…æ™°ï¼Œå¹¶åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¿›è¡Œäº†ç«¯åˆ°ç«¯æµ‹è¯•ã€‚

#### `remove_hallucinated_references`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L440)

```py
( text: str ) â†’ export const metadata = 'undefined';str
```

å‚æ•°

+   `text` (`str`) â€” åŒ…å«å¼•ç”¨çš„è¾“å…¥æ–‡æœ¬ã€‚

è¿”å›

`str`

åˆ é™¤è™šæ„å¼•ç”¨çš„æ–‡æœ¬ã€‚

ä»æ–‡æœ¬ä¸­åˆ é™¤è™šæ„æˆ–ç¼ºå¤±çš„å¼•ç”¨ã€‚

æ­¤å‡½æ•°è¯†åˆ«å¹¶åˆ é™¤è¾“å…¥æ–‡æœ¬ä¸­æ ‡è®°ä¸ºç¼ºå¤±æˆ–è™šæ„çš„å¼•ç”¨ã€‚

## NougatProcessor

### `class transformers.NougatProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L27)

```py
( image_processor tokenizer )
```

å‚æ•°

+   `image_processor` (NougatImageProcessor) â€” ä¸€ä¸ª NougatImageProcessor çš„å®ä¾‹ã€‚å›¾åƒå¤„ç†å™¨æ˜¯å¿…éœ€çš„è¾“å…¥ã€‚

+   `tokenizer` (NougatTokenizerFast) â€” ä¸€ä¸ª NougatTokenizerFast çš„å®ä¾‹ã€‚åˆ†è¯å™¨æ˜¯å¿…éœ€çš„è¾“å…¥ã€‚

æ„å»ºä¸€ä¸ª Nougat å¤„ç†å™¨ï¼Œå°† Nougat å›¾åƒå¤„ç†å™¨å’Œ Nougat tokenizer åŒ…è£…æˆä¸€ä¸ªå•ä¸€å¤„ç†å™¨ã€‚

NougatProcessor æä¾›äº† NougatImageProcessor å’Œ NougatTokenizerFast çš„æ‰€æœ‰åŠŸèƒ½ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ **call**() å’Œ decode()ã€‚ 

#### `__call__`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L49)

```py
( images = None text = None do_crop_margin: bool = None do_resize: bool = None size: Dict = None resample: PILImageResampling = None do_thumbnail: bool = None do_align_long_axis: bool = None do_pad: bool = None do_rescale: bool = None rescale_factor: Union = None do_normalize: bool = None image_mean: Union = None image_std: Union = None data_format: Optional = 'channels_first' input_data_format: Union = None text_pair: Union = None text_target: Union = None text_pair_target: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 is_split_into_words: bool = False pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True )
```

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)

```py
( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`) â€” è¿™å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„ *æ¨¡å‹ id*ï¼Œæ‰˜ç®¡åœ¨ huggingface.co ä¸Šçš„æ¨¡å‹å­˜å‚¨åº“ä¸­ã€‚æœ‰æ•ˆçš„æ¨¡å‹ id å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚ `bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚ `dbmdz/bert-base-german-cased`ã€‚

    +   ä¸€ä¸ªåŒ…å«ä½¿ç”¨ save_pretrained() æ–¹æ³•ä¿å­˜çš„ç‰¹å¾æå–å™¨æ–‡ä»¶çš„ *ç›®å½•* è·¯å¾„ï¼Œä¾‹å¦‚ `./my_model_directory/`ã€‚

    +   å·²ä¿å­˜çš„ç‰¹å¾æå–å™¨ JSON *æ–‡ä»¶* çš„è·¯å¾„æˆ– URLï¼Œä¾‹å¦‚ `./my_model_directory/preprocessor_config.json`ã€‚**kwargs â€” ä¼ é€’ç»™ from_pretrained() å’Œ `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å®ä¾‹åŒ–ä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸å…³è”çš„å¤„ç†å™¨ã€‚

è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ç‰¹å¾æå–å™¨ from_pretrained()ã€å›¾åƒå¤„ç†å™¨ ImageProcessingMixin å’Œåˆ†è¯å™¨ `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` æ–¹æ³•ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚

#### `save_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)

```py
( save_directory push_to_hub: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str` or `os.PathLike`) â€” å°†ä¿å­˜ç‰¹å¾æå–å™¨ JSON æ–‡ä»¶å’Œåˆ†è¯å™¨æ–‡ä»¶çš„ç›®å½•ï¼ˆå¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™å°†åˆ›å»ºï¼‰ã€‚

+   `push_to_hub` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨ä¿å­˜æ¨¡å‹åå°†å…¶æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`, *optional*) â€” ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†æ­¤å¤„ç†å™¨çš„å±æ€§ï¼ˆç‰¹å¾æå–å™¨ã€åˆ†è¯å™¨ç­‰ï¼‰ä¿å­˜åœ¨æŒ‡å®šçš„ç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained() æ–¹æ³•é‡æ–°åŠ è½½ã€‚

è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ save_pretrained() å’Œ save_pretrained()ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚

#### `batch_decode`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L141)

```py
( *args **kwargs )
```

è¿™ä¸ªæ–¹æ³•å°†æ‰€æœ‰å‚æ•°è½¬å‘ç»™ NougatTokenizer çš„ batch_decode()ã€‚è¯·å‚è€ƒæ­¤æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

#### `è§£ç `

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L148)

```py
( *args **kwargs )
```

è¿™ä¸ªæ–¹æ³•å°†æ‰€æœ‰å‚æ•°è½¬å‘ç»™ NougatTokenizer çš„ decode()ã€‚è¯·å‚è€ƒæ­¤æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

#### `åå¤„ç†ç”Ÿæˆ`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L155)

```py
( *args **kwargs )
```

è¿™ä¸ªæ–¹æ³•å°†æ‰€æœ‰å‚æ•°è½¬å‘ç»™ NougatTokenizer çš„`~PreTrainedTokenizer.post_process_generation`ã€‚è¯·å‚è€ƒæ­¤æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
