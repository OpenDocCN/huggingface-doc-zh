# 填充和截断

> 原文链接：[`huggingface.co/docs/transformers/v4.37.2/en/pad_truncation`](https://huggingface.co/docs/transformers/v4.37.2/en/pad_truncation)

批量输入通常具有不同的长度，因此无法转换为固定大小的张量。填充和截断是处理此问题的策略，以从不同长度的批次创建矩形张量。填充添加一个特殊的**填充标记**，以确保较短的序列将具有与批次中最长序列或模型接受的最大长度相同的长度。截断则是截断长序列。

在大多数情况下，将批次填充到最长序列的长度，并截断到模型可以接受的最大长度通常效果很好。但是，如果需要，API 支持更多策略。您需要的三个参数是：`padding`，`truncation`和`max_length`。

`padding`参数控制填充。它可以是布尔值或字符串：

+   `True`或`'longest'`：填充到批次中最长的序列（如果只提供单个序列，则不会应用填充）。

+   `'max_length'`：通过`max_length`参数指定的长度填充，或者如果没有提供`max_length`，则填充到模型接受的最大长度（`max_length=None`）。如果只提供单个序列，仍将应用填充。

+   `False`或`'do_not_pad'`：不会应用填充。这是默认行为。

`truncation`参数控制截断。它可以是布尔值或字符串：

+   `True`或`'longest_first'`：通过`max_length`参数指定的最大长度截断，或者如果没有提供`max_length`，则截断到模型接受的最大长度（`max_length=None`）。这将逐标记截断，从一对中最长的序列中删除一个标记，直到达到适当的长度。

+   `'only_second'`：通过`max_length`参数指定的最大长度截断，或者如果没有提供`max_length`，则截断到模型接受的最大长度（`max_length=None`）。如果提供了一对序列（或一批序列对），则只会截断第二句。

+   `'only_first'`: 通过`max_length`参数指定的最大长度截断，或者如果没有提供`max_length`，则截断到模型接受的最大长度（`max_length=None`）。如果提供了一对序列（或一批序列对），则只会截断第一句。

+   `False`或`'do_not_truncate'`：不会应用截断。这是默认行为。

`max_length`参数控制填充和截断的长度。它可以是整数或`None`，在这种情况下，它将默认为模型可以接受的最大长度。如果模型没有特定的最大输入长度，截断或填充到`max_length`将被禁用。

以下表格总结了设置填充和截断的推荐方式。如果在以下示例中使用输入序列对，可以将`truncation=True`替换为在`['only_first', 'only_second', 'longest_first']`中选择的`STRATEGY`，即`truncation='only_second'`或`truncation='longest_first'`以控制如前所述截断一对中的两个序列。

| 截断 | 填充 | 指令 |
| --- | --- | --- |
| 无截断 | 无填充 | `tokenizer(batch_sentences)` |
|  | 填充到批次中的最大序列 | `tokenizer(batch_sentences, padding=True)`或 |
|  |  | `tokenizer(batch_sentences, padding='longest')` |
|  | 填充到最大模型输入长度 | `tokenizer(batch_sentences, padding='max_length')` |
|  | 填充到特定长度 | `tokenizer(batch_sentences, padding='max_length', max_length=42)` |
|  | 填充到值的倍数 | `tokenizer(batch_sentences, padding=True, pad_to_multiple_of=8)` |
| 截断到最大模型输入长度 | 无填充 | `tokenizer(batch_sentences, truncation=True)`或 |
|  |  | `tokenizer(batch_sentences, truncation=STRATEGY)` |
|  | 填充到批次中的最大序列长度 | `tokenizer(batch_sentences, padding=True, truncation=True)` 或 |
|  |  | `tokenizer(batch_sentences, padding=True, truncation=STRATEGY)` |
|  | 填充到最大模型输入长度 | `tokenizer(batch_sentences, padding='max_length', truncation=True)` 或 |
|  |  | `tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY)` |
|  | 填充到特定长度 | 不可能 |
| 截断到特定长度 | 不填充 | `tokenizer(batch_sentences, truncation=True, max_length=42)` 或 |
|  |  | `tokenizer(batch_sentences, truncation=STRATEGY, max_length=42)` |
|  | 填充到批次中的最大序列长度 | `tokenizer(batch_sentences, padding=True, truncation=True, max_length=42)` 或 |
|  |  | `tokenizer(batch_sentences, padding=True, truncation=STRATEGY, max_length=42)` |
|  | 填充到最大模型输入长度 | 不可能 |
|  | 填充到特定长度 | `tokenizer(batch_sentences, padding='max_length', truncation=True, max_length=42)` 或 |
|  |  | `tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY, max_length=42)` |
