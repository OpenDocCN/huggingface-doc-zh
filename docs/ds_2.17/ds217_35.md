# å¤„ç†å›¾åƒæ•°æ®

> åŽŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/datasets/image_process`](https://huggingface.co/docs/datasets/image_process)

æœ¬æŒ‡å—å±•ç¤ºäº†å¤„ç†å›¾åƒæ•°æ®é›†çš„å…·ä½“æ–¹æ³•ã€‚å­¦ä¹ å¦‚ä½•ï¼š

+   ä½¿ç”¨ map()å¤„ç†å›¾åƒæ•°æ®é›†ã€‚

+   ä½¿ç”¨ set_transform()å°†æ•°æ®å¢žå¼ºåº”ç”¨åˆ°æ•°æ®é›†ä¸­ã€‚

æœ‰å…³å¦‚ä½•å¤„ç†ä»»ä½•ç±»åž‹çš„æ•°æ®é›†çš„æŒ‡å—ï¼Œè¯·æŸ¥çœ‹é€šç”¨å¤„ç†æŒ‡å—ã€‚

## æ˜ å°„

map()å‡½æ•°å¯ä»¥åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨å˜æ¢ã€‚

ä¾‹å¦‚ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„[`Resize`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html)å‡½æ•°ï¼š

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [image.convert("RGB").resize((100,100)) for image in examples["image"]]
...     return examples
```

çŽ°åœ¨ä½¿ç”¨ map()å‡½æ•°è°ƒæ•´æ•´ä¸ªæ•°æ®é›†çš„å¤§å°ï¼Œå¹¶è®¾ç½®`batched=True`ä»¥é€šè¿‡æŽ¥å—ç¤ºä¾‹æ‰¹æ¬¡åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚è¯¥å˜æ¢å°†`pixel_values`ä½œä¸ºå¯ç¼“å­˜çš„`PIL.Image`å¯¹è±¡è¿”å›žï¼š

```py
>>> dataset = dataset.map(transforms, remove_columns=["image"], batched=True)
>>> dataset[0]
{'label': 6,
 'pixel_values': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=100x100 at 0x7F058237BB10>}
```

ç¼“å­˜æ–‡ä»¶å¯ä»¥èŠ‚çœæ—¶é—´ï¼Œå› ä¸ºæ‚¨ä¸å¿…æ‰§è¡Œç›¸åŒçš„å˜æ¢ä¸¤æ¬¡ã€‚map()å‡½æ•°æœ€é€‚åˆæ‚¨æ¯æ¬¡è®­ç»ƒåªè¿è¡Œä¸€æ¬¡çš„æ“ä½œï¼Œæ¯”å¦‚è°ƒæ•´å›¾åƒå¤§å°ï¼Œè€Œä¸æ˜¯ç”¨äºŽæ¯ä¸ª epoch æ‰§è¡Œçš„æ“ä½œï¼Œæ¯”å¦‚æ•°æ®å¢žå¼ºã€‚

map()ä¼šå ç”¨ä¸€äº›å†…å­˜ï¼Œä½†æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‚æ•°å‡å°‘å…¶å†…å­˜éœ€æ±‚ï¼š

+   `batch_size`ç¡®å®šåœ¨ä¸€æ¬¡è°ƒç”¨å˜æ¢å‡½æ•°ä¸­å¤„ç†çš„ç¤ºä¾‹æ•°é‡ã€‚

+   `writer_batch_size`ç¡®å®šåœ¨å°†å…¶å­˜å‚¨ä¹‹å‰åœ¨å†…å­˜ä¸­ä¿ç•™çš„å·²å¤„ç†ç¤ºä¾‹æ•°é‡ã€‚

è¿™ä¸¤ä¸ªå‚æ•°å€¼é»˜è®¤ä¸º 1000ï¼Œå¦‚æžœæ‚¨è¦å­˜å‚¨å›¾åƒï¼Œè¿™å¯èƒ½ä¼šå¾ˆæ˜‚è´µã€‚é™ä½Žè¿™äº›å€¼ä»¥åœ¨ä½¿ç”¨ map()æ—¶ä½¿ç”¨æ›´å°‘çš„å†…å­˜ã€‚

## åº”ç”¨å˜æ¢

ðŸ¤— æ•°æ®é›†å¯ä»¥å°†ä»»ä½•åº“æˆ–åŒ…ä¸­çš„æ•°æ®å¢žå¼ºåº”ç”¨åˆ°æ‚¨çš„æ•°æ®é›†ä¸­ã€‚å˜æ¢å¯ä»¥åœ¨æ•°æ®æ‰¹æ¬¡ä¸Šå®žæ—¶åº”ç”¨ï¼Œä½¿ç”¨ set_transform()ï¼Œè¿™æ ·å¯ä»¥å‡å°‘ç£ç›˜ç©ºé—´çš„ä½¿ç”¨ã€‚

ä»¥ä¸‹ç¤ºä¾‹ä½¿ç”¨[torchvision](https://pytorch.org/vision/stable/index.html)ï¼Œä½†ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–æ•°æ®å¢žå¼ºåº“ï¼Œå¦‚[Albumentations](https://albumentations.ai/docs/)ã€[Kornia](https://kornia.readthedocs.io/en/latest/)å’Œ[imgaug](https://imgaug.readthedocs.io/en/latest/)ã€‚

ä¾‹å¦‚ï¼Œå¦‚æžœæ‚¨æƒ³éšæœºæ›´æ”¹å›¾åƒçš„é¢œè‰²å±žæ€§ï¼š

```py
>>> from torchvision.transforms import Compose, ColorJitter, ToTensor

>>> jitter = Compose(
...     [
...          ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.7),
...          ToTensor(),
...     ]
... )
```

åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥åº”ç”¨`ColorJitter`å˜æ¢ï¼š

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
...     return examples
```

ä½¿ç”¨ set_transform()å‡½æ•°åº”ç”¨å˜æ¢ï¼š

```py
>>> dataset.set_transform(transforms)
```
