# åœ¨ Amazon SageMaker ä¸Šè®­ç»ƒå’Œéƒ¨ç½² Hugging Face

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/sagemaker/getting-started`](https://huggingface.co/docs/sagemaker/getting-started)

å…¥é—¨æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åœ¨ Amazon SageMaker ä¸Šå¿«é€Ÿä½¿ç”¨ Hugging Faceã€‚å­¦ä¹ å¦‚ä½•åœ¨ SageMaker ä¸Šä¸ºäºŒè¿›åˆ¶æ–‡æœ¬åˆ†ç±»ä»»åŠ¡å¾®è°ƒå’Œéƒ¨ç½²é¢„è®­ç»ƒçš„ğŸ¤— Transformers æ¨¡å‹ã€‚

ğŸ’¡ å¦‚æœæ‚¨æ˜¯ Hugging Face çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬å»ºè®®å…ˆé˜…è¯»ğŸ¤— Transformers çš„[å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/transformers/quicktour)ã€‚

[`www.youtube.com/embed/pYqjCzoyWyo`](https://www.youtube.com/embed/pYqjCzoyWyo)

ğŸ““ æ‰“å¼€[notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb)è¿›è¡Œè·Ÿéšï¼

## å®‰è£…å’Œè®¾ç½®

é€šè¿‡å®‰è£…å¿…è¦çš„ Hugging Face åº“å’Œ SageMaker æ¥å¼€å§‹ã€‚å¦‚æœæ‚¨å°šæœªå®‰è£…ï¼Œè¿˜éœ€è¦å®‰è£…[PyTorch](https://pytorch.org/get-started/locally/)å’Œ[TensorFlow](https://www.tensorflow.org/install/pip#tensorflow-2-packages-are-available)ã€‚

```py
pip install "sagemaker>=2.140.0" "transformers==4.26.1" "datasets[s3]==2.10.1" --upgrade
```

å¦‚æœæ‚¨æƒ³åœ¨[SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html)ä¸­è¿è¡Œæ­¤ç¤ºä¾‹ï¼Œè¯·å‡çº§[ipywidgets](https://ipywidgets.readthedocs.io/en/latest/)ä»¥é…åˆğŸ¤— Datasets åº“ï¼Œå¹¶é‡æ–°å¯åŠ¨å†…æ ¸ï¼š

```py
%%capture
import IPython
!conda install -c conda-forge ipywidgets -y
IPython.Application.instance().kernel.do_shutdown(True)
```

æ¥ä¸‹æ¥ï¼Œæ‚¨åº”è¯¥è®¾ç½®æ‚¨çš„ç¯å¢ƒï¼šä¸€ä¸ª SageMaker ä¼šè¯å’Œä¸€ä¸ª S3 å­˜å‚¨æ¡¶ã€‚S3 å­˜å‚¨æ¡¶å°†å­˜å‚¨æ•°æ®ã€æ¨¡å‹å’Œæ—¥å¿—ã€‚æ‚¨éœ€è¦è®¿é—®ä¸€ä¸ªå…·æœ‰æ‰€éœ€æƒé™çš„[IAM æ‰§è¡Œè§’è‰²](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)ã€‚

å¦‚æœæ‚¨è®¡åˆ’åœ¨æœ¬åœ°ç¯å¢ƒä¸­ä½¿ç”¨ SageMakerï¼Œæ‚¨éœ€è¦è‡ªå·±æä¾›`role`ã€‚äº†è§£å¦‚ä½•è®¾ç½®è¯·æŸ¥çœ‹[è¿™é‡Œ](https://huggingface.co/docs/sagemaker/train#installation-and-setup)ã€‚

âš ï¸ åªæœ‰åœ¨ SageMaker å†…è¿è¡Œç¬”è®°æœ¬æ—¶æ‰å¯ç”¨æ‰§è¡Œè§’è‰²ã€‚å¦‚æœæ‚¨å°è¯•åœ¨ä¸åœ¨ SageMaker ä¸Šè¿è¡Œçš„ç¬”è®°æœ¬ä¸­è¿è¡Œ`get_execution_role`ï¼Œæ‚¨å°†æ”¶åˆ°åŒºåŸŸé”™è¯¯ã€‚

```py
import sagemaker

sess = sagemaker.Session()
sagemaker_session_bucket = None
if sagemaker_session_bucket is None and sess is not None:
    sagemaker_session_bucket = sess.default_bucket()

role = sagemaker.get_execution_role()
sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)
```

## é¢„å¤„ç†

ğŸ¤— Datasets åº“ä½¿ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®é›†å˜å¾—å®¹æ˜“ã€‚ä¸‹è½½å’Œæ ‡è®°[IMDb](https://huggingface.co/datasets/imdb)æ•°æ®é›†ï¼š

```py
from datasets import load_dataset
from transformers import AutoTokenizer

# load dataset
train_dataset, test_dataset = load_dataset("imdb", split=["train", "test"])

# load tokenizer
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

# create tokenization function
def tokenize(batch):
    return tokenizer(batch["text"], padding="max_length", truncation=True)

# tokenize train and test datasets
train_dataset = train_dataset.map(tokenize, batched=True)
test_dataset = test_dataset.map(tokenize, batched=True)

# set dataset format for PyTorch
train_dataset =  train_dataset.rename_column("label", "labels")
train_dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])
test_dataset = test_dataset.rename_column("label", "labels")
test_dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])
```

## å°†æ•°æ®é›†ä¸Šä¼ åˆ° S3 å­˜å‚¨æ¡¶

æ¥ä¸‹æ¥ï¼Œä½¿ç”¨ğŸ¤— Datasets S3 [æ–‡ä»¶ç³»ç»Ÿ](https://huggingface.co/docs/datasets/filesystems.html)å®ç°å°†é¢„å¤„ç†çš„æ•°æ®é›†ä¸Šä¼ åˆ°æ‚¨çš„ S3 ä¼šè¯å­˜å‚¨æ¡¶ä¸­ï¼š

```py
# save train_dataset to s3
training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'
train_dataset.save_to_disk(training_input_path)

# save test_dataset to s3
test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test'
test_dataset.save_to_disk(test_input_path)
```

## å¼€å§‹è®­ç»ƒä½œä¸š

åˆ›å»ºä¸€ä¸ª Hugging Face Estimator æ¥å¤„ç†ç«¯åˆ°ç«¯çš„ SageMaker è®­ç»ƒå’Œéƒ¨ç½²ã€‚éœ€è¦æ³¨æ„çš„æœ€é‡è¦çš„å‚æ•°æ˜¯ï¼š

+   `entry_point`æŒ‡çš„æ˜¯æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/scripts/train.py)æ‰¾åˆ°çš„å¾®è°ƒè„šæœ¬ã€‚

+   `instance_type`æŒ‡çš„æ˜¯å°†å¯åŠ¨çš„ SageMaker å®ä¾‹ã€‚æŸ¥çœ‹[è¿™é‡Œ](https://aws.amazon.com/sagemaker/pricing/)ä»¥è·å–å®Œæ•´çš„å®ä¾‹ç±»å‹åˆ—è¡¨ã€‚

+   `è¶…å‚æ•°`æŒ‡çš„æ˜¯æ¨¡å‹å°†è¿›è¡Œå¾®è°ƒçš„è®­ç»ƒè¶…å‚æ•°ã€‚

```py
from sagemaker.huggingface import HuggingFace

hyperparameters={
    "epochs": 1,                            # number of training epochs
    "train_batch_size": 32,                 # training batch size
    "model_name":"distilbert-base-uncased"  # name of pretrained model
}

huggingface_estimator = HuggingFace(
    entry_point="train.py",                 # fine-tuning script to use in training job
    source_dir="./scripts",                 # directory where fine-tuning script is stored
    instance_type="ml.p3.2xlarge",          # instance type
    instance_count=1,                       # number of instances
    role=role,                              # IAM role used in training job to acccess AWS resources (S3)
    transformers_version="4.26",             # Transformers version
    pytorch_version="1.13",                  # PyTorch version
    py_version="py39",                      # Python version
    hyperparameters=hyperparameters         # hyperparameters to use in training job
)
```

ä¸€è¡Œä»£ç å¼€å§‹è®­ç»ƒï¼š

```py
huggingface_estimator.fit({"train": training_input_path, "test": test_input_path})
```

## éƒ¨ç½²æ¨¡å‹

ä¸€æ—¦è®­ç»ƒä½œä¸šå®Œæˆï¼Œé€šè¿‡è°ƒç”¨`deploy()`éƒ¨ç½²æ‚¨çš„å¾®è°ƒæ¨¡å‹ï¼ŒæŒ‡å®šå®ä¾‹æ•°é‡å’Œå®ä¾‹ç±»å‹ï¼š

```py
predictor = huggingface_estimator.deploy(initial_instance_count=1,"ml.g4dn.xlarge")
```

åœ¨æ‚¨çš„æ•°æ®ä¸Šè°ƒç”¨`predict()`ï¼š

```py
sentiment_input = {"inputs": "It feels like a curtain closing...there was an elegance in the way they moved toward conclusion. No fan is going to watch and feel short-changed."}

predictor.predict(sentiment_input)
```

è¿è¡Œå®Œæ‚¨çš„è¯·æ±‚åï¼Œåˆ é™¤ç«¯ç‚¹ï¼š

```py
predictor.delete_endpoint()
```

## æ¥ä¸‹æ¥åšä»€ä¹ˆï¼Ÿ

æ­å–œï¼Œæ‚¨åˆšåˆšåœ¨ SageMaker ä¸Šå¾®è°ƒå’Œéƒ¨ç½²äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„ğŸ¤— Transformers æ¨¡å‹ï¼ğŸ‰

æ¥ä¸‹æ¥ï¼Œç»§ç»­é˜…è¯»æˆ‘ä»¬çš„æ–‡æ¡£ï¼Œäº†è§£æ›´å¤šå…³äºè®­ç»ƒå’Œéƒ¨ç½²çš„ç»†èŠ‚ã€‚æœ‰è®¸å¤šæœ‰è¶£çš„åŠŸèƒ½ï¼Œå¦‚åˆ†å¸ƒå¼è®­ç»ƒå’Œ Spot å®ä¾‹ã€‚
