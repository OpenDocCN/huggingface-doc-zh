# åœ¨ Amazon SageMaker ä¸Šè¿è¡Œè®­ç»ƒ

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/sagemaker/train`](https://huggingface.co/docs/sagemaker/train)

[`www.youtube.com/embed/ok3hetb42gU`](https://www.youtube.com/embed/ok3hetb42gU)

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨`HuggingFace` SageMaker Python SDK è®­ç»ƒä¸€ä¸ªğŸ¤— Transformers æ¨¡å‹ã€‚å­¦ä¹ å¦‚ä½•ï¼š

+   å®‰è£…å’Œè®¾ç½®æ‚¨çš„è®­ç»ƒç¯å¢ƒã€‚

+   å‡†å¤‡ä¸€ä¸ªè®­ç»ƒè„šæœ¬ã€‚

+   åˆ›å»ºä¸€ä¸ª Hugging Face Estimatorã€‚

+   ä½¿ç”¨`fit`æ–¹æ³•è¿è¡Œè®­ç»ƒã€‚

+   è®¿é—®æ‚¨è®­ç»ƒçš„æ¨¡å‹ã€‚

+   è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚

+   åˆ›å»ºä¸€ä¸ª spot å®ä¾‹ã€‚

+   ä» GitHub å­˜å‚¨åº“åŠ è½½è®­ç»ƒè„šæœ¬ã€‚

+   æ”¶é›†è®­ç»ƒæŒ‡æ ‡ã€‚

## å®‰è£…å’Œè®¾ç½®

åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ SageMaker è®­ç»ƒğŸ¤— Transformers æ¨¡å‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦æ³¨å†Œ AWS è´¦æˆ·ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰ AWS è´¦æˆ·ï¼Œè¯·åœ¨[è¿™é‡Œ](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html)äº†è§£æ›´å¤šä¿¡æ¯ã€‚

ä¸€æ—¦æ‚¨æ‹¥æœ‰ AWS è´¦æˆ·ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€å¼€å§‹ä½¿ç”¨ï¼š

+   [SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html)

+   [SageMaker ç¬”è®°æœ¬å®ä¾‹](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)

+   æœ¬åœ°ç¯å¢ƒ

è¦åœ¨æœ¬åœ°å¼€å§‹è®­ç»ƒï¼Œæ‚¨éœ€è¦è®¾ç½®é€‚å½“çš„[IAM è§’è‰²](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)ã€‚

å‡çº§åˆ°æœ€æ–°çš„`sagemaker`ç‰ˆæœ¬ï¼š

```py
pip install sagemaker --upgrade
```

**SageMaker ç¯å¢ƒ**

æŒ‰ç…§ä¸‹é¢æ‰€ç¤ºè®¾ç½®æ‚¨çš„ SageMaker ç¯å¢ƒï¼š

```py
import sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()
```

*æ³¨æ„ï¼šæ‰§è¡Œè§’è‰²ä»…åœ¨ SageMaker å†…è¿è¡Œç¬”è®°æœ¬æ—¶å¯ç”¨ã€‚å¦‚æœåœ¨é SageMaker ç¬”è®°æœ¬ä¸­è¿è¡Œ`get_execution_role`ï¼Œåˆ™ä¼šå‡ºç°`region`é”™è¯¯ã€‚*

**æœ¬åœ°ç¯å¢ƒ**

æŒ‰ç…§ä¸‹é¢æ‰€ç¤ºè®¾ç½®æ‚¨çš„æœ¬åœ°ç¯å¢ƒï¼š

```py
import sagemaker
import boto3

iam_client = boto3.client('iam')
role = iam_client.get_role(RoleName='role-name-of-your-iam-role-with-right-permissions')['Role']['Arn']
sess = sagemaker.Session()
```

## å‡†å¤‡ä¸€ä¸ªğŸ¤— Transformers å¾®è°ƒè„šæœ¬

æˆ‘ä»¬çš„è®­ç»ƒè„šæœ¬ä¸æ‚¨å¯èƒ½åœ¨ SageMaker ä¹‹å¤–è¿è¡Œçš„è®­ç»ƒè„šæœ¬éå¸¸ç›¸ä¼¼ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥é€šè¿‡å„ç§ç¯å¢ƒå˜é‡è®¿é—®æœ‰å…³è®­ç»ƒç¯å¢ƒçš„æœ‰ç”¨å±æ€§ï¼ˆè¯·å‚é˜…[è¿™é‡Œ](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md)è·å–å®Œæ•´åˆ—è¡¨ï¼‰ï¼Œä¾‹å¦‚ï¼š

+   `SM_MODEL_DIR`: ä¸€ä¸ªè¡¨ç¤ºè®­ç»ƒä½œä¸šå†™å…¥æ¨¡å‹å·¥ä»¶çš„è·¯å¾„çš„å­—ç¬¦ä¸²ã€‚è®­ç»ƒåï¼Œæ­¤ç›®å½•ä¸­çš„å·¥ä»¶å°†ä¸Šä¼ åˆ° S3 ä»¥è¿›è¡Œæ¨¡å‹æ‰˜ç®¡ã€‚`SM_MODEL_DIR`å§‹ç»ˆè®¾ç½®ä¸º`/opt/ml/model`ã€‚

+   `SM_NUM_GPUS`: ä¸€ä¸ªè¡¨ç¤ºä¸»æœºå¯ç”¨ GPU æ•°é‡çš„æ•´æ•°ã€‚

+   `SM_CHANNEL_XXXX:` ä¸€ä¸ªè¡¨ç¤ºåŒ…å«æŒ‡å®šé€šé“è¾“å…¥æ•°æ®çš„ç›®å½•è·¯å¾„çš„å­—ç¬¦ä¸²ã€‚ä¾‹å¦‚ï¼Œå½“æ‚¨åœ¨ Hugging Face Estimator çš„`fit`æ–¹æ³•ä¸­æŒ‡å®š`train`å’Œ`test`æ—¶ï¼Œç¯å¢ƒå˜é‡è®¾ç½®ä¸º`SM_CHANNEL_TRAIN`å’Œ`SM_CHANNEL_TEST`ã€‚

åœ¨ Hugging Face Estimator ä¸­å®šä¹‰çš„`hyperparameters`ä½œä¸ºå‘½åå‚æ•°ä¼ é€’ï¼Œå¹¶ç”±`ArgumentParser()`å¤„ç†ã€‚

```py
import transformers
import datasets
import argparse
import os

if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    # hyperparameters sent by the client are passed as command-line arguments to the script
    parser.add_argument("--epochs", type=int, default=3)
    parser.add_argument("--per_device_train_batch_size", type=int, default=32)
    parser.add_argument("--model_name_or_path", type=str)

    # data, model, and output directories
    parser.add_argument("--model-dir", type=str, default=os.environ["SM_MODEL_DIR"])
    parser.add_argument("--training_dir", type=str, default=os.environ["SM_CHANNEL_TRAIN"])
    parser.add_argument("--test_dir", type=str, default=os.environ["SM_CHANNEL_TEST"])
```

*è¯·æ³¨æ„ï¼ŒSageMaker ä¸æ”¯æŒ argparse æ“ä½œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³ä½¿ç”¨å¸ƒå°”è¶…å‚æ•°ï¼Œè¯·åœ¨è„šæœ¬ä¸­å°†`type`æŒ‡å®šä¸º`bool`å¹¶æä¾›æ˜ç¡®çš„`True`æˆ–`False`å€¼ã€‚*

æŸ¥çœ‹[è¿™é‡Œ](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/scripts/train.py)å®Œæ•´çš„ğŸ¤— Transformers è®­ç»ƒè„šæœ¬ç¤ºä¾‹ã€‚

## è®­ç»ƒè¾“å‡ºç®¡ç†

å¦‚æœ `TrainingArguments` ä¸­çš„ `output_dir` è®¾ç½®ä¸º â€˜/opt/ml/modelâ€™ï¼Œåˆ™ Trainer ä¼šä¿å­˜æ‰€æœ‰è®­ç»ƒå·¥ä»¶ï¼ŒåŒ…æ‹¬æ—¥å¿—ã€æ£€æŸ¥ç‚¹å’Œæ¨¡å‹ã€‚Amazon SageMaker å°†æ•´ä¸ª â€˜/opt/ml/modelâ€™ ç›®å½•å­˜æ¡£ä¸º `model.tar.gz`ï¼Œå¹¶åœ¨è®­ç»ƒä½œä¸šç»“æŸæ—¶å°†å…¶ä¸Šä¼ åˆ° Amazon S3ã€‚æ ¹æ®æ‚¨çš„è¶…å‚æ•°å’Œ `TrainingArguments`ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¸€ä¸ªå¤§çš„å·¥ä»¶ï¼ˆ> 5GBï¼‰ï¼Œè¿™å¯èƒ½ä¼šå‡æ…¢ Amazon SageMaker æ¨ç†çš„éƒ¨ç½²é€Ÿåº¦ã€‚æ‚¨å¯ä»¥é€šè¿‡è‡ªå®šä¹‰ [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) æ§åˆ¶æ£€æŸ¥ç‚¹ã€æ—¥å¿—å’Œå·¥ä»¶çš„ä¿å­˜æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡æä¾› `save_total_limit` ä½œä¸º `TrainingArgument`ï¼Œæ‚¨å¯ä»¥æ§åˆ¶æ£€æŸ¥ç‚¹çš„æ€»é‡é™åˆ¶ã€‚å¦‚æœä¿å­˜äº†æ–°çš„æ£€æŸ¥ç‚¹å¹¶ä¸”è¾¾åˆ°äº†æœ€å¤§é™åˆ¶ï¼Œåˆ™åˆ é™¤ `output_dir` ä¸­çš„æ—§æ£€æŸ¥ç‚¹ã€‚

é™¤äº†ä¸Šé¢å·²ç»æåˆ°çš„é€‰é¡¹ä¹‹å¤–ï¼Œè¿˜æœ‰å¦ä¸€ä¸ªé€‰é¡¹å¯ä»¥åœ¨è®­ç»ƒä¼šè¯æœŸé—´ä¿å­˜è®­ç»ƒå·¥ä»¶ã€‚Amazon SageMaker æ”¯æŒ[Checkpointing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html)ï¼Œå…è®¸æ‚¨åœ¨è®­ç»ƒæœŸé—´æŒç»­å°†æ‚¨çš„å·¥ä»¶ä¿å­˜åˆ° Amazon S3ï¼Œè€Œä¸æ˜¯åœ¨è®­ç»ƒç»“æŸæ—¶ä¿å­˜ã€‚è¦å¯ç”¨[Checkpointing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html)ï¼Œæ‚¨éœ€è¦æä¾›æŒ‡å‘ Amazon S3 ä½ç½®çš„ `checkpoint_s3_uri` å‚æ•°ï¼Œè¯¥å‚æ•°ä½äº `HuggingFace` estimator ä¸­ï¼Œå¹¶å°† `output_dir` è®¾ç½®ä¸º `/opt/ml/checkpoints`ã€‚*æ³¨æ„ï¼šå¦‚æœå°† `output_dir` è®¾ç½®ä¸º `/opt/ml/checkpoints`ï¼Œè¯·ç¡®ä¿åœ¨è®­ç»ƒç»“æŸæ—¶è°ƒç”¨ `trainer.save_model("/opt/ml/model")` æˆ– model.save_pretrained(â€œ/opt/ml/modelâ€)/`tokenizer.save_pretrained("/opt/ml/model")`ï¼Œä»¥ä¾¿èƒ½å¤Ÿæ— ç¼åœ°å°†æ‚¨çš„æ¨¡å‹éƒ¨ç½²åˆ° Amazon SageMaker è¿›è¡Œæ¨ç†ã€‚*

## åˆ›å»ºä¸€ä¸ª Hugging Face Estimator

é€šè¿‡åˆ›å»º[Hugging Face Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#huggingface-estimator)åœ¨ SageMaker ä¸Šè¿è¡Œ ğŸ¤— Transformers è®­ç»ƒè„šæœ¬ã€‚Estimator å¤„ç†ç«¯åˆ°ç«¯çš„ SageMaker è®­ç»ƒã€‚æ‚¨åº”è¯¥åœ¨ Estimator ä¸­å®šä¹‰å‡ ä¸ªå‚æ•°ï¼š

1.  `entry_point` æŒ‡å®šè¦ä½¿ç”¨çš„å¾®è°ƒè„šæœ¬ã€‚

1.  `instance_type` æŒ‡å®šè¦å¯åŠ¨çš„ Amazon å®ä¾‹ã€‚è¯·å‚è€ƒ[è¿™é‡Œ](https://aws.amazon.com/sagemaker/pricing/)è·å–å®Œæ•´çš„å®ä¾‹ç±»å‹åˆ—è¡¨ã€‚

1.  `hyperparameters` æŒ‡å®šè®­ç»ƒè¶…å‚æ•°ã€‚æŸ¥çœ‹å…¶ä»–å¯ç”¨çš„è¶…å‚æ•°[è¿™é‡Œ](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/scripts/train.py)ã€‚

ä»¥ä¸‹ä»£ç ç¤ºä¾‹æ˜¾ç¤ºå¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰è„šæœ¬ `train.py` è¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…å«ä¸‰ä¸ªè¶…å‚æ•°ï¼ˆ`epochs`ã€`per_device_train_batch_size` å’Œ `model_name_or_path`ï¼‰ï¼š

```py
from sagemaker.huggingface import HuggingFace

# hyperparameters which are passed to the training job
hyperparameters={'epochs': 1,
                 'per_device_train_batch_size': 32,
                 'model_name_or_path': 'distilbert-base-uncased'
                 }

# create the Estimator
huggingface_estimator = HuggingFace(
        entry_point='train.py',
        source_dir='./scripts',
        instance_type='ml.p3.2xlarge',
        instance_count=1,
        role=role,
        transformers_version='4.26',
        pytorch_version='1.13',
        py_version='py39',
        hyperparameters = hyperparameters
)
```

å¦‚æœæ‚¨åœ¨æœ¬åœ°è¿è¡Œ `TrainingJob`ï¼Œè¯·å®šä¹‰ `instance_type='local'` æˆ– `instance_type='local_gpu'` ä»¥ä½¿ç”¨ GPUã€‚è¯·æ³¨æ„ï¼Œè¿™åœ¨ SageMaker Studio ä¸­ä¸èµ·ä½œç”¨ã€‚

## æ‰§è¡Œè®­ç»ƒ

é€šè¿‡åœ¨ Hugging Face Estimator ä¸Šè°ƒç”¨ `fit` æ¥å¯åŠ¨æ‚¨çš„ `TrainingJob`ã€‚åœ¨ `fit` ä¸­æŒ‡å®šæ‚¨çš„è¾“å…¥è®­ç»ƒæ•°æ®ã€‚è¾“å…¥è®­ç»ƒæ•°æ®å¯ä»¥æ˜¯ï¼š

+   S3 URIï¼Œä¾‹å¦‚ `s3://my-bucket/my-training-data`ã€‚

+   å¯¹äº Amazon å¼¹æ€§æ–‡ä»¶ç³»ç»Ÿæˆ– FSx for Lustreï¼Œè¿è¡Œ `FileSystemInput`ã€‚è¯·å‚è€ƒ[è¿™é‡Œ](https://sagemaker.readthedocs.io/en/stable/overview.html?highlight=FileSystemInput#use-file-systems-as-training-inputs)è·å–æœ‰å…³å°†è¿™äº›æ–‡ä»¶ç³»ç»Ÿç”¨ä½œè¾“å…¥çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

è°ƒç”¨ `fit` å¼€å§‹è®­ç»ƒï¼š

```py
huggingface_estimator.fit(
  {'train': 's3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/train',
   'test': 's3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/test'}
)
```

SageMaker å¯åŠ¨å¹¶ç®¡ç†æ‰€æœ‰å¿…éœ€çš„ EC2 å®ä¾‹ï¼Œå¹¶é€šè¿‡è¿è¡Œä»¥ä¸‹å†…å®¹æ¥å¯åŠ¨ `TrainingJob`ï¼š

```py
/opt/conda/bin/python train.py --epochs 1 --model_name_or_path distilbert-base-uncased --per_device_train_batch_size 32
```

## è®¿é—®è®­ç»ƒæ¨¡å‹

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥é€šè¿‡[AWS æ§åˆ¶å°](https://console.aws.amazon.com/console/home?nc2=h_ct&src=header-signin)è®¿é—®æ‚¨çš„æ¨¡å‹ï¼Œæˆ–ç›´æ¥ä» S3 ä¸‹è½½ã€‚

```py
from sagemaker.s3 import S3Downloader

S3Downloader.download(
    s3_uri=huggingface_estimator.model_data, # S3 URI where the trained model is located
    local_path='.',                          # local path where *.targ.gz is saved
    sagemaker_session=sess                   # SageMaker session used for training the model
)
```

## åˆ†å¸ƒå¼è®­ç»ƒ

SageMaker æä¾›äº†ä¸¤ç§åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ï¼šæ•°æ®å¹¶è¡Œ ism å’Œæ¨¡å‹å¹¶è¡Œ ismã€‚æ•°æ®å¹¶è¡Œ ism å°†è®­ç»ƒé›†åˆ†å‰²åˆ°å¤šä¸ª GPU ä¸Šï¼Œè€Œæ¨¡å‹å¹¶è¡Œ ism å°†æ¨¡å‹åˆ†å‰²åˆ°å¤šä¸ª GPU ä¸Šã€‚

### æ•°æ®å¹¶è¡Œ ism

Hugging Face çš„[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)æ”¯æŒ SageMaker çš„æ•°æ®å¹¶è¡Œ ism åº“ã€‚å¦‚æœæ‚¨çš„è®­ç»ƒè„šæœ¬ä½¿ç”¨ Trainer APIï¼Œæ‚¨åªéœ€è¦åœ¨ Hugging Face Estimator ä¸­å®šä¹‰åˆ†å¸ƒå‚æ•°ï¼š

```py
# configuration for running training on smdistributed data parallel
distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}

# create the Estimator
huggingface_estimator = HuggingFace(
        entry_point='train.py',
        source_dir='./scripts',
        instance_type='ml.p3dn.24xlarge',
        instance_count=2,
        role=role,
        transformers_version='4.26.0',
        pytorch_version='1.13.1',
        py_version='py39',
        hyperparameters = hyperparameters,
        distribution = distribution
)
```

ğŸ““ æ‰“å¼€[notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb)ä»¥æŸ¥çœ‹å¦‚ä½•ä½¿ç”¨ TensorFlow è¿è¡Œæ•°æ®å¹¶è¡Œ ism åº“çš„ç¤ºä¾‹ã€‚

### æ¨¡å‹å¹¶è¡Œ ism

Hugging Face çš„[Trainer]è¿˜æ”¯æŒ SageMaker çš„æ¨¡å‹å¹¶è¡Œ ism åº“ã€‚å¦‚æœæ‚¨çš„è®­ç»ƒè„šæœ¬ä½¿ç”¨ Trainer APIï¼Œæ‚¨åªéœ€è¦åœ¨ Hugging Face Estimator ä¸­å®šä¹‰åˆ†å¸ƒå‚æ•°ï¼ˆæœ‰å…³ä½¿ç”¨æ¨¡å‹å¹¶è¡Œ ism çš„æ›´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[æ­¤å¤„](https://sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html?highlight=modelparallel#required-sagemaker-python-sdk-parameters)ï¼‰ï¼š

```py
# configuration for running training on smdistributed model parallel
mpi_options = {
    "enabled" : True,
    "processes_per_host" : 8
}

smp_options = {
    "enabled":True,
    "parameters": {
        "microbatches": 4,
        "placement_strategy": "spread",
        "pipeline": "interleaved",
        "optimize": "speed",
        "partitions": 4,
        "ddp": True,
    }
}

distribution={
    "smdistributed": {"modelparallel": smp_options},
    "mpi": mpi_options
}

 # create the Estimator
huggingface_estimator = HuggingFace(
        entry_point='train.py',
        source_dir='./scripts',
        instance_type='ml.p3dn.24xlarge',
        instance_count=2,
        role=role,
        transformers_version='4.26.0',
        pytorch_version='1.13.1',
        py_version='py39',
        hyperparameters = hyperparameters,
        distribution = distribution
)
```

ğŸ““ æ‰“å¼€[notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb)ä»¥æŸ¥çœ‹å¦‚ä½•è¿è¡Œæ¨¡å‹å¹¶è¡Œ ism åº“çš„ç¤ºä¾‹ã€‚

## Spot å®ä¾‹

Hugging Face æ‰©å±•äº† SageMaker Python SDKï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ä»[å®Œå…¨æ‰˜ç®¡çš„ EC2 spot å®ä¾‹](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)ä¸­å—ç›Šã€‚è¿™å¯ä»¥å¸®åŠ©æ‚¨èŠ‚çœé«˜è¾¾ 90%çš„è®­ç»ƒæˆæœ¬ï¼

*æ³¨æ„ï¼šé™¤éæ‚¨çš„è®­ç»ƒä½œä¸šå®Œæˆå¾—å¾ˆå¿«ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä½¿ç”¨[checkpointing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html)ä¸æ‰˜ç®¡çš„ spot è®­ç»ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦å®šä¹‰`checkpoint_s3_uri`ã€‚*

è®¾ç½®`use_spot_instances=True`å¹¶åœ¨ Estimator ä¸­å®šä¹‰æ‚¨çš„`max_wait`å’Œ`max_run`æ—¶é—´ä»¥ä½¿ç”¨ spot å®ä¾‹ï¼š

```py
# hyperparameters which are passed to the training job
hyperparameters={'epochs': 1,
                 'train_batch_size': 32,
                 'model_name':'distilbert-base-uncased',
                 'output_dir':'/opt/ml/checkpoints'
                 }

# create the Estimator
huggingface_estimator = HuggingFace(
        entry_point='train.py',
        source_dir='./scripts',
        instance_type='ml.p3.2xlarge',
        instance_count=1,
	    checkpoint_s3_uri=f's3://{sess.default_bucket()}/checkpoints'
        use_spot_instances=True,
        # max_wait should be equal to or greater than max_run in seconds
        max_wait=3600,
        max_run=1000,
        role=role,
        transformers_version='4.26',
        pytorch_version='1.13',
        py_version='py39',
        hyperparameters = hyperparameters
)

# Training seconds: 874
# Billable seconds: 262
# Managed Spot Training savings: 70.0%
```

ğŸ““ æ‰“å¼€[notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb)ä»¥æŸ¥çœ‹å¦‚ä½•ä½¿ç”¨ spot å®ä¾‹çš„ç¤ºä¾‹ã€‚

## Git å­˜å‚¨åº“

Hugging Face Estimator å¯ä»¥åŠ è½½å­˜å‚¨åœ¨ GitHub å­˜å‚¨åº“ä¸­çš„è®­ç»ƒè„šæœ¬ï¼ˆhttps://sagemaker.readthedocs.io/en/stable/overview.html#use-scripts-stored-in-a-git-repositoryï¼‰ã€‚åœ¨`entry_point`ä¸­æä¾›è®­ç»ƒè„šæœ¬çš„ç›¸å¯¹è·¯å¾„ï¼Œåœ¨`source_dir`ä¸­æä¾›ç›®å½•çš„ç›¸å¯¹è·¯å¾„ã€‚

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨`git_config`æ¥è¿è¡Œ[ğŸ¤— Transformers ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples)ï¼Œæ‚¨éœ€è¦åœ¨`transformers_version`ä¸­é…ç½®æ­£ç¡®çš„`'branch'`ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨`transformers_version='4.4.2'`ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨`'branch':'v4.4.2'`ï¼‰ã€‚

*æç¤ºï¼šé€šè¿‡åœ¨è®­ç»ƒè„šæœ¬çš„è¶…å‚æ•°ä¸­è®¾ç½®`output_dir=/opt/ml/model`å°†æ‚¨çš„æ¨¡å‹ä¿å­˜åˆ° S3 ä¸­ã€‚*

```py
# configure git settings
git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.4.2'} # v4.4.2 refers to the transformers_version you use in the estimator

 # create the Estimator
huggingface_estimator = HuggingFace(
        entry_point='run_glue.py',
        source_dir='./examples/pytorch/text-classification',
        git_config=git_config,
        instance_type='ml.p3.2xlarge',
        instance_count=1,
        role=role,
        transformers_version='4.26',
        pytorch_version='1.13',
        py_version='py39',
        hyperparameters=hyperparameters
)
```

## SageMaker æŒ‡æ ‡

[SageMaker æŒ‡æ ‡](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html#define-train-metrics)è‡ªåŠ¨è§£æè®­ç»ƒä½œä¸šæ—¥å¿—ä»¥è·å–æŒ‡æ ‡å¹¶å°†å…¶å‘é€åˆ° CloudWatchã€‚å¦‚æœæ‚¨å¸Œæœ› SageMaker è§£ææ—¥å¿—ï¼Œæ‚¨å¿…é¡»æŒ‡å®šæŒ‡æ ‡çš„åç§°å’Œ SageMaker ç”¨äºæŸ¥æ‰¾æŒ‡æ ‡çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚

```py
# define metrics definitions
metric_definitions = [
    {"Name": "train_runtime", "Regex": "train_runtime.*=\D*(.*?)$"},
    {"Name": "eval_accuracy", "Regex": "eval_accuracy.*=\D*(.*?)$"},
    {"Name": "eval_loss", "Regex": "eval_loss.*=\D*(.*?)$"},
]

# create the Estimator
huggingface_estimator = HuggingFace(
        entry_point='train.py',
        source_dir='./scripts',
        instance_type='ml.p3.2xlarge',
        instance_count=1,
        role=role,
        transformers_version='4.26',
        pytorch_version='1.13',
        py_version='py39',
        metric_definitions=metric_definitions,
        hyperparameters = hyperparameters)
```

ğŸ““ æ‰“å¼€[notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb)ä»¥æŸ¥çœ‹å¦‚ä½•åœ¨ SageMaker ä¸­æ•è·æŒ‡æ ‡çš„ç¤ºä¾‹ã€‚
