+   [AWS 中文文档](README.md)
+   [最佳神经元](aws_01.md)
+   [🤗 Optimum Neuron](aws_02.md)
+   [安装](aws_03.md)
+   [快速入门](aws_04.md)
+   [教程](aws_05.md)
+   [概述](aws_06.md)
+   [笔记本](aws_07.md)
+   [在 AWS Trainium 上为文本分类微调 BERT](aws_08.md)
+   [在 AWS Inferentia 上使用稳定扩散模型生成图像](aws_09.md)
+   [在 AWS Inferentia 上使用 llama-2-13B 创建您自己的聊天机器人](aws_10.md)
+   [在 AWS Trainium 上对 Llama 2 7B 进行微调和测试](aws_11.md)
+   [在 AWS Inferentia 上使用 Optimum Neuron 的句子转换器](aws_12.md)
+   [如何指南](aws_13.md)
+   [概述](aws_14.md)
+   [设置 AWS Trainium 实例](aws_15.md)
+   [在亚马逊 SageMaker 上使用 Optimum Neuron](aws_16.md)
+   [神经元模型缓存](aws_17.md)
+   [使用 AWS Trainium 对 Transformers 进行微调](aws_18.md)
+   [使用 optimum-neuron 进行分布式训练](aws_19.md)
+   [将模型导出到 Inferentia](aws_20.md)
+   [神经元模型推理](aws_21.md)
+   [使用 AWS Neuron（Inf2/Trn1）进行推理管道](aws_22.md)
+   [贡献](aws_23.md)
+   [为新架构添加支持](aws_24.md)
+   [参考](aws_25.md)
+   [NeuronTrainer](aws_26.md)
+   [Optimum Neuron Distributed](aws_27.md)
+   [Inferentia 导出器](aws_28.md)
+   [模型](aws_29.md)
+   [基准测试](aws_30.md)
+   [Llama 在 AWS Inferentia2 上的性能（延迟和吞吐量）](aws_31.md)