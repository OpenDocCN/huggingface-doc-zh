# æœ‰ç”¨çš„å·¥å…·

> åŸæ–‡ï¼š[`huggingface.co/docs/accelerate/package_reference/utilities`](https://huggingface.co/docs/accelerate/package_reference/utilities)

ä»¥ä¸‹æ˜¯ğŸ¤— Accelerate æä¾›çš„å„ç§å®ç”¨å‡½æ•°ï¼ŒæŒ‰ç”¨ä¾‹åˆ†ç±»ã€‚

## å¸¸é‡

ç”¨äºå‚è€ƒçš„ğŸ¤— Accelerate ä¸­ä½¿ç”¨çš„å¸¸é‡

ä»¥ä¸‹æ˜¯åœ¨ä½¿ç”¨ Accelerator.save_state()æ—¶ä½¿ç”¨çš„å¸¸é‡

`utils.MODEL_NAME`: `"pytorch_model"` `utils.OPTIMIZER_NAME`: `"optimizer"` `utils.RNG_STATE_NAME`: `"random_states"` `utils.SCALER_NAME`: `"scaler.pt` `utils.SCHEDULER_NAME`: `"scheduler`

ä»¥ä¸‹æ˜¯åœ¨ä½¿ç”¨ Accelerator.save_model()æ—¶ä½¿ç”¨çš„å¸¸é‡

`utils.WEIGHTS_NAME`: `"pytorch_model.bin"` `utils.SAFE_WEIGHTS_NAME`: `"model.safetensors"` `utils.WEIGHTS_INDEX_NAME`: `"pytorch_model.bin.index.json"` `utils.SAFE_WEIGHTS_INDEX_NAME`: `"model.safetensors.index.json"`

## æ•°æ®ç±»

è¿™äº›æ˜¯åœ¨ğŸ¤— Accelerate ä¸­ä½¿ç”¨çš„åŸºæœ¬æ•°æ®ç±»ï¼Œå¯ä»¥ä½œä¸ºå‚æ•°ä¼ é€’ã€‚

### ç‹¬ç«‹çš„

è¿™äº›æ˜¯ç”¨äºæ£€æŸ¥çš„ç‹¬ç«‹æ•°æ®ç±»ï¼Œä¾‹å¦‚æ­£åœ¨ä½¿ç”¨çš„åˆ†å¸ƒå¼ç³»ç»Ÿç±»å‹

### `class accelerate.utils.ComputeEnvironment`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L329)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

ä»£è¡¨è®¡ç®—ç¯å¢ƒçš„ä¸€ç§ç±»å‹ã€‚

å€¼ï¼š

+   `LOCAL_MACHINE` â€” ç§æœ‰/è‡ªå®šä¹‰é›†ç¾¤ç¡¬ä»¶ã€‚

+   `AMAZON_SAGEMAKER` â€” Amazon SageMaker ä½œä¸ºè®¡ç®—ç¯å¢ƒã€‚

### `class accelerate.DistributedType`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L285)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

ä»£è¡¨ä¸€ç§åˆ†å¸ƒå¼ç¯å¢ƒç±»å‹ã€‚

å€¼ï¼š

+   `NO` â€” ä¸æ˜¯åˆ†å¸ƒå¼ç¯å¢ƒï¼Œåªæ˜¯å•ä¸ªè¿›ç¨‹ã€‚

+   `MULTI_CPU` â€” åœ¨å¤šä¸ª CPU èŠ‚ç‚¹ä¸Šåˆ†å¸ƒã€‚

+   `MULTI_GPU` â€” åœ¨å¤šä¸ª GPU ä¸Šåˆ†å¸ƒã€‚

+   `MULTI_NPU` â€” åœ¨å¤šä¸ª NPU ä¸Šåˆ†å¸ƒã€‚

+   `MULTI_XPU` â€” åœ¨å¤šä¸ª XPU ä¸Šåˆ†å¸ƒã€‚

+   `DEEPSPEED` â€” ä½¿ç”¨ DeepSpeedã€‚

+   `TPU` â€” åœ¨ TPU ä¸Šåˆ†å¸ƒã€‚

### `class accelerate.utils.DynamoBackend`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L344)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

ä»£è¡¨ä¸€ä¸ª dynamo åç«¯ï¼ˆå‚è§[`github.com/pytorch/torchdynamo`](https://github.com/pytorch/torchdynamo)ï¼‰ã€‚

å€¼ï¼š

+   `NO` â€” ä¸ä½¿ç”¨ torch dynamoã€‚

+   `EAGER` â€” ä½¿ç”¨ PyTorch æ¥è¿è¡Œæå–çš„ GraphModuleã€‚åœ¨è°ƒè¯• TorchDynamo é—®é¢˜æ—¶éå¸¸æœ‰ç”¨ã€‚

+   `AOT_EAGER` â€” ä½¿ç”¨ AotAutograd è€Œä¸ä½¿ç”¨ç¼–è¯‘å™¨ï¼Œå³ä»…ä½¿ç”¨ PyTorch eager è¿›è¡Œ AotAutograd çš„æå–çš„å‰å‘å’Œåå‘å›¾ã€‚è¿™å¯¹è°ƒè¯•å¾ˆæœ‰ç”¨ï¼Œä¸å¤ªå¯èƒ½æä¾›åŠ é€Ÿã€‚

+   `INDUCTOR` â€” ä½¿ç”¨ TorchInductor åç«¯ä¸ AotAutograd å’Œ cudagraphsï¼Œé€šè¿‡åˆ©ç”¨ codegened Triton å†…æ ¸ã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)

+   `AOT_TS_NVFUSER` â€” ä½¿ç”¨ AotAutograd/TorchScript çš„ nvFuserã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)

+   `NVPRIMS_NVFUSER` â€” ä½¿ç”¨ PrimTorch çš„ nvFuserã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)

+   `CUDAGRAPHS` â€” ä½¿ç”¨ AotAutograd çš„ cudagraphsã€‚[é˜…è¯»æ›´å¤š](https://github.com/pytorch/torchdynamo/pull/757)

+   `OFI` â€” ä½¿ç”¨ Torchscript optimize_for_inferenceã€‚ä»…æ¨ç†ã€‚[é˜…è¯»æ›´å¤š](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)

+   `FX2TRT` â€” ä½¿ç”¨ Nvidia TensorRT è¿›è¡Œæ¨ç†ä¼˜åŒ–ã€‚ä»…æ¨ç†ã€‚[é˜…è¯»æ›´å¤š](https://github.com/pytorch/TensorRT/blob/master/docsrc/tutorials/getting_started_with_fx_path.rst)

+   `ONNXRT` â€” ä½¿ç”¨ ONNXRT åœ¨ CPU/GPU ä¸Šè¿›è¡Œæ¨ç†ã€‚ä»…æ¨ç†ã€‚[é˜…è¯»æ›´å¤š](https://onnxruntime.ai/)

+   `TENSORRT` â€” ä½¿ç”¨ ONNXRT æ¥è¿è¡Œ TensorRT è¿›è¡Œæ¨ç†ä¼˜åŒ–ã€‚[é˜…è¯»æ›´å¤š](https://github.com/onnx/onnx-tensorrt)

+   `IPEX` â€” åœ¨ CPU ä¸Šä½¿ç”¨ IPEX è¿›è¡Œæ¨æ–­ã€‚ä»…æ¨æ–­ã€‚[é˜…è¯»æ›´å¤š](https://github.com/intel/intel-extension-for-pytorch)ã€‚

+   `TVM` â€” ä½¿ç”¨ Apach TVM è¿›è¡Œæ¨æ–­ä¼˜åŒ–ã€‚[é˜…è¯»æ›´å¤š](https://tvm.apache.org/)

### `class accelerate.utils.LoggerType`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L392)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

è¡¨ç¤ºæ”¯æŒçš„å®éªŒè·Ÿè¸ªå™¨ç±»å‹

å€¼ï¼š

+   `ALL` â€” ç¯å¢ƒä¸­æ‰€æœ‰å¯ç”¨çš„å—æ”¯æŒè·Ÿè¸ªå™¨

+   `TENSORBOARD` â€” TensorBoard ä½œä¸ºå®éªŒè·Ÿè¸ªå™¨

+   `WANDB` â€” wandb ä½œä¸ºå®éªŒè·Ÿè¸ªå™¨

+   `COMETML` â€” comet_ml ä½œä¸ºå®éªŒè·Ÿè¸ªå™¨

+   `DVCLIVE` â€” dvclive ä½œä¸ºå®éªŒè·Ÿè¸ªå™¨

### `class accelerate.utils.PrecisionType`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L414)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

è¡¨ç¤ºæµ®ç‚¹å€¼ä¸Šä½¿ç”¨çš„ç²¾åº¦ç±»å‹

å€¼ï¼š

+   `NO` â€” ä½¿ç”¨å…¨ç²¾åº¦ï¼ˆFP32ï¼‰

+   `FP16` â€” ä½¿ç”¨åŠç²¾åº¦

+   `BF16` â€” ä½¿ç”¨è„‘æµ®ç‚¹ç²¾åº¦

### `class accelerate.utils.RNGType`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L430)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

ä¸€ä¸ªæšä¸¾ã€‚

### `class accelerate.utils.SageMakerDistributedType`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L312)

```py
( value names = None module = None qualname = None type = None start = 1 )
```

è¡¨ç¤ºåˆ†å¸ƒå¼ç¯å¢ƒç±»å‹ã€‚

å€¼ï¼š

+   `NO` â€” ä¸æ˜¯åˆ†å¸ƒå¼ç¯å¢ƒï¼Œåªæ˜¯ä¸€ä¸ªå•ä¸€è¿›ç¨‹ã€‚

+   `DATA_PARALLEL` â€” ä½¿ç”¨ sagemaker åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œã€‚

+   `MODEL_PARALLEL` â€” ä½¿ç”¨ sagemaker åˆ†å¸ƒå¼æ¨¡å‹å¹¶è¡Œã€‚

### Kwargs

è¿™äº›æ˜¯åŠ é€Ÿåœ¨å¹•åå¤„ç†çš„ PyTorch ç”Ÿæ€ç³»ç»Ÿä¸­ç‰¹å®šäº¤äº’çš„å¯é…ç½®å‚æ•°ã€‚

### `class accelerate.AutocastKwargs`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L60)

```py
( enabled: bool = True cache_enabled: bool = None )
```

åœ¨æ‚¨çš„ Accelerator ä¸­ä½¿ç”¨æ­¤å¯¹è±¡ï¼Œä»¥è‡ªå®šä¹‰`torch.autocast`çš„è¡Œä¸ºã€‚è¯·å‚è€ƒæ­¤[ä¸Šä¸‹æ–‡ç®¡ç†å™¨](https://pytorch.org/docs/stable/amp.html#torch.autocast)çš„æ–‡æ¡£ï¼Œä»¥è·å–æœ‰å…³æ¯ä¸ªå‚æ•°çš„æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
from accelerate import Accelerator
from accelerate.utils import AutocastKwargs

kwargs = AutocastKwargs(cache_enabled=True)
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

### `class accelerate.DistributedDataParallelKwargs`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L82)

```py
( dim: int = 0 broadcast_buffers: bool = True bucket_cap_mb: int = 25 find_unused_parameters: bool = False check_reduction: bool = False gradient_as_bucket_view: bool = False static_graph: bool = False )
```

åœ¨æ‚¨çš„ Accelerator ä¸­ä½¿ç”¨æ­¤å¯¹è±¡ï¼Œä»¥è‡ªå®šä¹‰å¦‚ä½•å°†æ‚¨çš„æ¨¡å‹åŒ…è£…åœ¨`torch.nn.parallel.DistributedDataParallel`ä¸­ã€‚è¯·å‚è€ƒæ­¤[åŒ…è£…å™¨](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)çš„æ–‡æ¡£ï¼Œä»¥è·å–æœ‰å…³æ¯ä¸ªå‚æ•°çš„æ›´å¤šä¿¡æ¯ã€‚

`gradient_as_bucket_view` ä»…åœ¨ PyTorch 1.7.0 åŠæ›´é«˜ç‰ˆæœ¬ä¸­å¯ç”¨ã€‚

`static_graph` ä»…åœ¨ PyTorch 1.11.0 åŠæ›´é«˜ç‰ˆæœ¬ä¸­å¯ç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
from accelerate import Accelerator
from accelerate.utils import DistributedDataParallelKwargs

kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

### `class accelerate.utils.FP8RecipeKwargs`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L179)

```py
( backend: Literal = 'MSAMP' opt_level: Literal = 'O2' margin: int = 0 interval: int = 1 fp8_format: Literal = 'E4M3' amax_history_len: int = 1 amax_compute_algo: Literal = 'most_recent' override_linear_precision: Tuple = (False, False, False) )
```

å‚æ•°

+   `backend` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"msamp"`) â€” ä½¿ç”¨çš„ FP8 å¼•æ“ã€‚å¿…é¡»æ˜¯`"msamp"`ï¼ˆMS-AMPï¼‰æˆ–`"te"`ï¼ˆTransformerEngineï¼‰ä¹‹ä¸€ã€‚

+   `margin` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” ç”¨äºæ¢¯åº¦ç¼©æ”¾çš„è¾¹è·ã€‚

+   `interval` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” ç”¨äºé‡æ–°è®¡ç®—ç¼©æ”¾å› å­çš„é—´éš”ã€‚

+   `fp8_format` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`E4M3`) â€” ç”¨äº FP8 é…æ–¹çš„æ ¼å¼ã€‚å¿…é¡»æ˜¯`E4M3`æˆ–`HYBRID`ä¹‹ä¸€ã€‚

+   `amax_history_len` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1024) â€” ç”¨äºç¼©æ”¾å› å­è®¡ç®—çš„å†å²é•¿åº¦

+   `amax_compute_algo` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`most_recent`) â€” ç”¨äºç¼©æ”¾å› å­è®¡ç®—çš„ç®—æ³•ã€‚å¿…é¡»æ˜¯`max`æˆ–`most_recent`ä¹‹ä¸€ã€‚

+   `override_linear_precision`ï¼ˆä¸‰ä¸ª`bool`çš„`tuple`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`(False, False, False)`ï¼‰ â€” æ˜¯å¦åœ¨æ›´é«˜ç²¾åº¦ä¸­æ‰§è¡Œ`fprop`ã€`dgrad`å’Œ`wgrad` GEMMSã€‚

+   `optimization_level`ï¼ˆ`str`ï¼‰ï¼Œå…¶ä¸­ä¹‹ä¸€ä¸º`O1`ã€`O2`ã€‚ ï¼ˆé»˜è®¤ä¸º`O2`ï¼‰ â€” ä½¿ç”¨ MS-AMP æ—¶åº”ä½¿ç”¨çš„ 8 ä½é›†ä½“é€šä¿¡çº§åˆ«ã€‚ä¸€èˆ¬æ¥è¯´ï¼š

    +   O1: æƒé‡æ¢¯åº¦å’Œ`all_reduce`é€šä¿¡åœ¨ fp8 ä¸­å®Œæˆï¼Œå‡å°‘äº† GPU å†…å­˜ä½¿ç”¨å’Œé€šä¿¡å¸¦å®½

    +   O2: ä¸€é˜¶ä¼˜åŒ–å™¨çŠ¶æ€ä¸º 8 ä½ï¼ŒäºŒé˜¶çŠ¶æ€ä¸º FP16ã€‚ ä»…åœ¨ä½¿ç”¨ Adam æˆ– AdamW æ—¶å¯ç”¨ã€‚è¿™å¯ä»¥ä¿æŒå‡†ç¡®æ€§ï¼Œå¹¶å¯èƒ½èŠ‚çœæœ€é«˜çš„å†…å­˜ã€‚

    +   03: ä¸“é—¨ä¸º DeepSpeed å®ç°åŠŸèƒ½ï¼Œä½¿æ¨¡å‹çš„æƒé‡å’Œä¸»æƒé‡å­˜å‚¨åœ¨ FP8 ä¸­ã€‚å¦‚æœé€‰æ‹©äº†`fp8`å¹¶å¯ç”¨äº† deepspeedï¼Œåˆ™å°†é»˜è®¤ä½¿ç”¨ï¼ˆç›®å‰ä¸å¯ç”¨ï¼‰ã€‚

åœ¨æ‚¨çš„ Accelerator ä¸­ä½¿ç”¨æ­¤å¯¹è±¡ï¼Œä»¥è‡ªå®šä¹‰ä½¿ç”¨`transformer-engine`æˆ–`ms-amp`è¿›è¡Œ FP8 æ··åˆç²¾åº¦è®­ç»ƒçš„é…æ–¹çš„åˆå§‹åŒ–ã€‚

æœ‰å…³`transformer-engine`å‚æ•°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ API[æ–‡æ¡£](https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/api/common.html)ã€‚

æœ‰å…³`ms-amp`å‚æ•°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä¼˜åŒ–çº§åˆ«[æ–‡æ¡£](https://azure.github.io/MS-AMP/docs/user-tutorial/optimization-level)ã€‚

```py
from accelerate import Accelerator
from accelerate.utils import FP8RecipeKwargs

kwargs = FP8RecipeKwargs(backend="te", fp8_format="HYBRID")
accelerator = Accelerator(mixed_precision="fp8", kwargs_handlers=[kwargs])
```

è¦å°† MS-AMP ä½œä¸ºå¼•æ“ä½¿ç”¨ï¼Œè¯·ä¼ é€’`backend="msamp"`å’Œ`optimization_level`ï¼š

```py
kwargs = FP8RecipeKwargs(backend="msamp", optimization_level="02")
```

### `class accelerate.GradScalerKwargs`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L118)

```py
( init_scale: float = 65536.0 growth_factor: float = 2.0 backoff_factor: float = 0.5 growth_interval: int = 2000 enabled: bool = True )
```

åœ¨æ‚¨çš„ Accelerator ä¸­ä½¿ç”¨æ­¤å¯¹è±¡ï¼Œä»¥è‡ªå®šä¹‰æ··åˆç²¾åº¦çš„è¡Œä¸ºï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•åˆ›å»ºæ‰€ä½¿ç”¨çš„`torch.cuda.amp.GradScaler`ã€‚è¯·å‚è€ƒæ­¤[scaler](https://pytorch.org/docs/stable/amp.html?highlight=gradscaler)çš„æ–‡æ¡£ï¼Œä»¥è·å–æœ‰å…³æ¯ä¸ªå‚æ•°çš„æ›´å¤šä¿¡æ¯ã€‚

`GradScaler`ä»…åœ¨ PyTorch 1.5.0 åŠæ›´é«˜ç‰ˆæœ¬ä¸­å¯ç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
from accelerate import Accelerator
from accelerate.utils import GradScalerKwargs

kwargs = GradScalerKwargs(backoff_filter=0.25)
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

### `class accelerate.InitProcessGroupKwargs`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L149)

```py
( backend: Optional = 'nccl' init_method: Optional = None timeout: timedelta = datetime.timedelta(seconds=1800) )
```

åœ¨æ‚¨çš„ Accelerator ä¸­ä½¿ç”¨æ­¤å¯¹è±¡ï¼Œä»¥è‡ªå®šä¹‰åˆ†å¸ƒå¼è¿›ç¨‹çš„åˆå§‹åŒ–ã€‚è¯·å‚è€ƒæ­¤[method](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group)çš„æ–‡æ¡£ï¼Œä»¥è·å–æœ‰å…³æ¯ä¸ªå‚æ•°çš„æ›´å¤šä¿¡æ¯ã€‚

```py
from datetime import timedelta
from accelerate import Accelerator
from accelerate.utils import InitProcessGroupKwargs

kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=800))
accelerator = Accelerator(kwargs_handlers=[kwargs])
```

## æ’ä»¶

è¿™äº›æ˜¯å¯ä»¥ä¼ é€’ç»™ Accelerator å¯¹è±¡çš„æ’ä»¶ã€‚è™½ç„¶å®ƒä»¬åœ¨æ–‡æ¡£çš„å…¶ä»–åœ°æ–¹å®šä¹‰ï¼Œä½†ä¸ºäº†æ–¹ä¾¿ï¼Œæ‰€æœ‰æ’ä»¶éƒ½å¯ä»¥åœ¨æ­¤å¤„æŸ¥çœ‹ï¼š

### `class accelerate.DeepSpeedPlugin`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L562)

```py
( hf_ds_config: Any = None gradient_accumulation_steps: int = None gradient_clipping: float = None zero_stage: int = None is_train_batch_min: str = True offload_optimizer_device: bool = None offload_param_device: bool = None offload_optimizer_nvme_path: str = None offload_param_nvme_path: str = None zero3_init_flag: bool = None zero3_save_16bit_model: bool = None )
```

æ­¤æ’ä»¶ç”¨äºé›†æˆ DeepSpeedã€‚

#### `deepspeed_config_process`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L756)

```py
( prefix = '' mismatches = None config = None must_match = True **kwargs )
```

ä½¿ç”¨ kwargs ä¸­çš„å€¼å¤„ç† DeepSpeed é…ç½®ã€‚

### `class accelerate.FullyShardedDataParallelPlugin`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L872)

```py
( sharding_strategy: typing.Any = None backward_prefetch: typing.Any = None mixed_precision_policy: typing.Any = None auto_wrap_policy: Optional = None cpu_offload: typing.Any = None ignored_modules: Optional = None state_dict_type: typing.Any = None state_dict_config: typing.Any = None optim_state_dict_config: typing.Any = None limit_all_gathers: bool = True use_orig_params: bool = True param_init_fn: Optional = None sync_module_states: bool = True forward_prefetch: bool = False activation_checkpointing: bool = False )
```

æ­¤æ’ä»¶ç”¨äºå¯ç”¨å®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œã€‚

#### `get_module_class_from_name`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1025)

```py
( module name )
```

å‚æ•°

+   `module`ï¼ˆ`torch.nn.Module`ï¼‰ â€” è¦ä»ä¸­è·å–ç±»çš„æ¨¡å—ã€‚

+   `name`ï¼ˆ`str`ï¼‰ â€” ç±»çš„åç§°ã€‚

é€šè¿‡åç§°ä»æ¨¡å—ä¸­è·å–ä¸€ä¸ªç±»ã€‚

### `class accelerate.utils.GradientAccumulationPlugin`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L505)

```py
( num_steps: int = None adjust_scheduler: bool = True sync_with_dataloader: bool = True )
```

ä¸€ä¸ªæ’ä»¶ï¼Œç”¨äºé…ç½®æ¢¯åº¦ç´¯ç§¯è¡Œä¸ºã€‚

### `class accelerate.utils.MegatronLMPlugin`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1105)

```py
( tp_degree: int = None pp_degree: int = None num_micro_batches: int = None gradient_clipping: float = None sequence_parallelism: bool = None recompute_activations: bool = None use_distributed_optimizer: bool = None pipeline_model_parallel_split_rank: int = None num_layers_per_virtual_pipeline_stage: int = None is_train_batch_min: str = True train_iters: int = None train_samples: int = None weight_decay_incr_style: str = 'constant' start_weight_decay: float = None end_weight_decay: float = None lr_decay_style: str = 'linear' lr_decay_iters: int = None lr_decay_samples: int = None lr_warmup_iters: int = None lr_warmup_samples: int = None lr_warmup_fraction: float = None min_lr: float = 0 consumed_samples: List = None no_wd_decay_cond: Optional = None scale_lr_cond: Optional = None lr_mult: float = 1.0 megatron_dataset_flag: bool = False seq_length: int = None encoder_seq_length: int = None decoder_seq_length: int = None tensorboard_dir: str = None set_all_logging_options: bool = False eval_iters: int = 100 eval_interval: int = 1000 return_logits: bool = False custom_train_step_class: Optional = None custom_train_step_kwargs: Optional = None custom_model_provider_function: Optional = None custom_prepare_model_function: Optional = None other_megatron_args: Optional = None )
```

ç”¨äº Megatron-LM çš„æ’ä»¶ï¼Œä»¥å¯ç”¨å¼ é‡ã€ç®¡é“ã€åºåˆ—å’Œæ•°æ®å¹¶è¡Œã€‚è¿˜å¯å¯ç”¨é€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—å’Œä¼˜åŒ–èåˆå†…æ ¸ã€‚

### `class accelerate.utils.TorchDynamoPlugin`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L526)

```py
( backend: DynamoBackend = None mode: str = None fullgraph: bool = None dynamic: bool = None options: Any = None disable: bool = False )
```

æ­¤æ’ä»¶ç”¨äºä½¿ç”¨ PyTorch 2.0 ç¼–è¯‘æ¨¡å‹

## é…ç½®

è¿™äº›æ˜¯å¯ä»¥é…ç½®å¹¶ä¼ é€’ç»™é€‚å½“é›†æˆçš„ç±»

### `class accelerate.utils.BnbQuantizationConfig`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L1480)

```py
( load_in_8bit: bool = False llm_int8_threshold: float = 6.0 load_in_4bit: bool = False bnb_4bit_quant_type: str = 'fp4' bnb_4bit_use_double_quant: bool = False bnb_4bit_compute_dtype: bool = 'fp16' torch_dtype: dtype = None skip_modules: List = None keep_in_fp32_modules: List = None )
```

ä¸€ä¸ªæ’ä»¶ï¼Œç”¨äºå¯ç”¨ BitsAndBytes 4 ä½å’Œ 8 ä½é‡åŒ–

### `class accelerate.utils.ProjectConfiguration`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L457)

```py
( project_dir: str = None logging_dir: str = None automatic_checkpoint_naming: bool = False total_limit: int = None iteration: int = 0 save_on_each_node: bool = False )
```

åŸºäºå†…éƒ¨é¡¹ç›®éœ€æ±‚çš„åŠ é€Ÿå™¨å¯¹è±¡çš„é…ç½®ã€‚

#### `set_directories`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L495)

```py
( project_dir: str = None )
```

å°†`self.project_dir`å’Œ`self.logging_dir`è®¾ç½®ä¸ºé€‚å½“çš„å€¼ã€‚

## ç¯å¢ƒå˜é‡

è¿™äº›æ˜¯å¯ä»¥ä¸ºä¸åŒç”¨ä¾‹å¯ç”¨çš„ç¯å¢ƒå˜é‡

+   `ACCELERATE_DEBUG_MODE`ï¼ˆ`str`ï¼‰ï¼šæ˜¯å¦åœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¿è¡ŒåŠ é€Ÿã€‚æ›´å¤šä¿¡æ¯è¯·å‚é˜…æ­¤å¤„ã€‚

## æ•°æ®æ“ä½œå’Œæ“ä½œ

è¿™äº›åŒ…æ‹¬æ¨¡æ‹Ÿç›¸åŒ`torch`æ“ä½œçš„æ•°æ®æ“ä½œï¼Œä½†å¯ä»¥åœ¨åˆ†å¸ƒå¼è¿›ç¨‹ä¸Šä½¿ç”¨ã€‚

#### `accelerate.utils.broadcast`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L542)

```py
( tensor from_process: int = 0 )
```

å‚æ•°

+   `tensor`ï¼ˆåµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸çš„`torch.Tensor`ï¼‰-è¦æ”¶é›†çš„æ•°æ®ã€‚

+   `from_process`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰-è¦å‘é€æ•°æ®çš„è¿›ç¨‹

é€’å½’å¹¿æ’­åµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸ä¸­çš„å¼ é‡åˆ°æ‰€æœ‰è®¾å¤‡ã€‚

#### `accelerate.utils.broadcast_object_list`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L564)

```py
( object_list from_process: int = 0 )
```

å‚æ•°

+   `object_list`ï¼ˆå¯æ‹¾å–å¯¹è±¡åˆ—è¡¨ï¼‰-è¦å¹¿æ’­çš„å¯¹è±¡åˆ—è¡¨ã€‚æ­¤åˆ—è¡¨å°†è¢«å°±åœ°ä¿®æ”¹ã€‚

+   `from_process`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰-è¦å‘é€æ•°æ®çš„è¿›ç¨‹ã€‚

ä»ä¸€ä¸ªè¿›ç¨‹å‘å…¶ä»–è¿›ç¨‹å¹¿æ’­ä¸€ä¸ªå¯æ‹¾å–å¯¹è±¡åˆ—è¡¨ã€‚

#### `accelerate.utils.concatenate`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L605)

```py
( data dim = 0 )
```

å‚æ•°

+   `data`ï¼ˆåµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸çš„å¼ é‡åˆ—è¡¨`torch.Tensor`ï¼‰-è¦è¿æ¥çš„æ•°æ®ã€‚

+   `dim`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰-è¦è¿æ¥çš„ç»´åº¦ã€‚

é€’å½’è¿æ¥å…·æœ‰ç›¸åŒå½¢çŠ¶çš„å¼ é‡åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸­çš„å¼ é‡ã€‚

#### `accelerate.utils.convert_outputs_to_fp32`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L813)

```py
( model_forward )
```

#### `accelerate.utils.convert_to_fp32`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L766)

```py
( tensor )
```

å‚æ•°

+   `tensor`ï¼ˆåµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸çš„`torch.Tensor`ï¼‰-è¦ä» FP16/BF16 è½¬æ¢ä¸º FP32 çš„æ•°æ®ã€‚

é€’å½’å°† FP16/BF16 ç²¾åº¦ä¸­çš„åµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸ä¸­çš„å…ƒç´ è½¬æ¢ä¸º FP32ã€‚

#### `accelerate.utils.gather`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L422)

```py
( tensor )
```

å‚æ•°

+   `tensor`ï¼ˆåµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸çš„`torch.Tensor`ï¼‰-è¦æ”¶é›†çš„æ•°æ®ã€‚

ä»æ‰€æœ‰è®¾å¤‡ä¸­é€’å½’æ”¶é›†åµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸ä¸­çš„å¼ é‡ã€‚

#### `accelerate.utils.gather_object`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L449)

```py
( object: Any )
```

å‚æ•°

+   `å¯¹è±¡`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«å¯ pickle å¯¹è±¡ï¼‰- è¦æ”¶é›†çš„æ•°æ®ã€‚

é€’å½’åœ°ä»æ‰€æœ‰è®¾å¤‡ä¸­çš„åµŒå¥—åˆ—è¡¨/å…ƒç»„/å­—å…¸å¯¹è±¡ä¸­æ”¶é›†å¯¹è±¡ã€‚

#### `accelerate.utils.listify`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L283)

```py
( data )
```

å‚æ•°

+   `æ•°æ®`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«`torch.Tensor`ï¼‰- è¦è½¬æ¢ä¸ºå¸¸è§„æ•°å­—çš„æ•°æ®ã€‚

é€’å½’åœ°æŸ¥æ‰¾åµŒå¥—åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸­çš„å¼ é‡ï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢ä¸ºæ•°å­—åˆ—è¡¨ã€‚

#### `accelerate.utils.pad_across_processes`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L631)

```py
( tensor dim = 0 pad_index = 0 pad_first = False )
```

å‚æ•°

+   `å¼ é‡`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«`torch.Tensor`ï¼‰- è¦æ”¶é›†çš„æ•°æ®ã€‚

+   `dim`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰- è¦å¡«å……çš„ç»´åº¦ã€‚

+   `pad_index`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰- ç”¨äºå¡«å……çš„å€¼ã€‚

+   `pad_first`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰- æ˜¯å¦åœ¨å¼€å¤´æˆ–ç»“å°¾å¡«å……ã€‚

é€’å½’åœ°å¡«å……æ¥è‡ªæ‰€æœ‰è®¾å¤‡çš„åµŒå¥—åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸­çš„å¼ é‡ï¼Œä½¿å®ƒä»¬è¾¾åˆ°ç›¸åŒçš„å¤§å°ï¼Œä»¥ä¾¿å®‰å…¨åœ°æ”¶é›†ã€‚

#### `accelerate.utils.recursively_apply`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L93)

```py
( func data *args test_type = <function is_torch_tensor at 0x7f2b4f4c7d00> error_on_other_type = False **kwargs )
```

å‚æ•°

+   `func`ï¼ˆ`callable`ï¼‰- è¦é€’å½’åº”ç”¨çš„å‡½æ•°ã€‚

+   `æ•°æ®`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«`main_type`ï¼‰- è¦åº”ç”¨`func`çš„æ•°æ®*args- å½“åº”ç”¨äºè§£åŒ…æ•°æ®æ—¶å°†ä¼ é€’ç»™`func`çš„ä½ç½®å‚æ•°ã€‚

+   `main_type`ï¼ˆ`type`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`torch.Tensor`ï¼‰- è¦åº”ç”¨`func`çš„å¯¹è±¡çš„åŸºæœ¬ç±»å‹ã€‚

+   `error_on_other_type`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰- å¦‚æœåœ¨è§£åŒ…`æ•°æ®`åå¾—åˆ°ä¸€ä¸ªä¸æ˜¯`main_type`ç±»å‹çš„å¯¹è±¡ï¼Œæ˜¯å¦è¿”å›é”™è¯¯ã€‚å¦‚æœä¸º`False`ï¼Œå‡½æ•°å°†ä¿æŒä¸`main_type`ä¸åŒç±»å‹çš„å¯¹è±¡ä¸å˜ã€‚**kwargs- å½“åº”ç”¨äºè§£åŒ…æ•°æ®æ—¶å°†ä¼ é€’ç»™`func`çš„å…³é”®å­—å‚æ•°ã€‚

é€’å½’åœ°åœ¨ç»™å®šåŸºæœ¬ç±»å‹çš„åµŒå¥—åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸Šåº”ç”¨å‡½æ•°ã€‚

#### `accelerate.utils.reduce`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L724)

```py
( tensor reduction = 'mean' scale = 1.0 )
```

å‚æ•°

+   `å¼ é‡`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«`torch.Tensor`ï¼‰- è¦å‡å°‘çš„æ•°æ®ã€‚

+   `reduction`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"mean"`ï¼‰- ä¸€ç§å‡å°‘æ–¹æ³•ã€‚å¯ä»¥æ˜¯`"mean"`ï¼Œâ€œsumâ€æˆ–â€œnoneâ€

+   `scale`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼‰- åœ¨å‡å°‘ååº”ç”¨çš„é»˜è®¤ç¼©æ”¾å€¼ï¼Œä»…åœ¨ XLA ä¸Šæœ‰æ•ˆã€‚

é€šè¿‡ç»™å®šæ“ä½œçš„å¹³å‡å€¼ï¼Œé€’å½’åœ°å‡å°‘æ‰€æœ‰è¿›ç¨‹ä¸­çš„å¼ é‡åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸­çš„å¼ é‡ã€‚

#### `accelerate.utils.send_to_device`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L144)

```py
( tensor device non_blocking = False skip_keys = None )
```

å‚æ•°

+   `å¼ é‡`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«`torch.Tensor`ï¼‰- è¦å‘é€åˆ°æŒ‡å®šè®¾å¤‡çš„æ•°æ®ã€‚

+   `device`ï¼ˆ`torch.device`ï¼‰- è¦å‘é€æ•°æ®çš„è®¾å¤‡ã€‚

é€’å½’åœ°å°†åµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸­çš„å…ƒç´ å‘é€åˆ°æŒ‡å®šè®¾å¤‡ã€‚

#### `accelerate.utils.slice_tensors`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/operations.py#L585)

```py
( data tensor_slice process_index = None num_processes = None )
```

å‚æ•°

+   `æ•°æ®`ï¼ˆåµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼ŒåŒ…å«`torch.Tensor`ï¼‰- è¦åˆ‡ç‰‡çš„æ•°æ®ã€‚

+   `tensor_slice`ï¼ˆ`slice`ï¼‰- è¦å–çš„åˆ‡ç‰‡ã€‚

é€’å½’åœ°åœ¨åµŒå¥—çš„åˆ—è¡¨/å…ƒç»„/å­—å…¸ä¸­çš„å¼ é‡ä¸­å–ä¸€ä¸ªåˆ‡ç‰‡ã€‚

## ç¯å¢ƒæ£€æŸ¥

è¿™äº›åŠŸèƒ½æ£€æŸ¥å½“å‰å·¥ä½œç¯å¢ƒçš„çŠ¶æ€ï¼ŒåŒ…æ‹¬æœ‰å…³æ“ä½œç³»ç»Ÿæœ¬èº«çš„ä¿¡æ¯ï¼Œå®ƒå¯ä»¥æ”¯æŒçš„å†…å®¹ï¼Œä»¥åŠç‰¹å®šä¾èµ–é¡¹æ˜¯å¦å·²å®‰è£…ã€‚

#### `accelerate.utils.is_bf16_available`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L130)

```py
( ignore_tpu = False )
```

æ£€æŸ¥æ˜¯å¦æ”¯æŒ bf16ï¼Œå¯é€‰æ‹©å¿½ç•¥ TPU

#### `accelerate.utils.is_ipex_available`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L255)

```py
( )
```

#### `accelerate.utils.is_mps_available`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/imports.py#L251)

```py
( )
```

#### `accelerate.utils.is_npu_available`

```py
( check_device = False )
```

æ£€æŸ¥æ˜¯å¦å®‰è£…äº†`torch_npu`ï¼Œå¹¶ä¸”å¯èƒ½ç¯å¢ƒä¸­æ˜¯å¦æœ‰ NPU

#### `accelerate.utils.is_torch_version`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/versions.py#L46)

```py
( operation: str version: str )
```

å‚æ•°

+   `operation`ï¼ˆ`str`ï¼‰â€” æ“ä½œç¬¦çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œä¾‹å¦‚`">"`æˆ–`"<="`

+   `version`ï¼ˆ`str`ï¼‰â€” PyTorch çš„å­—ç¬¦ä¸²ç‰ˆæœ¬

å°†å½“å‰çš„ PyTorch ç‰ˆæœ¬ä¸ç»™å®šçš„å‚è€ƒç‰ˆæœ¬è¿›è¡Œæ¯”è¾ƒã€‚

#### `accelerate.utils.is_tpu_available`

```py
( check_device = True )
```

æ£€æŸ¥æ˜¯å¦å®‰è£…äº†`torch_xla`ï¼Œå¹¶ä¸”å¯èƒ½ç¯å¢ƒä¸­æ˜¯å¦æœ‰ TPU

#### `accelerate.utils.is_xpu_available`

```py
( check_device = False )
```

æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜ç¡®ç¦ç”¨å®ƒ

## ç¯å¢ƒæ“ä½œ

#### `accelerate.utils.patch_environment`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L219)

```py
( **kwargs )
```

ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå°†æ¯ä¸ªå…³é”®å­—å‚æ•°æ·»åŠ åˆ°`os.environ`ä¸­ï¼Œå¹¶åœ¨é€€å‡ºæ—¶å°†å®ƒä»¬åˆ é™¤ã€‚

å°†`kwargs`ä¸­çš„å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶å°†æ‰€æœ‰é”®å¤§å†™ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import os
>>> from accelerate.utils import patch_environment

>>> with patch_environment(FOO="bar"):
...     print(os.environ["FOO"])  # prints "bar"
>>> print(os.environ["FOO"])  # raises KeyError
```

#### `accelerate.utils.clear_environment`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L186)

```py
( )
```

ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå°†ç¼“å­˜çš„åŸå§‹`os.environ`æ›¿æ¢ä¸ºä¸€ä¸ªç©ºå­—å…¸åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ã€‚

å½“æ­¤ä¸Šä¸‹æ–‡é€€å‡ºæ—¶ï¼Œç¼“å­˜çš„`os.environ`å°†æ¢å¤ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import os
>>> from accelerate.utils import clear_environment

>>> os.environ["FOO"] = "bar"
>>> with clear_environment():
...     print(os.environ)
...     os.environ["FOO"] = "new_bar"
...     print(os.environ["FOO"])
{}
new_bar

>>> print(os.environ["FOO"])
bar
```

#### `accelerate.commands.config.default.write_basic_config`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/commands/config/default.py#L29)

```py
( mixed_precision = 'no' save_location: str = '/github/home/.cache/huggingface/accelerate/default_config.yaml' use_xpu: bool = False )
```

å‚æ•°

+   `mixed_precision`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºâ€œnoâ€ï¼‰â€” è¦ä½¿ç”¨çš„æ··åˆç²¾åº¦ã€‚åº”è¯¥æ˜¯â€œnoâ€ï¼Œâ€œfp16â€æˆ–â€œbf16â€ä¸­çš„ä¸€ä¸ªã€‚

+   `save_location`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`default_json_config_file`ï¼‰â€” å¯é€‰çš„è‡ªå®šä¹‰ä¿å­˜ä½ç½®ã€‚åœ¨ä½¿ç”¨`accelerate launch`æ—¶åº”ä¼ é€’ç»™`--config_file`ã€‚é»˜è®¤ä½ç½®ä½äº huggingface ç¼“å­˜æ–‡ä»¶å¤¹å†…ï¼ˆ`~/.cache/huggingface`ï¼‰ï¼Œä½†å¯ä»¥é€šè¿‡è®¾ç½®`HF_HOME`ç¯å¢ƒå˜é‡ï¼Œç„¶åè·Ÿéš`accelerate/default_config.yaml`æ¥è¦†ç›–ã€‚

+   `use_xpu`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦åœ¨å¯ç”¨æ—¶ä½¿ç”¨ XPUã€‚

åˆ›å»ºå¹¶ä¿å­˜ä¸€ä¸ªåŸºæœ¬çš„é›†ç¾¤é…ç½®ï¼Œç”¨äºåœ¨æœ¬åœ°æœºå™¨ä¸Šä½¿ç”¨å¯èƒ½æœ‰å¤šä¸ª GPUã€‚å¦‚æœæ˜¯ä»… CPU çš„æœºå™¨ï¼Œè¿˜å°†è®¾ç½® CPUã€‚

é¦–æ¬¡è®¾ç½®ğŸ¤— Accelerate æ—¶ï¼Œå¯ä»¥ä½¿ç”¨`accelerate config`è€Œä¸æ˜¯è¿è¡Œ[~utils.write_basic_config]ä½œä¸ºå¿«é€Ÿé…ç½®çš„æ›¿ä»£æ–¹æ³•ã€‚

## å†…å­˜

#### `accelerate.find_executable_batch_size`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/memory.py#L83)

```py
( function: callable = None starting_batch_size: int = 128 )
```

å‚æ•°

+   `function`ï¼ˆ`callable`ï¼Œ*å¯é€‰*ï¼‰â€” è¦åŒ…è£…çš„å‡½æ•°

+   `starting_batch_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€” å°è¯•é€‚åº”å†…å­˜çš„æ‰¹é‡å¤§å°

ä¸€ä¸ªåŸºæœ¬çš„è£…é¥°å™¨ï¼Œå°†å°è¯•æ‰§è¡Œ`function`ã€‚å¦‚æœç”±äºå†…å­˜ä¸è¶³æˆ– CUDNN ç›¸å…³çš„å¼‚å¸¸è€Œå¤±è´¥ï¼Œåˆ™å°†æ‰¹é‡å¤§å°å‡åŠå¹¶ä¼ é€’ç»™`function`

`function`å¿…é¡»å°†`batch_size`å‚æ•°ä½œä¸ºå…¶ç¬¬ä¸€ä¸ªå‚æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate.utils import find_executable_batch_size

>>> @find_executable_batch_size(starting_batch_size=128)
... def train(batch_size, model, optimizer):
...     ...

>>> train(model, optimizer)
```

## å»ºæ¨¡

è¿™äº›å®ç”¨ç¨‹åºä¸ä¸ PyTorch æ¨¡å‹äº¤äº’æœ‰å…³

#### `accelerate.utils.calculate_maximum_sizes`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1004)

```py
( model: Module )
```

è®¡ç®—æ¨¡å‹åŠå…¶æœ€å¤§å±‚çš„æ€»å¤§å°

#### `accelerate.utils.compute_module_sizes`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L686)

```py
( model: Module dtype: Union = None special_dtypes: Optional = None )
```

è®¡ç®—ç»™å®šæ¨¡å‹çš„æ¯ä¸ªå­æ¨¡å—çš„å¤§å°ã€‚

#### `accelerate.utils.extract_model_from_parallel`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L56)

```py
( model keep_fp32_wrapper: bool = True ) â†’ export const metadata = 'undefined';torch.nn.Module
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦æå–çš„æ¨¡å‹ã€‚

+   `keep_fp32_wrapper` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä»æ¨¡å‹ä¸­åˆ é™¤æ··åˆç²¾åº¦é’©å­ã€‚

è¿”å›

`torch.nn.Module`

æå–çš„æ¨¡å‹ã€‚

ä»å…¶åˆ†å¸ƒå¼å®¹å™¨ä¸­æå–æ¨¡å‹ã€‚

#### `accelerate.utils.get_balanced_memory`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L872)

```py
( model: Module max_memory: Optional = None no_split_module_classes: Optional = None dtype: Union = None special_dtypes: Optional = None low_zero: bool = False )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦åˆ†æçš„æ¨¡å‹ã€‚

+   `max_memory` (`Dict`, *å¯é€‰*) â€” è®¾å¤‡æ ‡è¯†ç¬¦åˆ°æœ€å¤§å†…å­˜çš„å­—å…¸ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºå¯ç”¨çš„æœ€å¤§å†…å­˜ã€‚ç¤ºä¾‹ï¼š`max_memory={0: "1GB"}`ã€‚

+   `no_split_module_classes` (`List[str]`, *å¯é€‰*) â€” ä¸åº”è·¨è®¾å¤‡æ‹†åˆ†çš„å±‚ç±»ååˆ—è¡¨ï¼ˆä¾‹å¦‚å…·æœ‰æ®‹å·®è¿æ¥çš„ä»»ä½•å±‚ï¼‰ã€‚

+   `dtype` (`str` æˆ– `torch.dtype`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼ŒåŠ è½½æ—¶å°†å°†æƒé‡è½¬æ¢ä¸ºè¯¥ç±»å‹ã€‚

+   `special_dtypes` (`Dict[str, Union[str, torch.device]]`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼Œç”¨äºæŸäº›ç‰¹å®šæƒé‡çš„ç‰¹æ®Šæ•°æ®ç±»å‹ï¼ˆå°†è¦†ç›–é»˜è®¤ç”¨äºæ‰€æœ‰æƒé‡çš„ dtypeï¼‰ã€‚

+   `low_zero` (`bool`, *å¯é€‰*) â€” æœ€å°åŒ– GPU 0 ä¸Šçš„æƒé‡æ•°é‡ï¼Œåœ¨å…¶ä»–æ“ä½œï¼ˆå¦‚ Transformers ç”Ÿæˆå‡½æ•°ï¼‰ä¸­ä½¿ç”¨æ—¶å¾ˆæ–¹ä¾¿ã€‚

ä¸º infer_auto_device_map() è®¡ç®—ä¸€ä¸ª `max_memory` å­—å…¸ï¼Œä»¥å¹³è¡¡æ¯ä¸ªå¯ç”¨ GPU çš„ä½¿ç”¨ã€‚

æ‰€æœ‰è®¡ç®—éƒ½æ˜¯é€šè¿‡åˆ†ææ¨¡å‹å‚æ•°çš„å¤§å°å’Œæ•°æ®ç±»å‹æ¥å®Œæˆçš„ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯ä»¥ä½äºå…ƒè®¾å¤‡ä¸Šï¼ˆå°±åƒåœ¨ `init_empty_weights` ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆå§‹åŒ–æ—¶ä¸€æ ·ï¼‰ã€‚

#### `accelerate.utils.get_max_layer_size`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L719)

```py
( modules: List module_sizes: Dict no_split_module_classes: List ) â†’ export const metadata = 'undefined';Tuple[int, List[str]]
```

å‚æ•°

+   `modules` (`List[Tuple[str, torch.nn.Module]]`) â€” æˆ‘ä»¬è¦ç¡®å®šæœ€å¤§å±‚å°ºå¯¸çš„å‘½åæ¨¡å—åˆ—è¡¨ã€‚

+   `module_sizes` (`Dict[str, int]`) â€” å°†æ¯ä¸ªå±‚åç§°æ˜ å°„åˆ°å…¶å¤§å°çš„å­—å…¸ï¼ˆç”± `compute_module_sizes` ç”Ÿæˆï¼‰ã€‚

+   `no_split_module_classes` (`List[str]`) â€” ä¸å¸Œæœ›æ‹†åˆ†çš„å±‚ç±»ååˆ—è¡¨ã€‚

è¿”å›

`Tuple[int, List[str]]`

å…·æœ‰å®ç°æœ€å¤§å°ºå¯¸çš„å±‚åç§°åˆ—è¡¨çš„æœ€å¤§å±‚å°ºå¯¸ã€‚

å°†æ‰«æå‘½åæ¨¡å—åˆ—è¡¨å¹¶è¿”å›ä¸€ä¸ªå®Œæ•´å±‚ä½¿ç”¨çš„æœ€å¤§å°ºå¯¸çš„å®ç”¨å‡½æ•°ã€‚å±‚çš„å®šä¹‰ä¸ºï¼š

+   æ²¡æœ‰ç›´æ¥å­çº§ï¼ˆåªæœ‰å‚æ•°å’Œç¼“å†²åŒºï¼‰çš„æ¨¡å—

+   ç±»ååœ¨åˆ—è¡¨ `no_split_module_classes` ä¸­çš„æ¨¡å—

#### `accelerate.infer_auto_device_map`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1022)

```py
( model: Module max_memory: Optional = None no_split_module_classes: Optional = None dtype: Union = None special_dtypes: Optional = None verbose: bool = False clean_result: bool = True )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦åˆ†æçš„æ¨¡å‹ã€‚

+   `max_memory` (`Dict`, *å¯é€‰*) â€” è®¾å¤‡æ ‡è¯†ç¬¦åˆ°æœ€å¤§å†…å­˜çš„å­—å…¸ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºå¯ç”¨çš„æœ€å¤§å†…å­˜ã€‚ç¤ºä¾‹ï¼š`max_memory={0: "1GB"}`ã€‚

+   `no_split_module_classes` (`List[str]`, *å¯é€‰*) â€” ä¸åº”è·¨è®¾å¤‡æ‹†åˆ†çš„å±‚ç±»ååˆ—è¡¨ï¼ˆä¾‹å¦‚å…·æœ‰æ®‹å·®è¿æ¥çš„ä»»ä½•å±‚ï¼‰ã€‚

+   `dtype` (`str` æˆ– `torch.dtype`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼ŒåŠ è½½æ—¶å°†å°†æƒé‡è½¬æ¢ä¸ºè¯¥ç±»å‹ã€‚

+   `special_dtypes` (`Dict[str, Union[str, torch.device]]`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼Œç”¨äºæŸäº›ç‰¹å®šæƒé‡çš„ç‰¹æ®Šæ•°æ®ç±»å‹ï¼ˆå°†è¦†ç›–é»˜è®¤ç”¨äºæ‰€æœ‰æƒé‡çš„ dtypeï¼‰ã€‚

+   `verbose` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨å‡½æ•°æ„å»º device_map æ—¶æä¾›è°ƒè¯•è¯­å¥ã€‚

+   `clean_result` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” é€šè¿‡å°†æ‰€æœ‰æ”¾åœ¨åŒä¸€è®¾å¤‡ä¸Šçš„å­æ¨¡å—åˆ†ç»„æ¥æ¸…ç†ç»“æœçš„ device_mapã€‚

ä¸ºç»™å®šæ¨¡å‹è®¡ç®—è®¾å¤‡æ˜ å°„ï¼Œä¼˜å…ˆè€ƒè™‘ GPUï¼Œç„¶åè½¬ç§»åˆ° CPUï¼Œæœ€åè½¬ç§»åˆ°ç£ç›˜ï¼Œä½¿å¾—ï¼š

+   æˆ‘ä»¬ä¸ä¼šè¶…å‡ºä»»ä½• GPU å¯ç”¨çš„å†…å­˜ã€‚

+   å¦‚æœéœ€è¦è½¬ç§»åˆ° CPUï¼Œæ€»æ˜¯åœ¨ GPU 0 ä¸Šç•™æœ‰ç©ºé—´ï¼Œä»¥å°†åœ¨ CPU ä¸Šè½¬ç§»çš„å…·æœ‰æœ€å¤§å°ºå¯¸çš„å±‚æ”¾å›ã€‚

+   å¦‚æœéœ€è¦è½¬ç§»åˆ° CPUï¼Œæˆ‘ä»¬ä¸ä¼šè¶…å‡º CPU å¯ç”¨çš„ RAMã€‚

+   å¦‚æœéœ€è¦è½¬ç§»åˆ°ç£ç›˜ï¼Œæ€»æ˜¯åœ¨ CPU ä¸Šç•™æœ‰ç©ºé—´ï¼Œä»¥å°†åœ¨ç£ç›˜ä¸Šè½¬ç§»çš„å…·æœ‰æœ€å¤§å°ºå¯¸çš„å±‚æ”¾å›ã€‚

æ‰€æœ‰è®¡ç®—éƒ½æ˜¯é€šè¿‡åˆ†ææ¨¡å‹å‚æ•°çš„å¤§å°å’Œæ•°æ®ç±»å‹æ¥å®Œæˆçš„ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯ä»¥åœ¨å…ƒè®¾å¤‡ä¸Šï¼ˆå°±åƒåœ¨`init_empty_weights`ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆå§‹åŒ–æ—¶ä¸€æ ·ï¼‰ã€‚

#### `accelerate.load_checkpoint_in_model`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1442)

```py
( model: Module checkpoint: Union device_map: Optional = None offload_folder: Union = None dtype: Union = None offload_state_dict: bool = False offload_buffers: bool = False keep_in_fp32_modules: List = None offload_8bit_bnb: bool = False )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” æˆ‘ä»¬è¦åŠ è½½æ£€æŸ¥ç‚¹çš„æ¨¡å‹ã€‚

+   `checkpoint` (`str`æˆ–`os.PathLike`) â€” è¦åŠ è½½çš„æ–‡ä»¶å¤¹æ£€æŸ¥ç‚¹ã€‚å®ƒå¯ä»¥æ˜¯ï¼š

    +   åŒ…å«æ•´ä¸ªæ¨¡å‹çŠ¶æ€å­—å…¸çš„æ–‡ä»¶è·¯å¾„ã€‚

    +   åŒ…å«åˆ†ç‰‡æ£€æŸ¥ç‚¹ç´¢å¼•çš„`.json`æ–‡ä»¶è·¯å¾„ã€‚

    +   ä¸€ä¸ªåŒ…å«å”¯ä¸€çš„`.index.json`æ–‡ä»¶å’Œæ£€æŸ¥ç‚¹åˆ†ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

    +   ä¸€ä¸ªåŒ…å«å”¯ä¸€çš„ pytorch_model.bin æˆ– model.safetensors æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

+   `device_map` (`Dict[str, Union[int, str, torch.device]]`, *å¯é€‰*) â€” ä¸€ä¸ªæŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥å»å“ªé‡Œçš„æ˜ å°„ã€‚å®ƒä¸éœ€è¦ç»†åŒ–åˆ°æ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°ï¼Œä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚

+   `offload_folder` (`str`æˆ–`os.PathLike`, *å¯é€‰*) â€” å¦‚æœ`device_map`åŒ…å«ä»»ä½•å€¼ä¸º`"disk"`ï¼Œåˆ™æˆ‘ä»¬å°†è½¬ç§»æƒé‡çš„æ–‡ä»¶å¤¹ã€‚

+   `dtype` (`str`æˆ–`torch.dtype`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼ŒåŠ è½½æ—¶æƒé‡å°†è½¬æ¢ä¸ºè¯¥ç±»å‹ã€‚

+   `offload_state_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`False`) â€” å¦‚æœä¸º`True`ï¼Œå°†ä¸´æ—¶å°† CPU çŠ¶æ€å­—å…¸è½¬ç§»åˆ°ç¡¬ç›˜ä¸Šï¼Œä»¥é¿å…å¦‚æœ CPU çŠ¶æ€å­—å…¸çš„æƒé‡+æœ€å¤§åˆ†ç‰‡çš„æƒé‡ä¸é€‚åˆæ—¶è¶…å‡º CPU RAMã€‚

+   `offload_buffers` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦å°†ç¼“å†²åŒºåŒ…å«åœ¨è½¬ç§»åˆ°ç£ç›˜çš„æƒé‡ä¸­ã€‚

+   `keep_in_fp32_modules(List[str],` *å¯é€‰*) â€” æˆ‘ä»¬ä¿ç•™åœ¨`torch.float32`æ•°æ®ç±»å‹ä¸­çš„æ¨¡å—åˆ—è¡¨ã€‚

+   `offload_8bit_bnb` (`bool`, *å¯é€‰*) â€” æ˜¯å¦å¯ç”¨åœ¨ cpu/disk ä¸Šè½¬ç§» 8 ä½æ¨¡å—ã€‚

åœ¨æ¨¡å‹ä¸­åŠ è½½ï¼ˆå¯èƒ½æ˜¯åˆ†ç‰‡çš„ï¼‰æ£€æŸ¥ç‚¹ï¼Œå¯èƒ½åœ¨åŠ è½½æ—¶å°†æƒé‡å‘é€åˆ°æŒ‡å®šçš„è®¾å¤‡ã€‚

ä¸€æ—¦è·¨è®¾å¤‡åŠ è½½ï¼Œæ‚¨ä»ç„¶éœ€è¦åœ¨æ¨¡å‹ä¸Šè°ƒç”¨ dispatch_model()ä½¿å…¶èƒ½å¤Ÿè¿è¡Œã€‚è¦å°†æ£€æŸ¥ç‚¹åŠ è½½å’Œåˆ†å‘ç»„åˆåœ¨ä¸€ä¸ªå•ä¸€è°ƒç”¨ä¸­ï¼Œè¯·ä½¿ç”¨ load_checkpoint_and_dispatch()ã€‚

#### `accelerate.utils.load_offloaded_weights`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L842)

```py
( model index offload_folder )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦åŠ è½½æƒé‡çš„æ¨¡å‹ã€‚

+   `index` (`dict`) â€” åŒ…å«ä»æ¨¡å‹è½¬ç§»çš„æ¯ä¸ªå‚æ•°çš„å‚æ•°åç§°åŠå…¶å…ƒæ•°æ®çš„å­—å…¸ã€‚

+   `offload_folder` (`str`) â€” å­˜å‚¨è½¬ç§»æƒé‡çš„æ–‡ä»¶å¤¹ã€‚

å°†æƒé‡ä»è½¬ç§»æ–‡ä»¶å¤¹åŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚

#### `accelerate.utils.load_state_dict`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1301)

```py
( checkpoint_file device_map = None )
```

å‚æ•°

+   `checkpoint_file` (`str`) â€” è¦åŠ è½½çš„æ£€æŸ¥ç‚¹è·¯å¾„ã€‚

+   `device_map` (`Dict[str, Union[int, str, torch.device]]`, *å¯é€‰*) â€” æŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥å»çš„ä½ç½®çš„æ˜ å°„ã€‚ä¸éœ€è¦å¯¹æ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°è¿›è¡Œç»†åŒ–ï¼Œä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚

ä»ç»™å®šæ–‡ä»¶åŠ è½½æ£€æŸ¥ç‚¹ã€‚å¦‚æœæ£€æŸ¥ç‚¹æ˜¯åœ¨ safetensors æ ¼å¼ä¸­å¹¶ä¸”ä¼ é€’äº†è®¾å¤‡æ˜ å°„ï¼Œåˆ™æƒé‡å¯ä»¥ç›´æ¥å¿«é€ŸåŠ è½½åˆ° GPU ä¸Šã€‚

#### `accelerate.utils.offload_state_dict`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/offload.py#L85)

```py
( save_dir: Union state_dict: Dict )
```

å‚æ•°

+   `save_dir` (`str` æˆ– `os.PathLike`) â€” è¦å¸è½½çŠ¶æ€å­—å…¸çš„ç›®å½•ã€‚

+   `state_dict` (`Dict[str, torch.Tensor]`) â€” è¦å¸è½½çš„å¼ é‡å­—å…¸ã€‚

åœ¨ç»™å®šæ–‡ä»¶å¤¹ä¸­å¸è½½çŠ¶æ€å­—å…¸ã€‚

#### `accelerate.utils.retie_parameters`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L644)

```py
( model tied_params )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦é‡æ–°ç»‘å®šå‚æ•°çš„æ¨¡å‹ã€‚

+   `tied_params` (`List[List[str]]`) â€” é€šè¿‡`find_tied_parameters`è·å¾—çš„å‚æ•°åç§°åˆ°ç»‘å®šå‚æ•°åç§°çš„æ˜ å°„ã€‚

åœ¨ç»™å®šæ¨¡å‹ä¸­é‡æ–°ç»‘å®šç»‘å®šå‚æ•°ï¼Œå¦‚æœé“¾æ¥è¢«æ–­å¼€ï¼ˆä¾‹å¦‚æ·»åŠ é’©å­æ—¶ï¼‰ã€‚

#### `accelerate.utils.set_module_tensor_to_device`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L275)

```py
( module: Module tensor_name: str device: Union value: Optional = None dtype: Union = None fp16_statistics: Optional = None tied_params_map: Optional = None )
```

å‚æ•°

+   `module` (`torch.nn.Module`) â€” æˆ‘ä»¬æƒ³è¦ç§»åŠ¨çš„å¼ é‡æ‰€åœ¨çš„æ¨¡å—ã€‚

+   `tensor_name` (`str`) â€” å‚æ•°/ç¼“å†²åŒºçš„å®Œæ•´åç§°ã€‚

+   `device` (`int`, `str` æˆ– `torch.device`) â€” è¦è®¾ç½®å¼ é‡çš„è®¾å¤‡ã€‚

+   `value` (`torch.Tensor`, *å¯é€‰*) â€” å¼ é‡çš„å€¼ï¼ˆåœ¨ä»å…ƒè®¾å¤‡è½¬åˆ°ä»»ä½•å…¶ä»–è®¾å¤‡æ—¶æœ‰ç”¨ï¼‰ã€‚

+   `dtype` (`torch.dtype`, *å¯é€‰*) â€” å¦‚æœä¼ é€’äº†å‚æ•°ï¼Œå‚æ•°çš„å€¼å°†è¢«è½¬æ¢ä¸ºè¿™ä¸ª`dtype`ã€‚å¦åˆ™ï¼Œ`value`å°†è¢«è½¬æ¢ä¸ºæ¨¡å‹ä¸­ç°æœ‰å‚æ•°çš„`dtype`ã€‚

+   `fp16_statistics` (`torch.HalfTensor`, *å¯é€‰*) â€” è¦è®¾ç½®åœ¨æ¨¡å—ä¸Šçš„ fp16 ç»Ÿè®¡ä¿¡æ¯åˆ—è¡¨ï¼Œç”¨äº 8 ä½æ¨¡å‹åºåˆ—åŒ–ã€‚

+   `tied_params_map` (Dict[int, Dict[torch.device, torch.Tensor]], *å¯é€‰*, é»˜è®¤ä¸º`None`) â€” å½“å‰æ•°æ®æŒ‡é’ˆåˆ°å·²åˆ†æ´¾çš„ç»‘å®šæƒé‡è®¾å¤‡å­—å…¸çš„æ˜ å°„ã€‚å¯¹äºç»™å®šçš„æ‰§è¡Œè®¾å¤‡ï¼Œæ­¤å‚æ•°å¯¹äºé‡ç”¨è®¾å¤‡ä¸Šå…±äº«æƒé‡çš„ç¬¬ä¸€ä¸ªå¯ç”¨æŒ‡é’ˆå¯¹äºæ‰€æœ‰å…¶ä»–è®¾å¤‡è€Œè¨€æ˜¯æœ‰ç”¨çš„ï¼Œè€Œä¸æ˜¯å¤åˆ¶å†…å­˜ã€‚

ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºå°†æ¨¡å—çš„ç»™å®šå¼ é‡ï¼ˆå‚æ•°æˆ–ç¼“å†²åŒºï¼‰è®¾ç½®åœ¨ç‰¹å®šè®¾å¤‡ä¸Šï¼ˆè¯·æ³¨æ„ï¼Œæ‰§è¡Œ`param.to(device)`ä¼šåˆ›å»ºä¸€ä¸ªä¸å‚æ•°ä¸ç›¸å…³è”çš„æ–°å¼ é‡ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦è¿™ä¸ªå‡½æ•°ï¼‰ã€‚

#### `accelerate.utils.shard_checkpoint`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L193)

```py
( state_dict: Dict max_shard_size: Union = '10GB' weights_name: str = 'pytorch_model.bin' )
```

å‚æ•°

+   `state_dict` (`Dict[str, torch.Tensor]`) â€” è¦ä¿å­˜çš„æ¨¡å‹çš„çŠ¶æ€å­—å…¸ã€‚

+   `max_shard_size` (`int` æˆ– `str`, *å¯é€‰*, é»˜è®¤ä¸º`"10GB"`) â€” æ¯ä¸ªå­æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚å¦‚æœä»¥å­—ç¬¦ä¸²å½¢å¼è¡¨ç¤ºï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚`"5MB"`ï¼‰ã€‚

+   `weights_name` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"pytorch_model.bin"`) â€” æ¨¡å‹ä¿å­˜æ–‡ä»¶çš„åç§°ã€‚

å°†æ¨¡å‹çŠ¶æ€å­—å…¸æ‹†åˆ†ä¸ºå­æ£€æŸ¥ç‚¹ï¼Œä»¥ä¾¿æ¯ä¸ªå­æ£€æŸ¥ç‚¹çš„æœ€ç»ˆå¤§å°ä¸è¶…è¿‡ç»™å®šå¤§å°ã€‚

å­æ£€æŸ¥ç‚¹æ˜¯é€šè¿‡æŒ‰ç…§å…¶é”®çš„é¡ºåºè¿­ä»£`state_dict`æ¥ç¡®å®šçš„ï¼Œå› æ­¤æ²¡æœ‰ä¼˜åŒ–ä½¿æ¯ä¸ªå­æ£€æŸ¥ç‚¹å°½å¯èƒ½æ¥è¿‘ä¼ é€’çš„æœ€å¤§å¤§å°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœé™åˆ¶ä¸º 10GBï¼Œæˆ‘ä»¬æœ‰å¤§å°ä¸º[6GB, 6GB, 2GB, 6GB, 2GB, 2GB]çš„æƒé‡ï¼Œå®ƒä»¬å°†è¢«åˆ†å‰²ä¸º[6GB]ï¼Œ[6+2GB]ï¼Œ[6+2+2GB]ï¼Œè€Œä¸æ˜¯[6+2+2GB]ï¼Œ[6+2GB]ï¼Œ[6GB]ã€‚

å¦‚æœæ¨¡å‹çš„æƒé‡ä¹‹ä¸€å¤§äº`max_shard_size`ï¼Œå®ƒå°†æœ€ç»ˆä½äºè‡ªå·±çš„å­æ£€æŸ¥ç‚¹ä¸­ï¼Œå…¶å¤§å°å¤§äº`max_shard_size`ã€‚

## å¹¶è¡Œ

è¿™äº›åŒ…æ‹¬åº”è¯¥åœ¨å¹¶è¡Œå·¥ä½œæ—¶ä½¿ç”¨çš„é€šç”¨å®ç”¨ç¨‹åºã€‚

#### `accelerate.utils.extract_model_from_parallel`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L56)

```py
( model keep_fp32_wrapper: bool = True ) â†’ export const metadata = 'undefined';torch.nn.Module
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦æå–çš„æ¨¡å‹ã€‚

+   `keep_fp32_wrapper` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä»æ¨¡å‹ä¸­åˆ é™¤æ··åˆç²¾åº¦é’©å­ã€‚

è¿”å›

`torch.nn.Module`

æå–çš„æ¨¡å‹ã€‚

ä»å…¶åˆ†å¸ƒå¼å®¹å™¨ä¸­æå–æ¨¡å‹ã€‚

#### `accelerate.utils.save`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L156)

```py
( obj f save_on_each_node: bool = False safe_serialization: bool = False )
```

å‚æ•°

+   `save_on_each_node` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åœ¨å…¨å±€ä¸»è¿›ç¨‹ä¸Šä¿å­˜

+   `safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors` æˆ–ä¼ ç»Ÿçš„ PyTorch æ–¹å¼ï¼ˆä½¿ç”¨ `pickle`ï¼‰ä¿å­˜ `obj`ã€‚

å°†æ•°æ®ä¿å­˜åˆ°ç£ç›˜ã€‚ç”¨äºæ›¿ä»£ `torch.save()`ã€‚

#### `accelerate.utils.wait_for_everyone`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/other.py#L108)

```py
( )
```

åœ¨è„šæœ¬ä¸­å¼•å…¥ä¸€ä¸ªé˜»å¡ç‚¹ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹åœ¨ç»§ç»­ä¹‹å‰éƒ½å·²åˆ°è¾¾æ­¤ç‚¹ã€‚

ç¡®ä¿æ‰€æœ‰è¿›ç¨‹å°†åˆ°è¾¾æ­¤æŒ‡ä»¤ï¼Œå¦åˆ™å…¶ä¸­ä¸€ä¸ªè¿›ç¨‹å°†æ°¸è¿œæŒ‚èµ·ã€‚

## éšæœº

è¿™äº›å®ç”¨ç¨‹åºæ¶‰åŠè®¾ç½®å’ŒåŒæ­¥æ‰€æœ‰éšæœºçŠ¶æ€ã€‚

#### `accelerate.utils.set_seed`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L31)

```py
( seed: int device_specific: bool = False )
```

å‚æ•°

+   `seed` (`int`) â€” è¦è®¾ç½®çš„ç§å­ã€‚

+   `device_specific` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ç¨å¾®åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šä½¿ç”¨ `self.process_index` ä¸åŒçš„ç§å­ã€‚

ç”¨äºåœ¨ `random`ã€`numpy`ã€`torch` ä¸­è®¾ç½®ç§å­ä»¥è·å¾—å¯é‡ç°è¡Œä¸ºçš„è¾…åŠ©å‡½æ•°ã€‚

#### `accelerate.utils.synchronize_rng_state`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L57)

```py
( rng_type: Optional = None generator: Optional = None )
```

#### `accelerate.synchronize_rng_states`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/random.py#L109)

```py
( rng_types: List generator: Optional = None )
```

## PyTorch XLA

è¿™äº›åŒ…æ‹¬åœ¨ä½¿ç”¨ PyTorch ä¸ XLA æ—¶æœ‰ç”¨çš„å®ç”¨ç¨‹åºã€‚

#### `accelerate.utils.install_xla`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/torch_xla.py#L20)

```py
( upgrade: bool = False )
```

å‚æ•°

+   `upgrade` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å‡çº§ `torch` å¹¶å®‰è£…æœ€æ–°çš„ `torch_xla` è½®å­ã€‚

åœ¨ Google Colaboratory ä¸­æ ¹æ® `torch` ç‰ˆæœ¬å®‰è£…é€‚å½“çš„ xla è½®å­çš„è¾…åŠ©å‡½æ•°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate.utils import install_xla

>>> install_xla(upgrade=True)
```

## åŠ è½½æ¨¡å‹æƒé‡

è¿™äº›åŒ…æ‹¬æœ‰ç”¨äºåŠ è½½æ£€æŸ¥ç‚¹çš„å®ç”¨ç¨‹åºã€‚

#### `accelerate.load_checkpoint_in_model`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/modeling.py#L1442)

```py
( model: Module checkpoint: Union device_map: Optional = None offload_folder: Union = None dtype: Union = None offload_state_dict: bool = False offload_buffers: bool = False keep_in_fp32_modules: List = None offload_8bit_bnb: bool = False )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” æˆ‘ä»¬è¦åŠ è½½æ£€æŸ¥ç‚¹çš„æ¨¡å‹ã€‚

+   `checkpoint` (`str` æˆ– `os.PathLike`) â€” è¦åŠ è½½çš„æ–‡ä»¶å¤¹æ£€æŸ¥ç‚¹ã€‚å¯ä»¥æ˜¯ï¼š

    +   åŒ…å«æ•´ä¸ªæ¨¡å‹çŠ¶æ€å­—å…¸çš„æ–‡ä»¶è·¯å¾„

    +   åŒ…å«æŒ‡å‘åˆ†ç‰‡æ£€æŸ¥ç‚¹ç´¢å¼•çš„`.json`æ–‡ä»¶çš„è·¯å¾„

    +   åŒ…å«å”¯ä¸€çš„ `.index.json` æ–‡ä»¶å’Œæ£€æŸ¥ç‚¹åˆ†ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

    +   åŒ…å«å”¯ä¸€çš„ pytorch_model.bin æˆ– model.safetensors æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

+   `device_map` (`Dict[str, Union[int, str, torch.device]]`, *å¯é€‰*) â€” æŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”æ”¾ç½®åœ¨ä½•å¤„çš„æ˜ å°„ã€‚å®ƒä¸éœ€è¦è¢«ç»†åŒ–åˆ°æ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°ï¼Œä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…éƒ¨ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚

+   `offload_folder` (`str` æˆ– `os.PathLike`, *å¯é€‰*) â€” å¦‚æœ `device_map` åŒ…å«ä»»ä½•å€¼ `"disk"`ï¼Œåˆ™æˆ‘ä»¬å°†å¸è½½æƒé‡çš„æ–‡ä»¶å¤¹ã€‚

+   `dtype` (`str` æˆ– `torch.dtype`, *å¯é€‰*) â€” å¦‚æœæä¾›ï¼ŒåŠ è½½æ—¶å°†å°†æƒé‡è½¬æ¢ä¸ºè¯¥ç±»å‹ã€‚

+   `offload_state_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `True`ï¼Œå°†ä¸´æ—¶å°† CPU çŠ¶æ€å­—å…¸è½¬ç§»åˆ°ç¡¬ç›˜ä¸Šï¼Œä»¥é¿å…å¦‚æœ CPU çŠ¶æ€å­—å…¸çš„é‡é‡ + æœ€å¤§åˆ†ç‰‡çš„é‡é‡ä¸é€‚åˆ CPU RAMã€‚

+   `offload_buffers` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å°†ç¼“å†²åŒºåŒ…å«åœ¨å¸è½½åˆ°ç£ç›˜çš„æƒé‡ä¸­ã€‚

+   `keep_in_fp32_modules(List[str],` *å¯é€‰*) â€” æˆ‘ä»¬ä¿ç•™åœ¨ `torch.float32` æ•°æ®ç±»å‹ä¸­çš„æ¨¡å—åˆ—è¡¨ã€‚

+   `offload_8bit_bnb` (`bool`, *å¯é€‰*) â€” æ˜¯å¦å¯ç”¨åœ¨ cpu/ç£ç›˜ä¸Šå¸è½½ 8 ä½æ¨¡å—ã€‚

åŠ è½½ï¼ˆå¯èƒ½æ˜¯åˆ†ç‰‡çš„ï¼‰æ£€æŸ¥ç‚¹åˆ°æ¨¡å‹ä¸­ï¼Œå¯èƒ½åœ¨åŠ è½½æ—¶å°†æƒé‡å‘é€åˆ°ç»™å®šè®¾å¤‡ã€‚

ä¸€æ—¦åœ¨è®¾å¤‡é—´åŠ è½½å®Œæˆï¼Œæ‚¨ä»ç„¶éœ€è¦è°ƒç”¨ dispatch_model()æ¥ä½¿æ¨¡å‹èƒ½å¤Ÿè¿è¡Œã€‚ä¸ºäº†åœ¨ä¸€ä¸ªå•ä¸€è°ƒç”¨ä¸­ç»„åˆæ£€æŸ¥ç‚¹åŠ è½½å’Œåˆ†å‘ï¼Œå¯ä»¥ä½¿ç”¨ load_checkpoint_and_dispatch()ã€‚

## é‡åŒ–

è¿™äº›åŒ…æ‹¬å¯¹é‡åŒ–æ¨¡å‹æœ‰ç”¨çš„å®ç”¨ç¨‹åºã€‚

#### `accelerate.utils.load_and_quantize_model`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/bnb.py#L44)

```py
( model: Module bnb_quantization_config: BnbQuantizationConfig weights_location: Union = None device_map: Optional = None no_split_module_classes: Optional = None max_memory: Optional = None offload_folder: Union = None offload_state_dict: bool = False ) â†’ export const metadata = 'undefined';torch.nn.Module
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¾“å…¥æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¯ä»¥å·²ç»åŠ è½½æˆ–åœ¨å…ƒè®¾å¤‡ä¸Š

+   `bnb_quantization_config` (`BnbQuantizationConfig`) â€” ä½å’Œå­—èŠ‚é‡åŒ–å‚æ•°

+   `weights_location` (`str` or `os.PathLike`) â€” è¦åŠ è½½çš„æƒé‡æ–‡ä»¶å¤¹ã€‚å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªåŒ…å«æ•´ä¸ªæ¨¡å‹çŠ¶æ€å­—å…¸çš„æ–‡ä»¶è·¯å¾„

    +   ä¸€ä¸ªåŒ…å«åˆ†ç‰‡æ£€æŸ¥ç‚¹ç´¢å¼•çš„ `.json` æ–‡ä»¶è·¯å¾„

    +   ä¸€ä¸ªåŒ…å«å”¯ä¸€çš„ `.index.json` æ–‡ä»¶å’Œæ£€æŸ¥ç‚¹åˆ†ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

    +   ä¸€ä¸ªåŒ…å«å”¯ä¸€çš„ pytorch_model.bin æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

+   `device_map` (`Dict[str, Union[int, str, torch.device]]`, *å¯é€‰*) â€” æŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥å»å“ªé‡Œçš„æ˜ å°„ã€‚å®ƒä¸éœ€è¦è¢«ç»†åŒ–åˆ°æ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°ï¼Œä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚

+   `no_split_module_classes` (`List[str]`, *å¯é€‰*) â€” ä¸åº”è¯¥è·¨è®¾å¤‡åˆ†å‰²çš„å±‚ç±»åç§°åˆ—è¡¨ï¼ˆä¾‹å¦‚å…·æœ‰æ®‹å·®è¿æ¥çš„ä»»ä½•å±‚ï¼‰ã€‚

+   `max_memory` (`Dict`, *å¯é€‰*) â€” è®¾å¤‡æ ‡è¯†ç¬¦åˆ°æœ€å¤§å†…å­˜çš„å­—å…¸ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºå¯ç”¨çš„æœ€å¤§å†…å­˜ã€‚

+   `offload_folder` (`str` or `os.PathLike`, *å¯é€‰*) â€” å¦‚æœ `device_map` åŒ…å«ä»»ä½•å€¼ä¸º `"disk"`ï¼Œåˆ™æˆ‘ä»¬å°†å¸è½½æƒé‡çš„æ–‡ä»¶å¤¹ã€‚

+   `offload_state_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º `True`ï¼Œå°†ä¸´æ—¶å°† CPU çŠ¶æ€å­—å…¸å¸è½½åˆ°ç¡¬ç›˜ä¸Šï¼Œä»¥é¿å…å¦‚æœ CPU çŠ¶æ€å­—å…¸çš„é‡é‡ + æœ€å¤§åˆ†ç‰‡çš„é‡é‡ä¸é€‚åˆæ—¶ä¼šè¶…å‡º CPU RAMã€‚

è¿”å›

`torch.nn.Module`

é‡åŒ–åçš„æ¨¡å‹

æ­¤å‡½æ•°å°†ä½¿ç”¨ä¼ é€’ç»™ `bnb_quantization_config` çš„ç›¸å…³é…ç½®å¯¹è¾“å…¥æ¨¡å‹è¿›è¡Œé‡åŒ–ã€‚å¦‚æœæ¨¡å‹åœ¨å…ƒè®¾å¤‡ä¸Šï¼Œæˆ‘ä»¬å°†æ ¹æ®ä¼ é€’çš„ `device_map` åŠ è½½å’Œåˆ†å‘æƒé‡ã€‚å¦‚æœæ¨¡å‹å·²ç»åŠ è½½ï¼Œæˆ‘ä»¬å°†é‡åŒ–æ¨¡å‹å¹¶å°†æ¨¡å‹æ”¾åœ¨ GPU ä¸Šï¼Œ
