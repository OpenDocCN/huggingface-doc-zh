# 用于 torch 数据加载器、优化器和调度器的包装类

> 原文链接：[`huggingface.co/docs/accelerate/package_reference/torch_wrappers`](https://huggingface.co/docs/accelerate/package_reference/torch_wrappers)

Accelerate 在调用 prepare()时使用的内部类，用于为分布式训练准备对象。

## 数据集和数据加载器

#### `accelerate.data_loader.prepare_data_loader`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/data_loader.py#L745)

```py
( dataloader: DataLoader device: Optional = None num_processes: Optional = None process_index: Optional = None split_batches: bool = False put_on_device: bool = False rng_types: Optional = None dispatch_batches: Optional = None even_batches: bool = True slice_fn_for_dispatch: Optional = None use_seedable_sampler: bool = False ) → export const metadata = 'undefined';torch.utils.data.dataloader.DataLoader
```

参数

+   `dataloader` (`torch.utils.data.dataloader.DataLoader`) — 要在多个设备上拆分的数据加载器。

+   `device` (`torch.device`) — 返回的`DataLoader`的目标设备。

+   `num_processes` (`int`, *可选*) — 并行运行的进程数。将默认为 AcceleratorState 给定的值。

+   `process_index` (`int`, *可选*) — 当前进程的索引。将默认为 AcceleratorState 给定的值。

+   `split_batches` (`bool`, *可选*, 默认为`False`) — 结果`DataLoader`是否应该将原始数据加载器的批次拆分到设备上或产生完整的批次（在这种情况下，它将产生从`process_index`开始的批次，并在每次迭代时向前推进`num_processes`批次）。

    另一种看待这个问题的方式是，如果将此选项设置为`True`，则观察到的批次大小将与初始`dataloader`的批次大小相同，否则将是初始`dataloader`的批次大小乘以`num_processes`。

    将此选项设置为`True`要求`dataloader`的批次大小是`batch_size`的整数倍。

+   `put_on_device` (`bool`, *可选*, 默认为`False`) — 是否将批次放在`device`上（仅在批次为嵌套列表、元组或张量字典时有效）。

+   `rng_types`（`str`列表或 RNGType） — 每次迭代开始时要同步的随机数生成器列表。应该是以下之一或几个：

    +   `"torch"`: 基本的 torch 随机数生成器

    +   `"cuda"`: CUDA 随机数生成器（仅适用于 GPU）

    +   `"xla"`: XLA 随机数生成器（仅适用于 TPU）

    +   `"generator"`: 采样器的`torch.Generator`（如果数据加载器中没有采样器）或可迭代数据集的`torch.Generator`（如果存在）。

+   `dispatch_batches` (`bool`, *可选*) — 如果设置为`True`，则准备的数据加载器仅在主进程上迭代，然后将批次拆分并广播到每个进程。当底层数据集为`IterableDataset`时，默认为`True`，否则为`False`。

+   `even_batches` (`bool`, *可选*, 默认为`True`) — 如果设置为`True`，在所有进程的总批次大小不能完全整除数据集的情况下，数据集开头的样本将被复制，以便批次可以在所有工作进程之间平均分配。

+   `slice_fn_for_dispatch` (`Callable`, *可选*`) -- 如果传递，将用于在`num_processes`上切片张量。将默认为 slice_tensors()。此参数仅在`dispatch_batches`设置为`True`时使用，否则将被忽略。

+   `use_seedable_sampler` (`bool`, *可选*, 默认为`False`) — 是否使用`SeedableRandomSampler`而不是`RandomSampler`以获得更好的可重现性。由于不同的洗牌算法可能导致不同的性能，但确保结果将是*完全*相同。应该与每个`self.set_epoch`配对使用`set_seed()`

返回值

`torch.utils.data.dataloader.DataLoader`

一个新的数据加载器，将产生批次的部分

将 PyTorch 的`DataLoader`包装起来，仅为一个进程生成批次。

根据传递的`dataloader`的`drop_last`属性的值，它将在第一个批次太小/不在所有进程上存在时停止迭代，或者使用从头开始的索引循环。

默认情况下不启用具有不同批次大小的`BatchSampler`。要启用此行为，请将`even_batches`设置为`False`。

#### `accelerate.skip_first_batches`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/data_loader.py#L1019)

```py
( dataloader num_batches = 0 )
```

创建一个`torch.utils.data.DataLoader`，将有效地跳过前`num_batches`。

### `class accelerate.data_loader.BatchSamplerShard`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/data_loader.py#L100)

```py
( batch_sampler: BatchSampler num_processes: int = 1 process_index: int = 0 split_batches: bool = False even_batches: bool = True )
```

参数

+   `batch_sampler` (`torch.utils.data.sampler.BatchSampler`) — 将批次采样器拆分为几个分片。

+   `num_processes` (`int`, *可选*, 默认为 1) — 并发运行的进程数。

+   `process_index` (`int`, *可选*, 默认为 0) — 当前进程的索引。

+   `split_batches` (`bool`, *可选*, 默认为`False`) — 是否通过将一个批次拆分为每个进程上的一部分来创建分片，或者通过在每个进程上产生不同的完整批次来创建分片。

    在一个采样器为`[[0, 1, 2, 3], [4, 5, 6, 7]]`的两个进程上，结果如下：

    +   在进程 0 上的采样器产生`[0, 1, 2, 3]`，在进程 1 上的采样器产生`[4, 5, 6, 7]`，如果此参数设置为`False`。

    +   在进程 0 上的采样器产生`[0, 1]`然后`[4, 5]`，在进程 1 上的采样器产生`[2, 3]`然后`[6, 7]`，如果此参数设置为`True`。

+   `even_batches` (`bool`, *可选*, 默认为`True`) — 当样本数量不是（原始批次大小/进程数）的整数倍时，是否在采样器开头循环回来。

将 PyTorch 的`BatchSampler`包装起来，仅为一个进程生成批次。此类的实例始终产生`num_processes`的整数倍的批次数量，并且所有批次大小相同。根据传递的批次采样器的`drop_last`属性的值，它将在第一个批次太小/不在所有进程上存在时停止迭代，或者使用从头开始的索引循环。

默认情况下不启用具有不同批次大小的`BatchSampler`。要启用此行为，请将`even_batches`设置为`False`。

### `class accelerate.data_loader.IterableDatasetShard`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/data_loader.py#L256)

```py
( dataset: IterableDataset batch_size: int = 1 drop_last: bool = False num_processes: int = 1 process_index: int = 0 split_batches: bool = False )
```

参数

+   `dataset` (`torch.utils.data.dataset.IterableDataset`) — 将批次拆分为几个分片的批次采样器。

+   `batch_size` (`int`, *可选*, 默认为 1) — 每个分片的批次大小（如果`split_batches=False`）或批次大小（如果`split_batches=True`）。

+   `drop_last` (`bool`, *可选*, 默认为`False`) — 是否丢弃最后一个不完整的批次或使用从头开始的样本完成最后的批次。

+   `num_processes` (`int`, *可选*, 默认为 1) — 并发运行的进程数。

+   `process_index` (`int`, *可选*, 默认为 0) — 当前进程的索引。

+   `split_batches` (`bool`, *可选*, 默认为`False`) — 是否通过将一个批次拆分为每个进程上的一部分来创建分片，或者通过在每个进程上产生不同的完整批次来创建分片。

    在一个可迭代数据集上有两个进程产生`[0, 1, 2, 3, 4, 5, 6, 7]`，结果如下：

    +   在进程 0 上的分片产生`[0, 1, 2, 3]`，在进程 1 上的分片产生`[4, 5, 6, 7]`，如果此参数设置为`False`。

    +   在进程 0 上分片以产生`[0, 1, 4, 5]`，在进程 1 上采样以产生`[2, 3, 6, 7]`，如果设置了此参数为`True`。

包装一个 PyTorch `IterableDataset`，仅为其中一个进程生成样本。此类的实例将始终产生实际批次大小的样本数量（取决于`split_batches`的值，这是`batch_size`或`batch_size x num_processes`）。根据传递的批次采样器的`drop_last`属性的值，它将在第一个批次太小的情况下停止迭代，或者从头开始循环索引。

### `class accelerate.data_loader.DataLoaderShard`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/data_loader.py#L391)

```py
( dataset device = None rng_types = None synchronized_generator = None skip_batches = 0 _drop_last: bool = False **kwargs )
```

参数

+   `dataset` (`torch.utils.data.dataset.Dataset`) — 用于构建此数据加载器的数据集。

+   `device` (`torch.device`, *可选*) — 如果传递，则将所有批次放在该设备上。

+   `rng_types`（`str`列表或 RNGType） — 每次迭代开始时要同步的随机数生成器列表。应该是以下之一或几个：

    +   `"torch"`: 基本的 torch 随机数生成器

    +   `"cuda"`: CUDA 随机数生成器（仅限 GPU）

    +   `"xla"`: XLA 随机数生成器（仅限 TPU）

    +   `"generator"`: 可选的`torch.Generator`

+   `synchronized_generator` (`torch.Generator`, *可选*) — 要在各个进程之间保持同步的随机数生成器。

+   `skip_batches` (`int`, *可选*, 默认为 0) — 在开始时要跳过的批次数。kwargs — 传递给常规`DataLoader`初始化的所有其他关键字参数。

PyTorch `DataLoader`的子类，将处理设备放置和当前分布式设置。

**可用属性:**

+   `total_batch_size` (`int`) — 所有进程中数据加载器的总批次大小。当`split_batches=True`时等于原始批次大小；否则等于原始批次大小乘以总进程数

+   `total_dataset_length` (`int`) — 所有进程中内部数据集的总长度。

### `class accelerate.data_loader.DataLoaderDispatcher`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/data_loader.py#L548)

```py
( dataset split_batches: bool = False skip_batches = 0 _drop_last: bool = False slice_fn = None **kwargs )
```

参数

+   `split_batches` (`bool`, *可选*, 默认为`False`) — 结果`DataLoader`是否应该将原始数据加载器的批次拆分到设备上或产生完整批次（在这种情况下，它将产生从`process_index`开始并在每次迭代时前进`num_processes`批次的批次）。另一种看待这个问题的方式是，如果将此选项设置为`True`，则观察到的批次大小将与初始`dataloader`的批次大小相同，否则将乘以`num_processes`。将此选项设置为`True`要求`dataloader`的批次大小是`batch_size`的圆整倍数。

+   `skip_batches` (`int`, *可选*, 默认为 0) — 在迭代开始时要跳过的批次数。

PyTorch `DataLoader`的子类，仅在进程 0 上迭代和预处理，然后在每个进程上分派其批次的部分。

**可用属性:**

+   `total_batch_size` (`int`) — 所有进程中数据加载器的总批次大小。当`split_batches=True`时等于原始批次大小；否则等于原始批次大小乘以总进程数

+   `total_dataset_length` (`int`) — 所有进程中内部数据集的总长度。

## 优化器

### `class accelerate.optimizer.AcceleratedOptimizer`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/optimizer.py#L38)

```py
( optimizer device_placement = True scaler = None )
```

参数

+   `optimizer` (`torch.optim.optimizer.Optimizer`) — 要包装的优化器。

+   `device_placement` (`bool`, *optional*, defaults to `True`) — 是否优化器应该处理设备放置。如果是，则会将`optimizer`的状态字典放置在正确的设备上。

+   `scaler` (`torch.cuda.amp.grad_scaler.GradScaler`, *optional*) — 如果使用混合精度进行训练，则在步进函数中使用的缩放器。

在 torch 优化器周围的内部包装器。

在执行梯度累积时，有条件地执行`step`和`zero_grad`，如果梯度应该在梯度累积时同步。

## 调度程序

### `class accelerate.scheduler.AcceleratedScheduler`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/scheduler.py#L25)

```py
( scheduler optimizers step_with_optimizer: bool = True split_batches: bool = False )
```

参数

+   `scheduler` (`torch.optim.lr_scheduler._LRScheduler`) — 要包装的调度程序。

+   `optimizers`（一个或多个`torch.optim.Optimizer`的列表） — 使用的优化器。

+   `step_with_optimizer` (`bool`, *optional*, defaults to `True`) — 是否调度程序应该在每个优化器步骤时进行步进。

+   `split_batches` (`bool`, *optional*, defaults to `False`) — 是否数据加载器跨不同进程拆分一个批次（因此无论进程数量如何，批次大小都相同），或者在每个进程上创建批次（因此批次大小是原始批次大小乘以进程数量）。

一个围绕学习率调度程序的包装器，只有当优化器有训练步骤时才会进行步进。在梯度溢出并且没有训练步骤时（在混合精度训练中），有用以避免使调度程序步进太快。

在执行梯度累积时，调度程序长度不应相应更改，Accelerate 将始终步进调度程序以考虑此情况。
