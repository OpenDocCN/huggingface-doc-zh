# åŠ é€Ÿå™¨

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/accelerate/package_reference/accelerator`](https://huggingface.co/docs/accelerate/package_reference/accelerator)

Accelerator æ˜¯ğŸ¤— Accelerate æä¾›çš„ä¸»è¦ç±»ã€‚å®ƒä½œä¸º API çš„ä¸»è¦å…¥å£ç‚¹ã€‚

## ä»£ç çš„å¿«é€Ÿé€‚åº”

å°†è„šæœ¬å¿«é€Ÿé€‚åº”ä»»ä½•ç±»å‹çš„è®¾ç½®ä¸ğŸ¤— Accelerate ä¸€èµ·å·¥ä½œåªéœ€ï¼š

1.  å°½æ—©åœ¨è„šæœ¬ä¸­åˆå§‹åŒ–ä¸€ä¸ª Accelerator å¯¹è±¡ï¼ˆæˆ‘ä»¬å°†åœ¨æœ¬é¡µä¸­ç§°ä¹‹ä¸º`accelerator`ï¼‰ã€‚

1.  å°†æ‚¨çš„æ•°æ®åŠ è½½å™¨ã€æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ä¼ é€’ç»™ prepare()æ–¹æ³•ã€‚

1.  ä»æ‚¨çš„ä»£ç ä¸­åˆ é™¤æ‰€æœ‰`.cuda()`æˆ–`.to(device)`ï¼Œè®©`accelerator`ä¸ºæ‚¨å¤„ç†è®¾å¤‡æ”¾ç½®ã€‚

ç¬¬ä¸‰æ­¥æ˜¯å¯é€‰çš„ï¼Œä½†è¢«è®¤ä¸ºæ˜¯æœ€ä½³å®è·µã€‚

1.  åœ¨æ‚¨çš„ä»£ç ä¸­ç”¨`accelerator.backward(loss)`æ›¿æ¢`loss.backward()`

1.  åœ¨å­˜å‚¨æˆ–ä½¿ç”¨é¢„æµ‹å’Œæ ‡ç­¾ä¹‹å‰ï¼Œä½¿ç”¨ gather()æ¥æ”¶é›†å®ƒä»¬ï¼Œä»¥è¿›è¡Œåº¦é‡è®¡ç®—ã€‚

åœ¨è¿›è¡Œåˆ†å¸ƒå¼è¯„ä¼°æ—¶ï¼Œç¬¬äº”æ­¥æ˜¯å¼ºåˆ¶çš„

åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™å°±æ˜¯æ‰€éœ€çš„ã€‚ä¸‹ä¸€èŠ‚åˆ—å‡ºäº†ä¸€äº›æ›´é«˜çº§çš„ç”¨ä¾‹å’Œæ‚¨åº”è¯¥æœç´¢å¹¶æ›¿æ¢ä¸º`accelerator`ç›¸åº”æ–¹æ³•çš„ä¸€äº›ä¸é”™çš„åŠŸèƒ½ï¼š

## é«˜çº§å»ºè®®

### æ‰“å°

å°†`print`è¯­å¥æ›¿æ¢ä¸º print()ä»¥æ¯ä¸ªè¿›ç¨‹æ‰“å°ä¸€æ¬¡ï¼š

```py
- print("My thing I want to print!")
+ accelerator.print("My thing I want to print!")
```

### æ‰§è¡Œè¿›ç¨‹

#### ä¸€æ¬¡åœ¨å•ä¸ªæœåŠ¡å™¨ä¸Š

å¯¹äºåº”åœ¨æ¯å°æœåŠ¡å™¨ä¸Šæ‰§è¡Œä¸€æ¬¡çš„è¯­å¥ï¼Œä½¿ç”¨`is_local_main_process`ï¼š

```py
if accelerator.is_local_main_process:
    do_thing_once_per_server()
```

å¯ä»¥ä½¿ç”¨ on_local_main_process()å‡½æ•°æ¥åŒ…è£…å‡½æ•°ï¼Œä»¥åœ¨å‡½æ•°æ‰§è¡Œæ—¶å®ç°ç›¸åŒçš„è¡Œä¸ºï¼š

```py
@accelerator.on_local_main_process
def do_my_thing():
    "Something done once per server"
    do_thing_once_per_server()
```

#### åœ¨æ‰€æœ‰æœåŠ¡å™¨ä¸Šä»…ä¸€æ¬¡

å¯¹äºåº”ä»…æ‰§è¡Œä¸€æ¬¡çš„è¯­å¥ï¼Œä½¿ç”¨`is_main_process`ï¼š

```py
if accelerator.is_main_process:
    do_thing_once()
```

å¯ä»¥ä½¿ç”¨ on_main_process()å‡½æ•°æ¥åŒ…è£…å‡½æ•°ï¼Œä»¥åœ¨å‡½æ•°æ‰§è¡Œæ—¶å®ç°ç›¸åŒçš„è¡Œä¸ºï¼š

```py
@accelerator.on_main_process
def do_my_thing():
    "Something done once per server"
    do_thing_once()
```

#### åœ¨ç‰¹å®šè¿›ç¨‹ä¸Š

å¦‚æœå‡½æ•°åº”åœ¨ç‰¹å®šçš„æ•´ä½“æˆ–æœ¬åœ°è¿›ç¨‹ç´¢å¼•ä¸Šè¿è¡Œï¼Œæœ‰ç±»ä¼¼çš„è£…é¥°å™¨å¯å®ç°æ­¤ç›®çš„ï¼š

```py
@accelerator.on_local_process(local_process_idx=0)
def do_my_thing():
    "Something done on process index 0 on each server"
    do_thing_on_index_zero_on_each_server()
```

```py
@accelerator.on_process(process_index=0)
def do_my_thing():
    "Something done on process index 0"
    do_thing_on_index_zero()
```

### åŒæ­¥æ§åˆ¶

ä½¿ç”¨ wait_for_everyone()ç¡®ä¿æ‰€æœ‰è¿›ç¨‹åœ¨ç»§ç»­ä¹‹å‰åŠ å…¥è¯¥ç‚¹ã€‚ï¼ˆä¾‹å¦‚ï¼Œåœ¨ä¿å­˜æ¨¡å‹ä¹‹å‰å¾ˆæœ‰ç”¨ï¼‰ã€‚

### ä¿å­˜å’ŒåŠ è½½

```py
model = MyModel()
model = accelerator.prepare(model)
```

ä½¿ç”¨ save_model()ä»£æ›¿`torch.save`æ¥ä¿å­˜æ¨¡å‹ã€‚å®ƒå°†åˆ é™¤åœ¨åˆ†å¸ƒå¼è¿‡ç¨‹ä¸­æ·»åŠ çš„æ‰€æœ‰æ¨¡å‹åŒ…è£…å™¨ï¼Œè·å–æ¨¡å‹çš„ state_dict å¹¶ä¿å­˜å®ƒã€‚state_dict å°†ä¸æ­£åœ¨è®­ç»ƒçš„æ¨¡å‹å…·æœ‰ç›¸åŒçš„ç²¾åº¦ã€‚

```py
- torch.save(state_dict, "my_state.pkl")
+ accelerator.save_model(model, save_directory)
```

save_model()è¿˜å¯ä»¥å°†æ¨¡å‹ä¿å­˜ä¸ºåˆ†ç‰‡æ£€æŸ¥ç‚¹æˆ–ä½¿ç”¨ safetensors æ ¼å¼ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

```py
accelerator.save_model(model, save_directory, max_shard_size="1GB", safe_serialization=True)
```

#### ğŸ¤— Transformers æ¨¡å‹

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨[ğŸ¤— Transformers](https://huggingface.co/docs/transformers/)åº“ä¸­çš„æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨`.save_pretrained()`æ–¹æ³•ã€‚

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("bert-base-cased")
model = accelerator.prepare(model)

# ...fine-tune with PyTorch...

unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(
    "path/to/my_model_directory",
    is_main_process=accelerator.is_main_process,
    save_function=accelerator.save,
)
```

è¿™å°†ç¡®ä¿æ‚¨çš„æ¨¡å‹ä¸å…¶ä»–ğŸ¤— Transformers åŠŸèƒ½ä¿æŒå…¼å®¹ï¼Œå¦‚`.from_pretrained()`æ–¹æ³•ã€‚

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("path/to/my_model_directory")
```

### æ“ä½œ

ä½¿ç”¨ clip*grad_norm*()ä»£æ›¿`torch.nn.utils.clip_grad_norm_`ï¼Œå¹¶ä½¿ç”¨ clip*grad_value*()ä»£æ›¿`torch.nn.utils.clip_grad_value`

### æ¢¯åº¦ç´¯ç§¯

è¦æ‰§è¡Œæ¢¯åº¦ç´¯ç§¯ï¼Œè¯·ä½¿ç”¨ accumulate()å¹¶æŒ‡å®š gradient_accumulation_stepsã€‚è¿™ä¹Ÿå°†è‡ªåŠ¨ç¡®ä¿åœ¨å¤šè®¾å¤‡è®­ç»ƒæ—¶åŒæ­¥æˆ–å¼‚æ­¥æ¢¯åº¦ï¼Œæ£€æŸ¥æ˜¯å¦å®é™…æ‰§è¡Œæ­¥éª¤ï¼Œå¹¶è‡ªåŠ¨ç¼©æ”¾æŸå¤±ï¼š

```py
- accelerator = Accelerator()
+ accelerator = Accelerator(gradient_accumulation_steps=2)

  for (input, label) in training_dataloader:
+     with accelerator.accumulate(model):
          predictions = model(input)
          loss = loss_function(predictions, labels)
          accelerator.backward(loss)
          optimizer.step()
          scheduler.step()
          optimizer.zero_grad()
```

#### GradientAccumulationPlugin

### `class accelerate.utils.GradientAccumulationPlugin`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L505)

```py
( num_steps: int = None adjust_scheduler: bool = True sync_with_dataloader: bool = True )
```

ä¸€ä¸ªç”¨äºé…ç½®æ¢¯åº¦ç´¯ç§¯è¡Œä¸ºçš„æ’ä»¶ã€‚

ä¸è¦ä¼ é€’`gradient_accumulation_steps`ï¼Œæ‚¨å¯ä»¥å®ä¾‹åŒ–ä¸€ä¸ª GradientAccumulationPlugin å¹¶å°†å…¶ä¼ é€’ç»™ Accelerator çš„`__init__`ä½œä¸º`gradient_accumulation_plugin`ã€‚æ‚¨åªèƒ½ä¼ é€’`gradient_accumulation_plugin`æˆ–`gradient_accumulation_steps`ä¸­çš„ä¸€ä¸ªï¼Œä¼ é€’ä¸¤è€…å°†å¼•å‘é”™è¯¯ã€‚

```py
from accelerate.utils import GradientAccumulationPlugin

gradient_accumulation_plugin = GradientAccumulationPlugin(num_steps=2)
- accelerator = Accelerator()
+ accelerator = Accelerator(gradient_accumulation_plugin=gradient_accumulation_plugin)
```

é™¤äº†æ­¥æ•°ä¹‹å¤–ï¼Œè¿™è¿˜è®©æ‚¨é…ç½®æ˜¯å¦è°ƒæ•´å­¦ä¹ ç‡è°ƒåº¦ç¨‹åºä»¥è€ƒè™‘ç”±äºç´¯ç§¯è€Œå¯¼è‡´çš„æ­¥éª¤å˜åŒ–ã€‚

## æ€»ä½“ API æ–‡æ¡£ï¼š

### `class accelerate.Accelerator`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L153)

```py
( device_placement: bool = True split_batches: bool = False mixed_precision: PrecisionType | str | None = None gradient_accumulation_steps: int = 1 cpu: bool = False deepspeed_plugin: DeepSpeedPlugin | None = None fsdp_plugin: FullyShardedDataParallelPlugin | None = None megatron_lm_plugin: MegatronLMPlugin | None = None rng_types: list[str | RNGType] | None = None log_with: str | LoggerType | GeneralTracker | list[str | LoggerType | GeneralTracker] | None = None project_dir: str | os.PathLike | None = None project_config: ProjectConfiguration | None = None gradient_accumulation_plugin: GradientAccumulationPlugin | None = None dispatch_batches: bool | None = None even_batches: bool = True use_seedable_sampler: bool = False step_scheduler_with_optimizer: bool = True kwargs_handlers: list[KwargsHandler] | None = None dynamo_backend: DynamoBackend | str | None = None )
```

å‚æ•°

+   `device_placement` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” åŠ é€Ÿå™¨æ˜¯å¦åº”è¯¥å°†å¯¹è±¡æ”¾åœ¨è®¾å¤‡ä¸Šï¼ˆæ•°æ®åŠ è½½å™¨äº§ç”Ÿçš„å¼ é‡ï¼Œæ¨¡å‹ç­‰ï¼‰ã€‚

+   `split_batches` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” åŠ é€Ÿå™¨æ˜¯å¦åº”è¯¥å°†æ•°æ®åŠ è½½å™¨äº§ç”Ÿçš„æ‰¹æ¬¡åˆ†é…åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šã€‚å¦‚æœä¸º`True`ï¼Œå®é™…ä½¿ç”¨çš„æ‰¹æ¬¡å¤§å°å°†åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è¿›ç¨‹ä¸Šç›¸åŒï¼Œä½†å¿…é¡»æ˜¯æ‚¨ä½¿ç”¨çš„`num_processes`çš„åœ†å€æ•°ã€‚å¦‚æœä¸º`False`ï¼Œå®é™…ä½¿ç”¨çš„æ‰¹æ¬¡å¤§å°å°†æ˜¯è„šæœ¬ä¸­è®¾ç½®çš„æ‰¹æ¬¡å¤§å°ä¹˜ä»¥è¿›ç¨‹æ•°ã€‚

+   `mixed_precision` (`str`, *optional*) â€” æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒã€‚é€‰æ‹©â€˜noâ€™ã€â€˜fp16â€™ã€â€˜bf16â€™æˆ–â€˜fp8â€™ã€‚å°†é»˜è®¤ä¸ºç¯å¢ƒå˜é‡`ACCELERATE_MIXED_PRECISION`ä¸­çš„å€¼ï¼Œè¯¥å€¼å°†ä½¿ç”¨å½“å‰ç³»ç»Ÿçš„åŠ é€Ÿé…ç½®ä¸­çš„é»˜è®¤å€¼æˆ–ä½¿ç”¨`accelerate.launch`å‘½ä»¤ä¼ é€’çš„æ ‡å¿—ã€‚â€˜fp8â€™éœ€è¦å®‰è£… transformers-engineã€‚

+   `gradient_accumulation_steps` (`int`, *optional*, default to 1) â€” åœ¨æ¢¯åº¦ç´¯ç§¯ä¹‹å‰åº”è¯¥ç»è¿‡çš„æ­¥æ•°ã€‚æ•°å­—å¤§äº 1 åº”è¯¥ä¸`Accelerator.accumulate`ç»“åˆä½¿ç”¨ã€‚å¦‚æœæœªä¼ é€’ï¼Œåˆ™é»˜è®¤ä¸ºç¯å¢ƒå˜é‡`ACCELERATE_GRADIENT_ACCUMULATION_STEPS`ä¸­çš„å€¼ã€‚ä¹Ÿå¯ä»¥é€šè¿‡`GradientAccumulationPlugin`è¿›è¡Œé…ç½®ã€‚

+   `cpu` (`bool`, *optional*) â€” æ˜¯å¦å¼ºåˆ¶è„šæœ¬åœ¨ CPU ä¸Šæ‰§è¡Œã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œå°†å¿½ç•¥ GPU çš„å¯ç”¨æ€§ï¼Œå¹¶å¼ºåˆ¶åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸Šæ‰§è¡Œã€‚

+   `deepspeed_plugin` (`DeepSpeedPlugin`, *optional*) â€” ä½¿ç”¨æ­¤å‚æ•°è°ƒæ•´æ‚¨çš„ DeepSpeed ç›¸å…³å‚æ•°ã€‚æ­¤å‚æ•°æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨*accelerate config*è¿›è¡Œé…ç½®ã€‚

+   `fsdp_plugin` (`FullyShardedDataParallelPlugin`, *optional*) â€” ä½¿ç”¨æ­¤å‚æ•°è°ƒæ•´æ‚¨çš„ FSDP ç›¸å…³å‚æ•°ã€‚æ­¤å‚æ•°æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨*accelerate config*è¿›è¡Œé…ç½®ã€‚

+   `megatron_lm_plugin` (`MegatronLMPlugin`, *optional*) â€” ä½¿ç”¨æ­¤å‚æ•°è°ƒæ•´æ‚¨çš„ MegatronLM ç›¸å…³å‚æ•°ã€‚æ­¤å‚æ•°æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨*accelerate config*è¿›è¡Œé…ç½®ã€‚

+   `rng_types`ï¼ˆ`str`åˆ—è¡¨æˆ– RNGTypeï¼‰â€” åœ¨å‡†å¤‡å¥½çš„æ•°æ®åŠ è½½å™¨çš„æ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶è¦åŒæ­¥çš„éšæœºæ•°ç”Ÿæˆå™¨åˆ—è¡¨ã€‚åº”è¯¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å‡ ä¸ªï¼š

    +   `"torch"`ï¼šåŸºæœ¬ torch éšæœºæ•°ç”Ÿæˆå™¨

    +   `"cuda"`ï¼šCUDA éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆä»…é™ GPUï¼‰

    +   `"xla"`ï¼šXLA éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆä»…é™ TPUï¼‰

    +   `"generator"`ï¼šé‡‡æ ·å™¨çš„`torch.Generator`ï¼ˆå¦‚æœæ•°æ®åŠ è½½å™¨ä¸­æ²¡æœ‰é‡‡æ ·å™¨ï¼Œåˆ™ä¸ºæ‰¹æ¬¡é‡‡æ ·å™¨ï¼‰æˆ–å¯è¿­ä»£æ•°æ®é›†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰çš„ç”Ÿæˆå™¨ï¼ˆå¦‚æœåŸºç¡€æ•°æ®é›†æ˜¯è¯¥ç±»å‹ï¼‰ã€‚

    å¯¹äº PyTorch ç‰ˆæœ¬<=1.5.1ï¼Œé»˜è®¤ä¸º`["torch"]`ï¼Œå¯¹äº PyTorch ç‰ˆæœ¬>= 1.6ï¼Œé»˜è®¤ä¸º`["generator"]`ã€‚

+   `log_with`ï¼ˆ`str`åˆ—è¡¨ï¼ŒLoggerType æˆ– GeneralTrackerï¼Œ*å¯é€‰*ï¼‰â€” è¦ä¸ºå®éªŒè·Ÿè¸ªè®¾ç½®çš„è®°å½•å™¨åˆ—è¡¨ã€‚åº”è¯¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å‡ ä¸ªï¼š

    +   `"all"`

    +   `"tensorboard"`

    +   `"wandb"`

    +   `"comet_ml"` å¦‚æœé€‰æ‹©`"all"`ï¼Œå°†æ¡èµ·ç¯å¢ƒä¸­æ‰€æœ‰å¯ç”¨çš„è·Ÿè¸ªå™¨å¹¶åˆå§‹åŒ–å®ƒä»¬ã€‚è¿˜å¯ä»¥æ¥å—`GeneralTracker`çš„è‡ªå®šä¹‰è·Ÿè¸ªå™¨çš„å®ç°ï¼Œå¹¶ä¸”å¯ä»¥ä¸`"all"`ç»„åˆä½¿ç”¨ã€‚

+   `project_config`ï¼ˆ`ProjectConfiguration`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå¤„ç†çŠ¶æ€ä¿å­˜çš„é…ç½®ã€‚

+   `project_dir`ï¼ˆ`str`ï¼Œ`os.PathLike`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå­˜å‚¨æ•°æ®çš„ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚æœ¬åœ°å…¼å®¹æ—¥å¿—è®°å½•å™¨çš„æ—¥å¿—å’Œå¯èƒ½çš„ä¿å­˜æ£€æŸ¥ç‚¹ã€‚

+   `dispatch_batches`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ç”±åŠ é€Ÿå™¨å‡†å¤‡çš„æ•°æ®åŠ è½½å™¨ä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè¿›è¡Œè¿­ä»£ï¼Œç„¶åå°†æ‰¹æ¬¡åˆ†å‰²å¹¶å¹¿æ’­åˆ°æ¯ä¸ªè¿›ç¨‹ã€‚å¯¹äºå…¶åŸºç¡€æ•°æ®é›†ä¸º`IterableDataset`çš„`DataLoader`ï¼Œé»˜è®¤ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚

+   `even_batches`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåœ¨æ‰€æœ‰è¿›ç¨‹çš„æ€»æ‰¹æ¬¡å¤§å°ä¸èƒ½å®Œå…¨æ•´é™¤æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œæ•°æ®é›†å¼€å¤´çš„æ ·æœ¬å°†è¢«å¤åˆ¶ï¼Œä»¥ä¾¿æ‰¹æ¬¡å¯ä»¥åœ¨æ‰€æœ‰å·¥ä½œè¿›ç¨‹ä¹‹é—´å‡åŒ€åˆ†é…ã€‚

+   `use_seedable_sampler`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä½¿ç”¨å®Œå…¨å¯ç§å­çš„éšæœºé‡‡æ ·å™¨ï¼ˆ`SeedableRandomSampler`ï¼‰ã€‚ç¡®ä¿ä½¿ç”¨ä¸åŒçš„é‡‡æ ·æŠ€æœ¯æ—¶è®­ç»ƒç»“æœæ˜¯å®Œå…¨å¯é‡ç°çš„ã€‚è™½ç„¶ç§å­åˆ°ç§å­çš„ç»“æœå¯èƒ½ä¸åŒï¼Œä½†å¹³å‡è€Œè¨€ï¼Œä½¿ç”¨å¤šä¸ªä¸åŒçš„ç§å­è¿›è¡Œæ¯”è¾ƒæ—¶å·®å¼‚å¾®ä¸è¶³é“ã€‚æ¯æ¬¡éƒ½åº”è¯¥ä¸ set_seed()ä¸€èµ·è¿è¡Œä»¥è·å¾—æœ€ä½³ç»“æœã€‚

+   `step_scheduler_with_optimizer`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰-- å¦‚æœå­¦ä¹ ç‡è°ƒåº¦ç¨‹åºä¸ä¼˜åŒ–å™¨åŒæ—¶è¿›è¡Œæ­¥è¿›ï¼Œåˆ™è®¾ç½®ä¸º`True`ï¼Œå¦‚æœä»…åœ¨æŸäº›æƒ…å†µä¸‹è¿›è¡Œï¼ˆä¾‹å¦‚åœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶ï¼‰ï¼Œåˆ™è®¾ç½®ä¸º`False`ã€‚

+   `kwargs_handlers`ï¼ˆ`list[KwargHandler]`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè‡ªå®šä¹‰ä¸åˆ†å¸ƒå¼è®­ç»ƒæˆ–æ··åˆç²¾åº¦ç›¸å…³çš„å¯¹è±¡å¦‚ä½•åˆ›å»ºçš„`KwargHandler`åˆ—è¡¨ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… kwargsã€‚

+   `dynamo_backend`ï¼ˆ`str`æˆ–`DynamoBackend`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"no"`ï¼‰â€” è®¾ç½®ä¸ºå¯èƒ½çš„ dynamo åç«¯ä¹‹ä¸€ï¼Œä»¥ä¼˜åŒ–ä½¿ç”¨ torch dynamo è¿›è¡Œè®­ç»ƒã€‚

+   `gradient_accumulation_plugin`ï¼ˆ`GradientAccumulationPlugin`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå¤„ç†æ¢¯åº¦ç´¯ç§¯çš„é…ç½®ï¼Œå¦‚æœéœ€è¦æ¯”ä»…ä½¿ç”¨`gradient_accumulation_steps`æ›´å¤šçš„è°ƒæ•´ã€‚

åˆ›å»ºä¸€ä¸ªç”¨äºåˆ†å¸ƒå¼è®­ç»ƒï¼ˆåœ¨å¤š GPUã€TPU ä¸Šï¼‰æˆ–æ··åˆç²¾åº¦è®­ç»ƒçš„åŠ é€Ÿå™¨å®ä¾‹ã€‚

**å¯ç”¨å±æ€§ï¼š**

+   `device`ï¼ˆ`torch.device`ï¼‰â€” è¦ä½¿ç”¨çš„è®¾å¤‡ã€‚

+   `distributed_type`ï¼ˆDistributedTypeï¼‰â€” åˆ†å¸ƒå¼è®­ç»ƒé…ç½®ã€‚

+   `local_process_index`ï¼ˆ`int`ï¼‰â€” å½“å‰æœºå™¨ä¸Šçš„è¿›ç¨‹ç´¢å¼•ã€‚

+   `mixed_precision`ï¼ˆ`str`ï¼‰-é…ç½®çš„æ··åˆç²¾åº¦æ¨¡å¼ã€‚

+   `num_processes`ï¼ˆ`int`ï¼‰-ç”¨äºè®­ç»ƒçš„è¿›ç¨‹æ€»æ•°ã€‚

+   `optimizer_step_was_skipped`ï¼ˆ`bool`ï¼‰-æ˜¯å¦è·³è¿‡äº†ä¼˜åŒ–å™¨æ›´æ–°ï¼ˆå› ä¸ºåœ¨æ··åˆç²¾åº¦ä¸­æ¢¯åº¦æº¢å‡ºï¼‰ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹å­¦ä¹ ç‡ä¸åº”è¯¥æ”¹å˜ã€‚

+   `process_index`ï¼ˆ`int`ï¼‰-å½“å‰è¿›ç¨‹åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­çš„æ€»ä½“ç´¢å¼•ã€‚

+   `state`ï¼ˆAcceleratorStateï¼‰-åˆ†å¸ƒå¼è®¾ç½®çŠ¶æ€ã€‚

+   `sync_gradients`ï¼ˆ`bool`ï¼‰-å½“å‰æ˜¯å¦æ­£åœ¨è·¨æ‰€æœ‰è¿›ç¨‹åŒæ­¥æ¢¯åº¦ã€‚

+   `use_distributed`ï¼ˆ`bool`ï¼‰-å½“å‰é…ç½®æ˜¯å¦ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒã€‚

#### `accumulate`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L967)

```py
( *models )
```

å‚æ•°

+   `*models`ï¼ˆ`torch.nn.Module`åˆ—è¡¨ï¼‰-ä½¿ç”¨`Accelerator.prepare`å‡†å¤‡çš„ PyTorch æ¨¡å—ã€‚ä¼ é€’ç»™`accumulate()`çš„æ¨¡å‹å°†åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„åå‘ä¼ é€’æœŸé—´è·³è¿‡æ¢¯åº¦åŒæ­¥

ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå°†è½»æ¾åŒ…è£…å¹¶è‡ªåŠ¨æ‰§è¡Œæ¢¯åº¦ç´¯ç§¯

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=1)
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

>>> for input, output in dataloader:
...     with accelerator.accumulate(model):
...         outputs = model(input)
...         loss = loss_func(outputs)
...         loss.backward()
...         optimizer.step()
...         scheduler.step()
...         optimizer.zero_grad()
```

#### `autocast`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3109)

```py
( cache_enabled: bool = False autocast_handler: AutocastKwargs = None )
```

å¦‚æœå¯ç”¨ï¼Œå°†åœ¨æ­¤ä¸Šä¸‹æ–‡ç®¡ç†å™¨å†…éƒ¨çš„å—ä¸­åº”ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ã€‚å¦åˆ™ä¸ä¼šå‘ç”Ÿä»»ä½•ä¸åŒã€‚

å¯ä»¥ä¼ å…¥ä¸åŒçš„`autocast_handler`æ¥è¦†ç›–`Accelerator`å¯¹è±¡ä¸­è®¾ç½®çš„å¤„ç†ç¨‹åºã€‚è¿™åœ¨`autocast`ä¸‹çš„å—ä¸­å¾ˆæœ‰ç”¨ï¼Œæ‚¨æƒ³è¦æ¢å¤åˆ° fp32ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(mixed_precision="fp16")
>>> with accelerator.autocast():
...     train()
```

#### `backward`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1938)

```py
( loss **kwargs )
```

æ ¹æ®`GradientAccumulationPlugin`ç¼©æ”¾æ¢¯åº¦ï¼Œå¹¶æ ¹æ®é…ç½®è°ƒç”¨æ­£ç¡®çš„`backward()`ã€‚

åº”è¯¥ç”¨æ¥ä»£æ›¿`loss.backward()`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=2)
>>> outputs = model(inputs)
>>> loss = loss_fn(outputs, labels)
>>> accelerator.backward(loss)
```

#### `check_trigger`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1994)

```py
( )
```

æ£€æŸ¥å†…éƒ¨è§¦å‘å¼ é‡æ˜¯å¦åœ¨ä»»ä½•è¿›ç¨‹ä¸­è®¾ç½®ä¸º 1ã€‚å¦‚æœæ˜¯ï¼Œåˆ™å°†è¿”å›`True`å¹¶å°†è§¦å‘å¼ é‡é‡ç½®ä¸º 0ã€‚

æ³¨æ„ï¼šä¸éœ€è¦`wait_for_everyone()`

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume later in the training script
>>> # `should_do_breakpoint` is a custom function to monitor when to break,
>>> # e.g. when the loss is NaN
>>> if should_do_breakpoint(loss):
...     accelerator.set_trigger()
>>> # Assume later in the training script
>>> if accelerator.check_trigger():
...     break
```

#### `clear`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2973)

```py
( )
```

åˆ«åä¸º`Accelerate.free_memory`ï¼Œé‡Šæ”¾æ‰€æœ‰å¯¹å­˜å‚¨çš„å†…éƒ¨å¯¹è±¡çš„å¼•ç”¨å¹¶è°ƒç”¨åƒåœ¾å›æ”¶å™¨ã€‚æ‚¨åº”è¯¥åœ¨ä¸¤ä¸ªå…·æœ‰ä¸åŒæ¨¡å‹/ä¼˜åŒ–å™¨çš„è®­ç»ƒä¹‹é—´è°ƒç”¨æ­¤æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, scheduler = ...
>>> model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)
>>> accelerator.free_memory()
>>> del model, optimizer, scheduler
```

#### `clip_grad_norm_`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2066)

```py
( parameters max_norm norm_type = 2 ) â†’ export const metadata = 'undefined';torch.Tensor
```

è¿”å›

`torch.Tensor`

å‚æ•°æ¢¯åº¦çš„æ€»èŒƒæ•°ï¼ˆè§†ä¸ºå•ä¸ªå‘é‡ï¼‰ã€‚

åº”è¯¥ç”¨æ¥ä»£æ›¿`torch.nn.utils.clip_grad_norm_`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=2)
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

>>> for input, target in dataloader:
...     optimizer.zero_grad()
...     output = model(input)
...     loss = loss_func(output, target)
...     accelerator.backward(loss)
...     if accelerator.sync_gradients:
...         accelerator.clip_grad_norm_(model.parameters(), max_grad_norm)
...     optimizer.step()
```

#### `clip_grad_value_`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2104)

```py
( parameters clip_value )
```

åº”è¯¥ç”¨æ¥ä»£æ›¿`torch.nn.utils.clip_grad_value_`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=2)
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

>>> for input, target in dataloader:
...     optimizer.zero_grad()
...     output = model(input)
...     loss = loss_func(output, target)
...     accelerator.backward(loss)
...     if accelerator.sync_gradients:
...         accelerator.clip_grad_value_(model.parameters(), clip_value)
...     optimizer.step()
```

#### `free_memory`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2948)

```py
( )
```

å°†é‡Šæ”¾æ‰€æœ‰å¯¹å­˜å‚¨çš„å†…éƒ¨å¯¹è±¡çš„å¼•ç”¨å¹¶è°ƒç”¨åƒåœ¾å›æ”¶å™¨ã€‚æ‚¨åº”è¯¥åœ¨ä¸¤ä¸ªå…·æœ‰ä¸åŒæ¨¡å‹/ä¼˜åŒ–å™¨çš„è®­ç»ƒä¹‹é—´è°ƒç”¨æ­¤æ–¹æ³•ã€‚è¿˜å°†`Accelerator.step`é‡ç½®ä¸º 0ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, scheduler = ...
>>> model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)
>>> accelerator.free_memory()
>>> del model, optimizer, scheduler
```

#### `gather`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2131)

```py
( tensor ) â†’ export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor
```

å‚æ•°

+   `tensor`ï¼ˆ`torch.Tensor`ï¼Œæˆ–`torch.Tensor`çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸ï¼‰-è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­æ”¶é›†çš„å¼ é‡ã€‚

è¿”å›

`torch.Tensor`ï¼Œæˆ–`torch.Tensor`çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸

æ”¶é›†çš„å¼ é‡ã€‚è¯·æ³¨æ„ï¼Œç»“æœçš„ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯* num_processes *ä¹˜ä»¥è¾“å…¥å¼ é‡çš„ç¬¬ä¸€ä¸ªç»´åº¦ã€‚

æ”¶é›†*å¼ é‡*åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­çš„å€¼ï¼Œå¹¶åœ¨ç¬¬ä¸€ç»´ä¸Šå°†å®ƒä»¬è¿æ¥èµ·æ¥ã€‚åœ¨è¿›è¡Œè¯„ä¼°æ—¶ï¼Œæœ‰åŠ©äºé‡æ–°ç»„åˆæ‰€æœ‰è¿›ç¨‹çš„é¢„æµ‹ã€‚

æ³¨æ„ï¼šæ­¤æ”¶é›†åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­å‘ç”Ÿã€‚

ç¤ºä¾‹:

```py
>>> # Assuming four processes
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> process_tensor = torch.tensor([accelerator.process_index])
>>> gathered_tensor = accelerator.gather(process_tensor)
>>> gathered_tensor
tensor([0, 1, 2, 3])
```

#### `gather_for_metrics`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2163)

```py
( input_data )
```

å‚æ•°

+   `input` (`torch.Tensor`, `object`, `torch.Tensor`çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸ï¼Œæˆ–`object`çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸) â€” ç”¨äºè®¡ç®—æ‰€æœ‰è¿›ç¨‹é—´æŒ‡æ ‡çš„å¼ é‡æˆ–å¯¹è±¡

æ”¶é›†`input_data`å¹¶åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸Šå¯èƒ½åˆ é™¤æœ€åä¸€æ‰¹ä¸­çš„é‡å¤é¡¹ã€‚åº”ç”¨äºæ”¶é›†ç”¨äºæŒ‡æ ‡è®¡ç®—çš„è¾“å…¥å’Œç›®æ ‡ã€‚

ç¤ºä¾‹:

```py
>>> # Assuming two processes, with a batch size of 5 on a dataset with 9 samples
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader = torch.utils.data.DataLoader(range(9), batch_size=5)
>>> dataloader = accelerator.prepare(dataloader)
>>> batch = next(iter(dataloader))
>>> gathered_items = accelerator.gather_for_metrics(batch)
>>> len(gathered_items)
9
```

#### `get_state_dict`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3017)

```py
( model unwrap = True ) â†’ export const metadata = 'undefined';dict
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” é€šè¿‡ Accelerator.prepare()å‘é€çš„ PyTorch æ¨¡å‹

+   `unwrap` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦è¿”å›`model`çš„åŸå§‹åº•å±‚`state_dict`æˆ–è¿”å›åŒ…è£…çš„`state_dict`

è¿”å›

`dict`

æ¨¡å‹çš„çŠ¶æ€å­—å…¸ï¼Œå¯èƒ½ä¸æ˜¯å®Œå…¨ç²¾ç¡®ã€‚

è¿”å›é€šè¿‡ Accelerator.prepare()å‘é€çš„æ¨¡å‹çš„çŠ¶æ€å­—å…¸ï¼Œå¯èƒ½ä¸æ˜¯å®Œå…¨ç²¾ç¡®ã€‚

ç¤ºä¾‹:

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> net = torch.nn.Linear(2, 2)
>>> net = accelerator.prepare(net)
>>> state_dict = accelerator.get_state_dict(net)
```

#### `get_tracker`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2400)

```py
( name: str unwrap: bool = False ) â†’ export const metadata = 'undefined';GeneralTracker
```

å‚æ•°

+   `name` (`str`) â€” ä¸€ä¸ªè·Ÿè¸ªå™¨çš„åç§°ï¼Œå¯¹åº”äº`.name`å±æ€§ã€‚

+   `unwrap` (`bool`) â€” æ˜¯å¦è¿”å›å†…éƒ¨è·Ÿè¸ªæœºåˆ¶æˆ–è¿”å›åŒ…è£…çš„è·Ÿè¸ªå™¨ï¼ˆæ¨èï¼‰ã€‚

è¿”å›

`GeneralTracker`

å¦‚æœå­˜åœ¨ï¼Œåˆ™è¿”å›ä¸`name`å¯¹åº”çš„è·Ÿè¸ªå™¨ã€‚

ä»…åœ¨ä¸»è¿›ç¨‹ä¸ŠåŸºäº`name`ä»`self.trackers`è¿”å›ä¸€ä¸ª`tracker`ã€‚

ç¤ºä¾‹:

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(log_with="tensorboard")
>>> accelerator.init_trackers("my_project")
>>> tensorboard_tracker = accelerator.get_tracker("tensorboard")
```

#### `join_uneven_inputs`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1001)

```py
( joinables even_batches = None )
```

å‚æ•°

+   `joinables` (`list[torch.distributed.algorithms.Joinable]`) â€” ä¸€ä¸ªå­ç±»ä¸º`torch.distributed.algorithms.Joinable`çš„æ¨¡å‹æˆ–ä¼˜åŒ–å™¨åˆ—è¡¨ã€‚æœ€å¸¸è§çš„æ˜¯ï¼Œä½¿ç”¨`Accelerator.prepare`ä¸ºåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œè®­ç»ƒå‡†å¤‡çš„ PyTorch æ¨¡å—ã€‚

+   `even_batches` (`bool`, *å¯é€‰*) â€” å¦‚æœè®¾ç½®ï¼Œè¿™å°†è¦†ç›–åœ¨`Accelerator`ä¸­è®¾ç½®çš„`even_batches`çš„å€¼ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™å°†ä½¿ç”¨é»˜è®¤çš„`Accelerator`å€¼ã€‚

ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºåœ¨ä¸å‡åŒ€è¾“å…¥ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒæˆ–è¯„ä¼°ï¼Œä½œä¸º`torch.distributed.algorithms.join`å‘¨å›´çš„åŒ…è£…å™¨ã€‚å½“æ€»æ‰¹é‡å¤§å°ä¸èƒ½å®Œå…¨æ•´é™¤æ•°æ®é›†çš„é•¿åº¦æ—¶ï¼Œè¿™æ˜¯æœ‰ç”¨çš„ã€‚

`join_uneven_inputs`ä»…æ”¯æŒåœ¨å¤šä¸ª GPU ä¸Šè¿›è¡Œåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œè®­ç»ƒã€‚å¯¹äºä»»ä½•å…¶ä»–é…ç½®ï¼Œæ­¤æ–¹æ³•å°†ä¸èµ·ä½œç”¨ã€‚

è¦†ç›–`even_batches`ä¸ä¼šå½±å“å¯è¿­ä»£æ ·å¼çš„æ•°æ®åŠ è½½å™¨ã€‚

ç¤ºä¾‹:

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(even_batches=True)
>>> ddp_model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

>>> with accelerator.join_uneven_inputs([ddp_model], even_batches=False):
...     for input, output in dataloader:
...         outputs = model(input)
...         loss = loss_func(outputs)
...         loss.backward()
...         optimizer.step()
...         optimizer.zero_grad()
```

#### `load_state`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2816)

```py
( input_dir: str = None **load_model_func_kwargs )
```

å‚æ•°

+   `input_dir` (`str`æˆ–`os.PathLike`) â€” æ‰€æœ‰ç›¸å…³æƒé‡å’ŒçŠ¶æ€ä¿å­˜åœ¨çš„æ–‡ä»¶å¤¹çš„åç§°ã€‚å¦‚æœä½¿ç”¨`automatic_checkpoint_naming`ï¼Œåˆ™å¯ä»¥ä¸º`None`ï¼Œå¹¶å°†ä»æœ€æ–°çš„æ£€æŸ¥ç‚¹ä¸­è·å–ã€‚

+   `load_model_func_kwargs` (`dict`, *å¯é€‰*) â€” ç”¨äºåŠ è½½æ¨¡å‹çš„é™„åŠ å…³é”®å­—å‚æ•°ï¼Œå¯ä»¥ä¼ é€’ç»™åº•å±‚åŠ è½½å‡½æ•°ï¼Œä¾‹å¦‚ DeepSpeed çš„`load_checkpoint`å‡½æ•°çš„å¯é€‰å‚æ•°æˆ–`map_location`ä»¥åŠ è½½æ¨¡å‹å’Œä¼˜åŒ–å™¨ã€‚

åŠ è½½æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€ç¼©æ”¾å™¨ã€RNG ç”Ÿæˆå™¨å’Œå·²æ³¨å†Œå¯¹è±¡çš„å½“å‰çŠ¶æ€ã€‚

åº”è¯¥ä¸ Accelerator.save_state() ç»“åˆä½¿ç”¨ã€‚å¦‚æœæœªæ³¨å†Œç”¨äºæ£€æŸ¥ç‚¹çš„æ–‡ä»¶ï¼Œåˆ™å¦‚æœå­˜å‚¨åœ¨ç›®å½•ä¸­ï¼Œåˆ™ä¸ä¼šåŠ è½½ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, lr_scheduler = ...
>>> model, optimizer, lr_scheduler = accelerator.prepare(model, optimizer, lr_scheduler)
>>> accelerator.load_state("my_checkpoint")
```

#### `local_main_process_first`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L830)

```py
( )
```

è®©æœ¬åœ°ä¸»è¿›ç¨‹åœ¨ with å—å†…æ‰§è¡Œã€‚

å…¶ä»–è¿›ç¨‹å°†åœ¨ä¸»è¿›ç¨‹é€€å‡ºåè¿›å…¥ with å—ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> with accelerator.local_main_process_first():
...     # This will be printed first by local process 0 then in a seemingly
...     # random order by the other processes.
...     print(f"This will be printed by process {accelerator.local_process_index}")
```

#### `main_process_first`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L808)

```py
( )
```

è®©ä¸»è¿›ç¨‹åœ¨ with å—å†…å…ˆæ‰§è¡Œã€‚

å…¶ä»–è¿›ç¨‹å°†åœ¨ä¸»è¿›ç¨‹é€€å‡ºåè¿›å…¥ with å—ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> with accelerator.main_process_first():
...     # This will be printed first by process 0 then in a seemingly
...     # random order by the other processes.
...     print(f"This will be printed by process {accelerator.process_index}")
```

#### `no_sync`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L852)

```py
( model )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” ä½¿ç”¨ `Accelerator.prepare` å‡†å¤‡çš„ PyTorch æ¨¡å—ã€‚

ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œé€šè¿‡è°ƒç”¨ `torch.nn.parallel.DistributedDataParallel.no_sync` æ¥ç¦ç”¨ DDP è¿›ç¨‹ä¹‹é—´çš„æ¢¯åº¦åŒæ­¥ã€‚

å¦‚æœ `model` ä¸åœ¨ DDP ä¸­ï¼Œåˆ™æ­¤ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸èµ·ä½œç”¨

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader, model, optimizer = accelerator.prepare(dataloader, model, optimizer)
>>> input_a = next(iter(dataloader))
>>> input_b = next(iter(dataloader))

>>> with accelerator.no_sync():
...     outputs = model(input_a)
...     loss = loss_func(outputs)
...     accelerator.backward(loss)
...     # No synchronization across processes, only accumulate gradients
>>> outputs = model(input_b)
>>> accelerator.backward(loss)
>>> # Synchronization across all processes
>>> optimizer.step()
>>> optimizer.zero_grad()
```

#### `on_last_process`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L676)

```py
( function: Callable[..., Any] )
```

å‚æ•°

+   `function` (`Callable`) â€” è¦è£…é¥°çš„å‡½æ•°ã€‚

ä¸€ä¸ªè£…é¥°å™¨ï¼Œåªä¼šåœ¨æœ€åä¸€ä¸ªè¿›ç¨‹ä¸Šè¿è¡Œè£…é¥°çš„å‡½æ•°ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ `PartialState` ç±»è°ƒç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
# Assume we have 4 processes.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_last_process
def print_something():
    print(f"Printed on process {accelerator.process_index}")

print_something()
"Printed on process 3"
```

#### `on_local_main_process`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L634)

```py
( function: Callable[..., Any] = None )
```

å‚æ•°

+   `function` (`Callable`) â€” è¦è£…é¥°çš„å‡½æ•°ã€‚

ä¸€ä¸ªè£…é¥°å™¨ï¼Œåªä¼šåœ¨æœ¬åœ°ä¸»è¿›ç¨‹ä¸Šè¿è¡Œè£…é¥°çš„å‡½æ•°ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ `PartialState` ç±»è°ƒç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
# Assume we have 2 servers with 4 processes each.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_local_main_process
def print_something():
    print("This will be printed by process 0 only on each server.")

print_something()
# On server 1:
"This will be printed by process 0 only"
# On server 2:
"This will be printed by process 0 only"
```

#### `on_local_process`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L760)

```py
( function: Callable[..., Any] = None local_process_index: int = None )
```

å‚æ•°

+   `function` (`Callable`, *å¯é€‰*) â€” è¦è£…é¥°çš„å‡½æ•°ã€‚

+   `local_process_index` (`int`, *å¯é€‰*) â€” è¦è¿è¡Œå‡½æ•°çš„æœ¬åœ°è¿›ç¨‹çš„ç´¢å¼•ã€‚

ä¸€ä¸ªè£…é¥°å™¨ï¼Œåªä¼šåœ¨ç»™å®šçš„æœ¬åœ°è¿›ç¨‹ç´¢å¼•ä¸Šè¿è¡Œè£…é¥°çš„å‡½æ•°ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ `PartialState` ç±»è°ƒç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
# Assume we have 2 servers with 4 processes each.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_local_process(local_process_index=2)
def print_something():
    print(f"Printed on process {accelerator.local_process_index}")

print_something()
# On server 1:
"Printed on process 2"
# On server 2:
"Printed on process 2"
```

#### `on_main_process`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L595)

```py
( function: Callable[..., Any] = None )
```

å‚æ•°

+   `function` (`Callable`) â€” è¦è£…é¥°çš„å‡½æ•°ã€‚

ä¸€ä¸ªè£…é¥°å™¨ï¼Œåªä¼šåœ¨ä¸»è¿›ç¨‹ä¸Šè¿è¡Œè£…é¥°çš„å‡½æ•°ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ `PartialState` ç±»è°ƒç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()

>>> @accelerator.on_main_process
... def print_something():
...     print("This will be printed by process 0 only.")

>>> print_something()
"This will be printed by process 0 only"
```

#### `on_process`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L715)

```py
( function: Callable[..., Any] = None process_index: int = None )
```

å‚æ•°

+   `function` (`Callable`, `å¯é€‰`) â€” è¦è£…é¥°çš„å‡½æ•°ã€‚

+   `process_index` (`int`, `å¯é€‰`) â€” è¦è¿è¡Œå‡½æ•°çš„è¿›ç¨‹çš„ç´¢å¼•ã€‚

ä¸€ä¸ªè£…é¥°å™¨ï¼Œåªä¼šåœ¨ç»™å®šçš„è¿›ç¨‹ç´¢å¼•ä¸Šè¿è¡Œè£…é¥°çš„å‡½æ•°ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ `PartialState` ç±»è°ƒç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
# Assume we have 4 processes.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_process(process_index=2)
def print_something():
    print(f"Printed on process {accelerator.process_index}")

print_something()
"Printed on process 2"
```

#### `pad_across_processes`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2261)

```py
( tensor dim = 0 pad_index = 0 pad_first = False ) â†’ export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor
```

å‚æ•°

+   `tensor`ï¼ˆ`torch.Tensor`çš„åµŒå¥—åˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼‰ â€” è¦æ”¶é›†çš„æ•°æ®ã€‚

+   `dim` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” è¦å¡«å……çš„ç»´åº¦ã€‚

+   `pad_index` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 0) â€” ç”¨äºå¡«å……çš„å€¼ã€‚

+   `pad_first` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨å¼€å¤´æˆ–ç»“å°¾å¡«å……ã€‚

è¿”å›

`torch.Tensor`ï¼Œæˆ– `torch.Tensor` çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸

å¡«å……åçš„å¼ é‡ã€‚

é€’å½’å¡«å……åµŒå¥—åˆ—è¡¨/å…ƒç»„/å¼ é‡å­—å…¸ä¸­çš„å¼ é‡ï¼Œä½¿å®ƒä»¬å¯ä»¥å®‰å…¨åœ°è¢«æ”¶é›†åˆ°ç›¸åŒçš„å¤§å°ã€‚

ç¤ºä¾‹ï¼š

```py
>>> # Assuming two processes, with the first processes having a tensor of size 1 and the second of size 2
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> process_tensor = torch.arange(accelerator.process_index + 1).to(accelerator.device)
>>> padded_tensor = accelerator.pad_across_processes(process_tensor)
>>> padded_tensor.shape
torch.Size([2])
```

#### `prepare`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1116)

```py
( *args device_placement = None )
```

å‚æ•°

+   `*args`ï¼ˆå¯¹è±¡åˆ—è¡¨ï¼‰ â€” ä»¥ä¸‹ç±»å‹çš„ä»»ä½•å¯¹è±¡ï¼š

    +   `torch.utils.data.DataLoader`: PyTorch æ•°æ®åŠ è½½å™¨

    +   `torch.nn.Module`: PyTorch æ¨¡å—

    +   `torch.optim.Optimizer`: PyTorch ä¼˜åŒ–å™¨

    +   `torch.optim.lr_scheduler.LRScheduler`: PyTorch LR è°ƒåº¦ç¨‹åº

+   `device_placement` (`list[bool]`, *å¯é€‰*) â€” ç”¨äºè‡ªå®šä¹‰æ˜¯å¦åº”ä¸ºä¼ é€’çš„æ¯ä¸ªå¯¹è±¡æ‰§è¡Œè‡ªåŠ¨è®¾å¤‡æ”¾ç½®ã€‚éœ€è¦ä¸ `args` é•¿åº¦ç›¸åŒçš„åˆ—è¡¨ã€‚ä¸ DeepSpeed æˆ– FSDP ä¸å…¼å®¹ã€‚

å‡†å¤‡ä¼ é€’çš„æ‰€æœ‰å¯¹è±¡è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦ï¼Œç„¶åä»¥ç›¸åŒé¡ºåºè¿”å›å®ƒä»¬ã€‚

å¦‚æœä»…ç”¨äºæ¨æ–­è€Œä¸æ¶‰åŠä»»ä½•æ··åˆç²¾åº¦ï¼Œåˆ™æ— éœ€å‡†å¤‡æ¨¡å‹

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume a model, optimizer, data_loader and scheduler are defined
>>> model, optimizer, data_loader, scheduler = accelerator.prepare(model, optimizer, data_loader, scheduler)
```

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume a model, optimizer, data_loader and scheduler are defined
>>> device_placement = [True, True, False, False]
>>> # Will place the first to items passed in automatically to the right device but not the last two.
>>> model, optimizer, data_loader, scheduler = accelerator.prepare(
...     model, optimizer, data_loader, scheduler, device_placement=device_placement
... )
```

#### `prepare_data_loader`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1812)

```py
( data_loader: torch.utils.data.DataLoader device_placement = None slice_fn_for_dispatch = None )
```

å‚æ•°

+   `data_loader` (`torch.utils.data.DataLoader`) â€” ä¸€ä¸ªæ™®é€šçš„ PyTorch æ•°æ®åŠ è½½å™¨è¦å‡†å¤‡

+   `device_placement` (`bool`, *å¯é€‰*) â€” æ˜¯å¦å°†æ‰¹æ¬¡æ”¾ç½®åœ¨å‡†å¤‡å¥½çš„æ•°æ®åŠ è½½å™¨ä¸­çš„æ­£ç¡®è®¾å¤‡ä¸Šã€‚é»˜è®¤ä¸º `self.device_placement`ã€‚

+   `slice_fn_for_dispatch` (`Callable`, *å¯é€‰*`) -- å¦‚æœä¼ é€’ï¼Œå°†ä½¿ç”¨æ­¤å‡½æ•°åœ¨` num_processes`ä¸Šåˆ‡ç‰‡å¼ é‡ã€‚é»˜è®¤ä¸º slice_tensors()ã€‚æ­¤å‚æ•°ä»…åœ¨` dispatch_batches`è®¾ç½®ä¸º`True`æ—¶ä½¿ç”¨ï¼Œå¦åˆ™å°†è¢«å¿½ç•¥ã€‚

ä¸ºåœ¨ä»»ä½•åˆ†å¸ƒå¼è®¾ç½®ä¸­è®­ç»ƒå‡†å¤‡ä¸€ä¸ª PyTorch æ•°æ®åŠ è½½å™¨ã€‚å»ºè®®ä½¿ç”¨ Accelerator.prepare()ä»£æ›¿ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> data_loader = torch.utils.data.DataLoader(...)
>>> data_loader = accelerator.prepare_data_loader(data_loader, device_placement=True)
```

#### `prepare_model`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1252)

```py
( model: torch.nn.Module device_placement: bool = None evaluation_mode: bool = False )
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” ä¸€ä¸ªè¦å‡†å¤‡çš„ PyTorch æ¨¡å‹ã€‚å¦‚æœä»…ç”¨äºæ¨æ–­è€Œä¸æ¶‰åŠä»»ä½•æ··åˆç²¾åº¦ï¼Œåˆ™æ— éœ€å‡†å¤‡æ¨¡å‹

+   `device_placement` (`bool`, *å¯é€‰*) â€” æ˜¯å¦å°†æ¨¡å‹æ”¾ç½®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šã€‚é»˜è®¤ä¸º `self.device_placement`ã€‚

+   `evaluation_mode` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œåªéœ€åº”ç”¨æ··åˆç²¾åº¦å’Œ `torch.compile`ï¼ˆå¦‚æœåœ¨ `Accelerator` å¯¹è±¡ä¸­é…ç½®ï¼‰ã€‚

ä¸ºåœ¨ä»»ä½•åˆ†å¸ƒå¼è®¾ç½®ä¸­è®­ç»ƒå‡†å¤‡ä¸€ä¸ª PyTorch æ¨¡å‹ã€‚å»ºè®®ä½¿ç”¨ Accelerator.prepare()ä»£æ›¿ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume a model is defined
>>> model = accelerator.prepare_model(model)
```

#### `prepare_optimizer`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1864)

```py
( optimizer: torch.optim.Optimizer device_placement = None )
```

å‚æ•°

+   `optimizer` (`torch.optim.Optimizer`) â€” ä¸€ä¸ªæ™®é€šçš„ PyTorch ä¼˜åŒ–å™¨è¦å‡†å¤‡

+   `device_placement` (`bool`, *å¯é€‰*) â€” æ˜¯å¦å°†ä¼˜åŒ–å™¨æ”¾ç½®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šã€‚é»˜è®¤ä¸º `self.device_placement`ã€‚

ä¸ºåœ¨ä»»ä½•åˆ†å¸ƒå¼è®¾ç½®ä¸­è®­ç»ƒå‡†å¤‡ä¸€ä¸ª PyTorch ä¼˜åŒ–å™¨ã€‚å»ºè®®ä½¿ç”¨ Accelerator.prepare()ä»£æ›¿ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> optimizer = torch.optim.Adam(...)
>>> optimizer = accelerator.prepare_optimizer(optimizer, device_placement=True)
```

#### `prepare_scheduler`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1897)

```py
( scheduler: LRScheduler )
```

å‚æ•°

+   `scheduler` (`torch.optim.lr_scheduler.LRScheduler`) â€” è¦å‡†å¤‡çš„ä¸€ä¸ªæ™®é€šçš„ PyTorch è°ƒåº¦ç¨‹åº

ä¸ºåœ¨ä»»ä½•åˆ†å¸ƒå¼è®¾ç½®ä¸­è®­ç»ƒå‡†å¤‡ä¸€ä¸ª PyTorch è°ƒåº¦ç¨‹åºã€‚å»ºè®®ä½¿ç”¨ Accelerator.prepare()ä»£æ›¿ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> optimizer = torch.optim.Adam(...)
>>> scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, ...)
>>> scheduler = accelerator.prepare_scheduler(scheduler)
```

#### `print`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1084)

```py
( *args **kwargs )
```

`print()`çš„æ›¿ä»£æ–¹æ³•ï¼Œæ¯ä¸ªæœåŠ¡å™¨åªæ‰“å°ä¸€æ¬¡ã€‚

ç¤ºä¾‹:

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> accelerator.print("Hello world!")
```

#### `reduce`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2225)

```py
( tensor reduction = 'sum' scale = 1.0 ) â†’ export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor
```

å‚æ•°

+   `tensor`ï¼ˆ`torch.Tensor`ï¼Œæˆ–`torch.Tensor`çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸ï¼‰â€” è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­å‡å°‘çš„å¼ é‡ã€‚

+   `reduction`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºâ€œsumâ€ï¼‰â€” å‡å°‘ç±»å‹ï¼Œå¯ä»¥æ˜¯â€œsumâ€ã€â€œmeanâ€æˆ–â€œnoneâ€ä¸­çš„ä¸€ä¸ªã€‚å¦‚æœæ˜¯â€œnoneâ€ï¼Œåˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œã€‚

+   `scale`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 1.0ï¼‰â€” åœ¨å‡å°‘ååº”ç”¨çš„é»˜è®¤ç¼©æ”¾å€¼ï¼Œä»…åœ¨ XLA ä¸Šæœ‰æ•ˆã€‚

è¿”å›

`torch.Tensor`ï¼Œæˆ–`torch.Tensor`çš„åµŒå¥—å…ƒç»„/åˆ—è¡¨/å­—å…¸

å‡å°‘çš„å¼ é‡ã€‚

æ ¹æ®*reduction*åœ¨*å¼ é‡*ä¸­å‡å°‘æ‰€æœ‰è¿›ç¨‹ä¸­çš„å€¼ã€‚

æ³¨æ„ï¼šæ‰€æœ‰è¿›ç¨‹éƒ½ä¼šå¾—åˆ°å‡å°‘çš„å€¼ã€‚

ç¤ºä¾‹ï¼š

```py
>>> # Assuming two processes
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> process_tensor = torch.arange(accelerator.num_processes) + 1 + (2 * accelerator.process_index)
>>> process_tensor = process_tensor.to(accelerator.device)
>>> reduced_tensor = accelerator.reduce(process_tensor, reduction="sum")
>>> reduced_tensor
tensor([4, 6])
```

#### `register_for_checkpointing`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3073)

```py
( *objects )
```

æ³¨æ„`objects`å¹¶å°†åœ¨`save_state`æˆ–`load_state`æœŸé—´ä¿å­˜æˆ–åŠ è½½å®ƒä»¬ã€‚

è¿™äº›åº”è¯¥åœ¨ç›¸åŒè„šæœ¬ä¸­åŠ è½½æˆ–ä¿å­˜çŠ¶æ€æ—¶ä½¿ç”¨ã€‚ä¸åº”è¯¥åœ¨ä¸åŒè„šæœ¬ä¸­ä½¿ç”¨ã€‚

æ¯ä¸ª`object`å¿…é¡»æœ‰ä¸€ä¸ª`load_state_dict`å’Œ`state_dict`å‡½æ•°ä»¥è¿›è¡Œå­˜å‚¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume `CustomObject` has a `state_dict` and `load_state_dict` function.
>>> obj = CustomObject()
>>> accelerator.register_for_checkpointing(obj)
>>> accelerator.save_state("checkpoint.pt")
```

#### `register_load_state_pre_hook`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2785)

```py
( hook: Callable[..., None] ) â†’ export const metadata = 'undefined';torch.utils.hooks.RemovableHandle
```

å‚æ•°

+   `hook`ï¼ˆ`Callable`ï¼‰â€” åœ¨ Accelerator.load_state()ä¹‹å‰è°ƒç”¨çš„å‡½æ•°ï¼Œç”¨äº`load_checkpoint`ã€‚

è¿”å›

`torch.utils.hooks.RemovableHandle`

ä¸€ä¸ªå¥æŸ„ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨`handle.remove()`æ¥ç§»é™¤æ·»åŠ çš„é’©å­

æ³¨å†Œä¸€ä¸ªé¢„é’©å­ï¼Œåœ¨ Accelerator.load_state()ä¸­è°ƒç”¨`load_checkpoint`ä¹‹å‰è¿è¡Œã€‚

é’©å­åº”è¯¥å…·æœ‰ä»¥ä¸‹ç­¾å:

`hook(models: list[torch.nn.Module], input_dir: str) -> None`

`models`å‚æ•°æ˜¯ä¿å­˜åœ¨åŠ é€Ÿå™¨çŠ¶æ€ä¸‹çš„æ¨¡å‹`accelerator._models`ï¼Œ`input_dir`å‚æ•°æ˜¯ä¼ é€’ç»™ Accelerator.load_state()çš„`input_dir`å‚æ•°ã€‚

åº”è¯¥åªä¸ Accelerator.register_save_state_pre_hook()ä¸€èµ·ä½¿ç”¨ã€‚å¯ä»¥ç”¨äºåŠ è½½é…ç½®ä»¥åŠæ¨¡å‹æƒé‡ã€‚ä¹Ÿå¯ä»¥ç”¨äºä½¿ç”¨è‡ªå®šä¹‰æ–¹æ³•è¦†ç›–æ¨¡å‹åŠ è½½ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·ç¡®ä¿ä»æ¨¡å‹åˆ—è¡¨ä¸­åˆ é™¤å·²åŠ è½½çš„æ¨¡å‹ã€‚

#### `register_save_state_pre_hook`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2619)

```py
( hook: Callable[..., None] ) â†’ export const metadata = 'undefined';torch.utils.hooks.RemovableHandle
```

å‚æ•°

+   `hook`ï¼ˆ`Callable`ï¼‰â€” åœ¨ Accelerator.save_state()ä¹‹å‰è°ƒç”¨çš„å‡½æ•°ï¼Œç”¨äº`save_checkpoint`ã€‚

è¿”å›

`torch.utils.hooks.RemovableHandle`

ä¸€ä¸ªå¥æŸ„ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨`handle.remove()`æ¥ç§»é™¤æ·»åŠ çš„é’©å­

æ³¨å†Œä¸€ä¸ªé¢„é’©å­ï¼Œåœ¨ Accelerator.save_state()ä¸­è°ƒç”¨`save_checkpoint`ä¹‹å‰è¿è¡Œã€‚

é’©å­åº”è¯¥å…·æœ‰ä»¥ä¸‹ç­¾åï¼š

`hook(models: list[torch.nn.Module], weights: list[dict[str, torch.Tensor]], input_dir: str) -> None`

`models`å‚æ•°æ˜¯ä¿å­˜åœ¨åŠ é€Ÿå™¨çŠ¶æ€ä¸‹çš„æ¨¡å‹`accelerator._models`ï¼Œ`weights`å‚æ•°æ˜¯`models`çš„çŠ¶æ€å­—å…¸ï¼Œ`input_dir`å‚æ•°æ˜¯ä¼ é€’ç»™ Accelerator.load_state()çš„`input_dir`å‚æ•°ã€‚

åº”ä»…ä¸ Accelerator.register_load_state_pre_hook()ä¸€èµ·ä½¿ç”¨ã€‚é™¤äº†æ¨¡å‹æƒé‡å¤–ï¼Œä¿å­˜é…ç½®ä¹Ÿå¾ˆæœ‰ç”¨ã€‚ä¹Ÿå¯ä»¥ç”¨äºä½¿ç”¨è‡ªå®šä¹‰æ–¹æ³•è¦†ç›–æ¨¡å‹ä¿å­˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·ç¡®ä¿ä»æƒé‡åˆ—è¡¨ä¸­åˆ é™¤å·²åŠ è½½çš„æƒé‡ã€‚

#### `save`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2482)

```py
( obj f safe_serialization = False )
```

å‚æ•°

+   `obj`ï¼ˆ`object`ï¼‰â€” è¦ä¿å­˜çš„å¯¹è±¡ã€‚

+   `f`ï¼ˆ`str`æˆ–`os.PathLike`ï¼‰â€” è¦ä¿å­˜`obj`å†…å®¹çš„ä½ç½®ã€‚

+   `safe_serialization`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦ä½¿ç”¨`safetensors`ä¿å­˜`obj`

å°†ä¼ é€’ç»™ç£ç›˜çš„å¯¹è±¡æ¯å°æœºå™¨ä¿å­˜ä¸€æ¬¡ã€‚ç”¨äºæ›¿ä»£`torch.save`ã€‚

æ³¨æ„ï¼šå¦‚æœ`save_on_each_node`ä½œä¸º`ProjectConfiguration`ä¼ å…¥ï¼Œåˆ™ä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜å¯¹è±¡ä¸€æ¬¡ï¼Œè€Œä¸ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šä¿å­˜ä¸€æ¬¡ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> arr = [0, 1, 2, 3]
>>> accelerator.save(arr, "array.pkl")
```

#### `save_model`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2512)

```py
( model: torch.nn.Module save_directory: Union[str, os.PathLike] max_shard_size: Union[int, str] = '10GB' safe_serialization: bool = True )
```

å‚æ•°

+   `save_directory`ï¼ˆ`str`æˆ–`os.PathLike`ï¼‰â€” è¦ä¿å­˜åˆ°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†ä¼šåˆ›å»ºã€‚

+   `max_shard_size`ï¼ˆ`int`æˆ–`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"10GB"`ï¼‰â€” åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡å°†æ¯ä¸ªå¤§å°éƒ½å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œåˆ™éœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚`"5MB"`ï¼‰ã€‚

    å¦‚æœæ¨¡å‹çš„å•ä¸ªæƒé‡å¤§äº`max_shard_size`ï¼Œåˆ™å®ƒå°†åœ¨è‡ªå·±çš„æ£€æŸ¥ç‚¹åˆ†ç‰‡ä¸­ï¼Œè¯¥åˆ†ç‰‡å°†å¤§äº`max_shard_size`ã€‚

+   `safe_serialization`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä½¿ç”¨`safetensors`æˆ–ä¼ ç»Ÿçš„ PyTorch æ–¹å¼ï¼ˆä½¿ç”¨`pickle`ï¼‰ä¿å­˜æ¨¡å‹ã€‚

ä¿å­˜æ¨¡å‹ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨`load_checkpoint_in_model`é‡æ–°åŠ è½½

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model = ...
>>> accelerator.save_model(model, save_directory)
```

#### `save_state`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2651)

```py
( output_dir: str = None safe_serialization: bool = True **save_model_func_kwargs )
```

å‚æ•°

+   `output_dir`ï¼ˆ`str`æˆ–`os.PathLike`ï¼‰â€” ä¿å­˜æ‰€æœ‰ç›¸å…³æƒé‡å’ŒçŠ¶æ€çš„æ–‡ä»¶å¤¹çš„åç§°ã€‚

+   `safe_serialization`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä½¿ç”¨`safetensors`æˆ–ä¼ ç»Ÿçš„ PyTorch æ–¹å¼ï¼ˆä½¿ç”¨`pickle`ï¼‰ä¿å­˜æ¨¡å‹ã€‚

+   `save_model_func_kwargs`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä¿å­˜æ¨¡å‹çš„é¢å¤–å…³é”®å­—å‚æ•°ï¼Œå¯ä»¥ä¼ é€’ç»™åº•å±‚ä¿å­˜å‡½æ•°ï¼Œä¾‹å¦‚ DeepSpeed çš„`save_checkpoint`å‡½æ•°çš„å¯é€‰å‚æ•°ã€‚

å°†æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€ç¼©æ”¾å™¨ã€RNG ç”Ÿæˆå™¨å’Œå·²æ³¨å†Œå¯¹è±¡çš„å½“å‰çŠ¶æ€ä¿å­˜åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚

å¦‚æœå°†`ProjectConfiguration`ä¼ é€’ç»™å¯ç”¨äº†`automatic_checkpoint_naming`çš„`Accelerator`å¯¹è±¡ï¼Œåˆ™æ£€æŸ¥ç‚¹å°†ä¿å­˜åœ¨`self.project_dir/checkpoints`ä¸­ã€‚å¦‚æœå½“å‰ä¿å­˜çš„æ•°é‡å¤§äº`total_limit`ï¼Œåˆ™å°†åˆ é™¤æœ€æ—§çš„ä¿å­˜ã€‚æ¯ä¸ªæ£€æŸ¥ç‚¹éƒ½ä¿å­˜åœ¨åä¸º`checkpoint_<iteration>`çš„å•ç‹¬æ–‡ä»¶å¤¹ä¸­ã€‚

å¦åˆ™å®ƒä»¬åªä¿å­˜åˆ°`output_dir`ã€‚

ä»…åœ¨å¸Œæœ›åœ¨è®­ç»ƒæœŸé—´ä¿å­˜æ£€æŸ¥ç‚¹å¹¶åœ¨ç›¸åŒç¯å¢ƒä¸­æ¢å¤çŠ¶æ€æ—¶ä½¿ç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, lr_scheduler = ...
>>> model, optimizer, lr_scheduler = accelerator.prepare(model, optimizer, lr_scheduler)
>>> accelerator.save_state(output_dir="my_checkpoint")
```

#### `set_trigger`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1968)

```py
( )
```

å°†å½“å‰è¿›ç¨‹çš„å†…éƒ¨è§¦å‘å¼ é‡è®¾ç½®ä¸º 1ã€‚éšååº”è¯¥ä½¿ç”¨æ­¤æ£€æŸ¥ï¼Œè¯¥æ£€æŸ¥å°†è·¨æ‰€æœ‰è¿›ç¨‹è¿›è¡Œæ£€æŸ¥ã€‚

æ³¨æ„ï¼šä¸éœ€è¦`wait_for_everyone()`

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume later in the training script
>>> # `should_do_breakpoint` is a custom function to monitor when to break,
>>> # e.g. when the loss is NaN
>>> if should_do_breakpoint(loss):
...     accelerator.set_trigger()
>>> # Assume later in the training script
>>> if accelerator.check_breakpoint():
...     break
```

#### `skip_first_batches`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3156)

```py
( dataloader num_batches: int = 0 )
```

å‚æ•°

+   `dataloader`ï¼ˆ`torch.utils.data.DataLoader`ï¼‰â€” è¦è·³è¿‡æ‰¹æ¬¡çš„æ•°æ®åŠ è½½å™¨ã€‚

+   `num_batches`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0ï¼‰â€” è¦è·³è¿‡çš„æ‰¹æ¬¡æ•°

åˆ›å»ºä¸€ä¸ªæ–°çš„`torch.utils.data.DataLoader`ï¼Œå®ƒå°†é«˜æ•ˆåœ°è·³è¿‡å‰`num_batches`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)
>>> skipped_dataloader = accelerator.skip_first_batches(dataloader, num_batches=2)
>>> # for the first epoch only
>>> for input, target in skipped_dataloader:
...     optimizer.zero_grad()
...     output = model(input)
...     loss = loss_func(output, target)
...     accelerator.backward(loss)
...     optimizer.step()

>>> # subsequent epochs
>>> for input, target in dataloader:
...     optimizer.zero_grad()
...     ...
```

#### `split_between_processes`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L553)

```py
( inputs: list | tuple | dict | torch.Tensor apply_padding: bool = False )
```

å‚æ•°

+   `inputs`ï¼ˆ`list`ï¼Œ`tuple`ï¼Œ`torch.Tensor`æˆ–`dict`çš„`list`/`tuple`/`torch.Tensor`ï¼‰â€” åœ¨è¿›ç¨‹ä¹‹é—´æ‹†åˆ†çš„è¾“å…¥ã€‚

+   `apply_padding`ï¼ˆ`bool`ï¼Œ`å¯é€‰`ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦é€šè¿‡é‡å¤è¾“å…¥çš„æœ€åä¸€ä¸ªå…ƒç´ æ¥åº”ç”¨å¡«å……ï¼Œä»¥ä¾¿æ‰€æœ‰è¿›ç¨‹å…·æœ‰ç›¸åŒæ•°é‡çš„å…ƒç´ ã€‚åœ¨å°è¯•å¯¹è¾“å‡ºæ‰§è¡Œ`Accelerator.gather()`ç­‰æ“ä½œæˆ–ä¼ å…¥å°‘äºè¿›ç¨‹æ•°çš„è¾“å…¥æ—¶å¾ˆæœ‰ç”¨ã€‚å¦‚æœæ˜¯è¿™æ ·ï¼Œè¯·è®°å¾—ä¹‹ååˆ é™¤å¡«å……çš„å…ƒç´ ã€‚

å¿«é€Ÿå°†`input`åœ¨`self.num_processes`ä¹‹é—´æ‹†åˆ†ï¼Œç„¶åå¯ä»¥åœ¨è¯¥è¿›ç¨‹ä¸Šä½¿ç”¨ã€‚åœ¨è¿›è¡Œåˆ†å¸ƒå¼æ¨ç†æ—¶å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚ä½¿ç”¨ä¸åŒçš„æç¤ºã€‚

è¯·æ³¨æ„ï¼Œä½¿ç”¨`dict`æ—¶ï¼Œæ‰€æœ‰é”®éƒ½éœ€è¦å…·æœ‰ç›¸åŒæ•°é‡çš„å…ƒç´ ã€‚

ç¤ºä¾‹ï¼š

```py
# Assume there are two processes
from accelerate import Accelerator

accelerator = Accelerator()
with accelerator.split_between_processes(["A", "B", "C"]) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C"]

with accelerator.split_between_processes(["A", "B", "C"], apply_padding=True) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C", "C"]
```

#### `trigger_sync_in_backward`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L893)

```py
( model )
```

å‚æ•°

+   `model`ï¼ˆ`torch.nn.Module`ï¼‰â€” è¦è§¦å‘æ¢¯åº¦åŒæ­¥çš„æ¨¡å‹ã€‚

åœ¨`Accelerator.no_sync`ä¸‹çš„å¤šæ¬¡å‰å‘ä¼ é€’åï¼Œè§¦å‘æ¨¡å‹åœ¨ä¸‹ä¸€ä¸ªåå‘ä¼ é€’ä¸­åŒæ­¥æ¢¯åº¦ï¼ˆä»…é€‚ç”¨äºå¤š GPU åœºæ™¯ï¼‰ã€‚

å¦‚æœè„šæœ¬æœªåœ¨åˆ†å¸ƒå¼æ¨¡å¼ä¸‹å¯åŠ¨ï¼Œåˆ™æ­¤ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸èµ·ä½œç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader, model, optimizer = accelerator.prepare(dataloader, model, optimizer)

>>> with accelerator.no_sync():
...     loss_a = loss_func(model(input_a))  # first forward pass
...     loss_b = loss_func(model(input_b))  # second forward pass
>>> accelerator.backward(loss_a)  # No synchronization across processes, only accumulate gradients
>>> with accelerator.trigger_sync_in_backward(model):
...     accelerator.backward(loss_b)  # Synchronization across all processes
>>> optimizer.step()
>>> optimizer.zero_grad()
```

#### `unscale_gradients`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2027)

```py
( optimizer = None )
```

å‚æ•°

+   `optimizer`ï¼ˆ`torch.optim.Optimizer`æˆ–`list[torch.optim.Optimizer]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦å¯¹æ¢¯åº¦è¿›è¡Œä¸ç¼©æ”¾çš„ä¼˜åŒ–å™¨ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†å¯¹ä¼ é€’ç»™ prepare()çš„æ‰€æœ‰ä¼˜åŒ–å™¨è¿›è¡Œæ¢¯åº¦ä¸ç¼©æ”¾ã€‚

åœ¨ AMP æ··åˆç²¾åº¦è®­ç»ƒä¸­ä¸ç¼©æ”¾æ¢¯åº¦ã€‚åœ¨æ‰€æœ‰å…¶ä»–è®¾ç½®ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ªç©ºæ“ä½œã€‚

å¯èƒ½åº”è¯¥é€šè¿‡ Accelerator.clip*grad_norm*()æˆ– Accelerator.clip*grad_value*()æ¥è°ƒç”¨

ç¤ºä¾‹ï¼š

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer = accelerator.prepare(model, optimizer)
>>> outputs = model(inputs)
>>> loss = loss_fn(outputs, labels)
>>> accelerator.backward(loss)
>>> accelerator.unscale_gradients(optimizer=optimizer)
```

#### `unwrap_model`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2296)

```py
( model keep_fp32_wrapper: bool = True ) â†’ export const metadata = 'undefined';torch.nn.Module
```

å‚æ•°

+   `model`ï¼ˆ`torch.nn.Module`ï¼‰â€” è¦å–æ¶ˆåŒ…è£…çš„æ¨¡å‹ã€‚

+   `keep_fp32_wrapper`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦åœ¨æ·»åŠ æ—¶ä¸åˆ é™¤æ··åˆç²¾åº¦é’©å­ã€‚

è¿”å›

`torch.nn.Module`

æœªåŒ…è£…çš„æ¨¡å‹ã€‚

ä» prepare()å¯èƒ½æ·»åŠ çš„é¢å¤–å±‚ä¸­å–æ¶ˆåŒ…è£…`model`ã€‚åœ¨ä¿å­˜æ¨¡å‹ä¹‹å‰å¾ˆæœ‰ç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> # Assuming two GPU processes
>>> from torch.nn.parallel import DistributedDataParallel
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model = accelerator.prepare(MyModel())
>>> print(model.__class__.__name__)
DistributedDataParallel

>>> model = accelerator.unwrap_model(model)
>>> print(model.__class__.__name__)
MyModel
```

#### `verify_device_map`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3192)

```py
( model: torch.nn.Module )
```

éªŒè¯`model`æ˜¯å¦æœªå‡†å¤‡å¥½ä½¿ç”¨ç±»ä¼¼`auto`çš„è®¾å¤‡æ˜ å°„è¿›è¡Œå¤§å‹æ¨¡å‹æ¨ç†ã€‚

#### `wait_for_everyone`

[<æ¥æº>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2329)

```py
( )
```

å°†åœæ­¢å½“å‰è¿›ç¨‹çš„æ‰§è¡Œï¼Œç›´åˆ°æ¯ä¸ªå…¶ä»–è¿›ç¨‹éƒ½è¾¾åˆ°è¯¥ç‚¹ï¼ˆå› æ­¤å½“è„šæœ¬ä»…åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­è¿è¡Œæ—¶ï¼Œæ­¤æ“ä½œæ— æ•ˆï¼‰ã€‚åœ¨ä¿å­˜æ¨¡å‹ä¹‹å‰æ‰§è¡Œæ­¤æ“ä½œå¾ˆæœ‰ç”¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> # Assuming two GPU processes
>>> import time
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> if accelerator.is_main_process:
...     time.sleep(2)
>>> else:
...     print("I'm waiting for the main process to finish its sleep...")
>>> accelerator.wait_for_everyone()
>>> # Should print on every process at the same time
>>> print("Everyone is here")
```
