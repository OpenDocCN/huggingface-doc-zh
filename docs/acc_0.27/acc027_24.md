# DeepSpeed

> [åŸæ–‡é“¾æ¥](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)

[DeepSpeed](https://github.com/microsoft/DeepSpeed)å®ç°äº†[ZeRO è®ºæ–‡](https://arxiv.org/abs/1910.02054)ä¸­æè¿°çš„æ‰€æœ‰å†…å®¹ã€‚ä¸€äº›æ˜¾è‘—çš„ä¼˜åŒ–åŒ…æ‹¬ï¼š

1.  ä¼˜åŒ–å™¨çŠ¶æ€åˆ†åŒºï¼ˆZeRO é˜¶æ®µ 1ï¼‰

1.  æ¢¯åº¦åˆ†åŒºï¼ˆZeRO é˜¶æ®µ 2ï¼‰

1.  å‚æ•°åˆ†åŒºï¼ˆZeRO é˜¶æ®µ 3ï¼‰

1.  è‡ªå®šä¹‰æ··åˆç²¾åº¦è®­ç»ƒå¤„ç†

1.  ä¸€ç³»åˆ—åŸºäºå¿«é€Ÿ CUDA æ‰©å±•çš„ä¼˜åŒ–å™¨

1.  ZeRO-Offload åˆ° CPU å’Œç£ç›˜/NVMe

1.  æ¨¡å‹å‚æ•°çš„åˆ†å±‚åˆ†åŒºï¼ˆZeRO++ï¼‰

ZeRO-Offload æœ‰è‡ªå·±çš„ä¸“é—¨è®ºæ–‡ï¼š[ZeRO-Offload:æ°‘ä¸»åŒ–äº¿çº§æ¨¡å‹è®­ç»ƒ](https://arxiv.org/abs/2101.06840)ã€‚NVMe æ”¯æŒåœ¨è®ºæ–‡[ZeRO-Infinity:æ‰“ç ´ GPU å†…å­˜å£å’ï¼Œå®ç°æç«¯è§„æ¨¡çš„æ·±åº¦å­¦ä¹ ](https://arxiv.org/abs/2104.07857)ä¸­æœ‰æè¿°ã€‚

DeepSpeed ZeRO-2 ä¸»è¦ä»…ç”¨äºè®­ç»ƒï¼Œå› ä¸ºå…¶ç‰¹æ€§å¯¹æ¨ç†æ— ç”¨ã€‚

DeepSpeed ZeRO-3 ä¹Ÿå¯ç”¨äºæ¨ç†ï¼Œå› ä¸ºå®ƒå…è®¸å°†åºå¤§çš„æ¨¡å‹åŠ è½½åˆ°å¤šä¸ª GPU ä¸Šï¼Œè¿™åœ¨å•ä¸ª GPU ä¸Šæ˜¯ä¸å¯èƒ½çš„ã€‚

ğŸ¤— Accelerate é€šè¿‡ 2 ç§é€‰é¡¹é›†æˆ[DeepSpeed](https://github.com/microsoft/DeepSpeed)ï¼š

1.  é€šè¿‡åœ¨`accelerate config`ä¸­ä½¿ç”¨`deepspeed config file`è§„èŒƒé›†æˆ DeepSpeed åŠŸèƒ½ã€‚æ‚¨åªéœ€æä¾›è‡ªå®šä¹‰é…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡æ¿ã€‚æœ¬æ–‡æ¡£çš„å¤§éƒ¨åˆ†å†…å®¹éƒ½é›†ä¸­åœ¨è¿™ä¸ªåŠŸèƒ½ä¸Šã€‚è¿™æ”¯æŒ DeepSpeed çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›äº†å¾ˆå¤§çš„çµæ´»æ€§ã€‚ç”¨æˆ·å¯èƒ½éœ€è¦æ ¹æ®é…ç½®æ›´æ”¹å‡ è¡Œä»£ç ã€‚

1.  é€šè¿‡`deepspeed_plugin`è¿›è¡Œé›†æˆã€‚è¿™æ”¯æŒ DeepSpeed åŠŸèƒ½çš„å­é›†ï¼Œå¹¶å¯¹å…¶ä½™é…ç½®ä½¿ç”¨é»˜è®¤é€‰é¡¹ã€‚ç”¨æˆ·æ— éœ€æ›´æ”¹ä»»ä½•ä»£ç ï¼Œé€‚ç”¨äºé‚£äº›å¯¹ DeepSpeed çš„å¤§å¤šæ•°é»˜è®¤è®¾ç½®æ»¡æ„çš„ç”¨æˆ·ã€‚

## é›†æˆäº†ä»€ä¹ˆï¼Ÿ

è®­ç»ƒï¼š

1.  ğŸ¤— Accelerate é›†æˆäº† DeepSpeed ZeRO çš„æ‰€æœ‰åŠŸèƒ½ã€‚è¿™åŒ…æ‹¬æ‰€æœ‰ ZeRO é˜¶æ®µ 1ã€2 å’Œ 3ï¼Œä»¥åŠ ZeRO-Offloadã€ZeRO-Infinityï¼ˆå¯ä»¥å¸è½½åˆ°ç£ç›˜/NVMeï¼‰å’Œ ZeRO++ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ ZeRO è¿›è¡Œæ•°æ®å¹¶è¡Œçš„ç®€çŸ­æè¿° - é›¶å†—ä½™ä¼˜åŒ–å™¨ï¼Œä»¥åŠæ¥è‡ªè¿™ç¯‡[åšå®¢æ–‡ç« ](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)çš„å›¾è¡¨ ![ZeRO æ•°æ®å¹¶è¡Œ](img/61da03a3a1a0e2c5e704642f87f2f216.png)

ï¼ˆæ¥æºï¼š[é“¾æ¥](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)ï¼‰

a. **é˜¶æ®µ 1**ï¼šå°†ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡åˆ°æ•°æ®å¹¶è¡Œå·¥ä½œè€…/GPU ä¹‹é—´

b. **é˜¶æ®µ 2**ï¼šå°†ä¼˜åŒ–å™¨çŠ¶æ€+æ¢¯åº¦åˆ†ç‰‡åˆ°æ•°æ®å¹¶è¡Œå·¥ä½œè€…/GPU ä¹‹é—´

c. **é˜¶æ®µ 3**ï¼šå°†ä¼˜åŒ–å™¨çŠ¶æ€+æ¢¯åº¦+æ¨¡å‹å‚æ•°åˆ†ç‰‡åˆ°æ•°æ®å¹¶è¡Œå·¥ä½œè€…/GPU ä¹‹é—´

d. **ä¼˜åŒ–å™¨å¸è½½**ï¼šå°†æ¢¯åº¦+ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ° CPU/ç£ç›˜ï¼Œæ„å»ºåœ¨ ZERO é˜¶æ®µ 2 ä¹‹ä¸Š

e. **å‚æ•°å¸è½½**ï¼šå°†æ¨¡å‹å‚æ•°å¸è½½åˆ° CPU/ç£ç›˜ï¼Œæ„å»ºåœ¨ ZERO é˜¶æ®µ 3 ä¹‹ä¸Š

f. **åˆ†å±‚åˆ†åŒº**ï¼šé€šè¿‡åœ¨ ZeRO é˜¶æ®µ 3 ä¹‹ä¸Šæ„å»ºï¼Œå®ç°äº†è·¨èŠ‚ç‚¹çš„æ•°æ®å¹¶è¡Œè®­ç»ƒå’ŒèŠ‚ç‚¹å†…çš„ ZeRO-3 åˆ†ç‰‡çš„é«˜æ•ˆå¤šèŠ‚ç‚¹è®­ç»ƒã€‚

æ³¨æ„ï¼šå…³äºç£ç›˜å¸è½½ï¼Œç£ç›˜åº”ä¸º NVME ä»¥è·å¾—è‰¯å¥½çš„é€Ÿåº¦ï¼Œä½†ä»æŠ€æœ¯ä¸Šè®²ï¼Œå®ƒå¯ä»¥åœ¨ä»»ä½•ç£ç›˜ä¸Šè¿è¡Œ

æ¨ç†ï¼š

1.  DeepSpeed ZeRO æ¨ç†æ”¯æŒ ZeRO é˜¶æ®µ 3 å’Œ ZeRO-Infinityã€‚å®ƒä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ ZeRO åè®®ï¼Œä½†ä¸ä½¿ç”¨ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåªæœ‰é˜¶æ®µ 3 ç›¸å…³ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ï¼šdeepspeed-zero-inferenceã€‚

## å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

**å…ˆå†³æ¡ä»¶**ï¼šå®‰è£… DeepSpeed ç‰ˆæœ¬>=0.6.5ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ[DeepSpeed å®‰è£…è¯¦æƒ…](https://github.com/microsoft/DeepSpeed#installation)ã€‚

æˆ‘ä»¬å°†é¦–å…ˆçœ‹ä¸€ä¸‹é€šè¿‡`accelerate config`è¿›è¡Œæ˜“äºä½¿ç”¨çš„é›†æˆã€‚ç„¶åæ˜¯æ›´çµæ´»å’ŒåŠŸèƒ½ä¸°å¯Œçš„`deepspeed é…ç½®æ–‡ä»¶`é›†æˆã€‚

### åŠ é€Ÿ DeepSpeed æ’ä»¶

åœ¨æ‚¨çš„æœºå™¨ä¸Šè¿è¡Œï¼š

```py
accelerate config
```

å¹¶å›ç­”æå‡ºçš„é—®é¢˜ã€‚å®ƒä¼šè¯¢é—®æ‚¨æ˜¯å¦è¦ä½¿ç”¨ä¸€ä¸ª DeepSpeed é…ç½®æ–‡ä»¶ï¼Œæ‚¨åº”è¯¥å›ç­”å¦ã€‚ç„¶åå›ç­”ä»¥ä¸‹é—®é¢˜ä»¥ç”ŸæˆåŸºæœ¬çš„ DeepSpeed é…ç½®ã€‚è¿™å°†ç”Ÿæˆä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼Œå°†è‡ªåŠ¨ç”¨äºåœ¨æ‰§è¡Œæ—¶æ­£ç¡®è®¾ç½®é»˜è®¤é€‰é¡¹

```py
accelerate launch my_script.py --args_to_my_script
```

ä¾‹å¦‚ï¼Œè¿™æ˜¯å¦‚ä½•åœ¨ NLP ç¤ºä¾‹`examples/nlp_example.py`ï¼ˆä»å­˜å‚¨åº“çš„æ ¹ç›®å½•ï¼‰ä¸­ä½¿ç”¨ DeepSpeed æ’ä»¶è¿è¡Œçš„ï¼š

**ZeRO Stage-2 DeepSpeed æ’ä»¶ç¤ºä¾‹**

```py
compute_environment: LOCAL_MACHINE
deepspeed_config:
 gradient_accumulation_steps: 1
 gradient_clipping: 1.0
 offload_optimizer_device: none
 offload_param_device: none
 zero3_init_flag: true
 zero_stage: 2
distributed_type: DEEPSPEED
fsdp_config: {}
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
use_cpu: false
```

```py
accelerate launch examples/nlp_example.py --mixed_precision fp16
```

**å¸¦ CPU å¸è½½çš„ ZeRO Stage-3 DeepSpeed æ’ä»¶ç¤ºä¾‹**

```py
compute_environment: LOCAL_MACHINE
deepspeed_config:
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  offload_optimizer_device: cpu
  offload_param_device: cpu
  zero3_init_flag: true
  zero3_save_16bit_model: true
  zero_stage: 3
distributed_type: DEEPSPEED
fsdp_config: {}
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
use_cpu: false
```

```py
accelerate launch examples/nlp_example.py --mixed_precision fp16
```

ç›®å‰ï¼Œ`Accelerate`é€šè¿‡ CLI æ”¯æŒä»¥ä¸‹é…ç½®ï¼š

```py
`zero_stage`: [0] Disabled, [1] optimizer state partitioning, [2] optimizer+gradient state partitioning and [3] optimizer+gradient+parameter partitioning
`gradient_accumulation_steps`: Number of training steps to accumulate gradients before averaging and applying them.
`gradient_clipping`: Enable gradient clipping with value.
`offload_optimizer_device`: [none] Disable optimizer offloading, [cpu] offload optimizer to CPU, [nvme] offload optimizer to NVMe SSD. Only applicable with ZeRO >= Stage-2.
`offload_param_device`: [none] Disable parameter offloading, [cpu] offload parameters to CPU, [nvme] offload parameters to NVMe SSD. Only applicable with ZeRO Stage-3.
`zero3_init_flag`: Decides whether to enable `deepspeed.zero.Init` for constructing massive models. Only applicable with ZeRO Stage-3.
`zero3_save_16bit_model`: Decides whether to save 16-bit model weights when using ZeRO Stage-3.
`mixed_precision`: `no` for FP32 training, `fp16` for FP16 mixed-precision training and `bf16` for BF16 mixed-precision training.
```

ä¸ºäº†èƒ½å¤Ÿè°ƒæ•´æ›´å¤šé€‰é¡¹ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ DeepSpeed é…ç½®æ–‡ä»¶ã€‚

### DeepSpeed é…ç½®æ–‡ä»¶

åœ¨æ‚¨çš„æœºå™¨ä¸Šè¿è¡Œï¼š

```py
accelerate config
```

å¹¶å›ç­”æå‡ºçš„é—®é¢˜ã€‚å®ƒä¼šè¯¢é—®æ‚¨æ˜¯å¦è¦ä½¿ç”¨ä¸€ä¸ª DeepSpeed é…ç½®æ–‡ä»¶ï¼Œæ‚¨éœ€è¦å›ç­”æ˜¯ï¼Œå¹¶æä¾› DeepSpeed é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚è¿™å°†ç”Ÿæˆä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼Œå°†è‡ªåŠ¨ç”¨äºåœ¨æ‰§è¡Œæ—¶æ­£ç¡®è®¾ç½®é»˜è®¤é€‰é¡¹

```py
accelerate launch my_script.py --args_to_my_script
```

ä¾‹å¦‚ï¼Œè¿™æ˜¯å¦‚ä½•åœ¨ NLP ç¤ºä¾‹`examples/by_feature/deepspeed_with_config_support.py`ï¼ˆä»å­˜å‚¨åº“çš„æ ¹ç›®å½•ï¼‰ä¸­ä½¿ç”¨ DeepSpeed é…ç½®æ–‡ä»¶è¿è¡Œçš„ï¼š

**ZeRO Stage-2 DeepSpeed é…ç½®æ–‡ä»¶ç¤ºä¾‹**

```py
compute_environment: LOCAL_MACHINE
deepspeed_config:
 deepspeed_config_file: /home/ubuntu/accelerate/examples/configs/deepspeed_config_templates/zero_stage2_config.json
 zero3_init_flag: true
distributed_type: DEEPSPEED
fsdp_config: {}
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
use_cpu: false
```

ä½¿ç”¨`zero_stage2_config.json`çš„å†…å®¹ä¸ºï¼š

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "weight_decay": "auto",
            "torch_adam": true,
            "adam_w_mode": true
        }
    },
    "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto",
            "total_num_steps": "auto"
        }
    },
    "zero_optimization": {
        "stage": 2,
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": "auto",
        "contiguous_gradients": true
    },
    "gradient_accumulation_steps": 1,
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

```py
accelerate launch examples/by_feature/deepspeed_with_config_support.py \
--config_name "gpt2-large" \
--tokenizer_name "gpt2-large" \
--dataset_name "wikitext" \
--dataset_config_name "wikitext-2-raw-v1" \
--block_size 128 \
--output_dir "./clm/clm_deepspeed_stage2_accelerate" \
--learning_rate 5e-4 \
--per_device_train_batch_size 24 \
--per_device_eval_batch_size 24 \
--num_train_epochs 3 \
--with_tracking \
--report_to "wandb"\
```

**å¸¦ CPU å¸è½½çš„ ZeRO Stage-3 DeepSpeed é…ç½®æ–‡ä»¶ç¤ºä¾‹**

```py
compute_environment: LOCAL_MACHINE
deepspeed_config:
 deepspeed_config_file: /home/ubuntu/accelerate/examples/configs/deepspeed_config_templates/zero_stage3_offload_config.json
 zero3_init_flag: true
distributed_type: DEEPSPEED
fsdp_config: {}
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
use_cpu: false
```

ä½¿ç”¨`zero_stage3_offload_config.json`çš„å†…å®¹ä¸ºï¼š

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "weight_decay": "auto"
        }
    },
    "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto",
            "total_num_steps": "auto"
        }
    },
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "sub_group_size": 1e9,
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": "auto"
    },
    "gradient_accumulation_steps": 1,
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

```py
accelerate launch examples/by_feature/deepspeed_with_config_support.py \
--config_name "gpt2-large" \
--tokenizer_name "gpt2-large" \
--dataset_name "wikitext" \
--dataset_config_name "wikitext-2-raw-v1" \
--block_size 128 \
--output_dir "./clm/clm_deepspeed_stage3_offload_accelerate" \
--learning_rate 5e-4 \
--per_device_train_batch_size 32 \
--per_device_eval_batch_size 32 \
--num_train_epochs 3 \
--with_tracking \
--report_to "wandb"\
```

**ZeRO++é…ç½®ç¤ºä¾‹** æ‚¨å¯ä»¥é€šè¿‡ä½¿ç”¨é€‚å½“çš„é…ç½®å‚æ•°æ¥ä½¿ç”¨ ZeRO++çš„åŠŸèƒ½ã€‚è¯·æ³¨æ„ï¼ŒZeRO++æ˜¯ ZeRO Stage 3 çš„æ‰©å±•ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œæ¥è‡ª[DeepSpeed çš„ ZeRO++æ•™ç¨‹](https://www.deepspeed.ai/tutorials/zeropp/)ï¼š

```py
{
    "zero_optimization": {
        "stage": 3,
        "reduce_bucket_size": "auto",

        "zero_quantized_weights": true,
        "zero_hpz_partition_size": 8,
        "zero_quantized_gradients": true,

        "contiguous_gradients": true,
        "overlap_comm": true
    }
}
```

å¯¹äºåˆ†å±‚åˆ†åŒºï¼Œåˆ†åŒºå¤§å°`zero_hpz_partition_size`ç†æƒ³æƒ…å†µä¸‹åº”è®¾ç½®ä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„ GPU æ•°é‡ã€‚ï¼ˆä¾‹å¦‚ï¼Œä¸Šè¿°é…ç½®æ–‡ä»¶å‡å®šæ¯ä¸ªèŠ‚ç‚¹æœ‰ 8 ä¸ª GPUï¼‰

ä½¿ç”¨ DeepSpeed é…ç½®æ–‡ä»¶æ—¶çš„é‡è¦ä»£ç æ›´æ”¹

1.  DeepSpeed ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[DeepSpeed ä¼˜åŒ–å™¨](https://deepspeed.readthedocs.io/en/latest/optimizers.html)å’Œ[DeepSpeed è°ƒåº¦å™¨](https://deepspeed.readthedocs.io/en/latest/schedulers.html)æ–‡æ¡£ã€‚æˆ‘ä»¬å°†çœ‹åˆ°åœ¨ä½¿ç”¨è¿™äº›æ—¶ä»£ç éœ€è¦çš„æ›´æ”¹ã€‚

    a. DS Optim + DS Schedulerï¼šå½“ DeepSpeed é…ç½®æ–‡ä»¶ä¸­åŒæ—¶å­˜åœ¨`optimizer`å’Œ`scheduler`é”®æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™äº›å°†è¢«ä½¿ç”¨ï¼Œç”¨æˆ·å¿…é¡»ä½¿ç”¨`accelerate.utils.DummyOptim`å’Œ`accelerate.utils.DummyScheduler`æ¥æ›¿æ¢ä»–ä»¬ä»£ç ä¸­çš„ PyTorch/è‡ªå®šä¹‰ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ã€‚ä»¥ä¸‹æ˜¯`examples/by_feature/deepspeed_with_config_support.py`ä¸­æ˜¾ç¤ºçš„ç‰‡æ®µï¼š

    ```py
     # Creates Dummy Optimizer if `optimizer` was specified in the config file else creates Adam Optimizer
     optimizer_cls = (
         torch.optim.AdamW
         if accelerator.state.deepspeed_plugin is None
         or "optimizer" not in accelerator.state.deepspeed_plugin.deepspeed_config
         else DummyOptim
     )
     optimizer = optimizer_cls(optimizer_grouped_parameters, lr=args.learning_rate)

     # Creates Dummy Scheduler if `scheduler` was specified in the config file else creates `args.lr_scheduler_type` Scheduler
     if (
         accelerator.state.deepspeed_plugin is None
         or "scheduler" not in accelerator.state.deepspeed_plugin.deepspeed_config
     ):
         lr_scheduler = get_scheduler(
             name=args.lr_scheduler_type,
             optimizer=optimizer,
             num_warmup_steps=args.num_warmup_steps,
             num_training_steps=args.max_train_steps,
         )
     else:
         lr_scheduler = DummyScheduler(
             optimizer, total_num_steps=args.max_train_steps, warmup_num_steps=args.num_warmup_steps
         )
    ```

    b. Custom Optim + Custom Schedulerï¼šå½“ DeepSpeed é…ç½®æ–‡ä»¶ä¸­`optimizer`å’Œ`scheduler`é”®éƒ½ä¸å­˜åœ¨æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”¨æˆ·ä¸éœ€è¦è¿›è¡Œä»»ä½•ä»£ç æ›´æ”¹ï¼Œè¿™æ˜¯ä½¿ç”¨ DeepSpeed æ’ä»¶è¿›è¡Œé›†æˆæ—¶çš„æƒ…å†µã€‚åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¦‚æœ DeepSpeed é…ç½®æ–‡ä»¶ä¸­ä¸å­˜åœ¨`optimizer`å’Œ`scheduler`é”®ï¼Œåˆ™ä»£ç ä¿æŒä¸å˜ã€‚

    c. Custom Optim + DS Schedulerï¼šå½“ DeepSpeed é…ç½®æ–‡ä»¶ä¸­åªæœ‰`scheduler`é”®å­˜åœ¨æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”¨æˆ·å¿…é¡»ä½¿ç”¨`accelerate.utils.DummyScheduler`æ¥æ›¿æ¢ä»–ä»¬ä»£ç ä¸­çš„ PyTorch/è‡ªå®šä¹‰è°ƒåº¦å™¨ã€‚

    d. DS Optim + Custom Schedulerï¼šå½“ DeepSpeed é…ç½®æ–‡ä»¶ä¸­åªæœ‰`optimizer`é”®å­˜åœ¨æ—¶ã€‚è¿™å°†å¯¼è‡´é”™è¯¯ï¼Œå› ä¸ºåªæœ‰åœ¨ä½¿ç”¨ DS Optim æ—¶æ‰èƒ½ä½¿ç”¨ DS Schedulerã€‚

1.  è¯·æ³¨æ„ä¸Šè¿°ç¤ºä¾‹ DeepSpeed é…ç½®æ–‡ä»¶ä¸­çš„`auto`å€¼ã€‚è¿™äº›å€¼ç”±`prepare`æ–¹æ³•æ ¹æ®æä¾›ç»™`prepare`æ–¹æ³•çš„æ¨¡å‹ã€æ•°æ®åŠ è½½å™¨ã€è™šæ‹Ÿä¼˜åŒ–å™¨å’Œè™šæ‹Ÿè°ƒåº¦å™¨è‡ªåŠ¨å¤„ç†ã€‚ä¸Šè¿°ç¤ºä¾‹ä¸­æŒ‡å®šçš„`auto`å­—æ®µç”±`prepare`æ–¹æ³•å¤„ç†ï¼Œå…¶ä½™å­—æ®µå¿…é¡»ç”±ç”¨æˆ·æ˜¾å¼æŒ‡å®šã€‚

`auto`å€¼çš„è®¡ç®—å¦‚ä¸‹ï¼š

+   `reduce_bucket_size`: `hidden_size * hidden_size`

+   `stage3_prefetch_bucket_size`: `0.9 * hidden_size * hidden_size`

+   `stage3_param_persistence_threshold`: `10 * hidden_size`

ä¸ºäº†ä½¿è¿™ 3 ä¸ªé…ç½®æ¡ç›®çš„`auto`åŠŸèƒ½æ­£å¸¸å·¥ä½œ - Accelerate å°†ä½¿ç”¨`model.config.hidden_size`æˆ–`max(model.config.hidden_sizes)`ä½œä¸º`hidden_size`ã€‚å¦‚æœè¿™ä¸¤è€…éƒ½ä¸å¯ç”¨ï¼Œå¯åŠ¨å°†å¤±è´¥ï¼Œæ‚¨å°†ä¸å¾—ä¸æ‰‹åŠ¨è®¾ç½®è¿™ 3 ä¸ªé…ç½®æ¡ç›®ã€‚è¯·è®°ä½ï¼Œå‰ä¸¤ä¸ªé…ç½®æ¡ç›®æ˜¯é€šä¿¡ç¼“å†²åŒº - å®ƒä»¬è¶Šå¤§ï¼Œé€šä¿¡æ•ˆç‡å°±è¶Šé«˜ï¼Œå®ƒä»¬è¶Šå¤§ï¼ŒGPU å†…å­˜æ¶ˆè€—å°±è¶Šå¤§ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªå¯è°ƒæ•´çš„æ€§èƒ½æƒè¡¡ã€‚

**ä½¿ç”¨ DeepSpeed é…ç½®æ–‡ä»¶æ—¶éœ€è¦æ³¨æ„çš„äº‹é¡¹**

ä»¥ä¸‹æ˜¯åœ¨ä¸åŒåœºæ™¯ä¸­ä½¿ç”¨`deepspeed_config_file`çš„ç¤ºä¾‹è„šæœ¬ã€‚

ä»£ç `test.py`ï¼š

```py
from accelerate import Accelerator
from accelerate.state import AcceleratorState

def main():
    accelerator = Accelerator()
    accelerator.print(f"{AcceleratorState()}")

if __name__ == "__main__":
    main()
```

**åœºæ™¯ 1**ï¼šæ‰‹åŠ¨ç¯¡æ”¹çš„å¸¦æœ‰`deepspeed_config_file`çš„ accelerate é…ç½®æ–‡ä»¶ä»¥åŠå…¶ä»–æ¡ç›®ã€‚

1.  `accelerate`é…ç½®çš„å†…å®¹ï¼š

```py
command_file: null
commands: null
compute_environment: LOCAL_MACHINE
deepspeed_config:
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  offload_optimizer_device: 'cpu'
  offload_param_device: 'cpu'
  zero3_init_flag: true
  zero3_save_16bit_model: true
  zero_stage: 3
  deepspeed_config_file: 'ds_config.json'
distributed_type: DEEPSPEED
downcast_bf16: 'no'
dynamo_backend: 'NO'
fsdp_config: {}
gpu_ids: null
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
megatron_lm_config: {}
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_name: null
tpu_zone: null
use_cpu: false
```

1.  `ds_config.json`ï¼š

```py
{
    "bf16": {
        "enabled": true
    },
    "zero_optimization": {
        "stage": 3,
        "stage3_gather_16bit_weights_on_model_save": false,
        "offload_optimizer": {
            "device": "none"
        },
        "offload_param": {
            "device": "none"
        }
    },
    "gradient_clipping": 1.0,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "gradient_accumulation_steps": 10,
    "steps_per_print": 2000000
}
```

1.  è¿è¡Œ`accelerate launch test.py`çš„è¾“å‡ºï¼š

```py
ValueError: When using `deepspeed_config_file`, the following accelerate config variables will be ignored:
['gradient_accumulation_steps', 'gradient_clipping', 'zero_stage', 'offload_optimizer_device', 'offload_param_device',
'zero3_save_16bit_model', 'mixed_precision'].
Please specify them appropriately in the DeepSpeed config file.
If you are using an accelerate config file, remove others config variables mentioned in the above specified list.
The easiest method is to create a new config following the questionnaire via `accelerate config`.
It will only ask for the necessary config variables when using `deepspeed_config_file`.
```

**åœºæ™¯ 2**ï¼šä½¿ç”¨é”™è¯¯çš„è§£å†³æ–¹æ¡ˆåˆ›å»ºæ–°çš„ accelerate é…ç½®ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦ç°åœ¨ä¸ä¼šæŠ›å‡ºä»»ä½•æ­§ä¹‰é”™è¯¯ã€‚

1.  è¿è¡Œ`accelerate config`ï¼š

```py
$ accelerate config
-------------------------------------------------------------------------------------------------------------------------------
In which compute environment are you running?
This machine
-------------------------------------------------------------------------------------------------------------------------------
Which type of machine are you using?
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]:
Do you wish to optimize your script with torch dynamo?[yes/NO]:
Do you want to use DeepSpeed? [yes/NO]: yes
Do you want to specify a json file to a DeepSpeed config? [yes/NO]: yes
Please enter the path to the json DeepSpeed config file: ds_config.json
Do you want to enable `deepspeed.zero.Init` when using ZeRO Stage-3 for constructing massive models? [yes/NO]: yes
How many GPU(s) should be used for distributed training? [1]:4
accelerate configuration saved at ds_config_sample.yaml
```

1.  `accelerate`é…ç½®çš„å†…å®¹ï¼š

```py
compute_environment: LOCAL_MACHINE
deepspeed_config:
  deepspeed_config_file: ds_config.json
  zero3_init_flag: true
distributed_type: DEEPSPEED
downcast_bf16: 'no'
dynamo_backend: 'NO'
fsdp_config: {}
machine_rank: 0
main_training_function: main
megatron_lm_config: {}
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
use_cpu: false
```

1.  è¿è¡Œ`accelerate launch test.py`çš„è¾“å‡ºï¼š

```py
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0
Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'stage3_gather_16bit_weights_on_model_save': False, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}}, 'gradient_clipping': 1.0, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 10, 'steps_per_print': inf, 'fp16': {'enabled': False}}
```

**åœºæ™¯ 3**ï¼šåœ¨ DeepSpeed é…ç½®æ–‡ä»¶ä¸­å°†ä¸ DeepSpeed ç›¸å…³çš„`accelerate launch`å‘½ä»¤å‚æ•°è®¾ç½®ä¸º`"auto"`ï¼Œå¹¶æ£€æŸ¥äº‹æƒ…æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œã€‚

1.  ä½¿ç”¨`"auto"`ä¸º`accelerate launch` DeepSpeed å‘½ä»¤å‚æ•°åˆ›å»ºæ–°çš„`ds_config.json`ï¼š

```py
{
    "bf16": {
        "enabled": "auto"
    },
    "zero_optimization": {
        "stage": "auto",
        "stage3_gather_16bit_weights_on_model_save": "auto",
        "offload_optimizer": {
            "device": "auto"
        },
        "offload_param": {
            "device": "auto"
        }
    },
    "gradient_clipping": "auto",
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "gradient_accumulation_steps": "auto",
    "steps_per_print": 2000000
}
```

1.  è¿è¡Œ`accelerate launch --mixed_precision="fp16" --zero_stage=3 --gradient_accumulation_steps=5 --gradient_clipping=1.0 --offload_param_device="cpu" --offload_optimizer_device="nvme" --zero3_save_16bit_model="true" test.py`çš„è¾“å‡ºï¼š

```py
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0
Mixed precision type: fp16
ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'stage3_gather_16bit_weights_on_model_save': True, 'offload_optimizer': {'device': 'nvme'}, 'offload_param': {'device': 'cpu'}}, 'gradient_clipping': 1.0, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 5, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}
```

**æ³¨æ„**ï¼š

1.  å‰©ä½™çš„`"auto"`å€¼åœ¨`accelerator.prepare()`è°ƒç”¨ä¸­å¤„ç†ï¼Œå¦‚åœ¨ä½¿ç”¨ DeepSpeed é…ç½®æ–‡ä»¶æ—¶çš„é‡è¦ä»£ç æ›´æ”¹çš„ç¬¬ 2 ç‚¹ä¸­æ‰€è§£é‡Šçš„ã€‚

1.  åªæœ‰å½“`gradient_accumulation_steps`ä¸º`auto`æ—¶ï¼Œåˆ›å»º`Accelerator`å¯¹è±¡æ—¶é€šè¿‡`Accelerator(gradient_accumulation_steps=k)`ä¼ é€’çš„å€¼æ‰ä¼šè¢«ä½¿ç”¨ã€‚ä½¿ç”¨ DeepSpeed æ’ä»¶æ—¶ï¼Œå°†ä½¿ç”¨å…¶ä¸­çš„å€¼ï¼Œå¹¶ä¸”å®ƒå°†è¦†ç›–åˆ›å»º Accelerator å¯¹è±¡æ—¶ä¼ é€’çš„å€¼ã€‚

## ä¿å­˜å’ŒåŠ è½½

1.  å¯¹äº ZeRO Stage-1 å’Œ Stage-2ï¼Œæ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½ä¿æŒä¸å˜ã€‚

1.  åœ¨ ZeRO Stage-3 ä¸‹ï¼Œ`state_dict`ä»…åŒ…å«å ä½ç¬¦ï¼Œå› ä¸ºæ¨¡å‹æƒé‡è¢«åˆ†åŒºåˆ°å¤šä¸ª GPU ä¸Šã€‚ZeRO Stage-3 æœ‰ 2 ä¸ªé€‰é¡¹ï¼š

    a. å°†æ•´ä¸ª 16 ä½æ¨¡å‹æƒé‡ä¿å­˜ä»¥ä¾¿ä»¥åç›´æ¥åŠ è½½ï¼Œä½¿ç”¨`model.load_state_dict(torch.load(pytorch_model.bin))`ã€‚ä¸ºæ­¤ï¼Œåœ¨ DeepSpeed é…ç½®æ–‡ä»¶ä¸­å°†`zero_optimization.stage3_gather_16bit_weights_on_model_save`è®¾ç½®ä¸º Trueï¼Œæˆ–è€…åœ¨ DeepSpeed æ’ä»¶ä¸­å°†`zero3_save_16bit_model`è®¾ç½®ä¸º Trueã€‚**è¯·æ³¨æ„ï¼Œæ­¤é€‰é¡¹è¦æ±‚åœ¨ä¸€ä¸ª GPU ä¸Šåˆå¹¶æƒé‡ï¼Œå¯èƒ½ä¼šå¾ˆæ…¢ä¸”å ç”¨å†…å­˜ï¼Œå› æ­¤åªåœ¨éœ€è¦æ—¶ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚**ä»¥ä¸‹æ˜¯`examples/by_feature/deepspeed_with_config_support.py`ä¸­æ˜¾ç¤ºæ­¤åŠŸèƒ½çš„ç‰‡æ®µï¼š

    ```py
    unwrapped_model = accelerator.unwrap_model(model)

    # New Code #
    # Saves the whole/unpartitioned fp16 model when in ZeRO Stage-3 to the output directory if
    # `stage3_gather_16bit_weights_on_model_save` is True in DeepSpeed Config file or
    # `zero3_save_16bit_model` is True in DeepSpeed Plugin.
    # For Zero Stages 1 and 2, models are saved as usual in the output directory.
    # The model name saved is `pytorch_model.bin`
    unwrapped_model.save_pretrained(
        args.output_dir,
        is_main_process=accelerator.is_main_process,
        save_function=accelerator.save,
        state_dict=accelerator.get_state_dict(model),
    )
    ```

    b. è¦è·å– 32 ä½æƒé‡ï¼Œé¦–å…ˆä½¿ç”¨`model.save_checkpoint()`ä¿å­˜æ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯`examples/by_feature/deepspeed_with_config_support.py`ä¸­æ˜¾ç¤ºæ­¤åŠŸèƒ½çš„ç‰‡æ®µï¼š

    ```py
    success = model.save_checkpoint(PATH, ckpt_id, checkpoint_state_dict)
    status_msg = "checkpointing: PATH={}, ckpt_id={}".format(PATH, ckpt_id)
    if success:
        logging.info(f"Success {status_msg}")
    else:
        logging.warning(f"Failure {status_msg}")
    ```

    è¿™å°†åœ¨æ£€æŸ¥ç‚¹ç›®å½•ä¸­åˆ›å»º ZeRO æ¨¡å‹å’Œä¼˜åŒ–å™¨åˆ†åŒºï¼Œä»¥åŠ`zero_to_fp32.py`è„šæœ¬ã€‚æ‚¨å¯ä»¥ä½¿ç”¨æ­¤è„šæœ¬è¿›è¡Œç¦»çº¿åˆå¹¶ã€‚å®ƒä¸éœ€è¦é…ç½®æ–‡ä»¶æˆ– GPUã€‚ä»¥ä¸‹æ˜¯å…¶ç”¨æ³•ç¤ºä¾‹ï¼š

    ```py
    $ cd /path/to/checkpoint_dir
    $ ./zero_to_fp32.py . pytorch_model.bin
    Processing zero checkpoint at global_step1
    Detected checkpoint of type zero stage 3, world_size: 2
    Saving fp32 state dict to pytorch_model.bin (total_numel=60506624)
    ```

    è¦è·å¾—ç”¨äºä¿å­˜/æ¨ç†çš„ 32 ä½æ¨¡å‹ï¼Œæ‚¨å¯ä»¥æ‰§è¡Œï¼š

    ```py
    from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint

    unwrapped_model = accelerator.unwrap_model(model)
    fp32_model = load_state_dict_from_zero_checkpoint(unwrapped_model, checkpoint_dir)
    ```

    å¦‚æœæ‚¨åªå¯¹`state_dict`æ„Ÿå…´è¶£ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

    ```py
    from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint

    state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir)
    ```

    è¯·æ³¨æ„ï¼Œæ‰€æœ‰è¿™äº›åŠŸèƒ½éœ€è¦æœ€ç»ˆæ£€æŸ¥ç‚¹å¤§å°çš„å¤§çº¦ 2 å€å†…å­˜ï¼ˆé€šç”¨ RAMï¼‰ã€‚

## ZeRO æ¨ç†

DeepSpeed ZeRO æ¨ç†æ”¯æŒä½¿ç”¨ ZeRO-Infinity çš„ ZeRO é˜¶æ®µ 3ã€‚å®ƒä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ ZeRO åè®®ï¼Œä½†ä¸ä½¿ç”¨ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦ç¨‹åºï¼Œåªæœ‰é˜¶æ®µ 3 ç›¸å…³ã€‚é€šè¿‡åŠ é€Ÿé›†æˆï¼Œæ‚¨åªéœ€è¦å‡†å¤‡å¦‚ä¸‹æ‰€ç¤ºçš„æ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨ï¼š

```py
model, eval_dataloader = accelerator.prepare(model, eval_dataloader)
```

## éœ€è¦æ³¨æ„çš„ä¸€äº›æ³¨æ„äº‹é¡¹

1.  å½“å‰é›†æˆä¸æ”¯æŒ DeepSpeed çš„ç®¡é“å¹¶è¡Œæ€§ã€‚

1.  å½“å‰é›†æˆä¸æ”¯æŒ`mpu`ï¼Œé™åˆ¶äº†åœ¨ Megatron-LM ä¸­æ”¯æŒçš„å¼ é‡å¹¶è¡Œæ€§ã€‚

1.  å½“å‰é›†æˆä¸æ”¯æŒå¤šä¸ªæ¨¡å‹ã€‚

## DeepSpeed èµ„æº

æœ‰å…³ä¸ deepspeed ç›¸å…³çš„å†…éƒ¨æ–‡æ¡£å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ã€‚

+   [é¡¹ç›®çš„ github](https://github.com/microsoft/deepspeed)

+   [ä½¿ç”¨æ–‡æ¡£](https://www.deepspeed.ai/getting-started/)

+   [API æ–‡æ¡£](https://deepspeed.readthedocs.io/en/latest/index.html)

+   [åšå®¢æ–‡ç« ](https://www.microsoft.com/en-us/research/search/?q=deepspeed)

è®ºæ–‡:

+   [ZeROï¼šæœç€è®­ç»ƒä¸‡äº¿å‚æ•°æ¨¡å‹çš„å†…å­˜ä¼˜åŒ–](https://arxiv.org/abs/1910.02054)

+   [ZeRO-Offloadï¼šæ°‘ä¸»åŒ–äº¿çº§è§„æ¨¡æ¨¡å‹è®­ç»ƒ](https://arxiv.org/abs/2101.06840)

+   [ZeRO-Infinityï¼šæ‰“ç ´æç«¯è§„æ¨¡æ·±åº¦å­¦ä¹ çš„ GPU å†…å­˜å£](https://arxiv.org/abs/2104.07857)

+   [ZeRO++ï¼šç”¨äºå·¨å‹æ¨¡å‹è®­ç»ƒçš„æå…¶é«˜æ•ˆçš„é›†ä½“é€šä¿¡](https://arxiv.org/abs/2306.10209)

æœ€åï¼Œè¯·è®°ä½ï¼ŒğŸ¤— `Accelerate` åªé›†æˆäº† DeepSpeedï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä½¿ç”¨ DeepSpeed æ—¶é‡åˆ°ä»»ä½•é—®é¢˜æˆ–ç–‘é—®ï¼Œè¯·åœ¨[DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed/issues)ä¸Šæäº¤é—®é¢˜ã€‚
