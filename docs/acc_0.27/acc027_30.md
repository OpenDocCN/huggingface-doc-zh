# 🤗 Accelerate 的内部机制

> 原文链接：[`huggingface.co/docs/accelerate/concept_guides/internal_mechanism`](https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism)

在内部，🤗 Accelerate 首先分析启动脚本的环境，以确定使用了哪种类型的分布式设置，有多少个不同的进程以及当前脚本在哪个进程中。所有这些信息都存储在`~AcceleratorState`中。

这个类在您第一次实例化~Accelerator 时初始化，以及执行任何特定于您的分布式设置需要的初始化。然后，它的状态通过所有 AcceleratorState 实例唯一共享。（也可以使用 PartialState 来完成相同的操作，它是一个更简化的版本）

然后，在调用 prepare()时，库：

+   将您的模型包装在适用于分布式设置的容器中，

+   将您的优化器包装在 AcceleratedOptimizer 中，

+   将您的调度程序包装在 AcceleratedScheduler 中

+   在 DataLoaderShard 或 DataLoaderDispatcher 中创建您的数据加载器的新版本

虽然模型、优化器和调度程序只是简单的包装器，但数据加载器是重新创建的。这主要是因为 PyTorch 不允许用户在创建后更改数据加载器的`batch_sampler`，而库通过将`batch_sampler`更改为每隔其他`num_processes`批次（如果启用）来处理数据在进程之间的分片。

DataLoaderShard 子类`DataLoader`以添加以下功能：

+   它在每次新迭代时同步所有进程的适当随机数生成器，以确保任何随机化（如洗牌）在所有进程中都以完全相同的方式进行。

+   在产生批次之前将批次放在正确的设备上（除非您选择了`device_placement=True`）。

DataLoaderDispatcher 子类与 DataLoaderShard 不同之处在于，当通过`DataLoader`迭代时，数据都是从进程 0 开始，然后再分割并发送到每个进程，而不是在数据集级别发生。

默认情况下，随机数生成器同步将同步：

+   给定采样器（如 PyTorch 的`RandomSampler`）的`generator`属性，适用于 PyTorch >= 1.6

+   PyTorch <=1.5.1 中的主随机数生成器

您可以通过主 Accelerator 的`rng_types`参数选择要与之同步的随机数生成器。在 PyTorch >= 1.6 中，建议依赖于本地`generator`，以避免在所有进程中设置相同的种子。

主要 torch（或 CUDA 或 XLA）随机数生成器的同步将影响数据集中可能存在的任何其他随机现象（如随机数据增强），因为所有进程将从 torch 随机模块中获得相同的随机数（因此如果由 torch 控制，则将应用相同的随机数据增强）。

您自定义采样器、批量采样器或可迭代数据集的随机化部分应该使用本地的`torch.Generator`对象来完成（在 PyTorch >= 1.6 中），可以参考传统的`RandomSampler`作为示例。

有关内部详细信息，请参阅内部页面。
