# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers.js/custom_usage`](https://huggingface.co/docs/transformers.js/custom_usage)

é»˜è®¤æƒ…å†µä¸‹ï¼ŒTransformers.js ä½¿ç”¨[æ‰˜ç®¡çš„é¢„è®­ç»ƒæ¨¡å‹](https://huggingface.co/models?library=transformers.js)å’Œ[é¢„ç¼–è¯‘çš„ WASM äºŒè¿›åˆ¶æ–‡ä»¶](https://cdn.jsdelivr.net/npm/@xenova/transformers@2.15.0/dist/)ï¼Œåº”è¯¥å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼è‡ªå®šä¹‰ï¼š

### è®¾ç½®

```py
import { env } from '@xenova/transformers';

// Specify a custom location for models (defaults to '/models/').
env.localModelPath = '/path/to/models/';

// Disable the loading of remote models from the Hugging Face Hub:
env.allowRemoteModels = false;

// Set location of .wasm files. Defaults to use a CDN.
env.backends.onnx.wasm.wasmPaths = '/path/to/files/';
```

è¦æŸ¥çœ‹æ‰€æœ‰å¯ç”¨è®¾ç½®çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·æŸ¥çœ‹ API å‚è€ƒã€‚

### å°†æ‚¨çš„æ¨¡å‹è½¬æ¢ä¸º ONNX

æˆ‘ä»¬å»ºè®®ä½¿ç”¨æˆ‘ä»¬çš„[è½¬æ¢è„šæœ¬](https://github.com/xenova/transformers.js/blob/main/scripts/convert.py)æ¥å°†æ‚¨çš„ PyTorchã€TensorFlow æˆ– JAX æ¨¡å‹ä¸€æ¬¡æ€§è½¬æ¢ä¸º ONNXã€‚åœ¨å¹•åï¼Œå®ƒä½¿ç”¨[ğŸ¤— Optimum](https://huggingface.co/docs/optimum)æ¥æ‰§è¡Œæ¨¡å‹çš„è½¬æ¢å’Œé‡åŒ–ã€‚

```py
python -m scripts.convert --quantize --model_id <model_name_or_path>
```

ä¾‹å¦‚ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è½¬æ¢å’Œé‡åŒ–[bert-base-uncased](https://huggingface.co/bert-base-uncased)ï¼š

```py
python -m scripts.convert --quantize --model_id bert-base-uncased
```

è¿™å°†ä¿å­˜ä»¥ä¸‹æ–‡ä»¶åˆ°`./models/`ï¼š

```py
bert-base-uncased/
â”œâ”€â”€ config.json
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â””â”€â”€ onnx/
    â”œâ”€â”€ model.onnx
    â””â”€â”€ model_quantized.onnx
```

è¦æŸ¥çœ‹æ”¯æŒçš„æ‰€æœ‰æ¶æ„çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚é˜…[Optimum æ–‡æ¡£](https://huggingface.co/docs/optimum/main/en/exporters/onnx/overview)ã€‚
