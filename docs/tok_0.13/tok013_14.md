# 模型

> 原始文本：[`huggingface.co/docs/tokenizers/api/models`](https://huggingface.co/docs/tokenizers/api/models)

PythonRustNode

## BPE

### `class tokenizers.models.BPE`

```py
( vocab = None merges = None cache_capacity = None dropout = None unk_token = None continuing_subword_prefix = None end_of_word_suffix = None fuse_unk = None byte_fallback = False )
```

参数

+   `vocab` (`Dict[str, int]`, *可选*) — 一个字符串键和其 ID 的字典 `{"am": 0,...}`

+   `merges` (`List[Tuple[str, str]]`, *可选*) — 一对标记（`Tuple[str, str]`）的列表 `[("a", "b"),...]`

+   `cache_capacity` (`int`, *可选*) — BPE 缓存可以包含的单词数。缓存通过保留一定数量的单词的合并操作结果来加速过程。

+   `dropout` (`float`, *可选*) — 介于 0 和 1 之间的浮点数，表示要使用的 BPE dropout。

+   `unk_token` (`str`, *可选*) — 模型要使用的未知标记。

+   `continuing_subword_prefix` (`str`, *可选*) — 要附加到不表示单词开头的子词单元的前缀。

+   `end_of_word_suffix` (`str`, *可选*) — 要附加到表示单词结尾的子词单元的后缀。

+   `fuse_unk` (`bool`, *可选*) — 是否将任何后续未知标记融合为一个

+   `byte_fallback` (`bool`, *可选*) — 是否使用 spm 字节回退技巧（默认为 False）

BPE（Byte-Pair Encoding）算法的实现

#### `from_file`

```py
( vocab merge **kwargs ) → BPE
```

参数

+   `vocab` (`str`) — 指向 `vocab.json` 文件的路径

+   `merges` (`str`) — 指向 `merges.txt` 文件的路径

返回

BPE

从这些文件加载的 BPE 实例

从给定文件实例化一个 BPE 模型。

此方法大致相当于执行以下操作：

```py
vocab, merges = BPE.read_file(vocab_filename, merges_filename)
bpe = BPE(vocab, merges)
```

如果不需要保留`vocab, merges`值，此方法比手动调用`read_file()`来初始化 BPE 更为优化。

#### `read_file`

```py
( vocab merges ) → A Tuple with the vocab and the merges
```

参数

+   `vocab` (`str`) — 指向 `vocab.json` 文件的路径

+   `merges` (`str`) — 指向 `merges.txt` 文件的路径

返回

一个包含词汇表和合并的`Tuple`

加载到内存中的词汇表和合并

读取一个`vocab.json`和一个`merges.txt`文件

此方法提供了一种读取和解析这些文件内容的方式，返回相关的数据结构。如果要从内存实例化一些 BPE 模型，此方法会为您提供标准文件的预期输入。

## 模型

### `class tokenizers.models.Model`

```py
( )
```

所有模型的基类

该模型代表实际的标记化算法。这部分将包含和管理学习到的词汇表。

此类不能直接构造。请使用其中一个具体模型。

#### `get_trainer`

```py
( ) → Trainer
```

返回

`Trainer`

用于训练此模型的 Trainer

获取相关的`Trainer`

检索与此 Model 相关联的`Trainer`。

#### `id_to_token`

```py
( id ) → str
```

参数

+   `id` (`int`) — 要转换为标记的 ID

返回

`str`

与 ID 相关联的标记

获取与 ID 相关联的标记

#### `save`

```py
( folder prefix ) → List[str]
```

参数

+   `folder` (`str`) — 要保存各种文件的目标文件夹的路径

+   `prefix` (`str`, *可选*) — 一个可选的前缀，用于给每个文件名加前缀

返回

`List[str]`

保存文件的列表

保存当前模型

在给定文件夹中保存当前模型，使用给定的前缀创建各种文件。如果该文件夹中已经存在同名文件，将被覆盖。

#### `token_to_id`

```py
( tokens ) → int
```

参数

+   `token` (`str`) — 要转换为 ID 的标记

返回

`int`

与标记相关联的 ID

获取与标记相关联的 ID

#### `tokenize`

```py
( sequence ) → A List of Token
```

参数

+   `sequence` (`str`) — 要标记化的序列

返回

一个`Token`的`List`

生成的标记

对序列进行标记化

## Unigram

### `class tokenizers.models.Unigram`

```py
( vocab unk_id byte_fallback )
```

参数

+   `vocab` (`List[Tuple[str, float]]`, *可选*, *可选*) — 一个词汇项和其相对分数的列表 [(“am”, -0.2442),…]

Unigram 算法的实现

## WordLevel

### `class tokenizers.models.WordLevel`

```py
( vocab unk_token )
```

参数

+   `vocab` (`str`, *optional*) — 一个字符串键和它们的 id 的字典 `{"am": 0,...}`

+   `unk_token` (`str`, *optional*) — 模型使用的未知标记。

WordLevel 算法的实现

基于将标记映射到相应 id 的最简单的分词器模型。

#### `from_file`

```py
( vocab unk_token ) → WordLevel
```

参数

+   `vocab` (`str`) — 指向 `vocab.json` 文件的路径

返回

WordLevel

从文件加载的 WordLevel 实例

从给定文件实例化一个 WordLevel 模型

这种方法大致相当于：

```py
vocab = WordLevel.read_file(vocab_filename)
wordlevel = WordLevel(vocab)
```

如果您不需要保留 `vocab` 值，这种方法比手动调用 `read_file()` 来初始化一个 WordLevel 更为优化。

#### `read_file`

```py
( vocab ) → Dict[str, int]
```

参数

+   `vocab` (`str`) — 指向 `vocab.json` 文件的路径

返回

`Dict[str, int]`

作为 `dict` 的词汇表

读取一个 `vocab.json`

这种方法提供了一种读取和解析词汇文件内容的方式，返回相关的数据结构。如果您想要从内存中实例化一些 WordLevel 模型，这种方法会给您标准文件的预期输入。

## WordPiece

### `class tokenizers.models.WordPiece`

```py
( vocab unk_token max_input_chars_per_word )
```

参数

+   `vocab` (`Dict[str, int]`, *optional*) — 一个字符串键和它们的 id 的字典 `{"am": 0,...}`

+   `unk_token` (`str`, *optional*) — 模型使用的未知标记。

+   `max_input_chars_per_word` (`int`, *optional*) — 单词中允许的最大字符数。

WordPiece 算法的实现

#### `from_file`

```py
( vocab **kwargs ) → WordPiece
```

参数

+   `vocab` (`str`) — 指向 `vocab.txt` 文件的路径

返回

WordPiece

从文件加载的 WordPiece 实例

从给定文件实例化一个 WordPiece 模型

这种方法大致相当于：

```py
vocab = WordPiece.read_file(vocab_filename)
wordpiece = WordPiece(vocab)
```

如果您不需要保留 `vocab` 值，这种方法比手动调用 `read_file()` 来初始化一个 WordPiece 更为优化。

#### `read_file`

```py
( vocab ) → Dict[str, int]
```

参数

+   `vocab` (`str`) — 指向 `vocab.txt` 文件的路径

返回

`Dict[str, int]`

作为 `dict` 的词汇表

读取一个 `vocab.txt` 文件

这种方法提供了一种读取和解析标准 *vocab.txt* 文件内容的方式，该文件由 WordPiece 模型使用，返回相关的数据结构。如果您想要从内存中实例化一些 WordPiece 模型，这种方法会给您标准文件的预期输入。
