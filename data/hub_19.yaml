- en: Widgets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°éƒ¨ä»¶
- en: 'Original text: [https://huggingface.co/docs/hub/models-widgets](https://huggingface.co/docs/hub/models-widgets)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/hub/models-widgets](https://huggingface.co/docs/hub/models-widgets)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Whatâ€™s a widget?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯å°éƒ¨ä»¶ï¼Ÿ
- en: Many model repos have a widget that allows anyone to run inferences directly
    in the browser!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šæ¨¡å‹å­˜å‚¨åº“éƒ½æœ‰ä¸€ä¸ªå°éƒ¨ä»¶ï¼Œå…è®¸ä»»ä½•äººç›´æ¥åœ¨æµè§ˆå™¨ä¸­è¿è¡Œæ¨ç†ï¼
- en: 'Here are some examples:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š
- en: '[Named Entity Recognition](https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London)
    using [spaCy](https://spacy.io/).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å‘½åå®ä½“è¯†åˆ«](https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London)
    ä½¿ç”¨[spaCy](https://spacy.io/)ã€‚'
- en: '[Image Classification](https://huggingface.co/google/vit-base-patch16-224)
    using [ğŸ¤— Transformers](https://github.com/huggingface/transformers)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å›¾åƒåˆ†ç±»](https://huggingface.co/google/vit-base-patch16-224) ä½¿ç”¨[ğŸ¤— Transformers](https://github.com/huggingface/transformers)'
- en: '[Text to Speech](https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train)
    using [ESPnet](https://github.com/espnet/espnet).'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ–‡æœ¬è½¬è¯­éŸ³](https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train)
    ä½¿ç”¨[ESPnet](https://github.com/espnet/espnet)ã€‚'
- en: '[Sentence Similarity](https://huggingface.co/osanseviero/full-sentence-distillroberta3)
    using [Sentence Transformers](https://github.com/UKPLab/sentence-transformers).'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å¥å­ç›¸ä¼¼åº¦](https://huggingface.co/osanseviero/full-sentence-distillroberta3) ä½¿ç”¨[å¥å­è½¬æ¢å™¨](https://github.com/UKPLab/sentence-transformers)ã€‚'
- en: You can try out all the widgets [here](https://huggingface-widgets.netlify.app/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface-widgets.netlify.app/)å°è¯•æ‰€æœ‰å°éƒ¨ä»¶ã€‚
- en: Enabling a widget
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯ç”¨å°éƒ¨ä»¶
- en: A widget is automatically created for your model when you upload it to the Hub.
    To determine which pipeline and widget to display (`text-classification`, `token-classification`,
    `translation`, etc.), we analyze information in the repo, such as the metadata
    provided in the model card and configuration files. This information is mapped
    to a single `pipeline_tag`. We choose to expose **only one** widget per model
    for simplicity.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨å°†æ¨¡å‹ä¸Šä¼ åˆ°Hubæ—¶ï¼Œå°†è‡ªåŠ¨ä¸ºæ‚¨çš„æ¨¡å‹åˆ›å»ºä¸€ä¸ªå°éƒ¨ä»¶ã€‚ä¸ºäº†ç¡®å®šæ˜¾ç¤ºå“ªä¸ªç®¡é“å’Œå°éƒ¨ä»¶ï¼ˆ`æ–‡æœ¬åˆ†ç±»`ï¼Œ`æ ‡è®°åˆ†ç±»`ï¼Œ`ç¿»è¯‘`ç­‰ï¼‰ï¼Œæˆ‘ä»¬ä¼šåˆ†æå­˜å‚¨åº“ä¸­æä¾›çš„å…ƒæ•°æ®å’Œé…ç½®æ–‡ä»¶ç­‰ä¿¡æ¯ã€‚è¿™äº›ä¿¡æ¯è¢«æ˜ å°„åˆ°ä¸€ä¸ªå•ä¸€çš„`pipeline_tag`ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬é€‰æ‹©**ä»…æ˜¾ç¤ºä¸€ä¸ª**æ¨¡å‹çš„å°éƒ¨ä»¶ã€‚
- en: 'For most use cases, we determine the model type from the tags. For example,
    if there is `tag: text-classification` in the [model card metadata](./model-cards),
    the inferred `pipeline_tag` will be `text-classification`.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¯¹äºå¤§å¤šæ•°ç”¨ä¾‹ï¼Œæˆ‘ä»¬ä»æ ‡ç­¾ä¸­ç¡®å®šæ¨¡å‹ç±»å‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœåœ¨[modelå¡ç‰‡å…ƒæ•°æ®](./model-cards)ä¸­æœ‰`tag: text-classification`ï¼Œåˆ™æ¨æ–­çš„`pipeline_tag`å°†æ˜¯`text-classification`ã€‚'
- en: 'For some libraries, such as ğŸ¤— `Transformers`, the model type should be inferred
    automatically based from configuration files (`config.json`). The architecture
    can determine the type: for example, `AutoModelForTokenClassification` corresponds
    to `token-classification`. If youâ€™re interested in this, you can see pseudo-code
    in [this gist](https://gist.github.com/julien-c/857ba86a6c6a895ecd90e7f7cab48046).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€äº›åº“ï¼Œä¾‹å¦‚ğŸ¤—`Transformers`ï¼Œåº”æ ¹æ®é…ç½®æ–‡ä»¶ï¼ˆ`config.json`ï¼‰è‡ªåŠ¨æ¨æ–­æ¨¡å‹ç±»å‹ã€‚æ¶æ„å¯ä»¥ç¡®å®šç±»å‹ï¼šä¾‹å¦‚ï¼Œ`AutoModelForTokenClassification`å¯¹åº”äº`token-classification`ã€‚å¦‚æœæ‚¨å¯¹æ­¤æ„Ÿå…´è¶£ï¼Œå¯ä»¥åœ¨[æ­¤ä»£ç ç‰‡æ®µ](https://gist.github.com/julien-c/857ba86a6c6a895ecd90e7f7cab48046)ä¸­çœ‹åˆ°ä¼ªä»£ç ã€‚
- en: '**You can always manually override your pipeline type with `pipeline_tag: xxx`
    in your [model card metadata](./model-cards#model-card-metadata).** (You can also
    use the metadata GUI editor to do this).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ‚¨å¯ä»¥å§‹ç»ˆåœ¨æ‚¨çš„[modelå¡ç‰‡å…ƒæ•°æ®](./model-cards#model-card-metadata)ä¸­æ‰‹åŠ¨è¦†ç›–æ‚¨çš„ç®¡é“ç±»å‹ï¼Œä½¿ç”¨`pipeline_tag:
    xxx`ã€‚**ï¼ˆæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å…ƒæ•°æ®GUIç¼–è¾‘å™¨æ¥æ‰§è¡Œæ­¤æ“ä½œï¼‰ã€‚'
- en: How can I control my modelâ€™s widget example input?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¦‚ä½•æ§åˆ¶æˆ‘çš„æ¨¡å‹çš„å°éƒ¨ä»¶ç¤ºä¾‹è¾“å…¥ï¼Ÿ
- en: 'You can specify the widget input in the model card metadata section:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨æ¨¡å‹å¡ç‰‡å…ƒæ•°æ®éƒ¨åˆ†æŒ‡å®šå°éƒ¨ä»¶è¾“å…¥ï¼š
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can provide more than one example input. In the examples dropdown menu of
    the widget, they will appear as `Example 1`, `Example 2`, etc. Optionally, you
    can supply `example_title` as well.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥æä¾›å¤šä¸ªç¤ºä¾‹è¾“å…¥ã€‚åœ¨å°éƒ¨ä»¶çš„ç¤ºä¾‹ä¸‹æ‹‰èœå•ä¸­ï¼Œå®ƒä»¬å°†æ˜¾ç¤ºä¸º`ç¤ºä¾‹1`ï¼Œ`ç¤ºä¾‹2`ç­‰ã€‚ä¹Ÿå¯ä»¥é€‰æ‹©æä¾›`example_title`ã€‚
- en: '![](../Images/2e667af198cffeb9b266712fc947a249.png) ![](../Images/b3e00f232523405c5b89a7cbb3c63c02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e667af198cffeb9b266712fc947a249.png) ![](../Images/b3e00f232523405c5b89a7cbb3c63c02.png)'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Moreover, you can specify non-text example inputs in the model card metadata.
    Refer [here](./models-widgets-examples) for a complete list of sample input formats
    for all widget types. For vision & audio widget types, provide example inputs
    with `src` rather than `text`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ‚¨å¯ä»¥åœ¨æ¨¡å‹å¡ç‰‡å…ƒæ•°æ®ä¸­æŒ‡å®šéæ–‡æœ¬ç¤ºä¾‹è¾“å…¥ã€‚è¯·å‚è€ƒ[æ­¤å¤„](./models-widgets-examples)ä»¥è·å–æ‰€æœ‰å°éƒ¨ä»¶ç±»å‹çš„ç¤ºä¾‹è¾“å…¥æ ¼å¼çš„å®Œæ•´åˆ—è¡¨ã€‚å¯¹äºè§†è§‰å’ŒéŸ³é¢‘å°éƒ¨ä»¶ç±»å‹ï¼Œè¯·ä½¿ç”¨`src`è€Œä¸æ˜¯`text`æä¾›ç¤ºä¾‹è¾“å…¥ã€‚
- en: 'For example, allow users to choose from two sample audio files for automatic
    speech recognition tasks by:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå…è®¸ç”¨æˆ·ä»ä¸¤ä¸ªç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶ä¸­é€‰æ‹©ï¼Œç”¨äºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼š
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that you can also include example files in your model repository and use
    them as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæ‚¨è¿˜å¯ä»¥åœ¨æ‚¨çš„æ¨¡å‹å­˜å‚¨åº“ä¸­åŒ…å«ç¤ºä¾‹æ–‡ä»¶å¹¶å°†å…¶ç”¨ä½œï¼š
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'But even more convenient, if the file lives in the corresponding model repo,
    you can just use the filename or file path inside the repo:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ›´æ–¹ä¾¿çš„æ˜¯ï¼Œå¦‚æœæ–‡ä»¶ä½äºç›¸åº”çš„æ¨¡å‹å­˜å‚¨åº“ä¸­ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨æ–‡ä»¶åæˆ–å­˜å‚¨åº“å†…çš„æ–‡ä»¶è·¯å¾„ï¼š
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'or if it was nested inside the repo:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…å¦‚æœå®ƒè¢«åµŒå¥—åœ¨å­˜å‚¨åº“ä¸­ï¼š
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We provide example inputs for some languages and most widget types in [default-widget-inputs.ts
    file](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/default-widget-inputs.ts).
    If some examples are missing, we welcome PRs from the community to add them!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ºä¸€äº›è¯­è¨€å’Œå¤§å¤šæ•°å°éƒ¨ä»¶ç±»å‹æä¾›ç¤ºä¾‹è¾“å…¥ï¼Œ[default-widget-inputs.tsæ–‡ä»¶](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/default-widget-inputs.ts)ä¸­æœ‰ã€‚å¦‚æœç¼ºå°‘æŸäº›ç¤ºä¾‹ï¼Œæˆ‘ä»¬æ¬¢è¿ç¤¾åŒºæä¾›PRæ¥æ·»åŠ å®ƒä»¬ï¼
- en: Example outputs
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹è¾“å‡º
- en: As an extension to example inputs, for each widget example, you can also optionally
    describe the corresponding model output, directly in the `output` property.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºç¤ºä¾‹è¾“å…¥çš„æ‰©å±•ï¼Œå¯¹äºæ¯ä¸ªå°éƒ¨ä»¶ç¤ºä¾‹ï¼Œæ‚¨è¿˜å¯ä»¥é€‰æ‹©åœ¨`output`å±æ€§ä¸­ç›´æ¥æè¿°ç›¸åº”çš„æ¨¡å‹è¾“å‡ºã€‚
- en: This is useful when the model is not yet supported by the Inference API (for
    instance, the model library is not yet supported or the model is too large) so
    that the model page can still showcase how the model works and what results it
    gives.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ¨¡å‹å°šæœªå—åˆ°æ¨ç†APIçš„æ”¯æŒæ—¶ï¼ˆä¾‹å¦‚ï¼Œæ¨¡å‹åº“å°šæœªå—åˆ°æ”¯æŒæˆ–æ¨¡å‹è¿‡å¤§ï¼‰ï¼Œè¿™å°†éå¸¸æœ‰ç”¨ï¼Œä»¥ä¾¿æ¨¡å‹é¡µé¢ä»ç„¶å¯ä»¥å±•ç¤ºæ¨¡å‹çš„å·¥ä½œåŸç†å’Œç»“æœã€‚
- en: 'For instance, for an [automatic-speech-recognition](./models-widgets-examples#automatic-speech-recognition)
    model:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¯¹äº[automatic-speech-recognition](./models-widgets-examples#automatic-speech-recognition)æ¨¡å‹ï¼š
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/08c477c6d1dd4bb7c844c730f176c3e9.png) ![](../Images/c80148c8cad45a4510b41176888bfa95.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08c477c6d1dd4bb7c844c730f176c3e9.png) ![](../Images/c80148c8cad45a4510b41176888bfa95.png)'
- en: The `output` property should be a YAML dictionary that represents the Inference
    API output.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`output`å±æ€§åº”è¯¥æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ¨ç†APIè¾“å‡ºçš„YAMLå­—å…¸ã€‚'
- en: For a model that outputs text, see the example above.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¾“å‡ºæ–‡æœ¬çš„æ¨¡å‹ï¼Œè¯·å‚é˜…ä¸Šé¢çš„ç¤ºä¾‹ã€‚
- en: 'For a model that outputs labels (like a [text-classification](./models-widgets-examples#text-classification)
    model for instance), output should look like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¾“å‡ºæ ‡ç­¾çš„æ¨¡å‹ï¼ˆä¾‹å¦‚[æ–‡æœ¬åˆ†ç±»](./models-widgets-examples#text-classification)æ¨¡å‹ï¼‰ï¼Œè¾“å‡ºåº”å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/933ebdde720cfeda653c4dfa6dd91f56.png) ![](../Images/51974136749f2869e4b018133697ada9.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/933ebdde720cfeda653c4dfa6dd91f56.png) ![](../Images/51974136749f2869e4b018133697ada9.png)'
- en: 'Finally, for a model that outputs an image, audio, or any other kind of asset,
    the output should include a `url` property linking to either a file name or path
    inside the repo or a remote URL. For example, for a text-to-image model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¯¹äºè¾“å‡ºå›¾åƒã€éŸ³é¢‘æˆ–ä»»ä½•å…¶ä»–ç±»å‹èµ„äº§çš„æ¨¡å‹ï¼Œè¾“å‡ºåº”åŒ…æ‹¬ä¸€ä¸ª`url`å±æ€§ï¼Œé“¾æ¥åˆ°å­˜å‚¨åº“å†…çš„æ–‡ä»¶åæˆ–è·¯å¾„ï¼Œæˆ–è¿œç¨‹URLã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼š
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/d1f98b52d0f98e0639af7b77624d07af.png) ![](../Images/5002ad2cf1d0dcdf434b887f68789704.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1f98b52d0f98e0639af7b77624d07af.png) ![](../Images/5002ad2cf1d0dcdf434b887f68789704.png)'
- en: We can also surface the example outputs in the Hugging Face UI, for instance,
    for a text-to-image model to display a gallery of cool image generations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥åœ¨Hugging Face UIä¸­å±•ç¤ºç¤ºä¾‹è¾“å‡ºï¼Œä¾‹å¦‚ï¼Œå¯¹äºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œä»¥æ˜¾ç¤ºä¸€ä¸ªé…·ç‚«å›¾åƒç”Ÿæˆçš„ç”»å»Šã€‚
- en: '![](../Images/0576121b8e46b63008259c4e8831cc52.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0576121b8e46b63008259c4e8831cc52.png)'
- en: What are all the possible task/widget types?
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å¯èƒ½çš„ä»»åŠ¡/å°éƒ¨ä»¶ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ
- en: You can find all the supported tasks in [pipelines.ts file](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/pipelines.ts).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨[pipelines.tsæ–‡ä»¶](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/pipelines.ts)ä¸­æ‰¾åˆ°æ‰€æœ‰æ”¯æŒçš„ä»»åŠ¡ã€‚
- en: 'Here are some links to examples:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹é“¾æ¥ï¼š
- en: '`text-classification`, for instance [`roberta-large-mnli`](https://huggingface.co/roberta-large-mnli)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-classification`ï¼Œä¾‹å¦‚[`roberta-large-mnli`](https://huggingface.co/roberta-large-mnli)'
- en: '`token-classification`, for instance [`dbmdz/bert-large-cased-finetuned-conll03-english`](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token-classification`ï¼Œä¾‹å¦‚[`dbmdz/bert-large-cased-finetuned-conll03-english`](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)'
- en: '`question-answering`, for instance [`distilbert-base-uncased-distilled-squad`](https://huggingface.co/distilbert-base-uncased-distilled-squad)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question-answering`ï¼Œä¾‹å¦‚[`distilbert-base-uncased-distilled-squad`](https://huggingface.co/distilbert-base-uncased-distilled-squad)'
- en: '`translation`, for instance [`t5-base`](https://huggingface.co/t5-base)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`translation`ï¼Œä¾‹å¦‚[`t5-base`](https://huggingface.co/t5-base)'
- en: '`summarization`, for instance [`facebook/bart-large-cnn`](https://huggingface.co/facebook/bart-large-cnn)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`summarization`ï¼Œä¾‹å¦‚[`facebook/bart-large-cnn`](https://huggingface.co/facebook/bart-large-cnn)'
- en: '`conversational`, for instance [`facebook/blenderbot-400M-distill`](https://huggingface.co/facebook/blenderbot-400M-distill)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conversational`ï¼Œä¾‹å¦‚[`facebook/blenderbot-400M-distill`](https://huggingface.co/facebook/blenderbot-400M-distill)'
- en: '`text-generation`, for instance [`gpt2`](https://huggingface.co/gpt2)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-generation`ï¼Œä¾‹å¦‚[`gpt2`](https://huggingface.co/gpt2)'
- en: '`fill-mask`, for instance [`distilroberta-base`](https://huggingface.co/distilroberta-base)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fill-mask`ï¼Œä¾‹å¦‚[`distilroberta-base`](https://huggingface.co/distilroberta-base)'
- en: '`zero-shot-classification` (implemented on top of a nli `text-classification`
    model), for instance [`facebook/bart-large-mnli`](https://huggingface.co/facebook/bart-large-mnli)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zero-shot-classification`ï¼ˆå»ºç«‹åœ¨nli `text-classification`æ¨¡å‹ä¹‹ä¸Šï¼‰ï¼Œä¾‹å¦‚[`facebook/bart-large-mnli`](https://huggingface.co/facebook/bart-large-mnli)'
- en: '`table-question-answering`, for instance [`google/tapas-base-finetuned-wtq`](https://huggingface.co/google/tapas-base-finetuned-wtq)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-question-answering`ï¼Œä¾‹å¦‚[`google/tapas-base-finetuned-wtq`](https://huggingface.co/google/tapas-base-finetuned-wtq)'
- en: '`sentence-similarity`, for instance [`osanseviero/full-sentence-distillroberta2`](/osanseviero/full-sentence-distillroberta2)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sentence-similarity`ï¼Œä¾‹å¦‚[`osanseviero/full-sentence-distillroberta2`](/osanseviero/full-sentence-distillroberta2)'
- en: How can I control my modelâ€™s widget Inference API parameters?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¦‚ä½•æ§åˆ¶æˆ‘çš„æ¨¡å‹å°éƒ¨ä»¶æ¨ç†APIå‚æ•°ï¼Ÿ
- en: Generally, the Inference API for a model uses the default pipeline settings
    associated with each task. But if youâ€™d like to change the pipelineâ€™s default
    settings and specify additional inference parameters, you can configure the parameters
    directly through the model card metadata. Refer [here](https://huggingface.co/docs/api-inference/detailed_parameters)
    for some of the most commonly used parameters associated with each task.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ¨¡å‹çš„æ¨ç†APIä½¿ç”¨ä¸æ¯ä¸ªä»»åŠ¡ç›¸å…³çš„é»˜è®¤ç®¡é“è®¾ç½®ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³æ›´æ”¹ç®¡é“çš„é»˜è®¤è®¾ç½®å¹¶æŒ‡å®šé¢å¤–çš„æ¨ç†å‚æ•°ï¼Œå¯ä»¥é€šè¿‡æ¨¡å‹å¡ç‰‡å…ƒæ•°æ®ç›´æ¥é…ç½®å‚æ•°ã€‚æœ‰å…³ä¸æ¯ä¸ªä»»åŠ¡ç›¸å…³çš„ä¸€äº›å¸¸ç”¨å‚æ•°ï¼Œè¯·å‚è€ƒ[è¿™é‡Œ](https://huggingface.co/docs/api-inference/detailed_parameters)ã€‚
- en: 'For example, if you want to specify an aggregation strategy for a NER task
    in the widget:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³ä¸ºå°éƒ¨ä»¶ä¸­çš„NERä»»åŠ¡æŒ‡å®šèšåˆç­–ç•¥ï¼š
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Or if youâ€™d like to change the temperature for a summarization task in the
    widget:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œå¦‚æœæ‚¨æƒ³åœ¨å°éƒ¨ä»¶ä¸­æ›´æ”¹æ‘˜è¦ä»»åŠ¡çš„æ¸©åº¦ï¼š
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The Inference API allows you to send HTTP requests to models in the Hugging
    Face Hub, and itâ€™s 2x to 10x faster than the widgets! âš¡âš¡ Learn more about it by
    reading the [Inference API documentation](./models-inference). Finally, you can
    also deploy all those models to dedicated [Inference Endpoints](https://huggingface.co/docs/inference-endpoints).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨ç†APIå…è®¸æ‚¨å‘Hugging Face Hubä¸­çš„æ¨¡å‹å‘é€HTTPè¯·æ±‚ï¼Œæ¯”å°éƒ¨ä»¶å¿«2å€åˆ°10å€ï¼âš¡âš¡ é€šè¿‡é˜…è¯»[æ¨ç†APIæ–‡æ¡£](./models-inference)äº†è§£æ›´å¤šã€‚æœ€åï¼Œæ‚¨è¿˜å¯ä»¥å°†æ‰€æœ‰è¿™äº›æ¨¡å‹éƒ¨ç½²åˆ°ä¸“ç”¨çš„[æ¨ç†ç«¯ç‚¹](https://huggingface.co/docs/inference-endpoints)ã€‚
