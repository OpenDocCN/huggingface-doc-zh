- en: DreamBooth
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DreamBooth
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/dreambooth](https://huggingface.co/docs/diffusers/training/dreambooth)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/training/dreambooth](https://huggingface.co/docs/diffusers/training/dreambooth)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[DreamBooth](https://huggingface.co/papers/2208.12242) is a training technique
    that updates the entire diffusion model by training on just a few images of a
    subject or style. It works by associating a special word in the prompt with the
    example images.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[DreamBooth](https://huggingface.co/papers/2208.12242)是一种训练技术，通过仅对主题或风格的少量图像进行训练来更新整个扩散模型。它通过将提示中的特殊单词与示例图像关联起来工作。'
- en: If you’re training on a GPU with limited vRAM, you should try enabling the `gradient_checkpointing`
    and `mixed_precision` parameters in the training command. You can also reduce
    your memory footprint by using memory-efficient attention with [xFormers](../optimization/xformers).
    JAX/Flax training is also supported for efficient training on TPUs and GPUs, but
    it doesn’t support gradient checkpointing or xFormers. You should have a GPU with
    >30GB of memory if you want to train faster with Flax.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在具有有限vRAM的GPU上进行训练，应尝试在训练命令中启用`gradient_checkpointing`和`mixed_precision`参数。您还可以通过使用[xFormers](../optimization/xformers)的内存高效注意力来减少内存占用。JAX/Flax训练也支持在TPU和GPU上进行高效训练，但不支持梯度检查点或xFormers。如果您想要使用Flax更快地进行训练，则应该具有>30GB内存的GPU。
- en: This guide will explore the [train_dreambooth.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将探讨[train_dreambooth.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)脚本，以帮助您更熟悉它，并了解如何为自己的用例进行调整。
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行脚本之前，请确保您从源代码安装库：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Navigate to the example folder with the training script and install the required
    dependencies for the script you’re using:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到包含训练脚本的示例文件夹，并安装所需的依赖项以供您使用的脚本：
- en: PyTorchFlax
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 🤗 Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. It’ll automatically configure your training setup based on your
    hardware and environment. Take a look at the 🤗 Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Accelerate是一个帮助您在多个GPU/TPU上训练或使用混合精度的库。它将根据您的硬件和环境自动配置您的训练设置。查看🤗 Accelerate
    [快速入门](https://huggingface.co/docs/accelerate/quicktour)以了解更多。
- en: 'Initialize an 🤗 Accelerate environment:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化🤗 Accelerate环境：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default 🤗 Accelerate environment without choosing any configurations:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置默认的🤗 Accelerate环境而不选择任何配置：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesn’t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您的环境不支持交互式shell，比如笔记本，您可以使用：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您想在自己的数据集上训练模型，请查看[创建用于训练的数据集](create_dataset)指南，了解如何创建适用于训练脚本的数据集。
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesn’t cover every aspect of the script
    in detail. If you’re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)
    and let us know if you have any questions or concerns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分突出了训练脚本中重要的部分，以帮助您了解如何修改它，但并未详细涵盖脚本的每个方面。如果您有兴趣了解更多，请随时阅读[脚本](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)，并告诉我们如果您有任何问题或疑虑。
- en: Script parameters
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚本参数
- en: DreamBooth is very sensitive to training hyperparameters, and it is easy to
    overfit. Read the [Training Stable Diffusion with Dreambooth using 🧨 Diffusers](https://huggingface.co/blog/dreambooth)
    blog post for recommended settings for different subjects to help you choose the
    appropriate hyperparameters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: DreamBooth对训练超参数非常敏感，很容易过拟合。阅读[使用🧨 Diffusers训练稳定扩散的DreamBooth](https://huggingface.co/blog/dreambooth)博客文章，了解不同主题的推荐设置，以帮助您选择适当的超参数。
- en: The training script offers many parameters for customizing your training run.
    All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L228)
    function. The parameters are set with default values that should work pretty well
    out-of-the-box, but you can also set your own values in the training command if
    you’d like.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本提供了许多参数，用于自定义您的训练运行。所有参数及其描述均在[`parse_args()`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L228)函数中找到。这些参数设置了默认值，应该可以很好地开箱即用，但如果您愿意，也可以在训练命令中设置自己的值。
- en: 'For example, to train in the bf16 format:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以bf16格式进行训练：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Some basic and important parameters to know and specify are:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一些基本和重要的参数需要了解和指定：
- en: '`--pretrained_model_name_or_path`: the name of the model on the Hub or a local
    path to the pretrained model'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --pretrained_model_name_or_path：Hub上模型的名称或预训练模型的本地路径
- en: '`--instance_data_dir`: path to a folder containing the training dataset (example
    images)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --instance_data_dir：包含训练数据集（示例图像）的文件夹路径
- en: '`--instance_prompt`: the text prompt that contains the special word for the
    example images'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --instance_prompt：包含示例图像的特殊单词的文本提示
- en: '`--train_text_encoder`: whether to also train the text encoder'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --train_text_encoder：是否还要训练文本编码器
- en: '`--output_dir`: where to save the trained model'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --output_dir：保存训练好的模型的位置
- en: '`--push_to_hub`: whether to push the trained model to the Hub'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --push_to_hub：是否将训练好的模型推送到Hub
- en: '`--checkpointing_steps`: frequency of saving a checkpoint as the model trains;
    this is useful if for some reason training is interrupted, you can continue training
    from that checkpoint by adding `--resume_from_checkpoint` to your training command'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--checkpointing_steps`：保存检查点的频率，这在训练中断时很有用，您可以通过在训练命令中添加 `--resume_from_checkpoint`
    从该检查点继续训练'
- en: Min-SNR weighting
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Min-SNR 权重策略
- en: The [Min-SNR](https://huggingface.co/papers/2303.09556) weighting strategy can
    help with training by rebalancing the loss to achieve faster convergence. The
    training script supports predicting `epsilon` (noise) or `v_prediction`, but Min-SNR
    is compatible with both prediction types. This weighting strategy is only supported
    by PyTorch and is unavailable in the Flax training script.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[Min-SNR](https://huggingface.co/papers/2303.09556) 权重策略可以通过重新平衡损失来帮助训练，以实现更快的收敛。训练脚本支持预测
    `epsilon`（噪音）或 `v_prediction`，但 Min-SNR 与两种预测类型兼容。这种权重策略仅由 PyTorch 支持，在 Flax 训练脚本中不可用。'
- en: 'Add the `--snr_gamma` parameter and set it to the recommended value of 5.0:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 添加 `--snr_gamma` 参数，并将其设置为推荐值 5.0：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Prior preservation loss
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 先前保留损失
- en: Prior preservation loss is a method that uses a model’s own generated samples
    to help it learn how to generate more diverse images. Because these generated
    sample images belong to the same class as the images you provided, they help the
    model retain what it has learned about the class and how it can use what it already
    knows about the class to make new compositions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的保留损失是一种方法，它利用模型自己生成的样本来帮助学习如何生成更多样化的图像。因为这些生成的样本图像属于您提供的图像相同的类别，它们帮助模型保留对该类别已学习的知识，以及如何利用已知的关于该类别的知识来生成新的组合。
- en: '`--with_prior_preservation`: whether to use prior preservation loss'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--with_prior_preservation`：是否使用先前保留损失'
- en: '`--prior_loss_weight`: controls the influence of the prior preservation loss
    on the model'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--prior_loss_weight`：控制模型对先前保留损失的影响'
- en: '`--class_data_dir`: path to a folder containing the generated class sample
    images'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--class_data_dir`：包含生成的类别样本图像的文件夹路径'
- en: '`--class_prompt`: the text prompt describing the class of the generated sample
    images'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--class_prompt`：描述生成样本图像类别的文本提示'
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Train text encoder
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练文本编码器
- en: 'To improve the quality of the generated outputs, you can also train the text
    encoder in addition to the UNet. This requires additional memory and you’ll need
    a GPU with at least 24GB of vRAM. If you have the necessary hardware, then training
    the text encoder produces better results, especially when generating images of
    faces. Enable this option by:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高生成输出的质量，您还可以训练文本编码器以及 UNet。这需要额外的内存，您需要至少具有 24GB 的 vRAM 的 GPU。如果您有必要的硬件，那么训练文本编码器会产生更好的结果，特别是在生成面部图像时。通过以下选项启用此选项：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Training script
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练脚本
- en: 'DreamBooth comes with its own dataset classes:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: DreamBooth 自带其自己的数据集类：
- en: '[`DreamBoothDataset`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L604):
    preprocesses the images and class images, and tokenizes the prompts for training'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`DreamBoothDataset`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L604)：预处理图像和类别图像，并为训练令牌化提示'
- en: '[`PromptDataset`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L738):
    generates the prompt embeddings to generate the class images'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`PromptDataset`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L738)：生成提示嵌入以生成类别图像'
- en: 'If you enabled [prior preservation loss](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L842),
    the class images are generated here:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您启用了[先前保留损失](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L842)，则在此处生成类别图像：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next is the [`main()`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L799)
    function which handles setting up the dataset for training and the training loop
    itself. The script loads the [tokenizer](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L898),
    [scheduler and models](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L912C1-L912C1):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是 [`main()`](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L799)
    函数，负责设置用于训练的数据集和训练循环本身。脚本加载 [tokenizer](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L898)、[调度器和模型](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L912C1-L912C1)：
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, it’s time to [create the training dataset](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L1073)
    and DataLoader from `DreamBoothDataset`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，是时候[创建训练数据集](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L1073)和从
    `DreamBoothDataset` 创建 DataLoader 了：
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Lastly, the [training loop](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L1151)
    takes care of the remaining steps such as converting images to latent space, adding
    noise to the input, predicting the noise residual, and calculating the loss.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，[训练循环](https://github.com/huggingface/diffusers/blob/072e00897a7cf4302c347a63ec917b4b8add16d4/examples/dreambooth/train_dreambooth.py#L1151)
    处理剩余步骤，如将图像转换为潜在空间，向输入添加噪音，预测噪音残差，并计算损失。
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers](../using-diffusers/write_own_pipeline) tutorial
    which breaks down the basic pattern of the denoising process.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解训练循环的工作原理，请查看 [理解管道、模型和调度器](../using-diffusers/write_own_pipeline) 教程，该教程解析了去噪过程的基本模式。
- en: Launch the script
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动脚本
- en: You’re now ready to launch the training script! 🚀
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以启动训练脚本了！🚀
- en: For this guide, you’ll download some images of a [dog](https://huggingface.co/datasets/diffusers/dog-example)
    and store them in a directory. But remember, you can create and use your own dataset
    if you want (see the [Create a dataset for training](create_dataset) guide).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个指南，您将下载一些[狗](https://huggingface.co/datasets/diffusers/dog-example)的图像并将它们存储在一个目录中。但请记住，如果您愿意，您可以创建和使用自己的数据集（请参阅[创建用于训练的数据集](create_dataset)指南）。
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Set the environment variable `MODEL_NAME` to a model id on the Hub or a path
    to a local model, `INSTANCE_DIR` to the path where you just downloaded the dog
    images to, and `OUTPUT_DIR` to where you want to save the model. You’ll use `sks`
    as the special word to tie the training to.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将环境变量`MODEL_NAME`设置为Hub上的模型ID或本地模型的路径，`INSTANCE_DIR`设置为您刚下载狗图片的路径，`OUTPUT_DIR`设置为您想要保存模型的路径。您将使用`sks`作为将训练绑定到的特殊词。
- en: 'If you’re interested in following along with the training process, you can
    periodically save generated images as training progresses. Add the following parameters
    to the training command:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣跟随训练过程，可以在训练进行时定期保存生成的图像。将以下参数添加到训练命令中：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: One more thing before you launch the script! Depending on the GPU you have,
    you may need to enable certain optimizations to train DreamBooth.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动脚本之前还有一件事！根据您拥有的GPU，您可能需要启用某些优化来训练DreamBooth。
- en: 16GB12GB8GB
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 16GB12GB8GB
- en: 'On a 16GB GPU, you can use bitsandbytes 8-bit optimizer and gradient checkpointing
    to help you train a DreamBooth model. Install bitsandbytes:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在16GB GPU上，您可以使用bitsandbytes 8位优化器和梯度检查点来帮助您训练DreamBooth模型。安装bitsandbytes：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, add the following parameter to your training command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将以下参数添加到您的训练命令中：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: PyTorchFlax
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Once training is complete, you can use your newly trained model for inference!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，您可以使用新训练的模型进行推理！
- en: Can’t wait to try your model for inference before training is complete? 🤭 Make
    sure you have the latest version of 🤗 Accelerate installed.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练完成之前就迫不及待地尝试您的模型进行推理？🤭 确保您已安装最新版本的🤗 Accelerate。
- en: '[PRE17]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: PyTorchFlax
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: LoRA
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LoRA
- en: LoRA is a training technique for significantly reducing the number of trainable
    parameters. As a result, training is faster and it is easier to store the resulting
    weights because they are a lot smaller (~100MBs). Use the [train_dreambooth_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py)
    script to train with LoRA.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA是一种用于显著减少可训练参数数量的训练技术。因此，训练速度更快，存储结果权重更容易，因为它们要小得多（~100MB）。使用[train_dreambooth_lora.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py)脚本来使用LoRA进行训练。
- en: The LoRA training script is discussed in more detail in the [LoRA training](lora)
    guide.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有关LoRA训练脚本的更多详细信息，请参阅[LoRA训练](lora)指南。
- en: Stable Diffusion XL
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Stable Diffusion XL
- en: Stable Diffusion XL (SDXL) is a powerful text-to-image model that generates
    high-resolution images, and it adds a second text-encoder to its architecture.
    Use the [train_dreambooth_lora_sdxl.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora_sdxl.py)
    script to train a SDXL model with LoRA.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion XL（SDXL）是一个强大的文本到图像模型，可以生成高分辨率图像，并在其架构中添加了第二个文本编码器。使用[train_dreambooth_lora_sdxl.py](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora_sdxl.py)脚本来训练一个带有LoRA的SDXL模型。
- en: The SDXL training script is discussed in more detail in the [SDXL training](sdxl)
    guide.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有关SDXL训练脚本的更多详细信息，请参阅[SDXL训练](sdxl)指南。
- en: Next steps
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: 'Congratulations on training your DreamBooth model! To learn more about how
    to use your new model, the following guide may be helpful:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您训练成功DreamBooth模型！要了解如何使用您的新模型，以下指南可能会有所帮助：
- en: Learn how to [load a DreamBooth](../using-diffusers/loading_adapters) model
    for inference if you trained your model with LoRA.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您使用LoRA训练了您的模型，学习如何[加载DreamBooth](../using-diffusers/loading_adapters)模型进行推理。
