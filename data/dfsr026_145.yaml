- en: InstructPix2Pix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: InstructPix2Pix
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/pix2pix](https://huggingface.co/docs/diffusers/api/pipelines/pix2pix)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/pix2pix](https://huggingface.co/docs/diffusers/api/pipelines/pix2pix)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[InstructPix2Pix: Learning to Follow Image Editing Instructions](https://huggingface.co/papers/2211.09800)
    is by Tim Brooks, Aleksander Holynski and Alexei A. Efros.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[InstructPix2Pixï¼šå­¦ä¹ éµå¾ªå›¾åƒç¼–è¾‘è¯´æ˜](https://huggingface.co/papers/2211.09800)ç”±Tim
    Brooksã€Aleksander Holynskiå’ŒAlexei A. Efrosæ’°å†™ã€‚'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è®ºæ–‡çš„æ‘˜è¦ä¸ºï¼š
- en: '*We propose a method for editing images from human instructions: given an input
    image and a written instruction that tells the model what to do, our model follows
    these instructions to edit the image. To obtain training data for this problem,
    we combine the knowledge of two large pretrained models â€” a language model (GPT-3)
    and a text-to-image model (Stable Diffusion) â€” to generate a large dataset of
    image editing examples. Our conditional diffusion model, InstructPix2Pix, is trained
    on our generated data, and generalizes to real images and user-written instructions
    at inference time. Since it performs edits in the forward pass and does not require
    per example fine-tuning or inversion, our model edits images quickly, in a matter
    of seconds. We show compelling editing results for a diverse collection of input
    images and written instructions.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ ¹æ®äººç±»æŒ‡ä»¤ç¼–è¾‘å›¾åƒçš„æ–¹æ³•ï¼šç»™å®šä¸€ä¸ªè¾“å…¥å›¾åƒå’Œä¸€æ¡ä¹¦é¢æŒ‡ä»¤å‘Šè¯‰æ¨¡å‹è¯¥åšä»€ä¹ˆï¼Œæˆ‘ä»¬çš„æ¨¡å‹éµå¾ªè¿™äº›æŒ‡ä»¤æ¥ç¼–è¾‘å›¾åƒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜çš„è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªå¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†-è¯­è¨€æ¨¡å‹ï¼ˆGPT-3ï¼‰å’Œæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼ˆç¨³å®šæ‰©æ•£ï¼‰-ç”Ÿæˆäº†å¤§é‡çš„å›¾åƒç¼–è¾‘ç¤ºä¾‹æ•°æ®é›†ã€‚æˆ‘ä»¬çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹InstructPix2Pixæ˜¯åœ¨æˆ‘ä»¬ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œå¹¶ä¸”åœ¨æ¨ç†æ—¶æ¨å¹¿åˆ°çœŸå®å›¾åƒå’Œç”¨æˆ·ç¼–å†™çš„æŒ‡ä»¤ã€‚ç”±äºå®ƒåœ¨å‰å‘ä¼ é€’ä¸­æ‰§è¡Œç¼–è¾‘ï¼Œä¸éœ€è¦æ¯ä¸ªç¤ºä¾‹çš„å¾®è°ƒæˆ–åæ¼”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨å‡ ç§’é’Ÿå†…å¿«é€Ÿç¼–è¾‘å›¾åƒã€‚æˆ‘ä»¬å±•ç¤ºäº†å¯¹å„ç§è¾“å…¥å›¾åƒå’Œä¹¦é¢æŒ‡ä»¤çš„å¼•äººæ³¨ç›®çš„ç¼–è¾‘ç»“æœã€‚*'
- en: You can find additional information about InstructPix2Pix on the [project page](https://www.timothybrooks.com/instruct-pix2pix),
    [original codebase](https://github.com/timothybrooks/instruct-pix2pix), and try
    it out in a [demo](https://huggingface.co/spaces/timbrooks/instruct-pix2pix).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨[é¡¹ç›®é¡µé¢](https://www.timothybrooks.com/instruct-pix2pix)ã€[åŸå§‹ä»£ç åº“](https://github.com/timothybrooks/instruct-pix2pix)å’Œ[æ¼”ç¤º](https://huggingface.co/spaces/timbrooks/instruct-pix2pix)ä¸­æ‰¾åˆ°æœ‰å…³InstructPix2Pixçš„å…¶ä»–ä¿¡æ¯ã€‚
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿æŸ¥çœ‹è°ƒåº¦å™¨æŒ‡å—ä»¥äº†è§£å¦‚ä½•åœ¨è°ƒåº¦å™¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œå¹¶æŸ¥çœ‹é‡ç”¨ç»„ä»¶è·¨ç®¡é“éƒ¨åˆ†ä»¥äº†è§£å¦‚ä½•æœ‰æ•ˆåœ°å°†ç›¸åŒç»„ä»¶åŠ è½½åˆ°å¤šä¸ªç®¡é“ä¸­ã€‚
- en: StableDiffusionInstructPix2PixPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£æŒ‡å¯¼Pix2Pixç®¡é“
- en: '### `class diffusers.StableDiffusionInstructPix2PixPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionInstructPix2PixPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L75)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L75)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKLï¼‰ï¼‰-
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç åˆ°å’Œä»æ½œåœ¨è¡¨ç¤ºä¸­ã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelï¼‰ï¼‰-
    å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” A `CLIPTokenizer` to tokenize text.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerï¼‰ï¼‰-
    ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°çš„`CLIPTokenizer`ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModelï¼‰ï¼‰-
    ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨çš„`UNet2DConditionModel`ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`ï¼ˆ[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixinï¼‰ï¼‰-
    ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨çš„è°ƒåº¦å™¨ã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a modelâ€™s potential harms.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker`ï¼ˆ`StableDiffusionSafetyChecker`ï¼‰- ä¼°è®¡ç”Ÿæˆçš„å›¾åƒæ˜¯å¦å¯èƒ½è¢«è§†ä¸ºå…·æœ‰å†’çŠ¯æ€§æˆ–æœ‰å®³æ€§çš„åˆ†ç±»æ¨¡å—ã€‚è¯·å‚è€ƒ[æ¨¡å‹å¡ç‰‡](https://huggingface.co/runwayml/stable-diffusion-v1-5)ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`ï¼ˆ[CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessorï¼‰ï¼‰-
    ç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾çš„`CLIPImageProcessor`ï¼›ä½œä¸º`safety_checker`çš„è¾“å…¥ã€‚'
- en: Pipeline for pixel-level image editing by following text instructions (based
    on Stable Diffusion).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ–‡æœ¬æŒ‡ä»¤è¿›è¡Œåƒç´ çº§å›¾åƒç¼–è¾‘çš„æµæ°´çº¿ï¼ˆåŸºäº Stable Diffusionï¼‰ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    ç”¨äºåŠ è½½ LoRA æƒé‡'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    ç”¨äºä¿å­˜ LoRA æƒé‡'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    ç”¨äºåŠ è½½ IP é€‚é…å™¨'
- en: '#### `__call__`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L159)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L159)'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`prompt_embeds`ã€‚'
- en: '`image` (`torch.FloatTensor` `np.ndarray`, `PIL.Image.Image`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) â€” `Image` or tensor representing
    an image batch to be repainted according to `prompt`. Can also accept image latents
    as `image`, but if passing latents directly it is not encoded again.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` `np.ndarray`, `PIL.Image.Image`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, æˆ– `List[np.ndarray]`) â€” è¡¨ç¤ºè¦æ ¹æ®`prompt`é‡æ–°ç»˜åˆ¶çš„å›¾åƒæ‰¹æ¬¡çš„`Image`æˆ–å¼ é‡ã€‚ä¹Ÿå¯ä»¥æ¥å—å›¾åƒæ½œå˜é‡ä½œä¸º`image`ï¼Œä½†å¦‚æœç›´æ¥ä¼ é€’æ½œå˜é‡ï¼Œåˆ™ä¸ä¼šå†æ¬¡ç¼–ç ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) â€” The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º100) â€” é™å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„é™å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬`prompt`ç´§å¯†ç›¸å…³çš„å›¾åƒï¼Œä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚å½“`guidance_scale
    > 1`æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚'
- en: '`image_guidance_scale` (`float`, *optional*, defaults to 1.5) â€” Push the generated
    image towards the inital `image`. Image guidance scale is enabled by setting `image_guidance_scale
    > 1`. Higher image guidance scale encourages generated images that are closely
    linked to the source `image`, usually at the expense of lower image quality. This
    pipeline requires a value of at least `1`.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º1.5) â€” å°†ç”Ÿæˆçš„å›¾åƒæ¨å‘åˆå§‹`image`ã€‚è®¾ç½®`image_guidance_scale
    > 1`å¯ä»¥å¯ç”¨å›¾åƒå¼•å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„å›¾åƒå¼•å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆçš„å›¾åƒä¸æº`image`ç´§å¯†ç›¸å…³ï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚æ­¤æµæ°´çº¿éœ€è¦è‡³å°‘`1`çš„å€¼ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” æŒ‡å¯¼åœ¨å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’`negative_prompt_embeds`ã€‚å½“ä¸ä½¿ç”¨å¼•å¯¼æ—¶ï¼ˆ`guidance_scale
    < 1`ï¼‰å°†è¢«å¿½ç•¥ã€‚'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º0.0) â€” å¯¹åº”äº[DDIM](https://arxiv.org/abs/2010.02502)è®ºæ–‡ä¸­çš„å‚æ•°
    eta (Î·)ã€‚ä»…é€‚ç”¨äº[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator`, *optional*) â€” A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *å¯é€‰*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚'
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *å¯é€‰*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­æŠ½æ ·çš„é¢„ç”Ÿæˆå™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é€šè¿‡ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡ŒæŠ½æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument. ip_adapter_image â€” (`PipelineImageInput`, *optional*): Optional
    image input to work with IP Adapters.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼ˆæç¤ºåŠ æƒï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œ`negative_prompt_embeds`å°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚ip_adapter_image
    â€”ï¼ˆ`PipelineImageInput`ï¼Œ*å¯é€‰*ï¼‰ï¼šå¯é€‰çš„å›¾åƒè¾“å…¥ä»¥ä¸IPé€‚é…å™¨ä¸€èµ·ä½¿ç”¨ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"pil"`ï¼‰â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹©`PIL.Image`æˆ–`np.array`ä¹‹é—´çš„ä¸€ä¸ªã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦è¿”å›[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`callback_on_step_end` (`Callable`, *optional*) â€” A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end`ï¼ˆ`Callable`ï¼Œ*å¯é€‰*ï¼‰â€” åœ¨æ¨æ–­æœŸé—´æ¯ä¸ªå»å™ªæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`ã€‚`callback_kwargs`å°†åŒ…æ‹¬ç”±`callback_on_step_end_tensor_inputs`æŒ‡å®šçš„æ‰€æœ‰å¼ é‡çš„åˆ—è¡¨ã€‚'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs`ï¼ˆ`List`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äº`callback_on_step_end`å‡½æ•°çš„å¼ é‡è¾“å…¥åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æŒ‡å®šçš„å¼ é‡å°†ä½œä¸º`callback_kwargs`å‚æ•°ä¼ é€’ã€‚æ‚¨åªèƒ½åŒ…å«åœ¨ç®¡é“ç±»çš„`._callback_tensor_inputs`å±æ€§ä¸­åˆ—å‡ºçš„å˜é‡ã€‚'
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)æˆ–`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains â€œnot-safe-for-workâ€ (nsfw)
    content.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å›[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª`tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«ç›¸åº”ç”Ÿæˆå›¾åƒæ˜¯å¦åŒ…å«â€œä¸é€‚å®œå·¥ä½œâ€ï¼ˆnsfwï¼‰å†…å®¹çš„`bool`åˆ—è¡¨ã€‚
- en: The call function to the pipeline for generation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚
- en: 'Examples:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `load_textual_inversion`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_textual_inversion`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike` or `List[str or os.PathLike]`
    or `Dict` or `List[Dict]`) â€” Can be either one of the following or a list of them:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`ï¼ˆ`str`æˆ–`os.PathLike`æˆ–`List[stræˆ–os.PathLike]`æˆ–`Dict`æˆ–`List[Dict]`ï¼‰â€”
    å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€æˆ–å®ƒä»¬çš„åˆ—è¡¨ï¼š'
- en: A string, the *model id* (for example `sd-concepts-library/low-poly-hd-logos-icons`)
    of a pretrained model hosted on the Hub.
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨Hubä¸Šæ‰˜ç®¡çš„*æ¨¡å‹ID*ï¼ˆä¾‹å¦‚`sd-concepts-library/low-poly-hd-logos-icons`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_text_inversion_directory/`) containing
    the textual inversion weights.
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„è·¯å¾„ä¸º*ç›®å½•*ï¼ˆä¾‹å¦‚`./my_text_inversion_directory/ï¼‰ã€‚
- en: A path to a *file* (for example `./my_text_inversions.pt`) containing textual
    inversion weights.
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒ…å«æ–‡æœ¬åè½¬æƒé‡çš„*æ–‡ä»¶*è·¯å¾„ï¼ˆä¾‹å¦‚`./my_text_inversions.pt`ï¼‰ã€‚
- en: A [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict).
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[torchçŠ¶æ€å­—å…¸](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)ã€‚
- en: '`token` (`str` or `List[str]`, *optional*) â€” Override the token to use for
    the textual inversion weights. If `pretrained_model_name_or_path` is a list, then
    `token` must also be a list of equal length.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦†ç›–ç”¨äºæ–‡æœ¬åè½¬æƒé‡çš„ä»¤ç‰Œã€‚å¦‚æœ`pretrained_model_name_or_path`æ˜¯åˆ—è¡¨ï¼Œåˆ™`token`ä¹Ÿå¿…é¡»æ˜¯ç›¸åŒé•¿åº¦çš„åˆ—è¡¨ã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).
    If not specified, function will take self.tokenizer.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)ï¼Œ*å¯é€‰*ï¼‰â€”
    å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨self.tokenizerã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) â€” A `CLIPTokenizer` to tokenize text. If not specified, function will
    take self.tokenizer.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºæ ‡è®°æ–‡æœ¬çš„`CLIPTokenizer`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå‡½æ•°å°†ä½¿ç”¨self.tokenizerã€‚'
- en: '`weight_name` (`str`, *optional*) â€” Name of a custom weight file. This should
    be used when:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” è‡ªå®šä¹‰æƒé‡æ–‡ä»¶çš„åç§°ã€‚åº”åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨ï¼š'
- en: The saved textual inversion file is in ğŸ¤— Diffusers format, but was saved under
    a specific weight name such as `text_inv.bin`.
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥ğŸ¤— Diffusersæ ¼å¼ä¿å­˜ï¼Œä½†æ˜¯ä¿å­˜åœ¨ç‰¹å®šæƒé‡åç§°ä¸‹ï¼Œä¾‹å¦‚`text_inv.bin`ã€‚
- en: The saved textual inversion file is in the Automatic1111 format.
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„æ–‡æœ¬åè½¬æ–‡ä»¶ä»¥Automatic1111æ ¼å¼ä¿å­˜ã€‚
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®æ—¶ç¼“å­˜çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼Œ`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†å°†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º`True`ï¼Œæ¨¡å‹å°†ä¸ä¼šä»Hubä¸‹è½½ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` or *bool*, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ä½¿ç”¨ä»`diffusers-cli
    login`ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤IDæˆ–Gitå…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) â€” The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *optional*, defaults to `""`) â€” åœ¨Hubæˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­æ¨¡å‹æ–‡ä»¶çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚'
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *optional*) â€” é•œåƒæºï¼Œç”¨äºè§£å†³åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶çš„å¯è®¿é—®æ€§é—®é¢˜ã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚'
- en: Load Textual Inversion embeddings into the text encoder of [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    (both ğŸ¤— Diffusers and Automatic1111 formats are supported).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ–‡æœ¬åè½¬åµŒå…¥åŠ è½½åˆ°[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)çš„æ–‡æœ¬ç¼–ç å™¨ä¸­ï¼ˆæ”¯æŒğŸ¤—
    Diffuserså’ŒAutomatic1111æ ¼å¼ï¼‰ã€‚
- en: 'Example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: 'To load a Textual Inversion embedding vector in ğŸ¤— Diffusers format:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½ğŸ¤— Diffusersæ ¼å¼ä¸­çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼š
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To load a Textual Inversion embedding vector in Automatic1111 format, make sure
    to download the vector first (for example from [civitAI](https://civitai.com/models/3036?modelVersionId=9857))
    and then load the vector
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½Automatic1111æ ¼å¼ä¸­çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼Œè¯·ç¡®ä¿é¦–å…ˆä¸‹è½½å‘é‡ï¼ˆä¾‹å¦‚ä»[civitAI](https://civitai.com/models/3036?modelVersionId=9857)ï¼‰ï¼Œç„¶ååŠ è½½å‘é‡ã€‚
- en: 'locally:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åœ°ï¼š
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `load_lora_weights`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    â€” See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    â€” æŸ¥çœ‹[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚'
- en: '`kwargs` (`dict`, *optional*) â€” See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`dict`, *optional*) â€” æŸ¥çœ‹[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ã€‚'
- en: '`adapter_name` (`str`, *optional*) â€” Adapter name to be used for referencing
    the loaded adapter model. If not specified, it will use `default_{i}` where i
    is the total number of adapters being loaded.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *optional*) â€” ç”¨äºå¼•ç”¨åŠ è½½çš„é€‚é…å™¨æ¨¡å‹çš„é€‚é…å™¨åç§°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨`default_{i}`ï¼Œå…¶ä¸­iæ˜¯è¦åŠ è½½çš„é€‚é…å™¨æ€»æ•°ã€‚'
- en: Load LoRA weights specified in `pretrained_model_name_or_path_or_dict` into
    `self.unet` and `self.text_encoder`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å°†åœ¨`self.unet`å’Œ`self.text_encoder`ä¸­åŠ è½½æŒ‡å®šçš„LoRAæƒé‡ã€‚
- en: All kwargs are forwarded to `self.lora_state_dict`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰kwargséƒ½å°†è½¬å‘åˆ°`self.lora_state_dict`ã€‚
- en: See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    for more details on how the state dict is loaded.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)ä»¥è·å–æœ‰å…³å¦‚ä½•åŠ è½½çŠ¶æ€å­—å…¸çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: See [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    for more details on how the state dict is loaded into `self.unet`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°`self.unet`çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: See [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    for more details on how the state dict is loaded into `self.text_encoder`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)ä»¥è·å–æœ‰å…³å¦‚ä½•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°`self.text_encoder`çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: '#### `save_lora_weights`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to save LoRA parameters
    to. Will be created if it doesnâ€™t exist.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` or `os.PathLike`) â€” ä¿å­˜LoRAå‚æ•°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†è¢«åˆ›å»ºã€‚'
- en: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” State dict of the LoRA layers corresponding to the `unet`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet_lora_layers`ï¼ˆ`Dict[str, torch.nn.Module]`æˆ–`Dict[str, torch.Tensor]`ï¼‰â€”
    ä¸`unet`å¯¹åº”çš„LoRAå±‚çš„çŠ¶æ€å­—å…¸ã€‚'
- en: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    â€” State dict of the LoRA layers corresponding to the `text_encoder`. Must explicitly
    pass the text encoder LoRA state dict because it comes from ğŸ¤— Transformers.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_lora_layers`ï¼ˆ`Dict[str, torch.nn.Module]`æˆ–`Dict[str, torch.Tensor]`ï¼‰â€”
    ä¸`text_encoder`å¯¹åº”çš„LoRAå±‚çš„çŠ¶æ€å­—å…¸ã€‚å¿…é¡»æ˜¾å¼ä¼ é€’æ–‡æœ¬ç¼–ç å™¨LoRAçŠ¶æ€å­—å…¸ï¼Œå› ä¸ºå®ƒæ¥è‡ªğŸ¤— Transformersã€‚'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) â€” Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´å¾ˆæœ‰ç”¨ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®`is_main_process=True`ï¼Œä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚'
- en: '`save_function` (`Callable`) â€” The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function`ï¼ˆ`Callable`ï¼‰â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢`torch.save`æ—¶å¾ˆæœ‰ç”¨ã€‚å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡`DIFFUSERS_SAVE_MODE`è¿›è¡Œé…ç½®ã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä½¿ç”¨`safetensors`ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„PyTorchæ–¹å¼ä¸`pickle`ã€‚'
- en: Save the LoRA parameters corresponding to the UNet and text encoder.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿å­˜ä¸UNetå’Œæ–‡æœ¬ç¼–ç å™¨å¯¹åº”çš„LoRAå‚æ•°ã€‚
- en: '#### `disable_freeu`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L832)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L832)'
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨äº†å¯ç”¨çš„FreeUæœºåˆ¶ã€‚
- en: '#### `enable_freeu`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L809)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L809)'
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1`ï¼ˆ`float`ï¼‰â€” ç”¨äºé˜»å°¼è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚'
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2`ï¼ˆ`float`ï¼‰â€” ç”¨äºé˜»å°¼è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚'
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚'
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨äº†FreeUæœºåˆ¶ï¼Œå¦‚[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)ä¸­æ‰€è¿°ã€‚
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬è¢«åº”ç”¨çš„é˜¶æ®µã€‚
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚Stable Diffusion
    v1ã€v2å’ŒStable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚
- en: StableDiffusionXLInstructPix2PixPipeline
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionXLInstructPix2PixPipeline
- en: '### `class diffusers.StableDiffusionXLInstructPix2PixPipeline`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionXLInstructPix2PixPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L120)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L120)'
- en: '[PRE10]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)ï¼‰â€”
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç ä»¥åŠä»æ½œåœ¨è¡¨ç¤ºä¸­ã€‚'
- en: '`text_encoder` (`CLIPTextModel`) â€” Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ`CLIPTextModel`ï¼‰â€” å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚Stable Diffusion XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)å˜ä½“ã€‚'
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) â€” Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_2`ï¼ˆ`CLIPTextModelWithProjection`ï¼‰â€” ç¬¬äºŒä¸ªå†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚Stable Diffusion
    XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection)çš„æ–‡æœ¬å’Œæ± éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)å˜ä½“ã€‚'
- en: '`tokenizer` (`CLIPTokenizer`) â€” Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ`CLIPTokenizer`ï¼‰â€” ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„åˆ†è¯å™¨ã€‚'
- en: '`tokenizer_2` (`CLIPTokenizer`) â€” Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_2` (`CLIPTokenizer`) â€” ç¬¬äºŒä¸ªç±»çš„Tokenizer [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„æ¡ä»¶U-Netæ¶æ„ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” ä¸`unet`ç»“åˆä½¿ç”¨çš„è°ƒåº¦å™¨ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`requires_aesthetics_score` (`bool`, *optional*, defaults to `"False"`) â€” Whether
    the `unet` requires a aesthetic_score condition to be passed during inference.
    Also see the config of `stabilityai/stable-diffusion-xl-refiner-1-0`.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requires_aesthetics_score` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`"False"`) â€” `unet`åœ¨æ¨æ–­æœŸé—´æ˜¯å¦éœ€è¦é€šè¿‡å®¡ç¾è¯„åˆ†æ¡ä»¶ã€‚ä¹Ÿè¯·å‚é˜…`stabilityai/stable-diffusion-xl-refiner-1-0`çš„é…ç½®ã€‚'
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) â€”
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_zeros_for_empty_prompt` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`"True"`) â€” æ˜¯å¦å¼ºåˆ¶å°†è´Ÿæç¤ºåµŒå…¥å§‹ç»ˆè®¾ç½®ä¸º0ã€‚ä¹Ÿè¯·å‚é˜…`stabilityai/stable-diffusion-xl-base-1-0`çš„é…ç½®ã€‚'
- en: '`add_watermarker` (`bool`, *optional*) â€” Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_watermarker` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨[invisible_watermarkåº“](https://github.com/ShieldMnt/invisible-watermark/)æ¥ç»™è¾“å‡ºå›¾åƒæ·»åŠ æ°´å°ã€‚å¦‚æœæœªå®šä¹‰ï¼Œä¸”è¯¥è½¯ä»¶åŒ…å·²å®‰è£…ï¼Œåˆ™é»˜è®¤ä¸ºTrueï¼Œå¦åˆ™å°†ä¸ä½¿ç”¨æ°´å°ã€‚'
- en: Pipeline for pixel-level image editing by following text instructions. Based
    on Stable Diffusion XL.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºç¨³å®šæ‰©æ•£XLçš„åƒç´ çº§å›¾åƒç¼–è¾‘æµæ°´çº¿ï¼Œé€šè¿‡ä»¥ä¸‹æ–‡æœ¬æŒ‡ä»¤ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æµæ°´çº¿è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    ç”¨äºåŠ è½½LoRAæƒé‡'
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_lora_weights()` ç”¨äºä¿å­˜LoRAæƒé‡'
- en: '#### `__call__`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L652)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L652)'
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” å¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`prompt_embeds`ã€‚'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`prompt`ã€‚'
- en: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `np.ndarray` or `List[torch.FloatTensor]`
    or `List[PIL.Image.Image]` or `List[np.ndarray]`) â€” The image(s) to modify with
    the pipeline.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` æˆ– `PIL.Image.Image` æˆ– `np.ndarray` æˆ– `List[torch.FloatTensor]`
    æˆ– `List[PIL.Image.Image]` æˆ– `List[np.ndarray]`) â€” è¦ä½¿ç”¨æµæ°´çº¿ä¿®æ”¹çš„å›¾åƒã€‚'
- en: '`height` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    â€” The height in pixels of the generated image.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *å¯é€‰*, é»˜è®¤ä¸ºself.unet.config.sample_size * self.vae_scale_factor)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚'
- en: '`width` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    â€” The width in pixels of the generated image.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *å¯é€‰*, é»˜è®¤ä¸ºself.unet.config.sample_size * self.vae_scale_factor)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨æ–­é€Ÿåº¦ã€‚'
- en: '`denoising_end` (`float`, *optional*) â€” When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise as determined by the discrete timesteps
    selected by the scheduler. The denoising_end parameter should ideally be utilized
    when this pipeline forms a part of a â€œMixture of Denoisersâ€ multi-pipeline setup,
    as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`denoising_end` (`float`, *å¯é€‰*) â€” å½“æŒ‡å®šæ—¶ï¼Œç¡®å®šåœ¨æœ‰æ„æå‰ç»ˆæ­¢ä¹‹å‰å®Œæˆçš„æ€»å»å™ªè¿‡ç¨‹çš„åˆ†æ•°ï¼ˆä»‹äº0.0å’Œ1.0ä¹‹é—´ï¼‰ã€‚å› æ­¤ï¼Œè¿”å›çš„æ ·æœ¬ä»å°†ä¿ç•™ç”±è°ƒåº¦ç¨‹åºé€‰æ‹©çš„ç¦»æ•£æ—¶é—´æ­¥ç¡®å®šçš„å¤§é‡å™ªå£°ã€‚å½“æ­¤ç®¡é“å½¢æˆâ€œå»å™ªå™¨æ··åˆâ€å¤šç®¡é“è®¾ç½®çš„ä¸€éƒ¨åˆ†æ—¶ï¼Œåº”ç†æƒ³åœ°åˆ©ç”¨
    `denoising_end` å‚æ•°ï¼Œå¦‚[`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)ä¸­æ‰€è¿°ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 5.0) â€” Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 5.0) â€” åœ¨[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)ä¸­å®šä¹‰çš„æŒ‡å¯¼æ¯”ä¾‹ã€‚`guidance_scale`
    å®šä¹‰ä¸º[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)ä¸­æ–¹ç¨‹å¼2çš„ `w`ã€‚é€šè¿‡è®¾ç½® `guidance_scale
    > 1` æ¥å¯ç”¨æŒ‡å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„æŒ‡å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆä¸æ–‡æœ¬ `prompt` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚'
- en: '`image_guidance_scale` (`float`, *optional*, defaults to 1.5) â€” Image guidance
    scale is to push the generated image towards the inital image `image`. Image guidance
    scale is enabled by setting `image_guidance_scale > 1`. Higher image guidance
    scale encourages to generate images that are closely linked to the source image
    `image`, usually at the expense of lower image quality. This pipeline requires
    a value of at least `1`.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 1.5) â€” å›¾åƒæŒ‡å¯¼æ¯”ä¾‹ç”¨äºå°†ç”Ÿæˆçš„å›¾åƒæ¨å‘åˆå§‹å›¾åƒ `image`ã€‚é€šè¿‡è®¾ç½®
    `image_guidance_scale > 1` æ¥å¯ç”¨å›¾åƒæŒ‡å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„å›¾åƒæŒ‡å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆä¸æºå›¾åƒ `image` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚æ­¤ç®¡é“éœ€è¦è‡³å°‘
    `1` çš„å€¼ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„è´Ÿé¢æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’ `negative_prompt_embeds`ã€‚å¦‚æœä¸ä½¿ç”¨æŒ‡å¯¼ï¼ˆå³ï¼Œå¦‚æœ
    `guidance_scale` å°äº `1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„è´Ÿé¢æç¤ºï¼Œå°†å‘é€åˆ° `tokenizer_2`
    å’Œ `text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­éƒ½ä½¿ç”¨ `negative_prompt`ã€‚'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” å¯¹åº”äºDDIMè®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ï¼š[https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502)ã€‚ä»…é€‚ç”¨äº[schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œå¯¹å…¶ä»–æƒ…å†µå°†è¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` æˆ– `List[torch.Generator]`, *å¯é€‰*) â€” ä¸€ä¸ªæˆ–å¤šä¸ª[torchç”Ÿæˆå™¨](https://pytorch.org/docs/stable/generated/torch.Generator.html)ï¼Œç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§ã€‚'
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„å˜ˆæ‚æ½œå˜é‡ï¼Œä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨æä¾›çš„éšæœº
    `generator` è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»
    `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿé¢æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆ `negative_prompt_embeds`ã€‚'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ± åŒ–æ–‡æœ¬åµŒå…¥å°†ä»
    `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿé¢æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„è´Ÿé¢æç¤ºåµŒå…¥ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹©åœ¨ [PIL](https://pillow.readthedocs.io/en/stable/)
    ä¸­çš„ `PIL.Image.Image` æˆ– `np.array` ä¹‹é—´ã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` instead
    of a plain tuple.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput`
    è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„ tupleã€‚'
- en: '`callback` (`Callable`, *optional*) â€” A function that will be called every
    `callback_steps` steps during inference. The function will be called with the
    following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *å¯é€‰*) â€” æ¨æ–­æœŸé—´æ¯ `callback_steps` æ­¥è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`ã€‚'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) â€” The frequency at which
    the `callback` function will be called. If not specified, the callback will be
    called at every step.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” `callback` å‡½æ•°å°†è¢«è°ƒç”¨çš„é¢‘ç‡ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†åœ¨æ¯ä¸€æ­¥è°ƒç”¨å›è°ƒå‡½æ•°ã€‚'
- en: '`cross_attention_kwargs` (`dict`, *optional*) â€” A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™ `AttentionProcessor` çš„
    kwargs å­—å…¸ï¼Œå¦‚åœ¨ [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    ä¸­çš„ `self.processor` ä¸­å®šä¹‰ã€‚'
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) â€” Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `Ï†` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_rescale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” [Common Diffusion Noise Schedules
    and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf) æå‡ºçš„æŒ‡å¯¼ç¼©æ”¾å› å­ã€‚`guidance_scale`
    åœ¨ [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    çš„æ–¹ç¨‹å¼ 16 ä¸­å®šä¹‰ã€‚æŒ‡å¯¼ç¼©æ”¾å› å­åº”åœ¨ä½¿ç”¨é›¶ç»ˆç«¯ SNR æ—¶ä¿®å¤è¿‡æ›å…‰é—®é¢˜ã€‚'
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXLâ€™s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`original_size` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º (1024, 1024)) â€” å¦‚æœ `original_size`
    ä¸ `target_size` ä¸åŒï¼Œå›¾åƒå°†å‘ˆç°ä¸ºç¼©å°æˆ–æ”¾å¤§ã€‚å¦‚æœæœªæŒ‡å®šï¼Œ`original_size` é»˜è®¤ä¸º `(height, width)`ã€‚è¿™æ˜¯
    SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    ç¬¬2.2èŠ‚ã€‚'
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) â€” `crops_coords_top_left`
    can be used to generate an image that appears to be â€œcroppedâ€ from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crops_coords_top_left` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º (0, 0)) â€” `crops_coords_top_left`
    å¯ç”¨äºç”Ÿæˆä¸€ä¸ªçœ‹èµ·æ¥ä»ä½ç½® `crops_coords_top_left` å‘ä¸‹â€œè£å‰ªâ€çš„å›¾åƒã€‚é€šå¸¸é€šè¿‡å°† `crops_coords_top_left`
    è®¾ç½®ä¸º (0, 0) æ¥å®ç°æœ‰åˆ©çš„ã€å±…ä¸­çš„å›¾åƒã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    ç¬¬2.2èŠ‚ã€‚'
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size` (`Tuple[int]`, *å¯é€‰*, é»˜è®¤ä¸º (1024, 1024)) â€” å¯¹äºå¤§å¤šæ•°æƒ…å†µï¼Œ`target_size`
    åº”è®¾ç½®ä¸ºç”Ÿæˆå›¾åƒçš„æœŸæœ›é«˜åº¦å’Œå®½åº¦ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º `(height, width)`ã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    ç¬¬2.2èŠ‚ã€‚'
- en: '`aesthetic_score` (`float`, *optional*, defaults to 6.0) â€” Used to simulate
    an aesthetic score of the generated image by influencing the positive text condition.
    Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aesthetic_score` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 6.0) â€” é€šè¿‡å½±å“æ­£æ–‡æ¡ä»¶æ¥æ¨¡æ‹Ÿç”Ÿæˆå›¾åƒçš„ç¾å­¦è¯„åˆ†ã€‚è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    ç¬¬2.2èŠ‚ã€‚'
- en: '`negative_aesthetic_score` (`float`, *optional*, defaults to 2.5) â€” Part of
    SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_aesthetic_score` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 2.5) â€” è¿™æ˜¯ SDXL å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    ç¬¬2.2èŠ‚ã€‚å¯ç”¨äºé€šè¿‡å½±å“è´Ÿé¢æ–‡æœ¬æ¡ä»¶æ¥æ¨¡æ‹Ÿç”Ÿæˆå›¾åƒçš„ç¾å­¦è¯„åˆ†ã€‚'
- en: Returns
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›å€¼
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` or `tuple`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` æˆ– `tuple`'
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple`. When returning a tuple, the first element is a list
    with the generated images.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ `return_dict` ä¸º Trueï¼Œåˆ™è¿”å› `~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput`ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª
    `tuple`ã€‚å½“è¿”å›ä¸€ä¸ª tuple æ—¶ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ã€‚
- en: Function invoked when calling the pipeline for generation.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒç”¨ç®¡é“è¿›è¡Œç”Ÿæˆæ—¶è°ƒç”¨çš„å‡½æ•°ã€‚
- en: 'Examples:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE12]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `disable_freeu`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L648)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L648)'
- en: '[PRE13]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¯ç”¨äº†FreeUæœºåˆ¶ï¼Œåˆ™å°†å…¶ç¦ç”¨ã€‚
- en: '#### `disable_vae_slicing`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L217)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L217)'
- en: '[PRE14]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously invoked,
    this method will go back to computing decoding in one step.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ†ç‰‡VAEè§£ç ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_vae_slicing`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚
- en: '#### `disable_vae_tiling`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L233)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L233)'
- en: '[PRE15]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously invoked, this
    method will go back to computing decoding in one step.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ†ç‰‡VAEè§£ç ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_vae_tiling`ï¼Œåˆ™æ­¤æ–¹æ³•å°†è¿”å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚
- en: '#### `enable_freeu`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L625)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L625)'
- en: '[PRE16]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1`ï¼ˆ`float`ï¼‰â€” ç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚'
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2`ï¼ˆ`float`ï¼‰â€” ç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆæœâ€ã€‚'
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ1çš„ç¼©æ”¾å› å­ã€‚'
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2`ï¼ˆ`float`ï¼‰â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„é˜¶æ®µ2çš„ç¼©æ”¾å› å­ã€‚'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨FreeUæœºåˆ¶ï¼Œå¦‚[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)ä¸­æ‰€è¿°ã€‚
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬è¢«åº”ç”¨çš„é˜¶æ®µã€‚
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚Stable Diffusion
    v1ã€v2å’ŒStable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚
- en: '#### `enable_vae_slicing`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L208)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L208)'
- en: '[PRE17]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Enable sliced VAE decoding.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ†ç‰‡VAEè§£ç ã€‚
- en: When this option is enabled, the VAE will split the input tensor in slices to
    compute decoding in several steps. This is useful to save some memory and allow
    larger batch sizes.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†åˆ†å‰²è¾“å…¥å¼ é‡ä»¥åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç ã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜å¹¶å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°éå¸¸æœ‰ç”¨ã€‚
- en: '#### `enable_vae_tiling`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L224)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L224)'
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Enable tiled VAE decoding.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ†ç‰‡VAEè§£ç ã€‚
- en: When this option is enabled, the VAE will split the input tensor into tiles
    to compute decoding and encoding in several steps. This is useful to save a large
    amount of memory and to allow the processing of larger images.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†åˆ†å‰²è¾“å…¥å¼ é‡ä»¥åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚
- en: '#### `encode_prompt`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L240)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L240)'
- en: '[PRE19]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦ç¼–ç çš„æç¤º'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device â€” (`torch.device`): torch device'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`prompt`ã€‚è®¾å¤‡
    â€” (`torch.device`): torchè®¾å¤‡'
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`ï¼ˆ`int`ï¼‰â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡'
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance`ï¼ˆ`bool`ï¼‰â€” æ˜¯å¦ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚å¦‚æœä¸ä½¿ç”¨æŒ‡å¯¼ï¼ˆå³ï¼Œå¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” ç”¨äºä¸æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºï¼Œå°†å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨`negative_prompt`ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆnegative_prompt_embedsã€‚'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„æ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional`) â€” é¢„ç”Ÿæˆçš„è´Ÿæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–çš„negative_prompt_embedsã€‚'
- en: '`lora_scale` (`float`, *optional*) â€” A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *optional*) â€” å¦‚æœåŠ è½½äº†LoRAå±‚ï¼Œåˆ™å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰LoRAå±‚çš„loraæ¯”ä¾‹ã€‚'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
