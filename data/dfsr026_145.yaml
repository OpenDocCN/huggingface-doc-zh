- en: InstructPix2Pix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: InstructPix2Pix
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/pix2pix](https://huggingface.co/docs/diffusers/api/pipelines/pix2pix)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/pix2pix](https://huggingface.co/docs/diffusers/api/pipelines/pix2pix)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[InstructPix2Pix: Learning to Follow Image Editing Instructions](https://huggingface.co/papers/2211.09800)
    is by Tim Brooks, Aleksander Holynski and Alexei A. Efros.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[InstructPix2Pix：学习遵循图像编辑说明](https://huggingface.co/papers/2211.09800)由Tim
    Brooks、Aleksander Holynski和Alexei A. Efros撰写。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要为：
- en: '*We propose a method for editing images from human instructions: given an input
    image and a written instruction that tells the model what to do, our model follows
    these instructions to edit the image. To obtain training data for this problem,
    we combine the knowledge of two large pretrained models — a language model (GPT-3)
    and a text-to-image model (Stable Diffusion) — to generate a large dataset of
    image editing examples. Our conditional diffusion model, InstructPix2Pix, is trained
    on our generated data, and generalizes to real images and user-written instructions
    at inference time. Since it performs edits in the forward pass and does not require
    per example fine-tuning or inversion, our model edits images quickly, in a matter
    of seconds. We show compelling editing results for a diverse collection of input
    images and written instructions.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了一种根据人类指令编辑图像的方法：给定一个输入图像和一条书面指令告诉模型该做什么，我们的模型遵循这些指令来编辑图像。为了解决这个问题的训练数据，我们结合了两个大型预训练模型的知识-语言模型（GPT-3）和文本到图像模型（稳定扩散）-生成了大量的图像编辑示例数据集。我们的条件扩散模型InstructPix2Pix是在我们生成的数据上训练的，并且在推理时推广到真实图像和用户编写的指令。由于它在前向传递中执行编辑，不需要每个示例的微调或反演，我们的模型可以在几秒钟内快速编辑图像。我们展示了对各种输入图像和书面指令的引人注目的编辑结果。*'
- en: You can find additional information about InstructPix2Pix on the [project page](https://www.timothybrooks.com/instruct-pix2pix),
    [original codebase](https://github.com/timothybrooks/instruct-pix2pix), and try
    it out in a [demo](https://huggingface.co/spaces/timbrooks/instruct-pix2pix).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[项目页面](https://www.timothybrooks.com/instruct-pix2pix)、[原始代码库](https://github.com/timothybrooks/instruct-pix2pix)和[演示](https://huggingface.co/spaces/timbrooks/instruct-pix2pix)中找到有关InstructPix2Pix的其他信息。
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 确保查看调度器指南以了解如何在调度器速度和质量之间进行权衡，并查看重用组件跨管道部分以了解如何有效地将相同组件加载到多个管道中。
- en: StableDiffusionInstructPix2PixPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散指导Pix2Pix管道
- en: '### `class diffusers.StableDiffusionInstructPix2PixPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionInstructPix2PixPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L75)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L75)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL））-
    变分自动编码器（VAE）模型，用于对图像进行编码和解码到和从潜在表示中。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel））-
    冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer））-
    用于对文本进行标记的`CLIPTokenizer`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel））-
    用于去噪编码图像潜在的`UNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin））-
    与`unet`结合使用以去噪编码图像潜在的调度器。可以是[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)或[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)之一。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker`（`StableDiffusionSafetyChecker`）- 估计生成的图像是否可能被视为具有冒犯性或有害性的分类模块。请参考[模型卡片](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`（[CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor））-
    用于从生成的图像中提取特征的`CLIPImageProcessor`；作为`safety_checker`的输入。'
- en: Pipeline for pixel-level image editing by following text instructions (based
    on Stable Diffusion).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 根据文本指令进行像素级图像编辑的流水线（基于 Stable Diffusion）。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有流水线实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该流水线还继承了以下加载方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    用于加载 LoRA 权重'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    用于保存 LoRA 权重'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    用于加载 IP 适配器'
- en: '#### `__call__`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L159)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L159)'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 指导图像生成的提示或提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`image` (`torch.FloatTensor` `np.ndarray`, `PIL.Image.Image`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image` or tensor representing
    an image batch to be repainted according to `prompt`. Can also accept image latents
    as `image`, but if passing latents directly it is not encoded again.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` `np.ndarray`, `PIL.Image.Image`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 表示要根据`prompt`重新绘制的图像批次的`Image`或张量。也可以接受图像潜变量作为`image`，但如果直接传递潜变量，则不会再次编码。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为7.5) — 更高的引导比例值鼓励模型生成与文本`prompt`紧密相关的图像，以降低图像质量为代价。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`image_guidance_scale` (`float`, *optional*, defaults to 1.5) — Push the generated
    image towards the inital `image`. Image guidance scale is enabled by setting `image_guidance_scale
    > 1`. Higher image guidance scale encourages generated images that are closely
    linked to the source `image`, usually at the expense of lower image quality. This
    pipeline requires a value of at least `1`.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_guidance_scale` (`float`, *可选*, 默认为1.5) — 将生成的图像推向初始`image`。设置`image_guidance_scale
    > 1`可以启用图像引导比例。更高的图像引导比例鼓励生成的图像与源`image`紧密相关，通常以降低图像质量为代价。此流水线需要至少`1`的值。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 指导在图像生成中不包括的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。当不使用引导时（`guidance_scale
    < 1`）将被忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *可选*, 默认为0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数
    eta (η)。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度程序中将被忽略。'
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *可选*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 从高斯分布中抽样的预生成噪声潜变量，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则通过使用提供的随机`generator`进行抽样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument. ip_adapter_image — (`PipelineImageInput`, *optional*): Optional
    image input to work with IP Adapters.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，`negative_prompt_embeds`将从`negative_prompt`输入参数生成。ip_adapter_image
    —（`PipelineImageInput`，*可选*）：可选的图像输入以与IP适配器一起使用。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type`（`str`，*可选*，默认为`"pil"`）— 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是普通元组。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end`（`Callable`，*可选*）— 在推断期间每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`将包括由`callback_on_step_end_tensor_inputs`指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs`（`List`，*可选*）— 用于`callback_on_step_end`函数的张量输入列表。列表中指定的张量将作为`callback_kwargs`参数传递。您只能包含在管道类的`._callback_tensor_inputs`属性中列出的变量。'
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个`tuple`，其中第一个元素是生成的图像列表，第二个元素是一个包含相应生成图像是否包含“不适宜工作”（nsfw）内容的`bool`列表。
- en: The call function to the pipeline for generation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `load_textual_inversion`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_textual_inversion`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/textual_inversion.py#L265)'
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike` or `List[str or os.PathLike]`
    or `Dict` or `List[Dict]`) — Can be either one of the following or a list of them:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`或`List[str或os.PathLike]`或`Dict`或`List[Dict]`）—
    可以是以下之一或它们的列表：'
- en: A string, the *model id* (for example `sd-concepts-library/low-poly-hd-logos-icons`)
    of a pretrained model hosted on the Hub.
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型在Hub上托管的*模型ID*（例如`sd-concepts-library/low-poly-hd-logos-icons`）。
- en: A path to a *directory* (for example `./my_text_inversion_directory/`) containing
    the textual inversion weights.
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含文本反转权重的路径为*目录*（例如`./my_text_inversion_directory/）。
- en: A path to a *file* (for example `./my_text_inversions.pt`) containing textual
    inversion weights.
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含文本反转权重的*文件*路径（例如`./my_text_inversions.pt`）。
- en: A [torch state dict](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict).
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个[torch状态字典](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)。
- en: '`token` (`str` or `List[str]`, *optional*) — Override the token to use for
    the textual inversion weights. If `pretrained_model_name_or_path` is a list, then
    `token` must also be a list of equal length.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`str`或`List[str]`，*可选*）— 覆盖用于文本反转权重的令牌。如果`pretrained_model_name_or_path`是列表，则`token`也必须是相同长度的列表。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel),
    *optional*) — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).
    If not specified, function will take self.tokenizer.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)，*可选*）—
    冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。如果未指定，函数将使用self.tokenizer。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer),
    *optional*) — A `CLIPTokenizer` to tokenize text. If not specified, function will
    take self.tokenizer.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)，*可选*）—
    用于标记文本的`CLIPTokenizer`。如果未指定，函数将使用self.tokenizer。'
- en: '`weight_name` (`str`, *optional*) — Name of a custom weight file. This should
    be used when:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_name`（`str`，*可选*）— 自定义权重文件的名称。应在以下情况使用：'
- en: The saved textual inversion file is in 🤗 Diffusers format, but was saved under
    a specific weight name such as `text_inv.bin`.
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存的文本反转文件以🤗 Diffusers格式保存，但是保存在特定权重名称下，例如`text_inv.bin`。
- en: The saved textual inversion file is in the Automatic1111 format.
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存的文本反转文件以Automatic1111格式保存。
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) — 下载预训练模型配置时缓存的目录路径，如果不使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否恢复下载模型权重和配置文件。如果设置为`False`，任何未完全下载的文件将被删除。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理将在每个请求上使用。'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won’t be downloaded from the Hub.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, defaults to `False`) — 是否仅加载本地模型权重和配置文件。如果设置为`True`，模型将不会从Hub下载。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` or *bool*, *optional*) — 用作远程文件HTTP bearer授权的令牌。如果为`True`，则使用从`diffusers-cli
    login`生成的令牌（存储在`~/.huggingface`）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交ID或Git允许的任何标识符。'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) — The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *optional*, defaults to `""`) — 在Hub或本地较大模型存储库中模型文件的子文件夹位置。'
- en: '`mirror` (`str`, *optional*) — Mirror source to resolve accessibility issues
    if you’re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *optional*) — 镜像源，用于解决在中国下载模型时的可访问性问题。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。'
- en: Load Textual Inversion embeddings into the text encoder of [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    (both 🤗 Diffusers and Automatic1111 formats are supported).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本反转嵌入加载到[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)的文本编码器中（支持🤗
    Diffusers和Automatic1111格式）。
- en: 'Example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'To load a Textual Inversion embedding vector in 🤗 Diffusers format:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载🤗 Diffusers格式中的文本反转嵌入向量：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To load a Textual Inversion embedding vector in Automatic1111 format, make sure
    to download the vector first (for example from [civitAI](https://civitai.com/models/3036?modelVersionId=9857))
    and then load the vector
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载Automatic1111格式中的文本反转嵌入向量，请确保首先下载向量（例如从[civitAI](https://civitai.com/models/3036?modelVersionId=9857)），然后加载向量。
- en: 'locally:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本地：
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `load_lora_weights`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `load_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L83)'
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    — See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path_or_dict` (`str` or `os.PathLike` or `dict`)
    — 查看[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)。'
- en: '`kwargs` (`dict`, *optional*) — See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`dict`, *optional*) — 查看[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)。'
- en: '`adapter_name` (`str`, *optional*) — Adapter name to be used for referencing
    the loaded adapter model. If not specified, it will use `default_{i}` where i
    is the total number of adapters being loaded.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *optional*) — 用于引用加载的适配器模型的适配器名称。如果未指定，将使用`default_{i}`，其中i是要加载的适配器总数。'
- en: Load LoRA weights specified in `pretrained_model_name_or_path_or_dict` into
    `self.unet` and `self.text_encoder`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 将在`self.unet`和`self.text_encoder`中加载指定的LoRA权重。
- en: All kwargs are forwarded to `self.lora_state_dict`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 所有kwargs都将转发到`self.lora_state_dict`。
- en: See [lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)
    for more details on how the state dict is loaded.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[lora_state_dict()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.lora_state_dict)以获取有关如何加载状态字典的更多详细信息。
- en: See [load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)
    for more details on how the state dict is loaded into `self.unet`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[load_lora_into_unet()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_unet)以获取有关如何将状态字典加载到`self.unet`的更多详细信息。
- en: See [load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)
    for more details on how the state dict is loaded into `self.text_encoder`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[load_lora_into_text_encoder()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_into_text_encoder)以获取有关如何将状态字典加载到`self.text_encoder`的更多详细信息。
- en: '#### `save_lora_weights`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_lora_weights`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/lora.py#L869)'
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory to save LoRA parameters
    to. Will be created if it doesn’t exist.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` or `os.PathLike`) — 保存LoRA参数的目录。如果不存在，将被创建。'
- en: '`unet_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    — State dict of the LoRA layers corresponding to the `unet`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet_lora_layers`（`Dict[str, torch.nn.Module]`或`Dict[str, torch.Tensor]`）—
    与`unet`对应的LoRA层的状态字典。'
- en: '`text_encoder_lora_layers` (`Dict[str, torch.nn.Module]` or `Dict[str, torch.Tensor]`)
    — State dict of the LoRA layers corresponding to the `text_encoder`. Must explicitly
    pass the text encoder LoRA state dict because it comes from 🤗 Transformers.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_lora_layers`（`Dict[str, torch.nn.Module]`或`Dict[str, torch.Tensor]`）—
    与`text_encoder`对应的LoRA层的状态字典。必须显式传递文本编码器LoRA状态字典，因为它来自🤗 Transformers。'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) — Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process`（`bool`，*可选*，默认为`True`）— 调用此函数的进程是否为主进程。在分布式训练期间很有用，当您需要在所有进程上调用此函数时。在这种情况下，仅在主进程上设置`is_main_process=True`，以避免竞争条件。'
- en: '`save_function` (`Callable`) — The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function`（`Callable`）— 用于保存状态字典的函数。在分布式训练期间，当您需要用另一种方法替换`torch.save`时很有用。可以通过环境变量`DIFFUSERS_SAVE_MODE`进行配置。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization`（`bool`，*可选*，默认为`True`）— 是否使用`safetensors`保存模型，还是使用传统的PyTorch方式与`pickle`。'
- en: Save the LoRA parameters corresponding to the UNet and text encoder.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 保存与UNet和文本编码器对应的LoRA参数。
- en: '#### `disable_freeu`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L832)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L832)'
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用了启用的FreeU机制。
- en: '#### `enable_freeu`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L809)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py#L809)'
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1`（`float`）— 用于阻尼跳过特征贡献的阶段1的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效果”。'
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2`（`float`）— 用于阻尼跳过特征贡献的阶段2的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效果”。'
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1`（`float`）— 用于放大骨干特征贡献的阶段1的缩放因子。'
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2`（`float`）— 用于放大骨干特征贡献的阶段2的缩放因子。'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 启用了FreeU机制，如[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)中所述。
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子后缀表示它们被应用的阶段。
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同管道（如Stable Diffusion
    v1、v2和Stable Diffusion XL）的值组合。
- en: StableDiffusionXLInstructPix2PixPipeline
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionXLInstructPix2PixPipeline
- en: '### `class diffusers.StableDiffusionXLInstructPix2PixPipeline`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionXLInstructPix2PixPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L120)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L120)'
- en: '[PRE10]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)）—
    变分自动编码器（VAE）模型，用于对图像进行编码和解码以及从潜在表示中。'
- en: '`text_encoder` (`CLIPTextModel`) — Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（`CLIPTextModel`）— 冻结的文本编码器。Stable Diffusion XL使用[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)的文本部分，具体是[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)变体。'
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) — Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_2`（`CLIPTextModelWithProjection`）— 第二个冻结的文本编码器。Stable Diffusion
    XL使用[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection)的文本和池部分，具体是[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)变体。'
- en: '`tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`CLIPTokenizer`）— 类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`tokenizer_2` (`CLIPTokenizer`) — Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_2` (`CLIPTokenizer`) — 第二个类的Tokenizer [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪编码图像潜在特征的条件U-Net架构。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 与`unet`结合使用的调度器，用于去噪编码图像潜在特征。可以是[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)或[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)之一。'
- en: '`requires_aesthetics_score` (`bool`, *optional*, defaults to `"False"`) — Whether
    the `unet` requires a aesthetic_score condition to be passed during inference.
    Also see the config of `stabilityai/stable-diffusion-xl-refiner-1-0`.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requires_aesthetics_score` (`bool`, *可选*, 默认为`"False"`) — `unet`在推断期间是否需要通过审美评分条件。也请参阅`stabilityai/stable-diffusion-xl-refiner-1-0`的配置。'
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) —
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_zeros_for_empty_prompt` (`bool`, *可选*, 默认为`"True"`) — 是否强制将负提示嵌入始终设置为0。也请参阅`stabilityai/stable-diffusion-xl-base-1-0`的配置。'
- en: '`add_watermarker` (`bool`, *optional*) — Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_watermarker` (`bool`, *可选*) — 是否使用[invisible_watermark库](https://github.com/ShieldMnt/invisible-watermark/)来给输出图像添加水印。如果未定义，且该软件包已安装，则默认为True，否则将不使用水印。'
- en: Pipeline for pixel-level image editing by following text instructions. Based
    on Stable Diffusion XL.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 基于稳定扩散XL的像素级图像编辑流水线，通过以下文本指令。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有流水线实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 该流水线还继承了以下加载方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    用于加载`.ckpt`文件'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    用于加载LoRA权重'
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_lora_weights()` 用于保存LoRA权重'
- en: '#### `__call__`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L652)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L652)'
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 引导图像生成的提示或提示。如果未定义，则必须传递`prompt_embeds`。'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2` (`str` 或 `List[str]`, *可选*) — 发送到`tokenizer_2`和`text_encoder_2`的提示或提示。如果未定义，则在两个文本编码器中使用`prompt`。'
- en: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `np.ndarray` or `List[torch.FloatTensor]`
    or `List[PIL.Image.Image]` or `List[np.ndarray]`) — The image(s) to modify with
    the pipeline.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` 或 `PIL.Image.Image` 或 `np.ndarray` 或 `List[torch.FloatTensor]`
    或 `List[PIL.Image.Image]` 或 `List[np.ndarray]`) — 要使用流水线修改的图像。'
- en: '`height` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    — The height in pixels of the generated image.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为self.unet.config.sample_size * self.vae_scale_factor)
    — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    — The width in pixels of the generated image.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为self.unet.config.sample_size * self.vae_scale_factor)
    — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推断速度。'
- en: '`denoising_end` (`float`, *optional*) — When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise as determined by the discrete timesteps
    selected by the scheduler. The denoising_end parameter should ideally be utilized
    when this pipeline forms a part of a “Mixture of Denoisers” multi-pipeline setup,
    as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`denoising_end` (`float`, *可选*) — 当指定时，确定在有意提前终止之前完成的总去噪过程的分数（介于0.0和1.0之间）。因此，返回的样本仍将保留由调度程序选择的离散时间步确定的大量噪声。当此管道形成“去噪器混合”多管道设置的一部分时，应理想地利用
    `denoising_end` 参数，如[`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)中所述。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 5.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 5.0) — 在[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale`
    定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式2的 `w`。通过设置 `guidance_scale
    > 1` 来启用指导比例。更高的指导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`image_guidance_scale` (`float`, *optional*, defaults to 1.5) — Image guidance
    scale is to push the generated image towards the inital image `image`. Image guidance
    scale is enabled by setting `image_guidance_scale > 1`. Higher image guidance
    scale encourages to generate images that are closely linked to the source image
    `image`, usually at the expense of lower image quality. This pipeline requires
    a value of at least `1`.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_guidance_scale` (`float`, *可选*, 默认为 1.5) — 图像指导比例用于将生成的图像推向初始图像 `image`。通过设置
    `image_guidance_scale > 1` 来启用图像指导比例。更高的图像指导比例鼓励生成与源图像 `image` 密切相关的图像，通常以降低图像质量为代价。此管道需要至少
    `1` 的值。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成的负面提示。如果未定义，则必须传递 `negative_prompt_embeds`。如果不使用指导（即，如果
    `guidance_scale` 小于 `1`，则忽略）。'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成的负面提示，将发送到 `tokenizer_2`
    和 `text_encoder_2`。如果未定义，则在两个文本编码器中都使用 `negative_prompt`。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *可选*, 默认为 0.0) — 对应于DDIM论文中的参数 eta (η)：[https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502)。仅适用于[schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，对其他情况将被忽略。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，文本嵌入将从
    `prompt` 输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负面文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从
    `negative_prompt` 输入参数生成 `negative_prompt_embeds`。'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的池化文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，池化文本嵌入将从
    `prompt` 输入参数生成。'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负面池化文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从
    `negative_prompt` 输入参数生成池化的负面提示嵌入。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。选择在 [PIL](https://pillow.readthedocs.io/en/stable/)
    中的 `PIL.Image.Image` 或 `np.array` 之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` instead
    of a plain tuple.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回一个 `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput`
    而不是一个普通的 tuple。'
- en: '`callback` (`Callable`, *optional*) — A function that will be called every
    `callback_steps` steps during inference. The function will be called with the
    following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 推断期间每 `callback_steps` 步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function will be called. If not specified, the callback will be
    called at every step.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为 1) — `callback` 函数将被调用的频率。如果未指定，将在每一步调用回调函数。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *可选*) — 如果指定，将传递给 `AttentionProcessor` 的
    kwargs 字典，如在 [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    中的 `self.processor` 中定义。'
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) — Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `φ` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_rescale` (`float`, *可选*, 默认为 0.0) — [Common Diffusion Noise Schedules
    and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf) 提出的指导缩放因子。`guidance_scale`
    在 [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    的方程式 16 中定义。指导缩放因子应在使用零终端 SNR 时修复过曝光问题。'
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) — If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXL’s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`original_size` (`Tuple[int]`, *可选*, 默认为 (1024, 1024)) — 如果 `original_size`
    与 `target_size` 不同，图像将呈现为缩小或放大。如果未指定，`original_size` 默认为 `(height, width)`。这是
    SDXL 微调节的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) — `crops_coords_top_left`
    can be used to generate an image that appears to be “cropped” from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crops_coords_top_left` (`Tuple[int]`, *可选*, 默认为 (0, 0)) — `crops_coords_top_left`
    可用于生成一个看起来从位置 `crops_coords_top_left` 向下“裁剪”的图像。通常通过将 `crops_coords_top_left`
    设置为 (0, 0) 来实现有利的、居中的图像。这是 SDXL 微调节的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) — For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size` (`Tuple[int]`, *可选*, 默认为 (1024, 1024)) — 对于大多数情况，`target_size`
    应设置为生成图像的期望高度和宽度。如果未指定，将默认为 `(height, width)`。这是 SDXL 微调节的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`aesthetic_score` (`float`, *optional*, defaults to 6.0) — Used to simulate
    an aesthetic score of the generated image by influencing the positive text condition.
    Part of SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aesthetic_score` (`float`, *可选*, 默认为 6.0) — 通过影响正文条件来模拟生成图像的美学评分。这是 SDXL 微调节的一部分，详见
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`negative_aesthetic_score` (`float`, *optional*, defaults to 2.5) — Part of
    SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_aesthetic_score` (`float`, *可选*, 默认为 2.5) — 这是 SDXL 微调节的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。可用于通过影响负面文本条件来模拟生成图像的美学评分。'
- en: Returns
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` or `tuple`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` 或 `tuple`'
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple`. When returning a tuple, the first element is a list
    with the generated images.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `return_dict` 为 True，则返回 `~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput`，否则返回一个
    `tuple`。当返回一个 tuple 时，第一个元素是包含生成图像的列表。
- en: Function invoked when calling the pipeline for generation.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `disable_freeu`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L648)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L648)'
- en: '[PRE13]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了FreeU机制，则将其禁用。
- en: '#### `disable_vae_slicing`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L217)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L217)'
- en: '[PRE14]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously invoked,
    this method will go back to computing decoding in one step.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用分片VAE解码。如果之前调用了`enable_vae_slicing`，则此方法将返回到一步计算解码。
- en: '#### `disable_vae_tiling`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L233)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L233)'
- en: '[PRE15]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously invoked, this
    method will go back to computing decoding in one step.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用分片VAE解码。如果之前调用了`enable_vae_tiling`，则此方法将返回到一步计算解码。
- en: '#### `enable_freeu`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L625)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L625)'
- en: '[PRE16]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1`（`float`）— 用于减弱跳过特征贡献的阶段1的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效果”。'
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2`（`float`）— 用于减弱跳过特征贡献的阶段2的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效果”。'
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1`（`float`）— 用于放大骨干特征贡献的阶段1的缩放因子。'
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2`（`float`）— 用于放大骨干特征贡献的阶段2的缩放因子。'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 启用FreeU机制，如[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)中所述。
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子后缀表示它们被应用的阶段。
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同管道（如Stable Diffusion
    v1、v2和Stable Diffusion XL）的值组合。
- en: '#### `enable_vae_slicing`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L208)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L208)'
- en: '[PRE17]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Enable sliced VAE decoding.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 启用分片VAE解码。
- en: When this option is enabled, the VAE will split the input tensor in slices to
    compute decoding in several steps. This is useful to save some memory and allow
    larger batch sizes.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用此选项时，VAE将分割输入张量以在多个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `enable_vae_tiling`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L224)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L224)'
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Enable tiled VAE decoding.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 启用分片VAE解码。
- en: When this option is enabled, the VAE will split the input tensor into tiles
    to compute decoding and encoding in several steps. This is useful to save a large
    amount of memory and to allow the processing of larger images.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用此选项时，VAE将分割输入张量以在多个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `encode_prompt`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L240)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py#L240)'
- en: '[PRE19]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`，*可选*）— 要编码的提示'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device — (`torch.device`): torch device'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2`（`str`或`List[str]`，*可选*）— 要发送到`tokenizer_2`和`text_encoder_2`的提示。如果未定义，则在两个文本编码器中使用`prompt`。设备
    — (`torch.device`): torch设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`（`int`）— 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance`（`bool`）— 是否使用分类器自由指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`（`str`或`List[str]`，*可选*）— 不用于指导图像生成的提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用指导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — 用于不指导图像生成的提示或提示，将发送到`tokenizer_2`和`text_encoder_2`。如果未定义，则在两个文本编码器中使用`negative_prompt`。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成negative_prompt_embeds。'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的池化文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成池化的文本嵌入。'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional`) — 预生成的负池化文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成池化的negative_prompt_embeds。'
- en: '`lora_scale` (`float`, *optional*) — A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *optional*) — 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的lora比例。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
