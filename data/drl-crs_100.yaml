- en: Hands-on
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®è·µ
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit8/hands-on-cleanrl](https://huggingface.co/learn/deep-rl-course/unit8/hands-on-cleanrl)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/learn/deep-rl-course/unit8/hands-on-cleanrl](https://huggingface.co/learn/deep-rl-course/unit8/hands-on-cleanrl)
- en: '[![Ask a Question](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit8/unit8_part1.ipynb)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[![æé—®](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit8/unit8_part1.ipynb)'
- en: Now that we studied the theory behind PPO, the best way to understand how it
    worksÂ **is to implement it from scratch.**
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ç ”ç©¶äº†PPOèƒŒåçš„ç†è®ºï¼Œç†è§£å®ƒçš„æœ€ä½³æ–¹æ³•**æ˜¯ä»å¤´å¼€å§‹å®ç°å®ƒ**ã€‚
- en: Implementing an architecture from scratch is the best way to understand it,
    and itâ€™s a good habit. We have already done it for a value-based method with Q-Learning
    and a Policy-based method with Reinforce.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å¤´å¼€å§‹å®ç°æ¶æ„æ˜¯ç†è§£å®ƒçš„æœ€ä½³æ–¹æ³•ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚æˆ‘ä»¬å·²ç»ä¸ºåŸºäºä»·å€¼çš„Qå­¦ä¹ æ–¹æ³•å’ŒåŸºäºç­–ç•¥çš„Reinforceæ–¹æ³•åšè¿‡äº†ã€‚
- en: 'So, to be able to code it, weâ€™re going to use two resources:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸ºäº†èƒ½å¤Ÿç¼–å†™ä»£ç ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªèµ„æºï¼š
- en: A tutorial made by [Costa Huang](https://github.com/vwxyzjn). Costa is behind
    [CleanRL](https://github.com/vwxyzjn/cleanrl), a Deep Reinforcement Learning library
    that provides high-quality single-file implementation with research-friendly features.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±[Costa Huang](https://github.com/vwxyzjn)åˆ¶ä½œçš„æ•™ç¨‹ã€‚Costaæ˜¯[CleanRL](https://github.com/vwxyzjn/cleanrl)èƒŒåçš„äººï¼Œè¿™æ˜¯ä¸€ä¸ªæä¾›é«˜è´¨é‡å•æ–‡ä»¶å®ç°å’Œç ”ç©¶å‹å¥½åŠŸèƒ½çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ã€‚
- en: In addition to the tutorial, to go deeper, you can read the 13 core implementation
    details:Â [https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†æ•™ç¨‹å¤–ï¼Œä¸ºäº†æ›´æ·±å…¥åœ°äº†è§£ï¼Œæ‚¨å¯ä»¥é˜…è¯»13ä¸ªæ ¸å¿ƒå®ç°ç»†èŠ‚ï¼š[https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)
- en: 'Then, to test its robustness, weâ€™re going to train it in:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œä¸ºäº†æµ‹è¯•å…¶ç¨³å¥æ€§ï¼Œæˆ‘ä»¬å°†åœ¨ä»¥ä¸‹è¿›è¡Œè®­ç»ƒï¼š
- en: '[LunarLander-v2](https://www.gymlibrary.ml/environments/box2d/lunar_lander/)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LunarLander-v2](https://www.gymlibrary.ml/environments/box2d/lunar_lander/)'
- en: <assets/63_deep_rl_intro/lunarlander.mp4>
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/63_deep_rl_intro/lunarlander.mp4>
- en: And finally, we will push the trained model to the Hub to evaluate and visualize
    your agent playing.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å°†æŠŠè®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ°Hubï¼Œä»¥è¯„ä¼°å’Œå¯è§†åŒ–æ‚¨çš„ä»£ç†æ¸¸æˆã€‚
- en: LunarLander-v2 is the first environment you used when you started this course.
    At that time, you didnâ€™t know how it worked, and now you can code it from scratch
    and train it.Â **How incredible is that ğŸ¤©.**
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: LunarLander-v2æ˜¯æ‚¨å¼€å§‹æœ¬è¯¾ç¨‹æ—¶ä½¿ç”¨çš„ç¬¬ä¸€ä¸ªç¯å¢ƒã€‚é‚£æ—¶ï¼Œæ‚¨ä¸çŸ¥é“å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œç°åœ¨æ‚¨å¯ä»¥ä»å¤´å¼€å§‹ç¼–å†™ä»£ç å¹¶è¿›è¡Œè®­ç»ƒã€‚**è¿™æ˜¯å¤šä¹ˆä»¤äººéš¾ä»¥ç½®ä¿¡çš„
    ğŸ¤©ã€‚**
- en: '[https://giphy.com/embed/pynZagVcYxVUk](https://giphy.com/embed/pynZagVcYxVUk)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://giphy.com/embed/pynZagVcYxVUk](https://giphy.com/embed/pynZagVcYxVUk)'
- en: '[via GIPHY](https://giphy.com/gifs/the-office-michael-heartbreak-pynZagVcYxVUk)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[é€šè¿‡GIPHY](https://giphy.com/gifs/the-office-michael-heartbreak-pynZagVcYxVUk)'
- en: Letâ€™s get started! ğŸš€
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼ğŸš€
- en: 'The colab notebook:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: colabç¬”è®°æœ¬ï¼š
- en: '[![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit8/unit8_part1.ipynb)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit8/unit8_part1.ipynb)'
- en: 'Unit 8: Proximal Policy Gradient (PPO) with PyTorch ğŸ¤–'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Unit 8: ä½¿ç”¨PyTorchè¿›è¡ŒProximal Policy Gradientï¼ˆPPOï¼‰ğŸ¤–'
- en: '![Unit 8](../Images/99ae9849fcb07d6d32b6cef4d05623c4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![Unit 8](../Images/99ae9849fcb07d6d32b6cef4d05623c4.png)'
- en: In this notebook, youâ€™ll learn to **code your PPO agent from scratch with PyTorch
    using CleanRL implementation as model**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç¬”è®°æœ¬ä¸­ï¼Œæ‚¨å°†å­¦ä¹ **ä½¿ç”¨PyTorchä»å¤´å¼€å§‹ç¼–å†™æ‚¨çš„PPOä»£ç†ï¼Œä½¿ç”¨CleanRLå®ç°ä½œä¸ºæ¨¡å‹**ã€‚
- en: 'To test its robustness, weâ€™re going to train it in:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æµ‹è¯•å…¶ç¨³å¥æ€§ï¼Œæˆ‘ä»¬å°†åœ¨ä»¥ä¸‹è¿›è¡Œè®­ç»ƒï¼š
- en: '[LunarLander-v2 ğŸš€](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LunarLander-v2 ğŸš€](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)'
- en: Weâ€™re constantly trying to improve our tutorials, so **if you find some issues
    in this notebook**, please [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ–­åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœæ‚¨åœ¨æœ¬ç¬”è®°æœ¬ä¸­å‘ç°é—®é¢˜**ï¼Œè¯·åœ¨GitHub Repoä¸Š[æå‡ºé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)ã€‚
- en: Objectives of this notebook ğŸ†
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ¬ç¬”è®°æœ¬çš„ç›®æ ‡ ğŸ†
- en: 'At the end of the notebook, you will:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬”è®°æœ¬çš„æœ«å°¾ï¼Œæ‚¨å°†ï¼š
- en: Be able to **code your PPO agent from scratch using PyTorch**.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èƒ½å¤Ÿ**ä½¿ç”¨PyTorchä»å¤´å¼€å§‹ç¼–å†™æ‚¨çš„PPOä»£ç†**ã€‚
- en: Be able to **push your trained agent and the code to the Hub** with a nice video
    replay and an evaluation score ğŸ”¥.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èƒ½å¤Ÿ**å°†æ‚¨è®­ç»ƒçš„ä»£ç†å’Œä»£ç æ¨é€åˆ°Hub**ï¼Œå¹¶é™„å¸¦ä¸€ä¸ªæ¼‚äº®çš„è§†é¢‘å›æ”¾å’Œè¯„ä¼°åˆ†æ•°ğŸ”¥ã€‚
- en: Prerequisites ğŸ—ï¸
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…ˆå†³æ¡ä»¶ ğŸ—ï¸
- en: 'Before diving into the notebook, you need to:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ·±å…¥ç ”ç©¶ç¬”è®°æœ¬ä¹‹å‰ï¼Œæ‚¨éœ€è¦ï¼š
- en: ğŸ”² ğŸ“š Study [PPO by reading Unit 8](https://huggingface.co/deep-rl-course/unit8/introduction)
    ğŸ¤—
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”² ğŸ“š å­¦ä¹ [PPOï¼Œé˜…è¯»ç¬¬8å•å…ƒ](https://huggingface.co/deep-rl-course/unit8/introduction)
    ğŸ¤—
- en: To validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process),
    you need to push one model, we donâ€™t ask for a minimal result but we **advise
    you to try different hyperparameters settings to get better results**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†éªŒè¯è¿™ä¸ªå®è·µè¿‡ç¨‹çš„[è®¤è¯è¿‡ç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)ï¼Œæ‚¨éœ€è¦æ¨é€ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬ä¸è¦æ±‚æœ€å°ç»“æœï¼Œä½†æˆ‘ä»¬**å»ºè®®æ‚¨å°è¯•ä¸åŒçš„è¶…å‚æ•°è®¾ç½®ä»¥è·å¾—æ›´å¥½çš„ç»“æœ**ã€‚
- en: If you donâ€™t find your model, **go to the bottom of the page and click on the
    refresh button**
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‰¾ä¸åˆ°æ‚¨çš„æ¨¡å‹ï¼Œ**è¯·è½¬åˆ°é¡µé¢åº•éƒ¨å¹¶å•å‡»åˆ·æ–°æŒ‰é’®**
- en: For more information about the certification process, check this section ğŸ‘‰ [https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³è®¤è¯è¿‡ç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰[https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
- en: Set the GPU ğŸ’ª
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¾ç½®GPU ğŸ’ª
- en: To **accelerate the agentâ€™s training, weâ€™ll use a GPU**. To do that, go to `Runtime
    > Change Runtime type`
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†**åŠ é€Ÿä»£ç†çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨GPU**ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œè¯·è½¬åˆ°`è¿è¡Œæ—¶ > æ›´æ”¹è¿è¡Œæ—¶ç±»å‹`
- en: '![GPU Step 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![GPU Step 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
- en: '`Hardware Accelerator > GPU`'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ç¡¬ä»¶åŠ é€Ÿå™¨ > GPU`'
- en: '![GPU Step 2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![GPUæ­¥éª¤2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
- en: Create a virtual display ğŸ”½
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ˜¾ç¤º ğŸ”½
- en: During the notebook, weâ€™ll need to generate a replay video. To do so, with colab,
    **we need to have a virtual screen to be able to render the environment** (and
    thus record the frames).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªé‡æ’­è§†é¢‘ã€‚ä¸ºæ­¤ï¼Œåœ¨colabä¸­ï¼Œ**æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ¥æ¸²æŸ“ç¯å¢ƒ**ï¼ˆä»è€Œè®°å½•å¸§ï¼‰ã€‚
- en: Hence the following cell will install the librairies and create and run a virtual
    screen ğŸ–¥
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä»¥ä¸‹å•å…ƒæ ¼å°†å®‰è£…åº“å¹¶åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªè™šæ‹Ÿå±å¹• ğŸ–¥
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Install dependencies ğŸ”½
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®‰è£…ä¾èµ– ğŸ”½
- en: For this exercise, we use `gym==0.21` because the video was recorded with Gym.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªç»ƒä¹ ï¼Œæˆ‘ä»¬ä½¿ç”¨`gym==0.21`ï¼Œå› ä¸ºè§†é¢‘æ˜¯ç”¨Gymå½•åˆ¶çš„ã€‚
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Letâ€™s code PPO from scratch with Costa Huangâ€™s tutorial
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»å¤´å¼€å§‹ç”¨Costa Huangçš„æ•™ç¨‹ç¼–å†™PPO
- en: For the core implementation of PPO weâ€™re going to use the excellent [Costa Huang](https://costa.sh/)
    tutorial.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºPPOçš„æ ¸å¿ƒå®ç°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¼˜ç§€çš„[Costa Huang](https://costa.sh/)æ•™ç¨‹ã€‚
- en: 'In addition to the tutorial, to go deeper you can read the 37 core implementation
    details: [https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†æ•™ç¨‹ï¼Œè¦æ·±å…¥äº†è§£ï¼Œæ‚¨å¯ä»¥é˜…è¯»37ä¸ªæ ¸å¿ƒå®ç°ç»†èŠ‚ï¼š[https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)
- en: 'ğŸ‘‰ The video tutorial: [https://youtu.be/MEt6rrxH8W4](https://youtu.be/MEt6rrxH8W4)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‰ è§†é¢‘æ•™ç¨‹ï¼š[https://youtu.be/MEt6rrxH8W4](https://youtu.be/MEt6rrxH8W4)
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Add the Hugging Face Integration ğŸ¤—
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ·»åŠ Hugging Faceé›†æˆ ğŸ¤—
- en: In order to push our model to the Hub, we need to define a function `package_to_hub`
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†æˆ‘ä»¬çš„æ¨¡å‹æ¨é€åˆ°Hubï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ª`package_to_hub`å‡½æ•°
- en: Add dependencies we need to push our model to the Hub
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ æˆ‘ä»¬éœ€è¦å°†æ¨¡å‹æ¨é€åˆ°Hubçš„ä¾èµ–é¡¹
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Add new argument in `parse_args()` function to define the repo-id where we want
    to push the model.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨`parse_args()`å‡½æ•°ä¸­æ·»åŠ æ–°å‚æ•°ï¼Œä»¥å®šä¹‰æˆ‘ä»¬è¦æ¨é€æ¨¡å‹çš„repo-idã€‚
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next, we add the methods needed to push the model to the Hub
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ·»åŠ æ¨é€æ¨¡å‹åˆ°Hubæ‰€éœ€çš„æ–¹æ³•
- en: 'These methods will:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›æ–¹æ³•å°†ï¼š
- en: '`_evalutate_agent()`: evaluate the agent.'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_evalutate_agent()`: è¯„ä¼°ä»£ç†ã€‚'
- en: '`_generate_model_card()`: generate the model card of your agent.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_generate_model_card()`: ç”Ÿæˆæ‚¨çš„ä»£ç†çš„æ¨¡å‹å¡ç‰‡ã€‚'
- en: '`_record_video()`: record a video of your agent.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_record_video()`: è®°å½•æ‚¨çš„ä»£ç†çš„è§†é¢‘ã€‚'
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, we call this function at the end of the PPO training
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œåœ¨PPOè®­ç»ƒç»“æŸæ—¶è°ƒç”¨è¿™ä¸ªå‡½æ•°
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Hereâ€™s what the final ppo.py file looks like:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœ€ç»ˆppo.pyæ–‡ä»¶çš„æ ·å­ï¼š
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To be able to share your model with the community there are three more steps
    to follow:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†èƒ½å¤Ÿä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ï¼Œè¿˜æœ‰ä¸‰ä¸ªæ­¥éª¤è¦éµå¾ªï¼š
- en: 1ï¸âƒ£ (If itâ€™s not already done) create an account to HF â¡ [https://huggingface.co/join](https://huggingface.co/join)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ (å¦‚æœå°šæœªå®Œæˆ) åˆ›å»ºä¸€ä¸ªHFå¸æˆ· â¡ [https://huggingface.co/join](https://huggingface.co/join)
- en: 2ï¸âƒ£ Sign in and get your authentication token from the Hugging Face website.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ ç™»å½•å¹¶ä»Hugging Faceç½‘ç«™è·å–æ‚¨çš„èº«ä»½éªŒè¯ä»¤ç‰Œã€‚
- en: Create a new token ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
    **with write role**
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ–°çš„ä»¤ç‰Œ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
    **å…·æœ‰å†™å…¥æƒé™**
- en: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![åˆ›å»ºHFä»¤ç‰Œ](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
- en: Copy the token
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤åˆ¶ä»¤ç‰Œ
- en: Run the cell below and paste the token
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å¹¶ç²˜è´´ä»¤ç‰Œ
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you donâ€™t want to use Google Colab or a Jupyter Notebook, you need to use
    this command instead: `huggingface-cli login`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨Google Colabæˆ–Jupyter Notebookï¼Œæ‚¨éœ€è¦ä½¿ç”¨è¿™ä¸ªå‘½ä»¤ï¼š`huggingface-cli login`
- en: Letâ€™s start the training ğŸ”¥
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹è®­ç»ƒ ğŸ”¥
- en: âš ï¸ âš ï¸ âš ï¸ Donâ€™t use **the same repo id with the one you used for the Unit 1**
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ âš ï¸ âš ï¸ ä¸è¦ä½¿ç”¨**ä¸æ‚¨åœ¨ç¬¬1å•å…ƒä¸­ä½¿ç”¨çš„ç›¸åŒçš„repo id**
- en: Now that youâ€™ve coded PPO from scratch and added the Hugging Face Integration,
    weâ€™re ready to start the training ğŸ”¥
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»ä»å¤´å¼€å§‹ç¼–å†™äº†PPOå¹¶æ·»åŠ äº†Hugging Faceé›†æˆï¼Œæˆ‘ä»¬å‡†å¤‡å¼€å§‹è®­ç»ƒ ğŸ”¥
- en: First, you need to copy all your code to a file you create called `ppo.py`
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæ‚¨éœ€è¦å°†æ‰€æœ‰ä»£ç å¤åˆ¶åˆ°ä¸€ä¸ªåä¸º`ppo.py`çš„æ–‡ä»¶ä¸­
- en: '![PPO](../Images/c6a57155d0c4da38fd607c740b13277e.png) ![PPO](../Images/2fd5c967c9514b78a4b2bbbefa476afd.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![PPO](../Images/c6a57155d0c4da38fd607c740b13277e.png) ![PPO](../Images/2fd5c967c9514b78a4b2bbbefa476afd.png)'
- en: Now we just need to run this python script using `python <name-of-python-script>.py`
    with the additional parameters we defined using `argparse`
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬åªéœ€è¦ä½¿ç”¨`python <name-of-python-script>.py`è¿è¡Œè¿™ä¸ªpythonè„šæœ¬ï¼Œä½¿ç”¨æˆ‘ä»¬å®šä¹‰çš„é¢å¤–å‚æ•°`argparse`
- en: You should modify more hyperparameters otherwise the training will not be super
    stable.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨åº”è¯¥ä¿®æ”¹æ›´å¤šè¶…å‚æ•°ï¼Œå¦åˆ™è®­ç»ƒå°†ä¸ä¼šå¾ˆç¨³å®šã€‚
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Some additional challenges ğŸ†
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸€äº›é¢å¤–çš„æŒ‘æˆ˜ ğŸ†
- en: The best way to learn **is to try things on your own**! Why not try another
    environment? Or why not trying to modify the implementation to work with Gymnasium?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ çš„æœ€ä½³æ–¹å¼**æ˜¯è‡ªå·±å°è¯•**ï¼ä¸ºä»€ä¹ˆä¸å°è¯•å¦ä¸€ä¸ªç¯å¢ƒï¼Ÿæˆ–è€…ä¸ºä»€ä¹ˆä¸å°è¯•ä¿®æ”¹å®ç°ä»¥é€‚ç”¨äºä½“è‚²é¦†ï¼Ÿ
- en: See you in Unit 8, part 2 where weâ€™re going to train agents to play Doom ğŸ”¥
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç¬¬8å•å…ƒçš„ç¬¬2éƒ¨åˆ†è§ï¼Œé‚£é‡Œæˆ‘ä»¬å°†è®­ç»ƒä»£ç†ç©æ¯ç­ ğŸ”¥
- en: Keep learning, stay awesome ğŸ¤—
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»§ç»­å­¦ä¹ ï¼Œä¿æŒå‡ºè‰² ğŸ¤—
