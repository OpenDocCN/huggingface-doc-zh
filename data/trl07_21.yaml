- en: Examples
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: 'Original text: [https://huggingface.co/docs/trl/example_overview](https://huggingface.co/docs/trl/example_overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/trl/example_overview](https://huggingface.co/docs/trl/example_overview)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'The examples should work in any of the following settings (with the same script):'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例应该在以下任何设置中运行（使用相同的脚本）：
- en: single GPU
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单GPU
- en: multi GPUS (using PyTorch distributed mode)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多GPU（使用PyTorch分布式模式）
- en: multi GPUS (using DeepSpeed ZeRO-Offload stages 1, 2, & 3)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多GPU（使用DeepSpeed ZeRO-Offload阶段1、2和3）
- en: fp16 (mixed-precision), fp32 (normal precision), or bf16 (bfloat16 precision)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fp16（混合精度），fp32（正常精度）或bf16（bfloat16精度）
- en: To run it in each of these various modes, first initialize the accelerate configuration
    with `accelerate config`
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要在这些不同模式中运行它，请首先使用`accelerate config`初始化加速配置
- en: '**NOTE to train with a 4-bit or 8-bit model**, please run'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：要训练4位或8位模型，请运行**'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Accelerate Config
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加速配置
- en: 'For all the examples, you’ll need to generate a 🤗 Accelerate config file with:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有示例，您需要生成一个🤗 Accelerate配置文件：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then, it is encouraged to launch jobs with `accelerate launch`!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，鼓励使用`accelerate launch`启动作业！
- en: Maintained Examples
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维护的示例
- en: '| File | Description |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 文件 | 描述 |'
- en: '| --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| [`examples/scripts/sft.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
    | This script shows how to use the `SFTTrainer` to fine tune a model or adapters
    into a target dataset. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/sft.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
    | 此脚本展示了如何使用`SFTTrainer`来微调模型或适配器以适应目标数据集。 |'
- en: '| [`examples/scripts/reward_modeling.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/reward_modeling.py)
    | This script shows how to use the `RewardTrainer` to train a reward model on
    your own dataset. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/reward_modeling.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/reward_modeling.py)
    | 此脚本展示了如何使用`RewardTrainer`来在您自己的数据集上训练奖励模型。 |'
- en: '| [`examples/scripts/ppo.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo.py)
    | This script shows how to use the `PPOTrainer` to fine-tune a sentiment analysis
    model using IMDB dataset |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/ppo.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo.py)
    | 此脚本展示了如何使用`PPOTrainer`来使用IMDB数据集微调情感分析模型 |'
- en: '| [`examples/scripts/ppo_multi_adapter.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo_multi_adapter.py)
    | This script shows how to use the `PPOTrainer` to train a single base model with
    multiple adapters. Requires you to run the example script with the reward model
    training beforehand. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/ppo_multi_adapter.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo_multi_adapter.py)
    | 此脚本展示了如何使用`PPOTrainer`来训练一个带有多个适配器的单个基础模型。需要您先运行奖励模型训练的示例脚本。 |'
- en: '| [`examples/scripts/stable_diffusion_tuning_example.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/stable_diffusion_tuning_example.py)
    | This script shows to use DDPOTrainer to fine-tune a stable diffusion model using
    reinforcement learning. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/stable_diffusion_tuning_example.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/stable_diffusion_tuning_example.py)
    | 此脚本展示了如何使用DDPOTrainer来使用强化学习微调稳定扩散模型。 |'
- en: 'Here are also some easier-to-run colab notebooks that you can use to get started
    with TRL:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一些更容易运行的colab笔记本，您可以用来开始使用TRL：
- en: '| File | Description |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 文件 | 描述 |'
- en: '| --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| [`examples/notebooks/best_of_n.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/best_of_n.ipynb)
    | This notebook demonstrates how to use the “Best of N” sampling strategy using
    TRL when fine-tuning your model with PPO. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/notebooks/best_of_n.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/best_of_n.ipynb)
    | 该笔记本演示了在使用PPO微调模型时如何使用TRL的“最佳N”抽样策略。 |'
- en: '| [`examples/notebooks/gpt2-sentiment.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-sentiment.ipynb)
    | This notebook demonstrates how to reproduce the GPT2 imdb sentiment tuning example
    on a jupyter notebook. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/notebooks/gpt2-sentiment.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-sentiment.ipynb)
    | 该笔记本演示了如何在jupyter笔记本上重现GPT2 imdb情感调整示例。 |'
- en: '| [`examples/notebooks/gpt2-control.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-control.ipynb)
    | This notebook demonstrates how to reproduce the GPT2 sentiment control example
    on a jupyter notebook. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/notebooks/gpt2-control.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-control.ipynb)
    | 该笔记本演示了如何在jupyter笔记本上重现GPT2情感控制示例。 |'
- en: 'We also have some other examples that are less maintained but can be used as
    a reference:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一些其他示例，虽然维护较少，但可以用作参考：
- en: '**[research_projects](https://github.com/huggingface/trl/tree/main/examples/research_projects)**:
    Check out this folder to find the scripts used for some research projects that
    used TRL (LM de-toxification, Stack-Llama, etc.)'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[research_projects](https://github.com/huggingface/trl/tree/main/examples/research_projects)：查看此文件夹以找到用于使用TRL的一些研究项目的脚本（LM去毒化，Stack-Llama等）'
- en: Distributed training
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式训练
- en: All of the scripts can be run on multiple GPUs by providing the path of an 🤗
    Accelerate config file when calling `accelerate launch`. To launch one of them
    on one or multiple GPUs, run the following command (swapping `{NUM_GPUS}` with
    the number of GPUs in your machine and `--all_arguments_of_the_script` with your
    arguments.)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在调用`accelerate launch`时提供🤗 Accelerate配置文件的路径，所有脚本都可以在多个GPU上运行。要在一个或多个GPU上启动其中一个，请运行以下命令（将`{NUM_GPUS}`替换为您机器上的GPU数量，将`--all_arguments_of_the_script`替换为您的参数。）
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can also adjust the parameters of the 🤗 Accelerate config file to suit your
    needs (e.g. training in mixed precision).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以调整🤗 Accelerate配置文件的参数以满足您的需求（例如在混合精度下训练）。
- en: Distributed training with DeepSpeed
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用DeepSpeed进行分布式训练
- en: 'Most of the scripts can be run on multiple GPUs together with DeepSpeed ZeRO-{1,2,3}
    for efficient sharding of the optimizer states, gradients, and model weights.
    To do so, run following command (swapping `{NUM_GPUS}` with the number of GPUs
    in your machine, `--all_arguments_of_the_script` with your arguments, and `--deepspeed_config`
    with the path to the DeepSpeed config file such as `examples/deepspeed_configs/deepspeed_zero1.yaml`):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数脚本可以与DeepSpeed ZeRO-{1,2,3}一起在多个GPU上运行，以实现优化器状态、梯度和模型权重的有效分片。要这样做，请运行以下命令（将`{NUM_GPUS}`替换为您机器上的GPU数量，将`--all_arguments_of_the_script`替换为您的参数，将`--deepspeed_config`替换为DeepSpeed配置文件的路径，例如`examples/deepspeed_configs/deepspeed_zero1.yaml`）：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
