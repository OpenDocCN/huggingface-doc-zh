- en: CLAP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CLAP
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clap](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clap)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clap](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clap)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The CLAP model was proposed in [Large Scale Contrastive Language-Audio pretraining
    with feature fusion and keyword-to-caption augmentation](https://arxiv.org/pdf/2211.06687.pdf)
    by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo
    Dubnov.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: CLAP模型由Yusong Wu，Ke Chen，Tianyu Zhang，Yuchen Hui，Taylor Berg-Kirkpatrick，Shlomo
    Dubnov在[大规模对比语言音频预训练与特征融合和关键词到标题增强](https://arxiv.org/pdf/2211.06687.pdf)中提出。
- en: CLAP (Contrastive Language-Audio Pretraining) is a neural network trained on
    a variety of (audio, text) pairs. It can be instructed in to predict the most
    relevant text snippet, given an audio, without directly optimizing for the task.
    The CLAP model uses a SWINTransformer to get audio features from a log-Mel spectrogram
    input, and a RoBERTa model to get text features. Both the text and audio features
    are then projected to a latent space with identical dimension. The dot product
    between the projected audio and text features is then used as a similar score.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: CLAP（对比语言音频预训练）是一个神经网络，训练于各种（音频，文本）对。它可以被指示来预测最相关的文本片段，给定一个音频，而不是直接为任务进行优化。CLAP模型使用SWINTransformer从对数Mel频谱图输入中获取音频特征，并使用RoBERTa模型获取文本特征。然后，文本和音频特征被投影到具有相同维度的潜在空间中。然后使用投影音频和文本特征之间的点积作为相似分数。
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Contrastive learning has shown remarkable success in the field of multimodal
    representation learning. In this paper, we propose a pipeline of contrastive language-audio
    pretraining to develop an audio representation by combining audio data with natural
    language descriptions. To accomplish this target, we first release LAION-Audio-630K,
    a large collection of 633,526 audio-text pairs from different data sources. Second,
    we construct a contrastive language-audio pretraining model by considering different
    audio encoders and text encoders. We incorporate the feature fusion mechanism
    and keyword-to-caption augmentation into the model design to further enable the
    model to process audio inputs of variable lengths and enhance the performance.
    Third, we perform comprehensive experiments to evaluate our model across three
    tasks: text-to-audio retrieval, zero-shot audio classification, and supervised
    audio classification. The results demonstrate that our model achieves superior
    performance in text-to-audio retrieval task. In audio classification tasks, the
    model achieves state-of-the-art performance in the zeroshot setting and is able
    to obtain performance comparable to models’ results in the non-zero-shot setting.
    LAION-Audio-6*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*对比学习在多模态表示学习领域取得了显著的成功。在本文中，我们提出了对比语言音频预训练的流水线，通过将音频数据与自然语言描述相结合来开发音频表示。为了实现这一目标，我们首先发布了LAION-Audio-630K，一个包含来自不同数据源的633,526个音频文本对的大型集合。其次，我们通过考虑不同的音频编码器和文本编码器构建了对比语言音频预训练模型。我们将特征融合机制和关键词到标题增强纳入模型设计中，以进一步使模型能够处理长度可变的音频输入并增强性能。第三，我们进行了全面的实验来评估我们的模型在三个任务中的表现：文本到音频检索，零样本音频分类和监督音频分类。结果表明，我们的模型在文本到音频检索任务中取得了优越的性能。在音频分类任务中，该模型在零样本设置下取得了最先进的性能，并且能够获得与非零样本设置中模型结果相媲美的性能。LAION-Audio-6*'
- en: This model was contributed by [Younes Belkada](https://huggingface.co/ybelkada)
    and [Arthur Zucker](https://huggingface.co/ArthurZ) . The original code can be
    found [here](https://github.com/LAION-AI/Clap).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[Younes Belkada](https://huggingface.co/ybelkada)和[Arthur Zucker](https://huggingface.co/ArthurZ)贡献。原始代码可以在[这里](https://github.com/LAION-AI/Clap)找到。
- en: ClapConfig
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapConfig
- en: '### `class transformers.ClapConfig`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L334)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L334)'
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize [ClapTextConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextConfig).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_config`（`dict`，*可选*）— 用于初始化[ClapTextConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextConfig)的配置选项字典。'
- en: '`audio_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize [ClapAudioConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioConfig).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_config`（`dict`，*可选*）— 用于初始化[ClapAudioConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioConfig)的配置选项字典。'
- en: '`logit_scale_init_value` (`float`, *optional*, defaults to 14.29) — The inital
    value of the *logit_scale* paramter. Default is used as per the original CLAP
    implementation.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logit_scale_init_value`（`float`，*可选*，默认为14.29）— *logit_scale*参数的初始值。默认值根据原始CLAP实现使用。'
- en: '`projection_dim` (`int`, *optional*, defaults to 512) — Dimentionality of text
    and audio projection layers.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_dim`（`int`，*可选*，默认为512）— 文本和音频投影层的维度。'
- en: '`projection_hidden_act` (`str`, *optional*, defaults to `"relu"`) — Activation
    function for the projection layers.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_hidden_act`（`str`，*可选*，默认为`"relu"`）— 投影层的激活函数。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1.0) — Factor to scale
    the initialization of the model weights.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor`（`float`，*可选*，默认为1.0）— 用于缩放模型权重初始化的因子。'
- en: '`kwargs` (*optional*) — Dictionary of keyword arguments.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（*可选*）— 关键字参数的字典。'
- en: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    is the configuration class to store the configuration of a [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel).
    It is used to instantiate a CLAP model according to the specified arguments, defining
    the text model and audio model configs. Instantiating a configuration with the
    defaults will yield a similar configuration to that of the CLAP [laion/clap-htsat-fused](https://huggingface.co/laion/clap-htsat-fused)
    architecture.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)是用于存储[ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)配置的配置类。根据指定的参数实例化一个
    CLAP 模型，定义文本模型和音频模型配置。使用默认值实例化配置将产生与 CLAP [laion/clap-htsat-fused](https://huggingface.co/laion/clap-htsat-fused)
    架构类似的配置。'
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#### `from_text_audio_configs`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_text_audio_configs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L422)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L422)'
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Returns
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)'
- en: An instance of a configuration object
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个配置对象的实例
- en: Instantiate a [ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    (or a derived class) from clap text model configuration and clap audio model configuration.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从 clap 文本模型配置和 clap 音频模型配置实例化一个[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)（或派生类）。
- en: ClapTextConfig
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapTextConfig
- en: '### `class transformers.ClapTextConfig`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapTextConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L32)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L32)'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    CLAP model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *可选*, 默认为30522) — CLAP 模型的词汇表大小。定义了在调用[ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel)时可以表示的不同标记的数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *可选*, 默认为768) — 编码器层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *可选*, 默认为12) — Transformer 编码器中的隐藏层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *可选*, 默认为12) — Transformer 编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (often named feed-forward) layer in the Transformer encoder.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *可选*, 默认为3072) — Transformer 编码器中“中间”（通常称为前馈）层的维度。'
- en: '`hidden_act` (`str` or `Callable`, *optional*, defaults to `"relu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"relu"`, `"relu"`, `"silu"` and `"relu_new"` are supported.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` 或 `Callable`, *可选*, 默认为`"relu"`) — 编码器和池化层中的非线性激活函数（函数或字符串）。如果是字符串，支持`"relu"`、`"relu"`、`"silu"`和`"relu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probability for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *可选*, 默认为0.1) — 嵌入层、编码器和池化层中所有全连接层的丢弃概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *可选*, 默认为0.1) — 注意力概率的丢弃比例。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *可选*, 默认为512) — 此模型可能使用的最大序列长度。通常设置为较大的值以防万一（例如，512或1024或2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids` passed when calling [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *可选*, 默认为2) — 在调用[ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel)时传递的`token_type_ids`的词汇表大小。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *可选*, 默认为1e-12) — 层归一化层使用的 epsilon。'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"absolute"`) — Type
    of position embedding. Choose one of `"absolute"`, `"relative_key"`, `"relative_key_query"`.
    For positional embeddings use `"absolute"`. For more information on `"relative_key"`,
    please refer to [Self-Attention with Relative Position Representations (Shaw et
    al.)](https://arxiv.org/abs/1803.02155). For more information on `"relative_key_query"`,
    please refer to *Method 4* in [Improve Transformer Models with Better Relative
    Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *可选*, 默认为`"absolute"`) — 位置嵌入的类型。选择`"absolute"`、`"relative_key"`、`"relative_key_query"`中的一个。对于位置嵌入，请使用`"absolute"`。有关`"relative_key"`的更多信息，请参考[Self-Attention
    with Relative Position Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)。有关`"relative_key_query"`的更多信息，请参考[Improve
    Transformer Models with Better Relative Position Embeddings (Huang et al.)]中的*Method
    4* (https://arxiv.org/abs/2009.13658)。'
- en: '`is_decoder` (`bool`, *optional*, defaults to `False`) — Whether the model
    is used as a decoder or not. If `False`, the model is used as an encoder.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_decoder` (`bool`, *可选*, 默认为`False`) — 模型是否用作解码器。如果为`False`，则模型用作编码器。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models). Only relevant
    if `config.is_decoder=True`.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *可选*, 默认为`True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。仅在`config.is_decoder=True`时相关。'
- en: '`projection_hidden_act` (`str`, *optional*, defaults to `"relu"`) — The non-linear
    activation function (function or string) in the projection layer. If string, `"gelu"`,
    `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_hidden_act` (`str`, *可选*, 默认为`"relu"`) — 投影层中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`projection_dim` (`int`, *optional*, defaults to 512) — Dimension of the projection
    head of the `ClapTextModelWithProjection`.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_dim` (`int`, *可选*, 默认为512) — `ClapTextModelWithProjection`的投影头的维度。'
- en: This is the configuration class to store the configuration of a [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel).
    It is used to instantiate a CLAP model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the CLAP [calp-hsat-fused](https://huggingface.co/laion/clap-hsat-fused)
    architecture.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel)的配置。根据指定的参数实例化一个CLAP模型，定义模型架构。使用默认值实例化配置将产生类似于CLAP
    [calp-hsat-fused](https://huggingface.co/laion/clap-hsat-fused)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Examples:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ClapAudioConfig
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapAudioConfig
- en: '### `class transformers.ClapAudioConfig`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapAudioConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L164)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/configuration_clap.py#L164)'
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`window_size` (`int`, *optional*, defaults to 8) — Image size of the spectrogram'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`window_size` (`int`, *可选*, 默认为8) — 频谱图的图像大小'
- en: '`num_mel_bins` (`int`, *optional*, defaults to 64) — Number of mel features
    used per frames. Should correspond to the value used in the `ClapProcessor` class.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_mel_bins` (`int`, *可选*, 默认为64) — 每帧使用的mel特征数。应与`ClapProcessor`类中使用的值对应。'
- en: '`spec_size` (`int`, *optional*, defaults to 256) — Desired input size of the
    spectrogram that the model supports. It can be different from the output of the
    `ClapFeatureExtractor`, in which case the input features will be resized. Corresponds
    to the `image_size` of the audio models.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec_size` (`int`, *可选*, 默认为256) — 模型支持的频谱图的期望输入大小。它可以与`ClapFeatureExtractor`的输出不同，此时输入特征将被调整大小。对应于音频模型的`image_size`。'
- en: '`hidden_act` (`str`, *optional*, defaults to `"gelu"`) — The non-linear activation
    function (function or string) in the encoder and pooler. If string, `"gelu"`,
    `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`, *可选*, 默认为`"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`patch_size` (`int`, *optional*, defaults to 4) — Patch size for the audio
    spectrogram'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *可选*, 默认为4) — 音频频谱图的补丁大小'
- en: '`patch_stride` (`list`, *optional*, defaults to `[4, 4]`) — Patch stride for
    the audio spectrogram'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_stride` (`list`, *可选*, 默认为`[4, 4]`) — 音频频谱图的补丁步幅'
- en: '`num_classes` (`int`, *optional*, defaults to 527) — Number of classes used
    for the head training'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_classes` (`int`, *可选*, 默认为527) — 用于头部训练的类别数'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Hidden size of the output
    of the audio encoder. Correspond to the dimension of the penultimate layer’s output,which
    is sent to the projection MLP layer.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *可选*, 默认为768) — 音频编码器输出的隐藏大小。对应于倒数第二层输出的维度，发送到投影MLP层。'
- en: '`projection_dim` (`int`, *optional*, defaults to 512) — Hidden size of the
    projection layer.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_dim` (`int`, *可选*, 默认为512) — 投影层的隐藏大小。'
- en: '`depths` (`list`, *optional*, defaults to `[2, 2, 6, 2]`) — Depths used for
    the Swin Layers of the audio model'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depths` (`list`, *可选*, 默认为`[2, 2, 6, 2]`) — 用于音频模型的Swin层的深度'
- en: '`num_attention_heads` (`list`, *optional*, defaults to `[4, 8, 16, 32]`) —
    Number of attention heads used for the Swin Layers of the audio model'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`list`, *可选*, 默认为`[4, 8, 16, 32]`) — 用于音频模型的Swin层的注意力头数。'
- en: '`enable_fusion` (`bool`, *optional*, defaults to `False`) — Whether or not
    to enable patch fusion. This is the main contribution of the authors, and should
    give the best results.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enable_fusion` (`bool`, *可选*, 默认为`False`) — 是否启用补丁融合。这是作者的主要贡献，应该能够获得最佳结果。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the encoder.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *可选*, 默认为0.1) — 编码器中所有全连接层的丢失概率。'
- en: '`fusion_type` (`[type]`, *optional*) — Fusion type used for the patch fusion.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fusion_type` (`[type]`, *可选*) — 用于补丁融合的融合类型。'
- en: '`patch_embed_input_channels` (`int`, *optional*, defaults to 1) — Number of
    channels used for the input spectrogram'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_embed_input_channels` (`int`, *可选*, 默认为1) — 用于输入频谱图的通道数'
- en: '`flatten_patch_embeds` (`bool`, *optional*, defaults to `True`) — Whether or
    not to flatten the patch embeddings'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flatten_patch_embeds` (`bool`, *可选*, 默认为`True`) — 是否展平补丁嵌入'
- en: '`patch_embeds_hidden_size` (`int`, *optional*, defaults to 96) — Hidden size
    of the patch embeddings. It is used as the number of output channels.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_embeds_hidden_size` (`int`, *optional*, 默认为96) — 补丁嵌入的隐藏大小。它用作输出通道数。'
- en: '`enable_patch_layer_norm` (`bool`, *optional*, defaults to `True`) — Whether
    or not to enable layer normalization for the patch embeddings'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enable_patch_layer_norm` (`bool`, *optional*, 默认为`True`) — 是否启用补丁嵌入的层归一化'
- en: '`drop_path_rate` (`float`, *optional*, defaults to 0.0) — Drop path rate for
    the patch fusion'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop_path_rate` (`float`, *optional*, 默认为0.0) — 用于补丁融合的Drop path率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — The
    dropout ratio for the attention probabilities.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, 默认为0.0) — 注意力概率的dropout比率。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether or not to add
    a bias to the query, key, value projections.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`, *optional*, 默认为`True`) — 是否向查询、键、值投影添加偏置。'
- en: '`mlp_ratio` (`float`, *optional*, defaults to 4.0) — Ratio of the mlp hidden
    dim to embedding dim.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlp_ratio` (`float`, *optional*, 默认为4.0) — MLP隐藏维度与嵌入维度的比率。'
- en: '`aff_block_r` (`int`, *optional*, defaults to 4) — downsize_ratio used in the
    AudioFF block'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aff_block_r` (`int`, *optional*, 默认为4) — AudioFF块中使用的downsize_ratio。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 4) — Number of hidden layers
    in the Transformer encoder.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, 默认为4) — Transformer编码器中的隐藏层数量。'
- en: '`projection_hidden_act` (`str`, *optional*, defaults to `"relu"`) — The non-linear
    activation function (function or string) in the projection layer. If string, `"gelu"`,
    `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_hidden_act` (`str`, *optional*, 默认为`"relu"`) — 投影层中的非线性激活函数（函数或字符串）。如果是字符串，则支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`layer_norm_eps` (`[type]`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`[type]`, *optional*, 默认为1e-05) — 层归一化层使用的epsilon。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1.0) — A factor for
    initializing all weight matrices (should be kept to 1, used internally for initialization
    testing).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor` (`float`, *optional*, 默认为1.0) — 用于初始化所有权重矩阵的因子（应保持为1，内部用于初始化测试）。'
- en: This is the configuration class to store the configuration of a [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel).
    It is used to instantiate a CLAP audio encoder according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the audio encoder of the CLAP [laion/clap-htsat-fused](https://huggingface.co/laion/clap-htsat-fused)
    architecture.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel)配置的配置类。根据指定的参数实例化一个CLAP音频编码器，定义模型架构。使用默认值实例化配置将产生类似于CLAP
    [laion/clap-htsat-fused](https://huggingface.co/laion/clap-htsat-fused)架构的音频编码器的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ClapFeatureExtractor
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapFeatureExtractor
- en: '### `class transformers.ClapFeatureExtractor`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/feature_extraction_clap.py#L33)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/feature_extraction_clap.py#L33)'
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_size` (`int`, *optional*, defaults to 64) — The feature dimension
    of the extracted Mel spectrograms. This corresponds to the number of mel filters
    (`n_mels`).'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_size` (`int`, *optional*, 默认为64) — 提取的Mel频谱图的特征维度。这对应于Mel滤波器的数量（`n_mels`）。'
- en: '`sampling_rate` (`int`, *optional*, defaults to 48000) — The sampling rate
    at which the audio files should be digitalized expressed in hertz (Hz). This only
    serves to warn users if the audio fed to the feature extractor does not have the
    same sampling rate.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *optional*, 默认为48000) — 音频文件应数字化的采样率，以赫兹（Hz）表示。这仅用于警告用户，如果输入到特征提取器的音频采样率不同。'
- en: '`hop_length` (`int`,*optional*, defaults to 480) — Length of the overlaping
    windows for the STFT used to obtain the Mel Spectrogram. The audio will be split
    in smaller `frames` with a step of `hop_length` between each frame.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hop_length` (`int`,*optional*, 默认为480) — 用于获取Mel Spectrogram的STFT中重叠窗口的长度。音频将被分割成较小的`frames`，每个帧之间的步长为`hop_length`。'
- en: '`max_length_s` (`int`, *optional*, defaults to 10) — The maximum input length
    of the model in seconds. This is used to pad the audio.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length_s` (`int`, *optional*, 默认为10) — 模型的最大输入长度（以秒为单位）。这用于填充音频。'
- en: '`fft_window_size` (`int`, *optional*, defaults to 1024) — Size of the window
    (in samples) on which the Fourier transform is applied. This controls the frequency
    resolution of the spectrogram. 400 means that the fourrier transform is computed
    on windows of 400 samples.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fft_window_size` (`int`, *optional*, 默认为1024) — 应用傅立叶变换的窗口大小（以样本为单位）。这控制了频谱图的频率分辨率。400表示傅立叶变换在400个样本的窗口上计算。'
- en: '`padding_value` (`float`, *optional*, defaults to 0.0) — Padding value used
    to pad the audio. Should correspond to silences.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value` (`float`, *optional*, 默认为0.0) — 用于填充音频的填充值。应对应于静音。'
- en: '`return_attention_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not the model should return the attention masks coresponding to the input.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *optional*, 默认为`False`) — 模型是否应返回与输入对应的注意力掩码。'
- en: '`frequency_min` (`float`, *optional*, defaults to 0) — The lowest frequency
    of interest. The STFT will not be computed for values below this.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frequency_min` (`float`, *optional*, 默认为0) — 感兴趣的最低频率。对于低于此值的频率，将不计算STFT。'
- en: '`frequency_max` (`float`, *optional*, defaults to 14000) — The highest frequency
    of interest. The STFT will not be computed for values above this.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frequency_max`（`float`，*可选*，默认为14000）- 感兴趣的最高频率。对于超过此值的值，STFT将不会计算。'
- en: '`top_db` (`float`, *optional*) — The highest decibel value used to convert
    the mel spectrogram to the log scale. For more details see the `audio_utils.power_to_db`
    function'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_db`（`float`，*可选*）- 用于将mel频谱图转换为对数刻度的最高分贝值。有关更多详细信息，请参阅`audio_utils.power_to_db`函数'
- en: '`truncation` (`str`, *optional*, defaults to `"fusion"`) — Truncation pattern
    for long audio inputs. Two patterns are available:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`str`，*可选*，默认为`"fusion"`）- 用于长音频输入的截断模式。有两种模式可用：'
- en: '`fusion` will use `_random_mel_fusion`, which stacks 3 random crops from the
    mel spectrogram and a downsampled version of the entire mel spectrogram. If `config.fusion`
    is set to True, shorter audios also need to to return 4 mels, which will just
    be a copy of the original mel obtained from the padded audio.'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fusion`将使用`_random_mel_fusion`，它堆叠了来自mel频谱图的3个随机裁剪和整个mel频谱图的降采样版本。如果`config.fusion`设置为True，则较短的音频也需要返回4个mel，这将只是从填充音频中获得的原始mel的副本。'
- en: '`rand_trunc` will select a random crop of the mel spectrogram.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rand_trunc`将选择mel频谱图的随机裁剪。'
- en: '`padding` (`str`, *optional*, defaults to `"repeatpad"`) — Padding pattern
    for shorter audio inputs. Three patterns were originally implemented:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`str`，*可选*，默认为`"repeatpad"`）- 用于较短音频输入的填充模式。最初实现了三种模式：'
- en: '`repeatpad`: the audio is repeated, and then padded to fit the `max_length`.'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repeatpad`：音频被重复，然后被填充以适应`max_length`。'
- en: '`repeat`: the audio is repeated and then cut to fit the `max_length`'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repeat`：音频被重复，然后被裁剪以适应`max_length`'
- en: '`pad`: the audio is padded.'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad`：音频被填充。'
- en: Constructs a CLAP feature extractor.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个CLAP特征提取器。
- en: This feature extractor inherits from [SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特征提取器继承自[SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: This class extracts mel-filter bank features from raw speech using a custom
    numpy implementation of the *Short Time Fourier Transform* (STFT) which should
    match pytorch’s `torch.stft` equivalent.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类使用自定义的numpy实现*短时傅里叶变换*（STFT）从原始语音中提取mel滤波器组特征，这应该与pytorch的`torch.stft`等效。
- en: '#### `to_dict`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/feature_extraction_clap.py#L138)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/feature_extraction_clap.py#L138)'
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Returns
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, Any]`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, Any]`'
- en: Dictionary of all the attributes that make up this configuration instance, excpet
    for the mel filter banks, which do not need to be saved or printed as they are
    too long.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 构成此配置实例的所有属性的字典，除了mel滤波器组，它们不需要被保存或打印，因为它们太长。
- en: Serializes this instance to a Python dictionary.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将此实例序列化为Python字典。
- en: ClapProcessor
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapProcessor
- en: '### `class transformers.ClapProcessor`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/processing_clap.py#L23)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/processing_clap.py#L23)'
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_extractor` ([ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor))
    — The audio processor is a required input.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`（[ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)）-
    音频处理器是必需的输入。'
- en: '`tokenizer` ([RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast))
    — The tokenizer is a required input.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)）-
    分词器是必需的输入。'
- en: Constructs a CLAP processor which wraps a CLAP feature extractor and a RoBerta
    tokenizer into a single processor.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个CLAP处理器，将CLAP特征提取器和RoBerta分词器封装成一个单一处理器。
- en: '[ClapProcessor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor)
    offers all the functionalities of [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    and [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast).
    See the `__call__()` and [decode()](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor.decode)
    for more information.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapProcessor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor)提供了[ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)和[RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)的所有功能。有关更多信息，请参阅`__call__()`和[decode()](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor.decode)。'
- en: '#### `batch_decode`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/processing_clap.py#L99)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/processing_clap.py#L99)'
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This method forwards all its arguments to RobertaTokenizerFast’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将所有参数转发给RobertaTokenizerFast的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。请参考此方法的文档字符串以获取更多信息。
- en: '#### `decode`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/processing_clap.py#L106)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/processing_clap.py#L106)'
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This method forwards all its arguments to RobertaTokenizerFast’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将所有参数转发给RobertaTokenizerFast的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。请参考此方法的文档字符串以获取更多信息。
- en: ClapModel
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapModel
- en: '### `class transformers.ClapModel`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1920)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1920)'
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2050)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2050)'
- en: '[PRE13]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。默认情况下，如果提供填充，则将被忽略。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[输入ID是什么？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*) —
    避免在填充标记索引上执行注意力的掩码。选择的掩码值为`[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被“掩码”的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被“掩码”的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[注意力掩码是什么？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[位置ID是什么？](../glossary#position-ids)'
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Input audio features. This should be returnes by the [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    class that you can also retrieve from [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor).
    See `ClapFeatureExtractor.__call__()` for details.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 输入音频特征。这应该由[ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)类返回，您也可以从[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)中检索。有关详细信息，请参阅`ClapFeatureExtractor.__call__()`。'
- en: '`return_loss` (`bool`, *optional*) — Whether or not to return the contrastive
    loss.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_loss` (`bool`, *可选*) — 是否返回对比损失。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请查看返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: Returns
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.clap.modeling_clap.ClapOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.clap.modeling_clap.ClapOutput` 或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.clap.modeling_clap.ClapOutput` or a tuple of `torch.FloatTensor`
    (if `return_dict=False` is passed or when `config.return_dict=False`) comprising
    various elements depending on the configuration (`<class 'transformers.models.clap.configuration_clap.ClapConfig'>`)
    and inputs.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.clap.modeling_clap.ClapOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（`<class
    'transformers.models.clap.configuration_clap.ClapConfig'>`）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `return_loss`
    is `True`) — Contrastive loss for audio-text similarity.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *可选*, 当 `return_loss` 为 `True`
    时返回) — 音频-文本相似性的对比损失。'
- en: '`logits_per_audio:(torch.FloatTensor` of shape `(audio_batch_size, text_batch_size)`)
    — The scaled dot product scores between `audio_embeds` and `text_embeds`. This
    represents the audio-text similarity scores.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits_per_audio:(torch.FloatTensor` of shape `(audio_batch_size, text_batch_size)`)
    — `audio_embeds` 和 `text_embeds` 之间的缩放点积分数。这代表了音频-文本相似度分数。'
- en: '`logits_per_text:(torch.FloatTensor` of shape `(text_batch_size, audio_batch_size)`)
    — The scaled dot product scores between `text_embeds` and `audio_embeds`. This
    represents the text-audio similarity scores.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits_per_text:(torch.FloatTensor` of shape `(text_batch_size, audio_batch_size)`)
    — `text_embeds` 和 `audio_embeds` 之间的缩放点积分数。这代表了文本-音频相似度分数。'
- en: '`text_embeds(torch.FloatTensor` of shape `(batch_size, output_dim`) — The text
    embeddings obtained by applying the projection layer to the pooled output of [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_embeds(torch.FloatTensor` of shape `(batch_size, output_dim`) — 通过将 [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel)
    的汇聚输出应用到投影层而获得的文本嵌入。'
- en: '`audio_embeds(torch.FloatTensor` of shape `(batch_size, output_dim`) — The
    audio embeddings obtained by applying the projection layer to the pooled output
    of [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_embeds(torch.FloatTensor` of shape `(batch_size, output_dim`) — 通过将
    [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel)
    的汇聚输出应用到投影层而获得的音频嵌入。'
- en: '`text_model_output(BaseModelOutputWithPooling):` The output of the [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_model_output(BaseModelOutputWithPooling):` [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel)
    的输出。'
- en: '`audio_model_output(BaseModelOutputWithPooling):` The output of the [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_model_output(BaseModelOutputWithPooling):` [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel)
    的输出。'
- en: The [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    forward method, overrides the `__call__` special method.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用 `Module` 实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Examples:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `get_text_features`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_text_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1956)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1956)'
- en: '[PRE15]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。默认情况下将忽略填充。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *可选*) — 避免在填充标记索引上执行注意力的掩码。掩码值选在 `[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表 `未被掩码` 的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 代表 `被掩码` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *可选*) — 每个输入序列标记在位置嵌入中的位置索引。在范围 `[0, config.max_position_embeddings - 1]` 中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: text_features (`torch.FloatTensor` of shape `(batch_size, output_dim`)
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: text_features (`torch.FloatTensor` of shape `(batch_size, output_dim`)
- en: The text embeddings obtained by applying the projection layer to the pooled
    output of [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将 [ClapTextModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModel)
    的汇聚输出应用到投影层而获得的文本嵌入。
- en: The [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    forward method, overrides the `__call__` special method.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用 `Module` 实例，而不是这个函数，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE16]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#### `get_audio_features`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_audio_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2004)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2004)'
- en: '[PRE17]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Input audio features. This should be returnes by the [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    class that you can also retrieve from [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor).
    See `ClapFeatureExtractor.__call__()` for details.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height,
    width)`) — 输入音频特征。这应该由 [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    类返回，您也可以从 [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    中检索。有关详细信息，请参阅 `ClapFeatureExtractor.__call__()`。'
- en: '`is_longer` (`torch.FloatTensor`, of shape `(batch_size, 1)`, *optional*) —
    Whether the audio clip is longer than `max_length`. If `True`, a feature fusion
    will be enabled to enhance the features.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_longer` (`torch.FloatTensor`，形状为 `(batch_size, 1)`，*可选*) — 音频片段是否比 `max_length`
    更长。如果为 `True`，将启用特征融合以增强特征。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是一个普通元组。'
- en: Returns
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: audio_features (`torch.FloatTensor` of shape `(batch_size, output_dim`)
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: audio_features (`torch.FloatTensor`，形状为 `(batch_size, output_dim)`)
- en: The audio embeddings obtained by applying the projection layer to the pooled
    output of [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将投影层应用于 [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel)
    的汇聚输出获得的音频嵌入。
- en: The [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    forward method, overrides the `__call__` special method.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用 `Module` 实例，而不是这个函数，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE18]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ClapTextModel
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapTextModel
- en: '### `class transformers.ClapTextModel`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapTextModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1751)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1751)'
- en: '[PRE19]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The model can behave as an encoder (with only self-attention) as well as a decoder,
    in which case a layer of cross-attention is added between the self-attention layers,
    following the architecture described in *Attention is all you need*_ by Ashish
    Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
    Lukasz Kaiser and Illia Polosukhin.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以作为编码器（仅具有自注意力）以及解码器的行为，此时在自注意力层之间添加了一层交叉注意力，遵循 *Attention is all you need*_
    中描述的架构，作者为 Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
    Aidan N. Gomez, Lukasz Kaiser 和 Illia Polosukhin。
- en: To behave as an decoder the model needs to be initialized with the `is_decoder`
    argument of the configuration set to `True`. To be used in a Seq2Seq model, the
    model needs to initialized with both `is_decoder` argument and `add_cross_attention`
    set to `True`; an `encoder_hidden_states` is then expected as an input to the
    forward pass.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 要使模型行为像一个解码器，需要使用配置中的 `is_decoder` 参数设置为 `True` 来初始化模型。要在 Seq2Seq 模型中使用，模型需要使用
    `is_decoder` 参数和 `add_cross_attention` 都设置为 `True` 来初始化；然后预期在前向传递中输入一个 `encoder_hidden_states`。
- en: '.. _*Attention is all you need*: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '.. _*注意力就是你所需要的*: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
- en: '#### `forward`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1789)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1789)'
- en: '[PRE20]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'encoder_hidden_states (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*): Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention if the model is configured as
    a decoder. encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size,
    sequence_length)`, *optional*): Mask to avoid performing attention on the padding
    token indices of the encoder input. This mask is used in the cross-attention if
    the model is configured as a decoder. Mask values selected in `[0, 1]`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: encoder_hidden_states（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）：编码器最后一层的隐藏状态序列。如果模型配置为解码器，则用于交叉注意力。encoder_attention_mask（形状为`(batch_size,
    sequence_length)`的`torch.FloatTensor`，*可选*）：避免在编码器输入的填充标记索引上执行注意力的掩码。如果模型配置为解码器，则在交叉注意力中使用此掩码。掩码值选择在`[0,
    1]`之间：
- en: 1 for tokens that are `not masked`,
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: '0 for tokens that are `masked`. past_key_values (`tuple(tuple(torch.FloatTensor))`
    of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size,
    num_heads, sequence_length - 1, embed_size_per_head)`): Contains precomputed key
    and value hidden states of the attention blocks. Can be used to speed up decoding.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。past_key_values（长度为`config.n_layers`的`tuple(tuple(torch.FloatTensor))`，每个元组包含4个形状为`(batch_size,
    num_heads, sequence_length - 1, embed_size_per_head)`的张量）：包含注意力块的预计算键和值隐藏状态。可用于加速解码。
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_ids` (those that don’t have their past key value states given to
    this model) of shape `(batch_size, 1)` instead of all `decoder_input_ids` of shape
    `(batch_size, sequence_length)`. use_cache (`bool`, *optional*): If set to `True`,
    `past_key_values` key value states are returned and can be used to speed up decoding
    (see `past_key_values`).'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后一个`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的）的形状为`(batch_size,
    1)`的张量，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_ids`。use_cache（`bool`，*可选*）：如果设置为`True`，则返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。
- en: ClapTextModelWithProjection
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapTextModelWithProjection
- en: '### `class transformers.ClapTextModelWithProjection`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapTextModelWithProjection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2148)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2148)'
- en: '[PRE21]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)）—
    包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: CLAP Text Model with a projection layer on top (a linear layer on top of the
    pooled output).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部投影层的CLAP文本模型（在汇总输出的顶部有一个线性层）。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2170)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2170)'
- en: '[PRE22]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。默认情况下将忽略填充。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)获取详细信息。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.Tensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0,
    1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.clap.modeling_clap.ClapTextModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.clap.modeling_clap.ClapTextModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.clap.modeling_clap.ClapTextModelOutput` or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.clap.configuration_clap.ClapTextConfig'>`)
    and inputs.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.clap.modeling_clap.ClapTextModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置(`<class
    'transformers.models.clap.configuration_clap.ClapTextConfig'>`)和输入的各种元素。
- en: '`text_embeds` (`torch.FloatTensor` of shape `(batch_size, output_dim)` *optional*
    returned when model is initialized with `with_projection=True`) — The text embeddings
    obtained by applying the projection layer to the pooler_output.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_embeds` (`torch.FloatTensor` of shape `(batch_size, output_dim)` *optional*
    当模型初始化为`with_projection=True`时返回) — 通过将投影层应用于pooler_output获得的文本嵌入。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层的隐藏状态序列。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有嵌入层，+
    一个用于每个层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [ClapTextModelWithProjection](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModelWithProjection)
    forward method, overrides the `__call__` special method.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapTextModelWithProjection](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapTextModelWithProjection)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默忽略它们。
- en: 'Examples:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE23]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ClapAudioModel
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapAudioModel
- en: '### `class transformers.ClapAudioModel`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapAudioModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1693)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1693)'
- en: '[PRE24]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#### `forward`'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1706)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L1706)'
- en: '[PRE25]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Input audio features. This should be returnes by the [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    class that you can also retrieve from [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor).
    See `ClapFeatureExtractor.__call__()` for details.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — 输入音频特征。这应该由[ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)类返回，您也可以从[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)中检索。有关详细信息，请参阅`ClapFeatureExtractor.__call__()`。'
- en: '`is_longer` (`torch.FloatTensor`, of shape `(batch_size, 1)`, *optional*) —
    Whether the audio clip is longer than `max_length`. If `True`, a feature fusion
    will be enabled to enhance the features.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_longer` (`torch.FloatTensor`, 形状为`(batch_size, 1)`, *optional*) — 音频剪辑是否比`max_length`更长。如果为`True`，将启用特征融合以增强特征。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.clap.configuration_clap.ClapAudioConfig'>`)
    and inputs.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包括各种元素，取决于配置（`<class
    'transformers.models.clap.configuration_clap.ClapAudioConfig'>`）和输入。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）-
    模型最后一层的隐藏状态序列输出。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`（形状为`(batch_size, hidden_size)`的`torch.FloatTensor`）- 经过用于辅助预训练任务的层进一步处理后的序列的第一个标记（分类标记）的最后一层隐藏状态。例如，对于BERT系列模型，这返回经过线性层和tanh激活函数处理后的分类标记。线性层的权重是在预训练期间从下一个句子预测（分类）目标中训练的。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel)
    forward method, overrides the `__call__` special method.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapAudioModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE26]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ClapAudioModelWithProjection
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ClapAudioModelWithProjection
- en: '### `class transformers.ClapAudioModelWithProjection`'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ClapAudioModelWithProjection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2224)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2224)'
- en: '[PRE27]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)）-
    包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: CLAP Audio Model with a projection layer on top (a linear layer on top of the
    pooled output).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部具有投影层的CLAP音频模型（在池化输出的顶部有一个线性层）。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 前进
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2244)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/clap/modeling_clap.py#L2244)'
- en: '[PRE28]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Input audio features. This should be returnes by the [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    class that you can also retrieve from [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor).
    See `ClapFeatureExtractor.__call__()` for details.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）—输入音频特征。这应该由您可以从[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)中检索的[ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)类返回。有关详细信息，请参阅`ClapFeatureExtractor.__call__()`。'
- en: '`is_longer` (`torch.FloatTensor`, of shape `(batch_size, 1)`, *optional*) —
    Whether the audio clip is longer than `max_length`. If `True`, a feature fusion
    will be enabled to enhance the features.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_longer`（形状为`(batch_size, 1)`的`torch.FloatTensor`，*可选*）—音频剪辑是否比`max_length`更长。如果为`True`，将启用特征融合以增强特征。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.clap.modeling_clap.ClapAudioModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.clap.modeling_clap.ClapAudioModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.clap.modeling_clap.ClapAudioModelOutput` or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.clap.configuration_clap.ClapAudioConfig'>`)
    and inputs.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.clap.modeling_clap.ClapAudioModelOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包括根据配置（`<class
    'transformers.models.clap.configuration_clap.ClapAudioConfig'>`）和输入的不同元素。
- en: '`audio_embeds` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`) —
    The Audio embeddings obtained by applying the projection layer to the pooler_output.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_embeds`（形状为`(batch_size, hidden_size)`的`torch.FloatTensor`）—通过将投影层应用于pooler_output获得的音频嵌入。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）—模型最后一层的隐藏状态序列。'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—形状为`(batch_size,
    num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—形状为`(batch_size,
    sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: The [ClapAudioModelWithProjection](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModelWithProjection)
    forward method, overrides the `__call__` special method.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClapAudioModelWithProjection](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapAudioModelWithProjection)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
