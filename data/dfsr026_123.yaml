- en: Transformer Temporal
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Transformer Temporal
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/transformer_temporal](https://huggingface.co/docs/diffusers/api/models/transformer_temporal)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/models/transformer_temporal](https://huggingface.co/docs/diffusers/api/models/transformer_temporal)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: A Transformer model for video-like data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 用于类似视频数据的Transformer模型。
- en: TransformerTemporalModel
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TransformerTemporalModel
- en: '### `class diffusers.models.TransformerTemporalModel`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.TransformerTemporalModel`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_temporal.py#L41)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_temporal.py#L41)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_attention_heads` (`int`, *optional*, defaults to 16) — The number of heads
    to use for multi-head attention.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads`（`int`，*可选*，默认为16）— 用于多头注意力的头数。'
- en: '`attention_head_dim` (`int`, *optional*, defaults to 88) — The number of channels
    in each head.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_head_dim`（`int`，*可选*，默认为88）— 每个头中的通道数。'
- en: '`in_channels` (`int`, *optional*) — The number of channels in the input and
    output (specify if the input is **continuous**).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_channels`（`int`，*可选*）— 输入和输出中的通道数（如果输入是**连续**，请指定）。'
- en: '`num_layers` (`int`, *optional*, defaults to 1) — The number of layers of Transformer
    blocks to use.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers`（`int`，*可选*，默认为1）— 要使用的Transformer块层数。'
- en: '`dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    to use.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout`（`float`，*可选*，默认为0.0）— 要使用的丢弃概率。'
- en: '`cross_attention_dim` (`int`, *optional*) — The number of `encoder_hidden_states`
    dimensions to use.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_dim`（`int`，*可选*）— 要使用的`encoder_hidden_states`维度数。'
- en: '`attention_bias` (`bool`, *optional*) — Configure if the `TransformerBlock`
    attention should contain a bias parameter.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_bias`（`bool`，*可选*）— 配置`TransformerBlock`注意力是否应包含偏置参数。'
- en: '`sample_size` (`int`, *optional*) — The width of the latent images (specify
    if the input is **discrete**). This is fixed during training since it is used
    to learn a number of position embeddings.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_size` (`int`, *optional*) — 潜在图像的宽度（如果输入是**离散**，请指定）。在训练期间固定，因为它用于学习一些位置嵌入。'
- en: '`activation_fn` (`str`, *optional*, defaults to `"geglu"`) — Activation function
    to use in feed-forward. See `diffusers.models.activations.get_activation` for
    supported activation functions.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_fn`（`str`，*可选*，默认为`"geglu"`）— 在前馈中使用的激活函数。查看`diffusers.models.activations.get_activation`以获取支持的激活函数。'
- en: '`norm_elementwise_affine` (`bool`, *optional*) — Configure if the `TransformerBlock`
    should use learnable elementwise affine parameters for normalization.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`norm_elementwise_affine`（`bool`，*可选*）— 配置`TransformerBlock`是否应该使用可学习的逐元素仿射参数进行归一化。'
- en: '`double_self_attention` (`bool`, *optional*) — Configure if each `TransformerBlock`
    should contain two self-attention layers. positional_embeddings — (`str`, *optional*):
    The type of positional embeddings to apply to the sequence input before passing
    use. num_positional_embeddings — (`int`, *optional*): The maximum length of the
    sequence over which to apply positional embeddings.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`double_self_attention`（`bool`，*可选*）— 配置每个`TransformerBlock`是否应包含两个自注意力层。位置嵌入
    —（`str`，*可选*）：在传递之前应用于序列输入的位置嵌入的类型。num_positional_embeddings —（`int`，*可选*）：要应用位置嵌入的序列的最大长度。'
- en: A Transformer model for video-like data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 用于类似视频数据的Transformer模型。
- en: '#### `forward`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_temporal.py#L121)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_temporal.py#L121)'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`hidden_states` (`torch.LongTensor` of shape `(batch size, num latent pixels)`
    if discrete, `torch.FloatTensor` of shape `(batch size, channel, height, width)`
    if continuous) — Input hidden_states.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（如果是离散的，则形状为`(batch size, num latent pixels)`的`torch.LongTensor`，如果是连续的，则形状为`(batch
    size, channel, height, width)`的`torch.FloatTensor`）— 输入的隐藏状态。'
- en: '`encoder_hidden_states` ( `torch.LongTensor` of shape `(batch size, encoder_hidden_states
    dim)`, *optional*) — Conditional embeddings for cross attention layer. If not
    given, cross-attention defaults to self-attention.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（形状为`(batch size, encoder_hidden_states dim)`的`torch.LongTensor`，*可选*）—
    用于交叉注意力层的条件嵌入。如果未给出，则交叉注意力默认为自注意力。'
- en: '`timestep` ( `torch.LongTensor`, *optional*) — Used to indicate denoising step.
    Optional timestep to be applied as an embedding in `AdaLayerNorm`.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep`（`torch.LongTensor`，*可选*）— 用于指示去噪步骤。可选的时间步骤，将作为嵌入应用于`AdaLayerNorm`中。'
- en: '`class_labels` ( `torch.LongTensor` of shape `(batch size, num classes)`, *optional*)
    — Used to indicate class labels conditioning. Optional class labels to be applied
    as an embedding in `AdaLayerZeroNorm`.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels`（形状为`(batch size, num classes)`的`torch.LongTensor`，*可选*）— 用于指示类标签条件的类标签。可选的类标签，将作为嵌入应用于`AdaLayerZeroNorm`。'
- en: '`num_frames` (`int`, *optional*, defaults to 1) — The number of frames to be
    processed per batch. This is used to reshape the hidden states.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_frames`（`int`，*可选*，默认为1）— 要在每批次中处理的帧数。这用于重塑隐藏状态。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs`（`dict`，*可选*）— 如果指定，将传递给`AttentionProcessor`的kwargs字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`下定义的。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [UNet2DConditionOutput](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.models.unets.unet_2d_condition.UNet2DConditionOutput)
    instead of a plain tuple.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回[UNet2DConditionOutput](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.models.unets.unet_2d_condition.UNet2DConditionOutput)而不是普通元组。'
- en: Returns
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`~models.transformer_temporal.TransformerTemporalModelOutput` or `tuple`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`~models.transformer_temporal.TransformerTemporalModelOutput`或`tuple`'
- en: If `return_dict` is True, an `~models.transformer_temporal.TransformerTemporalModelOutput`
    is returned, otherwise a `tuple` where the first element is the sample tensor.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为True，则返回一个`~models.transformer_temporal.TransformerTemporalModelOutput`，否则返回一个元组，其中第一个元素是样本张量。
- en: The `TransformerTemporal` forward method.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`TransformerTemporal`的前向方法。'
- en: TransformerTemporalModelOutput
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TransformerTemporalModelOutput
- en: '### `class diffusers.models.transformers.transformer_temporal.TransformerTemporalModelOutput`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.transformers.transformer_temporal.TransformerTemporalModelOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_temporal.py#L28)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_temporal.py#L28)'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor` of shape `(batch_size x num_frames, num_channels,
    height, width)`) — The hidden states output conditioned on `encoder_hidden_states`
    input.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（形状为`(batch_size x num_frames, num_channels, height, width)`的`torch.FloatTensor`）-
    在`encoder_hidden_states`输入条件下的隐藏状态输出。'
- en: The output of `TransformerTemporalModel`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`TransformerTemporalModel`的输出。'
