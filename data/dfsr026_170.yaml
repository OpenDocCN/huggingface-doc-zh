- en: Latent upscaler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ½œåœ¨æ”¾å¤§å™¨
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The Stable Diffusion latent upscaler model was created by [Katherine Crowson](https://github.com/crowsonkb/k-diffusion)
    in collaboration with [Stability AI](https://stability.ai/). It is used to enhance
    the output image resolution by a factor of 2 (see this demo [notebook](https://colab.research.google.com/drive/1o1qYJcFeywzCIdkfKJy7cTpgZTCM2EI4)
    for a demonstration of the original implementation).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£æ½œåœ¨æ”¾å¤§å™¨æ¨¡å‹æ˜¯ç”±[Katherine Crowson](https://github.com/crowsonkb/k-diffusion)ä¸[Stability
    AI](https://stability.ai/)åˆä½œåˆ›å»ºçš„ã€‚å®ƒç”¨äºé€šè¿‡2å€å¢åŠ è¾“å‡ºå›¾åƒçš„åˆ†è¾¨ç‡ï¼ˆæŸ¥çœ‹æ­¤æ¼”ç¤º[ç¬”è®°æœ¬](https://colab.research.google.com/drive/1o1qYJcFeywzCIdkfKJy7cTpgZTCM2EI4)ä»¥äº†è§£åŸå§‹å®ç°çš„æ¼”ç¤ºï¼‰ã€‚
- en: Make sure to check out the Stable Diffusion [Tips](overview#tips) section to
    learn how to explore the tradeoff between scheduler speed and quality, and how
    to reuse pipeline components efficiently!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·ç¡®ä¿æŸ¥çœ‹ç¨³å®šæ‰©æ•£[Tips](overview#tips)éƒ¨åˆ†ï¼Œä»¥äº†è§£å¦‚ä½•åœ¨è°ƒåº¦å™¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œå¹¶å¦‚ä½•æœ‰æ•ˆåœ°é‡ç”¨ç®¡é“ç»„ä»¶ï¼
- en: If youâ€™re interested in using one of the official checkpoints for a task, explore
    the [CompVis](https://huggingface.co/CompVis), [Runway](https://huggingface.co/runwayml),
    and [Stability AI](https://huggingface.co/stabilityai) Hub organizations!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£ä½¿ç”¨å®˜æ–¹æ£€æŸ¥ç‚¹æ¥æ‰§è¡Œä»»åŠ¡ï¼Œè¯·æ¢ç´¢[CompVis](https://huggingface.co/CompVis)ã€[Runway](https://huggingface.co/runwayml)å’Œ[Stability
    AI](https://huggingface.co/stabilityai) Hubç»„ç»‡ï¼
- en: StableDiffusionLatentUpscalePipeline
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionLatentUpscalePipeline
- en: '### `class diffusers.StableDiffusionLatentUpscalePipeline`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionLatentUpscalePipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L63)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L63)'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)ï¼‰â€”å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    â€” Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)ï¼‰â€”å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆ[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)ï¼‰ã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” A `CLIPTokenizer` to tokenize text.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)ï¼‰â€”ä¸€ä¸ª`CLIPTokenizer`ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)ï¼‰â€”ä¸€ä¸ª`UNet2DConditionModel`ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A [EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
    to be used in combination with `unet` to denoise the encoded image latents.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`ï¼ˆ[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)ï¼‰â€”ä¸`unet`ç»“åˆä½¿ç”¨çš„[EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)ã€‚'
- en: Pipeline for upscaling Stable Diffusion output image resolution by a factor
    of 2.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å› å­2æ”¾å¤§ç¨³å®šæ‰©æ•£è¾“å‡ºå›¾åƒåˆ†è¾¨ç‡çš„ç®¡é“ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£ä¸ºæ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®¡é“è¿˜ç»§æ‰¿äº†ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶'
- en: '#### `__call__`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L289)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L289)'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`) â€” The prompt or prompts to guide image upscaling.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼‰â€”æŒ‡å¯¼å›¾åƒæ”¾å¤§çš„æç¤ºæˆ–æç¤ºã€‚'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) â€” `Image` or tensor representing
    an image batch to be upscaled. If itâ€™s a tensor, it can be either a latent output
    from a Stable Diffusion model or an image tensor in the range `[-1, 1]`. It is
    considered a `latent` if `image.shape[1]` is `4`; otherwise, it is considered
    to be an image representation and encoded using this pipelineâ€™s `vae` encoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`ï¼ˆ`torch.FloatTensor`ï¼Œ`PIL.Image.Image`ï¼Œ`np.ndarray`ï¼Œ`List[torch.FloatTensor]`ï¼Œ`List[PIL.Image.Image]`æˆ–`List[np.ndarray]`ï¼‰â€”è¡¨ç¤ºè¦æ”¾å¤§çš„å›¾åƒæ‰¹æ¬¡çš„`Image`æˆ–å¼ é‡ã€‚å¦‚æœæ˜¯å¼ é‡ï¼Œåˆ™å¯ä»¥æ˜¯ç¨³å®šæ‰©æ•£æ¨¡å‹çš„æ½œåœ¨è¾“å‡ºï¼Œä¹Ÿå¯ä»¥æ˜¯èŒƒå›´ä¸º`[-1,
    1]`çš„å›¾åƒå¼ é‡ã€‚å¦‚æœ`image.shape[1]`ä¸º`4`ï¼Œåˆ™è¢«è§†ä¸º`latent`ï¼›å¦åˆ™ï¼Œè¢«è§†ä¸ºå›¾åƒè¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨æ­¤ç®¡é“çš„`vae`ç¼–ç å™¨è¿›è¡Œç¼–ç ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º50ï¼‰â€”å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” æ›´é«˜çš„æŒ‡å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬
    `prompt` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“ `guidance_scale > 1` æ—¶å¯ç”¨æŒ‡å¯¼æ¯”ä¾‹ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” æŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…å«çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’
    `negative_prompt_embeds`ã€‚å½“ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶ï¼ˆ`guidance_scale < 1` æ—¶ï¼‰ï¼Œå°†è¢«å¿½ç•¥ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, defaults to 0.0) â€” å¯¹åº”äº [DDIM](https://arxiv.org/abs/2010.02502)
    è®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ã€‚ä»…é€‚ç”¨äº [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚'
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„é¢„ç”Ÿæˆå™ªå£°æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™å°†ä½¿ç”¨æä¾›çš„éšæœº
    `generator` è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹© `PIL.Image`
    æˆ– `np.array` ä¹‹é—´çš„ä¸€ä¸ªã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦è¿”å› [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    è€Œä¸æ˜¯æ™®é€šçš„ tupleã€‚'
- en: '`callback` (`Callable`, *optional*) â€” A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) â€” ä¸€ä¸ªåœ¨æ¨æ–­è¿‡ç¨‹ä¸­æ¯ `callback_steps` æ­¥è°ƒç”¨ä¸€æ¬¡çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å°†ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`ã€‚'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) â€” The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, defaults to 1) â€” `callback` å‡½æ•°è¢«è°ƒç”¨çš„é¢‘ç‡ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™åœ¨æ¯ä¸€æ­¥éƒ½ä¼šè°ƒç”¨å›è°ƒå‡½æ•°ã€‚'
- en: Returns
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    æˆ– `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ `return_dict` ä¸º `True`ï¼Œåˆ™è¿”å› [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª
    `tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åŒ…å«ç”Ÿæˆå›¾åƒçš„åˆ—è¡¨ã€‚
- en: The call function to the pipeline for generation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç”Ÿæˆçš„ç®¡é“çš„è°ƒç”¨å‡½æ•°ã€‚
- en: 'Examples:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1499)'
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`gpu_id` (`int`, *optional*) â€” The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id` (`int`, *optional*) â€” æ¨æ–­ä¸­è¦ä½¿ç”¨çš„åŠ é€Ÿå™¨çš„ IDã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º 0ã€‚'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to â€œcudaâ€) â€” The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to â€œcudaâ€.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`torch.Device` or `str`, *optional*, defaults to â€œcudaâ€) â€” æ¨æ–­ä¸­è¦ä½¿ç”¨çš„åŠ é€Ÿå™¨çš„
    PyTorch è®¾å¤‡ç±»å‹ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸ºâ€œcudaâ€ã€‚'
- en: Offloads all models to CPU using ğŸ¤— Accelerate, significantly reducing memory
    usage. When called, the state dicts of all `torch.nn.Module` components (except
    those in `self._exclude_from_cpu_offload`) are saved to CPU and then moved to
    `torch.device('meta')` and loaded to GPU only when their specific submodule has
    its `forward` method called. Offloading happens on a submodule basis. Memory savings
    are higher than with `enable_model_cpu_offload`, but performance is lower.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ ğŸ¤— Accelerate å°†æ‰€æœ‰æ¨¡å‹è½¬ç§»åˆ° CPUï¼Œæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚è°ƒç”¨æ—¶ï¼Œæ‰€æœ‰ `torch.nn.Module` ç»„ä»¶çš„çŠ¶æ€å­—å…¸ï¼ˆé™¤äº† `self._exclude_from_cpu_offload`
    ä¸­çš„ç»„ä»¶ï¼‰å°†ä¿å­˜åˆ° CPUï¼Œç„¶åç§»åŠ¨åˆ° `torch.device('meta')`ï¼Œä»…åœ¨å…¶ç‰¹å®šå­æ¨¡å—è°ƒç”¨ `forward` æ–¹æ³•æ—¶æ‰åŠ è½½åˆ° GPUã€‚å¸è½½æ˜¯åŸºäºå­æ¨¡å—çš„ã€‚å†…å­˜èŠ‚çœé«˜äº
    `enable_model_cpu_offload`ï¼Œä½†æ€§èƒ½è¾ƒä½ã€‚
- en: '#### `enable_attention_slicing`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2063)'
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`slice_size` (`str` or `int`, *optional*, defaults to `"auto"`) â€” When `"auto"`,
    halves the input to the attention heads, so attention will be computed in two
    steps. If `"max"`, maximum amount of memory will be saved by running only one
    slice at a time. If a number is provided, uses as many slices as `attention_head_dim
    // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size`.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`slice_size` (`str` æˆ– `int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"auto"`) â€” å½“ä¸º `"auto"` æ—¶ï¼Œå°†è¾“å…¥å‡åŠåˆ°æ³¨æ„åŠ›å¤´éƒ¨ï¼Œå› æ­¤æ³¨æ„åŠ›å°†åˆ†ä¸¤æ­¥è®¡ç®—ã€‚å¦‚æœä¸º
    `"max"`ï¼Œå°†é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥èŠ‚çœæœ€å¤§å†…å­˜é‡ã€‚å¦‚æœæä¾›ä¸€ä¸ªæ•°å­—ï¼Œåˆ™ä½¿ç”¨ `attention_head_dim // slice_size` ä½œä¸ºåˆ‡ç‰‡æ•°é‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`attention_head_dim`
    å¿…é¡»æ˜¯ `slice_size` çš„å€æ•°ã€‚'
- en: Enable sliced attention computation. When this option is enabled, the attention
    module splits the input tensor in slices to compute attention in several steps.
    For more than one attention head, the computation is performed sequentially over
    each head. This is useful to save some memory in exchange for a small speed decrease.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆåˆ‡ç‰‡ï¼Œä»¥ä¾¿åœ¨å¤šä¸ªæ­¥éª¤ä¸­è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—å°†æŒ‰é¡ºåºåœ¨æ¯ä¸ªå¤´ä¸Šæ‰§è¡Œã€‚è¿™å¯¹äºèŠ‚çœä¸€äº›å†…å­˜ä»¥æ¢å–å°å¹…åº¦é€Ÿåº¦é™ä½å¾ˆæœ‰ç”¨ã€‚
- en: âš ï¸ Donâ€™t enable attention slicing if youâ€™re already using `scaled_dot_product_attention`
    (SDPA) from PyTorch 2.0 or xFormers. These attention computations are already
    very memory efficient so you wonâ€™t need to enable this function. If you enable
    attention slicing with SDPA or xFormers, it can lead to serious slow downs!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 æˆ– xFormers ä¸­çš„ `scaled_dot_product_attention`ï¼ˆSDPAï¼‰ï¼Œè¯·ä¸è¦å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ã€‚è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸å†…å­˜é«˜æ•ˆï¼Œå› æ­¤æ‚¨ä¸éœ€è¦å¯ç”¨æ­¤åŠŸèƒ½ã€‚å¦‚æœæ‚¨åœ¨ä½¿ç”¨
    SDPA æˆ– xFormers æ—¶å¯ç”¨äº†æ³¨æ„åŠ›åˆ‡ç‰‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡å‡é€Ÿï¼
- en: 'Examples:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `disable_attention_slicing`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_attention_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2103)'
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Disable sliced attention computation. If `enable_attention_slicing` was previously
    called, attention is computed in one step.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº† `enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2002)'
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`attention_op` (`Callable`, *optional*) â€” Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`, *å¯é€‰*) â€” ç”¨ä½œ `xFormers` çš„ [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    å‡½æ•°çš„ `op` å‚æ•°çš„é»˜è®¤ `None` æ“ä½œç¬¦çš„è¦†ç›–ã€‚'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
    When this option is enabled, you should observe lower GPU memory usage and a potential
    speed up during inference. Speed up during training is not guaranteed.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨æ¥è‡ª[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°æ›´ä½çš„
    GPU å†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶ä¸”åœ¨æ¨æ–­æœŸé—´å¯èƒ½ä¼šåŠ é€Ÿã€‚è®­ç»ƒæœŸé—´çš„åŠ é€Ÿä¸è¢«ä¿è¯ã€‚
- en: âš ï¸ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å½“å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚
- en: 'Examples:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L2037)'
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨æ¥è‡ª[xFormers](https://facebookresearch.github.io/xformers/)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚
- en: '#### `disable_freeu`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L285)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L285)'
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå·²å¯ç”¨ï¼Œåˆ™ç¦ç”¨ FreeU æœºåˆ¶ã€‚
- en: '#### `enable_freeu`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L262)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_latent_upscale.py#L262)'
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1` (`float`) â€” ç”¨äºå‡å¼±è·³è·ƒç‰¹å¾è´¡çŒ®çš„ç¬¬1é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚'
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2` (`float`) â€” ç”¨äºå‡å¼±è·³è·ƒç‰¹å¾è´¡çŒ®çš„ç¬¬2é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡åº¦å¹³æ»‘æ•ˆåº”â€ã€‚'
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1` (`float`) â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„ç¬¬1é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚'
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2` (`float`) â€” ç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾è´¡çŒ®çš„ç¬¬2é˜¶æ®µçš„ç¼©æ”¾å› å­ã€‚'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨ FreeU æœºåˆ¶ï¼Œå¦‚[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)ã€‚
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºå®ƒä»¬è¢«åº”ç”¨çš„é˜¶æ®µã€‚
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è€ƒ[å®˜æ–¹å­˜å‚¨åº“](https://github.com/ChenyangSi/FreeU)ï¼Œäº†è§£å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion
    v1ã€v2 å’Œ Stable Diffusion XLï¼‰çš„å€¼ç»„åˆã€‚
- en: StableDiffusionPipelineOutput
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) â€” List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` æˆ– `np.ndarray`) â€” é•¿åº¦ä¸º `batch_size` çš„å»å™ª PIL
    å›¾åƒåˆ—è¡¨æˆ–å½¢çŠ¶ä¸º `(batch_size, height, width, num_channels)` çš„ NumPy æ•°ç»„ã€‚'
- en: '`nsfw_content_detected` (`List[bool]`) â€” List indicating whether the corresponding
    generated image contains â€œnot-safe-for-workâ€ (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) â€” åˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ï¼Œå¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º
    `None`ã€‚'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚
