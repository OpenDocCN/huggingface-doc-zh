- en: Troubleshoot
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•…éšœæ’é™¤
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting](https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting](https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes errors occur, but we are here to help! This guide covers some of
    the most common issues weâ€™ve seen and how you can resolve them. However, this
    guide isnâ€™t meant to be a comprehensive collection of every ğŸ¤— Transformers issue.
    For more help with troubleshooting your issue, try:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶ä¼šå‡ºç°é”™è¯¯ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œå¸®åŠ©æ‚¨ï¼æœ¬æŒ‡å—æ¶µç›–äº†æˆ‘ä»¬è§è¿‡çš„ä¸€äº›æœ€å¸¸è§é—®é¢˜ä»¥åŠæ‚¨å¯ä»¥å¦‚ä½•è§£å†³å®ƒä»¬ã€‚ä½†æ˜¯ï¼Œæœ¬æŒ‡å—å¹¶ä¸æ—¨åœ¨æˆä¸ºæ¯ä¸ªğŸ¤— Transformersé—®é¢˜çš„å…¨é¢é›†åˆã€‚å¦‚éœ€æ›´å¤šæœ‰å…³æ•…éšœæ’é™¤çš„å¸®åŠ©ï¼Œè¯·å°è¯•ï¼š
- en: '[https://www.youtube-nocookie.com/embed/S2EEG3JIt2A](https://www.youtube-nocookie.com/embed/S2EEG3JIt2A)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube-nocookie.com/embed/S2EEG3JIt2A](https://www.youtube-nocookie.com/embed/S2EEG3JIt2A)'
- en: Asking for help on the [forums](https://discuss.huggingface.co/). There are
    specific categories you can post your question to, like [Beginners](https://discuss.huggingface.co/c/beginners/5)
    or [ğŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9). Make sure
    you write a good descriptive forum post with some reproducible code to maximize
    the likelihood that your problem is solved!
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨[è®ºå›](https://discuss.huggingface.co/)ä¸Šå¯»æ±‚å¸®åŠ©ã€‚æ‚¨å¯ä»¥å°†é—®é¢˜å‘å¸ƒåˆ°ç‰¹å®šç±»åˆ«ï¼Œå¦‚[åˆå­¦è€…](https://discuss.huggingface.co/c/beginners/5)æˆ–[ğŸ¤—
    Transformers](https://discuss.huggingface.co/c/transformers/9)ã€‚è¯·ç¡®ä¿ç¼–å†™ä¸€ä¸ªå…·æœ‰ä¸€äº›å¯é‡ç°ä»£ç çš„è‰¯å¥½æè¿°æ€§è®ºå›å¸–å­ï¼Œä»¥æœ€å¤§ç¨‹åº¦åœ°æé«˜è§£å†³é—®é¢˜çš„å¯èƒ½æ€§ï¼
- en: '[https://www.youtube-nocookie.com/embed/_PAli-V4wj0](https://www.youtube-nocookie.com/embed/_PAli-V4wj0)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube-nocookie.com/embed/_PAli-V4wj0](https://www.youtube-nocookie.com/embed/_PAli-V4wj0)'
- en: Create an [Issue](https://github.com/huggingface/transformers/issues/new/choose)
    on the ğŸ¤— Transformers repository if it is a bug related to the library. Try to
    include as much information describing the bug as possible to help us better figure
    out whatâ€™s wrong and how we can fix it.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœæ˜¯ä¸åº“ç›¸å…³çš„é”™è¯¯ï¼Œè¯·åœ¨ğŸ¤— Transformerså­˜å‚¨åº“ä¸Šåˆ›å»ºä¸€ä¸ª[Issue](https://github.com/huggingface/transformers/issues/new/choose)ã€‚å°½é‡åŒ…å«å°½å¯èƒ½å¤šæè¿°é”™è¯¯çš„ä¿¡æ¯ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ä»¥åŠå¦‚ä½•ä¿®å¤å®ƒã€‚
- en: Check the [Migration](migration) guide if you use an older version of ğŸ¤— Transformers
    since some important changes have been introduced between versions.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨è¾ƒæ—§ç‰ˆæœ¬çš„ğŸ¤— Transformersï¼Œè¯·æŸ¥çœ‹[è¿ç§»](migration)æŒ‡å—ï¼Œå› ä¸ºåœ¨ç‰ˆæœ¬ä¹‹é—´å¼•å…¥äº†ä¸€äº›é‡è¦æ›´æ”¹ã€‚
- en: For more details about troubleshooting and getting help, take a look at [Chapter
    8](https://huggingface.co/course/chapter8/1?fw=pt) of the Hugging Face course.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³æ•…éšœæ’é™¤å’Œè·å–å¸®åŠ©çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹Hugging Faceè¯¾ç¨‹çš„[ç¬¬8ç« ](https://huggingface.co/course/chapter8/1?fw=pt)ã€‚
- en: Firewalled environments
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é˜²ç«å¢™ç¯å¢ƒ
- en: 'Some GPU instances on cloud and intranet setups are firewalled to external
    connections, resulting in a connection error. When your script attempts to download
    model weights or datasets, the download will hang and then timeout with the following
    message:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›äº‘ç«¯å’Œå†…éƒ¨è®¾ç½®çš„GPUå®ä¾‹è¢«é˜²ç«å¢™é˜»æ­¢å¯¹å¤–éƒ¨è¿æ¥ï¼Œå¯¼è‡´è¿æ¥é”™è¯¯ã€‚å½“æ‚¨çš„è„šæœ¬å°è¯•ä¸‹è½½æ¨¡å‹æƒé‡æˆ–æ•°æ®é›†æ—¶ï¼Œä¸‹è½½å°†æŒ‚èµ·ï¼Œç„¶åè¶…æ—¶å¹¶æ˜¾ç¤ºä»¥ä¸‹æ¶ˆæ¯ï¼š
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this case, you should try to run ğŸ¤— Transformers on [offline mode](installation#offline-mode)
    to avoid the connection error.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥å°è¯•åœ¨[ç¦»çº¿æ¨¡å¼](installation#offline-mode)ä¸‹è¿è¡ŒğŸ¤— Transformersä»¥é¿å…è¿æ¥é”™è¯¯ã€‚
- en: CUDA out of memory
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CUDAå†…å­˜ä¸è¶³
- en: 'Training large models with millions of parameters can be challenging without
    the appropriate hardware. A common error you may encounter when the GPU runs out
    of memory is:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ²¡æœ‰é€‚å½“ç¡¬ä»¶çš„æƒ…å†µä¸‹è®­ç»ƒæ‹¥æœ‰æ•°ç™¾ä¸‡å‚æ•°çš„å¤§å‹æ¨¡å‹å¯èƒ½ä¼šå¾ˆå…·æŒ‘æˆ˜æ€§ã€‚å½“GPUå†…å­˜ä¸è¶³æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°çš„å¸¸è§é”™è¯¯æ˜¯ï¼š
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here are some potential solutions you can try to lessen memory use:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€äº›æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆï¼Œæ‚¨å¯ä»¥å°è¯•å‡å°‘å†…å­˜ä½¿ç”¨ï¼š
- en: Reduce the [`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size)
    value in [TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å°‘[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­çš„[`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size)å€¼ã€‚
- en: Try using [`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps)
    in [TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)
    to effectively increase overall batch size.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°è¯•åœ¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­ä½¿ç”¨[`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps)æ¥æœ‰æ•ˆå¢åŠ æ€»ä½“æ‰¹é‡å¤§å°ã€‚
- en: Refer to the Performance [guide](performance) for more details about memory-saving
    techniques.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³èŠ‚çœå†…å­˜æŠ€æœ¯çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒæ€§èƒ½[æŒ‡å—](performance)ã€‚
- en: Unable to load a saved TensorFlow model
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ— æ³•åŠ è½½ä¿å­˜çš„TensorFlowæ¨¡å‹
- en: 'TensorFlowâ€™s [model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)
    method will save the entire model - architecture, weights, training configuration
    - in a single file. However, when you load the model file again, you may run into
    an error because ğŸ¤— Transformers may not load all the TensorFlow-related objects
    in the model file. To avoid issues with saving and loading TensorFlow models,
    we recommend you:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowçš„[model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)æ–¹æ³•å°†æ•´ä¸ªæ¨¡å‹ï¼ˆæ¶æ„ã€æƒé‡ã€è®­ç»ƒé…ç½®ï¼‰ä¿å­˜åœ¨å•ä¸ªæ–‡ä»¶ä¸­ã€‚ç„¶è€Œï¼Œå½“æ‚¨å†æ¬¡åŠ è½½æ¨¡å‹æ–‡ä»¶æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°é”™è¯¯ï¼Œå› ä¸ºğŸ¤—
    Transformerså¯èƒ½ä¸ä¼šåŠ è½½æ¨¡å‹æ–‡ä»¶ä¸­çš„æ‰€æœ‰ä¸TensorFlowç›¸å…³çš„å¯¹è±¡ã€‚ä¸ºé¿å…ä¿å­˜å’ŒåŠ è½½TensorFlowæ¨¡å‹æ—¶å‡ºç°é—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ï¼š
- en: 'Save the model weights as a `h5` file extension with [`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)
    and then reload the model with [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained):'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)å°†æ¨¡å‹æƒé‡ä¿å­˜ä¸º`h5`æ–‡ä»¶æ‰©å±•åï¼Œç„¶åä½¿ç”¨[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)é‡æ–°åŠ è½½æ¨¡å‹ï¼š
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Save the model with `~TFPretrainedModel.save_pretrained` and load it again
    with [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained):'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`~TFPretrainedModel.save_pretrained`ä¿å­˜æ¨¡å‹ï¼Œç„¶åä½¿ç”¨[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)å†æ¬¡åŠ è½½å®ƒï¼š
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ImportError
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ImportError
- en: 'Another common error you may encounter, especially if it is a newly released
    model, is `ImportError`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯èƒ½ä¼šé‡åˆ°å¦ä¸€ç§å¸¸è§é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ–°å‘å¸ƒçš„æ¨¡å‹ï¼Œå³`ImportError`ï¼š
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For these error types, check to make sure you have the latest version of ğŸ¤—
    Transformers installed to access the most recent models:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™äº›é”™è¯¯ç±»å‹ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ğŸ¤— Transformers ä»¥è®¿é—®æœ€æ–°çš„æ¨¡å‹ï¼š
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'CUDA error: device-side assert triggered'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'CUDA error: device-side assert triggered'
- en: Sometimes you may run into a generic CUDA error about an error in the device
    code.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶æ‚¨å¯èƒ½ä¼šé‡åˆ°æœ‰å…³è®¾å¤‡ä»£ç é”™è¯¯çš„é€šç”¨CUDAé”™è¯¯ã€‚
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should try to run the code on a CPU first to get a more descriptive error
    message. Add the following environment variable to the beginning of your code
    to switch to a CPU:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨åº”è¯¥é¦–å…ˆå°è¯•åœ¨CPUä¸Šè¿è¡Œä»£ç ï¼Œä»¥è·å¾—æ›´è¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯ã€‚å°†ä»¥ä¸‹ç¯å¢ƒå˜é‡æ·»åŠ åˆ°æ‚¨çš„ä»£ç å¼€å¤´ä»¥åˆ‡æ¢åˆ°CPUï¼š
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Another option is to get a better traceback from the GPU. Add the following
    environment variable to the beginning of your code to get the traceback to point
    to the source of the error:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé€‰é¡¹æ˜¯ä»GPUè·å–æ›´å¥½çš„å›æº¯ã€‚å°†ä»¥ä¸‹ç¯å¢ƒå˜é‡æ·»åŠ åˆ°æ‚¨çš„ä»£ç å¼€å¤´ï¼Œä»¥ä½¿å›æº¯æŒ‡å‘é”™è¯¯æºï¼š
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Incorrect output when padding tokens arenâ€™t masked
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å½“å¡«å……æ ‡è®°æœªè¢«å±è”½æ—¶è¾“å‡ºä¸æ­£ç¡®
- en: In some cases, the output `hidden_state` may be incorrect if the `input_ids`
    include padding tokens. To demonstrate, load a model and tokenizer. You can access
    a modelâ€™s `pad_token_id` to see its value. The `pad_token_id` may be `None` for
    some models, but you can always manually set it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æœ`input_ids`åŒ…å«å¡«å……æ ‡è®°ï¼Œåˆ™è¾“å‡ºçš„`hidden_state`å¯èƒ½æ˜¯ä¸æ­£ç¡®çš„ã€‚ä¸ºäº†æ¼”ç¤ºï¼ŒåŠ è½½ä¸€ä¸ªæ¨¡å‹å’Œåˆ†è¯å™¨ã€‚æ‚¨å¯ä»¥è®¿é—®æ¨¡å‹çš„`pad_token_id`ä»¥æŸ¥çœ‹å…¶å€¼ã€‚å¯¹äºä¸€äº›æ¨¡å‹ï¼Œ`pad_token_id`å¯èƒ½ä¸º`None`ï¼Œä½†æ‚¨æ€»æ˜¯å¯ä»¥æ‰‹åŠ¨è®¾ç½®å®ƒã€‚
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following example shows the output without masking the padding tokens:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ç¤ºä¾‹æ˜¾ç¤ºäº†ä¸å±è”½å¡«å……æ ‡è®°æ—¶çš„è¾“å‡ºï¼š
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is the actual output of the second sequence:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ç¬¬äºŒä¸ªåºåˆ—çš„å®é™…è¾“å‡ºï¼š
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Most of the time, you should provide an `attention_mask` to your model to ignore
    the padding tokens to avoid this silent error. Now the output of the second sequence
    matches its actual output:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥ä¸ºæ‚¨çš„æ¨¡å‹æä¾›ä¸€ä¸ª`attention_mask`æ¥å¿½ç•¥å¡«å……æ ‡è®°ï¼Œä»¥é¿å…è¿™ç§æ½œåœ¨é”™è¯¯ã€‚ç°åœ¨ç¬¬äºŒä¸ªåºåˆ—çš„è¾“å‡ºä¸å…¶å®é™…è¾“å‡ºåŒ¹é…ï¼š
- en: By default, the tokenizer creates an `attention_mask` for you based on your
    specific tokenizerâ€™s defaults.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ†è¯å™¨æ ¹æ®ç‰¹å®šåˆ†è¯å™¨çš„é»˜è®¤å€¼ä¸ºæ‚¨åˆ›å»º`attention_mask`ã€‚
- en: '[PRE12]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'ğŸ¤— Transformers doesnâ€™t automatically create an `attention_mask` to mask a padding
    token if it is provided because:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformersä¸ä¼šè‡ªåŠ¨åˆ›å»º`attention_mask`æ¥å±è”½å¡«å……æ ‡è®°ï¼Œå¦‚æœæä¾›äº†å¡«å……æ ‡è®°ï¼Œå› ä¸ºï¼š
- en: Some models donâ€™t have a padding token.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€äº›æ¨¡å‹æ²¡æœ‰å¡«å……æ ‡è®°ã€‚
- en: For some use-cases, users want a model to attend to a padding token.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæŸäº›ç”¨ä¾‹ï¼Œç”¨æˆ·å¸Œæœ›æ¨¡å‹å…³æ³¨å¡«å……æ ‡è®°ã€‚
- en: 'ValueError: Unrecognized configuration class XYZ for this kind of AutoModel'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'ValueError: Unrecognized configuration class XYZ for this kind of AutoModel'
- en: 'Generally, we recommend using the [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    class to load pretrained instances of models. This class can automatically infer
    and load the correct architecture from a given checkpoint based on the configuration.
    If you see this `ValueError` when loading a model from a checkpoint, this means
    the Auto class couldnâ€™t find a mapping from the configuration in the given checkpoint
    to the kind of model you are trying to load. Most commonly, this happens when
    a checkpoint doesnâ€™t support a given task. For instance, youâ€™ll see this error
    in the following example because there is no GPT2 for question answering:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)ç±»æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„å®ä¾‹ã€‚è¿™ä¸ªç±»å¯ä»¥æ ¹æ®é…ç½®è‡ªåŠ¨æ¨æ–­å’ŒåŠ è½½ç»™å®šæ£€æŸ¥ç‚¹ä¸­çš„æ­£ç¡®æ¶æ„ã€‚å¦‚æœåœ¨ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹æ—¶çœ‹åˆ°`ValueError`ï¼Œè¿™æ„å‘³ç€Autoç±»æ— æ³•ä»ç»™å®šæ£€æŸ¥ç‚¹ä¸­çš„é…ç½®æ‰¾åˆ°åˆ°æ‚¨å°è¯•åŠ è½½çš„æ¨¡å‹ç±»å‹çš„æ˜ å°„ã€‚æœ€å¸¸è§çš„æƒ…å†µæ˜¯ï¼Œå½“æ£€æŸ¥ç‚¹ä¸æ”¯æŒç»™å®šä»»åŠ¡æ—¶ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚ä¾‹å¦‚ï¼Œåœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°æ­¤é”™è¯¯ï¼Œå› ä¸ºæ²¡æœ‰ç”¨äºé—®ç­”çš„GPT2ï¼š
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
