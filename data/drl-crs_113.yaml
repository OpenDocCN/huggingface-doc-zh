- en: Decision Transformers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策Transformer
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers](https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers](https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The Decision Transformer model was introduced by [“Decision Transformer: Reinforcement
    Learning via Sequence Modeling” by Chen L. et al](https://arxiv.org/abs/2106.01345).
    It abstracts Reinforcement Learning as a conditional-sequence modeling problem.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 决策Transformer模型由[Chen L.等人提出的“决策Transformer：通过序列建模进行强化学习”](https://arxiv.org/abs/2106.01345)引入。它将强化学习抽象为一个条件序列建模问题。
- en: The main idea is that instead of training a policy using RL methods, such as
    fitting a value function, that will tell us what action to take to maximize the
    return (cumulative reward), **we use a sequence modeling algorithm (Transformer)
    that, given a desired return, past states, and actions, will generate future actions
    to achieve this desired return**. It’s an autoregressive model conditioned on
    the desired return, past states, and actions to generate future actions that achieve
    the desired return.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是，**我们使用一个序列建模算法（Transformer），根据期望的回报、过去的状态和行动，生成未来的行动以实现期望的回报**，而不是使用RL方法训练策略，比如拟合值函数，告诉我们应该采取什么行动来最大化回报（累积奖励）。这是一个自回归模型，根据期望的回报、过去的状态和行动来生成未来的行动，以实现期望的回报。
- en: This is a complete shift in the Reinforcement Learning paradigm since we use
    generative trajectory modeling (modeling the joint distribution of the sequence
    of states, actions, and rewards) to replace conventional RL algorithms. This means
    that in Decision Transformers, we don’t maximize the return but rather generate
    a series of future actions that achieve the desired return.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对强化学习范式的完全转变，因为我们使用生成轨迹建模（建模状态、行动和奖励序列的联合分布）来替代传统的RL算法。这意味着在决策Transformer中，我们不是最大化回报，而是生成一系列未来的行动，以实现期望的回报。
- en: The 🤗 Transformers team integrated the Decision Transformer, an Offline Reinforcement
    Learning method, into the library as well as the Hugging Face Hub.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers团队将决策Transformer（一种离线强化学习方法）集成到库中，以及Hugging Face Hub。
- en: Learn about Decision Transformers
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解决策Transformer
- en: To learn more about Decision Transformers, you should read the blogpost we wrote
    about it [Introducing Decision Transformers on Hugging Face](https://huggingface.co/blog/decision-transformers)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于决策Transformer的信息，您应该阅读我们撰写的博文[Introducing Decision Transformers on Hugging
    Face](https://huggingface.co/blog/decision-transformers)
- en: Train your first Decision Transformers
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练您的第一个决策Transformer
- en: Now that you understand how Decision Transformers work thanks to [Introducing
    Decision Transformers on Hugging Face](https://huggingface.co/blog/decision-transformers),
    you’re ready to learn to train your first Offline Decision Transformer model from
    scratch to make a half-cheetah run.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了决策Transformer的工作原理，感谢[Introducing Decision Transformers on Hugging Face](https://huggingface.co/blog/decision-transformers)，您已经准备好学习如何从头开始训练您的第一个离线决策Transformer模型，让半猎豹奔跑。
- en: Start the tutorial here 👉 [https://huggingface.co/blog/train-decision-transformers](https://huggingface.co/blog/train-decision-transformers)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始教程👉[https://huggingface.co/blog/train-decision-transformers](https://huggingface.co/blog/train-decision-transformers)
- en: Further reading
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information, we recommend that you check out the following resources:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多信息，建议查看以下资源：
- en: '[Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策Transformer：通过序列建模进行强化学习](https://arxiv.org/abs/2106.01345)'
- en: '[Online Decision Transformer](https://arxiv.org/abs/2202.05607)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线决策Transformer](https://arxiv.org/abs/2202.05607)'
- en: Author
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作者
- en: This section was written by [Edward Beeching](https://twitter.com/edwardbeeching)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分由[Edward Beeching](https://twitter.com/edwardbeeching)撰写
