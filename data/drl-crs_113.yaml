- en: Decision Transformers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å†³ç­–Transformer
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers](https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers](https://huggingface.co/learn/deep-rl-course/unitbonus3/decision-transformers)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The Decision Transformer model was introduced by [â€œDecision Transformer: Reinforcement
    Learning via Sequence Modelingâ€ by Chen L. et al](https://arxiv.org/abs/2106.01345).
    It abstracts Reinforcement Learning as a conditional-sequence modeling problem.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–Transformeræ¨¡å‹ç”±[Chen L.ç­‰äººæå‡ºçš„â€œå†³ç­–Transformerï¼šé€šè¿‡åºåˆ—å»ºæ¨¡è¿›è¡Œå¼ºåŒ–å­¦ä¹ â€](https://arxiv.org/abs/2106.01345)å¼•å…¥ã€‚å®ƒå°†å¼ºåŒ–å­¦ä¹ æŠ½è±¡ä¸ºä¸€ä¸ªæ¡ä»¶åºåˆ—å»ºæ¨¡é—®é¢˜ã€‚
- en: The main idea is that instead of training a policy using RL methods, such as
    fitting a value function, that will tell us what action to take to maximize the
    return (cumulative reward), **we use a sequence modeling algorithm (Transformer)
    that, given a desired return, past states, and actions, will generate future actions
    to achieve this desired return**. Itâ€™s an autoregressive model conditioned on
    the desired return, past states, and actions to generate future actions that achieve
    the desired return.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦æ€æƒ³æ˜¯ï¼Œ**æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåºåˆ—å»ºæ¨¡ç®—æ³•ï¼ˆTransformerï¼‰ï¼Œæ ¹æ®æœŸæœ›çš„å›æŠ¥ã€è¿‡å»çš„çŠ¶æ€å’Œè¡ŒåŠ¨ï¼Œç”Ÿæˆæœªæ¥çš„è¡ŒåŠ¨ä»¥å®ç°æœŸæœ›çš„å›æŠ¥**ï¼Œè€Œä¸æ˜¯ä½¿ç”¨RLæ–¹æ³•è®­ç»ƒç­–ç•¥ï¼Œæ¯”å¦‚æ‹Ÿåˆå€¼å‡½æ•°ï¼Œå‘Šè¯‰æˆ‘ä»¬åº”è¯¥é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨æ¥æœ€å¤§åŒ–å›æŠ¥ï¼ˆç´¯ç§¯å¥–åŠ±ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªè‡ªå›å½’æ¨¡å‹ï¼Œæ ¹æ®æœŸæœ›çš„å›æŠ¥ã€è¿‡å»çš„çŠ¶æ€å’Œè¡ŒåŠ¨æ¥ç”Ÿæˆæœªæ¥çš„è¡ŒåŠ¨ï¼Œä»¥å®ç°æœŸæœ›çš„å›æŠ¥ã€‚
- en: This is a complete shift in the Reinforcement Learning paradigm since we use
    generative trajectory modeling (modeling the joint distribution of the sequence
    of states, actions, and rewards) to replace conventional RL algorithms. This means
    that in Decision Transformers, we donâ€™t maximize the return but rather generate
    a series of future actions that achieve the desired return.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹å¼ºåŒ–å­¦ä¹ èŒƒå¼çš„å®Œå…¨è½¬å˜ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ç”Ÿæˆè½¨è¿¹å»ºæ¨¡ï¼ˆå»ºæ¨¡çŠ¶æ€ã€è¡ŒåŠ¨å’Œå¥–åŠ±åºåˆ—çš„è”åˆåˆ†å¸ƒï¼‰æ¥æ›¿ä»£ä¼ ç»Ÿçš„RLç®—æ³•ã€‚è¿™æ„å‘³ç€åœ¨å†³ç­–Transformerä¸­ï¼Œæˆ‘ä»¬ä¸æ˜¯æœ€å¤§åŒ–å›æŠ¥ï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ç³»åˆ—æœªæ¥çš„è¡ŒåŠ¨ï¼Œä»¥å®ç°æœŸæœ›çš„å›æŠ¥ã€‚
- en: The ğŸ¤— Transformers team integrated the Decision Transformer, an Offline Reinforcement
    Learning method, into the library as well as the Hugging Face Hub.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformerså›¢é˜Ÿå°†å†³ç­–Transformerï¼ˆä¸€ç§ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼‰é›†æˆåˆ°åº“ä¸­ï¼Œä»¥åŠHugging Face Hubã€‚
- en: Learn about Decision Transformers
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: äº†è§£å†³ç­–Transformer
- en: To learn more about Decision Transformers, you should read the blogpost we wrote
    about it [Introducing Decision Transformers on Hugging Face](https://huggingface.co/blog/decision-transformers)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£æ›´å¤šå…³äºå†³ç­–Transformerçš„ä¿¡æ¯ï¼Œæ‚¨åº”è¯¥é˜…è¯»æˆ‘ä»¬æ’°å†™çš„åšæ–‡[Introducing Decision Transformers on Hugging
    Face](https://huggingface.co/blog/decision-transformers)
- en: Train your first Decision Transformers
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ‚¨çš„ç¬¬ä¸€ä¸ªå†³ç­–Transformer
- en: Now that you understand how Decision Transformers work thanks to [Introducing
    Decision Transformers on Hugging Face](https://huggingface.co/blog/decision-transformers),
    youâ€™re ready to learn to train your first Offline Decision Transformer model from
    scratch to make a half-cheetah run.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»äº†è§£äº†å†³ç­–Transformerçš„å·¥ä½œåŸç†ï¼Œæ„Ÿè°¢[Introducing Decision Transformers on Hugging Face](https://huggingface.co/blog/decision-transformers)ï¼Œæ‚¨å·²ç»å‡†å¤‡å¥½å­¦ä¹ å¦‚ä½•ä»å¤´å¼€å§‹è®­ç»ƒæ‚¨çš„ç¬¬ä¸€ä¸ªç¦»çº¿å†³ç­–Transformeræ¨¡å‹ï¼Œè®©åŠçŒè±¹å¥”è·‘ã€‚
- en: Start the tutorial here ğŸ‘‰ [https://huggingface.co/blog/train-decision-transformers](https://huggingface.co/blog/train-decision-transformers)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™é‡Œå¼€å§‹æ•™ç¨‹ğŸ‘‰[https://huggingface.co/blog/train-decision-transformers](https://huggingface.co/blog/train-decision-transformers)
- en: Further reading
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: 'For more information, we recommend that you check out the following resources:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œå»ºè®®æŸ¥çœ‹ä»¥ä¸‹èµ„æºï¼š
- en: '[Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å†³ç­–Transformerï¼šé€šè¿‡åºåˆ—å»ºæ¨¡è¿›è¡Œå¼ºåŒ–å­¦ä¹ ](https://arxiv.org/abs/2106.01345)'
- en: '[Online Decision Transformer](https://arxiv.org/abs/2202.05607)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åœ¨çº¿å†³ç­–Transformer](https://arxiv.org/abs/2202.05607)'
- en: Author
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½œè€…
- en: This section was written by [Edward Beeching](https://twitter.com/edwardbeeching)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€éƒ¨åˆ†ç”±[Edward Beeching](https://twitter.com/edwardbeeching)æ’°å†™
