- en: Latent Consistency Distillation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 潜在一致性蒸馏
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/lcm_distill](https://huggingface.co/docs/diffusers/training/lcm_distill)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/training/lcm_distill](https://huggingface.co/docs/diffusers/training/lcm_distill)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Latent Consistency Models (LCMs)](https://hf.co/papers/2310.04378) are able
    to generate high-quality images in just a few steps, representing a big leap forward
    because many pipelines require at least 25+ steps. LCMs are produced by applying
    the latent consistency distillation method to any Stable Diffusion model. This
    method works by applying *one-stage guided distillation* to the latent space,
    and incorporating a *skipping-step* method to consistently skip timesteps to accelerate
    the distillation process (refer to section 4.1, 4.2, and 4.3 of the paper for
    more details).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[潜在一致性模型（LCMs）](https://hf.co/papers/2310.04378)能够在几个步骤内生成高质量图像，这是一个重大进步，因为许多流程至少需要25步以上。LCMs是通过将潜在一致性蒸馏方法应用于任何稳定扩散模型而产生的。该方法通过将*单阶段引导蒸馏*应用于潜在空间，并结合*跳步*方法来一致地跳过时间步骤以加速蒸馏过程（有关更多详细信息，请参阅论文的第4.1、4.2和4.3节）。'
- en: If you’re training on a GPU with limited vRAM, try enabling `gradient_checkpointing`,
    `gradient_accumulation_steps`, and `mixed_precision` to reduce memory-usage and
    speedup training. You can reduce your memory-usage even more by enabling memory-efficient
    attention with [xFormers](../optimization/xformers) and [bitsandbytes’](https://github.com/TimDettmers/bitsandbytes)
    8-bit optimizer.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在具有有限vRAM的GPU上进行训练，请尝试启用`gradient_checkpointing`、`gradient_accumulation_steps`和`mixed_precision`以减少内存使用量并加快训练速度。您还可以通过启用[xFormers](../optimization/xformers)和[bitsandbytes'](https://github.com/TimDettmers/bitsandbytes)
    8位优化器的内存高效注意力来进一步减少内存使用。
- en: This guide will explore the [train_lcm_distill_sd_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将探讨[train_lcm_distill_sd_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)脚本，帮助您更熟悉它，以及如何为您自己的用例进行调整。
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行脚本之前，请确保从源代码安装库：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then navigate to the example folder containing the training script and install
    the required dependencies for the script you’re using:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 然后导航到包含训练脚本的示例文件夹，并安装您正在使用的脚本所需的依赖项：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 🤗 Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. It’ll automatically configure your training setup based on your
    hardware and environment. Take a look at the 🤗 Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗加速是一个帮助您在多个GPU/TPU上或使用混合精度进行训练的库。它将根据您的硬件和环境自动配置您的训练设置。查看🤗加速[快速入门](https://huggingface.co/docs/accelerate/quicktour)以了解更多。
- en: 'Initialize an 🤗 Accelerate environment (try enabling `torch.compile` to significantly
    speedup training):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化🤗加速环境（尝试启用`torch.compile`以显著加快训练）：
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default 🤗 Accelerate environment without choosing any configurations:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 设置默认的🤗加速环境，不选择任何配置：
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesn’t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您的环境不支持交互式shell，比如笔记本，您可以使用：
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您想在自己的数据集上训练模型，请查看[创建用于训练的数据集](create_dataset)指南，了解如何创建适用于训练脚本的数据集。
- en: Script parameters
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚本参数
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesn’t cover every aspect of the script
    in detail. If you’re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)
    and let us know if you have any questions or concerns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分突出显示了训练脚本的一些重要部分，以帮助您了解如何修改它，但并未详细涵盖脚本的每个方面。如果您有兴趣了解更多，请随时阅读[脚本](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)，如果您有任何问题或疑虑，请告诉我们。
- en: The training script provides many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L419)
    function. This function provides default values for each parameter, such as the
    training batch size and learning rate, but you can also set your own values in
    the training command if you’d like.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本提供了许多参数，帮助您定制您的训练运行。所有参数及其描述均在[`parse_args()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L419)函数中找到。该函数为每个参数提供了默认值，如训练批量大小和学习率，但如果您愿意，也可以在训练命令中设置自己的值。
- en: 'For example, to speedup training with mixed precision using the fp16 format,
    add the `--mixed_precision` parameter to the training command:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为了加快使用fp16格式的混合精度进行训练，将`--mixed_precision`参数添加到训练命令中：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Most of the parameters are identical to the parameters in the [Text-to-image](text2image#script-parameters)
    training guide, so you’ll focus on the parameters that are relevant to latent
    consistency distillation in this guide.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数参数与[文本到图像](text2image#script-parameters)训练指南中的参数相同，因此您将专注于本指南中与潜在一致性蒸馏相关的参数。
- en: '`--pretrained_teacher_model`: the path to a pretrained latent diffusion model
    to use as the teacher model'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--pretrained_teacher_model`：预训练潜在扩散模型的路径，用作教师模型'
- en: '`--pretrained_vae_model_name_or_path`: path to a pretrained VAE; the SDXL VAE
    is known to suffer from numerical instability, so this parameter allows you to
    specify an alternative VAE (like this [VAE]((https://huggingface.co/madebyollin/sdxl-vae-fp16-fix))
    by madebyollin which works in fp16)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--pretrained_vae_model_name_or_path`: 预训练VAE的路径；SDXL VAE已知存在数值不稳定性问题，因此此参数允许您指定另一个VAE（比如这个[VAE]((https://huggingface.co/madebyollin/sdxl-vae-fp16-fix))，由madebyollin制作，可以在fp16中运行）'
- en: '`--w_min` and `--w_max`: the minimum and maximum guidance scale values for
    guidance scale sampling'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--w_min`和`--w_max`：指导尺度采样的最小和最大值'
- en: '`--num_ddim_timesteps`: the number of timesteps for DDIM sampling'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_ddim_timesteps`: DDIM采样的时间步数'
- en: '`--loss_type`: the type of loss (L2 or Huber) to calculate for latent consistency
    distillation; Huber loss is generally preferred because it’s more robust to outliers'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--loss_type`：用于计算潜在一致性蒸馏的损失类型（L2或Huber）；通常更喜欢Huber损失，因为它对异常值更加稳健'
- en: '`--huber_c`: the Huber loss parameter'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--huber_c`：Huber损失参数'
- en: Training script
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练脚本
- en: The training script starts by creating a dataset class - [`Text2ImageDataset`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L141)
    - for preprocessing the images and creating a training dataset.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本首先创建一个数据集类 - [`Text2ImageDataset`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L141)
    - 用于预处理图像并创建训练数据集。
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For improved performance on reading and writing large datasets stored in the
    cloud, this script uses the [WebDataset](https://github.com/webdataset/webdataset)
    format to create a preprocessing pipeline to apply transforms and create a dataset
    and dataloader for training. Images are processed and fed to the training loop
    without having to download the full dataset first.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高在云中读取和写入大型数据集的性能，此脚本使用[WebDataset](https://github.com/webdataset/webdataset)格式创建一个预处理管道，应用变换并创建一个数据集和数据加载器用于训练。图像被处理并馈送到训练循环中，而无需先下载完整数据集。
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the [`main()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L768)
    function, all the necessary components like the noise scheduler, tokenizers, text
    encoders, and VAE are loaded. The teacher UNet is also loaded here and then you
    can create a student UNet from the teacher UNet. The student UNet is updated by
    the optimizer during training.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在[`main()`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L768)函数中，加载了所有必要的组件，如噪声调度程序、标记器、文本编码器和VAE。教师UNet也在这里加载，然后您可以从教师UNet创建一个学生UNet。在训练过程中，优化器会更新学生UNet。
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now you can create the [optimizer](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L979)
    to update the UNet parameters:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以创建[优化器](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L979)来更新UNet参数：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create the [dataset](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L994):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 创建[数据集](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L994)：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Next, you’re ready to setup the [training loop](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1049)
    and implement the latent consistency distillation method (see Algorithm 1 in the
    paper for more details). This section of the script takes care of adding noise
    to the latents, sampling and creating a guidance scale embedding, and predicting
    the original image from the noise.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以设置[训练循环](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1049)并实现潜在一致性蒸馏方法（有关更多详细信息，请参见论文中的算法1）。脚本的这一部分负责向潜在变量添加噪声、采样和创建指导尺度嵌入，并从噪声中预测原始图像。
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It gets the [teacher model predictions](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1172)
    and the [LCM predictions](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1209)
    next, calculates the loss, and then backpropagates it to the LCM.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，获取[教师模型预测](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1172)和[LCM预测](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1209)，计算损失，然后将其反向传播到LCM。
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers tutorial](../using-diffusers/write_own_pipeline)
    which breaks down the basic pattern of the denoising process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解训练循环的工作原理，请查看[理解管道、模型和调度器教程](../using-diffusers/write_own_pipeline)，该教程解析了去噪过程的基本模式。
- en: Launch the script
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动脚本
- en: Now you’re ready to launch the training script and start distilling!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经准备好启动训练脚本并开始蒸馏！
- en: For this guide, you’ll use the `--train_shards_path_or_url` to specify the path
    to the [Conceptual Captions 12M](https://github.com/google-research-datasets/conceptual-12m)
    dataset stored on the Hub [here](https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset).
    Set the `MODEL_DIR` environment variable to the name of the teacher model and
    `OUTPUT_DIR` to where you want to save the model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，您将使用`--train_shards_path_or_url`来指定存储在Hub上的[Conceptual Captions 12M](https://github.com/google-research-datasets/conceptual-12m)数据集的路径。将`MODEL_DIR`环境变量设置为教师模型的名称，将`OUTPUT_DIR`设置为您想要保存模型的位置。
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once training is complete, you can use your new LCM for inference.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，您可以使用新的LCM进行推断。
- en: '[PRE14]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: LoRA
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LoRA
- en: LoRA is a training technique for significantly reducing the number of trainable
    parameters. As a result, training is faster and it is easier to store the resulting
    weights because they are a lot smaller (~100MBs). Use the [train_lcm_distill_lora_sd_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sd_wds.py)
    or [train_lcm_distill_lora_sdxl.wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sdxl_wds.py)
    script to train with LoRA.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA是一种显著减少可训练参数数量的训练技术。因此，训练速度更快，存储结果权重更容易，因为它们要小得多（~100MB）。使用[train_lcm_distill_lora_sd_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sd_wds.py)或[train_lcm_distill_lora_sdxl.wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sdxl_wds.py)脚本来进行LoRA训练。
- en: The LoRA training script is discussed in more detail in the [LoRA training](lora)
    guide.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有关LoRA训练脚本的详细讨论，请参阅[LoRA训练](lora)指南。
- en: Stable Diffusion XL
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散XL
- en: Stable Diffusion XL (SDXL) is a powerful text-to-image model that generates
    high-resolution images, and it adds a second text-encoder to its architecture.
    Use the [train_lcm_distill_sdxl_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sdxl_wds.py)
    script to train a SDXL model with LoRA.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散XL（SDXL）是一个强大的文本到图像模型，可以生成高分辨率图像，并在其架构中添加了第二个文本编码器。使用[train_lcm_distill_sdxl_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sdxl_wds.py)脚本来训练一个带有LoRA的SDXL模型。
- en: The SDXL training script is discussed in more detail in the [SDXL training](sdxl)
    guide.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有关SDXL训练脚本的详细讨论，请参阅[SDXL训练](sdxl)指南。
- en: Next steps
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: 'Congratulations on distilling a LCM model! To learn more about LCM, the following
    may be helpful:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您精炼LCM模型！要了解更多关于LCM的信息，以下内容可能会有所帮助：
- en: Learn how to use [LCMs for inference](../using-diffusers/lcm) for text-to-image,
    image-to-image, and with LoRA checkpoints.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何使用[LCMs进行推理](../using-diffusers/lcm)用于文本到图像、图像到图像以及带有LoRA检查点。
- en: Read the [SDXL in 4 steps with Latent Consistency LoRAs](https://huggingface.co/blog/lcm_lora)
    blog post to learn more about SDXL LCM-LoRA’s for super fast inference, quality
    comparisons, benchmarks, and more.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读[SDXL在4个步骤中使用潜在一致性LoRAs](https://huggingface.co/blog/lcm_lora)博客文章，了解更多关于SDXL
    LCM-LoRA的信息，用于超快推理、质量比较、基准测试等。
