- en: (Automatic) Curriculum Learning for RL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: （自动）强化学习课程
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unitbonus3/curriculum-learning](https://huggingface.co/learn/deep-rl-course/unitbonus3/curriculum-learning)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/learn/deep-rl-course/unitbonus3/curriculum-learning](https://huggingface.co/learn/deep-rl-course/unitbonus3/curriculum-learning)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'While most of the RL methods seen in this course work well in practice, there
    are some cases where using them alone fails. This can happen, for instance, when:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本课程中介绍的大多数强化学习方法在实践中表现良好，但有些情况下仅使用它们会失败。例如，当：
- en: the task to learn is hard and requires an **incremental acquisition of skills**
    (for instance when one wants to make a bipedal agent learn to go through hard
    obstacles, it must first learn to stand, then walk, then maybe jump…)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习的任务很艰巨，需要**逐步习得技能**（例如，当一个人想让一个双足机器人学会穿过困难障碍物时，它必须首先学会站立，然后行走，然后可能跳跃…）
- en: there are variations in the environment (that affect the difficulty) and one
    wants its agent to be **robust** to them
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境中存在变化（影响难度），人们希望他们的代理能够**对其具有鲁棒性**
- en: '![Bipedal](../Images/e675d3cbd1fb1e896c36e92b88b2a7dd.png) ![Movable creepers](../Images/515895e0a85621d86aab110f7a7f5398.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![双足](../Images/e675d3cbd1fb1e896c36e92b88b2a7dd.png) ![可移动的爬行者](../Images/515895e0a85621d86aab110f7a7f5398.png)'
- en: '[TeachMyAgent](https://developmentalsystems.org/TeachMyAgent/)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[TeachMyAgent](https://developmentalsystems.org/TeachMyAgent/)'
- en: In such cases, it seems needed to propose different tasks to our RL agent and
    organize them such that the agent progressively acquires skills. This approach
    is called **Curriculum Learning** and usually implies a hand-designed curriculum
    (or set of tasks organized in a specific order). In practice, one can, for instance,
    control the generation of the environment, the initial states, or use Self-Play
    and control the level of opponents proposed to the RL agent.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，似乎需要向我们的强化学习代理提出不同的任务，并组织这些任务，使代理逐渐习得技能。这种方法称为**课程学习**，通常意味着手动设计的课程（或按特定顺序组织的任务集）。在实践中，例如，可以控制环境的生成，初始状态，或者使用自我对弈并控制提供给强化学习代理的对手的水平。
- en: 'As designing such a curriculum is not always trivial, the field of **Automatic
    Curriculum Learning (ACL) proposes to design approaches that learn to create such
    an organization of tasks in order to maximize the RL agent’s performances**. Portelas
    et al. proposed to define ACL as:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设计这样的课程并不总是简单的，**自动课程学习（ACL）领域提出设计方法，学习创建这样的任务组织，以最大化强化学习代理的表现**。Portelas等人提出将ACL定义为：
- en: … a family of mechanisms that automatically adapt the distribution of training
    data by learning to adjust the selection of learning situations to the capabilities
    of RL agents.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: … 一系列机制，通过学习调整学习情境的选择，自动调整训练数据的分布，以适应强化学习代理的能力。
- en: As an example, OpenAI used **Domain Randomization** (they applied random variations
    on the environment) to make a robot hand solve Rubik’s Cubes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，OpenAI使用**领域随机化**（他们在环境中应用随机变化）让一个机器人手解决魔方。
- en: '![Dr](../Images/375a72dcd7269a70641cfd815a1e9467.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![博士](../Images/375a72dcd7269a70641cfd815a1e9467.png)'
- en: '[OpenAI - Solving Rubik’s Cube with a Robot Hand](https://openai.com/blog/solving-rubiks-cube/)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenAI - 用机器人手解决魔方](https://openai.com/blog/solving-rubiks-cube/)'
- en: Finally, you can play with the robustness of agents trained in the [TeachMyAgent](https://huggingface.co/spaces/flowers-team/Interactive_DeepRL_Demo)
    benchmark by controlling environment variations or even drawing the terrain 👇
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以通过控制环境变化或甚至绘制地形👇来玩强化学习代理在[TeachMyAgent](https://huggingface.co/spaces/flowers-team/Interactive_DeepRL_Demo)基准测试中训练的鲁棒性
- en: '![Demo](../Images/5c2270050486e329736af710094b7c28.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![演示](../Images/5c2270050486e329736af710094b7c28.png)'
- en: '[https://huggingface.co/spaces/flowers-team/Interactive_DeepRL_Demo](https://huggingface.co/spaces/flowers-team/Interactive_DeepRL_Demo)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/spaces/flowers-team/Interactive_DeepRL_Demo](https://huggingface.co/spaces/flowers-team/Interactive_DeepRL_Demo)'
- en: Further reading
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information, we recommend that you check out the following resources:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请查看以下资源：
- en: Overview of the field
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 领域概述
- en: '[Automatic Curriculum Learning For Deep RL: A Short Survey](https://arxiv.org/pdf/2003.04664.pdf)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度强化学习的自动课程学习：简短调查](https://arxiv.org/pdf/2003.04664.pdf)'
- en: '[Curriculum for Reinforcement Learning](https://lilianweng.github.io/posts/2020-01-29-curriculum-rl/)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[强化学习课程](https://lilianweng.github.io/posts/2020-01-29-curriculum-rl/)'
- en: Recent methods
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最新方法
- en: '[Evolving Curricula with Regret-Based Environment Design](https://arxiv.org/abs/2203.01302)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过基于遗憾的环境设计演变课程](https://arxiv.org/abs/2203.01302)'
- en: '[Curriculum Reinforcement Learning via Constrained Optimal Transport](https://proceedings.mlr.press/v162/klink22a.html)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过受限最优传输进行课程强化学习](https://proceedings.mlr.press/v162/klink22a.html)'
- en: '[Prioritized Level Replay](https://arxiv.org/abs/2010.03934)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优先级水平重播](https://arxiv.org/abs/2010.03934)'
- en: Author
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作者
- en: This section was written by [Clément Romac](https://twitter.com/ClementRomac)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本节由[Clément Romac](https://twitter.com/ClementRomac)撰写
