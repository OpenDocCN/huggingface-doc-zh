- en: Kandinsky
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 康定斯基
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/kandinsky](https://huggingface.co/docs/diffusers/using-diffusers/kandinsky)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/using-diffusers/kandinsky](https://huggingface.co/docs/diffusers/using-diffusers/kandinsky)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The Kandinsky models are a series of multilingual text-to-image generation models.
    The Kandinsky 2.0 model uses two multilingual text encoders and concatenates those
    results for the UNet.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 康定斯基模型是一系列多语言文本到图像生成模型。康定斯基2.0模型使用两个多语言文本编码器，并将这些结果连接到UNet中。
- en: '[Kandinsky 2.1](../api/pipelines/kandinsky) changes the architecture to include
    an image prior model ([`CLIP`](https://huggingface.co/docs/transformers/model_doc/clip))
    to generate a mapping between text and image embeddings. The mapping provides
    better text-image alignment and it is used with the text embeddings during training,
    leading to higher quality results. Finally, Kandinsky 2.1 uses a [Modulating Quantized
    Vectors (MoVQ)](https://huggingface.co/papers/2209.09002) decoder - which adds
    a spatial conditional normalization layer to increase photorealism - to decode
    the latents into images.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[康定斯基2.1](../api/pipelines/kandinsky)改变了架构，包括一个图像先前模型（[`CLIP`](https://huggingface.co/docs/transformers/model_doc/clip)），用于生成文本和图像嵌入之间的映射。该映射提供更好的文本-图像对齐，并在训练期间与文本嵌入一起使用，从而产生更高质量的结果。最后，康定斯基2.1使用了一个[调制量化向量（MoVQ）](https://huggingface.co/papers/2209.09002)解码器，它添加了一个空间条件归一化层以增加照片逼真度，将潜在特征解码为图像。'
- en: '[Kandinsky 2.2](../api/pipelines/kandinsky_v22) improves on the previous model
    by replacing the image encoder of the image prior model with a larger CLIP-ViT-G
    model to improve quality. The image prior model was also retrained on images with
    different resolutions and aspect ratios to generate higher-resolution images and
    different image sizes.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[康定斯基2.2](../api/pipelines/kandinsky_v22)通过用更大的CLIP-ViT-G模型替换图像先前模型的图像编码器来改进先前模型。图像先前模型还经过重新训练，用不同分辨率和长宽比的图像生成更高分辨率和不同尺寸的图像。'
- en: '[Kandinsky 3](../api/pipelines/kandinsky3) simplifies the architecture and
    shifts away from the two-stage generation process involving the prior model and
    diffusion model. Instead, Kandinsky 3 uses [Flan-UL2](https://huggingface.co/google/flan-ul2)
    to encode text, a UNet with [BigGan-deep](https://hf.co/papers/1809.11096) blocks,
    and [Sber-MoVQGAN](https://github.com/ai-forever/MoVQGAN) to decode the latents
    into images. Text understanding and generated image quality are primarily achieved
    by using a larger text encoder and UNet.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[康定斯基3](../api/pipelines/kandinsky3)简化了架构，并摆脱了涉及先前模型和扩散模型的两阶段生成过程。相反，康定斯基3使用[Flan-UL2](https://huggingface.co/google/flan-ul2)来编码文本，一个带有[BigGan-deep](https://hf.co/papers/1809.11096)块的UNet，以及[Sber-MoVQGAN](https://github.com/ai-forever/MoVQGAN)来将潜在特征解码为图像。通过使用更大的文本编码器和UNet，主要实现了文本理解和生成图像质量的提高。'
- en: This guide will show you how to use the Kandinsky models for text-to-image,
    image-to-image, inpainting, interpolation, and more.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将向您展示如何使用康定斯基模型进行文本到图像、图像到图像、修复、插值等操作。
- en: 'Before you begin, make sure you have the following libraries installed:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已安装以下库：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Kandinsky 2.1 and 2.2 usage is very similar! The only difference is Kandinsky
    2.2 doesn’t accept `prompt` as an input when decoding the latents. Instead, Kandinsky
    2.2 only accepts `image_embeds` during decoding.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 康定斯基2.1和2.2的用法非常相似！唯一的区别是康定斯基2.2在解码潜在特征时不接受`prompt`作为输入。相反，康定斯基2.2在解码时只接受`image_embeds`。
- en: Kandinsky 3 has a more concise architecture and it doesn’t require a prior model.
    This means it’s usage is identical to other diffusion models like [Stable Diffusion
    XL](sdxl).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 康定斯基3具有更简洁的架构，不需要先前的模型。这意味着它的用法与其他扩散模型（如[稳定扩散XL](sdxl)）相同。
- en: Text-to-image
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本到图像
- en: To use the Kandinsky models for any task, you always start by setting up the
    prior pipeline to encode the prompt and generate the image embeddings. The prior
    pipeline also generates `negative_image_embeds` that correspond to the negative
    prompt `""`. For better results, you can pass an actual `negative_prompt` to the
    prior pipeline, but this’ll increase the effective batch size of the prior pipeline
    by 2x.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用康定斯基模型执行任何任务，您始终要先设置先前流程以对提示进行编码并生成图像嵌入。先前流程还会生成与负提示`""`对应的`negative_image_embeds`。为了获得更好的结果，您可以向先前流程传递实际的`negative_prompt`，但这会使先前流程的有效批量大小增加2倍。
- en: Kandinsky 2.1Kandinsky 2.2Kandinsky 3
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 康定斯基2.1康定斯基2.2康定斯基3
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now pass all the prompts and embeddings to the [KandinskyPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyPipeline)
    to generate an image:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将所有提示和嵌入传递给[KandinskyPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyPipeline)以生成图像：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/7a49f6e1db66e1eebcfa846868181899.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a49f6e1db66e1eebcfa846868181899.png)'
- en: 🤗 Diffusers also provides an end-to-end API with the [KandinskyCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyCombinedPipeline)
    and [KandinskyV22CombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22CombinedPipeline),
    meaning you don’t have to separately load the prior and text-to-image pipeline.
    The combined pipeline automatically loads both the prior model and the decoder.
    You can still set different values for the prior pipeline with the `prior_guidance_scale`
    and `prior_num_inference_steps` parameters if you want.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗扩散器还提供了一个端到端的API，其中包括[KandinskyCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyCombinedPipeline)和[KandinskyV22CombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22CombinedPipeline)，这意味着您不必单独加载先前的模型和文本到图像的流程。合并流程会自动加载先前模型和解码器。如果需要，您仍然可以通过`prior_guidance_scale`和`prior_num_inference_steps`参数为先前流程设置不同的值。
- en: 'Use the [AutoPipelineForText2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForText2Image)
    to automatically call the combined pipelines under the hood:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[AutoPipelineForText2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForText2Image)来自动调用底层的合并流程：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 康定斯基2.1康定斯基2.2
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Image-to-image
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像到图像
- en: 'For image-to-image, pass the initial image and text prompt to condition the
    image to the pipeline. Start by loading the prior pipeline:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像到图像，将初始图像和文本提示传递给管道以对图像进行条件设置。首先加载先前管道：
- en: Kandinsky 2.1Kandinsky 2.2Kandinsky 3
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2Kandinsky 3
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Download an image to condition on:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下载一个图像进行条件设置：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/f2a11ed9e52e5fabb2124e5fe7bba075.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2a11ed9e52e5fabb2124e5fe7bba075.png)'
- en: 'Generate the `image_embeds` and `negative_image_embeds` with the prior pipeline:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前管道生成`image_embeds`和`negative_image_embeds`：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now pass the original image, and all the prompts and embeddings to the pipeline
    to generate an image:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将原始图像和所有提示和嵌入传递给管道以生成图像：
- en: Kandinsky 2.1Kandinsky 2.2Kandinsky 3
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2Kandinsky 3
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/8554b2d04f4b98afeb9692a00447ba5d.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8554b2d04f4b98afeb9692a00447ba5d.png)'
- en: 🤗 Diffusers also provides an end-to-end API with the [KandinskyImg2ImgCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyImg2ImgCombinedPipeline)
    and [KandinskyV22Img2ImgCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22Img2ImgCombinedPipeline),
    meaning you don’t have to separately load the prior and image-to-image pipeline.
    The combined pipeline automatically loads both the prior model and the decoder.
    You can still set different values for the prior pipeline with the `prior_guidance_scale`
    and `prior_num_inference_steps` parameters if you want.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Diffusers还提供了端到端的API，使用[KandinskyImg2ImgCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyImg2ImgCombinedPipeline)和[KandinskyV22Img2ImgCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22Img2ImgCombinedPipeline)，这意味着您不必单独加载先前和图像到图像管道。组合管道会自动加载先前模型和解码器。如果需要，仍然可以通过`prior_guidance_scale`和`prior_num_inference_steps`参数为先前管道设置不同的值。
- en: 'Use the [AutoPipelineForImage2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)
    to automatically call the combined pipelines under the hood:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[AutoPipelineForImage2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)来在内部自动调用组合管道：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Inpainting
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修复
- en: '⚠️ The Kandinsky models use ⬜️ **white pixels** to represent the masked area
    now instead of black pixels. If you are using [KandinskyInpaintPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyInpaintPipeline)
    in production, you need to change the mask to use white pixels:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ Kandinsky模型现在使用⬜️ **白色像素**来代表遮罩区域，而不是黑色像素。如果您正在生产中使用[KandinskyInpaintPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyInpaintPipeline)，您需要将遮罩更改为使用白色像素：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For inpainting, you’ll need the original image, a mask of the area to replace
    in the original image, and a text prompt of what to inpaint. Load the prior pipeline:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于修复，您将需要原始图像、原始图像中要替换的区域的遮罩，以及要修复的内容的文本提示。加载先前管道：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Load an initial image and create a mask:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 加载初始图像并创建遮罩：
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Generate the embeddings with the prior pipeline:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前管道生成嵌入：
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now pass the initial image, mask, and prompt and embeddings to the pipeline
    to generate an image:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将初始图像、遮罩、提示和嵌入传递给管道以生成图像：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2
- en: '[PRE13]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/06d9ede591c4c816c0afb1ac1756de88.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06d9ede591c4c816c0afb1ac1756de88.png)'
- en: 'You can also use the end-to-end [KandinskyInpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyInpaintCombinedPipeline)
    and [KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)
    to call the prior and decoder pipelines together under the hood. Use the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    for this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用端到端的[KandinskyInpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky#diffusers.KandinskyInpaintCombinedPipeline)和[KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)来在内部同时调用先前和解码器管道。使用[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)来实现：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Interpolation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插值
- en: 'Interpolation allows you to explore the latent space between the image and
    text embeddings which is a cool way to see some of the prior model’s intermediate
    outputs. Load the prior pipeline and two images you’d like to interpolate:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 插值允许您探索图像和文本嵌入之间的潜在空间，这是一种很酷的方式来查看先前模型的中间输出。加载先前管道和您想要插值的两个图像：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/c39ee2cbaacad2963f3842a301c122a7.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c39ee2cbaacad2963f3842a301c122a7.png)'
- en: a cat
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一只猫
- en: '![](../Images/d28a21117fde9e1974b55867c4e29dea.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d28a21117fde9e1974b55867c4e29dea.png)'
- en: Van Gogh's Starry Night painting
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 梵高的《星夜》绘画
- en: Specify the text or images to interpolate, and set the weights for each text
    or image. Experiment with the weights to see how they affect the interpolation!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 指定要插值的文本或图像，并为每个文本或图像设置权重。尝试不同的权重以查看它们如何影响插值！
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Call the `interpolate` function to generate the embeddings, and then pass them
    to the pipeline to generate the image:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`interpolate`函数生成嵌入，然后将其传递给管道生成图像：
- en: Kandinsky 2.1Kandinsky 2.2
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1Kandinsky 2.2
- en: '[PRE17]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/59fe929dc7d1553d026875441e579c7b.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59fe929dc7d1553d026875441e579c7b.png)'
- en: ControlNet
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ControlNet
- en: ⚠️ ControlNet is only supported for Kandinsky 2.2!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ ControlNet仅支持Kandinsky 2.2！
- en: ControlNet enables conditioning large pretrained diffusion models with additional
    inputs such as a depth map or edge detection. For example, you can condition Kandinsky
    2.2 with a depth map so the model understands and preserves the structure of the
    depth image.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet使得可以使用额外的输入条件化大型预训练扩散模型，例如深度图或边缘检测。例如，您可以使用深度图对Kandinsky 2.2进行条件设置，以便模型理解并保留深度图像的结构。
- en: 'Let’s load an image and extract it’s depth map:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载一张图像并提取其深度图：
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/098067659c7d591c7d25aac963832424.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/098067659c7d591c7d25aac963832424.png)'
- en: 'Then you can use the `depth-estimation` [Pipeline](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)
    from 🤗 Transformers to process the image and retrieve the depth map:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用🤗 Transformers的`depth-estimation` [Pipeline](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)处理图像并检索深度图：
- en: '[PRE19]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Text-to-image
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本到图像
- en: 'Load the prior pipeline and the [KandinskyV22ControlnetPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetPipeline):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 加载先前的管道和[KandinskyV22ControlnetPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetPipeline)：
- en: '[PRE20]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Generate the image embeddings from a prompt and negative prompt:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从提示和负提示生成图像嵌入：
- en: '[PRE21]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, pass the image embeddings and the depth image to the [KandinskyV22ControlnetPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetPipeline)
    to generate an image:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将图像嵌入和深度图像传递给[KandinskyV22ControlnetPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetPipeline)以生成图像：
- en: '[PRE22]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/b044b806899a4ae7cdc6df24f2b71924.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b044b806899a4ae7cdc6df24f2b71924.png)'
- en: Image-to-image
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像到图像
- en: 'For image-to-image with ControlNet, you’ll need to use the:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用ControlNet的图像到图像，您需要使用：
- en: '[KandinskyV22PriorEmb2EmbPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22PriorEmb2EmbPipeline)
    to generate the image embeddings from a text prompt and an image'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KandinskyV22PriorEmb2EmbPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22PriorEmb2EmbPipeline)从文本提示和图像生成图像嵌入'
- en: '[KandinskyV22ControlnetImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetImg2ImgPipeline)
    to generate an image from the initial image and the image embeddings'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KandinskyV22ControlnetImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetImg2ImgPipeline)从初始图像和图像嵌入生成图像'
- en: 'Process and extract a depth map of an initial image of a cat with the `depth-estimation`
    [Pipeline](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)
    from 🤗 Transformers:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用🤗 Transformers的`depth-estimation` [Pipeline](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.Pipeline)处理和提取猫的初始图像的深度图：
- en: '[PRE23]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Load the prior pipeline and the [KandinskyV22ControlnetImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetImg2ImgPipeline):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 加载先前的管道和[KandinskyV22ControlnetImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetImg2ImgPipeline)：
- en: '[PRE24]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Pass a text prompt and the initial image to the prior pipeline to generate
    the image embeddings:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 传递文本提示和初始图像到先前的管道以生成图像嵌入：
- en: '[PRE25]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now you can run the [KandinskyV22ControlnetImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetImg2ImgPipeline)
    to generate an image from the initial image and the image embeddings:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以运行[KandinskyV22ControlnetImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22ControlnetImg2ImgPipeline)从初始图像和图像嵌入生成图像：
- en: '[PRE26]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/3b9c48325073009cf6dc5d406bfe39d2.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b9c48325073009cf6dc5d406bfe39d2.png)'
- en: Optimizations
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化
- en: Kandinsky is unique because it requires a prior pipeline to generate the mappings,
    and a second pipeline to decode the latents into an image. Optimization efforts
    should be focused on the second pipeline because that is where the bulk of the
    computation is done. Here are some tips to improve Kandinsky during inference.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky是独特的，因为它需要一个先前的管道来生成映射，以及第二个管道来将潜在变量解码为图像。优化工作应该集中在第二个管道上，因为那里完成了大部分计算。以下是一些改进Kandinsky推理的提示。
- en: 'Enable [xFormers](../optimization/xformers) if you’re using PyTorch < 2.0:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您使用的是PyTorch < 2.0，请启用[xFormers](../optimization/xformers)：
- en: '[PRE27]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Enable `torch.compile` if you’re using PyTorch >= 2.0 to automatically use
    scaled dot-product attention (SDPA):'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您使用的是PyTorch >= 2.0，请启用`torch.compile`以自动使用缩放点积注意力（SDPA）：
- en: '[PRE28]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This is the same as explicitly setting the attention processor to use [AttnAddedKVProcessor2_0](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.AttnAddedKVProcessor2_0):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这与显式设置注意力处理器为[AttnAddedKVProcessor2_0](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.AttnAddedKVProcessor2_0)相同：
- en: '[PRE29]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Offload the model to the CPU with [enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)
    to avoid out-of-memory errors:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)将模型卸载到CPU以避免内存不足错误：
- en: '[PRE30]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'By default, the text-to-image pipeline uses the [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)
    but you can replace it with another scheduler like [DDPMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler)
    to see how that affects the tradeoff between inference speed and image quality:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，文本到图像管道使用[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，但您可以将其替换为另一个调度程序，如[DDPMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler)，以查看它如何影响推理速度和图像质量之间的权衡：
- en: '[PRE31]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
