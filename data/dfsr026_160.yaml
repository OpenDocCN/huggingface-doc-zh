- en: Stable Diffusion pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ç®¡é“
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion is a text-to-image latent diffusion model created by the researchers
    and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/)
    and [LAION](https://laion.ai/). Latent diffusion applies the diffusion process
    over a lower dimensional latent space to reduce memory and compute complexity.
    This specific type of diffusion model was proposed in [High-Resolution Image Synthesis
    with Latent Diffusion Models](https://huggingface.co/papers/2112.10752) by Robin
    Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£æ˜¯ç”±[CompVis](https://github.com/CompVis)ã€[Stability AI](https://stability.ai/)å’Œ[LAION](https://laion.ai/)çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåˆ›å»ºçš„æ–‡æœ¬åˆ°å›¾åƒæ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚æ½œåœ¨æ‰©æ•£å°†æ‰©æ•£è¿‡ç¨‹åº”ç”¨äºè¾ƒä½ç»´åº¦çš„æ½œåœ¨ç©ºé—´ï¼Œä»¥å‡å°‘å†…å­˜å’Œè®¡ç®—å¤æ‚æ€§ã€‚è¿™ç§ç‰¹å®šç±»å‹çš„æ‰©æ•£æ¨¡å‹æ˜¯ç”±Robin
    Rombachã€Andreas Blattmannã€Dominik Lorenzã€Patrick Esserã€BjÃ¶rn Ommeråœ¨ã€Šä½¿ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡Œé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆã€‹ä¸­æå‡ºçš„ã€‚
- en: Stable Diffusion is trained on 512x512 images from a subset of the LAION-5B
    dataset. This model uses a frozen CLIP ViT-L/14 text encoder to condition the
    model on text prompts. With its 860M UNet and 123M text encoder, the model is
    relatively lightweight and can run on consumer GPUs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£æ˜¯åœ¨LAION-5Bæ•°æ®é›†çš„512x512å›¾åƒä¸Šè®­ç»ƒçš„ã€‚è¯¥æ¨¡å‹ä½¿ç”¨å†»ç»“çš„CLIP ViT-L/14æ–‡æœ¬ç¼–ç å™¨æ¥æ ¹æ®æ–‡æœ¬æç¤ºå¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ã€‚è¯¥æ¨¡å‹å…·æœ‰860Mçš„UNetå’Œ123Mçš„æ–‡æœ¬ç¼–ç å™¨ï¼Œç›¸å¯¹è½»é‡çº§ï¼Œå¯ä»¥åœ¨æ¶ˆè´¹è€…GPUä¸Šè¿è¡Œã€‚
- en: For more details about how Stable Diffusion works and how it differs from the
    base latent diffusion model, take a look at the Stability AI [announcement](https://stability.ai/blog/stable-diffusion-announcement)
    and our own [blog post](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work)
    for more technical details.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³ç¨³å®šæ‰©æ•£çš„å·¥ä½œåŸç†åŠå…¶ä¸åŸºæœ¬æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„åŒºåˆ«çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹Stability AIçš„[å…¬å‘Š](https://stability.ai/blog/stable-diffusion-announcement)å’Œæˆ‘ä»¬è‡ªå·±çš„[åšå®¢æ–‡ç« ](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work)ä»¥è·å–æ›´å¤šæŠ€æœ¯ç»†èŠ‚ã€‚
- en: You can find the original codebase for Stable Diffusion v1.0 at [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)
    and Stable Diffusion v2.0 at [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)
    as well as their original scripts for various tasks. Additional official checkpoints
    for the different Stable Diffusion versions and tasks can be found on the [CompVis](https://huggingface.co/CompVis),
    [Runway](https://huggingface.co/runwayml), and [Stability AI](https://huggingface.co/stabilityai)
    Hub organizations. Explore these organizations to find the best checkpoint for
    your use-case!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨[CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)æ‰¾åˆ°ç¨³å®šæ‰©æ•£v1.0çš„åŸå§‹ä»£ç åº“ï¼Œä»¥åŠåœ¨[Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)æ‰¾åˆ°ç¨³å®šæ‰©æ•£v2.0çš„åŸå§‹ä»£ç åº“ï¼Œä»¥åŠå®ƒä»¬å„è‡ªçš„å„ç§ä»»åŠ¡çš„åŸå§‹è„šæœ¬ã€‚ä¸åŒç¨³å®šæ‰©æ•£ç‰ˆæœ¬å’Œä»»åŠ¡çš„é¢å¤–å®˜æ–¹æ£€æŸ¥ç‚¹å¯ä»¥åœ¨[CompVis](https://huggingface.co/CompVis)ã€[Runway](https://huggingface.co/runwayml)å’Œ[Stability
    AI](https://huggingface.co/stabilityai) Hubç»„ç»‡ä¸­æ‰¾åˆ°ã€‚æ¢ç´¢è¿™äº›ç»„ç»‡ï¼Œæ‰¾åˆ°é€‚åˆæ‚¨ç”¨ä¾‹çš„æœ€ä½³æ£€æŸ¥ç‚¹ï¼
- en: 'The table below summarizes the available Stable Diffusion pipelines, their
    supported tasks, and an interactive demo:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è¡¨æ€»ç»“äº†å¯ç”¨çš„ç¨³å®šæ‰©æ•£ç®¡é“ã€å®ƒä»¬æ”¯æŒçš„ä»»åŠ¡ä»¥åŠäº¤äº’å¼æ¼”ç¤ºï¼š
- en: '| Pipeline | Supported tasks | ğŸ¤— Space |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| ç®¡é“ | æ”¯æŒçš„ä»»åŠ¡ | ğŸ¤— ç©ºé—´ |'
- en: '| --- | --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [StableDiffusion](./text2img) | text-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusion](./text2img) | æ–‡æœ¬åˆ°å›¾åƒ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
- en: '| [StableDiffusionImg2Img](./img2img) | image-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface/diffuse-the-rest)
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionImg2Img](./img2img) | å›¾åƒåˆ°å›¾åƒ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface/diffuse-the-rest)
    |'
- en: '| [StableDiffusionInpaint](./inpaint) | inpainting | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/runwayml/stable-diffusion-inpainting)
    |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionInpaint](./inpaint) | è¡¥å…¨ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/runwayml/stable-diffusion-inpainting)
    |'
- en: '| [StableDiffusionDepth2Img](./depth2img) | depth-to-image | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/radames/stable-diffusion-depth2img)
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionDepth2Img](./depth2img) | æ·±åº¦åˆ°å›¾åƒ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/radames/stable-diffusion-depth2img)
    |'
- en: '| [StableDiffusionImageVariation](./image_variation) | image variation | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations)
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionImageVariation](./image_variation) | å›¾åƒå˜åŒ– | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations)
    |'
- en: '| [StableDiffusionPipelineSafe](./stable_diffusion_safe) | filtered text-to-image
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/AIML-TUDA/unsafe-vs-safe-stable-diffusion)
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionPipelineSafe](./stable_diffusion_safe) | è¿‡æ»¤çš„æ–‡æœ¬åˆ°å›¾åƒ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/AIML-TUDA/unsafe-vs-safe-stable-diffusion)
    |'
- en: '| [StableDiffusion2](./stable_diffusion_2) | text-to-image, inpainting, depth-to-image,
    super-resolution | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusion2](./stable_diffusion_2) | æ–‡æœ¬åˆ°å›¾åƒã€è¡¥å…¨ã€æ·±åº¦åˆ°å›¾åƒã€è¶…åˆ†è¾¨ç‡ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    |'
- en: '| [StableDiffusionXL](./stable_diffusion_xl) | text-to-image, image-to-image
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/RamAnanth1/stable-diffusion-xl)
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionXL](./stable_diffusion_xl) | æ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/RamAnanth1/stable-diffusion-xl)
    |'
- en: '| [StableDiffusionLatentUpscale](./latent_upscale) | super-resolution | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface-projects/stable-diffusion-latent-upscaler)
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionLatentUpscale](./latent_upscale) | è¶…åˆ†è¾¨ç‡ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/huggingface-projects/stable-diffusion-latent-upscaler)
    |'
- en: '| [StableDiffusionUpscale](./upscale) | super-resolution |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionUpscale](./upscale) | è¶…åˆ†è¾¨ç‡ |'
- en: '| [StableDiffusionLDM3D](./ldm3d_diffusion) | text-to-rgb, text-to-depth, text-to-pano
    | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/r23/ldm3d-space)
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionLDM3D](./ldm3d_diffusion) | æ–‡æœ¬åˆ°RGBï¼Œæ–‡æœ¬åˆ°æ·±åº¦ï¼Œæ–‡æœ¬åˆ°å…¨æ™¯ | [![](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/r23/ldm3d-space)
    |'
- en: '| [StableDiffusionUpscaleLDM3D](./ldm3d_diffusion) | ldm3d super-resolution
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [StableDiffusionUpscaleLDM3D](./ldm3d_diffusion) | ldm3dè¶…åˆ†è¾¨ç‡ |'
- en: Tips
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æç¤º
- en: To help you get the most out of the Stable Diffusion pipelines, here are a few
    tips for improving performance and usability. These tips are applicable to all
    Stable Diffusion pipelines.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¸®åŠ©æ‚¨å……åˆ†åˆ©ç”¨ç¨³å®šæ‰©æ•£ç®¡é“ï¼Œè¿™é‡Œæœ‰ä¸€äº›æ”¹å–„æ€§èƒ½å’Œå¯ç”¨æ€§çš„æç¤ºã€‚è¿™äº›æç¤ºé€‚ç”¨äºæ‰€æœ‰ç¨³å®šæ‰©æ•£ç®¡é“ã€‚
- en: Explore tradeoff between speed and quality
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡
- en: '[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    uses the [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    by default, but ğŸ¤— Diffusers provides many other schedulers (some of which are
    faster or output better quality) that are compatible. For example, if you want
    to use the [EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
    instead of the default:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
    é»˜è®¤ä½¿ç”¨[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ï¼Œä½†ğŸ¤—
    Diffusersæä¾›è®¸å¤šå…¶ä»–è°ƒåº¦å™¨ï¼ˆå…¶ä¸­ä¸€äº›æ›´å¿«æˆ–è¾“å‡ºè´¨é‡æ›´å¥½ï¼‰ï¼Œè¿™äº›è°ƒåº¦å™¨æ˜¯å…¼å®¹çš„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³ä½¿ç”¨[EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)è€Œä¸æ˜¯é»˜è®¤å€¼ï¼š'
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Reuse pipeline components to save memory
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é‡å¤ä½¿ç”¨ç®¡é“ç»„ä»¶ä»¥èŠ‚çœå†…å­˜
- en: To save memory and use the same components across multiple pipelines, use the
    `.components` method to avoid loading weights into RAM more than once.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†èŠ‚çœå†…å­˜å¹¶åœ¨å¤šä¸ªç®¡é“ä¸­ä½¿ç”¨ç›¸åŒçš„ç»„ä»¶ï¼Œè¯·ä½¿ç”¨`.components`æ–¹æ³•ï¼Œä»¥é¿å…å°†æƒé‡åŠ è½½åˆ°RAMä¸­è¶…è¿‡ä¸€æ¬¡ã€‚
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
