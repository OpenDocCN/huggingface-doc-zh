- en: VisualBERT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VisualBERT
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/visual_bert](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/visual_bert)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/visual_bert](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/visual_bert)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The VisualBERT model was proposed in [VisualBERT: A Simple and Performant Baseline
    for Vision and Language](https://arxiv.org/pdf/1908.03557) by Liunian Harold Li,
    Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang. VisualBERT is a neural network
    trained on a variety of (image, text) pairs.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'VisualBERT模型是由Liunian Harold Li、Mark Yatskar、Da Yin、Cho-Jui Hsieh、Kai-Wei Chang在[VisualBERT:
    A Simple and Performant Baseline for Vision and Language](https://arxiv.org/pdf/1908.03557)中提出的。VisualBERT是一个在各种（图像，文本）对上训练的神经网络。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We propose VisualBERT, a simple and flexible framework for modeling a broad
    range of vision-and-language tasks. VisualBERT consists of a stack of Transformer
    layers that implicitly align elements of an input text and regions in an associated
    input image with self-attention. We further propose two visually-grounded language
    model objectives for pre-training VisualBERT on image caption data. Experiments
    on four vision-and-language tasks including VQA, VCR, NLVR2, and Flickr30K show
    that VisualBERT outperforms or rivals with state-of-the-art models while being
    significantly simpler. Further analysis demonstrates that VisualBERT can ground
    elements of language to image regions without any explicit supervision and is
    even sensitive to syntactic relationships, tracking, for example, associations
    between verbs and image regions corresponding to their arguments.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了VisualBERT，一个简单灵活的框架，用于建模广泛的视觉和语言任务。VisualBERT由一堆Transformer层组成，通过自注意力隐式对齐输入文本的元素和相关输入图像中的区域。我们进一步提出了两个基于视觉的语言模型目标，用于在图像标题数据上预训练VisualBERT。对包括VQA、VCR、NLVR2和Flickr30K在内的四个视觉和语言任务的实验表明，VisualBERT在简化的同时优于或与最先进的模型相媲美。进一步的分析表明，VisualBERT可以将语言元素与图像区域联系起来，而无需任何明确的监督，并且甚至对句法关系敏感，例如跟踪动词和与其参数对应的图像区域之间的关联。*'
- en: This model was contributed by [gchhablani](https://huggingface.co/gchhablani).
    The original code can be found [here](https://github.com/uclanlp/visualbert).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[gchhablani](https://huggingface.co/gchhablani)贡献。原始代码可以在[这里](https://github.com/uclanlp/visualbert)找到。
- en: Usage tips
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: Most of the checkpoints provided work with the [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    configuration. Other checkpoints provided are the fine-tuned checkpoints for down-stream
    tasks - VQA (‘visualbert-vqa’), VCR (‘visualbert-vcr’), NLVR2 (‘visualbert-nlvr2’).
    Hence, if you are not working on these downstream tasks, it is recommended that
    you use the pretrained checkpoints.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供的大多数检查点适用于[VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)配置。提供的其他检查点是用于下游任务微调的检查点
    - VQA（'visualbert-vqa'）、VCR（'visualbert-vcr'）、NLVR2（'visualbert-nlvr2'）。因此，如果您不是在进行这些下游任务，建议使用预训练检查点。
- en: For the VCR task, the authors use a fine-tuned detector for generating visual
    embeddings, for all the checkpoints. We do not provide the detector and its weights
    as a part of the package, but it will be available in the research projects, and
    the states can be loaded directly into the detector provided.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于VCR任务，作者使用了一个经过微调的检测器来生成视觉嵌入，对于所有的检查点。我们不会将检测器及其权重作为软件包的一部分提供，但它将在研究项目中提供，并且状态可以直接加载到提供的检测器中。
- en: VisualBERT is a multi-modal vision and language model. It can be used for visual
    question answering, multiple choice, visual reasoning and region-to-phrase correspondence
    tasks. VisualBERT uses a BERT-like transformer to prepare embeddings for image-text
    pairs. Both the text and visual features are then projected to a latent space
    with identical dimension.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: VisualBERT是一个多模态视觉和语言模型。它可用于视觉问答、多项选择、视觉推理和区域到短语对应任务。VisualBERT使用类似BERT的变压器来为图像-文本对准备嵌入。然后将文本和视觉特征投影到具有相同维度的潜在空间中。
- en: To feed images to the model, each image is passed through a pre-trained object
    detector and the regions and the bounding boxes are extracted. The authors use
    the features generated after passing these regions through a pre-trained CNN like
    ResNet as visual embeddings. They also add absolute position embeddings, and feed
    the resulting sequence of vectors to a standard BERT model. The text input is
    concatenated in the front of the visual embeddings in the embedding layer, and
    is expected to be bound by [CLS] and a [SEP] tokens, as in BERT. The segment IDs
    must also be set appropriately for the textual and visual parts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要将图像馈送到模型中，必须通过预训练的对象检测器传递每个图像，并提取区域和边界框。作者使用通过将这些区域通过预训练的CNN（如ResNet）传递后生成的特征作为视觉嵌入。他们还添加了绝对位置嵌入，并将生成的向量序列馈送到标准的BERT模型中。文本输入在嵌入层的前面与视觉嵌入连接，并且预期由[CLS]和[SEP]标记限定，就像BERT一样。段ID也必须适当设置为文本和视觉部分。
- en: 'The [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    is used to encode the text. A custom detector/image processor must be used to
    get the visual embeddings. The following example notebooks show how to use VisualBERT
    with Detectron-like models:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)对文本进行编码。必须使用自定义检测器/图像处理器来获取视觉嵌入。以下示例笔记本展示了如何使用类似Detectron的模型与VisualBERT一起使用：
- en: '[VisualBERT VQA demo notebook](https://github.com/huggingface/transformers/tree/main/examples/research_projects/visual_bert)
    : This notebook contains an example on VisualBERT VQA.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisualBERT VQA演示笔记本](https://github.com/huggingface/transformers/tree/main/examples/research_projects/visual_bert)：此笔记本包含VisualBERT
    VQA的示例。'
- en: '[Generate Embeddings for VisualBERT (Colab Notebook)](https://colab.research.google.com/drive/1bLGxKdldwqnMVA5x4neY7-l_8fKGWQYI?usp=sharing)
    : This notebook contains an example on how to generate visual embeddings.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为VisualBERT生成嵌入（Colab笔记本）](https://colab.research.google.com/drive/1bLGxKdldwqnMVA5x4neY7-l_8fKGWQYI?usp=sharing)：此笔记本包含如何生成视觉嵌入的示例。'
- en: 'The following example shows how to get the last hidden state using [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例显示如何使用 [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    获取最后一个隐藏状态：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: VisualBertConfig
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertConfig
- en: '### `class transformers.VisualBertConfig`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/configuration_visual_bert.py#L43)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/configuration_visual_bert.py#L43)'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    VisualBERT model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel).
    Vocabulary size of the model. Defines the different tokens that can be represented
    by the `inputs_ids` passed to the forward method of [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 30522) — VisualBERT 模型的词汇表大小。定义了在调用
    [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    时可以由 `inputs_ids` 表示的不同标记数量。模型的词汇表大小。定义了可以由传递给 [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    的 forward 方法的 `inputs_ids` 表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 编码器层和池化器层的维度。'
- en: '`visual_embedding_dim` (`int`, *optional*, defaults to 512) — Dimensionality
    of the visual embeddings to be passed to the model.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embedding_dim` (`int`, *optional*, defaults to 512) — 要传递给模型的视觉嵌入的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Transformer 编码器中的隐藏层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Transformer 编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Transformer 编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持
    `"gelu"`、`"relu"`、`"selu"` 和 `"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的
    dropout 概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — 注意力概率的
    dropout 比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — 模型可能使用的最大序列长度。通常设置为较大的值（例如
    512、1024 或 2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids` passed when calling [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, defaults to 2) — 在调用 [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    时传递的 `token_type_ids` 的词汇表大小。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的 epsilon。'
- en: '`bypass_transformer` (`bool`, *optional*, defaults to `False`) — Whether or
    not the model should bypass the transformer for the visual embeddings. If set
    to `True`, the model directly concatenates the visual embeddings from `VisualBertEmbeddings`
    with text output from transformers, and then pass it to a self-attention layer.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bypass_transformer` (`bool`, *optional*, defaults to `False`) — 模型是否应绕过 Transformer
    处理视觉嵌入。如果设置为 `True`，模型直接将来自 `VisualBertEmbeddings` 的视觉嵌入与来自 transformers 的文本输出连接起来，然后传递给自注意力层。'
- en: '`special_visual_initialize` (`bool`, *optional*, defaults to `True`) — Whether
    or not the visual token type and position type embedding weights should be initialized
    the same as the textual token type and positive type embeddings. When set to `True`,
    the weights of the textual token type and position type embeddings are copied
    to the respective visual embedding layers.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_visual_initialize` (`bool`, *optional*, defaults to `True`) — 视觉标记类型和位置类型嵌入权重是否应该与文本标记类型和正向类型嵌入相同初始化。当设置为
    `True` 时，文本标记类型和位置类型嵌入的权重将复制到相应的视觉嵌入层。'
- en: This is the configuration class to store the configuration of a [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel).
    It is used to instantiate an VisualBERT model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the VisualBERT [uclanlp/visualbert-vqa-coco-pre](https://huggingface.co/uclanlp/visualbert-vqa-coco-pre)
    architecture.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储 [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    配置的配置类。根据指定的参数实例化 VisualBERT 模型，定义模型架构。使用默认值实例化配置将产生类似于 VisualBERT [uclanlp/visualbert-vqa-coco-pre](https://huggingface.co/uclanlp/visualbert-vqa-coco-pre)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: VisualBertModel
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertModel
- en: '### `class transformers.VisualBertModel`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L664)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L664)'
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）—
    模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare VisualBert Model transformer outputting raw hidden-states without any
    specific head on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的VisualBert模型变压器输出原始隐藏状态，没有特定的头部。此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（如下载或保存，调整输入嵌入，修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: The model can behave as an encoder (with only self-attention) following the
    architecture described in [Attention is all you need](https://arxiv.org/abs/1706.03762)
    by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
    N. Gomez, Lukasz Kaiser and Illia Polosukhin.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以作为一个编码器（仅具有自注意力），遵循[Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion
    Jones，Aidan N. Gomez，Lukasz Kaiser和Illia Polosukhin描述的架构](https://arxiv.org/abs/1706.03762)。
- en: '#### `forward`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L707)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L707)'
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是输入ID？
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被“掩盖”的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被“掩盖”的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是注意力掩码？
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是标记类型ID？
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    输入序列标记在位置嵌入中的位置索引。在范围`[0, config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是位置ID？
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使自注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被“掩盖”，
- en: 0 indicates the head is `masked`.
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“掩盖”。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，您可以直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`visual_embeds` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length,
    visual_embedding_dim)`, *optional*) — The embedded representation of the visual
    inputs, generally derived using using an object detector.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embeds`（形状为`(batch_size, visual_seq_length, visual_embedding_dim)`的`torch.FloatTensor`，*可选*）—
    视觉输入的嵌入表示，通常使用对象检测器派生。'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Mask to avoid performing attention on visual embeddings. Mask values
    selected in `[0, 1]`:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask`（形状为`(batch_size, visual_seq_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在视觉嵌入上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的令牌，
- en: 0 for tokens that are `masked`.
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的令牌。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力掩码是什么？
- en: '`visual_token_type_ids` (`torch.LongTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Segment token indices to indicate different portions of the visual
    embeds.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VisualBERT的作者将*visual_token_type_ids*设置为所有令牌的*1*。
- en: '[What are token type IDs?](../glossary#token-type-ids) The authors of VisualBERT
    set the *visual_token_type_ids* to *1* for all tokens.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 令牌类型ID是什么？
- en: '`image_text_alignment` (`torch.LongTensor` of shape `(batch_size, visual_seq_length,
    alignment_number)`, *optional*) — Image-Text alignment uses to decide the position
    IDs of the visual embeddings.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_text_alignment`（形状为`(batch_size, visual_seq_length, alignment_number)`的`torch.LongTensor`，*可选*）—
    用于决定视觉嵌入的位置ID的图像-文本对齐。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）—
    模型最后一层的隐藏状态的序列输出。'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    and inputs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）和输入的不同元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_token_type_ids`（形状为`(batch_size, visual_seq_length)`的`torch.LongTensor`，*可选*）—
    段令牌索引，用于指示视觉嵌入的不同部分。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`（形状为`(batch_size, hidden_size)`的`torch.FloatTensor`）— 经过用于辅助预训练任务的层进一步处理后的序列的第一个令牌（分类令牌）的最后一层隐藏状态。例如，对于BERT系列模型，这将返回经过线性层和tanh激活函数处理后的分类令牌。线性层的权重是从预训练期间的下一个句子预测（分类）目标中训练的。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层的输出，则为一个+每层输出的一个）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层的输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在自注意力头部中使用注意力softmax后的注意力权重，用于计算加权平均值。
- en: The [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    forward method, overrides the `__call__` special method.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: VisualBertForPreTraining
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertForPreTraining
- en: '### `class transformers.VisualBertForPreTraining`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L858)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L858)'
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: 'VisualBert Model with two heads on top as done during the pretraining: a `masked
    language modeling` head and a `sentence-image prediction (classification)` head.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: VisualBert模型在预训练期间在顶部有两个头部：一个`掩码语言建模`头部和一个`句子-图像预测（分类）`头部。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（如下载或保存，调整输入嵌入大小，修剪头部等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L883)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L883)'
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未屏蔽`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`已屏蔽`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于一个*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于一个*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。在范围`[0, config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块中选择的头部失效的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部是`未屏蔽`，
- en: 0 indicates the head is `masked`.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部是`已屏蔽`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，您可以选择直接传递一个嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`visual_embeds` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length,
    visual_embedding_dim)`, *optional*) — The embedded representation of the visual
    inputs, generally derived using using an object detector.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embeds`（形状为`(batch_size, visual_seq_length, visual_embedding_dim)`的`torch.FloatTensor`，*可选*）—
    视觉输入的嵌入表示，通常使用对象检测器派生。'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Mask to avoid performing attention on visual embeddings. Mask values
    selected in `[0, 1]`:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask`（形状为`(batch_size, visual_seq_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在视觉嵌入上执行注意力的掩码。选择的掩码值在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被掩码`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`被掩码`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_token_type_ids` (`torch.LongTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Segment token indices to indicate different portions of the visual
    embeds.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_token_type_ids`（形状为`(batch_size, visual_seq_length)`的`torch.LongTensor`，*可选*）—
    段标记索引，用于指示视觉嵌入的不同部分。'
- en: '[What are token type IDs?](../glossary#token-type-ids) The authors of VisualBERT
    set the *visual_token_type_ids* to *1* for all tokens.'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids) VisualBERT的作者将*visual_token_type_ids*设置为*1*以表示所有标记。'
- en: '`image_text_alignment` (`torch.LongTensor` of shape `(batch_size, visual_seq_length,
    alignment_number)`, *optional*) — Image-Text alignment uses to decide the position
    IDs of the visual embeddings.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_text_alignment`（形状为`(batch_size, visual_seq_length, alignment_number)`的`torch.LongTensor`，*可选*）—
    用于决定视觉嵌入的位置ID的图像-文本对齐。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, total_sequence_length)`,
    *optional*) — Labels for computing the masked language modeling loss. Indices
    should be in `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens
    with indices set to `-100` are ignored (masked), the loss is only computed for
    the tokens with labels in `[0, ..., config.vocab_size]`'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, total_sequence_length)`的`torch.LongTensor`，*可选*）—
    用于计算掩码语言建模损失的标签。索引应在`[-100, 0, ..., config.vocab_size]`中（请参见`input_ids`文档字符串）。将索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`中的标记。'
- en: '`sentence_image_labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    — Labels for computing the sentence-image prediction (classification) loss. Input
    should be a sequence pair (see `input_ids` docstring) Indices should be in `[0,
    1]`:'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sentence_image_labels`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算句子-图像预测（分类）损失的标签。输入应为一个序列对（请参见`input_ids`文档字符串）索引应在`[0,
    1]`中。'
- en: 0 indicates sequence B is a matching pair of sequence A for the given image,
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示对于给定图像，序列B是序列A的匹配对，
- en: 1 indicates sequence B is a random sequence w.r.t A for the given image.
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示对于给定图像，序列B是相对于A的随机序列。
- en: Returns
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.visual_bert.modeling_visual_bert.VisualBertForPreTrainingOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.visual_bert.modeling_visual_bert.VisualBertForPreTrainingOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.visual_bert.modeling_visual_bert.VisualBertForPreTrainingOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    and inputs.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.visual_bert.modeling_visual_bert.VisualBertForPreTrainingOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时），包含根据配置（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）和输入的不同元素。
- en: '`loss` (*optional*, returned when `labels` is provided, `torch.FloatTensor`
    of shape `(1,)`) — Total loss as the sum of the masked language modeling loss
    and the sentence-image prediction (classification) loss.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（*可选*，当提供`labels`时返回，形状为`(1,)`的`torch.FloatTensor`）— 作为掩码语言建模损失和句子-图像预测（分类）损失之和的总损失。'
- en: '`prediction_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.vocab_size)`) — Prediction scores of the language modeling head (scores
    for each vocabulary token before SoftMax).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）—
    语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`seq_relationship_logits` (`torch.FloatTensor` of shape `(batch_size, 2)`)
    — Prediction scores of the sentence-image prediction (classification) head (scores
    of True/False continuation before SoftMax).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seq_relationship_logits`（形状为`(batch_size, 2)`的`torch.FloatTensor`）— 句子-图像预测（分类）头的预测分数（SoftMax之前的True/False连续分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每个层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层的输出以及初始嵌入输出的隐藏状态。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在自注意力头中用于计算加权平均值的注意力softmax后的注意力权重。
- en: The [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    forward method, overrides the `__call__` special method.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE8]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: VisualBertForQuestionAnswering
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertForQuestionAnswering
- en: '### `class transformers.VisualBertForQuestionAnswering`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1162)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1162)'
- en: '[PRE9]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）-
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: VisualBert Model with a classification/regression head on top (a dropout and
    a linear layer on top of the pooled output) for VQA.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: VisualBert模型在顶部具有分类/回归头（在汇总输出的顶部有一个dropout和一个线性层）用于VQA。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（例如下载或保存，调整输入嵌入大小，修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1181)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1181)'
- en: '[PRE10]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）-
    避免在填充标记索引上执行注意力的掩码。选择的掩码值在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表*未被掩码*的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 代表*被掩码*的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）-
    段标记索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 每个输入序列令牌的位置在位置嵌入中的索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块中选择的头部失效的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*)
    — 可选地，可以直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`visual_embeds` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length,
    visual_embedding_dim)`, *optional*) — The embedded representation of the visual
    inputs, generally derived using using an object detector.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embeds` (`torch.FloatTensor`，形状为`(batch_size, visual_seq_length, visual_embedding_dim)`，*可选*)
    — 视觉输入的嵌入表示，通常使用对象检测器派生。'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Mask to avoid performing attention on visual embeddings. Mask values
    selected in `[0, 1]`:'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask` (`torch.FloatTensor`，形状为`(batch_size, visual_seq_length)`，*可选*)
    — 避免对视觉嵌入执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的令牌，
- en: 0 for tokens that are `masked`.
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的令牌。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_token_type_ids` (`torch.LongTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Segment token indices to indicate different portions of the visual
    embeds.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_token_type_ids` (`torch.LongTensor`，形状为`(batch_size, visual_seq_length)`，*可选*)
    — 段令牌索引，用于指示视觉嵌入的不同部分。'
- en: '[What are token type IDs?](../glossary#token-type-ids) The authors of VisualBERT
    set the *visual_token_type_ids* to *1* for all tokens.'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是令牌类型ID？](../glossary#token-type-ids) VisualBERT的作者将*visual_token_type_ids*设置为所有令牌的*1*。'
- en: '`image_text_alignment` (`torch.LongTensor` of shape `(batch_size, visual_seq_length,
    alignment_number)`, *optional*) — Image-Text alignment uses to decide the position
    IDs of the visual embeddings.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_text_alignment` (`torch.LongTensor`，形状为`(batch_size, visual_seq_length,
    alignment_number)`，*可选*) — 用于决定视觉嵌入的位置ID的图像-文本对齐。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, total_sequence_length)`,
    *optional*) — Labels for computing the sequence classification/regression loss.
    Indices should be in `[0, ..., config.num_labels - 1]`. A KLDivLoss is computed
    between the labels and the returned logits.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size, total_sequence_length)`，*可选*)
    — 用于计算序列分类/回归损失的标签。索引应在`[0, ..., config.num_labels - 1]`范围内。标签和返回的logits之间计算KLDivLoss。'
- en: Returns
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    and inputs.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类（如果config.num_labels==1则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels)`) — 分类（如果config.num_labels==1则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层的输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在自注意力头中用于计算加权平均值的注意力权重之后的注意力softmax。
- en: The [VisualBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[VisualBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForQuestionAnswering)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE11]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: VisualBertForMultipleChoice
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertForMultipleChoice
- en: '### `class transformers.VisualBertForMultipleChoice`'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertForMultipleChoice`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1009)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1009)'
- en: '[PRE12]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: VisualBert Model with a multiple choice classification head on top (a linear
    layer on top of the pooled output and a softmax) e.g. for VCR tasks.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: VisualBert模型在顶部具有多选分类头（池化输出顶部的线性层和softmax），例如用于VCR任务。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为其所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1027)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1027)'
- en: '[PRE13]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, num_choices, sequence_length)`的`torch.LongTensor`）—
    词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_choices, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, num_choices, sequence_length)`的`torch.FloatTensor`，*可选*）—
    避免在填充标记索引上执行注意力的蒙版。蒙版值在`[0, 1]`中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`掩码`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`掩码`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力蒙版？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（`torch.LongTensor`，形状为`(batch_size, num_choices, sequence_length)`，*可选*）—
    段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应一个*句子B*的标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, num_choices, sequence_length)`的`torch.LongTensor`，*可选*）—
    每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使自注意力模块的选定头部失效的掩码。掩码值选择在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部`未被屏蔽`，
- en: 0 indicates the head is `masked`.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部`被屏蔽`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_choices, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, num_choices, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`visual_embeds` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length,
    visual_embedding_dim)`, *optional*) — The embedded representation of the visual
    inputs, generally derived using using an object detector.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embeds`（形状为`(batch_size, visual_seq_length, visual_embedding_dim)`的`torch.FloatTensor`，*可选*）—
    视觉输入的嵌入表示，通常使用对象检测器派生。'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Mask to avoid performing attention on visual embeddings. Mask values
    selected in `[0, 1]`:'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask`（形状为`(batch_size, visual_seq_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在视觉嵌入上执行注意力的掩码。掩码值选择在`[0, 1]`范围内：'
- en: 1 for tokens that are `not masked`,
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 用于那些`未被屏蔽`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 用于`被屏蔽`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力屏蔽？](../glossary#attention-mask)'
- en: '`visual_token_type_ids` (`torch.LongTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Segment token indices to indicate different portions of the visual
    embeds.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_token_type_ids`（形状为`(batch_size, visual_seq_length)`的`torch.LongTensor`，*可选*）—
    段标记索引，用于指示视觉嵌入的不同部分。'
- en: '[What are token type IDs?](../glossary#token-type-ids) The authors of VisualBERT
    set the *visual_token_type_ids* to *1* for all tokens.'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids) VisualBERT的作者将*visual_token_type_ids*设置为*1*，适用于所有标记。'
- en: '`image_text_alignment` (`torch.LongTensor` of shape `(batch_size, visual_seq_length,
    alignment_number)`, *optional*) — Image-Text alignment uses to decide the position
    IDs of the visual embeddings.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_text_alignment`（形状为`(batch_size, visual_seq_length, alignment_number)`的`torch.LongTensor`，*可选*）—
    图像文本对齐用于决定视觉嵌入的位置ID。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the multiple choice classification loss. Indices should be in `[0,
    ..., num_choices-1]` where `num_choices` is the size of the second dimension of
    the input tensors. (See `input_ids` above)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`标签`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算多选分类损失的标签。索引应在`[0, ...,
    num_choices-1]`范围内，其中`num_choices`是输入张量第二维的大小。（参见上面的`input_ids`）'
- en: Returns
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.MultipleChoiceModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.MultipleChoiceModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.MultipleChoiceModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    and inputs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.MultipleChoiceModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包括根据配置（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape *(1,)*, *optional*, returned when `labels`
    is provided) — Classification loss.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为*(1,)*的`torch.FloatTensor`，*可选*，在提供`labels`时返回）— 分类损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_choices)`) — *num_choices*
    is the second dimension of the input tensors. (see *input_ids* above).'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, num_choices)`的`torch.FloatTensor`）— *num_choices*是输入张量的第二维。（参见上面的*input_ids*）。'
- en: Classification scores (before SoftMax).
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分类得分（SoftMax之前）。
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [VisualBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForMultipleChoice)
    forward method, overrides the `__call__` special method.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[VisualBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForMultipleChoice)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: VisualBertForVisualReasoning
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertForVisualReasoning
- en: '### `class transformers.VisualBertForVisualReasoning`'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertForVisualReasoning`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1288)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1288)'
- en: '[PRE15]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: VisualBert Model with a sequence classification head on top (a dropout and a
    linear layer on top of the pooled output) for Visual Reasoning e.g. for NLVR task.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: VisualBert模型在顶部具有一个序列分类头（在池化输出的顶部有一个dropout和一个线性层），用于视觉推理，例如用于NLVR任务。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1307)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1307)'
- en: '[PRE16]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`） — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)获取详细信息。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被掩盖`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`被掩盖`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 段标记索引，指示输入的第一部分和第二部分。索引选在`[0, 1]`之间：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    每个输入序列标记在位置嵌入中的位置索引。在范围`[0, config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使自注意力模块的选定头部失效的掩码。在`[0, 1]`中选择的掩码值：'
- en: 1 indicates the head is `not masked`,
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮罩，
- en: 0 indicates the head is `masked`.
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮罩。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`visual_embeds` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length,
    visual_embedding_dim)`, *optional*) — The embedded representation of the visual
    inputs, generally derived using using an object detector.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embeds`（形状为`(batch_size, visual_seq_length, visual_embedding_dim)`的`torch.FloatTensor`，*可选*）—
    视觉输入的嵌入表示，通常使用对象检测器派生。'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Mask to avoid performing attention on visual embeddings. Mask values
    selected in `[0, 1]`:'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask`（形状为`(batch_size, visual_seq_length)`的`torch.FloatTensor`，*可选*）—
    用于避免对视觉嵌入执行注意力的掩码。在`[0, 1]`中选择的掩码值：'
- en: 1 for tokens that are `not masked`,
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被遮罩的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被遮罩的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_token_type_ids` (`torch.LongTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Segment token indices to indicate different portions of the visual
    embeds.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_token_type_ids`（形状为`(batch_size, visual_seq_length)`的`torch.LongTensor`，*可选*）—
    段标记索引，用于指示视觉嵌入的不同部分。'
- en: '[What are token type IDs?](../glossary#token-type-ids) The authors of VisualBERT
    set the *visual_token_type_ids* to *1* for all tokens.'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids) VisualBERT的作者将*visual_token_type_ids*设置为*1*以表示所有标记。'
- en: '`image_text_alignment` (`torch.LongTensor` of shape `(batch_size, visual_seq_length,
    alignment_number)`, *optional*) — Image-Text alignment uses to decide the position
    IDs of the visual embeddings.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_text_alignment`（形状为`(batch_size, visual_seq_length, alignment_number)`的`torch.LongTensor`，*可选*）—
    用于决定视觉嵌入的位置ID的图像-文本对齐。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. A classification loss is computed (Cross-Entropy)
    against these labels.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算序列分类/回归损失的标签。索引应在`[0,
    ..., config.num_labels - 1]`中。根据这些标签计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    and inputs.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包括各种元素，取决于配置（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 分类（如果`config.num_labels==1`则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, config.num_labels)`的`torch.FloatTensor`）— 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有一个嵌入层，+
    一个用于每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每一层输出的模型的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [VisualBertForVisualReasoning](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForVisualReasoning)
    forward method, overrides the `__call__` special method.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '[VisualBertForVisualReasoning](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForVisualReasoning)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Example:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: VisualBertForRegionToPhraseAlignment
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VisualBertForRegionToPhraseAlignment
- en: '### `class transformers.VisualBertForRegionToPhraseAlignment`'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VisualBertForRegionToPhraseAlignment`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1448)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1448)'
- en: '[PRE18]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: VisualBert Model with a Masked Language Modeling head and an attention layer
    on top for Region-to-Phrase Alignment e.g. for Flickr30 Entities task.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: VisualBert模型具有一个用于区域到短语对齐的遮蔽语言建模头部和一个位于顶部的注意力层，例如用于Flickr30实体任务。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1469)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/visual_bert/modeling_visual_bert.py#L1469)'
- en: '[PRE19]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    指示输入的第一部分和第二部分的段标记索引。索引选在`[0, 1]`之间：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于一个 *sentence B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`，*可选*)
    — 每个输入序列标记在位置嵌入中的位置索引。选择范围为 `[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置 ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块中选择的头部失效的掩码。掩码值选择在 `[0, 1]` 之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部是 `not masked` 的，
- en: 0 indicates the head is `masked`.
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部是 `masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*可选*)
    — 可选地，可以直接传递嵌入表示而不是传递 `input_ids`。如果您想要更多控制权来将 `input_ids` 索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`visual_embeds` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length,
    visual_embedding_dim)`, *optional*) — The embedded representation of the visual
    inputs, generally derived using using an object detector.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embeds` (`torch.FloatTensor`，形状为 `(batch_size, visual_seq_length, visual_embedding_dim)`，*可选*)
    — 视觉输入的嵌入表示，通常使用对象检测器生成。'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Mask to avoid performing attention on visual embeddings. Mask values
    selected in `[0, 1]`:'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask` (`torch.FloatTensor`，形状为 `(batch_size, visual_seq_length)`，*可选*)
    — 用于避免在视觉嵌入上执行注意力的掩码。掩码值选择在 `[0, 1]` 之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被 `masked` 的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部是 `masked` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_token_type_ids` (`torch.LongTensor` of shape `(batch_size, visual_seq_length)`,
    *optional*) — Segment token indices to indicate different portions of the visual
    embeds.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_token_type_ids` (`torch.LongTensor`，形状为 `(batch_size, visual_seq_length)`，*可选*)
    — 段标记索引，用于指示视觉嵌入的不同部分。'
- en: '[What are token type IDs?](../glossary#token-type-ids) The authors of VisualBERT
    set the *visual_token_type_ids* to *1* for all tokens.'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids) VisualBERT 的作者将 *visual_token_type_ids*
    设置为 *1* 以表示所有标记。'
- en: '`image_text_alignment` (`torch.LongTensor` of shape `(batch_size, visual_seq_length,
    alignment_number)`, *optional*) — Image-Text alignment uses to decide the position
    IDs of the visual embeddings.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_text_alignment` (`torch.LongTensor`，形状为 `(batch_size, visual_seq_length,
    alignment_number)`，*可选*) — 图像-文本对齐用于决定视觉嵌入的位置 ID。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是一个普通的元组。'
- en: '`region_to_phrase_position` (`torch.LongTensor` of shape `(batch_size, total_sequence_length)`,
    *optional*) — The positions depicting the position of the image embedding corresponding
    to the textual tokens.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`region_to_phrase_position` (`torch.LongTensor`，形状为 `(batch_size, total_sequence_length)`，*可选*)
    — 描述图像嵌入位置与文本标记位置对应的位置。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, total_sequence_length,
    visual_sequence_length)`, *optional*) — Labels for computing the masked language
    modeling loss. KLDivLoss is computed against these labels and the outputs from
    the attention layer.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为 `(batch_size, total_sequence_length, visual_sequence_length)`，*可选*)
    — 用于计算掩码语言建模损失的标签。KLDivLoss 是根据这些标签和注意力层的输出计算的。'
- en: Returns
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig))
    and inputs.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含各种元素，取决于配置（[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为 `(1,)`，*可选*，当提供了 `labels` 时返回) — 分类（如果 config.num_labels==1
    则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为 `(batch_size, config.num_labels)`) — 分类（如果
    config.num_labels==1 则为回归）得分（SoftMax 之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态，以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [VisualBertForRegionToPhraseAlignment](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForRegionToPhraseAlignment)
    forward method, overrides the `__call__` special method.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '[VisualBertForRegionToPhraseAlignment](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForRegionToPhraseAlignment)的前向方法重写了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后的处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE20]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
