- en: UnivNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: UnivNet
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/univnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/univnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/univnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/univnet)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The UnivNet model was proposed in [UnivNet: A Neural Vocoder with Multi-Resolution
    Spectrogram Discriminators for High-Fidelity Waveform Generation](https://arxiv.org/abs/2106.07889)
    by Won Jang, Dan Lim, Jaesam Yoon, Bongwan Kin, and Juntae Kim. The UnivNet model
    is a generative adversarial network (GAN) trained to synthesize high fidelity
    speech waveforms. The UnivNet model shared in `transformers` is the *generator*,
    which maps a conditioning log-mel spectrogram and optional noise sequence to a
    speech waveform (e.g. a vocoder). Only the generator is required for inference.
    The *discriminator* used to train the `generator` is not implemented.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'UnivNet模型是由Won Jang、Dan Lim、Jaesam Yoon、Bongwan Kin和Juntae Kim在[UnivNet: A
    Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity
    Waveform Generation](https://arxiv.org/abs/2106.07889)中提出的。UnivNet模型是一个生成对抗网络（GAN），用于合成高保真度语音波形。在`transformers`中共享的UnivNet模型是*生成器*，它将一个条件化的对数梅尔频谱图和可选的噪声序列映射到语音波形（例如声码器）。推理只需要生成器。用于训练`生成器`的*鉴别器*没有实现。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Most neural vocoders employ band-limited mel-spectrograms to generate waveforms.
    If full-band spectral features are used as the input, the vocoder can be provided
    with as much acoustic information as possible. However, in some models employing
    full-band mel-spectrograms, an over-smoothing problem occurs as part of which
    non-sharp spectrograms are generated. To address this problem, we propose UnivNet,
    a neural vocoder that synthesizes high-fidelity waveforms in real time. Inspired
    by works in the field of voice activity detection, we added a multi-resolution
    spectrogram discriminator that employs multiple linear spectrogram magnitudes
    computed using various parameter sets. Using full-band mel-spectrograms as input,
    we expect to generate high-resolution signals by adding a discriminator that employs
    spectrograms of multiple resolutions as the input. In an evaluation on a dataset
    containing information on hundreds of speakers, UnivNet obtained the best objective
    and subjective results among competing models for both seen and unseen speakers.
    These results, including the best subjective score for text-to-speech, demonstrate
    the potential for fast adaptation to new speakers without a need for training
    from scratch.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*大多数神经声码器使用带限制的梅尔频谱图来生成波形。如果将全频段谱特征用作输入，则声码器可以提供尽可能多的声学信息。然而，在一些使用全频段梅尔频谱图的模型中，会出现过度平滑的问题，其中生成了非锐利的频谱图。为了解决这个问题，我们提出了UnivNet，一个能够实时合成高保真波形的神经声码器。受到语音活动检测领域的研究启发，我们添加了一个多分辨率谱图鉴别器，该鉴别器使用了使用不同参数集计算的多个线性谱图幅度。通过使用全频段梅尔频谱图作为输入，我们希望通过添加一个使用多个分辨率谱图作为输入的鉴别器来生成高分辨率信号。在包含数百位说话者信息的数据集上进行评估时，UnivNet在看到和未看到的说话者方面获得了最佳客观和主观结果。这些结果，包括文本转语音的最佳主观评分，展示了快速适应新说话者的潜力，而无需从头开始训练。*'
- en: 'Tips:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: The `noise_sequence` argument for [UnivNetModel.forward()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel.forward)
    should be standard Gaussian noise (such as from `torch.randn`) of shape `([batch_size],
    noise_length, model.config.model_in_channels)`, where `noise_length` should match
    the length dimension (dimension 1) of the `input_features` argument. If not supplied,
    it will be randomly generated; a `torch.Generator` can be supplied to the `generator`
    argument so that the forward pass can be reproduced. (Note that [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    will return generated noise by default, so it shouldn’t be necessary to generate
    `noise_sequence` manually.)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UnivNetModel.forward()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel.forward)的`noise_sequence`参数应为标准的高斯噪声（例如来自`torch.randn`），形状为`([batch_size],
    noise_length, model.config.model_in_channels)`，其中`noise_length`应与`input_features`参数的长度维度（维度1）匹配。如果未提供，将随机生成；可以向`generator`参数提供`torch.Generator`，以便可以重现前向传递。（请注意，[UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)默认会返回生成的噪声，因此通常不需要手动生成`noise_sequence`。）'
- en: Padding added by [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    can be removed from the [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    output through the `UnivNetFeatureExtractor.batch_decode()` method, as shown in
    the usage example below.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`UnivNetFeatureExtractor.batch_decode()`方法可以从[UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)输出中移除[UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)添加的填充，如下面的用法示例所示。
- en: Padding the end of each waveform with silence can reduce artifacts at the end
    of the generated audio sample. This can be done by supplying `pad_end = True`
    to [UnivNetFeatureExtractor.**call**()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor.__call__).
    See [this issue](https://github.com/seungwonpark/melgan/issues/8) for more details.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个波形的末尾填充静音可以减少生成音频样本末尾的伪影。可以通过在[UnivNetFeatureExtractor.**call**()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor.__call__)中提供`pad_end
    = True`来实现。更多细节请参见[此问题](https://github.com/seungwonpark/melgan/issues/8)。
- en: 'Usage Example:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 用法示例：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This model was contributed by [dg845](https://huggingface.co/dg845). To the
    best of my knowledge, there is no official code release, but an unofficial implementation
    can be found at [maum-ai/univnet](https://github.com/maum-ai/univnet) with pretrained
    checkpoints [here](https://github.com/maum-ai/univnet#pre-trained-model).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[dg845](https://huggingface.co/dg845)贡献。据我所知，没有官方代码发布，但可以在[maum-ai/univnet](https://github.com/maum-ai/univnet)找到非官方实现，预训练检查点在[这里](https://github.com/maum-ai/univnet#pre-trained-model)。
- en: UnivNetConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UnivNetConfig
- en: '### `class transformers.UnivNetConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.UnivNetConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/configuration_univnet.py#L28)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/configuration_univnet.py#L28)'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model_in_channels` (`int`, *optional*, defaults to 64) — The number of input
    channels for the UnivNet residual network. This should correspond to `noise_sequence.shape[1]`
    and the value used in the [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    class.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_in_channels`（`int`，*可选*，默认为64）- UnivNet残差网络的输入通道数。这应该对应于`noise_sequence.shape[1]`和[UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)类中使用的值。'
- en: '`model_hidden_channels` (`int`, *optional*, defaults to 32) — The number of
    hidden channels of each residual block in the UnivNet residual network.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_hidden_channels`（`int`，*可选*，默认为32）- UnivNet残差网络中每个残差块的隐藏通道数。'
- en: '`num_mel_bins` (`int`, *optional*, defaults to 100) — The number of frequency
    bins in the conditioning log-mel spectrogram. This should correspond to the value
    used in the [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    class.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_mel_bins`（`int`，*可选*，默认为100）- 条件对数梅尔频谱图中的频率箱数。这应该对应于[UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)类中使用的值。'
- en: '`resblock_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[3, 3, 3]`) — A tuple of integers defining the kernel sizes of the 1D convolutional
    layers in the UnivNet residual network. The length of `resblock_kernel_sizes`
    defines the number of resnet blocks and should match that of `resblock_stride_sizes`
    and `resblock_dilation_sizes`.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_kernel_sizes`（`Tuple[int]`或`List[int]`，*可选*，默认为`[3, 3, 3]`）- 一个整数元组，定义了UnivNet残差网络中1D卷积层的内核大小。`resblock_kernel_sizes`的长度定义了resnet块的数量，并应与`resblock_stride_sizes`和`resblock_dilation_sizes`相匹配。'
- en: '`resblock_stride_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[8, 8, 4]`) — A tuple of integers defining the stride sizes of the 1D convolutional
    layers in the UnivNet residual network. The length of `resblock_stride_sizes`
    should match that of `resblock_kernel_sizes` and `resblock_dilation_sizes`.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_stride_sizes`（`Tuple[int]`或`List[int]`，*可选*，默认为`[8, 8, 4]`）- 一个整数元组，定义了UnivNet残差网络中1D卷积层的步幅大小。`resblock_stride_sizes`的长度应与`resblock_kernel_sizes`和`resblock_dilation_sizes`相匹配。'
- en: '`resblock_dilation_sizes` (`Tuple[Tuple[int]]` or `List[List[int]]`, *optional*,
    defaults to `[[1, 3, 9, 27], [1, 3, 9, 27], [1, 3, 9, 27]]`) — A nested tuple
    of integers defining the dilation rates of the dilated 1D convolutional layers
    in the UnivNet residual network. The length of `resblock_dilation_sizes` should
    match that of `resblock_kernel_sizes` and `resblock_stride_sizes`. The length
    of each nested list in `resblock_dilation_sizes` defines the number of convolutional
    layers per resnet block.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_dilation_sizes`（`Tuple[Tuple[int]]`或`List[List[int]]`，*可选*，默认为`[[1,
    3, 9, 27], [1, 3, 9, 27], [1, 3, 9, 27]]`）- 一个嵌套的整数元组，定义了UnivNet残差网络中扩张的1D卷积层的扩张率。`resblock_dilation_sizes`的长度应与`resblock_kernel_sizes`和`resblock_stride_sizes`相匹配。`resblock_dilation_sizes`中每个嵌套列表的长度定义了每个resnet块中的卷积层数量。'
- en: '`kernel_predictor_num_blocks` (`int`, *optional*, defaults to 3) — The number
    of residual blocks in the kernel predictor network, which calculates the kernel
    and bias for each location variable convolution layer in the UnivNet residual
    network.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_predictor_num_blocks`（`int`，*可选*，默认为3）- 核预测网络中的残差块数量，用于计算UnivNet残差网络中每个位置变量卷积层的内核和偏置。'
- en: '`kernel_predictor_hidden_channels` (`int`, *optional*, defaults to 64) — The
    number of hidden channels for each residual block in the kernel predictor network.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_predictor_hidden_channels`（`int`，*可选*，默认为64）- 核预测网络中每个残差块的隐藏通道数。'
- en: '`kernel_predictor_conv_size` (`int`, *optional*, defaults to 3) — The kernel
    size of each 1D convolutional layer in the kernel predictor network.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_predictor_conv_size`（`int`，*可选*，默认为3）- 核预测网络中每个1D卷积层的内核大小。'
- en: '`kernel_predictor_dropout` (`float`, *optional*, defaults to 0.0) — The dropout
    probability for each residual block in the kernel predictor network.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_predictor_dropout`（`float`，*可选*，默认为0.0）- 核预测网络中每个残差块的丢失概率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.01) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range`（`float`，*可选*，默认为0.01）- 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`leaky_relu_slope` (`float`, *optional*, defaults to 0.2) — The angle of the
    negative slope used by the leaky ReLU activation.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaky_relu_slope`（`float`，*可选*，默认为0.2）- leaky ReLU激活函数使用的负斜率的角度。'
- en: This is the configuration class to store the configuration of a [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel).
    It is used to instantiate a UnivNet vocoder model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the UnivNet [dg845/univnet-dev](https://huggingface.co/dg845/univnet-dev)
    architecture, which corresponds to the ‘c32’ architecture in [maum-ai/univnet](https://github.com/maum-ai/univnet/blob/master/config/default_c32.yaml).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)的配置。根据指定的参数实例化一个UnivNet声码器模型，定义模型架构。使用默认值实例化配置将产生类似于UnivNet
    [dg845/univnet-dev](https://huggingface.co/dg845/univnet-dev)架构的配置，该架构对应于[maum-ai/univnet](https://github.com/maum-ai/univnet/blob/master/config/default_c32.yaml)中的‘c32’架构。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读来自
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Example:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: UnivNetFeatureExtractor
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UnivNetFeatureExtractor
- en: '### `class transformers.UnivNetFeatureExtractor`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.UnivNetFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/feature_extraction_univnet.py#L29)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/feature_extraction_univnet.py#L29)'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_size` (`int`, *optional*, defaults to 1) — The feature dimension of
    the extracted features.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_size` (`int`, *optional*, 默认为 1) — 提取特征的特征维度。'
- en: '`sampling_rate` (`int`, *optional*, defaults to 24000) — The sampling rate
    at which the audio files should be digitalized expressed in hertz (Hz).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *optional*, 默认为 24000) — 音频文件应该以赫兹（Hz）表示的数字化采样率。'
- en: '`padding_value` (`float`, *optional*, defaults to 0.0) — The value to pad with
    when applying the padding strategy defined by the `padding` argument to [UnivNetFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor.__call__).
    Should correspond to audio silence. The `pad_end` argument to `__call__` will
    also use this padding value.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value` (`float`, *optional*, 默认为 0.0) — 在应用由 `padding` 参数定义的填充策略时要填充的值，应与音频静音对应。`__call__`
    中的 `pad_end` 参数也将使用此填充值。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `False`) — Whether to perform
    Tacotron 2 normalization on the input. Normalizing can help to significantly improve
    the performance for some models.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, 默认为 `False`) — 是否对输入执行 Tacotron 2 标准化。标准化可以帮助一些模型显著提高性能。'
- en: '`num_mel_bins` (`int`, *optional*, defaults to 100) — The number of mel-frequency
    bins in the extracted spectrogram features. This should match `UnivNetModel.config.num_mel_bins`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_mel_bins` (`int`, *optional*, 默认为 100) — 提取的频谱图特征中的梅尔频率箱数。这应该与 `UnivNetModel.config.num_mel_bins`
    匹配。'
- en: '`hop_length` (`int`, *optional*, defaults to 256) — The direct number of samples
    between sliding windows. Otherwise referred to as “shift” in many papers. Note
    that this is different from other audio feature extractors such as [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)
    which take the `hop_length` in ms.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hop_length` (`int`, *optional*, 默认为 256) — 滑动窗口之间的直接样本数。在许多论文中也称为“shift”。请注意，这与其他音频特征提取器（如
    [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor））中以毫秒为单位的
    `hop_length` 不同。'
- en: '`win_length` (`int`, *optional*, defaults to 1024) — The direct number of samples
    for each sliding window. Note that this is different from other audio feature
    extractors such as [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)
    which take the `win_length` in ms.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`win_length` (`int`, *optional*, 默认为 1024) — 每个滑动窗口的直接样本数。请注意，这与其他音频特征提取器（如
    [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor））中以毫秒为单位的
    `win_length` 不同。'
- en: '`win_function` (`str`, *optional*, defaults to `"hann_window"`) — Name for
    the window function used for windowing, must be accessible via `torch.{win_function}`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`win_function` (`str`, *optional*, 默认为 `"hann_window"`) — 用于窗口化的窗口函数的名称，必须通过
    `torch.{win_function}` 访问。'
- en: '`filter_length` (`int`, *optional*, defaults to 1024) — The number of FFT components
    to use. If `None`, this is determined using `transformers.audio_utils.optimal_fft_length`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_length` (`int`, *optional*, 默认为 1024) — 要使用的 FFT 组件数。如果为 `None`，则使用
    `transformers.audio_utils.optimal_fft_length` 来确定。'
- en: '`max_length_s` (`int`, *optional*, defaults to 10) — The maximum input lenght
    of the model in seconds. This is used to pad the audio.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length_s` (`int`, *optional*, 默认为 10) — 模型的最大输入长度，以秒为单位。这用于填充音频。'
- en: '`fmin` (`float`, *optional*, defaults to 0.0) — Minimum mel frequency in Hz.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fmin` (`float`, *optional*, 默认为 0.0) — 最小的梅尔频率，以赫兹为单位。'
- en: '`fmax` (`float`, *optional*) — Maximum mel frequency in Hz. If not set, defaults
    to `sampling_rate / 2`.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fmax` (`float`, *optional*) — 最大的梅尔频率，以赫兹为单位。如果未设置，默认为 `sampling_rate / 2`。'
- en: '`mel_floor` (`float`, *optional*, defaults to 1e-09) — Minimum value of mel
    frequency banks. Note that the way [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    uses `mel_floor` is different than in [transformers.audio_utils.spectrogram()](/docs/transformers/v4.37.2/en/internal/audio_utils#transformers.audio_utils.spectrogram).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mel_floor` (`float`, *optional*, 默认为 1e-09) — 梅尔频率银行的最小值。请注意，[UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    使用 `mel_floor` 的方式与 [transformers.audio_utils.spectrogram()](/docs/transformers/v4.37.2/en/internal/audio_utils#transformers.audio_utils.spectrogram)
    中的方式不同。'
- en: '`center` (`bool`, *optional*, defaults to `False`) — Whether to pad the waveform
    so that frame `t` is centered around time `t * hop_length`. If `False`, frame
    `t` will start at time `t * hop_length`.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`center` (`bool`, *optional*, 默认为 `False`) — 是否填充波形，使帧 `t` 围绕时间 `t * hop_length`
    居中。如果为 `False`，帧 `t` 将从时间 `t * hop_length` 开始。'
- en: '`compression_factor` (`float`, *optional*, defaults to 1.0) — The multiplicative
    compression factor for dynamic range compression during spectral normalization.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compression_factor` (`float`, *optional*, 默认为 1.0) — 动态范围压缩期间的乘法压缩因子。'
- en: '`compression_clip_val` (`float`, *optional*, defaults to 1e-05) — The clip
    value applied to the waveform before applying dynamic range compression during
    spectral normalization.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compression_clip_val` (`float`, *optional*, 默认为 1e-05) — 在应用动态范围压缩期间应用于波形的剪切值。'
- en: '`normalize_min` (`float`, *optional*, defaults to -11.512925148010254) — The
    min value used for Tacotron 2-style linear normalization. The default is the original
    value from the Tacotron 2 implementation.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize_min` (`float`, *可选*, 默认为-11.512925148010254) — 用于Tacotron 2风格线性归一化的最小值。默认值是Tacotron
    2实现的原始值。'
- en: '`normalize_max` (`float`, *optional*, defaults to 2.3143386840820312) — The
    max value used for Tacotron 2-style linear normalization. The default is the original
    value from the Tacotron 2 implementation.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize_max` (`float`, *可选*, 默认为2.3143386840820312) — 用于Tacotron 2风格线性归一化的最大值。默认值是Tacotron
    2实现的原始值。'
- en: '`model_in_channels` (`int`, *optional*, defaults to 64) — The number of input
    channels to the [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    model. This should match `UnivNetModel.config.model_in_channels`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_in_channels` (`int`, *可选*, 默认为64) — [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)模型的输入通道数。这应该与`UnivNetModel.config.model_in_channels`匹配。'
- en: '`pad_end_length` (`int`, *optional*, defaults to 10) — If padding the end of
    each waveform, the number of spectrogram frames worth of samples to append. The
    number of appended samples will be `pad_end_length * hop_length`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_end_length` (`int`, *可选*, 默认为10) — 如果在每个波形的末尾填充，要附加的样本的频谱图帧数。附加的样本数将为`pad_end_length
    * hop_length`。'
- en: '`return_attention_mask` (`bool`, *optional*, defaults to `True`) — Whether
    or not [`call`()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor.__call__)
    should return `attention_mask`.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *可选*, 默认为`True`) — [`call`()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor.__call__)是否应返回`attention_mask`。'
- en: Constructs a UnivNet feature extractor.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个UnivNet特征提取器。
- en: This class extracts log-mel-filter bank features from raw speech using the short
    time Fourier Transform (STFT). The STFT implementation follows that of TacoTron
    2 and Hifi-GAN.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该类使用短时傅里叶变换（STFT）从原始语音中提取对数梅尔滤波器组特征。STFT实现遵循TacoTron 2和Hifi-GAN的实现。
- en: This feature extractor inherits from [SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该特征提取器继承自[SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `__call__`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/feature_extraction_univnet.py#L286)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/feature_extraction_univnet.py#L286)'
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`raw_speech` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`)
    — The sequence or batch of sequences to be padded. Each sequence can be a numpy
    array, a list of float values, a list of numpy arrays or a list of list of float
    values. Must be mono channel audio, not stereo, i.e. single float per timestep.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`raw_speech` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`)
    — 要填充的序列或批次序列。每个序列可以是一个numpy数组，一个浮点值列表，一个numpy数组列表或一个浮点值列表的列表。必须是单声道音频，不是立体声，即每个时间步长一个浮点数。'
- en: '`sampling_rate` (`int`, *optional*) — The sampling rate at which the `raw_speech`
    input was sampled. It is strongly recommended to pass `sampling_rate` at the forward
    call to prevent silent errors and allow automatic speech recognition pipeline.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *可选*) — 输入`raw_speech`采样的采样率。强烈建议在前向调用时传递`sampling_rate`，以防止静默错误并允许自动语音识别流水线。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `True`) — Select a strategy to pad the input `raw_speech`
    waveforms (according to the model’s padding side and padding index) among:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str`或[PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *可选*, 默认为`True`) — 选择一种策略来填充输入`raw_speech`波形（根据模型的填充方向和填充索引）：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`：填充到批次中最长的序列（如果只提供一个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到指定的最大长度，该长度由参数`max_length`指定，或者如果未提供该参数，则填充到模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不填充（即，可以输出具有不同长度序列的批次）。'
- en: If `pad_end = True`, that padding will occur before the `padding` strategy is
    applied.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`pad_end = True`，则填充将在应用`padding`策略之前发生。
- en: '`max_length` (`int`, *optional*) — Maximum length of the returned list and
    optionally padding length (see above).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 返回列表的最大长度和可选填充长度（见上文）。'
- en: '`truncation` (`bool`, *optional*, defaults to `True`) — Activates truncation
    to cut input sequences longer than `max_length` to `max_length`.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, *可选*, 默认为`True`) — 激活截断，将长于`max_length`的输入序列截断为`max_length`。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *可选*) — 如果设置，将序列填充到提供的值的倍数。'
- en: This is especially useful to enable the use of Tensor Cores on NVIDIA hardware
    with compute capability `>= 7.5` (Volta), or on TPUs which benefit from having
    sequence lengths be a multiple of 128.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于在NVIDIA硬件上启用Tensor Cores特别有用，其计算能力为`>= 7.5`（Volta），或者对于受益于序列长度为128的倍数的TPU。
- en: '`return_noise` (`bool`, *optional*, defaults to `True`) — Whether to generate
    and return a noise waveform for use in [UnivNetModel.forward()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel.forward).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_noise` (`bool`, *可选*, 默认为`True`) — 是否生成并返回用于[UnivNetModel.forward()](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel.forward)的噪声波形。'
- en: '`generator` (`numpy.random.Generator`, *optional*, defaults to `None`) — An
    optional `numpy.random.Generator` random number generator to use when generating
    noise.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`numpy.random.Generator`, *可选*, 默认为 `None`) — 生成噪音时要使用的可选 `numpy.random.Generator`
    随机数生成器。'
- en: '`pad_end` (`bool`, *optional*, defaults to `False`) — Whether to pad the end
    of each waveform with silence. This can help reduce artifacts at the end of the
    generated audio sample; see [https://github.com/seungwonpark/melgan/issues/8](https://github.com/seungwonpark/melgan/issues/8)
    for more details. This padding will be done before the padding strategy specified
    in `padding` is performed.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_end` (`bool`, *可选*, 默认为 `False`) — 是否在每个波形的末尾填充静音。这可以帮助减少生成音频样本末尾的伪影。有关更多详细信息，请参阅
    [https://github.com/seungwonpark/melgan/issues/8](https://github.com/seungwonpark/melgan/issues/8)。此填充将在执行
    `padding` 中指定的填充策略之前完成。'
- en: '`pad_length` (`int`, *optional*, defaults to `None`) — If padding the end of
    each waveform, the length of the padding in spectrogram frames. If not set, this
    will default to `self.config.pad_end_length`.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_length` (`int`, *可选*, 默认为 `None`) — 如果在每个波形的末尾填充，填充在频谱图帧中的长度。如果未设置，将默认为
    `self.config.pad_end_length`。'
- en: '`do_normalize` (`bool`, *optional*) — Whether to perform Tacotron 2 normalization
    on the input. Normalizing can help to significantly improve the performance for
    some models. If not set, this will default to `self.config.do_normalize`.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *可选*) — 是否对输入执行 Tacotron 2 标准化。标准化可以帮助显著提高某些模型的性能。如果未设置，将默认为
    `self.config.do_normalize`。'
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific feature_extractor’s default.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *可选*) — 是否返回注意力掩码。如果保持默认设置，将根据特定的 feature_extractor
    默认返回注意力掩码。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *可选*) — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.np.array` objects.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回 PyTorch `torch.np.array` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回Numpy `np.ndarray` 对象。'
- en: Main method to featurize and prepare for the model one or several sequence(s).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个或多个序列进行特征化和准备模型的主要方法。
- en: UnivNetModel
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UnivNetModel
- en: '### `class transformers.UnivNetModel`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.UnivNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/modeling_univnet.py#L464)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/modeling_univnet.py#L464)'
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: UnivNet GAN vocoder. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: UnivNet GAN 语音合成器。此模型继承自 [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为其所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/modeling_univnet.py#L511)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/univnet/modeling_univnet.py#L511)'
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor`) — Tensor containing the log-mel spectrograms.
    Can be batched and of shape `(batch_size, sequence_length, config.num_mel_channels)`,
    or un-batched and of shape `(sequence_length, config.num_mel_channels)`.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`) — 包含对数梅尔频谱图的张量。可以是批处理的，形状为 `(batch_size,
    sequence_length, config.num_mel_channels)`，也可以是非批处理的，形状为 `(sequence_length, config.num_mel_channels)`。'
- en: '`noise_sequence` (`torch.FloatTensor`, *optional*) — Tensor containing a noise
    sequence of standard Gaussian noise. Can be batched and of shape `(batch_size,
    sequence_length, config.model_in_channels)`, or un-batched and of shape (sequence_length,
    config.model_in_channels)`. If not supplied, will be randomly generated.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`noise_sequence` (`torch.FloatTensor`, *可选*) — 包含标准高斯噪音的噪音序列的张量。可以是批处理的，形状为
    `(batch_size, sequence_length, config.model_in_channels)`，或者非批处理的，形状为 `(sequence_length,
    config.model_in_channels)`。如果未提供，则将随机生成。'
- en: '`padding_mask` (`torch.BoolTensor`, *optional*) — Mask indicating which parts
    of each sequence are padded. Mask values are selected in `[0, 1]`:'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_mask` (`torch.BoolTensor`, *可选*) — 指示每个序列的哪些部分被填充的掩码。掩码值在 `[0, 1]`
    中选择：'
- en: 1 for tokens that are `not masked`
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 用于未被“masked”的标记
- en: 0 for tokens that are `masked`
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被“masked”的标记
- en: The mask can be batched and of shape `(batch_size, sequence_length)` or un-batched
    and of shape `(sequence_length,)`.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 掩码可以是批处理的，形状为 `(batch_size, sequence_length)`，也可以是非批处理的，形状为 `(sequence_length,)`。
- en: '`generator` (`torch.Generator`, *optional*) — A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic. return_dict — Whether to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    subclass instead of a plain tuple.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`，*可选*）— 一个用于使生成过程确定性的[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)。return_dict
    — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)子类而不是一个普通元组。'
- en: Returns
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.univnet.modeling_univnet.UnivNetModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.univnet.modeling_univnet.UnivNetModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.univnet.modeling_univnet.UnivNetModelOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig))
    and inputs.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.univnet.modeling_univnet.UnivNetModelOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含根据配置（[UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)）和输入的不同元素。
- en: '`waveforms` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Batched 1D (mono-channel) output audio waveforms.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveforms`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`）— 批量的1D（单声道）输出音频波形。'
- en: '`waveform_lengths` (`torch.FloatTensor` of shape `(batch_size,)`) — The batched
    length in samples of each unpadded waveform in `waveforms`.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveform_lengths`（形状为`(batch_size,)`的`torch.FloatTensor`）— `waveforms`中每个未填充波形的批量长度（以样本为单位）。'
- en: The [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`UnivNetModel`的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: Converts a noise waveform and a conditioning spectrogram to a speech waveform.
    Passing a batch of log-mel spectrograms returns a batch of speech waveforms. Passing
    a single, un-batched log-mel spectrogram returns a single, un-batched speech waveform.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 将噪声波形和一个条件谱图转换为语音波形。传递一批log-mel谱图返回一批语音波形。传递一个单独的、未批处理的log-mel谱图返回一个单独的、未批处理的语音波形。
- en: 'Example:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
