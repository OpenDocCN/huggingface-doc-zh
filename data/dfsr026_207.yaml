- en: ScoreSdeVpScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ScoreSdeVpScheduler
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/score_sde_vp](https://huggingface.co/docs/diffusers/api/schedulers/score_sde_vp)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/api/schedulers/score_sde_vp](https://huggingface.co/docs/diffusers/api/schedulers/score_sde_vp)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '`ScoreSdeVpScheduler` is a variance preserving stochastic differential equation
    (SDE) scheduler. It was introduced in the [Score-Based Generative Modeling through
    Stochastic Differential Equations](https://huggingface.co/papers/2011.13456) paper
    by Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano
    Ermon, Ben Poole.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '`ScoreSdeVpScheduler` 是一个方差保持的随机微分方程（SDE）调度器。它在Yang Song, Jascha Sohl-Dickstein,
    Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole的论文[通过随机微分方程进行基于得分的生成建模](https://huggingface.co/papers/2011.13456)中被介绍。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要为：
- en: '*Creating noise from data is easy; creating data from noise is generative modeling.
    We present a stochastic differential equation (SDE) that smoothly transforms a
    complex data distribution to a known prior distribution by slowly injecting noise,
    and a corresponding reverse-time SDE that transforms the prior distribution back
    into the data distribution by slowly removing the noise. Crucially, the reverse-time
    SDE depends only on the time-dependent gradient field (\aka, score) of the perturbed
    data distribution. By leveraging advances in score-based generative modeling,
    we can accurately estimate these scores with neural networks, and use numerical
    SDE solvers to generate samples. We show that this framework encapsulates previous
    approaches in score-based generative modeling and diffusion probabilistic modeling,
    allowing for new sampling procedures and new modeling capabilities. In particular,
    we introduce a predictor-corrector framework to correct errors in the evolution
    of the discretized reverse-time SDE. We also derive an equivalent neural ODE that
    samples from the same distribution as the SDE, but additionally enables exact
    likelihood computation, and improved sampling efficiency. In addition, we provide
    a new way to solve inverse problems with score-based models, as demonstrated with
    experiments on class-conditional generation, image inpainting, and colorization.
    Combined with multiple architectural improvements, we achieve record-breaking
    performance for unconditional image generation on CIFAR-10 with an Inception score
    of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate
    high fidelity generation of 1024 x 1024 images for the first time from a score-based
    generative model.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*从数据中创建噪声很容易；从噪声中创建数据是生成建模。我们提出了一种随机微分方程（SDE），通过缓慢注入噪声，将复杂数据分布平滑地转换为已知的先验分布，以及相应的逆向时间SDE，通过缓慢去除噪声，将先验分布转换回数据分布。关键是，逆向时间SDE仅取决于扰动数据分布的时间相关梯度场（即得分）。通过利用得分为基础的生成建模的进展，我们可以使用神经网络准确估计这些得分，并使用数值SDE求解器生成样本。我们展示了这个框架封装了得分为基础的生成建模和扩散概率建模中的先前方法，允许新的采样程序和新的建模能力。特别是，我们引入了一个预测校正框架，以纠正离散化逆向时间SDE演变中的错误。我们还推导了一个等效的神经ODE，从与SDE相同的分布中采样，但另外还能实现精确的似然计算和改进的采样效率。此外，我们提供了一种使用基于得分的模型解决逆问题的新方法，通过在类条件生成、图像修补和着色方面的实验进行演示。结合多个架构改进，我们在CIFAR-10上实现了无条件图像生成的创纪录性性能，Inception得分为9.89，FID为2.20，竞争性似然度为2.99比特/维，并首次展示了从基于得分的生成模型生成1024
    x 1024图像的高保真度。*'
- en: 🚧 This scheduler is under construction!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 🚧 此调度器正在建设中！
- en: ScoreSdeVpScheduler
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ScoreSdeVpScheduler
- en: '### `class diffusers.schedulers.ScoreSdeVpScheduler`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.schedulers.ScoreSdeVpScheduler`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L27)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L27)'
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_train_timesteps` (`int`, defaults to 2000) — The number of diffusion steps
    to train the model.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_timesteps` (`int`, 默认为2000) — 训练模型的扩散步数。'
- en: '`beta_min` (`int`, defaults to 0.1) —'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_min` (`int`, 默认为0.1) —'
- en: '`beta_max` (`int`, defaults to 20) —'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_max` (`int`, 默认为20) —'
- en: '`sampling_eps` (`int`, defaults to 1e-3) — The end value of sampling where
    timesteps decrease progressively from 1 to epsilon.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_eps` (`int`, 默认为1e-3) — 采样的结束值，其中时间步从1逐渐减少到 epsilon。'
- en: '`ScoreSdeVpScheduler` is a variance preserving stochastic differential equation
    (SDE) scheduler.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`ScoreSdeVpScheduler` 是一个方差保持的随机微分方程（SDE）调度器。'
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)和[ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。
- en: '#### `set_timesteps`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_timesteps`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L51)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L51)'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_inference_steps` (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`) — 使用预训练模型生成样本时的扩散步数。'
- en: '`device` (`str` or `torch.device`, *optional*) — The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`str` 或 `torch.device`, *可选*) — 时间步应移动到的设备。如果为 `None`，则不移动时间步。'
- en: Sets the continuous timesteps used for the diffusion chain (to be run before
    inference).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于扩散链的连续时间步长（在推断之前运行）。
- en: '#### `step_pred`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step_pred`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L63)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/deprecated/scheduling_sde_vp.py#L63)'
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`score` () —'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score` () —'
- en: '`x` () —'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x` () —'
- en: '`t` () —'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t` () —'
- en: '`generator` (`torch.Generator`, *optional*) — A random number generator.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`，*可选*）— 一个随机数生成器。'
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反转SDE来预测上一个时间步的样本。这个函数从学习模型的输出（通常是预测的噪音）中传播扩散过程。
