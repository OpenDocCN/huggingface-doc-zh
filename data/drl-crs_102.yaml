- en: Additional Readings
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外阅读
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit8/additional-readings](https://huggingface.co/learn/deep-rl-course/unit8/additional-readings)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/learn/deep-rl-course/unit8/additional-readings](https://huggingface.co/learn/deep-rl-course/unit8/additional-readings)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: These are **optional readings** if you want to go deeper.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解，这些是**可选阅读**。
- en: PPO Explained
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PPO解释
- en: '[Towards Delivering a Coherent Self-Contained Explanation of Proximal Policy
    Optimization by Daniel Bick](https://fse.studenttheses.ub.rug.nl/25709/1/mAI_2021_BickD.pdf)'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过Daniel Bick提供的一致自包含解释向Proximal Policy Optimization迈进](https://fse.studenttheses.ub.rug.nl/25709/1/mAI_2021_BickD.pdf)'
- en: '[What is the way to understand Proximal Policy Optimization Algorithm in RL?](https://stackoverflow.com/questions/46422845/what-is-the-way-to-understand-proximal-policy-optimization-algorithm-in-rl)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何理解强化学习中的Proximal Policy Optimization算法的方法？
- en: '[Foundations of Deep RL Series, L4 TRPO and PPO by Pieter Abbeel](https://youtu.be/KjWF8VIMGiY)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度强化学习基础系列，L4 TRPO和PPO，由Pieter Abbeel](https://youtu.be/KjWF8VIMGiY)'
- en: '[OpenAI PPO Blogpost](https://openai.com/blog/openai-baselines-ppo/)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI PPO博文](https://openai.com/blog/openai-baselines-ppo/)'
- en: '[Spinning Up RL PPO](https://spinningup.openai.com/en/latest/algorithms/ppo.html)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Spinning Up RL PPO](https://spinningup.openai.com/en/latest/algorithms/ppo.html)'
- en: '[Paper Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[论文Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)'
- en: PPO Implementation details
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PPO实现细节
- en: '[The 37 Implementation Details of Proximal Policy Optimization](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Proximal Policy Optimization的37个实现细节](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)'
- en: '[Part 1 of 3 — Proximal Policy Optimization Implementation: 11 Core Implementation
    Details](https://www.youtube.com/watch?v=MEt6rrxH8W4)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第1部分- Proximal Policy Optimization实现：11个核心实现细节](https://www.youtube.com/watch?v=MEt6rrxH8W4)'
- en: Importance Sampling
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重要性采样
- en: '[Importance Sampling Explained](https://youtu.be/C3p2wI4RAi8)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重要性采样解释
