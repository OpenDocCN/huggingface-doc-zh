- en: Add custom Dependencies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加自定义依赖项
- en: 'Original text: [https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies](https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies](https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Inference Endpoints’ base image includes all required libraries to run inference
    on 🤗 Transformers models, but it also supports custom dependencies. This is useful
    if you want to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 推理端点的基础镜像包含运行🤗 Transformers模型推理所需的所有库，但也支持自定义依赖项。如果您想要：
- en: '[customize your inference pipeline](/docs/inference-endpoints/guides/custom_handler)
    and need additional Python dependencies'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自定义推理管道](/docs/inference-endpoints/guides/custom_handler)并需要额外的Python依赖项'
- en: run a model which requires special dependencies like the newest or a fixed version
    of a library (for example, `tapas` (`torch-scatter`)).
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行需要特殊依赖项的模型，例如最新版本或固定版本的库（例如，`tapas`（`torch-scatter`））。
- en: To add custom dependencies, add a `requirements.txt` [file](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/requirements.txt)
    with the Python dependencies you want to install in your model repository on the
    Hugging Face Hub. When your Endpoint and Image artifacts are created, Inference
    Endpoints checks if the model repository contains a `requirements.txt` file and
    installs the dependencies listed within.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加自定义依赖项，请在Hugging Face Hub上的模型存储库中添加一个带有您想要安装的Python依赖项的`requirements.txt`[文件](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/requirements.txt)。当创建您的端点和镜像工件时，推理端点会检查模型存储库是否包含`requirements.txt`文件，并安装列出的依赖项。
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Check out the `requirements.txt` files in the following model repositories
    for examples:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下模型存储库中的`requirements.txt`文件以获取示例：
- en: '[Optimum and onnxruntime](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/requirements.txt)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Optimum and onnxruntime](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/requirements.txt)'
- en: '[diffusers](https://huggingface.co/philschmid/stable-diffusion-v1-4-endpoints/blob/main/requirements.txt)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[diffusers](https://huggingface.co/philschmid/stable-diffusion-v1-4-endpoints/blob/main/requirements.txt)'
- en: For more information, take a look at how you can create and install dependencies
    when you [use your own custom container](/docs/inference-endpoints/guides/custom_container)
    for inference.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请查看如何在推理时[使用自定义容器](/docs/inference-endpoints/guides/custom_container)创建和安装依赖项。
