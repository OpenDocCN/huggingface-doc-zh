- en: Build and load
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和加载
- en: 'Original text: [https://huggingface.co/docs/datasets/about_dataset_load](https://huggingface.co/docs/datasets/about_dataset_load)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/datasets/about_dataset_load](https://huggingface.co/docs/datasets/about_dataset_load)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Nearly every deep learning workflow begins with loading a dataset, which makes
    it one of the most important steps. With 🤗 Datasets, there are more than 900 datasets
    available to help you get started with your NLP task. All you have to do is call:
    [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    to take your first step. This function is a true workhorse in every sense because
    it builds and loads every dataset you use.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个深度学习工作流都始于加载数据集，这使得它成为最重要的步骤之一。使用🤗 数据集，有超过 900 个数据集可供您开始进行 NLP 任务。您只需调用：[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    来迈出第一步。这个函数在各个方面都是一个真正的工作马，因为它会构建和加载您使用的每个数据集。
- en: 'ELI5: load_dataset'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ELI5：load_dataset
- en: Let’s begin with a basic Explain Like I’m Five.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个基本的五岁解释开始。
- en: 'A dataset is a directory that contains:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集是一个包含以下内容的目录：
- en: Some data files in generic formats (JSON, CSV, Parquet, text, etc.)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些以通用格式（JSON、CSV、Parquet、文本等）存储的数据文件
- en: A dataset card named `README.md` that contains documentation about the dataset
    as well as a YAML header to define the datasets tags and configurations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为`README.md`的数据集卡片，包含有关数据集的文档以及一个 YAML 头部来定义数据集的标签和配置
- en: An optional dataset script if it requires some code to read the data files.
    This is sometimes used to load files of specific formats and structures.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要一些代码来读取数据文件，则包含一个可选的数据集脚本。有时用于加载特定格式和结构的文件。
- en: The [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function fetches the requested dataset locally or from the Hugging Face Hub. The
    Hub is a central repository where all the Hugging Face datasets and models are
    stored.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)函数会在本地或从
    Hugging Face Hub 获取请求的数据集。Hub 是一个中央存储库，存储了所有 Hugging Face 数据集和模型。'
- en: 'If the dataset only contains data files, then [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    automatically infers how to load the data files from their extensions (json, csv,
    parquet, txt, etc.). Under the hood, 🤗 Datasets will use an appropriate [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    based on the data files format. There exist one builder per data file format in
    🤗 Datasets:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集只包含数据文件，则[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)会自动推断如何从其扩展名（json、csv、parquet、txt等）加载数据文件。在幕后，🤗
    数据集将根据数据文件格式使用适当的[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)。🤗
    数据集中存在一个构建器对应于每种数据文件格式：
- en: '[datasets.packaged_modules.text.Text](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.text.Text)
    for text'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.text.Text](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.text.Text)
    用于文本'
- en: '[datasets.packaged_modules.csv.Csv](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.csv.Csv)
    for CSV and TSV'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.csv.Csv](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.csv.Csv)
    用于 CSV 和 TSV'
- en: '[datasets.packaged_modules.json.Json](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.json.Json)
    for JSON and JSONL'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.json.Json](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.json.Json)
    用于 JSON 和 JSONL'
- en: '[datasets.packaged_modules.parquet.Parquet](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.parquet.Parquet)
    for Parquet'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.parquet.Parquet](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.parquet.Parquet)
    用于 Parquet'
- en: '[datasets.packaged_modules.arrow.Arrow](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.arrow.Arrow)
    for Arrow (streaming file format)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.arrow.Arrow](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.arrow.Arrow)
    用于 Arrow（流文件格式）'
- en: '[datasets.packaged_modules.sql.Sql](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.sql.Sql)
    for SQL databases'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.sql.Sql](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.sql.Sql)
    用于 SQL 数据库'
- en: '[datasets.packaged_modules.imagefolder.ImageFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.imagefolder.ImageFolder)
    for image folders'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.imagefolder.ImageFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.imagefolder.ImageFolder)
    用于图像文件夹'
- en: '[datasets.packaged_modules.audiofolder.AudioFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.audiofolder.AudioFolder)
    for audio folders'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.audiofolder.AudioFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.audiofolder.AudioFolder)
    用于音频文件夹'
- en: If the dataset has a dataset script, then it downloads and imports it from the
    Hugging Face Hub. Code in the dataset script defines a custom [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    the dataset information (description, features, URL to the original files, etc.),
    and tells 🤗 Datasets how to generate and display examples from it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集有一个数据集脚本，那么它会从 Hugging Face Hub 下载并导入。数据集脚本中的代码定义了一个自定义[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)来描述数据集信息（描述、特征、原始文件的URL等），并告诉🤗
    数据集如何生成和显示示例。
- en: Read the [Share](./upload_dataset) section to learn more about how to share
    a dataset. This section also provides a step-by-step guide on how to write your
    own dataset loading script!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读[分享](./upload_dataset)部分，了解如何分享数据集。该部分还提供了关于如何编写自己的数据集加载脚本的逐步指南！
- en: 🤗 Datasets downloads the dataset files from the original URL, generates the
    dataset and caches it in an Arrow table on your drive. If you’ve downloaded the
    dataset before, then 🤗 Datasets will reload it from the cache to save you the
    trouble of downloading it again.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 数据集会从原始URL下载数据集文件，生成数据集并将其缓存在您的驱动器上的 Arrow 表中。如果您之前已经下载过数据集，则🤗 数据集将从缓存中重新加载，以免再次下载。
- en: Now that you have a high-level understanding about how datasets are built, let’s
    take a closer look at the nuts and bolts of how all this works.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经对数据集是如何构建有了高层次的理解，让我们更仔细地看看所有这些是如何运作的。
- en: Building a dataset
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建数据集
- en: 'When you load a dataset for the first time, 🤗 Datasets takes the raw data file
    and builds it into a table of rows and typed columns. There are two main classes
    responsible for building a dataset: [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    and [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当您第一次加载数据集时，🤗 数据集会将原始数据文件构建成一张行和类型列的表格。负责构建数据集的两个主要类是：[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    和 [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)。
- en: '![](../Images/bd493a651fa07ec8829a2c0ef2818f43.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd493a651fa07ec8829a2c0ef2818f43.png)'
- en: BuilderConfig
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BuilderConfig
- en: '[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    is the configuration class of [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder).
    The [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    contains the following basic attributes about a dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    是 [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    的配置类。[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    包含有关数据集的以下基本属性：'
- en: '| Attribute | Description |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 属性 | 描述 |'
- en: '| --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `name` | Short name of the dataset. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `name` | 数据集的简称。 |'
- en: '| `version` | Dataset version identifier. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `version` | 数据集版本标识符。 |'
- en: '| `data_dir` | Stores the path to a local folder containing the data files.
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `data_dir` | 存储包含数据文件的本地文件夹的路径。 |'
- en: '| `data_files` | Stores paths to local data files. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `data_files` | 存储本地数据文件的路径。 |'
- en: '| `description` | Description of the dataset. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `description` | 数据集描述。 |'
- en: 'If you want to add additional attributes to your dataset such as the class
    labels, you can subclass the base [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class. There are two ways to populate the attributes of a [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class or subclass:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想向数据集添加额外的属性，例如类标签，可以对基础 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    类进行子类化。有两种方法可以填充 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    类或子类的属性：
- en: Provide a list of predefined [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class (or subclass) instances in the datasets `DatasetBuilder.BUILDER_CONFIGS()`
    attribute.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据集的 `DatasetBuilder.BUILDER_CONFIGS()` 属性中提供预定义的 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    类（或子类）实例的列表。
- en: When you call [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    any keyword arguments that are not specific to the method will be used to set
    the associated attributes of the [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class. This will override the predefined attributes if a specific configuration
    was selected.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您调用 [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    时，任何不特定于该方法的关键字参数将用于设置 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    类的相关属性。如果选择了特定配置，这将覆盖预定义的属性。
- en: You can also set the [DatasetBuilder.BUILDER_CONFIG_CLASS](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    to any custom subclass of [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将 [DatasetBuilder.BUILDER_CONFIG_CLASS](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    设置为 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    的任何自定义子类。
- en: DatasetBuilder
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DatasetBuilder
- en: '[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    accesses all the attributes inside [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    to build the actual dataset.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    访问 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    中的所有属性来构建实际数据集。'
- en: '![](../Images/bb7161ccc3fa095689cfa137b5590ded.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb7161ccc3fa095689cfa137b5590ded.png)'
- en: 'There are three main methods in [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    中有三个主要方法：'
- en: '`DatasetBuilder._info()` is in charge of defining the dataset attributes. When
    you call `dataset.info`, 🤗 Datasets returns the information stored here. Likewise,
    the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    are also specified here. Remember, the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    are like the skeleton of the dataset. It provides the names and types of each
    column.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._info()` 负责定义数据集属性。当您调用 `dataset.info` 时，🤗 数据集会返回存储在此处的信息。同样，[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    也在这里指定。请记住，[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    就像数据集的骨架。它提供了每列的名称和类型。'
- en: '`DatasetBuilder._split_generator` downloads or retrieves the requested data
    files, organizes them into splits, and defines specific arguments for the generation
    process. This method has a [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager)
    that downloads files or fetches them from your local filesystem. Within the [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager),
    there is a [DownloadManager.download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    method that accepts a dictionary of URLs to the original data files, and downloads
    the requested files. Accepted inputs include: a single URL or path, or a list/dictionary
    of URLs or paths. Any compressed file types like TAR, GZIP and ZIP archives will
    be automatically extracted.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._split_generator` 下载或检索请求的数据文件，将其组织成拆分，并为生成过程定义特定参数。该方法具有一个
    [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager)，用于下载文件或从本地文件系统获取文件。在
    [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager)
    中，有一个 [DownloadManager.download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    方法，接受一个包含原始数据文件的 URL 字典，并下载请求的文件。接受的输入包括：单个 URL 或路径，或 URL 或路径的列表/字典。任何压缩文件类型，如
    TAR、GZIP 和 ZIP 存档，都将被自动提取。'
- en: Once the files are downloaded, [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    organizes them into splits. The [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    contains the name of the split, and any keyword arguments that are provided to
    the `DatasetBuilder._generate_examples` method. The keyword arguments can be specific
    to each split, and typically comprise at least the local path to the data files
    for each split.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦文件下载完成，[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    将它们组织成拆分。[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    包含拆分的名称，以及提供给 `DatasetBuilder._generate_examples` 方法的任何关键字参数。关键字参数可以针对每个拆分具体设置，通常至少包括每个拆分的数据文件的本地路径。
- en: '`DatasetBuilder._generate_examples` reads and parses the data files for a split.
    Then it yields dataset examples according to the format specified in the `features`
    from `DatasetBuilder._info()`. The input of `DatasetBuilder._generate_examples`
    is actually the `filepath` provided in the keyword arguments of the last method.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._generate_examples` 读取并解析拆分的数据文件。然后根据 `DatasetBuilder._info()`
    中指定的 `features` 格式生成数据集示例。`DatasetBuilder._generate_examples` 的输入实际上是上一个方法的关键字参数中提供的
    `filepath`。'
- en: The dataset is generated with a Python generator, which doesn’t load all the
    data in memory. As a result, the generator can handle large datasets. However,
    before the generated samples are flushed to the dataset file on disk, they are
    stored in an `ArrowWriter` buffer. This means the generated samples are written
    by batch. If your dataset samples consumes a lot of memory (images or videos),
    then make sure to specify a low value for the `DEFAULT_WRITER_BATCH_SIZE` attribute
    in [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder).
    We recommend not exceeding a size of 200 MB.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集是使用 Python 生成器生成的，不会将所有数据加载到内存中。因此，生成器可以处理大型数据集。然而，在生成的样本刷新到磁盘上的数据集文件之前，它们会存储在
    `ArrowWriter` 缓冲区中。这意味着生成的样本是按批写入的。如果您的数据集样本消耗大量内存（图像或视频），请确保在 [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    中指定 `DEFAULT_WRITER_BATCH_SIZE` 属性的低值。我们建议不要超过 200 MB 的大小。
- en: Maintaining integrity
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保持完整性
- en: 'To ensure a dataset is complete, [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    will perform a series of tests on the downloaded files to make sure everything
    is there. This way, you don’t encounter any surprises when your requested dataset
    doesn’t get generated as expected. [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    verifies:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保数据集完整，[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    将对下载的文件执行一系列测试，以确保一切就绪。这样，当您请求的数据集未按预期生成时，您就不会遇到任何意外。[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    验证：
- en: The number of splits in the generated `DatasetDict`.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的 `DatasetDict` 中的拆分数量。
- en: The number of samples in each split of the generated `DatasetDict`.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的 `DatasetDict` 中每个拆分中的样本数量。
- en: The list of downloaded files.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载文件列表。
- en: The SHA256 checksums of the downloaded files (disabled by defaut).
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载文件的 SHA256 校验和（默认情况下已禁用）。
- en: If the dataset doesn’t pass the verifications, it is likely that the original
    host of the dataset made some changes in the data files.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集未通过验证，很可能是数据集的原始主机对数据文件进行了一些更改。
- en: If it is your own dataset, you’ll need to recompute the information above and
    update the `README.md` file in your dataset repository. Take a look at this [section](dataset_script#optional-generate-dataset-metadata)
    to learn how to generate and update this metadata.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是您自己的数据集，您需要重新计算上述信息，并更新数据集存储库中的 `README.md` 文件。查看这个 [section](dataset_script#optional-generate-dataset-metadata)
    了解如何生成和更新这些元数据。
- en: In this case, an error is raised to alert that the dataset has changed. To ignore
    the error, one needs to specify `verification_mode="no_checks"` in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset).
    Anytime you see a verification error, feel free to open a discussion or pull request
    in the corresponding dataset “Community” tab, so that the integrity checks for
    that dataset are updated.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，会引发错误以警示数据集已更改。要忽略错误，需要在 [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    中指定 `verification_mode="no_checks"`。每当看到验证错误时，请随时在相应数据集的“社区”选项卡中开启讨论或拉取请求，以便更新该数据集的完整性检查。
- en: Security
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全性
- en: The dataset repositories on the Hub are scanned for malware, see more information
    [here](https://huggingface.co/docs/hub/security#malware-scanning).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Hub上的数据集存储库会进行恶意软件扫描，更多信息请参见[这里](https://huggingface.co/docs/hub/security#malware-scanning)。
- en: Moreover the datasets without a namespace (originally contributed on our GitHub
    repository) have all been reviewed by our maintainers. The code of these datasets
    is considered **safe**. It concerns datasets that are not under a namespace, e.g.
    “squad” or “glue”, unlike the other datasets that are named “username/dataset_name”
    or “org/dataset_name”.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，没有命名空间的数据集（最初在我们的GitHub存储库上贡献）已经由我们的维护人员进行了审核。这些数据集的代码被认为是**安全**的。这涉及到没有命名空间的数据集，例如“squad”或“glue”，不同于其他被命名为“username/dataset_name”或“org/dataset_name”的数据集。
