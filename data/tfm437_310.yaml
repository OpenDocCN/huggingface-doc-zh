- en: MusicGen
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MusicGen
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/musicgen](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/musicgen)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/musicgen](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/musicgen)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The MusicGen model was proposed in the paper [Simple and Controllable Music
    Generation](https://arxiv.org/abs/2306.05284) by Jade Copet, Felix Kreuk, Itai
    Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre Défossez.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: MusicGen模型是由Jade Copet、Felix Kreuk、Itai Gat、Tal Remez、David Kant、Gabriel Synnaeve、Yossi
    Adi和Alexandre Défossez在论文[Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)中提出的。
- en: MusicGen is a single stage auto-regressive Transformer model capable of generating
    high-quality music samples conditioned on text descriptions or audio prompts.
    The text descriptions are passed through a frozen text encoder model to obtain
    a sequence of hidden-state representations. MusicGen is then trained to predict
    discrete audio tokens, or *audio codes*, conditioned on these hidden-states. These
    audio tokens are then decoded using an audio compression model, such as EnCodec,
    to recover the audio waveform.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: MusicGen是一个单阶段自回归Transformer模型，能够生成高质量的音乐样本，其条件是文本描述或音频提示。文本描述通过一个冻结的文本编码器模型传递，以获得一系列隐藏状态表示。然后训练MusicGen来预测离散的音频标记，或称为*音频代码*，这些标记是通过音频压缩模型（如EnCodec）解码以恢复音频波形。
- en: Through an efficient token interleaving pattern, MusicGen does not require a
    self-supervised semantic representation of the text/audio prompts, thus eliminating
    the need to cascade multiple models to predict a set of codebooks (e.g. hierarchically
    or upsampling). Instead, it is able to generate all the codebooks in a single
    forward pass.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通过高效的标记交错模式，MusicGen不需要自监督的文本/音频提示语义表示，从而消除了预测一组码书（例如分层或上采样）所需级联多个模型的需要。相反，它能够在单次前向传递中生成所有码书。
- en: 'The abstract from the paper is the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We tackle the task of conditional music generation. We introduce MusicGen,
    a single Language Model (LM) that operates over several streams of compressed
    discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised
    of a single-stage transformer LM together with efficient token interleaving patterns,
    which eliminates the need for cascading several models, e.g., hierarchically or
    upsampling. Following this approach, we demonstrate how MusicGen can generate
    high-quality samples, while being conditioned on textual description or melodic
    features, allowing better controls over the generated output. We conduct extensive
    empirical evaluation, considering both automatic and human studies, showing the
    proposed approach is superior to the evaluated baselines on a standard text-to-music
    benchmark. Through ablation studies, we shed light over the importance of each
    of the components comprising MusicGen.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们解决了条件音乐生成的任务。我们引入了MusicGen，一个单一语言模型（LM），它在几个流的压缩离散音乐表示（即标记）上运行。与以往的工作不同，MusicGen由单阶段Transformer
    LM和高效的标记交错模式组成，消除了级联多个模型的需要，例如分层或上采样。遵循这种方法，我们展示了MusicGen如何能够生成高质量的样本，同时在文本描述或旋律特征的条件下，允许更好地控制生成的输出。我们进行了广泛的实证评估，考虑了自动和人类研究，显示所提出的方法在标准文本到音乐基准上优于评估的基线。通过消融研究，我们阐明了构成MusicGen的每个组件的重要性。*'
- en: This model was contributed by [sanchit-gandhi](https://huggingface.co/sanchit-gandhi).
    The original code can be found [here](https://github.com/facebookresearch/audiocraft).
    The pre-trained checkpoints can be found on the [Hugging Face Hub](https://huggingface.co/models?sort=downloads&search=facebook%2Fmusicgen-).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[sanchit-gandhi](https://huggingface.co/sanchit-gandhi)贡献。原始代码可以在[这里](https://github.com/facebookresearch/audiocraft)找到。预训练检查点可以在[Hugging
    Face Hub](https://huggingface.co/models?sort=downloads&search=facebook%2Fmusicgen-)上找到。
- en: Usage tips
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: 'After downloading the original checkpoints from [here](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md#importing--exporting-models)
    , you can convert them using the **conversion script** available at `src/transformers/models/musicgen/convert_musicgen_transformers.py`
    with the following command:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在从[这里](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md#importing--exporting-models)下载原始检查点后，您可以使用位于`src/transformers/models/musicgen/convert_musicgen_transformers.py`的**转换脚本**进行转换，命令如下：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Generation
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成
- en: 'MusicGen is compatible with two generation modes: greedy and sampling. In practice,
    sampling leads to significantly better results than greedy, thus we encourage
    sampling mode to be used where possible. Sampling is enabled by default, and can
    be explicitly specified by setting `do_sample=True` in the call to `MusicgenForConditionalGeneration.generate()`,
    or by overriding the model’s generation config (see below).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MusicGen兼容两种生成模式：贪婪和抽样。实际上，抽样比贪婪产生的结果显著更好，因此我们鼓励尽可能使用抽样模式。抽样默认启用，并且可以通过在调用`MusicgenForConditionalGeneration.generate()`时设置`do_sample=True`来明确指定，或通过覆盖模型的生成配置（见下文）来指定。
- en: Generation is limited by the sinusoidal positional embeddings to 30 second inputs.
    Meaning, MusicGen cannot generate more than 30 seconds of audio (1503 tokens),
    and input audio passed by Audio-Prompted Generation contributes to this limit
    so, given an input of 20 seconds of audio, MusicGen cannot generate more than
    10 seconds of additional audio.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 生成受正弦位置嵌入的限制，输入限制为30秒。也就是说，MusicGen不能生成超过30秒的音频（1503个标记），输入音频通过音频提示生成也会对此限制有所贡献，因此，给定20秒的音频输入，MusicGen不能生成超过额外10秒的音频。
- en: Transformers supports both mono (1-channel) and stereo (2-channel) variants
    of MusicGen. The mono channel versions generate a single set of codebooks. The
    stereo versions generate 2 sets of codebooks, 1 for each channel (left/right),
    and each set of codebooks is decoded independently through the audio compression
    model. The audio streams for each channel are combined to give the final stereo
    output.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers支持MusicGen的单声道（1通道）和立体声（2通道）变体。单声道版本生成一组代码书。立体声版本生成2组代码书，每个通道（左/右）各一个，并且每组代码书通过音频压缩模型独立解码。每个通道的音频流合并以产生最终的立体声输出。
- en: Unconditional Generation
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无条件生成
- en: 'The inputs for unconditional (or ‘null’) generation can be obtained through
    the method `MusicgenForConditionalGeneration.get_unconditional_inputs()`:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 无条件（或'null'）生成的输入可以通过方法`MusicgenForConditionalGeneration.get_unconditional_inputs()`获得：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The audio outputs are a three-dimensional Torch tensor of shape `(batch_size,
    num_channels, sequence_length)`. To listen to the generated audio samples, you
    can either play them in an ipynb notebook:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 音频输出是一个形状为`(batch_size, num_channels, sequence_length)`的三维Torch张量。要听生成的音频样本，可以在ipynb笔记本中播放它们：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Or save them as a `.wav` file using a third-party library, e.g. `scipy`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 或者使用第三方库（例如`scipy`）将它们保存为`.wav`文件：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Text-Conditional Generation
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本条件生成
- en: 'The model can generate an audio sample conditioned on a text prompt through
    use of the [MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)
    to pre-process the inputs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以通过使用[MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)预处理输入来生成受文本提示条件的音频样本：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `guidance_scale` is used in classifier free guidance (CFG), setting the
    weighting between the conditional logits (which are predicted from the text prompts)
    and the unconditional logits (which are predicted from an unconditional or ‘null’
    prompt). Higher guidance scale encourages the model to generate samples that are
    more closely linked to the input prompt, usually at the expense of poorer audio
    quality. CFG is enabled by setting `guidance_scale > 1`. For best results, use
    `guidance_scale=3` (default).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`guidance_scale`用于分类器自由引导（CFG），设置条件对数（从文本提示预测）和无条件对数（从无条件或''null''提示预测）之间的权重。更高的引导比例鼓励模型生成更与输入提示密切相关的样本，通常以音频质量较差为代价。通过设置`guidance_scale
    > 1`启用CFG。为获得最佳结果，请使用`guidance_scale=3`（默认值）。'
- en: Audio-Prompted Generation
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 音频提示生成
- en: 'The same [MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)
    can be used to pre-process an audio prompt that is used for audio continuation.
    In the following example, we load an audio file using the 🤗 Datasets library,
    which can be pip installed through the command below:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的[MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)可用于预处理用于音频延续的音频提示。在以下示例中，我们使用🤗
    Datasets库加载音频文件，可以通过以下命令进行pip安装：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For batched audio-prompted generation, the generated `audio_values` can be
    post-processed to remove padding by using the [MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)
    class:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于批量音频提示生成，可以通过使用[MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)类对生成的`audio_values`进行后处理，以去除填充：
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Generation Configuration
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成配置
- en: 'The default parameters that control the generation process, such as sampling,
    guidance scale and number of generated tokens, can be found in the model’s generation
    config, and updated as desired:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 控制生成过程的默认参数，例如采样、引导比例和生成的标记数量，可以在模型的生成配置中找到，并根据需要进行更新：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that any arguments passed to the generate method will **supersede** those
    in the generation config, so setting `do_sample=False` in the call to generate
    will supersede the setting of `model.generation_config.do_sample` in the generation
    config.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，传递给生成方法的任何参数都将**覆盖**生成配置中的参数，因此在调用生成时设置`do_sample=False`将覆盖生成配置中`model.generation_config.do_sample`的设置。
- en: Model Structure
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型结构
- en: 'The MusicGen model can be de-composed into three distinct stages:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: MusicGen模型可以分解为三个不同的阶段：
- en: 'Text encoder: maps the text inputs to a sequence of hidden-state representations.
    The pre-trained MusicGen models use a frozen text encoder from either T5 or Flan-T5'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本编码器：将文本输入映射到一系列隐藏状态表示。预训练的MusicGen模型使用来自T5或Flan-T5的冻结文本编码器
- en: 'MusicGen decoder: a language model (LM) that auto-regressively generates audio
    tokens (or codes) conditional on the encoder hidden-state representations'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MusicGen解码器：一个语言模型（LM），根据编码器隐藏状态表示自回归生成音频标记（或代码）
- en: 'Audio encoder/decoder: used to encode an audio prompt to use as prompt tokens,
    and recover the audio waveform from the audio tokens predicted by the decoder'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 音频编码器/解码器：用于将音频提示编码为提示标记，并通过解码器预测的音频标记恢复音频波形
- en: 'Thus, the MusicGen model can either be used as a standalone decoder model,
    corresponding to the class [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM),
    or as a composite model that includes the text encoder and audio encoder/decoder,
    corresponding to the class [MusicgenForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForConditionalGeneration).
    If only the decoder needs to be loaded from the pre-trained checkpoint, it can
    be loaded by first specifying the correct config, or be accessed through the `.decoder`
    attribute of the composite model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，MusicGen模型可以作为独立的解码器模型使用，对应于类[MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)，或作为包含文本编码器和音频编码器/解码器的复合模型使用，对应于类[MusicgenForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForConditionalGeneration)。如果只需从预训练检查点加载解码器，则可以首先指定正确的配置，或通过复合模型的`.decoder`属性访问：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Since the text encoder and audio encoder/decoder models are frozen during training,
    the MusicGen decoder [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    can be trained standalone on a dataset of encoder hidden-states and audio codes.
    For inference, the trained decoder can be combined with the frozen text encoder
    and audio encoder/decoders to recover the composite [MusicgenForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForConditionalGeneration)
    model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文本编码器和音频编码器/解码器模型在训练期间被冻结，MusicGen解码器[MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)可以在编码器隐藏状态和音频代码的数据集上独立训练。对于推断，训练好的解码器可以与冻结的文本编码器和音频编码器/解码器结合，以恢复复合[MusicgenForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForConditionalGeneration)模型。
- en: 'Tips:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: MusicGen is trained on the 32kHz checkpoint of Encodec. You should ensure you
    use a compatible version of the Encodec model.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MusicGen是在Encodec的32kHz检查点上训练的。您应确保使用Encodec模型的兼容版本。
- en: Sampling mode tends to deliver better results than greedy - you can toggle sampling
    with the variable `do_sample` in the call to `MusicgenForConditionalGeneration.generate()`
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采样模式往往比贪婪模式提供更好的结果 - 您可以在调用`MusicgenForConditionalGeneration.generate()`时使用变量`do_sample`切换采样。
- en: MusicgenDecoderConfig
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicgenDecoderConfig
- en: '### `class transformers.MusicgenDecoderConfig`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MusicgenDecoderConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/configuration_musicgen.py#L30)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/configuration_musicgen.py#L30)'
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 2048) — Vocabulary size of the
    MusicgenDecoder model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling `MusicgenDecoder`.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为2048）— MusicgenDecoder模型的词汇量。定义了在调用`MusicgenDecoder`时传递的`inputs_ids`可以表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 1024) — Dimensionality of the
    layers and the pooler layer.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`（`int`，*可选*，默认为1024）— 层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 24) — Number of decoder
    layers.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers`（`int`，*可选*，默认为24）— 解码器层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 16) — Number of attention
    heads for each attention layer in the Transformer block.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads`（`int`，*可选*，默认为16）— Transformer块中每个注意力层的注意力头数。'
- en: '`ffn_dim` (`int`, *optional*, defaults to 4096) — Dimensionality of the “intermediate”
    (often named feed-forward) layer in the Transformer block.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ffn_dim`（`int`，*可选*，默认为4096）— Transformer块中“中间”（通常称为前馈）层的维度。'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    — The non-linear activation function (function or string) in the decoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function`（`str`或`function`，*可选*，默认为`"gelu"`）— 解码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, text_encoder, and pooler.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout`（`float`，*可选*，默认为0.1）— 嵌入、文本编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout`（`float`，*可选*，默认为0.0）— 注意力概率的dropout比率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout`（`float`，*可选*，默认为0.0）— 全连接层内部激活的dropout比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 2048) — The maximum
    sequence length that this model might ever be used with. Typically, set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings`（`int`，*可选*，默认为2048）— 该模型可能被使用的最大序列长度。通常情况下，将其设置为一个较大的值以防万一（例如512、1024或2048）。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor`（`float`，*可选*，默认为0.02）— 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop probability
    for the decoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layerdrop`（`float`，*可选*，默认为0.0）— 解码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop论文](见[https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`scale_embedding` (`bool`, *optional*, defaults to `False`) — Scale embeddings
    by diving by sqrt(hidden_size).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale_embedding`（`bool`，*可选*，默认为`False`）— 通过将其除以sqrt(hidden_size)来缩放嵌入。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether the model should
    return the last key/values attentions (not used by all models)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*，默认为`True`）— 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: '`num_codebooks` (`int`, *optional*, defaults to 4) — The number of parallel
    codebooks forwarded to the model.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_codebooks`（`int`，*可选*，默认为4）— 转发到模型的并行码书的数量。'
- en: '`tie_word_embeddings(bool,` *optional*, defaults to `False`) — Whether input
    and output word embeddings should be tied.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tie_word_embeddings(bool,` *可选*，默认为`False`）— 输入和输出词嵌入是否应该绑定。'
- en: '`audio_channels` (`int`, *optional*, defaults to 1 — Number of channels in
    the audio data. Either 1 for mono or 2 for stereo. Stereo models generate a separate
    audio stream for the left/right output channels. Mono models generate a single
    audio stream output.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_channels`（`int`，*可选*，默认为1）— 音频数据中的通道数。单声道为1，立体声为2。立体声模型为左/右输出通道生成单独的音频流。单声道模型生成单个音频流输出。'
- en: This is the configuration class to store the configuration of an `MusicgenDecoder`.
    It is used to instantiate a MusicGen decoder according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the MusicGen [facebook/musicgen-small](https://huggingface.co/facebook/musicgen-small)
    architecture.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储 `MusicgenDecoder` 配置的配置类。根据指定的参数实例化一个 MusicGen 解码器，定义模型架构。使用默认值实例化配置将产生类似于
    MusicGen [facebook/musicgen-small](https://huggingface.co/facebook/musicgen-small)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档获取更多信息。
- en: MusicgenConfig
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicgenConfig
- en: '### `class transformers.MusicgenConfig`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MusicgenConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/configuration_musicgen.py#L139)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/configuration_musicgen.py#L139)'
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`kwargs` (*optional*) — Dictionary of keyword arguments. Notably:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (*optional*) — 关键字参数的字典。特别是：'
- en: '`text_encoder` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — An instance of a configuration object that defines the text encoder
    config.'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 定义文本编码器配置的配置对象实例。'
- en: '`audio_encoder` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — An instance of a configuration object that defines the audio encoder
    config.'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_encoder` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 定义音频编码器配置的配置对象实例。'
- en: '`decoder` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — An instance of a configuration object that defines the decoder config.'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 定义解码器配置的配置对象实例。'
- en: This is the configuration class to store the configuration of a [MusicgenModel](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenModel).
    It is used to instantiate a MusicGen model according to the specified arguments,
    defining the text encoder, audio encoder and MusicGen decoder configs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储 [MusicgenModel](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenModel)
    配置的配置类。根据指定的参数实例化一个 MusicGen 模型，定义文本编码器、音频编码器和 MusicGen 解码器配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档获取更多信息。
- en: 'Example:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `from_sub_models_config`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_sub_models_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/configuration_musicgen.py#L217)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/configuration_musicgen.py#L217)'
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Returns
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)'
- en: An instance of a configuration object
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象实例
- en: Instantiate a [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    (or a derived class) from text encoder, audio encoder and decoder configurations.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本编码器、音频编码器和解码器配置实例化一个 [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)（或派生类）。
- en: MusicgenProcessor
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicgenProcessor
- en: '### `class transformers.MusicgenProcessor`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MusicgenProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/processing_musicgen.py#L26)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/processing_musicgen.py#L26)'
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_extractor` (`EncodecFeatureExtractor`) — An instance of [EncodecFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecFeatureExtractor).
    The feature extractor is a required input.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` (`EncodecFeatureExtractor`) — 一个 [EncodecFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecFeatureExtractor)
    的实例。特征提取器是一个必需的输入。'
- en: '`tokenizer` (`T5Tokenizer`) — An instance of [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer).
    The tokenizer is a required input.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`T5Tokenizer`) — 一个 [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    的实例。这是一个必需的输入。'
- en: Constructs a MusicGen processor which wraps an EnCodec feature extractor and
    a T5 tokenizer into a single processor class.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 MusicGen 处理器，将 EnCodec 特征提取器和 T5 分词器封装成一个单一的处理器类。
- en: '[MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)
    offers all the functionalities of [EncodecFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecFeatureExtractor)
    and `TTokenizer`. See `__call__()` and [decode()](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor.decode)
    for more information.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[MusicgenProcessor](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor)
    提供了 [EncodecFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecFeatureExtractor)
    和 `TTokenizer` 的所有功能。查看 `__call__()` 和 [decode()](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenProcessor.decode)
    获取更多信息。'
- en: '#### `batch_decode`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/processing_musicgen.py#L90)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/processing_musicgen.py#L90)'
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This method is used to decode either batches of audio outputs from the MusicGen
    model, or batches of token ids from the tokenizer. In the case of decoding token
    ids, this method forwards all its arguments to T5Tokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法用于解码来自MusicGen模型的音频输出批次或来自标记器的标记id批次。在解码标记id的情况下，此方法将其所有参数转发到T5Tokenizer的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。请参考此方法的文档字符串以获取更多信息。
- en: '#### `decode`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/processing_musicgen.py#L108)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/processing_musicgen.py#L108)'
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This method forwards all its arguments to T5Tokenizer’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将其所有参数转发到T5Tokenizer的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。请参考此方法的文档字符串以获取更多信息。
- en: MusicgenModel
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicgenModel
- en: '### `class transformers.MusicgenModel`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MusicgenModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L835)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L835)'
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Musicgen decoder model outputting raw hidden-states without any specific
    head on top.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Musicgen解码器模型，输出没有特定头部的原始隐藏状态。
- en: The Musicgen model was proposed in [Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)
    by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve,
    Yossi Adi, Alexandre Défossez. It is an encoder decoder transformer trained on
    the task of conditional music generation
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Musicgen模型是由Jade Copet、Felix Kreuk、Itai Gat、Tal Remez、David Kant、Gabriel Synnaeve、Yossi
    Adi、Alexandre Défossez在[Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)中提出的。它是一个在条件音乐生成任务上训练的编码器解码器变换器。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L855)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L855)'
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size * num_codebooks, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary, corresponding to the sequence
    of audio codes.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size * num_codebooks, sequence_length)`的`torch.LongTensor`）—
    词汇表中输入序列标记的索引，对应于音频代码序列。'
- en: Indices can be obtained by encoding an audio prompt with an audio encoder model
    to predict audio codes, such as with the [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel).
    See [EncodecModel.encode()](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel.encode)
    for details.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过使用音频编码器模型对音频提示进行编码以预测音频代码，可以获得索引，例如使用[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)。有关详细信息，请参阅[EncodecModel.encode()](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel.encode)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: The `input_ids` will automatically be converted from shape `(batch_size * num_codebooks,
    target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)`
    in the forward pass. If you obtain audio codes from an audio encoding model, such
    as [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel),
    ensure that the number of frames is equal to 1, and that you reshape the audio
    codes from `(frames, batch_size, num_codebooks, target_sequence_length)` to `(batch_size
    * num_codebooks, target_sequence_length)` prior to passing them as `input_ids`.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`input_ids`将在前向传递中自动从形状`(batch_size * num_codebooks, target_sequence_length)`转换为`(batch_size,
    num_codebooks, target_sequence_length)`。如果您从音频编码模型（如[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)）获取音频代码，请确保帧数等于1，并且在将其作为`input_ids`传递之前，将音频代码从`(frames,
    batch_size, num_codebooks, target_sequence_length)`重塑为`(batch_size * num_codebooks,
    target_sequence_length)`。'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.Tensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0,
    1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`encoder_hidden_states` (`torch.FloatTensor` of shape `(batch_size, encoder_sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention of the decoder.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（形状为`(batch_size, encoder_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    编码器最后一层的隐藏状态序列的输出。用于解码器的交叉注意力。'
- en: '`encoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, encoder_sequence_length)`,
    *optional*) — Mask to avoid performing cross-attention on padding tokens indices
    of encoder input_ids. Mask values selected in `[0, 1]`:'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_mask`（形状为`(batch_size, encoder_sequence_length)`的`torch.LongTensor`，*可选*）—
    用于避免在编码器输入标记的填充标记索引上执行交叉注意力的掩码。掩码值选在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules. Mask values
    selected in `[0, 1]`:'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使注意力模块的选定头部失效的掩码。掩码值选在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules in
    the decoder to avoid performing cross-attention on hidden heads. Mask values selected
    in `[0, 1]`:'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使解码器中交叉注意力模块的选定头部失效的掩码，以避免在隐藏头部上执行交叉注意力。掩码值选在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）—
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`的元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后一个形状为`(batch_size, 1)`的`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的）而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，可以直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: The [MusicgenModel](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenModel)
    forward method, overrides the `__call__` special method.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[MusicgenModel](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: MusicgenForCausalLM
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicgenForCausalLM
- en: '### `class transformers.MusicgenForCausalLM`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MusicgenForCausalLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L906)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L906)'
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)）—
    包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The MusicGen decoder model with a language modelling head on top.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: MusicGen解码器模型在顶部带有语言建模头。
- en: The Musicgen model was proposed in [Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)
    by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve,
    Yossi Adi, Alexandre Défossez. It is an encoder decoder transformer trained on
    the task of conditional music generation
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Musicgen模型由Jade Copet、Felix Kreuk、Itai Gat、Tal Remez、David Kant、Gabriel Synnaeve、Yossi
    Adi、Alexandre Défossez在[Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)中提出。这是一个在条件音乐生成任务上训练的编码器解码器变换器。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库实现的通用方法，例如下载或保存，调整输入嵌入大小，修剪头等。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L942)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L942)'
- en: '[PRE20]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size * num_codebooks, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary, corresponding to the sequence
    of audio codes.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size * num_codebooks, sequence_length)`的`torch.LongTensor`）—
    词汇表中输入序列标记的索引，对应于音频代码序列。'
- en: Indices can be obtained by encoding an audio prompt with an audio encoder model
    to predict audio codes, such as with the [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel).
    See [EncodecModel.encode()](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel.encode)
    for details.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过使用音频编码器模型对音频提示进行编码来获取索引，以预测音频代码，例如使用[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)。查看[EncodecModel.encode()](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel.encode)获取详细信息。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: The `input_ids` will automatically be converted from shape `(batch_size * num_codebooks,
    target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)`
    in the forward pass. If you obtain audio codes from an audio encoding model, such
    as [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel),
    ensure that the number of frames is equal to 1, and that you reshape the audio
    codes from `(frames, batch_size, num_codebooks, target_sequence_length)` to `(batch_size
    * num_codebooks, target_sequence_length)` prior to passing them as `input_ids`.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`input_ids`将在前向传递中自动从形状`(batch_size * num_codebooks, target_sequence_length)`转换为`(batch_size,
    num_codebooks, target_sequence_length)`。如果您从音频编码模型（例如[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)）获取音频代码，请确保帧数等于1，并且在将音频代码从`(frames,
    batch_size, num_codebooks, target_sequence_length)`重塑为`(batch_size * num_codebooks,
    target_sequence_length)`之前，将其作为`input_ids`传递。'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.Tensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0,
    1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被掩盖`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`被掩盖`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`encoder_hidden_states` (`torch.FloatTensor` of shape `(batch_size, encoder_sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention of the decoder.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（形状为`(batch_size, encoder_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    编码器最后一层的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`encoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, encoder_sequence_length)`,
    *optional*) — Mask to avoid performing cross-attention on padding tokens indices
    of encoder input_ids. Mask values selected in `[0, 1]`:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_mask`（形状为`(batch_size, encoder_sequence_length)`的`torch.LongTensor`，*可选*）—
    用于避免在编码器输入ID的填充标记索引上执行交叉注意力的掩码。掩码值选在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被掩盖`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`被掩盖`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules. Mask values
    selected in `[0, 1]`:'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使注意力模块的选定头部无效的掩码。掩码值选在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被掩盖`，
- en: 0 indicates the head is `masked`.
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`掩盖`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules in
    the decoder to avoid performing cross-attention on hidden heads. Mask values selected
    in `[0, 1]`:'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 用于将解码器中交叉注意力模块的选定头部置零的掩码，以避免在隐藏头部上执行交叉注意力。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`。
- en: 0 indicates the head is `masked`.
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（请参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入形状为`(batch_size, 1)`的最后`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的）而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for language modeling. Note that the labels **are shifted** inside the
    model, i.e. you can set `labels = input_ids` Indices are selected in `[-100, 0,
    ..., config.vocab_size]` All labels set to `-100` are ignored (masked), the loss
    is only computed for labels in `[0, ..., config.vocab_size]`'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 用于语言建模的标签。请注意，模型内部**移动**标签，即您可以设置`labels = input_ids`。索引在`[-100, 0, ..., config.vocab_size]`中选择。所有设置为`-100`的标签都被忽略（被`masked`），损失仅计算标签在`[0,
    ..., config.vocab_size]`中的标签。'
- en: 'Returns: [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`: A [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig))
    and inputs.'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '返回：[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或`tuple(torch.FloatTensor)`：一个[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`，或者当`config.return_dict=False`时）包含根据配置（[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)）和输入的各种元素。 '
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    语言建模损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头部的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有嵌入层，+
    一个用于每个层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层的输出隐藏状态以及初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列输出。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有嵌入层，+
    一个用于每个层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层的输出隐藏状态以及初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    forward method, overrides the `__call__` special method.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: MusicgenForConditionalGeneration
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicgenForConditionalGeneration
- en: '### `class transformers.MusicgenForConditionalGeneration`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MusicgenForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L1404)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L1404)'
- en: '[PRE21]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The composite MusicGen model with a text encoder, audio encoder and Musicgen
    decoder, for music generation tasks with one or both of text and audio prompts.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 具有文本编码器、音频编码器和Musicgen解码器的复合MusicGen模型，用于具有文本和/或音频提示的音乐生成任务。
- en: The Musicgen model was proposed in [Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)
    by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve,
    Yossi Adi, Alexandre Défossez. It is an encoder decoder transformer trained on
    the task of conditional music generation
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Musicgen模型由Jade Copet、Felix Kreuk、Itai Gat、Tal Remez、David Kant、Gabriel Synnaeve、Yossi
    Adi、Alexandre Défossez在[Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)中提出。它是一个在条件音乐生成任务上训练的编码器解码器transformer。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。请查看超类文档，了解库为其所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L1760)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/musicgen/modeling_musicgen.py#L1760)'
- en: '[PRE22]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。默认情况下将忽略填充。如果提供填充，则默认将忽略。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.Tensor`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。选择的掩码值为`[0,
    1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的标记。
- en: 0 for tokens that are `masked`.
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size * num_codebooks,
    target_sequence_length)`, *optional*) — Indices of decoder input sequence tokens
    in the vocabulary, corresponding to the sequence of audio codes.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size * num_codebooks, target_sequence_length)`的`torch.LongTensor`，*可选*）—
    词汇表中解码器输入序列标记的索引，对应于音频代码序列。'
- en: Indices can be obtained by encoding an audio prompt with an audio encoder model
    to predict audio codes, such as with the [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel).
    See [EncodecModel.encode()](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel.encode)
    for details.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过使用音频编码器模型对音频提示进行编码以预测音频代码来获取索引，例如使用[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)。有关详细信息，请参阅[EncodecModel.encode()](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel.encode)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是解码器输入ID？](../glossary#decoder-input-ids)'
- en: The `decoder_input_ids` will automatically be converted from shape `(batch_size
    * num_codebooks, target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)`
    in the forward pass. If you obtain audio codes from an audio encoding model, such
    as [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel),
    ensure that the number of frames is equal to 1, and that you reshape the audio
    codes from `(frames, batch_size, num_codebooks, target_sequence_length)` to `(batch_size
    * num_codebooks, target_sequence_length)` prior to passing them as `decoder_input_ids`.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`将在前向传递中自动从形状`(batch_size * num_codebooks, target_sequence_length)`转换为`(batch_size,
    num_codebooks, target_sequence_length)`。如果您从音频编码模型（如[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)）获取音频代码，请确保帧数等于1，并且在将音频代码从`(frames,
    batch_size, num_codebooks, target_sequence_length)`重塑为`(batch_size * num_codebooks,
    target_sequence_length)`之前，将其作为`decoder_input_ids`传递。'
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）—
    默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果掩码也将默认使用。'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使编码器中注意力模块的选定头部失效的掩码。选择的掩码值为`[0, 1]`。'
- en: 1 indicates the head is `not masked`,
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`。
- en: 0 indicates the head is `masked`.
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使解码器中注意力模块的选定头部失效的掩码。选择的掩码值为`[0, 1]`。'
- en: 1 indicates the head is `not masked`,
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`。
- en: 0 indicates the head is `masked`.
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules in
    the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 在解码器中将交叉注意力模块的选定头部置零的掩码。掩码值选定在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被掩盖，
- en: 0 indicates the head is `masked`.
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被掩盖。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括(`last_hidden_state`,
    *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*optional*)是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含可以用于加速顺序解码的预计算隐藏状态（自注意力块和交叉注意力块中的键和值）（请参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入形状为`(batch_size, 1)`的最后一个`decoder_input_ids`（那些没有将其过去的键值状态提供给此模型的）而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示而不是传递`decoder_input_ids`。如果使用`past_key_values`，则可以选择仅输入最后一个`decoder_inputs_embeds`（参见`past_key_values`）。这很有用，如果您想要更多控制如何将`decoder_input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵。'
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`decoder_input_ids`和`decoder_inputs_embeds`都未设置，则`decoder_inputs_embeds`取`inputs_embeds`的值。
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为`True`，将返回`past_key_values`键值状态，可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig))
    and inputs.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包括根据配置（[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    语言建模损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）-
    语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个和每层输出的一个）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每层解码器的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）-
    模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个和每层输出的一个）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每层编码器的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [MusicgenForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[MusicgenForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForConditionalGeneration)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE23]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
