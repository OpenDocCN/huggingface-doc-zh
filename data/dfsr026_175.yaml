- en: GLIGEN (Grounded Language-to-Image Generation)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GLIGEN（基于语言的图像生成）
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/gligen](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/gligen)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/gligen](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/gligen)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The GLIGEN model was created by researchers and engineers from [University of
    Wisconsin-Madison, Columbia University, and Microsoft](https://github.com/gligen/GLIGEN).
    The [StableDiffusionGLIGENPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENPipeline)
    and [StableDiffusionGLIGENTextImagePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline)
    can generate photorealistic images conditioned on grounding inputs. Along with
    text and bounding boxes with [StableDiffusionGLIGENPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENPipeline),
    if input images are given, [StableDiffusionGLIGENTextImagePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline)
    can insert objects described by text at the region defined by bounding boxes.
    Otherwise, it’ll generate an image described by the caption/prompt and insert
    objects described by text at the region defined by bounding boxes. It’s trained
    on COCO2014D and COCO2014CD datasets, and the model uses a frozen CLIP ViT-L/14
    text encoder to condition itself on grounding inputs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: GLIGEN模型是由[威斯康星大学麦迪逊分校、哥伦比亚大学和微软](https://github.com/gligen/GLIGEN)的研究人员和工程师创建的。[StableDiffusionGLIGENPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENPipeline)和[StableDiffusionGLIGENTextImagePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline)可以生成基于基础输入的逼真图像。除了文本和边界框外，如果输入图像，[StableDiffusionGLIGENTextImagePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline)可以在由边界框定义的区域插入文本描述的对象。否则，它将生成由标题/提示描述的图像，并在由边界框定义的区域插入文本描述的对象。它在COCO2014D和COCO2014CD数据集上进行了训练，该模型使用冻结的CLIP
    ViT-L/14文本编码器来根据基础输入对自身进行条件化。
- en: 'The abstract from the [paper](https://huggingface.co/papers/2301.07093) is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[论文](https://huggingface.co/papers/2301.07093)的摘要是：
- en: '*Large-scale text-to-image diffusion models have made amazing advances. However,
    the status quo is to use text input alone, which can impede controllability. In
    this work, we propose GLIGEN, Grounded-Language-to-Image Generation, a novel approach
    that builds upon and extends the functionality of existing pre-trained text-to-image
    diffusion models by enabling them to also be conditioned on grounding inputs.
    To preserve the vast concept knowledge of the pre-trained model, we freeze all
    of its weights and inject the grounding information into new trainable layers
    via a gated mechanism. Our model achieves open-world grounded text2img generation
    with caption and bounding box condition inputs, and the grounding ability generalizes
    well to novel spatial configurations and concepts. GLIGEN’s zeroshot performance
    on COCO and LVIS outperforms existing supervised layout-to-image baselines by
    a large margin.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*大规模文本到图像扩散模型取得了惊人的进展。然而，现状是仅使用文本输入，这可能会影响可控性。在这项工作中，我们提出GLIGEN，即基于语言的图像生成，这是一种新颖的方法，它在现有预训练的文本到图像扩散模型的基础上构建并扩展功能，使它们也能够根据基础输入进行条件化。为了保留预训练模型的广泛概念知识，我们冻结了所有权重，并通过门控机制将基础信息注入到新的可训练层中。我们的模型实现了具有标题和边界框条件输入的开放世界基于基础的文本到图像生成，而且基础能力很好地推广到新颖的空间配置和概念。GLIGEN在COCO和LVIS上的零样本性能远远超过现有的监督布局到图像基线。*'
- en: Make sure to check out the Stable Diffusion [Tips](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/overview#tips)
    section to learn how to explore the tradeoff between scheduler speed and quality
    and how to reuse pipeline components efficiently!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 请务必查看稳定扩散[Tips](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/overview#tips)部分，了解如何探索调度程序速度和质量之间的权衡，以及如何高效地重用管道组件！
- en: If you want to use one of the official checkpoints for a task, explore the [gligen](https://huggingface.co/gligen)
    Hub organizations!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要使用任务的官方检查点之一，请探索[gligen](https://huggingface.co/gligen) Hub组织！
- en: '[StableDiffusionGLIGENPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENPipeline)
    was contributed by [Nikhil Gajendrakumar](https://github.com/nikhil-masterful)
    and [StableDiffusionGLIGENTextImagePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline)
    was contributed by [Nguyễn Công Tú Anh](https://github.com/tuanh123789).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionGLIGENPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENPipeline)由[Nikhil
    Gajendrakumar](https://github.com/nikhil-masterful)贡献，而[StableDiffusionGLIGENTextImagePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline)由[Nguyễn
    Công Tú Anh](https://github.com/tuanh123789)贡献。'
- en: StableDiffusionGLIGENPipeline
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散GLIGEN管道
- en: '### `class diffusers.StableDiffusionGLIGENPipeline`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionGLIGENPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L102)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L102)'
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL））-
    变分自动编码器（VAE）模型，用于将图像编码和解码为潜在表示。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — 冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 用于对文本进行标记化的 `CLIPTokenizer`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪编码图像潜在特征的 `UNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 用于与 `unet` 结合使用以去噪编码图像潜在特征的调度器。可以是 [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)
    或 [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    中的一个。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) — 用于估计生成图像是否可能被视为具有攻击性或有害的分类模块。请参考[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 用于从生成的图像中提取特征的 `CLIPImageProcessor`；作为输入传递给 `safety_checker`。'
- en: Pipeline for text-to-image generation using Stable Diffusion with Grounded-Language-to-Image
    Generation (GLIGEN).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 和 Grounded-Language-to-Image Generation (GLIGEN) 进行文本到图像生成的管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。检查超类文档以了解库为所有管道实现的通用方法（例如下载或保存，运行在特定设备上等）。
- en: '#### `__call__`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L551)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L551)'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 用于引导图像生成的提示或提示。如果未定义，则需要传递 `prompt_embeds`。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 7.5) — 更高的引导比例值鼓励模型生成与文本 `prompt` 密切相关的图像，但会降低图像质量。当
    `guidance_scale > 1` 时启用引导比例。'
- en: '`gligen_phrases` (`List[str]`) — The phrases to guide what to include in each
    of the regions defined by the corresponding `gligen_boxes`. There should only
    be one phrase per bounding box.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_phrases` (`List[str]`) — 用于指导每个由相应的 `gligen_boxes` 定义的区域中包含什么内容的短语。每个边界框只能有一个短语。'
- en: '`gligen_boxes` (`List[List[float]]`) — The bounding boxes that identify rectangular
    regions of the image that are going to be filled with the content described by
    the corresponding `gligen_phrases`. Each rectangular box is defined as a `List[float]`
    of 4 elements `[xmin, ymin, xmax, ymax]` where each value is between [0,1].'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_boxes` (`List[List[float]]`) — 用于标识将填充由相应的 `gligen_phrases` 描述的内容的图像的矩形区域的边界框。每个矩形框被定义为包含
    4 个元素 `[xmin, ymin, xmax, ymax]` 的 `List[float]`，其中每个值都在 [0,1] 之间。'
- en: '`gligen_inpaint_image` (`PIL.Image.Image`, *optional*) — The input image, if
    provided, is inpainted with objects described by the `gligen_boxes` and `gligen_phrases`.
    Otherwise, it is treated as a generation task on a blank input image.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_inpaint_image` (`PIL.Image.Image`, *可选*) — 如果提供了输入图像，则将其用由 `gligen_boxes`
    和 `gligen_phrases` 描述的对象修复。否则，它将被视为在空白输入图像上的生成任务。'
- en: '`gligen_scheduled_sampling_beta` (`float`, defaults to 0.3) — Scheduled Sampling
    factor from [GLIGEN: Open-Set Grounded Text-to-Image Generation](https://arxiv.org/pdf/2301.07093.pdf).
    Scheduled Sampling factor is only varied for scheduled sampling during inference
    for improved quality and controllability.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_scheduled_sampling_beta` (`float`，默认为0.3) — 来自[GLIGEN: Open-Set Grounded
    Text-to-Image Generation](https://arxiv.org/pdf/2301.07093.pdf)的Scheduled Sampling因子。Scheduled
    Sampling因子仅在推断过程中为了提高质量和可控性而变化。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`或`List[str]`，*可选*) — 用于指导图像生成中不包含的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用指导时被忽略（`guidance_scale
    < 1`）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`，*可选*，默认为1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`，*可选*，默认为0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数eta
    (η)。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度器中被忽略。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`List[torch.Generator]`，*可选*) — 一个[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`，*可选*) — 从高斯分布中采样的预生成噪声潜变量，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则通过使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`，*可选*) — 预生成的文本嵌入。可用于轻松微调文本输入（提示加权）。如果未提供，则从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`，*可选*) — 预生成的负文本嵌入。可用于轻松微调文本输入（提示加权）。如果未提供，则从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`，*可选*，默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*，默认为`True`) — 是否返回一个[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是一个普通元组。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`，*可选*) — 在推断过程中每隔`callback_steps`步调用的函数。该函数使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`，*可选*，默认为1) — 调用`callback`函数的频率。如果未指定，将在每一步调用回调。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`，*可选*) — 如果指定，将传递给`AttentionProcessor`的kwargs字典，如[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中定义的那样。'
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) — Guidance rescale
    factor from [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_rescale` (`float`，*可选*，默认为0.0) — 来自[Common Diffusion Noise Schedules
    and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)的指导缩放因子。指导缩放因子应在使用零终端信噪比时修复过曝光问题。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`，*可选*) — 在计算提示嵌入时要跳过的CLIP层数。值为1意味着将使用预终层的输出来计算提示嵌入。'
- en: Returns
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个`tuple`，其中第一个元素是生成的图像列表，第二个元素是一个`bool`列表，指示相应生成的图像是否包含“不适宜工作”（nsfw）内容。
- en: The call function to the pipeline for generation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_vae_slicing`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L175)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L175)'
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。启用此选项时，VAE将在几个步骤中将输入张量分割为切片以进行解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `disable_vae_slicing`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L182)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L182)'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果先前启用了`enable_vae_slicing`，则此方法将返回到一步计算解码。
- en: '#### `enable_vae_tiling`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L189)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L189)'
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。启用此选项时，VAE将将输入张量分割为瓦片以在几个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `disable_vae_tiling`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L197)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L197)'
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果先前启用了`enable_vae_tiling`，则此方法将返回到一步计算解码。
- en: '#### `enable_model_cpu_offload`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_model_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`gpu_id` (`int`, *optional*) — The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id` (`int`, *可选*) — 用于推断的加速器的ID。如果未指定，将默认为0。'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to “cuda”) — The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to “cuda”.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`torch.Device` 或 `str`, *可选*, 默认为“cuda”) — 用于推断的加速器的PyTorch设备类型。如果未指定，将默认为“cuda”。'
- en: Offloads all models to CPU using accelerate, reducing memory usage with a low
    impact on performance. Compared to `enable_sequential_cpu_offload`, this method
    moves one whole model at a time to the GPU when its `forward` method is called,
    and the model remains in GPU until the next model runs. Memory savings are lower
    than with `enable_sequential_cpu_offload`, but performance is much better due
    to the iterative execution of the `unet`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有模型转移到CPU，减少内存使用量，对性能影响较小。与`enable_sequential_cpu_offload`相比，此方法在调用其`forward`方法时一次将一个完整模型移动到GPU，并且模型保持在GPU中直到下一个模型运行。与`enable_sequential_cpu_offload`相比，内存节省较低，但由于`unet`的迭代执行，性能要好得多。
- en: '#### `prepare_latents`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prepare_latents`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L507)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L507)'
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `enable_fuser`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_fuser`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L524)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L524)'
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#### `encode_prompt`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L238)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py#L238)'
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 要编码的提示 device — (`torch.device`): torch设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用分类器自由指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用指导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成negative_prompt_embeds。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *可选*) — 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的LoRA比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *可选*) — 在计算提示嵌入时要从CLIP中跳过的层数。值为1意味着将使用预终层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
- en: StableDiffusionGLIGENTextImagePipeline
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionGLIGENTextImagePipeline
- en: '### `class diffusers.StableDiffusionGLIGENTextImagePipeline`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionGLIGENTextImagePipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L148)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L148)'
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — 变分自动编码器（VAE）模型，用于对图像进行编码和解码，并从潜在表示中解码图像。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — 冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 用于对文本进行标记化的`CLIPTokenizer`。'
- en: '`processor` ([CLIPProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor))
    — A `CLIPProcessor` to procces reference image.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processor` ([CLIPProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor))
    — 用于处理参考图像的`CLIPProcessor`。'
- en: '`image_encoder` ([CLIPVisionModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModelWithProjection))
    — Frozen image-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_encoder` ([CLIPVisionModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModelWithProjection))
    — 冻结的图像编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`image_project` (`CLIPImageProjection`) — A `CLIPImageProjection` to project
    image embedding into phrases embedding space.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_project` (`CLIPImageProjection`) — 用于将图像嵌入投影到短语嵌入空间的`CLIPImageProjection`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪编码图像潜在的`UNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 用于与`unet`结合使用以去噪编码图像潜在的调度器。可以是[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)或[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)之一。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) — 估计生成的图像是否可能被认为是冒犯性或有害的分类模块。请参考[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 用于从生成的图像中提取特征的`CLIPImageProcessor`；作为`safety_checker`的输入。'
- en: Pipeline for text-to-image generation using Stable Diffusion with Grounded-Language-to-Image
    Generation (GLIGEN).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用稳定扩散和基于语言到图像生成（GLIGEN）的文本到图像生成管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。检查超类文档以获取库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L712)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L712)'
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *optional*) — 指导图像生成的提示或提示。如果未定义，则需要传递 `prompt_embeds`。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为 50) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认为 7.5) — 更高的指导比例值鼓励模型生成与文本 `prompt`
    密切相关的图像，但会降低图像质量。当 `guidance_scale > 1` 时启用指导比例。'
- en: '`gligen_phrases` (`List[str]`) — The phrases to guide what to include in each
    of the regions defined by the corresponding `gligen_boxes`. There should only
    be one phrase per bounding box.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_phrases` (`List[str]`) — 指导每个由相应的 `gligen_boxes` 定义的区域中包含什么内容的短语。每个边界框只应有一个短语。'
- en: '`gligen_images` (`List[PIL.Image.Image]`) — The images to guide what to include
    in each of the regions defined by the corresponding `gligen_boxes`. There should
    only be one image per bounding box'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_images` (`List[PIL.Image.Image]`) — 指导每个由相应的 `gligen_boxes` 定义的区域中包含什么内容的图像。每个边界框只应有一个图像'
- en: '`input_phrases_mask` (`int` or `List[int]`) — pre phrases mask input defined
    by the correspongding `input_phrases_mask`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_phrases_mask` (`int` 或 `List[int]`) — 由相应的 `input_phrases_mask` 定义的预短语掩码输入'
- en: '`input_images_mask` (`int` or `List[int]`) — pre images mask input defined
    by the correspongding `input_images_mask`'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_images_mask` (`int` 或 `List[int]`) — 由相应的 `input_images_mask` 定义的预图像掩码输入'
- en: '`gligen_boxes` (`List[List[float]]`) — The bounding boxes that identify rectangular
    regions of the image that are going to be filled with the content described by
    the corresponding `gligen_phrases`. Each rectangular box is defined as a `List[float]`
    of 4 elements `[xmin, ymin, xmax, ymax]` where each value is between [0,1].'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_boxes` (`List[List[float]]`) — 标识图像矩形区域的边界框，这些区域将填充由相应的 `gligen_phrases`
    描述的内容。每个矩形框被定义为包含 4 个元素 `[xmin, ymin, xmax, ymax]` 的 `List[float]`，其中每个值在 [0,1]
    之间。'
- en: '`gligen_inpaint_image` (`PIL.Image.Image`, *optional*) — The input image, if
    provided, is inpainted with objects described by the `gligen_boxes` and `gligen_phrases`.
    Otherwise, it is treated as a generation task on a blank input image.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_inpaint_image` (`PIL.Image.Image`, *optional*) — 如果提供了输入图像，则将其用由 `gligen_boxes`
    和 `gligen_phrases` 描述的对象修补。否则，它被视为在空白输入图像上的生成任务。'
- en: '`gligen_scheduled_sampling_beta` (`float`, defaults to 0.3) — Scheduled Sampling
    factor from [GLIGEN: Open-Set Grounded Text-to-Image Generation](https://arxiv.org/pdf/2301.07093.pdf).
    Scheduled Sampling factor is only varied for scheduled sampling during inference
    for improved quality and controllability.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_scheduled_sampling_beta` (`float`, 默认为 0.3) — 来自 [GLIGEN: 开放集文本到图像生成](https://arxiv.org/pdf/2301.07093.pdf)
    的计划抽样因子。计划抽样因子仅用于推理期间的计划抽样，以提高质量和可控性。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *optional*) — 指导图像生成中不包含的提示或提示。如果未定义，则需要传递
    `negative_prompt_embeds`。在不使用指导时（`guidance_scale < 1`）将被忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, 默认为 0.0) — 对应于 [DDIM](https://arxiv.org/abs/2010.02502)
    论文中的参数 eta (η)。仅适用于 [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度程序中将被忽略。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 用于使生成具有确定性的
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中抽样的预生成噪声潜变量，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则通过使用提供的随机
    `generator` 进行抽样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从
    `prompt` 输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是普通的tuple。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推断期间每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为1) — 调用`callback`函数的频率。如果未指定，将在每一步调用回调。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *可选*) — 如果指定了此kwargs字典，则将其传递给`AttentionProcessor`，如[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中定义的那样。'
- en: '`gligen_normalize_constant` (`float`, *optional*, defaults to 28.7) — The normalize
    value of the image embedding.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gligen_normalize_constant` (`float`, *可选*, 默认为28.7) — 图像嵌入的归一化值。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *可选*) — 在计算提示嵌入时，要从CLIP跳过的层数。值为1意味着将使用预终层的输出来计算提示嵌入。'
- en: Returns
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，将返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则将返回一个`tuple`，其中第一个元素是生成的图像列表，第二个元素是一个包含相应生成图像是否包含“不适宜工作”（nsfw）内容的`bool`列表。
- en: The call function to the pipeline for generation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE13]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#### `enable_vae_slicing`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L233)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L233)'
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。启用此选项时，VAE将在几个步骤中分割输入张量以计算解码。这对于节省一些内存并允许更大的批量大小很有用。
- en: '#### `disable_vae_slicing`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L240)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L240)'
- en: '[PRE15]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果之前启用了`enable_vae_slicing`，则此方法将返回到在一个步骤中计算解码。
- en: '#### `enable_vae_tiling`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L247)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L247)'
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺VAE解码。启用此选项时，VAE将将输入张量分割成瓦片以在几个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像很有用。
- en: '#### `disable_vae_tiling`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L255)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L255)'
- en: '[PRE17]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺VAE解码。如果之前启用了`enable_vae_tiling`，则此方法将返回到在一个步骤中计算解码。
- en: '#### `enable_model_cpu_offload`'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_model_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L1410)'
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`gpu_id` (`int`, *optional*) — The ID of the accelerator that shall be used
    in inference. If not specified, it will default to 0.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id`（`int`，*可选*）— 应在推理中使用的加速器的ID。如果未指定，将默认为0。'
- en: '`device` (`torch.Device` or `str`, *optional*, defaults to “cuda”) — The PyTorch
    device type of the accelerator that shall be used in inference. If not specified,
    it will default to “cuda”.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`（`torch.Device`或`str`，*可选*，默认为“cuda”）— 应在推理中使用的加速器的PyTorch设备类型。如果未指定，将默认为“cuda”。'
- en: Offloads all models to CPU using accelerate, reducing memory usage with a low
    impact on performance. Compared to `enable_sequential_cpu_offload`, this method
    moves one whole model at a time to the GPU when its `forward` method is called,
    and the model remains in GPU until the next model runs. Memory savings are lower
    than with `enable_sequential_cpu_offload`, but performance is much better due
    to the iterative execution of the `unet`.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有模型转移到CPU，减少内存使用量，对性能影响较小。与`enable_sequential_cpu_offload`相比，此方法在调用其`forward`方法时将一个完整的模型一次性移动到GPU，并且模型保持在GPU中，直到下一个模型运行。与`enable_sequential_cpu_offload`相比，内存节省较少，但由于`unet`的迭代执行，性能要好得多。
- en: '#### `prepare_latents`'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prepare_latents`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L531)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L531)'
- en: '[PRE19]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#### `enable_fuser`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_fuser`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L548)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L548)'
- en: '[PRE20]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `complete_mask`'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `complete_mask`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L585)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L585)'
- en: '[PRE21]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Based on the input mask corresponding value `0 or 1` for each phrases and image,
    mask the features corresponding to phrases and images.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输入遮罩对应的值`0或1`，为每个短语和图像，遮罩与短语和图像对应的特征。
- en: '#### `crop`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `crop`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L565)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L565)'
- en: '[PRE22]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Crop the input image to the specified dimensions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入图像裁剪到指定的尺寸。
- en: '#### `draw_inpaint_mask_from_boxes`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `draw_inpaint_mask_from_boxes`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L553)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L553)'
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Create an inpainting mask based on given boxes. This function generates an inpainting
    mask using the provided boxes to mark regions that need to be inpainted.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 基于给定的框创建一个修复遮罩。此函数使用提供的框生成一个修复遮罩，以标记需要修复的区域。
- en: '#### `encode_prompt`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L263)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L263)'
- en: '[PRE24]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`，*可选*）— 要编码的提示设备 —（`torch.device`）：torch设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`（`int`）— 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance`（`bool`）— 是否使用无分类器指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`（`str`或`List[str]`，*可选*）— 不指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用指导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，文本嵌入将从`prompt`输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds`（`torch.FloatTensor`，*可选*）— 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成负文本嵌入。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale`（`float`，*可选*）— 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的LoRA比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip`（`int`，*可选*）— 在计算提示嵌入时，要从CLIP中跳过的层数。值为1意味着将使用前一层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
- en: '#### `get_clip_feature`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_clip_feature`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L601)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L601)'
- en: '[PRE25]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Get image and phrases embedding by using CLIP pretrain model. The image embedding
    is transformed into the phrases embedding space through a projection.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用CLIP预训练模型获取图像和短语嵌入。通过投影，将图像嵌入转换为短语嵌入空间。
- en: '#### `get_cross_attention_kwargs_with_grounded`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_cross_attention_kwargs_with_grounded`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L625)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L625)'
- en: '[PRE26]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Prepare the cross-attention kwargs containing information about the grounded
    input (boxes, mask, image embedding, phrases embedding).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 准备包含有关基础输入（框、蒙版、图像嵌入、短语嵌入）信息的交叉注意力kwargs。
- en: '#### `get_cross_attention_kwargs_without_grounded`'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_cross_attention_kwargs_without_grounded`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L689)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L689)'
- en: '[PRE27]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Prepare the cross-attention kwargs without information about the grounded input
    (boxes, mask, image embedding, phrases embedding) (All are zero tensor).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 准备不包含有关基础输入（框、蒙版、图像嵌入、短语嵌入）信息的交叉注意力kwargs（全部为零张量）。
- en: '#### `target_size_center_crop`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `target_size_center_crop`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L576)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py#L576)'
- en: '[PRE28]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Crop and resize the image to the target size while keeping the center.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像裁剪并调整大小到目标尺寸，同时保持中心位置。
- en: StableDiffusionPipelineOutput
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE29]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为 `batch_size` 的去噪PIL图像列表或形状为
    `(batch_size, height, width, num_channels)` 的NumPy数组。'
- en: '`nsfw_content_detected` (`List[bool]`) — List indicating whether the corresponding
    generated image contains “not-safe-for-work” (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) — 列表指示相应生成的图像是否包含“不安全内容”（nsfw），如果无法执行安全检查，则为
    `None`。'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散管道的输出类。
