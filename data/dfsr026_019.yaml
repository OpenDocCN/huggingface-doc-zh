- en: Load safetensors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ è½½safetensors
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors](https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ›´å¤šåŸæ–‡ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors](https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[safetensors](https://github.com/huggingface/safetensors) is a safe and fast
    file format for storing and loading tensors. Typically, PyTorch model weights
    are saved or *pickled* into a `.bin` file with Pythonâ€™s [`pickle`](https://docs.python.org/3/library/pickle.html)
    utility. However, `pickle` is not secure and pickled files may contain malicious
    code that can be executed. safetensors is a secure alternative to `pickle`, making
    it ideal for sharing model weights.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[safetensors](https://github.com/huggingface/safetensors)æ˜¯ä¸€ç§å®‰å…¨ä¸”å¿«é€Ÿçš„æ–‡ä»¶æ ¼å¼ï¼Œç”¨äºå­˜å‚¨å’ŒåŠ è½½å¼ é‡ã€‚é€šå¸¸ï¼ŒPyTorchæ¨¡å‹æƒé‡ä¼šä½¿ç”¨Pythonçš„[`pickle`](https://docs.python.org/3/library/pickle.html)å®ç”¨ç¨‹åºä¿å­˜æˆ–*pickled*ä¸º`.bin`æ–‡ä»¶ã€‚ä½†æ˜¯ï¼Œ`pickle`ä¸å®‰å…¨ï¼Œpickledæ–‡ä»¶å¯èƒ½åŒ…å«å¯ä»¥æ‰§è¡Œçš„æ¶æ„ä»£ç ã€‚safetensorsæ˜¯`pickle`çš„å®‰å…¨æ›¿ä»£å“ï¼Œéå¸¸é€‚åˆå…±äº«æ¨¡å‹æƒé‡ã€‚'
- en: 'This guide will show you how you load `.safetensor` files, and how to convert
    Stable Diffusion model weights stored in other formats to `.safetensor`. Before
    you start, make sure you have safetensors installed:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åŠ è½½`.safetensor`æ–‡ä»¶ï¼Œä»¥åŠå¦‚ä½•å°†å­˜å‚¨åœ¨å…¶ä»–æ ¼å¼ä¸­çš„ç¨³å®šæ‰©æ•£æ¨¡å‹æƒé‡è½¬æ¢ä¸º`.safetensor`ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…safetensorsï¼š
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you look at the [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)
    repository, youâ€™ll see weights inside the `text_encoder`, `unet` and `vae` subfolders
    are stored in the `.safetensors` format. By default, ğŸ¤— Diffusers automatically
    loads these `.safetensors` files from their subfolders if theyâ€™re available in
    the model repository.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æŸ¥çœ‹[`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)å­˜å‚¨åº“ï¼Œæ‚¨ä¼šçœ‹åˆ°`text_encoder`ã€`unet`å’Œ`vae`å­æ–‡ä»¶å¤¹ä¸­å­˜å‚¨çš„æƒé‡ä»¥`.safetensors`æ ¼å¼å­˜å‚¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒğŸ¤—
    Diffusersä¼šè‡ªåŠ¨ä»æ¨¡å‹å­˜å‚¨åº“ä¸­çš„å­æ–‡ä»¶å¤¹åŠ è½½è¿™äº›`.safetensors`æ–‡ä»¶ï¼Œå¦‚æœå¯ç”¨ã€‚
- en: 'For more explicit control, you can optionally set `use_safetensors=True` (if
    `safetensors` is not installed, youâ€™ll get an error message asking you to install
    it):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´æ˜ç¡®åœ°æ§åˆ¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©è®¾ç½®`use_safetensors=True`ï¼ˆå¦‚æœæœªå®‰è£…`safetensors`ï¼Œæ‚¨å°†æ”¶åˆ°ä¸€æ¡é”™è¯¯æ¶ˆæ¯ï¼Œè¦æ±‚æ‚¨å®‰è£…å®ƒï¼‰ï¼š
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'However, model weights are not necessarily stored in separate subfolders like
    in the example above. Sometimes, all the weights are stored in a single `.safetensors`
    file. In this case, if the weights are Stable Diffusion weights, you can load
    the file directly with the [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    method:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œæ¨¡å‹æƒé‡ä¸ä¸€å®šåƒä¸Šé¢çš„ç¤ºä¾‹é‚£æ ·å­˜å‚¨åœ¨å•ç‹¬çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚æœ‰æ—¶ï¼Œæ‰€æœ‰æƒé‡éƒ½å­˜å‚¨åœ¨å•ä¸ª`.safetensors`æ–‡ä»¶ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæƒé‡æ˜¯ç¨³å®šæ‰©æ•£æƒé‡ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)æ–¹æ³•ç›´æ¥åŠ è½½æ–‡ä»¶ï¼š
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Convert to safetensors
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è½¬æ¢ä¸ºsafetensors
- en: Not all weights on the Hub are available in the `.safetensors` format, and you
    may encounter weights stored as `.bin`. In this case, use the [Convert Space](https://huggingface.co/spaces/diffusers/convert)
    to convert the weights to `.safetensors`. The Convert Space downloads the pickled
    weights, converts them, and opens a Pull Request to upload the newly converted
    `.safetensors` file on the Hub. This way, if there is any malicious code contained
    in the pickled files, theyâ€™re uploaded to the Hub - which has a [security scanner](https://huggingface.co/docs/hub/security-pickle#hubs-security-scanner)
    to detect unsafe files and suspicious pickle imports - instead of your computer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Hubä¸Šå¹¶éæ‰€æœ‰æƒé‡éƒ½ä»¥`.safetensors`æ ¼å¼å¯ç”¨ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°å­˜å‚¨ä¸º`.bin`çš„æƒé‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·ä½¿ç”¨[Convert Space](https://huggingface.co/spaces/diffusers/convert)å°†æƒé‡è½¬æ¢ä¸º`.safetensors`ã€‚Convert
    Spaceä¼šä¸‹è½½pickledæƒé‡ï¼Œè½¬æ¢å®ƒä»¬ï¼Œå¹¶æ‰“å¼€ä¸€ä¸ªæ‹‰å–è¯·æ±‚ï¼Œä»¥ä¸Šä¼ æ–°è½¬æ¢çš„`.safetensors`æ–‡ä»¶åˆ°Hubä¸Šã€‚è¿™æ ·ï¼Œå¦‚æœpickledæ–‡ä»¶ä¸­åŒ…å«ä»»ä½•æ¶æ„ä»£ç ï¼Œå®ƒä»¬å°†è¢«ä¸Šä¼ åˆ°Hubä¸Š
    - Hubä¸Šæœ‰ä¸€ä¸ª[å®‰å…¨æ‰«æå™¨](https://huggingface.co/docs/hub/security-pickle#hubs-security-scanner)æ¥æ£€æµ‹ä¸å®‰å…¨çš„æ–‡ä»¶å’Œå¯ç–‘çš„pickleå¯¼å…¥
    - è€Œä¸æ˜¯ä¸Šä¼ åˆ°æ‚¨çš„è®¡ç®—æœºä¸Šã€‚
- en: 'You can use the model with the new `.safetensors` weights by specifying the
    reference to the Pull Request in the `revision` parameter (you can also test it
    in this [Check PR](https://huggingface.co/spaces/diffusers/check_pr) Space on
    the Hub), for example `refs/pr/22`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡åœ¨`revision`å‚æ•°ä¸­æŒ‡å®šå¯¹æ‹‰å–è¯·æ±‚çš„å¼•ç”¨ï¼ˆæ‚¨è¿˜å¯ä»¥åœ¨Hubä¸Šçš„æ­¤[Check PR](https://huggingface.co/spaces/diffusers/check_pr)
    Spaceä¸­æµ‹è¯•å®ƒï¼‰ï¼Œä¾‹å¦‚`refs/pr/22`ï¼Œä½¿ç”¨æ–°çš„`.safetensors`æƒé‡çš„æ¨¡å‹ã€‚
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Why use safetensors?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä½¿ç”¨safetensorsï¼Ÿ
- en: 'There are several reasons for using safetensors:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨safetensorsæœ‰å‡ ä¸ªåŸå› ï¼š
- en: Safety is the number one reason for using safetensors. As open-source and model
    distribution grows, it is important to be able to trust the model weights you
    downloaded donâ€™t contain any malicious code. The current size of the header in
    safetensors prevents parsing extremely large JSON files.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®‰å…¨æ€§æ˜¯ä½¿ç”¨safetensorsçš„é¦–è¦åŸå› ã€‚éšç€å¼€æºå’Œæ¨¡å‹åˆ†å‘çš„å¢é•¿ï¼Œèƒ½å¤Ÿä¿¡ä»»æ‚¨ä¸‹è½½çš„æ¨¡å‹æƒé‡ä¸åŒ…å«ä»»ä½•æ¶æ„ä»£ç å˜å¾—è‡³å…³é‡è¦ã€‚safetensorsä¸­æ ‡å¤´çš„å½“å‰å¤§å°é˜²æ­¢è§£ææå¤§çš„JSONæ–‡ä»¶ã€‚
- en: Loading speed between switching models is another reason to use safetensors,
    which performs zero-copy of the tensors. It is especially fast compared to `pickle`
    if youâ€™re loading the weights to CPU (the default case), and just as fast if not
    faster when directly loading the weights to GPU. Youâ€™ll only notice the performance
    difference if the model is already loaded, and not if youâ€™re downloading the weights
    or loading the model for the first time.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨åˆ‡æ¢æ¨¡å‹ä¹‹é—´çš„åŠ è½½é€Ÿåº¦æ˜¯ä½¿ç”¨safetensorsçš„å¦ä¸€ä¸ªåŸå› ï¼Œå®ƒæ‰§è¡Œå¼ é‡çš„é›¶æ‹·è´ã€‚ä¸`pickle`ç›¸æ¯”ï¼Œå¦‚æœæ‚¨å°†æƒé‡åŠ è½½åˆ°CPUï¼ˆé»˜è®¤æƒ…å†µï¼‰ï¼ŒåŠ è½½é€Ÿåº¦ç‰¹åˆ«å¿«ï¼Œå¦‚æœç›´æ¥å°†æƒé‡åŠ è½½åˆ°GPUï¼Œåˆ™ä¸`pickle`ä¸€æ ·å¿«ç”šè‡³æ›´å¿«ã€‚åªæœ‰åœ¨æ¨¡å‹å·²åŠ è½½æ—¶æ‰ä¼šæ³¨æ„åˆ°æ€§èƒ½å·®å¼‚ï¼Œå¦‚æœæ‚¨æ­£åœ¨ä¸‹è½½æƒé‡æˆ–é¦–æ¬¡åŠ è½½æ¨¡å‹ï¼Œåˆ™ä¸ä¼šæ³¨æ„åˆ°ã€‚
- en: 'The time it takes to load the entire pipeline:'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŠ è½½æ•´ä¸ªç®¡é“æ‰€éœ€çš„æ—¶é—´ï¼š
- en: '[PRE4]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'But the actual time it takes to load 500MB of the model weights is only:'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½†åŠ è½½500MBæ¨¡å‹æƒé‡å®é™…æ‰€éœ€çš„æ—¶é—´ä»…ä¸ºï¼š
- en: '[PRE5]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Lazy loading is also supported in safetensors, which is useful in distributed
    settings to only load some of the tensors. This format allowed the [BLOOM](https://huggingface.co/bigscience/bloom)
    model to be loaded in 45 seconds on 8 GPUs instead of 10 minutes with regular
    PyTorch weights.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨safetensorsä¸­ä¹Ÿæ”¯æŒå»¶è¿ŸåŠ è½½ï¼Œè¿™åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥åªåŠ è½½éƒ¨åˆ†å¼ é‡ã€‚è¿™ç§æ ¼å¼ä½¿å¾—[BLOOM](https://huggingface.co/bigscience/bloom)æ¨¡å‹åœ¨8ä¸ªGPUä¸Šä»…ç”¨45ç§’åŠ è½½å®Œæˆï¼Œè€Œä½¿ç”¨å¸¸è§„çš„PyTorchæƒé‡åˆ™éœ€è¦10åˆ†é’Ÿã€‚
