- en: Transformer2D
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Transformer2D
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/transformer2d](https://huggingface.co/docs/diffusers/api/models/transformer2d)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/models/transformer2d](https://huggingface.co/docs/diffusers/api/models/transformer2d)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: A Transformer model for image-like data from [CompVis](https://huggingface.co/CompVis)
    that is based on the [Vision Transformer](https://huggingface.co/papers/2010.11929)
    introduced by Dosovitskiy et al. The [Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)
    accepts discrete (classes of vector embeddings) or continuous (actual embeddings)
    inputs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一种用于类似图像数据的Transformer模型，来自[CompVis](https://huggingface.co/CompVis)，基于Dosovitskiy等人介绍的[视觉Transformer](https://huggingface.co/papers/2010.11929)。[Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)接受离散（向量嵌入的类别）或连续（实际嵌入）输入。
- en: 'When the input is **continuous**:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入是**连续**时：
- en: Project the input and reshape it to `(batch_size, sequence_length, feature_dimension)`.
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入投影并重塑为`(batch_size, sequence_length, feature_dimension)`。
- en: Apply the Transformer blocks in the standard way.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以标准方式应用Transformer块。
- en: Reshape to image.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像重塑。
- en: 'When the input is **discrete**:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入是**离散**时：
- en: It is assumed one of the input classes is the masked latent pixel. The predicted
    classes of the unnoised image don’t contain a prediction for the masked pixel
    because the unnoised image cannot be masked.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输入类别之一是被屏蔽的潜在像素。无噪声图像的预测类别不包含对被屏蔽像素的预测，因为无噪声图像无法被屏蔽。
- en: Convert input (classes of latent pixels) to embeddings and apply positional
    embeddings.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入（潜在像素的类别）转换为嵌入并应用位置嵌入。
- en: Apply the Transformer blocks in the standard way.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以标准方式应用Transformer块。
- en: Predict classes of unnoised image.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测无噪声图像的类别。
- en: Transformer2DModel
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transformer2DModel
- en: '### `class diffusers.Transformer2DModel`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.Transformer2DModel`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_2d.py#L44)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_2d.py#L44)'
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_attention_heads` (`int`, *optional*, defaults to 16) — The number of heads
    to use for multi-head attention.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads`（`int`，*可选*，默认为16） - 用于多头注意力的头数。'
- en: '`attention_head_dim` (`int`, *optional*, defaults to 88) — The number of channels
    in each head.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_head_dim`（`int`，*可选*，默认为88） - 每个头中的通道数。'
- en: '`in_channels` (`int`, *optional*) — The number of channels in the input and
    output (specify if the input is **continuous**).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_channels`（`int`，*可选*） - 输入和输出中的通道数（如果输入是**连续**，请指定）。'
- en: '`num_layers` (`int`, *optional*, defaults to 1) — The number of layers of Transformer
    blocks to use.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers`（`int`，*可选*，默认为1） - 要使用的Transformer块的层数。'
- en: '`dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    to use.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout`（`float`，*可选*，默认为0.0） - 要使用的丢弃概率。'
- en: '`cross_attention_dim` (`int`, *optional*) — The number of `encoder_hidden_states`
    dimensions to use.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_dim`（`int`，*可选*） - 要使用的`encoder_hidden_states`维度数。'
- en: '`sample_size` (`int`, *optional*) — The width of the latent images (specify
    if the input is **discrete**). This is fixed during training since it is used
    to learn a number of position embeddings.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_size`（`int`，*可选*） - 潜在图像的宽度（如果输入是**离散**，请指定）。在训练期间固定，因为它用于学习一些位置嵌入。'
- en: '`num_vector_embeds` (`int`, *optional*) — The number of classes of the vector
    embeddings of the latent pixels (specify if the input is **discrete**). Includes
    the class for the masked latent pixel.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_vector_embeds`（`int`，*可选*） - 潜在像素的向量嵌入的类别数（如果输入是**离散**，请指定）。包括被屏蔽的潜在像素的类别。'
- en: '`activation_fn` (`str`, *optional*, defaults to `"geglu"`) — Activation function
    to use in feed-forward.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_fn`（`str`，*可选*，默认为`"geglu"`） - 在前馈中使用的激活函数。'
- en: '`num_embeds_ada_norm` ( `int`, *optional*) — The number of diffusion steps
    used during training. Pass if at least one of the norm_layers is `AdaLayerNorm`.
    This is fixed during training since it is used to learn a number of embeddings
    that are added to the hidden states.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_embeds_ada_norm`（`int`，*可选*） - 训练期间使用的扩散步骤数。如果至少一个norm_layers是`AdaLayerNorm`，请传递。在训练期间固定，因为它用于学习添加到隐藏状态的嵌入的数量。'
- en: During inference, you can denoise for up to but not more steps than `num_embeds_ada_norm`.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在推断期间，您可以去噪最多但不超过`num_embeds_ada_norm`步。
- en: '`attention_bias` (`bool`, *optional*) — Configure if the `TransformerBlocks`
    attention should contain a bias parameter.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_bias`（`bool`，*可选*） - 配置`TransformerBlocks`注意力是否应包含偏置参数。'
- en: A 2D Transformer model for image-like data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 用于类似图像的数据的2D Transformer模型。
- en: '#### `forward`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_2d.py#L245)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_2d.py#L245)'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`hidden_states` (`torch.LongTensor` of shape `(batch size, num latent pixels)`
    if discrete, `torch.FloatTensor` of shape `(batch size, channel, height, width)`
    if continuous) — Input `hidden_states`.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（如果是离散，则为形状为`(batch size, num latent pixels)`的`torch.LongTensor`，如果是连续，则为形状为`(batch
    size, channel, height, width)`的`torch.FloatTensor`） - 输入`hidden_states`。'
- en: '`encoder_hidden_states` ( `torch.FloatTensor` of shape `(batch size, sequence
    len, embed dims)`, *optional*) — Conditional embeddings for cross attention layer.
    If not given, cross-attention defaults to self-attention.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`torch.FloatTensor`，形状为`(batch size, sequence len,
    embed dims)`，*可选*） - 用于交叉注意力层的条件嵌入。如果未给出，则交叉注意力默认为自注意力。'
- en: '`timestep` ( `torch.LongTensor`, *optional*) — Used to indicate denoising step.
    Optional timestep to be applied as an embedding in `AdaLayerNorm`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep`（`torch.LongTensor`，*可选*） - 用于指示去噪步骤。可选的时间步骤将作为`AdaLayerNorm`中的嵌入应用。'
- en: '`class_labels` ( `torch.LongTensor` of shape `(batch size, num classes)`, *optional*)
    — Used to indicate class labels conditioning. Optional class labels to be applied
    as an embedding in `AdaLayerZeroNorm`.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels`（`torch.LongTensor`，形状为`(batch size, num classes)`，*可选*） - 用于指示类别标签条件。可选的类别标签将作为`AdaLayerZeroNorm`中的嵌入应用。'
- en: '`cross_attention_kwargs` ( `Dict[str, Any]`, *optional*) — A kwargs dictionary
    that if specified is passed along to the `AttentionProcessor` as defined under
    `self.processor` in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs`（`Dict[str, Any]`，*可选*）- 如果指定，将作为kwargs字典传递给`AttentionProcessor`，如[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`中定义的那样。'
- en: '`attention_mask` ( `torch.Tensor`, *optional*) — An attention mask of shape
    `(batch, key_tokens)` is applied to `encoder_hidden_states`. If `1` the mask is
    kept, otherwise if `0` it is discarded. Mask will be converted into a bias, which
    adds large negative values to the attention scores corresponding to “discard”
    tokens.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（`torch.Tensor`，*可选*）- 形状为`(batch, key_tokens)`的注意力掩码应用于`encoder_hidden_states`。如果为`1`，则保留掩码，否则如果为`0`，则丢弃。掩码将被转换为偏置，该偏置会向与“丢弃”标记对应的注意力分数添加大的负值。'
- en: '`encoder_attention_mask` ( `torch.Tensor`, *optional*) — Cross-attention mask
    applied to `encoder_hidden_states`. Two formats supported:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_mask`（`torch.Tensor`，*可选*）- 应用于`encoder_hidden_states`的交叉注意力掩码。支持两种格式：'
- en: Mask `(batch, sequence_length)` True = keep, False = discard.
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 掩码（`batch, sequence_length`）True = 保留，False = 丢弃。
- en: Bias `(batch, 1, sequence_length)` 0 = keep, -10000 = discard.
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏置（`batch, 1, sequence_length`）0 = 保留，-10000 = 丢弃。
- en: 'If `ndim == 2`: will be interpreted as a mask, then converted into a bias consistent
    with the format above. This bias will be added to the cross-attention scores.'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`ndim == 2`：将被解释为一个掩码，然后转换为与上述格式一致的偏置。此偏置将添加到交叉注意力分数中。
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [UNet2DConditionOutput](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.models.unets.unet_2d_condition.UNet2DConditionOutput)
    instead of a plain tuple.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）- 是否返回[UNet2DConditionOutput](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.models.unets.unet_2d_condition.UNet2DConditionOutput)而不是普通元组。'
- en: The [Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)
    forward method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)的前向方法。'
- en: Transformer2DModelOutput
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transformer2DModelOutput
- en: '### `class diffusers.models.transformers.transformer_2d.Transformer2DModelOutput`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.transformers.transformer_2d.Transformer2DModelOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_2d.py#L30)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/transformers/transformer_2d.py#L30)'
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` or `(batch size, num_vector_embeds - 1, num_latent_pixels)` if [Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)
    is discrete) — The hidden states output conditioned on the `encoder_hidden_states`
    input. If discrete, returns probability distributions for the unnoised latent
    pixels.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（形状为`(batch_size, num_channels, height, width)`或`(batch size, num_vector_embeds
    - 1, num_latent_pixels)`的`torch.FloatTensor`）如果[Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)是离散的）-
    在`encoder_hidden_states`输入条件下的隐藏状态输出。如果是离散的，则返回未加噪声的潜在像素的概率分布。'
- en: The output of [Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)的输出。'
