- en: Inpainting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修复
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/inpaint](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/using-diffusers/inpaint](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Inpainting replaces or edits specific areas of an image. This makes it a useful
    tool for image restoration like removing defects and artifacts, or even replacing
    an image area with something entirely new. Inpainting relies on a mask to determine
    which regions of an image to fill in; the area to inpaint is represented by white
    pixels and the area to keep is represented by black pixels. The white pixels are
    filled in by the prompt.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 修复替换或编辑图像的特定区域。这使得它成为像去除缺陷和伪影，甚至用全新内容替换图像区域等图像恢复的有用工具。修复依赖于蒙版来确定要填充图像的哪些区域；要修复的区域由白色像素表示，要保留的区域由黑色像素表示。白色像素由提示填充。
- en: 'With 🤗 Diffusers, here is how you can do inpainting:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 使用🤗 Diffusers，以下是您可以进行修复的方法：
- en: 'Load an inpainting checkpoint with the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    class. This’ll automatically detect the appropriate pipeline class to load based
    on the checkpoint:'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)类加载修复检查点。这将根据检查点自动检测要加载的适当管道类：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You’ll notice throughout the guide, we use [enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)
    and [enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention),
    to save memory and increase inference speed. If you’re using PyTorch 2.0, it’s
    not necessary to call [enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)
    on your pipeline because it’ll already be using PyTorch 2.0’s native [scaled-dot
    product attention](../optimization/torch2.0#scaled-dot-product-attention).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个指南中，您会注意到我们使用[enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)和[enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)，以节省内存并提高推理速度。如果您使用PyTorch
    2.0，则不需要在管道上调用[enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)，因为它已经在使用PyTorch
    2.0的本机[scaled-dot product attention](../optimization/torch2.0#scaled-dot-product-attention)。
- en: 'Load the base and mask images:'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载基础图像和蒙版图像：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a prompt to inpaint the image with and pass it to the pipeline with
    the base and mask images:'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个用于修复图像的提示，并将其传递给具有基础图像和蒙版图像的管道：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: base image
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基础图像
- en: '![](../Images/50397365c167c77e28b112edb22eb879.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50397365c167c77e28b112edb22eb879.png)'
- en: mask image
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙版图像
- en: '![](../Images/53b76ec0efb1b6851d4c8b23347a3f52.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53b76ec0efb1b6851d4c8b23347a3f52.png)'
- en: generated image
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像
- en: Create a mask image
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个蒙版图像
- en: Throughout this guide, the mask image is provided in all of the code examples
    for convenience. You can inpaint on your own images, but you’ll need to create
    a mask image for it. Use the Space below to easily create a mask image.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个指南中，蒙版图像在所有代码示例中都提供了，以方便使用。您可以对自己的图像进行修复，但需要为其创建一个蒙版图像。使用下面的空间轻松创建一个蒙版图像。
- en: Upload a base image to inpaint on and use the sketch tool to draw a mask. Once
    you’re done, click **Run** to generate and download the mask image.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 上传一个基础图像进行修复，并使用草图工具绘制蒙版。完成后，点击**运行**生成并下载蒙版图像。
- en: '[https://stevhliu-inpaint-mask-maker.hf.space](https://stevhliu-inpaint-mask-maker.hf.space)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://stevhliu-inpaint-mask-maker.hf.space](https://stevhliu-inpaint-mask-maker.hf.space)'
- en: Mask blur
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 蒙版模糊
- en: The `~VaeImageProcessor.blur` method provides an option for how to blend the
    original image and inpaint area. The amount of blur is determined by the `blur_factor`
    parameter. Increasing the `blur_factor` increases the amount of blur applied to
    the mask edges, softening the transition between the original image and inpaint
    area. A low or zero `blur_factor` preserves the sharper edges of the mask.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`~VaeImageProcessor.blur`方法提供了如何混合原始图像和修复区域的选项。模糊程度由`blur_factor`参数确定。增加`blur_factor`会增加应用于蒙版边缘的模糊量，软化原始图像和修复区域之间的过渡。低或零的`blur_factor`会保留蒙版的更清晰边缘。'
- en: To use this, create a blurred mask with the image processor.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此功能，请使用图像处理器创建一个模糊的蒙版。
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/bd4255378e4be6f2da63ef7b2951ac46.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd4255378e4be6f2da63ef7b2951ac46.png)'
- en: mask with no blur
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 无模糊的蒙版
- en: '![](../Images/8a2ec7820a1b085328cbab8c7625a7d0.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a2ec7820a1b085328cbab8c7625a7d0.png)'
- en: mask with blur applied
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 应用了模糊的蒙版
- en: Popular models
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 热门模型
- en: '[Stable Diffusion Inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting),
    [Stable Diffusion XL (SDXL) Inpainting](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1),
    and [Kandinsky 2.2 Inpainting](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint)
    are among the most popular models for inpainting. SDXL typically produces higher
    resolution images than Stable Diffusion v1.5, and Kandinsky 2.2 is also capable
    of generating high-quality images.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[稳定扩散修复](https://huggingface.co/runwayml/stable-diffusion-inpainting)、[稳定扩散XL（SDXL）修复](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1)和[Kandinsky
    2.2修复](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint)是修复中最受欢迎的模型之一。SDXL通常比稳定扩散v1.5生成更高分辨率的图像，而Kandinsky
    2.2也能够生成高质量的图像。'
- en: Stable Diffusion Inpainting
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 稳定扩散修复
- en: 'Stable Diffusion Inpainting is a latent diffusion model finetuned on 512x512
    images on inpainting. It is a good starting point because it is relatively fast
    and generates good quality images. To use this model for inpainting, you’ll need
    to pass a prompt, base and mask image to the pipeline:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散修复是一个在修复上进行微调的潜在扩散模型，适用于512x512图像。这是一个很好的起点，因为它相对快速并生成高质量的图像。要将此模型用于修复，您需要将提示、基础图像和蒙版图像传递给管道：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Stable Diffusion XL (SDXL) Inpainting
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 稳定扩散XL（SDXL）修复
- en: SDXL is a larger and more powerful version of Stable Diffusion v1.5\. This model
    can follow a two-stage model process (though each model can also be used alone);
    the base model generates an image, and a refiner model takes that image and further
    enhances its details and quality. Take a look at the [SDXL](sdxl) guide for a
    more comprehensive guide on how to use SDXL and configure it’s parameters.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: SDXL是稳定扩散v1.5的更大更强大的版本。该模型可以遵循两阶段模型过程（尽管每个模型也可以单独使用）；基础模型生成图像，精化模型接收该图像并进一步增强其细节和质量。查看[SDXL](sdxl)指南，了解如何使用SDXL并配置其参数的更全面指南。
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Kandinsky 2.2 Inpainting
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kandinsky 2.2修复
- en: The Kandinsky model family is similar to SDXL because it uses two models as
    well; the image prior model creates image embeddings, and the diffusion model
    generates images from them. You can load the image prior and diffusion model separately,
    but the easiest way to use Kandinsky 2.2 is to load it into the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    class which uses the [KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)
    under the hood.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky模型系列类似于SDXL，因为它也使用两个模型；图像先验模型创建图像嵌入，扩散模型从中生成图像。您可以分别加载图像先验和扩散模型，但使用Kandinsky
    2.2的最简单方法是将其加载到[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)类中，该类在底层使用[KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)。
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: base image
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 基础图像
- en: '![](../Images/09fbce513beddef5b655c0a444a3c86c.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09fbce513beddef5b655c0a444a3c86c.png)'
- en: Stable Diffusion Inpainting
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散修复
- en: '![](../Images/2489c89cec0d33d1acc14b3011bf03c9.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2489c89cec0d33d1acc14b3011bf03c9.png)'
- en: Stable Diffusion XL Inpainting
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散XL修复
- en: '![](../Images/44c50c30f2c0b8b5adb606ae538dbb54.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44c50c30f2c0b8b5adb606ae538dbb54.png)'
- en: Kandinsky 2.2 Inpainting
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.2修复
- en: Non-inpaint specific checkpoints
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非修复特定检查点
- en: So far, this guide has used inpaint specific checkpoints such as [runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting).
    But you can also use regular checkpoints like [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5).
    Let’s compare the results of the two checkpoints.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本指南已使用修复特定检查点，如[runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)。但您也可以使用常规检查点，如[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)。让我们比较这两个检查点的结果。
- en: The image on the left is generated from a regular checkpoint, and the image
    on the right is from an inpaint checkpoint. You’ll immediately notice the image
    on the left is not as clean, and you can still see the outline of the area the
    model is supposed to inpaint. The image on the right is much cleaner and the inpainted
    area appears more natural.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的图像是从常规检查点生成的，右侧的图像是从修复检查点生成的。您会立即注意到左侧的图像不够清晰，仍然可以看到模型应该修复的区域的轮廓。右侧的图像更清晰，修复区域看起来更自然。
- en: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpainting
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpainting
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/5a890789342f9e1a86868211a7896271.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a890789342f9e1a86868211a7896271.png)'
- en: runwayml/stable-diffusion-v1-5
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5
- en: '![](../Images/aecbb44542e32cda8ce2bb2da3d692e3.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aecbb44542e32cda8ce2bb2da3d692e3.png)'
- en: runwayml/stable-diffusion-inpainting
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-inpainting
- en: However, for more basic tasks like erasing an object from an image (like the
    rocks in the road for example), a regular checkpoint yields pretty good results.
    There isn’t as noticeable of difference between the regular and inpaint checkpoint.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于更基本的任务，比如从图像中擦除一个对象（比如道路上的岩石），常规检查点会产生相当不错的结果。常规检查点和修复检查点之间的差异不太明显。
- en: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpaint
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpaint
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/f49798dfa50ce8a7c46fe18a6da38589.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f49798dfa50ce8a7c46fe18a6da38589.png)'
- en: runwayml/stable-diffusion-v1-5
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5
- en: '![](../Images/c59fac74bc905b0800d717d2ce675c20.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c59fac74bc905b0800d717d2ce675c20.png)'
- en: runwayml/stable-diffusion-inpainting
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-inpainting
- en: The trade-off of using a non-inpaint specific checkpoint is the overall image
    quality may be lower, but it generally tends to preserve the mask area (that is
    why you can see the mask outline). The inpaint specific checkpoints are intentionally
    trained to generate higher quality inpainted images, and that includes creating
    a more natural transition between the masked and unmasked areas. As a result,
    these checkpoints are more likely to change your unmasked area.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用非修复特定检查点的折衷是整体图像质量可能较低，但通常倾向于保留蒙版区域（这就是为什么您可以看到蒙版轮廓）。修复特定检查点经过有意训练，以生成更高质量的修复图像，这包括在蒙版和非蒙版区域之间创建更自然的过渡。因此，这些检查点更有可能改变您的非蒙版区域。
- en: If preserving the unmasked area is important for your task, you can use the
    `VaeImageProcessor.apply_overlay` method to force the unmasked area of an image
    to remain the same at the expense of some more unnatural transitions between the
    masked and unmasked areas.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果保留非蒙版区域对您的任务很重要，您可以使用`VaeImageProcessor.apply_overlay`方法，强制图像的非蒙版区域保持不变，但会以一些更不自然的过渡为代价。
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Configure pipeline parameters
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置管道参数
- en: Image features - like quality and “creativity” - are dependent on pipeline parameters.
    Knowing what these parameters do is important for getting the results you want.
    Let’s take a look at the most important parameters and see how changing them affects
    the output.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图像特征 - 如质量和“创造力” - 取决于管道参数。了解这些参数的作用对于获得想要的结果很重要。让我们看看最重要的参数，并了解更改它们如何影响输出。
- en: Strength
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强度
- en: '`strength` is a measure of how much noise is added to the base image, which
    influences how similar the output is to the base image.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`强度`是衡量向基础图像添加多少噪音的指标，这影响输出与基础图像的相似程度。'
- en: 📈 a high `strength` value means more noise is added to an image and the denoising
    process takes longer, but you’ll get higher quality images that are more different
    from the base image
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📈 高`强度`值意味着向图像添加更多噪音，去噪过程需要更长时间，但您将获得质量更高且与基础图像不同的图像
- en: 📉 a low `strength` value means less noise is added to an image and the denoising
    process is faster, but the image quality may not be as great and the generated
    image resembles the base image more
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📉 低`强度`值意味着向图像添加的噪音较少，去噪过程更快，但图像质量可能不会很好，生成的图像更类似于基础图像
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/39f952b5e61ce473b5fc8dab92c18466.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39f952b5e61ce473b5fc8dab92c18466.png)'
- en: strength = 0.6
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 强度 = 0.6
- en: '![](../Images/ba1cef420a7d6632e8dad96029906868.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba1cef420a7d6632e8dad96029906868.png)'
- en: strength = 0.8
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 强度 = 0.8
- en: '![](../Images/b42b3e014dc563c0005c55a35f02fba9.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b42b3e014dc563c0005c55a35f02fba9.png)'
- en: strength = 1.0
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 强度 = 1.0
- en: Guidance scale
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引导比例
- en: '`guidance_scale` affects how aligned the text prompt and generated image are.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`guidance_scale`影响文本提示和生成图像的对齐程度。'
- en: 📈 a high `guidance_scale` value means the prompt and generated image are closely
    aligned, so the output is a stricter interpretation of the prompt
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📈 高`guidance_scale`值意味着提示和生成的图像紧密对齐，因此输出是对提示的更严格解释
- en: 📉 a low `guidance_scale` value means the prompt and generated image are more
    loosely aligned, so the output may be more varied from the prompt
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📉 低`guidance_scale`值意味着提示和生成的图像更松散对齐，因此输出可能与提示更为不同
- en: You can use `strength` and `guidance_scale` together for more control over how
    expressive the model is. For example, a combination high `strength` and `guidance_scale`
    values gives the model the most creative freedom.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以同时使用`强度`和`guidance_scale`来更好地控制模型的表现。例如，高`强度`和`guidance_scale`值的组合给予模型最大的创造自由度。
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/363406b3094071baef896b0e11a247cb.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/363406b3094071baef896b0e11a247cb.png)'
- en: guidance_scale = 2.5
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: guidance_scale = 2.5
- en: '![](../Images/0d10a98f98590aa92471ef3aabf758c6.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d10a98f98590aa92471ef3aabf758c6.png)'
- en: guidance_scale = 7.5
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: guidance_scale = 7.5
- en: '![](../Images/e32bf623e4fd55de7bce1266f480fffb.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e32bf623e4fd55de7bce1266f480fffb.png)'
- en: guidance_scale = 12.5
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: guidance_scale = 12.5
- en: Negative prompt
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负提示
- en: A negative prompt assumes the opposite role of a prompt; it guides the model
    away from generating certain things in an image. This is useful for quickly improving
    image quality and preventing the model from generating things you don’t want.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 负提示扮演与提示相反角色的作用；它引导模型远离在图像中生成某些内容。这对于快速改善图像质量并防止模型生成您不想要的内容非常有用。
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/a9e6a070339236ad42e15252d8be37a7.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9e6a070339236ad42e15252d8be37a7.png)'
- en: negative_prompt = "bad architecture, unstable, poor details, blurry"
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: negative_prompt = "bad architecture, unstable, poor details, blurry"
- en: Padding mask crop
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 填充蒙版裁剪
- en: A method for increasing the inpainting image quality is to use the [`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop)
    parameter. When enabled, this option crops the masked area with some user-specified
    padding and it’ll also crop the same area from the original image. Both the image
    and mask are upscaled to a higher resolution for inpainting, and then overlaid
    on the original image. This is a quick and easy way to improve image quality without
    using a separate pipeline like [StableDiffusionUpscalePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 增加修复图像质量的一种方法是使用[`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop)参数。启用此选项后，该选项将使用一些用户指定的填充裁剪掩码区域，并且还将从原始图像中裁剪相同区域。图像和掩码都将被放大到更高的分辨率进行修复，然后覆盖在原始图像上。这是一种快速简便的方法，可以在不使用单独的管道（如[StableDiffusionUpscalePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline)）的情况下改善图像质量。
- en: Add the `padding_mask_crop` parameter to the pipeline call and set it to the
    desired padding value.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道调用中添加`padding_mask_crop`参数，并将其设置为所需的填充值。
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/1770d17f089e4087ecdf844bc2f75ad6.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1770d17f089e4087ecdf844bc2f75ad6.png)'
- en: default inpaint image
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 默认修复图像
- en: '![](../Images/f4ef40443043de12e889be5caf4c9289.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4ef40443043de12e889be5caf4c9289.png)'
- en: inpaint image with `padding_mask_crop` enabled
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 启用`padding_mask_crop`对图像进行修复
- en: Chained inpainting pipelines
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 链接修复管道
- en: '[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    can be chained with other 🤗 Diffusers pipelines to edit their outputs. This is
    often useful for improving the output quality from your other diffusion pipelines,
    and if you’re using multiple pipelines, it can be more memory-efficient to chain
    them together to keep the outputs in latent space and reuse the same pipeline
    components.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)可以与其他🤗
    Diffusers管道链接以编辑它们的输出。这通常对于改善其他扩散管道的输出质量很有用，如果您使用多个管道，则将它们链接在一起以保持输出在潜在空间中并重复使用相同的管道组件可能更节省内存。'
- en: Text-to-image-to-inpaint
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本到图像到修复
- en: Chaining a text-to-image and inpainting pipeline allows you to inpaint the generated
    image, and you don’t have to provide a base image to begin with. This makes it
    convenient to edit your favorite text-to-image outputs without having to generate
    an entirely new image.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 链接文本到图像和修复管道允许您修复生成的图像，而无需提供基础图像。这使得编辑您喜欢的文本到图像输出变得更加方便，而无需生成全新的图像。
- en: 'Start with the text-to-image pipeline to create a castle:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本到图像管道开始创建一个城堡：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Load the mask image of the output from above:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 加载上述输出的蒙版图像：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And let’s inpaint the masked area with a waterfall:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们用瀑布填补蒙版区域：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/2cc5fc0f54d60ce54294305f4a65f5b2.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cc5fc0f54d60ce54294305f4a65f5b2.png)'
- en: text-to-image
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到图像
- en: '![](../Images/b685c42746dfa11241d879c1e331fac2.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b685c42746dfa11241d879c1e331fac2.png)'
- en: inpaint
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 修复
- en: Inpaint-to-image-to-image
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修复到图像到图像
- en: You can also chain an inpainting pipeline before another pipeline like image-to-image
    or an upscaler to improve the quality.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在另一个管道之前链接一个修复管道，如图像到图像或一个放大器，以提高质量。
- en: 'Begin by inpainting an image:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从修复图像开始：
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now let’s pass the image to another inpainting pipeline with SDXL’s refiner
    model to enhance the image details and quality:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将图像传递给另一个修复管道，使用SDXL的细化模型增强图像的细节和质量：
- en: '[PRE18]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It is important to specify `output_type="latent"` in the pipeline to keep all
    the outputs in latent space to avoid an unnecessary decode-encode step. This only
    works if the chained pipelines are using the same VAE. For example, in the [Text-to-image-to-inpaint](#text-to-image-to-inpaint)
    section, Kandinsky 2.2 uses a different VAE class than the Stable Diffusion model
    so it won’t work. But if you use Stable Diffusion v1.5 for both pipelines, then
    you can keep everything in latent space because they both use [AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道中指定`output_type="latent"`非常重要，以将所有输出保留在潜在空间中，避免不必要的解码-编码步骤。这仅在链接的管道使用相同的VAE时才有效。例如，在[Text-to-image-to-inpaint](#text-to-image-to-inpaint)部分中，Kandinsky
    2.2使用与稳定扩散模型不同的VAE类，因此不起作用。但是，如果您对两个管道都使用稳定扩散v1.5，则可以将所有内容保留在潜在空间中，因为它们都使用[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)。
- en: Finally, you can pass this image to an image-to-image pipeline to put the finishing
    touches on it. It is more efficient to use the [from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)
    method to reuse the existing pipeline components, and avoid unnecessarily loading
    all the pipeline components into memory again.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以将此图像传递给图像到图像管道，以完成最后的润色。最好使用[from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)方法来重用现有的管道组件，避免再次将所有管道组件加载到内存中。
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: initial image
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 初始图像
- en: '![](../Images/5fec6ffc8bfc87edf18dd2bfa1e68bb5.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fec6ffc8bfc87edf18dd2bfa1e68bb5.png)'
- en: inpaint
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 修复
- en: '![](../Images/ba2bb2403b87d4b1fb495bae370dc1c4.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba2bb2403b87d4b1fb495bae370dc1c4.png)'
- en: image-to-image
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图像到图像
- en: Image-to-image and inpainting are actually very similar tasks. Image-to-image
    generates a new image that resembles the existing provided image. Inpainting does
    the same thing, but it only transforms the image area defined by the mask and
    the rest of the image is unchanged. You can think of inpainting as a more precise
    tool for making specific changes and image-to-image has a broader scope for making
    more sweeping changes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图像到图像和修复实际上是非常相似的任务。图像到图像生成一个类似于提供的现有图像的新图像。修复也是同样的操作，但它只转换由蒙版定义的图像区域，其余部分保持不变。您可以将修复视为进行特定更改的更精确工具，而图像到图像则具有进行更广泛更改的更广泛范围。
- en: Control image generation
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制图像生成
- en: Getting an image to look exactly the way you want is challenging because the
    denoising process is random. While you can control certain aspects of generation
    by configuring parameters like `negative_prompt`, there are better and more efficient
    methods for controlling image generation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让图像看起来完全符合您的要求是具有挑战性的，因为去噪过程是随机的。虽然您可以通过配置诸如`negative_prompt`之类的参数来控制生成的某些方面，但有更好更有效的方法来控制图像生成。
- en: Prompt weighting
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示加权
- en: Prompt weighting provides a quantifiable way to scale the representation of
    concepts in a prompt. You can use it to increase or decrease the magnitude of
    the text embedding vector for each concept in the prompt, which subsequently determines
    how much of each concept is generated. The [Compel](https://github.com/damian0815/compel)
    library offers an intuitive syntax for scaling the prompt weights and generating
    the embeddings. Learn how to create the embeddings in the [Prompt weighting](../using-diffusers/weighted_prompts)
    guide.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 提示加权提供了一种可量化的方式来调整提示中概念的表示。您可以使用它来增加或减少提示中每个概念的文本嵌入向量的大小，从而确定生成每个概念的数量。[Compel](https://github.com/damian0815/compel)库提供了一种直观的语法，用于调整提示权重并生成嵌入。了解如何在[Prompt
    weighting](../using-diffusers/weighted_prompts)指南中创建嵌入。
- en: 'Once you’ve generated the embeddings, pass them to the `prompt_embeds` (and
    `negative_prompt_embeds` if you’re using a negative prompt) parameter in the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting).
    The embeddings replace the `prompt` parameter:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 生成嵌入后，将它们传递给[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)中的`prompt_embeds`（如果您使用负提示，则还有`negative_prompt_embeds`）参数。嵌入替换了`prompt`参数：
- en: '[PRE20]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ControlNet
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ControlNet
- en: ControlNet models are used with other diffusion models like Stable Diffusion,
    and they provide an even more flexible and accurate way to control how an image
    is generated. A ControlNet accepts an additional conditioning image input that
    guides the diffusion model to preserve the features in it.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet模型与其他扩散模型一起使用，如稳定扩散，它们提供了一种更灵活和准确的方式来控制图像的生成方式。ControlNet接受额外的条件图像输入，指导扩散模型保留其中的特征。
- en: 'For example, let’s condition an image with a ControlNet pretrained on inpaint
    images:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们使用在修复图像上预训练的ControlNet对图像进行条件处理：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now generate an image from the base, mask and control images. You’ll notice
    features of the base image are strongly preserved in the generated image.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在从基础、蒙版和控制图像生成图像。您会注意到生成的图像中强烈保留了基础图像的特征。
- en: '[PRE22]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You can take this a step further and chain it with an image-to-image pipeline
    to apply a new [style](https://huggingface.co/nitrosocke/elden-ring-diffusion):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以进一步将其与图像到图像管道链接起来，应用一个新的[风格](https://huggingface.co/nitrosocke/elden-ring-diffusion)：
- en: '[PRE23]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: initial image
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 初始图像
- en: '![](../Images/916b854bd12a25f80f4e9acf9e6601b6.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/916b854bd12a25f80f4e9acf9e6601b6.png)'
- en: ControlNet inpaint
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet inpaint
- en: '![](../Images/a9594334cac8c0320fd63c03f321d2de.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9594334cac8c0320fd63c03f321d2de.png)'
- en: image-to-image
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图像到图像
- en: Optimize
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化
- en: It can be difficult and slow to run diffusion models if you’re resource constrained,
    but it doesn’t have to be with a few optimization tricks. One of the biggest (and
    easiest) optimizations you can enable is switching to memory-efficient attention.
    If you’re using PyTorch 2.0, [scaled-dot product attention](../optimization/torch2.0#scaled-dot-product-attention)
    is automatically enabled and you don’t need to do anything else. For non-PyTorch
    2.0 users, you can install and use [xFormers](../optimization/xformers)’s implementation
    of memory-efficient attention. Both options reduce memory usage and accelerate
    inference.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 运行扩散模型可能会很困难和缓慢，如果你的资源受限，但通过一些优化技巧，就不必如此。其中一个最大（也是最简单）的优化是切换到内存高效的注意力机制。如果你正在使用PyTorch
    2.0，[缩放点积注意力](../optimization/torch2.0#scaled-dot-product-attention)会自动启用，你不需要做其他任何事情。对于非PyTorch
    2.0用户，你可以安装并使用[xFormers](../optimization/xformers)的内存高效注意力实现。这两个选项都可以减少内存使用量并加速推断。
- en: 'You can also offload the model to the CPU to save even more memory:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将模型转移到CPU以节省更多内存：
- en: '[PRE24]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To speed-up your inference code even more, use [`torch_compile`](../optimization/torch2.0#torchcompile).
    You should wrap `torch.compile` around the most intensive component in the pipeline
    which is typically the UNet:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步加快推断代码的速度，请使用[`torch_compile`](../optimization/torch2.0#torchcompile)。你应该将`torch.compile`包装在管道中最密集的组件周围，通常是UNet：
- en: '[PRE25]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Learn more in the [Reduce memory usage](../optimization/memory) and [Torch 2.0](../optimization/torch2.0)
    guides.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在[减少内存使用](../optimization/memory)和[Torch 2.0](../optimization/torch2.0)指南中了解更多。
