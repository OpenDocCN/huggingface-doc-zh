- en: Inpainting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¿®å¤
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/inpaint](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/inpaint](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Inpainting replaces or edits specific areas of an image. This makes it a useful
    tool for image restoration like removing defects and artifacts, or even replacing
    an image area with something entirely new. Inpainting relies on a mask to determine
    which regions of an image to fill in; the area to inpaint is represented by white
    pixels and the area to keep is represented by black pixels. The white pixels are
    filled in by the prompt.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿®å¤æ›¿æ¢æˆ–ç¼–è¾‘å›¾åƒçš„ç‰¹å®šåŒºåŸŸã€‚è¿™ä½¿å¾—å®ƒæˆä¸ºåƒå»é™¤ç¼ºé™·å’Œä¼ªå½±ï¼Œç”šè‡³ç”¨å…¨æ–°å†…å®¹æ›¿æ¢å›¾åƒåŒºåŸŸç­‰å›¾åƒæ¢å¤çš„æœ‰ç”¨å·¥å…·ã€‚ä¿®å¤ä¾èµ–äºè’™ç‰ˆæ¥ç¡®å®šè¦å¡«å……å›¾åƒçš„å“ªäº›åŒºåŸŸï¼›è¦ä¿®å¤çš„åŒºåŸŸç”±ç™½è‰²åƒç´ è¡¨ç¤ºï¼Œè¦ä¿ç•™çš„åŒºåŸŸç”±é»‘è‰²åƒç´ è¡¨ç¤ºã€‚ç™½è‰²åƒç´ ç”±æç¤ºå¡«å……ã€‚
- en: 'With ğŸ¤— Diffusers, here is how you can do inpainting:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ğŸ¤— Diffusersï¼Œä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥è¿›è¡Œä¿®å¤çš„æ–¹æ³•ï¼š
- en: 'Load an inpainting checkpoint with the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    class. Thisâ€™ll automatically detect the appropriate pipeline class to load based
    on the checkpoint:'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)ç±»åŠ è½½ä¿®å¤æ£€æŸ¥ç‚¹ã€‚è¿™å°†æ ¹æ®æ£€æŸ¥ç‚¹è‡ªåŠ¨æ£€æµ‹è¦åŠ è½½çš„é€‚å½“ç®¡é“ç±»ï¼š
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Youâ€™ll notice throughout the guide, we use [enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)
    and [enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention),
    to save memory and increase inference speed. If youâ€™re using PyTorch 2.0, itâ€™s
    not necessary to call [enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)
    on your pipeline because itâ€™ll already be using PyTorch 2.0â€™s native [scaled-dot
    product attention](../optimization/torch2.0#scaled-dot-product-attention).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•´ä¸ªæŒ‡å—ä¸­ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°æˆ‘ä»¬ä½¿ç”¨[enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)å’Œ[enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶æé«˜æ¨ç†é€Ÿåº¦ã€‚å¦‚æœæ‚¨ä½¿ç”¨PyTorch
    2.0ï¼Œåˆ™ä¸éœ€è¦åœ¨ç®¡é“ä¸Šè°ƒç”¨[enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)ï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ä½¿ç”¨PyTorch
    2.0çš„æœ¬æœº[scaled-dot product attention](../optimization/torch2.0#scaled-dot-product-attention)ã€‚
- en: 'Load the base and mask images:'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŠ è½½åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒï¼š
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a prompt to inpaint the image with and pass it to the pipeline with
    the base and mask images:'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªç”¨äºä¿®å¤å›¾åƒçš„æç¤ºï¼Œå¹¶å°†å…¶ä¼ é€’ç»™å…·æœ‰åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒçš„ç®¡é“ï¼š
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: base image
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºç¡€å›¾åƒ
- en: '![](../Images/50397365c167c77e28b112edb22eb879.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50397365c167c77e28b112edb22eb879.png)'
- en: mask image
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è’™ç‰ˆå›¾åƒ
- en: '![](../Images/53b76ec0efb1b6851d4c8b23347a3f52.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53b76ec0efb1b6851d4c8b23347a3f52.png)'
- en: generated image
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„å›¾åƒ
- en: Create a mask image
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªè’™ç‰ˆå›¾åƒ
- en: Throughout this guide, the mask image is provided in all of the code examples
    for convenience. You can inpaint on your own images, but youâ€™ll need to create
    a mask image for it. Use the Space below to easily create a mask image.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•´ä¸ªæŒ‡å—ä¸­ï¼Œè’™ç‰ˆå›¾åƒåœ¨æ‰€æœ‰ä»£ç ç¤ºä¾‹ä¸­éƒ½æä¾›äº†ï¼Œä»¥æ–¹ä¾¿ä½¿ç”¨ã€‚æ‚¨å¯ä»¥å¯¹è‡ªå·±çš„å›¾åƒè¿›è¡Œä¿®å¤ï¼Œä½†éœ€è¦ä¸ºå…¶åˆ›å»ºä¸€ä¸ªè’™ç‰ˆå›¾åƒã€‚ä½¿ç”¨ä¸‹é¢çš„ç©ºé—´è½»æ¾åˆ›å»ºä¸€ä¸ªè’™ç‰ˆå›¾åƒã€‚
- en: Upload a base image to inpaint on and use the sketch tool to draw a mask. Once
    youâ€™re done, click **Run** to generate and download the mask image.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šä¼ ä¸€ä¸ªåŸºç¡€å›¾åƒè¿›è¡Œä¿®å¤ï¼Œå¹¶ä½¿ç”¨è‰å›¾å·¥å…·ç»˜åˆ¶è’™ç‰ˆã€‚å®Œæˆåï¼Œç‚¹å‡»**è¿è¡Œ**ç”Ÿæˆå¹¶ä¸‹è½½è’™ç‰ˆå›¾åƒã€‚
- en: '[https://stevhliu-inpaint-mask-maker.hf.space](https://stevhliu-inpaint-mask-maker.hf.space)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://stevhliu-inpaint-mask-maker.hf.space](https://stevhliu-inpaint-mask-maker.hf.space)'
- en: Mask blur
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è’™ç‰ˆæ¨¡ç³Š
- en: The `~VaeImageProcessor.blur` method provides an option for how to blend the
    original image and inpaint area. The amount of blur is determined by the `blur_factor`
    parameter. Increasing the `blur_factor` increases the amount of blur applied to
    the mask edges, softening the transition between the original image and inpaint
    area. A low or zero `blur_factor` preserves the sharper edges of the mask.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`~VaeImageProcessor.blur`æ–¹æ³•æä¾›äº†å¦‚ä½•æ··åˆåŸå§‹å›¾åƒå’Œä¿®å¤åŒºåŸŸçš„é€‰é¡¹ã€‚æ¨¡ç³Šç¨‹åº¦ç”±`blur_factor`å‚æ•°ç¡®å®šã€‚å¢åŠ `blur_factor`ä¼šå¢åŠ åº”ç”¨äºè’™ç‰ˆè¾¹ç¼˜çš„æ¨¡ç³Šé‡ï¼Œè½¯åŒ–åŸå§‹å›¾åƒå’Œä¿®å¤åŒºåŸŸä¹‹é—´çš„è¿‡æ¸¡ã€‚ä½æˆ–é›¶çš„`blur_factor`ä¼šä¿ç•™è’™ç‰ˆçš„æ›´æ¸…æ™°è¾¹ç¼˜ã€‚'
- en: To use this, create a blurred mask with the image processor.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨å›¾åƒå¤„ç†å™¨åˆ›å»ºä¸€ä¸ªæ¨¡ç³Šçš„è’™ç‰ˆã€‚
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/bd4255378e4be6f2da63ef7b2951ac46.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd4255378e4be6f2da63ef7b2951ac46.png)'
- en: mask with no blur
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ— æ¨¡ç³Šçš„è’™ç‰ˆ
- en: '![](../Images/8a2ec7820a1b085328cbab8c7625a7d0.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a2ec7820a1b085328cbab8c7625a7d0.png)'
- en: mask with blur applied
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨äº†æ¨¡ç³Šçš„è’™ç‰ˆ
- en: Popular models
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: çƒ­é—¨æ¨¡å‹
- en: '[Stable Diffusion Inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting),
    [Stable Diffusion XL (SDXL) Inpainting](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1),
    and [Kandinsky 2.2 Inpainting](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint)
    are among the most popular models for inpainting. SDXL typically produces higher
    resolution images than Stable Diffusion v1.5, and Kandinsky 2.2 is also capable
    of generating high-quality images.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç¨³å®šæ‰©æ•£ä¿®å¤](https://huggingface.co/runwayml/stable-diffusion-inpainting)ã€[ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰ä¿®å¤](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1)å’Œ[Kandinsky
    2.2ä¿®å¤](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint)æ˜¯ä¿®å¤ä¸­æœ€å—æ¬¢è¿çš„æ¨¡å‹ä¹‹ä¸€ã€‚SDXLé€šå¸¸æ¯”ç¨³å®šæ‰©æ•£v1.5ç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒï¼Œè€ŒKandinsky
    2.2ä¹Ÿèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚'
- en: Stable Diffusion Inpainting
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ä¿®å¤
- en: 'Stable Diffusion Inpainting is a latent diffusion model finetuned on 512x512
    images on inpainting. It is a good starting point because it is relatively fast
    and generates good quality images. To use this model for inpainting, youâ€™ll need
    to pass a prompt, base and mask image to the pipeline:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ä¿®å¤æ˜¯ä¸€ä¸ªåœ¨ä¿®å¤ä¸Šè¿›è¡Œå¾®è°ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œé€‚ç”¨äº512x512å›¾åƒã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œå› ä¸ºå®ƒç›¸å¯¹å¿«é€Ÿå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚è¦å°†æ­¤æ¨¡å‹ç”¨äºä¿®å¤ï¼Œæ‚¨éœ€è¦å°†æç¤ºã€åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒä¼ é€’ç»™ç®¡é“ï¼š
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Stable Diffusion XL (SDXL) Inpainting
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰ä¿®å¤
- en: SDXL is a larger and more powerful version of Stable Diffusion v1.5\. This model
    can follow a two-stage model process (though each model can also be used alone);
    the base model generates an image, and a refiner model takes that image and further
    enhances its details and quality. Take a look at the [SDXL](sdxl) guide for a
    more comprehensive guide on how to use SDXL and configure itâ€™s parameters.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: SDXLæ˜¯ç¨³å®šæ‰©æ•£v1.5çš„æ›´å¤§æ›´å¼ºå¤§çš„ç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹å¯ä»¥éµå¾ªä¸¤é˜¶æ®µæ¨¡å‹è¿‡ç¨‹ï¼ˆå°½ç®¡æ¯ä¸ªæ¨¡å‹ä¹Ÿå¯ä»¥å•ç‹¬ä½¿ç”¨ï¼‰ï¼›åŸºç¡€æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œç²¾åŒ–æ¨¡å‹æ¥æ”¶è¯¥å›¾åƒå¹¶è¿›ä¸€æ­¥å¢å¼ºå…¶ç»†èŠ‚å’Œè´¨é‡ã€‚æŸ¥çœ‹[SDXL](sdxl)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨SDXLå¹¶é…ç½®å…¶å‚æ•°çš„æ›´å…¨é¢æŒ‡å—ã€‚
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Kandinsky 2.2 Inpainting
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kandinsky 2.2ä¿®å¤
- en: The Kandinsky model family is similar to SDXL because it uses two models as
    well; the image prior model creates image embeddings, and the diffusion model
    generates images from them. You can load the image prior and diffusion model separately,
    but the easiest way to use Kandinsky 2.2 is to load it into the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    class which uses the [KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)
    under the hood.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinskyæ¨¡å‹ç³»åˆ—ç±»ä¼¼äºSDXLï¼Œå› ä¸ºå®ƒä¹Ÿä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹ï¼›å›¾åƒå…ˆéªŒæ¨¡å‹åˆ›å»ºå›¾åƒåµŒå…¥ï¼Œæ‰©æ•£æ¨¡å‹ä»ä¸­ç”Ÿæˆå›¾åƒã€‚æ‚¨å¯ä»¥åˆ†åˆ«åŠ è½½å›¾åƒå…ˆéªŒå’Œæ‰©æ•£æ¨¡å‹ï¼Œä½†ä½¿ç”¨Kandinsky
    2.2çš„æœ€ç®€å•æ–¹æ³•æ˜¯å°†å…¶åŠ è½½åˆ°[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)ç±»ä¸­ï¼Œè¯¥ç±»åœ¨åº•å±‚ä½¿ç”¨[KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)ã€‚
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: base image
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºç¡€å›¾åƒ
- en: '![](../Images/09fbce513beddef5b655c0a444a3c86c.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09fbce513beddef5b655c0a444a3c86c.png)'
- en: Stable Diffusion Inpainting
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ä¿®å¤
- en: '![](../Images/2489c89cec0d33d1acc14b3011bf03c9.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2489c89cec0d33d1acc14b3011bf03c9.png)'
- en: Stable Diffusion XL Inpainting
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XLä¿®å¤
- en: '![](../Images/44c50c30f2c0b8b5adb606ae538dbb54.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44c50c30f2c0b8b5adb606ae538dbb54.png)'
- en: Kandinsky 2.2 Inpainting
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.2ä¿®å¤
- en: Non-inpaint specific checkpoints
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹
- en: So far, this guide has used inpaint specific checkpoints such as [runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting).
    But you can also use regular checkpoints like [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5).
    Letâ€™s compare the results of the two checkpoints.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæœ¬æŒ‡å—å·²ä½¿ç”¨ä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹ï¼Œå¦‚[runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)ã€‚ä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œå¦‚[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)ã€‚è®©æˆ‘ä»¬æ¯”è¾ƒè¿™ä¸¤ä¸ªæ£€æŸ¥ç‚¹çš„ç»“æœã€‚
- en: The image on the left is generated from a regular checkpoint, and the image
    on the right is from an inpaint checkpoint. Youâ€™ll immediately notice the image
    on the left is not as clean, and you can still see the outline of the area the
    model is supposed to inpaint. The image on the right is much cleaner and the inpainted
    area appears more natural.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦ä¾§çš„å›¾åƒæ˜¯ä»å¸¸è§„æ£€æŸ¥ç‚¹ç”Ÿæˆçš„ï¼Œå³ä¾§çš„å›¾åƒæ˜¯ä»ä¿®å¤æ£€æŸ¥ç‚¹ç”Ÿæˆçš„ã€‚æ‚¨ä¼šç«‹å³æ³¨æ„åˆ°å·¦ä¾§çš„å›¾åƒä¸å¤Ÿæ¸…æ™°ï¼Œä»ç„¶å¯ä»¥çœ‹åˆ°æ¨¡å‹åº”è¯¥ä¿®å¤çš„åŒºåŸŸçš„è½®å»“ã€‚å³ä¾§çš„å›¾åƒæ›´æ¸…æ™°ï¼Œä¿®å¤åŒºåŸŸçœ‹èµ·æ¥æ›´è‡ªç„¶ã€‚
- en: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpainting
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpainting
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/5a890789342f9e1a86868211a7896271.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a890789342f9e1a86868211a7896271.png)'
- en: runwayml/stable-diffusion-v1-5
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5
- en: '![](../Images/aecbb44542e32cda8ce2bb2da3d692e3.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aecbb44542e32cda8ce2bb2da3d692e3.png)'
- en: runwayml/stable-diffusion-inpainting
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-inpainting
- en: However, for more basic tasks like erasing an object from an image (like the
    rocks in the road for example), a regular checkpoint yields pretty good results.
    There isnâ€™t as noticeable of difference between the regular and inpaint checkpoint.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¯¹äºæ›´åŸºæœ¬çš„ä»»åŠ¡ï¼Œæ¯”å¦‚ä»å›¾åƒä¸­æ“¦é™¤ä¸€ä¸ªå¯¹è±¡ï¼ˆæ¯”å¦‚é“è·¯ä¸Šçš„å²©çŸ³ï¼‰ï¼Œå¸¸è§„æ£€æŸ¥ç‚¹ä¼šäº§ç”Ÿç›¸å½“ä¸é”™çš„ç»“æœã€‚å¸¸è§„æ£€æŸ¥ç‚¹å’Œä¿®å¤æ£€æŸ¥ç‚¹ä¹‹é—´çš„å·®å¼‚ä¸å¤ªæ˜æ˜¾ã€‚
- en: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpaint
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5runwayml/stable-diffusion-inpaint
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/f49798dfa50ce8a7c46fe18a6da38589.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f49798dfa50ce8a7c46fe18a6da38589.png)'
- en: runwayml/stable-diffusion-v1-5
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-v1-5
- en: '![](../Images/c59fac74bc905b0800d717d2ce675c20.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c59fac74bc905b0800d717d2ce675c20.png)'
- en: runwayml/stable-diffusion-inpainting
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: runwayml/stable-diffusion-inpainting
- en: The trade-off of using a non-inpaint specific checkpoint is the overall image
    quality may be lower, but it generally tends to preserve the mask area (that is
    why you can see the mask outline). The inpaint specific checkpoints are intentionally
    trained to generate higher quality inpainted images, and that includes creating
    a more natural transition between the masked and unmasked areas. As a result,
    these checkpoints are more likely to change your unmasked area.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨éä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹çš„æŠ˜è¡·æ˜¯æ•´ä½“å›¾åƒè´¨é‡å¯èƒ½è¾ƒä½ï¼Œä½†é€šå¸¸å€¾å‘äºä¿ç•™è’™ç‰ˆåŒºåŸŸï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨å¯ä»¥çœ‹åˆ°è’™ç‰ˆè½®å»“ï¼‰ã€‚ä¿®å¤ç‰¹å®šæ£€æŸ¥ç‚¹ç»è¿‡æœ‰æ„è®­ç»ƒï¼Œä»¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„ä¿®å¤å›¾åƒï¼Œè¿™åŒ…æ‹¬åœ¨è’™ç‰ˆå’Œéè’™ç‰ˆåŒºåŸŸä¹‹é—´åˆ›å»ºæ›´è‡ªç„¶çš„è¿‡æ¸¡ã€‚å› æ­¤ï¼Œè¿™äº›æ£€æŸ¥ç‚¹æ›´æœ‰å¯èƒ½æ”¹å˜æ‚¨çš„éè’™ç‰ˆåŒºåŸŸã€‚
- en: If preserving the unmasked area is important for your task, you can use the
    `VaeImageProcessor.apply_overlay` method to force the unmasked area of an image
    to remain the same at the expense of some more unnatural transitions between the
    masked and unmasked areas.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¿ç•™éè’™ç‰ˆåŒºåŸŸå¯¹æ‚¨çš„ä»»åŠ¡å¾ˆé‡è¦ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`VaeImageProcessor.apply_overlay`æ–¹æ³•ï¼Œå¼ºåˆ¶å›¾åƒçš„éè’™ç‰ˆåŒºåŸŸä¿æŒä¸å˜ï¼Œä½†ä¼šä»¥ä¸€äº›æ›´ä¸è‡ªç„¶çš„è¿‡æ¸¡ä¸ºä»£ä»·ã€‚
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Configure pipeline parameters
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é…ç½®ç®¡é“å‚æ•°
- en: Image features - like quality and â€œcreativityâ€ - are dependent on pipeline parameters.
    Knowing what these parameters do is important for getting the results you want.
    Letâ€™s take a look at the most important parameters and see how changing them affects
    the output.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒç‰¹å¾ - å¦‚è´¨é‡å’Œâ€œåˆ›é€ åŠ›â€ - å–å†³äºç®¡é“å‚æ•°ã€‚äº†è§£è¿™äº›å‚æ•°çš„ä½œç”¨å¯¹äºè·å¾—æƒ³è¦çš„ç»“æœå¾ˆé‡è¦ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æœ€é‡è¦çš„å‚æ•°ï¼Œå¹¶äº†è§£æ›´æ”¹å®ƒä»¬å¦‚ä½•å½±å“è¾“å‡ºã€‚
- en: Strength
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¼ºåº¦
- en: '`strength` is a measure of how much noise is added to the base image, which
    influences how similar the output is to the base image.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`å¼ºåº¦`æ˜¯è¡¡é‡å‘åŸºç¡€å›¾åƒæ·»åŠ å¤šå°‘å™ªéŸ³çš„æŒ‡æ ‡ï¼Œè¿™å½±å“è¾“å‡ºä¸åŸºç¡€å›¾åƒçš„ç›¸ä¼¼ç¨‹åº¦ã€‚'
- en: ğŸ“ˆ a high `strength` value means more noise is added to an image and the denoising
    process takes longer, but youâ€™ll get higher quality images that are more different
    from the base image
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“ˆ é«˜`å¼ºåº¦`å€¼æ„å‘³ç€å‘å›¾åƒæ·»åŠ æ›´å¤šå™ªéŸ³ï¼Œå»å™ªè¿‡ç¨‹éœ€è¦æ›´é•¿æ—¶é—´ï¼Œä½†æ‚¨å°†è·å¾—è´¨é‡æ›´é«˜ä¸”ä¸åŸºç¡€å›¾åƒä¸åŒçš„å›¾åƒ
- en: ğŸ“‰ a low `strength` value means less noise is added to an image and the denoising
    process is faster, but the image quality may not be as great and the generated
    image resembles the base image more
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“‰ ä½`å¼ºåº¦`å€¼æ„å‘³ç€å‘å›¾åƒæ·»åŠ çš„å™ªéŸ³è¾ƒå°‘ï¼Œå»å™ªè¿‡ç¨‹æ›´å¿«ï¼Œä½†å›¾åƒè´¨é‡å¯èƒ½ä¸ä¼šå¾ˆå¥½ï¼Œç”Ÿæˆçš„å›¾åƒæ›´ç±»ä¼¼äºåŸºç¡€å›¾åƒ
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/39f952b5e61ce473b5fc8dab92c18466.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39f952b5e61ce473b5fc8dab92c18466.png)'
- en: strength = 0.6
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºåº¦ = 0.6
- en: '![](../Images/ba1cef420a7d6632e8dad96029906868.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba1cef420a7d6632e8dad96029906868.png)'
- en: strength = 0.8
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºåº¦ = 0.8
- en: '![](../Images/b42b3e014dc563c0005c55a35f02fba9.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b42b3e014dc563c0005c55a35f02fba9.png)'
- en: strength = 1.0
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºåº¦ = 1.0
- en: Guidance scale
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¼•å¯¼æ¯”ä¾‹
- en: '`guidance_scale` affects how aligned the text prompt and generated image are.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`guidance_scale`å½±å“æ–‡æœ¬æç¤ºå’Œç”Ÿæˆå›¾åƒçš„å¯¹é½ç¨‹åº¦ã€‚'
- en: ğŸ“ˆ a high `guidance_scale` value means the prompt and generated image are closely
    aligned, so the output is a stricter interpretation of the prompt
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“ˆ é«˜`guidance_scale`å€¼æ„å‘³ç€æç¤ºå’Œç”Ÿæˆçš„å›¾åƒç´§å¯†å¯¹é½ï¼Œå› æ­¤è¾“å‡ºæ˜¯å¯¹æç¤ºçš„æ›´ä¸¥æ ¼è§£é‡Š
- en: ğŸ“‰ a low `guidance_scale` value means the prompt and generated image are more
    loosely aligned, so the output may be more varied from the prompt
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“‰ ä½`guidance_scale`å€¼æ„å‘³ç€æç¤ºå’Œç”Ÿæˆçš„å›¾åƒæ›´æ¾æ•£å¯¹é½ï¼Œå› æ­¤è¾“å‡ºå¯èƒ½ä¸æç¤ºæ›´ä¸ºä¸åŒ
- en: You can use `strength` and `guidance_scale` together for more control over how
    expressive the model is. For example, a combination high `strength` and `guidance_scale`
    values gives the model the most creative freedom.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åŒæ—¶ä½¿ç”¨`å¼ºåº¦`å’Œ`guidance_scale`æ¥æ›´å¥½åœ°æ§åˆ¶æ¨¡å‹çš„è¡¨ç°ã€‚ä¾‹å¦‚ï¼Œé«˜`å¼ºåº¦`å’Œ`guidance_scale`å€¼çš„ç»„åˆç»™äºˆæ¨¡å‹æœ€å¤§çš„åˆ›é€ è‡ªç”±åº¦ã€‚
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/363406b3094071baef896b0e11a247cb.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/363406b3094071baef896b0e11a247cb.png)'
- en: guidance_scale = 2.5
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: guidance_scale = 2.5
- en: '![](../Images/0d10a98f98590aa92471ef3aabf758c6.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d10a98f98590aa92471ef3aabf758c6.png)'
- en: guidance_scale = 7.5
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: guidance_scale = 7.5
- en: '![](../Images/e32bf623e4fd55de7bce1266f480fffb.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e32bf623e4fd55de7bce1266f480fffb.png)'
- en: guidance_scale = 12.5
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: guidance_scale = 12.5
- en: Negative prompt
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è´Ÿæç¤º
- en: A negative prompt assumes the opposite role of a prompt; it guides the model
    away from generating certain things in an image. This is useful for quickly improving
    image quality and preventing the model from generating things you donâ€™t want.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è´Ÿæç¤ºæ‰®æ¼”ä¸æç¤ºç›¸åè§’è‰²çš„ä½œç”¨ï¼›å®ƒå¼•å¯¼æ¨¡å‹è¿œç¦»åœ¨å›¾åƒä¸­ç”ŸæˆæŸäº›å†…å®¹ã€‚è¿™å¯¹äºå¿«é€Ÿæ”¹å–„å›¾åƒè´¨é‡å¹¶é˜²æ­¢æ¨¡å‹ç”Ÿæˆæ‚¨ä¸æƒ³è¦çš„å†…å®¹éå¸¸æœ‰ç”¨ã€‚
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/a9e6a070339236ad42e15252d8be37a7.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9e6a070339236ad42e15252d8be37a7.png)'
- en: negative_prompt = "bad architecture, unstable, poor details, blurry"
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: negative_prompt = "bad architecture, unstable, poor details, blurry"
- en: Padding mask crop
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¡«å……è’™ç‰ˆè£å‰ª
- en: A method for increasing the inpainting image quality is to use the [`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop)
    parameter. When enabled, this option crops the masked area with some user-specified
    padding and itâ€™ll also crop the same area from the original image. Both the image
    and mask are upscaled to a higher resolution for inpainting, and then overlaid
    on the original image. This is a quick and easy way to improve image quality without
    using a separate pipeline like [StableDiffusionUpscalePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å¢åŠ ä¿®å¤å›¾åƒè´¨é‡çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨[`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop)å‚æ•°ã€‚å¯ç”¨æ­¤é€‰é¡¹åï¼Œè¯¥é€‰é¡¹å°†ä½¿ç”¨ä¸€äº›ç”¨æˆ·æŒ‡å®šçš„å¡«å……è£å‰ªæ©ç åŒºåŸŸï¼Œå¹¶ä¸”è¿˜å°†ä»åŸå§‹å›¾åƒä¸­è£å‰ªç›¸åŒåŒºåŸŸã€‚å›¾åƒå’Œæ©ç éƒ½å°†è¢«æ”¾å¤§åˆ°æ›´é«˜çš„åˆ†è¾¨ç‡è¿›è¡Œä¿®å¤ï¼Œç„¶åè¦†ç›–åœ¨åŸå§‹å›¾åƒä¸Šã€‚è¿™æ˜¯ä¸€ç§å¿«é€Ÿç®€ä¾¿çš„æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸ä½¿ç”¨å•ç‹¬çš„ç®¡é“ï¼ˆå¦‚[StableDiffusionUpscalePipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline)ï¼‰çš„æƒ…å†µä¸‹æ”¹å–„å›¾åƒè´¨é‡ã€‚
- en: Add the `padding_mask_crop` parameter to the pipeline call and set it to the
    desired padding value.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç®¡é“è°ƒç”¨ä¸­æ·»åŠ `padding_mask_crop`å‚æ•°ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºæ‰€éœ€çš„å¡«å……å€¼ã€‚
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/1770d17f089e4087ecdf844bc2f75ad6.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1770d17f089e4087ecdf844bc2f75ad6.png)'
- en: default inpaint image
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤ä¿®å¤å›¾åƒ
- en: '![](../Images/f4ef40443043de12e889be5caf4c9289.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4ef40443043de12e889be5caf4c9289.png)'
- en: inpaint image with `padding_mask_crop` enabled
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨`padding_mask_crop`å¯¹å›¾åƒè¿›è¡Œä¿®å¤
- en: Chained inpainting pipelines
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é“¾æ¥ä¿®å¤ç®¡é“
- en: '[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
    can be chained with other ğŸ¤— Diffusers pipelines to edit their outputs. This is
    often useful for improving the output quality from your other diffusion pipelines,
    and if youâ€™re using multiple pipelines, it can be more memory-efficient to chain
    them together to keep the outputs in latent space and reuse the same pipeline
    components.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)å¯ä»¥ä¸å…¶ä»–ğŸ¤—
    Diffusersç®¡é“é“¾æ¥ä»¥ç¼–è¾‘å®ƒä»¬çš„è¾“å‡ºã€‚è¿™é€šå¸¸å¯¹äºæ”¹å–„å…¶ä»–æ‰©æ•£ç®¡é“çš„è¾“å‡ºè´¨é‡å¾ˆæœ‰ç”¨ï¼Œå¦‚æœæ‚¨ä½¿ç”¨å¤šä¸ªç®¡é“ï¼Œåˆ™å°†å®ƒä»¬é“¾æ¥åœ¨ä¸€èµ·ä»¥ä¿æŒè¾“å‡ºåœ¨æ½œåœ¨ç©ºé—´ä¸­å¹¶é‡å¤ä½¿ç”¨ç›¸åŒçš„ç®¡é“ç»„ä»¶å¯èƒ½æ›´èŠ‚çœå†…å­˜ã€‚'
- en: Text-to-image-to-inpaint
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ°å›¾åƒåˆ°ä¿®å¤
- en: Chaining a text-to-image and inpainting pipeline allows you to inpaint the generated
    image, and you donâ€™t have to provide a base image to begin with. This makes it
    convenient to edit your favorite text-to-image outputs without having to generate
    an entirely new image.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: é“¾æ¥æ–‡æœ¬åˆ°å›¾åƒå’Œä¿®å¤ç®¡é“å…è®¸æ‚¨ä¿®å¤ç”Ÿæˆçš„å›¾åƒï¼Œè€Œæ— éœ€æä¾›åŸºç¡€å›¾åƒã€‚è¿™ä½¿å¾—ç¼–è¾‘æ‚¨å–œæ¬¢çš„æ–‡æœ¬åˆ°å›¾åƒè¾“å‡ºå˜å¾—æ›´åŠ æ–¹ä¾¿ï¼Œè€Œæ— éœ€ç”Ÿæˆå…¨æ–°çš„å›¾åƒã€‚
- en: 'Start with the text-to-image pipeline to create a castle:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ–‡æœ¬åˆ°å›¾åƒç®¡é“å¼€å§‹åˆ›å»ºä¸€ä¸ªåŸå ¡ï¼š
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Load the mask image of the output from above:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸Šè¿°è¾“å‡ºçš„è’™ç‰ˆå›¾åƒï¼š
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And letâ€™s inpaint the masked area with a waterfall:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè®©æˆ‘ä»¬ç”¨ç€‘å¸ƒå¡«è¡¥è’™ç‰ˆåŒºåŸŸï¼š
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/2cc5fc0f54d60ce54294305f4a65f5b2.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cc5fc0f54d60ce54294305f4a65f5b2.png)'
- en: text-to-image
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ°å›¾åƒ
- en: '![](../Images/b685c42746dfa11241d879c1e331fac2.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b685c42746dfa11241d879c1e331fac2.png)'
- en: inpaint
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿®å¤
- en: Inpaint-to-image-to-image
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¿®å¤åˆ°å›¾åƒåˆ°å›¾åƒ
- en: You can also chain an inpainting pipeline before another pipeline like image-to-image
    or an upscaler to improve the quality.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥åœ¨å¦ä¸€ä¸ªç®¡é“ä¹‹å‰é“¾æ¥ä¸€ä¸ªä¿®å¤ç®¡é“ï¼Œå¦‚å›¾åƒåˆ°å›¾åƒæˆ–ä¸€ä¸ªæ”¾å¤§å™¨ï¼Œä»¥æé«˜è´¨é‡ã€‚
- en: 'Begin by inpainting an image:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¿®å¤å›¾åƒå¼€å§‹ï¼š
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now letâ€™s pass the image to another inpainting pipeline with SDXLâ€™s refiner
    model to enhance the image details and quality:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å°†å›¾åƒä¼ é€’ç»™å¦ä¸€ä¸ªä¿®å¤ç®¡é“ï¼Œä½¿ç”¨SDXLçš„ç»†åŒ–æ¨¡å‹å¢å¼ºå›¾åƒçš„ç»†èŠ‚å’Œè´¨é‡ï¼š
- en: '[PRE18]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It is important to specify `output_type="latent"` in the pipeline to keep all
    the outputs in latent space to avoid an unnecessary decode-encode step. This only
    works if the chained pipelines are using the same VAE. For example, in the [Text-to-image-to-inpaint](#text-to-image-to-inpaint)
    section, Kandinsky 2.2 uses a different VAE class than the Stable Diffusion model
    so it wonâ€™t work. But if you use Stable Diffusion v1.5 for both pipelines, then
    you can keep everything in latent space because they both use [AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç®¡é“ä¸­æŒ‡å®š`output_type="latent"`éå¸¸é‡è¦ï¼Œä»¥å°†æ‰€æœ‰è¾“å‡ºä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œé¿å…ä¸å¿…è¦çš„è§£ç -ç¼–ç æ­¥éª¤ã€‚è¿™ä»…åœ¨é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„VAEæ—¶æ‰æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼Œåœ¨[Text-to-image-to-inpaint](#text-to-image-to-inpaint)éƒ¨åˆ†ä¸­ï¼ŒKandinsky
    2.2ä½¿ç”¨ä¸ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸åŒçš„VAEç±»ï¼Œå› æ­¤ä¸èµ·ä½œç”¨ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨å¯¹ä¸¤ä¸ªç®¡é“éƒ½ä½¿ç”¨ç¨³å®šæ‰©æ•£v1.5ï¼Œåˆ™å¯ä»¥å°†æ‰€æœ‰å†…å®¹ä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä½¿ç”¨[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)ã€‚
- en: Finally, you can pass this image to an image-to-image pipeline to put the finishing
    touches on it. It is more efficient to use the [from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)
    method to reuse the existing pipeline components, and avoid unnecessarily loading
    all the pipeline components into memory again.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæ‚¨å¯ä»¥å°†æ­¤å›¾åƒä¼ é€’ç»™å›¾åƒåˆ°å›¾åƒç®¡é“ï¼Œä»¥å®Œæˆæœ€åçš„æ¶¦è‰²ã€‚æœ€å¥½ä½¿ç”¨[from_pipe()](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)æ–¹æ³•æ¥é‡ç”¨ç°æœ‰çš„ç®¡é“ç»„ä»¶ï¼Œé¿å…å†æ¬¡å°†æ‰€æœ‰ç®¡é“ç»„ä»¶åŠ è½½åˆ°å†…å­˜ä¸­ã€‚
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: initial image
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹å›¾åƒ
- en: '![](../Images/5fec6ffc8bfc87edf18dd2bfa1e68bb5.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fec6ffc8bfc87edf18dd2bfa1e68bb5.png)'
- en: inpaint
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿®å¤
- en: '![](../Images/ba2bb2403b87d4b1fb495bae370dc1c4.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba2bb2403b87d4b1fb495bae370dc1c4.png)'
- en: image-to-image
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒåˆ°å›¾åƒ
- en: Image-to-image and inpainting are actually very similar tasks. Image-to-image
    generates a new image that resembles the existing provided image. Inpainting does
    the same thing, but it only transforms the image area defined by the mask and
    the rest of the image is unchanged. You can think of inpainting as a more precise
    tool for making specific changes and image-to-image has a broader scope for making
    more sweeping changes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒåˆ°å›¾åƒå’Œä¿®å¤å®é™…ä¸Šæ˜¯éå¸¸ç›¸ä¼¼çš„ä»»åŠ¡ã€‚å›¾åƒåˆ°å›¾åƒç”Ÿæˆä¸€ä¸ªç±»ä¼¼äºæä¾›çš„ç°æœ‰å›¾åƒçš„æ–°å›¾åƒã€‚ä¿®å¤ä¹Ÿæ˜¯åŒæ ·çš„æ“ä½œï¼Œä½†å®ƒåªè½¬æ¢ç”±è’™ç‰ˆå®šä¹‰çš„å›¾åƒåŒºåŸŸï¼Œå…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜ã€‚æ‚¨å¯ä»¥å°†ä¿®å¤è§†ä¸ºè¿›è¡Œç‰¹å®šæ›´æ”¹çš„æ›´ç²¾ç¡®å·¥å…·ï¼Œè€Œå›¾åƒåˆ°å›¾åƒåˆ™å…·æœ‰è¿›è¡Œæ›´å¹¿æ³›æ›´æ”¹çš„æ›´å¹¿æ³›èŒƒå›´ã€‚
- en: Control image generation
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ§åˆ¶å›¾åƒç”Ÿæˆ
- en: Getting an image to look exactly the way you want is challenging because the
    denoising process is random. While you can control certain aspects of generation
    by configuring parameters like `negative_prompt`, there are better and more efficient
    methods for controlling image generation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è®©å›¾åƒçœ‹èµ·æ¥å®Œå…¨ç¬¦åˆæ‚¨çš„è¦æ±‚æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºå»å™ªè¿‡ç¨‹æ˜¯éšæœºçš„ã€‚è™½ç„¶æ‚¨å¯ä»¥é€šè¿‡é…ç½®è¯¸å¦‚`negative_prompt`ä¹‹ç±»çš„å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆçš„æŸäº›æ–¹é¢ï¼Œä½†æœ‰æ›´å¥½æ›´æœ‰æ•ˆçš„æ–¹æ³•æ¥æ§åˆ¶å›¾åƒç”Ÿæˆã€‚
- en: Prompt weighting
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æç¤ºåŠ æƒ
- en: Prompt weighting provides a quantifiable way to scale the representation of
    concepts in a prompt. You can use it to increase or decrease the magnitude of
    the text embedding vector for each concept in the prompt, which subsequently determines
    how much of each concept is generated. The [Compel](https://github.com/damian0815/compel)
    library offers an intuitive syntax for scaling the prompt weights and generating
    the embeddings. Learn how to create the embeddings in the [Prompt weighting](../using-diffusers/weighted_prompts)
    guide.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºåŠ æƒæä¾›äº†ä¸€ç§å¯é‡åŒ–çš„æ–¹å¼æ¥è°ƒæ•´æç¤ºä¸­æ¦‚å¿µçš„è¡¨ç¤ºã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥å¢åŠ æˆ–å‡å°‘æç¤ºä¸­æ¯ä¸ªæ¦‚å¿µçš„æ–‡æœ¬åµŒå…¥å‘é‡çš„å¤§å°ï¼Œä»è€Œç¡®å®šç”Ÿæˆæ¯ä¸ªæ¦‚å¿µçš„æ•°é‡ã€‚[Compel](https://github.com/damian0815/compel)åº“æä¾›äº†ä¸€ç§ç›´è§‚çš„è¯­æ³•ï¼Œç”¨äºè°ƒæ•´æç¤ºæƒé‡å¹¶ç”ŸæˆåµŒå…¥ã€‚äº†è§£å¦‚ä½•åœ¨[Prompt
    weighting](../using-diffusers/weighted_prompts)æŒ‡å—ä¸­åˆ›å»ºåµŒå…¥ã€‚
- en: 'Once youâ€™ve generated the embeddings, pass them to the `prompt_embeds` (and
    `negative_prompt_embeds` if youâ€™re using a negative prompt) parameter in the [AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting).
    The embeddings replace the `prompt` parameter:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ç”ŸæˆåµŒå…¥åï¼Œå°†å®ƒä»¬ä¼ é€’ç»™[AutoPipelineForInpainting](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)ä¸­çš„`prompt_embeds`ï¼ˆå¦‚æœæ‚¨ä½¿ç”¨è´Ÿæç¤ºï¼Œåˆ™è¿˜æœ‰`negative_prompt_embeds`ï¼‰å‚æ•°ã€‚åµŒå…¥æ›¿æ¢äº†`prompt`å‚æ•°ï¼š
- en: '[PRE20]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ControlNet
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ControlNet
- en: ControlNet models are used with other diffusion models like Stable Diffusion,
    and they provide an even more flexible and accurate way to control how an image
    is generated. A ControlNet accepts an additional conditioning image input that
    guides the diffusion model to preserve the features in it.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNetæ¨¡å‹ä¸å…¶ä»–æ‰©æ•£æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼Œå¦‚ç¨³å®šæ‰©æ•£ï¼Œå®ƒä»¬æä¾›äº†ä¸€ç§æ›´çµæ´»å’Œå‡†ç¡®çš„æ–¹å¼æ¥æ§åˆ¶å›¾åƒçš„ç”Ÿæˆæ–¹å¼ã€‚ControlNetæ¥å—é¢å¤–çš„æ¡ä»¶å›¾åƒè¾“å…¥ï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹ä¿ç•™å…¶ä¸­çš„ç‰¹å¾ã€‚
- en: 'For example, letâ€™s condition an image with a ControlNet pretrained on inpaint
    images:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨åœ¨ä¿®å¤å›¾åƒä¸Šé¢„è®­ç»ƒçš„ControlNetå¯¹å›¾åƒè¿›è¡Œæ¡ä»¶å¤„ç†ï¼š
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now generate an image from the base, mask and control images. Youâ€™ll notice
    features of the base image are strongly preserved in the generated image.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä»åŸºç¡€ã€è’™ç‰ˆå’Œæ§åˆ¶å›¾åƒç”Ÿæˆå›¾åƒã€‚æ‚¨ä¼šæ³¨æ„åˆ°ç”Ÿæˆçš„å›¾åƒä¸­å¼ºçƒˆä¿ç•™äº†åŸºç¡€å›¾åƒçš„ç‰¹å¾ã€‚
- en: '[PRE22]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You can take this a step further and chain it with an image-to-image pipeline
    to apply a new [style](https://huggingface.co/nitrosocke/elden-ring-diffusion):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è¿›ä¸€æ­¥å°†å…¶ä¸å›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥èµ·æ¥ï¼Œåº”ç”¨ä¸€ä¸ªæ–°çš„[é£æ ¼](https://huggingface.co/nitrosocke/elden-ring-diffusion)ï¼š
- en: '[PRE23]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54493b4e03ab58931aa2b35535a314d.png)'
- en: initial image
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹å›¾åƒ
- en: '![](../Images/916b854bd12a25f80f4e9acf9e6601b6.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/916b854bd12a25f80f4e9acf9e6601b6.png)'
- en: ControlNet inpaint
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet inpaint
- en: '![](../Images/a9594334cac8c0320fd63c03f321d2de.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9594334cac8c0320fd63c03f321d2de.png)'
- en: image-to-image
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒåˆ°å›¾åƒ
- en: Optimize
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–
- en: It can be difficult and slow to run diffusion models if youâ€™re resource constrained,
    but it doesnâ€™t have to be with a few optimization tricks. One of the biggest (and
    easiest) optimizations you can enable is switching to memory-efficient attention.
    If youâ€™re using PyTorch 2.0, [scaled-dot product attention](../optimization/torch2.0#scaled-dot-product-attention)
    is automatically enabled and you donâ€™t need to do anything else. For non-PyTorch
    2.0 users, you can install and use [xFormers](../optimization/xformers)â€™s implementation
    of memory-efficient attention. Both options reduce memory usage and accelerate
    inference.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œæ‰©æ•£æ¨¡å‹å¯èƒ½ä¼šå¾ˆå›°éš¾å’Œç¼“æ…¢ï¼Œå¦‚æœä½ çš„èµ„æºå—é™ï¼Œä½†é€šè¿‡ä¸€äº›ä¼˜åŒ–æŠ€å·§ï¼Œå°±ä¸å¿…å¦‚æ­¤ã€‚å…¶ä¸­ä¸€ä¸ªæœ€å¤§ï¼ˆä¹Ÿæ˜¯æœ€ç®€å•ï¼‰çš„ä¼˜åŒ–æ˜¯åˆ‡æ¢åˆ°å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶ã€‚å¦‚æœä½ æ­£åœ¨ä½¿ç”¨PyTorch
    2.0ï¼Œ[ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)ä¼šè‡ªåŠ¨å¯ç”¨ï¼Œä½ ä¸éœ€è¦åšå…¶ä»–ä»»ä½•äº‹æƒ…ã€‚å¯¹äºéPyTorch
    2.0ç”¨æˆ·ï¼Œä½ å¯ä»¥å®‰è£…å¹¶ä½¿ç”¨[xFormers](../optimization/xformers)çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å®ç°ã€‚è¿™ä¸¤ä¸ªé€‰é¡¹éƒ½å¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨é‡å¹¶åŠ é€Ÿæ¨æ–­ã€‚
- en: 'You can also offload the model to the CPU to save even more memory:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜å¯ä»¥å°†æ¨¡å‹è½¬ç§»åˆ°CPUä»¥èŠ‚çœæ›´å¤šå†…å­˜ï¼š
- en: '[PRE24]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To speed-up your inference code even more, use [`torch_compile`](../optimization/torch2.0#torchcompile).
    You should wrap `torch.compile` around the most intensive component in the pipeline
    which is typically the UNet:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿›ä¸€æ­¥åŠ å¿«æ¨æ–­ä»£ç çš„é€Ÿåº¦ï¼Œè¯·ä½¿ç”¨[`torch_compile`](../optimization/torch2.0#torchcompile)ã€‚ä½ åº”è¯¥å°†`torch.compile`åŒ…è£…åœ¨ç®¡é“ä¸­æœ€å¯†é›†çš„ç»„ä»¶å‘¨å›´ï¼Œé€šå¸¸æ˜¯UNetï¼š
- en: '[PRE25]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Learn more in the [Reduce memory usage](../optimization/memory) and [Torch 2.0](../optimization/torch2.0)
    guides.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[å‡å°‘å†…å­˜ä½¿ç”¨](../optimization/memory)å’Œ[Torch 2.0](../optimization/torch2.0)æŒ‡å—ä¸­äº†è§£æ›´å¤šã€‚
