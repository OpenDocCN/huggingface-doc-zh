- en: ControlNet with Stable Diffusion XL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有 Stable Diffusion XL 的 ControlNet
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/controlnet_sdxl](https://huggingface.co/docs/diffusers/api/pipelines/controlnet_sdxl)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/controlnet_sdxl](https://huggingface.co/docs/diffusers/api/pipelines/controlnet_sdxl)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ControlNet was introduced in [Adding Conditional Control to Text-to-Image Diffusion
    Models](https://huggingface.co/papers/2302.05543) by Lvmin Zhang, Anyi Rao, and
    Maneesh Agrawala.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 在 [向文本到图像扩散模型添加条件控制](https://huggingface.co/papers/2302.05543) 中由
    Lvmin Zhang、Anyi Rao 和 Maneesh Agrawala 提出。
- en: With a ControlNet model, you can provide an additional control image to condition
    and control Stable Diffusion generation. For example, if you provide a depth map,
    the ControlNet model generates an image that’ll preserve the spatial information
    from the depth map. It is a more flexible and accurate way to control the image
    generation process.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ControlNet 模型，您可以提供额外的控制图像来调节和控制 Stable Diffusion 生成。例如，如果您提供深度图，ControlNet
    模型将生成一个保留深度图中空间信息的图像。这是一种更灵活和准确的控制图像生成过程的方式。
- en: 'The abstract from the paper is:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要为：
- en: '*We present ControlNet, a neural network architecture to add spatial conditioning
    controls to large, pretrained text-to-image diffusion models. ControlNet locks
    the production-ready large diffusion models, and reuses their deep and robust
    encoding layers pretrained with billions of images as a strong backbone to learn
    a diverse set of conditional controls. The neural architecture is connected with
    “zero convolutions” (zero-initialized convolution layers) that progressively grow
    the parameters from zero and ensure that no harmful noise could affect the finetuning.
    We test various conditioning controls, eg, edges, depth, segmentation, human pose,
    etc, with Stable Diffusion, using single or multiple conditions, with or without
    prompts. We show that the training of ControlNets is robust with small (<50k)
    and large (>1m) datasets. Extensive results show that ControlNet may facilitate
    wider applications to control image diffusion models.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了 ControlNet，这是一种神经网络架构，用于向大型、预训练的文本到图像扩散模型添加空间调节控制。ControlNet 锁定了生产就绪的大型扩散模型，并重复使用它们的深度和稳健的编码层，这些编码层经过数十亿张图像的预训练，作为学习各种条件控制的强大支撑。神经架构连接了“零卷积”（从零初始化的卷积层），逐渐增加参数，确保没有有害噪音会影响微调。我们测试了各种调节控制，例如边缘、深度、分割、人体姿势等，使用单个或多个条件，有或没有提示，与
    Stable Diffusion 结合。我们展示了 ControlNet 的训练对于小型（<50k）和大型（>1m）数据集是稳健的。广泛的结果表明，ControlNet
    可能促进更广泛的应用，以控制图像扩散模型。*'
- en: You can find additional smaller Stable Diffusion XL (SDXL) ControlNet checkpoints
    from the 🤗 [Diffusers](https://huggingface.co/diffusers) Hub organization, and
    browse [community-trained](https://huggingface.co/models?other=stable-diffusion-xl&other=controlnet)
    checkpoints on the Hub.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在🤗 [Diffusers](https://huggingface.co/diffusers) Hub 组织中找到额外的较小的 Stable Diffusion
    XL（SDXL）ControlNet 检查点，并在 Hub 上浏览[社区训练的](https://huggingface.co/models?other=stable-diffusion-xl&other=controlnet)检查点。
- en: 🧪 Many of the SDXL ControlNet checkpoints are experimental, and there is a lot
    of room for improvement. Feel free to open an [Issue](https://github.com/huggingface/diffusers/issues/new/choose)
    and leave us feedback on how we can improve!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 🧪 许多 SDXL ControlNet 检查点是实验性的，有很大的改进空间。欢迎打开一个[Issue](https://github.com/huggingface/diffusers/issues/new/choose)，告诉我们如何改进！
- en: If you don’t see a checkpoint you’re interested in, you can train your own SDXL
    ControlNet with our [training script](../../../../../examples/controlnet/README_sdxl).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有看到您感兴趣的检查点，您可以使用我们的[训练脚本](../../../../../examples/controlnet/README_sdxl)训练自己的SDXL
    ControlNet。
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 确保查看调度器[指南](../../using-diffusers/schedulers)以了解如何探索调度器速度和质量之间的权衡，并查看[跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)部分，以了解如何有效地将相同组件加载到多个管道中。
- en: StableDiffusionXLControlNetPipeline
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionXLControlNetPipeline
- en: '### `class diffusers.StableDiffusionXLControlNetPipeline`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '`diffusers.StableDiffusionXLControlNetPipeline` 类'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L117)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L117)'
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — 变分自动编码器（VAE）模型，用于将图像编码和解码为潜在表示形式。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — 冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`text_encoder_2` ([CLIPTextModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelWithProjection))
    — Second frozen text-encoder ([laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_2` ([CLIPTextModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelWithProjection))
    — 第二个冻结的文本编码器（[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 用于对文本进行标记化的 `CLIPTokenizer`。'
- en: '`tokenizer_2` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_2` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 用于对文本进行标记化的 `CLIPTokenizer`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪编码图像潜变量的 `UNet2DConditionModel`。'
- en: '`controlnet` ([ControlNetModel](/docs/diffusers/v0.26.3/en/api/models/controlnet#diffusers.ControlNetModel)
    or `List[ControlNetModel]`) — Provides additional conditioning to the `unet` during
    the denoising process. If you set multiple ControlNets as a list, the outputs
    from each ControlNet are added together to create one combined additional conditioning.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`controlnet` ([ControlNetModel](/docs/diffusers/v0.26.3/en/api/models/controlnet#diffusers.ControlNetModel)
    或 `List[ControlNetModel]`) — 在去噪过程中为 `unet` 提供额外的条件。如果将多个 ControlNet 设置为列表，则每个
    ControlNet 的输出将相加，以创建一个组合的额外条件。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 用于与 `unet` 结合使用以去噪编码图像潜变量的调度程序。可以是 [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)
    或 [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    中的一个。'
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) —
    Whether the negative prompt embeddings should always be set to 0\. Also see the
    config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_zeros_for_empty_prompt` (`bool`, *可选*, 默认为 `"True"`) — 是否始终将负提示嵌入设置为
    0。也请参阅 `stabilityai/stable-diffusion-xl-base-1-0` 的配置。'
- en: '`add_watermarker` (`bool`, *optional*) — Whether to use the [invisible_watermark](https://github.com/ShieldMnt/invisible-watermark/)
    library to watermark output images. If not defined, it defaults to `True` if the
    package is installed; otherwise no watermarker is used.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_watermarker` (`bool`, *可选*) — 是否使用 [invisible_watermark](https://github.com/ShieldMnt/invisible-watermark/)
    库对输出图像进行水印处理。如果未定义，且安装了该软件包，则默认为 `True`；否则不使用水印处理。'
- en: Pipeline for text-to-image generation using Stable Diffusion XL with ControlNet
    guidance.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Stable Diffusion XL 和 ControlNet 指导的文本到图像生成流水线。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有流水线实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '该流水线还继承了以下加载方法:'
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    用于加载 LoRA 权重'
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_lora_weights()` 用于保存 LoRA 权重'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    用于加载 `.ckpt` 文件'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    用于加载 IP 适配器'
- en: '#### `__call__`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L943)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L943)'
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成的提示。如果未定义，则需要传递 `prompt_embeds`。'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts to be
    sent to `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used in
    both text-encoders.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2` (`str` 或 `List[str]`, *可选*) — 发送到 `tokenizer_2` 和 `text_encoder_2`
    的提示。如果未定义，则在两个文本编码器中使用 `prompt`。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, `List[np.ndarray]`, — `List[List[torch.FloatTensor]]`,
    `List[List[np.ndarray]]` or `List[List[PIL.Image.Image]]`): The ControlNet input
    condition to provide guidance to the `unet` for generation. If the type is specified
    as `torch.FloatTensor`, it is passed to ControlNet as is. `PIL.Image.Image` can
    also be accepted as an image. The dimensions of the output image defaults to `image`’s
    dimensions. If height and/or width are passed, `image` is resized accordingly.
    If multiple ControlNets are specified in `init`, images must be passed as a list
    such that each element of the list can be correctly batched for input to a single
    ControlNet.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, `List[np.ndarray]`, — `List[List[torch.FloatTensor]]`,
    `List[List[np.ndarray]]` 或 `List[List[PIL.Image.Image]]`): 用于为`unet`提供指导的ControlNet输入条件。如果指定类型为`torch.FloatTensor`，则按原样传递给ControlNet。`PIL.Image.Image`也可以作为图像接受。输出图像的尺寸默认为`image`的尺寸。如果传递了高度和/或宽度，`image`将相应调整大小。如果在`init`中指定了多个ControlNets，则必须将图像作为列表传递，以便列表的每个元素可以正确批处理为单个ControlNet的输入。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image. Anything below 512 pixels won’t
    work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为`self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素高度。低于512像素的任何内容都不适用于[stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)和未经专门调整以适应低分辨率的检查点。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image. Anything below 512 pixels won’t
    work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为`self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素宽度。低于512像素的任何内容都不适用于[stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)和未经专门调整以适应低分辨率的检查点。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为50) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 5.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为5.0) — 更高的引导比例值鼓励模型生成与文本`prompt`密切相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 指导图像生成中不包括的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用引导时（`guidance_scale
    < 1`）将被忽略。'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. This is sent to `tokenizer_2`
    and `text_encoder_2`. If not defined, `negative_prompt` is used in both text-encoders.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` 或 `List[str]`, *可选*) — 指导图像生成中不包括的提示或提示。这将发送到`tokenizer_2`和`text_encoder_2`。如果未定义，则在两个文本编码器中都使用`negative_prompt`。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *可选*, 默认为0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数eta
    (η)。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度程序中将被忽略。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 从高斯分布中预先生成的噪声潜变量，用作图像生成的输入。可用于使用不同提示微调相同的生成。如果未提供，则通过使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预先生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，将从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预先生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs (prompt weighting). If
    not provided, pooled text embeddings are generated from `prompt` input argument.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的池化文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，池化文本嵌入将从
    `prompt` 输入参数生成。'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs (prompt
    weighting). If not provided, pooled `negative_prompt_embeds` are generated from
    `negative_prompt` input argument. ip_adapter_image — (`PipelineImageInput`, *optional*):
    Optional image input to work with IP Adapters.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负面池化文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，负面池化文本嵌入将从
    `negative_prompt` 输入参数生成。ip_adapter_image — (`PipelineImageInput`, *optional*):
    可选的图像输入，用于与 IP 适配器一起使用。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为 `"pil"`) — 生成图像的输出格式。选择 `PIL.Image` 或
    `np.array` 之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为 `True`) — 是否返回 [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    而不是普通元组。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给 `AttentionProcessor`
    的 kwargs 字典，如 [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    中定义。'
- en: '`controlnet_conditioning_scale` (`float` or `List[float]`, *optional*, defaults
    to 1.0) — The outputs of the ControlNet are multiplied by `controlnet_conditioning_scale`
    before they are added to the residual in the original `unet`. If multiple ControlNets
    are specified in `init`, you can set the corresponding scale as a list.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`controlnet_conditioning_scale` (`float` 或 `List[float]`, *optional*, 默认为 1.0)
    — 在将 ControlNet 的输出添加到原始 `unet` 中的残差之前，将其乘以 `controlnet_conditioning_scale`。如果在
    `init` 中指定了多个 ControlNets，可以将相应的比例设置为列表。'
- en: '`guess_mode` (`bool`, *optional*, defaults to `False`) — The ControlNet encoder
    tries to recognize the content of the input image even if you remove all prompts.
    A `guidance_scale` value between 3.0 and 5.0 is recommended.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guess_mode` (`bool`, *optional*, 默认为 `False`) — 控制网络编码器尝试识别输入图像的内容，即使您删除了所有提示。建议设置
    `guidance_scale` 值在 3.0 到 5.0 之间。'
- en: '`control_guidance_start` (`float` or `List[float]`, *optional*, defaults to
    0.0) — The percentage of total steps at which the ControlNet starts applying.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`control_guidance_start` (`float` 或 `List[float]`, *optional*, 默认为 0.0) — 控制网络开始应用的总步骤百分比。'
- en: '`control_guidance_end` (`float` or `List[float]`, *optional*, defaults to 1.0)
    — The percentage of total steps at which the ControlNet stops applying.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`control_guidance_end` (`float` 或 `List[float]`, *optional*, 默认为 1.0) — 控制网络停止应用的总步骤百分比。'
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) — If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXL’s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`original_size` (`Tuple[int]`, *optional*, 默认为 (1024, 1024)) — 如果 `original_size`
    与 `target_size` 不同，图像将呈现为缩小或放大。如果未指定，`original_size` 默认为 `(height, width)`。作为
    SDXL 的微调条件的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) — `crops_coords_top_left`
    can be used to generate an image that appears to be “cropped” from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crops_coords_top_left` (`Tuple[int]`, *optional*, 默认为 (0, 0)) — `crops_coords_top_left`
    可用于生成一个看起来从位置 `crops_coords_top_left` 向下“裁剪”的图像。通常通过将 `crops_coords_top_left`
    设置为 (0, 0) 来实现有利的、居中的图像。作为 SDXL 的微调条件的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) — For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size` (`Tuple[int]`, *optional*, 默认为 (1024, 1024)) — 对于大多数情况，`target_size`
    应设置为生成图像的期望高度和宽度。如果未指定，将默认为 `(height, width)`。作为 SDXL 的微调条件的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。'
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    — To negatively condition the generation process based on a specific image resolution.
    Part of SDXL’s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_original_size` (`Tuple[int]`, *optional*, 默认为 (1024, 1024)) — 基于特定图像分辨率否定地调整生成过程。作为
    SDXL 的微调条件的一部分，详见 [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    第2.2节。有关更多信息，请参考此问题线程：[https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208)。'
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) — To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXL’s micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_crops_coords_top_left`（`Tuple[int]`，*可选*，默认为(0, 0)）—根据特定裁剪坐标对生成过程进行负条件化。作为SDXL的微条件化的一部分，如[https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)第2.2节中所述。有关更多信息，请参考此问题线程：[https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208)。'
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    — To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXL’s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_target_size`（`Tuple[int]`，*可选*，默认为(1024, 1024)）—根据目标图像分辨率对生成过程进行负条件化。对于大多数情况，它应与`target_size`相同。作为SDXL的微条件化的一部分，如[https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)第2.2节中所述。有关更多信息，请参考此问题线程：[https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208)。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip`（`int`，*可选*）—在计算提示嵌入时要跳过的CLIP层数。值为1意味着将使用预最终层的输出来计算提示嵌入。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end`（`Callable`，*可选*）—在推断期间每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`将包括由`callback_on_step_end_tensor_inputs`指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeine class.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs`（`List`，*可选*）—`callback_on_step_end`函数的张量输入列表。列表中指定的张量将作为`callback_kwargs`参数传递。您只能包含在管道类的`._callback_tensor_inputs`属性中列出的变量。'
- en: Returns
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned containing the output images.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个包含输出图像的`tuple`。
- en: The call function to the pipeline for generation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `disable_freeu`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L887)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L887)'
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用，禁用FreeU机制。
- en: '#### `disable_vae_slicing`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L234)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L234)'
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果之前启用了`enable_vae_slicing`，则此方法将返回到一步计算解码。
- en: '#### `disable_vae_tiling`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L251)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L251)'
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺VAE解码。如果之前启用了`enable_vae_tiling`，则此方法将返回到一步计算解码。
- en: '#### `enable_freeu`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L864)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L864)'
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1`（`float`）—用于减弱跳过特征贡献的第1阶段的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效应”。'
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2`（`float`）—用于减弱跳过特征贡献的第2阶段的缩放因子。这样做是为了减轻增强去噪过程中的“过度平滑效应”。'
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1`（`float`）—用于放大第1阶段的骨干特征贡献的缩放因子。'
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2`（`float`）—用于放大第2阶段的骨干特征贡献的缩放因子。'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 启用FreeU机制，如[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)。
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子后缀表示应用它们的阶段。
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同管道（如Stable Diffusion
    v1、v2和Stable Diffusion XL）的值组合。
- en: '#### `enable_vae_slicing`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L226)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L226)'
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。启用此选项时，VAE将在几个步骤中将输入张量分割成切片以进行解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `enable_vae_tiling`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L242)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L242)'
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺VAE解码。启用此选项时，VAE将将输入张量分成瓦片以在几个步骤中进行解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `encode_prompt`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L259)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py#L259)'
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) — 要编码的提示'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device — (`torch.device`): torch device'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2` (`str` or `List[str]`, *optional*) — 要发送到`tokenizer_2`和`text_encoder_2`的提示或提示。如果未定义，则在两个文本编码器设备中使用`prompt`
    — (`torch.device`): torch设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用无分类器指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 不用来指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。在不使用指导时被忽略（即如果`guidance_scale`小于`1`，则被忽略）。'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` or `List[str]`, *optional*) — 不用来指导图像生成的提示或提示，要发送到`tokenizer_2`和`text_encoder_2`。如果未定义，则在两个文本编码器中使用`negative_prompt`'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成负negative_prompt_embeds。'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的池化文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成池化的文本嵌入。'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负池化文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成池化的negative_prompt_embeds。'
- en: '`lora_scale` (`float`, *optional*) — A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *optional*) — 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的lora比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 计算提示嵌入时要从CLIP中跳过的层数。值为1表示将使用预终层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
