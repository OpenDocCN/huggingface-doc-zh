- en: Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: 'Original text: [https://huggingface.co/docs/tokenizers/api/models](https://huggingface.co/docs/tokenizers/api/models)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/tokenizers/api/models](https://huggingface.co/docs/tokenizers/api/models)
- en: PythonRustNode
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: PythonRustNode
- en: BPE
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BPE
- en: '### `class tokenizers.models.BPE`'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.models.BPE`'
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`Dict[str, int]`, *optional*) — A dictionnary of string keys and their
    ids `{"am": 0,...}`'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`Dict[str, int]`, *可选*) — 一个字符串键和其ID的字典 `{"am": 0,...}`'
- en: '`merges` (`List[Tuple[str, str]]`, *optional*) — A list of pairs of tokens
    (`Tuple[str, str]`) `[("a", "b"),...]`'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges` (`List[Tuple[str, str]]`, *可选*) — 一对标记（`Tuple[str, str]`）的列表 `[("a",
    "b"),...]`'
- en: '`cache_capacity` (`int`, *optional*) — The number of words that the BPE cache
    can contain. The cache allows to speed-up the process by keeping the result of
    the merge operations for a number of words.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_capacity` (`int`, *可选*) — BPE缓存可以包含的单词数。缓存通过保留一定数量的单词的合并操作结果来加速过程。'
- en: '`dropout` (`float`, *optional*) — A float between 0 and 1 that represents the
    BPE dropout to use.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *可选*) — 介于0和1之间的浮点数，表示要使用的BPE dropout。'
- en: '`unk_token` (`str`, *optional*) — The unknown token to be used by the model.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *可选*) — 模型要使用的未知标记。'
- en: '`continuing_subword_prefix` (`str`, *optional*) — The prefix to attach to subword
    units that don’t represent a beginning of word.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`continuing_subword_prefix` (`str`, *可选*) — 要附加到不表示单词开头的子词单元的前缀。'
- en: '`end_of_word_suffix` (`str`, *optional*) — The suffix to attach to subword
    units that represent an end of word.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end_of_word_suffix` (`str`, *可选*) — 要附加到表示单词结尾的子词单元的后缀。'
- en: '`fuse_unk` (`bool`, *optional*) — Whether to fuse any subsequent unknown tokens
    into a single one'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fuse_unk` (`bool`, *可选*) — 是否将任何后续未知标记融合为一个'
- en: '`byte_fallback` (`bool`, *optional*) — Whether to use spm byte-fallback trick
    (defaults to False)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`byte_fallback` (`bool`, *可选*) — 是否使用 spm 字节回退技巧（默认为 False）'
- en: An implementation of the BPE (Byte-Pair Encoding) algorithm
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: BPE（Byte-Pair Encoding）算法的实现
- en: '#### `from_file`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_file`'
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`) — 指向 `vocab.json` 文件的路径'
- en: '`merges` (`str`) — The path to a `merges.txt` file'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges` (`str`) — 指向 `merges.txt` 文件的路径'
- en: Returns
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BPE](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.BPE)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[BPE](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.BPE)'
- en: An instance of BPE loaded from these files
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些文件加载的BPE实例
- en: Instantiate a BPE model from the given files.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定文件实例化一个BPE模型。
- en: 'This method is roughly equivalent to doing:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法大致相当于执行以下操作：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you don’t need to keep the `vocab, merges` values lying around, this method
    is more optimized than manually calling `read_file()` to initialize a [BPE](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.BPE)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不需要保留`vocab, merges`值，此方法比手动调用`read_file()`来初始化[BPE](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.BPE)更为优化。
- en: '#### `read_file`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `read_file`'
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`) — 指向 `vocab.json` 文件的路径'
- en: '`merges` (`str`) — The path to a `merges.txt` file'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges` (`str`) — 指向 `merges.txt` 文件的路径'
- en: Returns
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A `Tuple` with the vocab and the merges
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含词汇表和合并的`Tuple`
- en: The vocabulary and merges loaded into memory
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 加载到内存中的词汇表和合并
- en: Read a `vocab.json` and a `merges.txt` files
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 读取一个`vocab.json`和一个`merges.txt`文件
- en: This method provides a way to read and parse the content of these files, returning
    the relevant data structures. If you want to instantiate some BPE models from
    memory, this method gives you the expected input from the standard files.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法提供了一种读取和解析这些文件内容的方式，返回相关的数据结构。如果要从内存实例化一些BPE模型，此方法会为您提供标准文件的预期输入。
- en: Model
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: '### `class tokenizers.models.Model`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.models.Model`'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Base class for all models
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所有模型的基类
- en: The model represents the actual tokenization algorithm. This is the part that
    will contain and manage the learned vocabulary.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型代表实际的标记化算法。这部分将包含和管理学习到的词汇表。
- en: This class cannot be constructed directly. Please use one of the concrete models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接构造。请使用其中一个具体模型。
- en: '#### `get_trainer`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_trainer`'
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Trainer`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`Trainer`'
- en: The Trainer used to train this model
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练此模型的Trainer
- en: Get the associated `Trainer`
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 获取相关的`Trainer`
- en: Retrieve the `Trainer` associated to this [Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 检索与此[Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model)相关联的`Trainer`。
- en: '#### `id_to_token`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `id_to_token`'
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`id` (`int`) — An ID to convert to a token'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` (`int`) — 要转换为标记的ID'
- en: Returns
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The token associated to the ID
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与ID相关联的标记
- en: Get the token associated to an ID
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 获取与ID相关联的标记
- en: '#### `save`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save`'
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`folder` (`str`) — The path to the target folder in which to save the various
    files'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`folder` (`str`) — 要保存各种文件的目标文件夹的路径'
- en: '`prefix` (`str`, *optional*) — An optional prefix, used to prefix each file
    name'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefix` (`str`, *可选*) — 一个可选的前缀，用于给每个文件名加前缀'
- en: Returns
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: The list of saved files
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 保存文件的列表
- en: Save the current model
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 保存当前模型
- en: Save the current model in the given folder, using the given prefix for the various
    files that will get created. Any file with the same name that already exists in
    this folder will be overwritten.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定文件夹中保存当前模型，使用给定的前缀创建各种文件。如果该文件夹中已经存在同名文件，将被覆盖。
- en: '#### `token_to_id`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `token_to_id`'
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token` (`str`) — A token to convert to an ID'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`) — 要转换为ID的标记'
- en: Returns
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The ID associated to the token
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 与标记相关联的ID
- en: Get the ID associated to a token
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 获取与标记相关联的ID
- en: '#### `tokenize`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tokenize`'
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequence` (`str`) — A sequence to tokenize'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequence` (`str`) — 要标记化的序列'
- en: Returns
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A `List` of `Token`
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`Token`的`List`
- en: The generated tokens
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的标记
- en: Tokenize a sequence
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对序列进行标记化
- en: Unigram
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Unigram
- en: '### `class tokenizers.models.Unigram`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.models.Unigram`'
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`List[Tuple[str, float]]`, *optional*, *optional*) — A list of vocabulary
    items and their relative score [(“am”, -0.2442),…]'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`List[Tuple[str, float]]`, *可选*, *可选*) — 一个词汇项和其相对分数的列表 [(“am”, -0.2442),…]'
- en: An implementation of the Unigram algorithm
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Unigram算法的实现
- en: WordLevel
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WordLevel
- en: '### `class tokenizers.models.WordLevel`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.models.WordLevel`'
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`, *optional*) — A dictionnary of string keys and their ids `{"am":
    0,...}`'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`, *optional*) — 一个字符串键和它们的 id 的字典 `{"am": 0,...}`'
- en: '`unk_token` (`str`, *optional*) — The unknown token to be used by the model.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*) — 模型使用的未知标记。'
- en: An implementation of the WordLevel algorithm
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: WordLevel 算法的实现
- en: Most simple tokenizer model based on mapping tokens to their corresponding id.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 基于将标记映射到相应 id 的最简单的分词器模型。
- en: '#### `from_file`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_file`'
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`) — 指向 `vocab.json` 文件的路径'
- en: Returns
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[WordLevel](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordLevel)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[WordLevel](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordLevel)'
- en: An instance of WordLevel loaded from file
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件加载的 WordLevel 实例
- en: Instantiate a WordLevel model from the given file
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定文件实例化一个 WordLevel 模型
- en: 'This method is roughly equivalent to doing:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法大致相当于：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If you don’t need to keep the `vocab` values lying around, this method is more
    optimized than manually calling `read_file()` to initialize a [WordLevel](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordLevel)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不需要保留 `vocab` 值，这种方法比手动调用 `read_file()` 来初始化一个 [WordLevel](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordLevel)
    更为优化。
- en: '#### `read_file`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `read_file`'
- en: '[PRE14]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`) — The path to a `vocab.json` file'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`) — 指向 `vocab.json` 文件的路径'
- en: Returns
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, int]`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, int]`'
- en: The vocabulary as a `dict`
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 `dict` 的词汇表
- en: Read a `vocab.json`
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 读取一个 `vocab.json`
- en: This method provides a way to read and parse the content of a vocabulary file,
    returning the relevant data structures. If you want to instantiate some WordLevel
    models from memory, this method gives you the expected input from the standard
    files.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法提供了一种读取和解析词汇文件内容的方式，返回相关的数据结构。如果您想要从内存中实例化一些 WordLevel 模型，这种方法会给您标准文件的预期输入。
- en: WordPiece
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WordPiece
- en: '### `class tokenizers.models.WordPiece`'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.models.WordPiece`'
- en: '[PRE15]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`Dict[str, int]`, *optional*) — A dictionnary of string keys and their
    ids `{"am": 0,...}`'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`Dict[str, int]`, *optional*) — 一个字符串键和它们的 id 的字典 `{"am": 0,...}`'
- en: '`unk_token` (`str`, *optional*) — The unknown token to be used by the model.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*) — 模型使用的未知标记。'
- en: '`max_input_chars_per_word` (`int`, *optional*) — The maximum number of characters
    to authorize in a single word.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_input_chars_per_word` (`int`, *optional*) — 单词中允许的最大字符数。'
- en: An implementation of the WordPiece algorithm
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: WordPiece 算法的实现
- en: '#### `from_file`'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_file`'
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`) — The path to a `vocab.txt` file'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`) — 指向 `vocab.txt` 文件的路径'
- en: Returns
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[WordPiece](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordPiece)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[WordPiece](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordPiece)'
- en: An instance of WordPiece loaded from file
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件加载的 WordPiece 实例
- en: Instantiate a WordPiece model from the given file
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定文件实例化一个 WordPiece 模型
- en: 'This method is roughly equivalent to doing:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法大致相当于：
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If you don’t need to keep the `vocab` values lying around, this method is more
    optimized than manually calling `read_file()` to initialize a [WordPiece](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordPiece)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不需要保留 `vocab` 值，这种方法比手动调用 `read_file()` 来初始化一个 [WordPiece](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.WordPiece)
    更为优化。
- en: '#### `read_file`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `read_file`'
- en: '[PRE18]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab` (`str`) — The path to a `vocab.txt` file'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab` (`str`) — 指向 `vocab.txt` 文件的路径'
- en: Returns
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, int]`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, int]`'
- en: The vocabulary as a `dict`
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 `dict` 的词汇表
- en: Read a `vocab.txt` file
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 读取一个 `vocab.txt` 文件
- en: This method provides a way to read and parse the content of a standard *vocab.txt*
    file as used by the WordPiece Model, returning the relevant data structures. If
    you want to instantiate some WordPiece models from memory, this method gives you
    the expected input from the standard files.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法提供了一种读取和解析标准 *vocab.txt* 文件内容的方式，该文件由 WordPiece 模型使用，返回相关的数据结构。如果您想要从内存中实例化一些
    WordPiece 模型，这种方法会给您标准文件的预期输入。
