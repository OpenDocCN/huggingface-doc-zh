- en: KOSMOS-2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KOSMOS-2
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/kosmos-2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/kosmos-2)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/kosmos-2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/kosmos-2)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The KOSMOS-2 model was proposed in [Kosmos-2: Grounding Multimodal Large Language
    Models to the World](https://arxiv.org/abs/2306.14824) by Zhiliang Peng, Wenhui
    Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, Furu Wei.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'KOSMOS-2模型是由Zhiliang Peng、Wenhui Wang、Li Dong、Yaru Hao、Shaohan Huang、Shuming
    Ma、Furu Wei在[Kosmos-2: Grounding Multimodal Large Language Models to the World](https://arxiv.org/abs/2306.14824)中提出的。'
- en: KOSMOS-2 is a Transformer-based causal language model and is trained using the
    next-word prediction task on a web-scale dataset of grounded image-text pairs
    [GRIT](https://huggingface.co/datasets/zzliang/GRIT). The spatial coordinates
    of the bounding boxes in the dataset are converted to a sequence of location tokens,
    which are appended to their respective entity text spans (for example, `a snowman`
    followed by `<patch_index_0044><patch_index_0863>`). The data format is similar
    to “hyperlinks” that connect the object regions in an image to their text span
    in the corresponding caption.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: KOSMOS-2是基于Transformer的因果语言模型，通过在基于网络规模的图像文本对数据集[GRIT](https://huggingface.co/datasets/zzliang/GRIT)上进行下一个单词预测任务进行训练。数据集中边界框的空间坐标被转换为位置标记序列，这些标记被附加到它们各自的实体文本跨度上（例如，`a
    snowman`后跟`<patch_index_0044><patch_index_0863>`）。数据格式类似于将图像中的对象区域与相应标题中的文本跨度连接起来的“超链接”。
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling
    new capabilities of perceiving object descriptions (e.g., bounding boxes) and
    grounding text to the visual world. Specifically, we represent refer expressions
    as links in Markdown, i.e., “[text span](bounding boxes)”, where object descriptions
    are sequences of location tokens. Together with multimodal corpora, we construct
    large-scale data of grounded image-text pairs (called GrIT) to train the model.
    In addition to the existing capabilities of MLLMs (e.g., perceiving general modalities,
    following instructions, and performing in-context learning), Kosmos-2 integrates
    the grounding capability into downstream applications. We evaluate Kosmos-2 on
    a wide range of tasks, including (i) multimodal grounding, such as referring expression
    comprehension, and phrase grounding, (ii) multimodal referring, such as referring
    expression generation, (iii) perception-language tasks, and (iv) language understanding
    and generation. This work lays out the foundation for the development of Embodiment
    AI and sheds light on the big convergence of language, multimodal perception,
    action, and world modeling, which is a key step toward artificial general intelligence.
    Code and pretrained models are available at [https://aka.ms/kosmos-2](https://aka.ms/kosmos-2).*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们介绍了Kosmos-2，一个多模态大型语言模型（MLLM），使其能够感知对象描述（例如，边界框）并将文本与视觉世界联系起来。具体来说，我们将引用表达式表示为Markdown中的链接，即“[文本跨度](边界框)”，其中对象描述是位置标记序列。与多模态语料库一起，我们构建了大规模的基于图像文本对的数据（称为GrIT）来训练模型。除了MLLM的现有功能（例如，感知一般模态，遵循指令以及执行上下文学习）之外，Kosmos-2还将接地能力整合到下游应用中。我们在广泛的任务上评估了Kosmos-2，包括（i）多模态接地，例如引用表达理解和短语接地，（ii）多模态引用，例如引用表达生成，（iii）感知语言任务，以及（iv）语言理解和生成。这项工作为实体AI的发展奠定了基础，并为语言、多模态感知、行动和世界建模的大融合提供了启示，这是通往人工通用智能的关键一步。代码和预训练模型可在[https://aka.ms/kosmos-2](https://aka.ms/kosmos-2)上获得。*'
- en: '![drawing](../Images/3603c868c64eefee06e6ec0e9aa1dd1d.png) Overview of tasks
    that KOSMOS-2 can handle. Taken from the [original paper](https://arxiv.org/abs/2306.14824).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/3603c868c64eefee06e6ec0e9aa1dd1d.png) KOSMOS-2可以处理的任务概述。摘自[原始论文](https://arxiv.org/abs/2306.14824)。'
- en: Example
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This model was contributed by [Yih-Dar SHIEH](https://huggingface.co/ydshieh).
    The original code can be found [here](https://github.com/microsoft/unilm/tree/master/kosmos-2).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是由[Yih-Dar SHIEH](https://huggingface.co/ydshieh)贡献的。原始代码可以在[这里找到](https://github.com/microsoft/unilm/tree/master/kosmos-2)。
- en: Kosmos2Config
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kosmos2Config
- en: '### `class transformers.Kosmos2Config`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Kosmos2Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/configuration_kosmos2.py#L244)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/configuration_kosmos2.py#L244)'
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize `Kosmos2TextConfig`.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_config` (`dict`, *optional*) — 用于初始化`Kosmos2TextConfig`的配置选项字典。'
- en: '`vision_config` (`dict`, *optional*) — Dictionary of configuration options
    used to initialize `Kosmos2VisionConfig`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_config` (`dict`, *optional*) — 用于初始化`Kosmos2VisionConfig`的配置选项字典。'
- en: '`latent_query_num` (`int`, *optional*, defaults to 64) — The number of latent
    query tokens that represent the image features used in the text decoder component.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_query_num` (`int`, *optional*, 默认为64) — 代表文本解码器组件中使用的图像特征的潜在查询标记数量。'
- en: '`kwargs` (*optional*) — Dictionary of keyword arguments.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (*optional*) — 关键字参数字典。'
- en: This is the configuration class to store the configuration of a [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model).
    It is used to instantiate a KOSMOS-2 model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the KOSMOS-2 [microsoft/kosmos-2-patch14-224](https://huggingface.co/microsoft/kosmos-2-patch14-224)
    architecture.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)的配置。根据指定的参数实例化KOSMOS-2模型，定义模型架构。使用默认值实例化配置将产生类似于KOSMOS-2
    [microsoft/kosmos-2-patch14-224](https://huggingface.co/microsoft/kosmos-2-patch14-224)
    架构的配置。
- en: 'Example:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Kosmos2ImageProcessor
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kosmos2ImageProcessor
- en: Kosmos2Processor
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kosmos2Processor
- en: '### `class transformers.Kosmos2Processor`'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Kosmos2Processor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/processing_kosmos2.py#L38)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/processing_kosmos2.py#L38)'
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` (`CLIPImageProcessor`) — An instance of [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor).
    The image processor is a required input.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` (`CLIPImageProcessor`) — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)的一个实例。图像处理器是必需的输入。'
- en: '`tokenizer` (`XLMRobertaTokenizerFast`) — An instance of [‘XLMRobertaTokenizerFast`].
    The tokenizer is a required input.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`XLMRobertaTokenizerFast`) — [‘XLMRobertaTokenizerFast`]的一个实例。分词器是必需的输入。'
- en: '`num_patch_index_tokens` (`int`, *optional*, defaults to 1024) — The number
    of tokens that represent patch indices.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_patch_index_tokens` (`int`, *可选*, 默认为1024) — 代表补丁索引的标记数量。'
- en: Constructs an KOSMOS-2 processor which wraps a KOSMOS-2 image processor and
    a KOSMOS-2 tokenizer into a single processor.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个KOSMOS-2处理器，将KOSMOS-2图像处理器和KOSMOS-2分词器包装成一个单一处理器。
- en: '[Kosmos2Processor](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor)
    offers all the functionalities of [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    and some functionalities of [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast).
    See the docstring of [**call**()](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor.__call__)
    and `decode()` for more information.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kosmos2Processor](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor)提供了[CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)的所有功能，以及[XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)的一些功能。查看[**call**()](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor.__call__)和`decode()`的文档字符串以获取更多信息。'
- en: '#### `__call__`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/processing_kosmos2.py#L105)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/processing_kosmos2.py#L105)'
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`bboxes` (`Union[List[Tuple[int]], List[Tuple[float]], List[List[Tuple[int]]],
    List[List[Tuple[float]]]]`, *optional*) — The bounding bboxes associated to `texts`.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bboxes` (`Union[List[Tuple[int]], List[Tuple[float]], List[List[Tuple[int]]],
    List[List[Tuple[float]]]`, *可选*) — 与`texts`相关联的边界框。'
- en: '`num_image_tokens` (`int`, defaults to 64) — The number of (consecutive) places
    that are used to mark the placeholders to store image information. This should
    be the same as `latent_query_num` in the instance of `Kosmos2Config` you are using.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_image_tokens` (`int`, 默认为64`) — 用于标记存储图像信息的占位符的(连续)位置数量。这应该与您正在使用的`Kosmos2Config`实例中的`latent_query_num`相同。'
- en: '`first_image_token_id` (`int`, *optional*) — The token id that will be used
    for the first place of the subsequence that is reserved to store image information.
    If unset, will default to `self.tokenizer.unk_token_id + 1`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`first_image_token_id` (`int`, *可选*) — 用于保留存储图像信息的子序列的第一个位置的标记id。如果未设置，将默认为`self.tokenizer.unk_token_id
    + 1`。'
- en: '`add_eos_token` (`bool`, defaults to `False`) — Whether or not to include `EOS`
    token id in the encoding when `add_special_tokens=True`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_eos_token` (`bool`, 默认为`False`) — 当`add_special_tokens=True`时，是否包含`EOS`标记id在编码中。'
- en: This method uses [CLIPImageProcessor.**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    method to prepare image(s) for the model, and [XLMRobertaTokenizerFast.**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    to prepare text for the model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用[CLIPImageProcessor.**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)方法为模型准备图像，并使用[XLMRobertaTokenizerFast.**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)为模型准备文本。
- en: Please refer to the docstring of the above two methods for more information.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考上述两种方法的文档字符串以获取更多信息。
- en: The rest of this documentation shows the arguments specific to `Kosmos2Processor`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本文档的其余部分显示了特定于`Kosmos2Processor`的参数。
- en: Kosmos2Model
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kosmos2Model
- en: '### `class transformers.Kosmos2Model`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Kosmos2Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1735)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1735)'
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: KOSMOS-2 Model for generating text and image features. The model consists of
    a vision encoder and a language model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: KOSMOS-2模型用于生成文本和图像特征。该模型由一个视觉编码器和一个语言模型组成。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)的子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1761)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [CLIPImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。可以使用 [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    获取像素值。有关详细信息，请参阅 [CLIPImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。默认情况下会忽略填充。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 0 表示头部被掩盖。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1 表示头部未被掩盖，
- en: '`image_embeds_position_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to indicate the location in a sequence to insert the image
    features . Mask values selected in `[0, 1]`:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` — (`torch.FloatTensor` of shape `(batch_size, latent_query_num,
    hidden_size)`, *optional*): 在 `Kosmos2ImageToTextProjection` 输出的隐藏状态序列。'
- en: 1 for places where to put the image features,
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示放置图像特征的位置，
- en: 0 for places that are not for image features (i.e. for text tokens).
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。选择范围为 `[0, config.max_position_embeddings -
    1]`。'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值选在 `[0, 1]` 之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被掩盖的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被掩盖的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置 ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是输入 ID？](../glossary#input-ids)'
- en: 1 indicates the head is `not masked`,
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds_position_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于指示在序列中插入图像特征的位置的掩码。掩码值选在 `[0, 1]` 之间：'
- en: 0 indicates the head is `masked`.
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，长度为 `config.n_layers`，每个元组包含
    4 个形状为 `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)` 的张量）
    — 包含注意力块的预计算键和值隐藏状态。可用于加速解码。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1761)'
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_ids` (those that don’t have their past key value states given to
    this model) of shape `(batch_size, 1)` instead of all `decoder_input_ids` of shape
    `(batch_size, sequence_length)`. image_embeds — (`torch.FloatTensor` of shape
    `(batch_size, latent_query_num, hidden_size)`, *optional*): Sequence of hidden-states
    at the output of `Kosmos2ImageToTextProjection`.'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了 `past_key_values`，用户可以选择仅输入最后的 `decoder_input_ids`（即没有将其过去的键值状态提供给此模型的那些）的形状为
    `(batch_size, 1)`，而不是所有 `decoder_input_ids` 的形状为 `(batch_size, sequence_length)`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制权，以便将
    `input_ids` 索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块的选定头部失效的掩码。掩码值选在 `[0, 1]` 之间：'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 0 表示不适用于图像特征的位置（即文本标记）。
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为 `True`，将返回 `past_key_values` 键值状态，可用于加速解码（请参阅
    `past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量中的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量中的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*） — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.kosmos2.modeling_kosmos2.Kosmos2ModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.kosmos2.modeling_kosmos2.Kosmos2ModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.kosmos2.modeling_kosmos2.Kosmos2ModelOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.kosmos2.configuration_kosmos2.Kosmos2Config'>`)
    and inputs.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.kosmos2.modeling_kosmos2.Kosmos2ModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（`<class
    'transformers.models.kosmos2.configuration_kosmos2.Kosmos2Config'>`）和输入不同元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）
    — 模型最后一层的隐藏状态序列。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, latent_query_num,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of `Kosmos2ImageToTextProjection`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds`（形状为`(batch_size, latent_query_num, hidden_size)`的`torch.FloatTensor`，*可选*）
    — `Kosmos2ImageToTextProjection`输出处的隐藏状态序列。'
- en: '`projection_attentions` (`tuple(torch.FloatTensor)`, *optional*) — Tuple of
    `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
    sequence_length)`.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_attentions`（`tuple(torch.FloatTensor)`，*可选*） — 形状为`(batch_size,
    num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights given by `Kosmos2ImageToTextProjection`, after the attention
    softmax, used to compute the weighted average in the self-attention heads.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由`Kosmos2ImageToTextProjection`给出的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`vision_model_output(BaseModelOutputWithPooling,` *optional*) — The output
    of the `Kosmos2VisionModel`.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_model_output(BaseModelOutputWithPooling,` *可选*) — `Kosmos2VisionModel`的输出。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and optionally if `config.is_encoder_decoder=True`
    2 additional tensors of shape `(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量，如果`config.is_encoder_decoder=True`，还有2个形状为`(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and optionally if `config.is_encoder_decoder=True` in the cross-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块中的键和值，以及在交叉注意力块中，如果`config.is_encoder_decoder=True`，还可以使用）可用于加速顺序解码。
- en: The [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    forward method, overrides the `__call__` special method.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Kosmos2ForConditionalGeneration
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kosmos2ForConditionalGeneration
- en: '### `class transformers.Kosmos2ForConditionalGeneration`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Kosmos2ForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1866)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1866)'
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config))
    — 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: KOSMOS-2 Model for generating text and bounding boxes given an image. The model
    consists of a vision encoder and a language model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: KOSMOS-2模型用于生成文本和边界框，给定一张图片。该模型由视觉编码器和语言模型组成。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1901)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/kosmos2/modeling_kosmos2.py#L1901)'
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [CLIPImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。详细信息请参阅[CLIPImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。默认情况下将忽略填充。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 索引可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取。详细信息请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`image_embeds_position_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to indicate the location in a sequence to insert the image
    features . Mask values selected in `[0, 1]`:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds_position_mask` (`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 用于指示在序列中插入图像特征的位置的蒙版。蒙版值选择在`[0, 1]`之间：'
- en: 1 for places where to put the image features,
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示放置图像特征的位置，
- en: 0 for places that are not for image features (i.e. for text tokens).
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示不用于图像特征的位置（即文本标记）。
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*) —
    避免在填充标记索引上执行注意力的蒙版。蒙版值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被蒙版的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被蒙版的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力蒙版？](../glossary#attention-mask)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块的选定头部失效的蒙版。蒙版值选择在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被蒙版，
- en: 0 indicates the head is `masked`.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被蒙版。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，长度为`config.n_layers`，每个元组包含形状为`(batch_size,
    num_heads, sequence_length - 1, embed_size_per_head)`的4个张量） — 包含注意力块的预计算键和值隐藏状态。可用于加速解码。'
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_ids` (those that don’t have their past key value states given to
    this model) of shape `(batch_size, 1)` instead of all `decoder_input_ids` of shape
    `(batch_size, sequence_length)`. image_embeds — (`torch.FloatTensor` of shape
    `(batch_size, latent_query_num, hidden_size)`, *optional*): Sequence of hidden-states
    at the output of `Kosmos2ImageToTextProjection`.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后一个`decoder_input_ids`（这些没有将其过去的键值状态提供给该模型）的形状为`(batch_size,
    1)`，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_ids`。image_embeds —
    (`torch.FloatTensor`，形状为`(batch_size, latent_query_num, hidden_size)`，*可选*）：`Kosmos2ImageToTextProjection`输出的隐藏状态序列。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，可以直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为相关向量，这将很有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为`True`，将返回`past_key_values`键值状态，可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the left-to-right language modeling loss (next word prediction).
    Indices should be in `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring)
    Tokens with indices set to `-100` are ignored (masked), the loss is only computed
    for the tokens with labels in `[0, ..., config.vocab_size]`'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 用于计算从左到右的语言建模损失（下一个词预测）的标签。索引应在`[-100, 0, ..., config.vocab_size]`范围内（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`范围内的标记。'
- en: Returns
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.kosmos2.modeling_kosmos2.Kosmos2ForConditionalGenerationModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.kosmos2.modeling_kosmos2.Kosmos2ForConditionalGenerationModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.kosmos2.modeling_kosmos2.Kosmos2ForConditionalGenerationModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.kosmos2.configuration_kosmos2.Kosmos2Config'>`)
    and inputs.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.kosmos2.modeling_kosmos2.Kosmos2ForConditionalGenerationModelOutput`或一个`torch.FloatTensor`元组（如果传入`return_dict=False`或`config.return_dict=False`）包含根据配置（`<class
    'transformers.models.kosmos2.configuration_kosmos2.Kosmos2Config'>`）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss (for next-token prediction).'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    语言建模损失（用于下一个标记预测）。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头部的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传入`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传入`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, latent_query_num,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of `Kosmos2ImageToTextProjection`.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, latent_query_num,
    hidden_size)`, *optional*) — 在`Kosmos2ImageToTextProjection`输出的隐藏状态序列。'
- en: '`projection_attentions` (`tuple(torch.FloatTensor)`, *optional*) — Tuple of
    `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
    sequence_length)`.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`projection_attentions` (`tuple(torch.FloatTensor)`, *optional*) — 形状为`(batch_size,
    num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights given by `Kosmos2ImageToTextProjection`, after the attention
    softmax, used to compute the weighted average in the self-attention heads.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由`Kosmos2ImageToTextProjection`给出的注意力权重，在注意力softmax后，用于计算自注意力头中的加权平均值。
- en: '`vision_model_output(BaseModelOutputWithPooling,` *optional*) — The output
    of the `Kosmos2VisionModel`.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_model_output(BaseModelOutputWithPooling,` *可选*) - `Kosmos2VisionModel`的输出。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and optionally if `config.is_encoder_decoder=True`
    2 additional tensors of shape `(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，如果`config.is_encoder_decoder=True`还有2个形状为`(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and optionally if `config.is_encoder_decoder=True` in the cross-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块中的键和值，如果`config.is_encoder_decoder=True`还包括交叉注意力块中的键和值），可以用来加速顺序解码（参见`past_key_values`输入）。
- en: The [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会处理运行前后的处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
