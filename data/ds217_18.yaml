- en: Stream
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流
- en: 'Original text: [https://huggingface.co/docs/datasets/stream](https://huggingface.co/docs/datasets/stream)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/stream](https://huggingface.co/docs/datasets/stream)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Dataset streaming lets you work with a dataset without downloading it. The
    data is streamed as you iterate over the dataset. This is especially helpful when:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集流式传输使您可以在不下载数据集的情况下使用数据集。当您遍历数据集时，数据会随之流动。这在以下情况下特别有帮助：
- en: You don’t want to wait for an extremely large dataset to download.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不想等待极大的数据集下载。
- en: The dataset size exceeds the amount of available disk space on your computer.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集大小超过计算机上可用磁盘空间的量。
- en: You want to quickly explore just a few samples of a dataset.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您想快速探索数据集的一些样本。
- en: '![](../Images/3a852aa4a279bb2476adf697aa4b6865.png) ![](../Images/a71d3ad700730cf461b4f099cd4a8c4b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a852aa4a279bb2476adf697aa4b6865.png) ![](../Images/a71d3ad700730cf461b4f099cd4a8c4b.png)'
- en: 'For example, the English split of the [oscar-corpus/OSCAR-2201](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201)
    dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream
    a dataset by setting `streaming=True` in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    as shown below:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[oscar-corpus/OSCAR-2201](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201)
    数据集的英文部分为1.2TB，但您可以立即使用流式传输。通过在[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)中设置`streaming=True`来流式传输数据集，如下所示：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Dataset streaming also lets you work with a dataset made of local files without
    doing any conversion. In this case, the data is streamed from the local files
    as you iterate over the dataset. This is especially helpful when:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集流式传输还使您可以处理由本地文件组成的数据集，而无需进行任何转换。在这种情况下，当您遍历数据集时，数据将从本地文件流动。这在以下情况下特别有帮助：
- en: You don’t want to wait for an extremely large local dataset to be converted
    to Arrow.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不想等待极大的本地数据集转换为Arrow。
- en: The converted files size would exceed the amount of available disk space on
    your computer.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换后的文件大小将超过计算机上可用磁盘空间的量。
- en: You want to quickly explore just a few samples of a dataset.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您想快速探索数据集的一些样本。
- en: 'For example, you can stream a local dataset of hundreds of compressed JSONL
    files like [oscar-corpus/OSCAR-2201](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201)
    to use it instantly:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以通过流式传输本地包含数百个压缩的JSONL文件的数据集，如[oscar-corpus/OSCAR-2201](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201)：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Loading a dataset in streaming mode creates a new dataset type instance (instead
    of the classic [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object), known as an [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset).
    This special type of dataset has its own set of processing methods shown below.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以流式传输模式加载数据集会创建一个新的数据集类型实例（而不是经典的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象），称为[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)。这种特殊类型的数据集具有自己的一组处理方法，如下所示。
- en: An [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    is useful for iterative jobs like training a model. You shouldn’t use a [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    for jobs that require random access to examples because you have to iterate all
    over it using a for loop. Getting the last example in an iterable dataset would
    require you to iterate over all the previous examples. You can find more details
    in the [Dataset vs. IterableDataset guide](./about_mapstyle_vs_iterable).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    对于像训练模型这样的迭代作业非常有用。您不应该将[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)用于需要随机访问示例的作业，因为您必须使用for循环遍历整个数据集。获取可迭代数据集中的最后一个示例需要您遍历所有先前的示例。您可以在[数据集与IterableDataset指南](./about_mapstyle_vs_iterable)中找到更多详细信息。'
- en: Convert from a Dataset
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从数据集转换
- en: If you have an existing [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object, you can convert it to an [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    with the [to_iterable_dataset()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_iterable_dataset)
    function. This is actually faster than setting the `streaming=True` argument in
    [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    because the data is streamed from local files.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有现有的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象，可以使用[to_iterable_dataset()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_iterable_dataset)函数将其转换为[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)。这实际上比在[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)中设置`streaming=True`参数更快，因为数据是从本地文件流式传输的。
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The [to_iterable_dataset()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_iterable_dataset)
    function supports sharding when the [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    is instantiated. This is useful when working with big datasets, and you’d like
    to shuffle the dataset or to enable fast parallel loading with a PyTorch DataLoader.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[to_iterable_dataset()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_iterable_dataset)函数在实例化[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)时支持分片。当处理大型数据集并且希望对数据集进行洗牌或使用PyTorch
    DataLoader进行快速并行加载时，这将非常有用。'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Shuffle
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 洗牌
- en: Like a regular [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object, you can also shuffle a [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    with [IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与常规[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象一样，您也可以使用[IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)对[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)进行洗牌。
- en: The `buffer_size` argument controls the size of the buffer to randomly sample
    examples from. Let’s say your dataset has one million examples, and you set the
    `buffer_size` to ten thousand. [IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)
    will randomly select examples from the first ten thousand examples in the buffer.
    Selected examples in the buffer are replaced with new examples. By default, the
    buffer size is 1,000.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`buffer_size`参数控制从中随机抽样示例的缓冲区的大小。假设您的数据集有一百万个示例，并且您将`buffer_size`设置为一万。[IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)将从缓冲区中的前一万个示例中随机选择示例。缓冲区中的选定示例将被新示例替换。默认情况下，缓冲区大小为1,000。'
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)
    will also shuffle the order of the shards if the dataset is sharded into multiple
    files.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)还将对分片的顺序进行洗牌，如果数据集被分片到多个文件中。'
- en: Reshuffle
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新洗牌
- en: Sometimes you may want to reshuffle the dataset after each epoch. This will
    require you to set a different seed for each epoch. Use `IterableDataset.set_epoch()`
    in between epochs to tell the dataset what epoch you’re on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您可能希望在每个时期之后重新洗牌数据集。这将需要您为每个时期设置不同的种子。在时期之间使用`IterableDataset.set_epoch()`告诉数据集您在哪个时期。
- en: 'Your seed effectively becomes: `initial seed + current epoch`.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您的种子实际上变为：`初始种子 + 当前时期`。
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Split dataset
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分数据集
- en: 'You can split your dataset one of two ways:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下两种方式拆分数据集：
- en: '[IterableDataset.take()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.take)
    returns the first `n` examples in a dataset:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IterableDataset.take()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.take)返回数据集中的前`n`个示例：'
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[IterableDataset.skip()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.skip)
    omits the first `n` examples in a dataset and returns the remaining examples:'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IterableDataset.skip()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.skip)省略数据集中的前`n`个示例，并返回剩余的示例：'
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`take` and `skip` prevent future calls to `shuffle` because they lock in the
    order of the shards. You should `shuffle` your dataset before splitting it.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`take`和`skip`阻止对`shuffle`的未来调用，因为它们锁定了分片的顺序。在拆分数据集之前，应该对数据集进行`shuffle`。'
- en: Interleave
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交错
- en: '[interleave_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.interleave_datasets)
    can combine an [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    with other datasets. The combined dataset returns alternating examples from each
    of the original datasets.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[interleave_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.interleave_datasets)可以将[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)与其他数据集组合。组合数据集返回每个原始数据集的交替示例。'
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Define sampling probabilities from each of the original datasets for more control
    over how each of them are sampled and combined. Set the `probabilities` argument
    with your desired sampling probabilities:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个原始数据集定义采样概率，以更好地控制如何对它们进行采样和组合。使用您期望的采样概率设置`probabilities`参数：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Around 80% of the final dataset is made of the `en_dataset`, and 20% of the
    `fr_dataset`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最终数据集的约80%由`en_dataset`组成，20%由`fr_dataset`组成。
- en: You can also specify the `stopping_strategy`. The default strategy, `first_exhausted`,
    is a subsampling strategy, i.e the dataset construction is stopped as soon one
    of the dataset runs out of samples. You can specify `stopping_strategy=all_exhausted`
    to execute an oversampling strategy. In this case, the dataset construction is
    stopped as soon as every samples in every dataset has been added at least once.
    In practice, it means that if a dataset is exhausted, it will return to the beginning
    of this dataset until the stop criterion has been reached. Note that if no sampling
    probabilities are specified, the new dataset will have `max_length_datasets*nb_dataset
    samples`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以指定`stopping_strategy`。默认策略`first_exhausted`是一种子采样策略，即数据集构建在其中一个数据集耗尽样本时停止。您可以指定`stopping_strategy=all_exhausted`来执行一种过采样策略。在这种情况下，数据集构建将在每个数据集的每个样本至少添加一次后停止。实际上，这意味着如果一个数据集耗尽，它将返回到该数据集的开头，直到达到停止标准。请注意，如果未指定采样概率，则新数据集将具有`max_length_datasets*nb_dataset`个样本。
- en: Rename, remove, and cast
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重命名、删除和转换
- en: The following methods allow you to modify the columns of a dataset. These methods
    are useful for renaming or removing columns and changing columns to a new set
    of features.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方法允许您修改数据集的列。这些方法对于重命名或删除列以及将列更改为新的特征集非常有用。
- en: Rename
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重命名
- en: Use [IterableDataset.rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.rename_column)
    when you need to rename a column in your dataset. Features associated with the
    original column are actually moved under the new column name, instead of just
    replacing the original column in-place.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当您需要在数据集中重命名列时，请使用[IterableDataset.rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.rename_column)。与原始列相关的特征实际上是移动到新列名下，而不仅仅是替换原始列。
- en: 'Provide [IterableDataset.rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.rename_column)
    with the name of the original column, and the new column name:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[IterableDataset.rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.rename_column)提供原始列的名称和新列名：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Remove
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除
- en: 'When you need to remove one or more columns, give [IterableDataset.remove_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.remove_columns)
    the name of the column to remove. Remove more than one column by providing a list
    of column names:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当您需要删除一个或多个列时，请给[IterableDataset.remove_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.remove_columns)要删除的列的名称。通过提供列名称的列表来删除多个列：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Cast
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换
- en: '[IterableDataset.cast()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.cast)
    changes the feature type of one or more columns. This method takes your new `Features`
    as its argument. The following sample code shows how to change the feature types
    of `ClassLabel` and `Value`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[IterableDataset.cast()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.cast)更改一个或多个列的特征类型。此方法将您的新`Features`作为其参数。以下示例代码显示了如何更改`ClassLabel`和`Value`的特征类型：'
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Casting only works if the original feature type and new feature type are compatible.
    For example, you can cast a column with the feature type `Value('int32')` to `Value('bool')`
    if the original column only contains ones and zeros.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 仅当原始特征类型和新特征类型兼容时，转换才有效。例如，如果原始列仅包含1和0，则可以将具有特征类型`Value('int32')`的列转换为`Value('bool')`。
- en: 'Use [IterableDataset.cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.cast_column)
    to change the feature type of just one column. Pass the column name and its new
    feature type as arguments:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[IterableDataset.cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.cast_column)来更改一个列的特征类型。将列名和其新特征类型作为参数传递：
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Map
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 映射
- en: Similar to the [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function for a regular [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset),
    🤗 Datasets features [IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)
    for processing an [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset).
    [IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)
    applies processing on-the-fly when examples are streamed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于常规[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)的[Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数，🤗
    Datasets功能[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)用于处理[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)。当示例被流式传输时，[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)会实时应用处理。
- en: It allows you to apply a processing function to each example in a dataset, independently
    or in batches. This function can even create new rows and columns.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许您对数据集中的每个示例应用处理函数，独立或批处理。该函数甚至可以创建新的行和列。
- en: 'The following example demonstrates how to tokenize a [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset).
    The function needs to accept and output a `dict`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了如何对[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)进行标记化。该函数需要接受并输出一个`dict`：
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, apply this function to the dataset with [IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)将此函数应用于数据集：
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Let’s take a look at another example, except this time, you will remove a column
    with [IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map).
    When you remove a column, it is only removed after the example has been provided
    to the mapped function. This allows the mapped function to use the content of
    the columns before they are removed.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子，除了这次您将使用[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)删除一列。当删除列时，仅在将示例提供给映射函数后才会删除。这使得映射函数可以在删除之前使用列的内容。
- en: 'Specify the column to remove with the `remove_columns` argument in [IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)中的`remove_columns`参数指定要删除的列：
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Batch processing
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理
- en: '[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)
    also supports working with batches of examples. Operate on batches by setting
    `batched=True`. The default batch size is 1000, but you can adjust it with the
    `batch_size` argument. This opens the door to many interesting applications such
    as tokenization, splitting long sentences into shorter chunks, and data augmentation.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[IterableDataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.map)还支持对示例批次进行操作。通过设置`batched=True`来操作批次。默认批处理大小为1000，但您可以使用`batch_size`参数进行调整。这为许多有趣的应用打开了大门，例如标记化、将长句子拆分为较短的块以及数据增强。'
- en: Tokenization
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标记化
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: See other examples of batch processing in the [batched map processing](./process#batch-processing)
    documentation. They work the same for iterable datasets.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[批处理映射处理](./process#batch-processing)文档中的其他批处理示例。它们对可迭代数据集的工作方式相同。
- en: Filter
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过滤
- en: 'You can filter rows in the dataset based on a predicate function using [Dataset.filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter).
    It returns rows that match a specified condition:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用[Dataset.filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)基于谓词函数过滤数据集中的行。它返回符合指定条件的行：
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Dataset.filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    can also filter by indices if you set `with_indices=True`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dataset.filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)还可以通过设置`with_indices=True`按索引进行过滤：'
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Stream in a training loop
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在训练循环中流式传输
- en: '[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    can be integrated into a training loop. First, shuffle the dataset:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)可以集成到训练循环中。首先，对数据集进行洗牌：'
- en: PytorchHide Pytorch content
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch隐藏 Pytorch内容
- en: '[PRE20]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Lastly, create a simple training loop and start training:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个简单的训练循环并开始训练：
- en: '[PRE21]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
