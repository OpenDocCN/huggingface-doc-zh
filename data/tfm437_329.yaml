- en: XLS-R
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XLS-R
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xls_r](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xls_r)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xls_r](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xls_r)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The XLS-R model was proposed in [XLS-R: Self-supervised Cross-lingual Speech
    Representation Learning at Scale](https://arxiv.org/abs/2111.09296) by Arun Babu,
    Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika
    Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau,
    Michael Auli.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'XLS-R模型由Arun Babu、Changhan Wang、Andros Tjandra、Kushal Lakhotia、Qiantong Xu、Naman
    Goyal、Kritika Singh、Patrick von Platen、Yatharth Saraf、Juan Pino、Alexei Baevski、Alexis
    Conneau、Michael Auli在[XLS-R: Self-supervised Cross-lingual Speech Representation
    Learning at Scale](https://arxiv.org/abs/2111.09296)中提出。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的摘要如下：
- en: '*This paper presents XLS-R, a large-scale model for cross-lingual speech representation
    learning based on wav2vec 2.0. We train models with up to 2B parameters on nearly
    half a million hours of publicly available speech audio in 128 languages, an order
    of magnitude more public data than the largest known prior work. Our evaluation
    covers a wide range of tasks, domains, data regimes and languages, both high and
    low-resource. On the CoVoST-2 speech translation benchmark, we improve the previous
    state of the art by an average of 7.4 BLEU over 21 translation directions into
    English. For speech recognition, XLS-R improves over the best known prior work
    on BABEL, MLS, CommonVoice as well as VoxPopuli, lowering error rates by 14-34%
    relative on average. XLS-R also sets a new state of the art on VoxLingua107 language
    identification. Moreover, we show that with sufficient model size, cross-lingual
    pretraining can outperform English-only pretraining when translating English speech
    into other languages, a setting which favors monolingual pretraining. We hope
    XLS-R can help to improve speech processing tasks for many more languages of the
    world.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文介绍了XLS-R，这是一个基于wav2vec 2.0的大规模跨语言语音表示学习模型。我们在128种语言中使用多达20亿参数的模型进行训练，使用近50万小时的公开可用语音音频数据，比已知最大的先前工作的公共数据量大一个数量级。我们的评估涵盖了各种任务、领域、数据制度和语言，包括高资源和低资源语言。在CoVoST-2语音翻译基准测试中，我们将先前的最新技术平均提高了7.4
    BLEU，涵盖了21个翻译方向到英语。对于语音识别，XLS-R在BABEL、MLS、CommonVoice以及VoxPopuli等最佳已知先前工作上的错误率平均降低了14-34%。XLS-R还在VoxLingua107语言识别上树立了新的技术水平。此外，我们展示了在足够大的模型尺寸下，跨语言预训练可以在将英语语音翻译成其他语言时胜过仅英语预训练，这种情况有利于单语预训练。我们希望XLS-R可以帮助改进世界上更多语言的语音处理任务。*'
- en: Relevant checkpoints can be found under [https://huggingface.co/models?other=xls_r](https://huggingface.co/models?other=xls_r).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的检查点可以在[https://huggingface.co/models?other=xls_r](https://huggingface.co/models?other=xls_r)下找到。
- en: The original code can be found [here](https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码可以在[这里](https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: XLS-R is a speech model that accepts a float array corresponding to the raw
    waveform of the speech signal.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XLS-R是一个语音模型，接受与语音信号的原始波形对应的浮点数组。
- en: XLS-R model was trained using connectionist temporal classification (CTC) so
    the model output has to be decoded using [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XLS-R模型是使用连接主义时间分类（CTC）进行训练的，因此模型输出必须使用[Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)进行解码。
- en: XLS-R’s architecture is based on the Wav2Vec2 model, refer to [Wav2Vec2’s documentation
    page](wav2vec2) for API reference.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: XLS-R的架构基于Wav2Vec2模型，请参考[Wav2Vec2的文档页面](wav2vec2)获取API参考。
