- en: Text Generation Inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本生成推理
- en: 'Original text: [https://huggingface.co/docs/text-generation-inference/index](https://huggingface.co/docs/text-generation-inference/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/text-generation-inference/index](https://huggingface.co/docs/text-generation-inference/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Text Generation Inference (TGI) is a toolkit for deploying and serving Large
    Language Models (LLMs). TGI enables high-performance text generation for the most
    popular open-source LLMs, including Llama, Falcon, StarCoder, BLOOM, GPT-NeoX,
    and T5.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成推理（TGI）是一个用于部署和提供大型语言模型（LLMs）的工具包。TGI实现了最流行的开源LLMs，包括Llama、Falcon、StarCoder、BLOOM、GPT-NeoX和T5的高性能文本生成。
- en: '![Text Generation Inference](../Images/d35ba6d3307e9474f5d05c1c873c7b52.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![文本生成推理](../Images/d35ba6d3307e9474f5d05c1c873c7b52.png)'
- en: 'Text Generation Inference implements many optimizations and features, such
    as:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成推理实现了许多优化和功能，例如：
- en: Simple launcher to serve most popular LLMs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的启动器来提供最流行的LLMs
- en: Production ready (distributed tracing with Open Telemetry, Prometheus metrics)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产就绪（使用Open Telemetry进行分布式跟踪，Prometheus指标）
- en: Tensor Parallelism for faster inference on multiple GPUs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张量并行性，用于在多个GPU上进行更快的推理
- en: Token streaming using Server-Sent Events (SSE)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用服务器发送事件（SSE）进行令牌流
- en: Continuous batching of incoming requests for increased total throughput
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续批处理传入请求，以增加总吞吐量
- en: Optimized transformers code for inference using [Flash Attention](https://github.com/HazyResearch/flash-attention)
    and [Paged Attention](https://github.com/vllm-project/vllm) on the most popular
    architectures
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化的变压器代码，使用[Flash Attention](https://github.com/HazyResearch/flash-attention)和[Paged
    Attention](https://github.com/vllm-project/vllm)在最流行的架构上进行推理
- en: Quantization with [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
    and [GPT-Q](https://arxiv.org/abs/2210.17323)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[bitsandbytes](https://github.com/TimDettmers/bitsandbytes)和[GPT-Q](https://arxiv.org/abs/2210.17323)进行量化
- en: '[Safetensors](https://github.com/huggingface/safetensors) weight loading'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Safetensors](https://github.com/huggingface/safetensors)权重加载'
- en: Watermarking with [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)进行水印处理
- en: Logits warper (temperature scaling, top-p, top-k, repetition penalty)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数变形器（温度缩放，前p，前k，重复惩罚）
- en: Stop sequences
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止序列
- en: Log probabilities
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数概率
- en: 'Custom Prompt Generation: Easily generate text by providing custom prompts
    to guide the model’s output.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义提示生成：通过提供自定义提示来引导模型的输出，轻松生成文本。
- en: 'Fine-tuning Support: Utilize fine-tuned models for specific tasks to achieve
    higher accuracy and performance.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调支持：利用微调模型来实现更高的准确性和性能。
- en: 'Text Generation Inference is used in production by multiple projects, such
    as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成推理已被多个项目用于生产，例如：
- en: '[Hugging Chat](https://github.com/huggingface/chat-ui), an open-source interface
    for open-access models, such as Open Assistant and Llama'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hugging Chat](https://github.com/huggingface/chat-ui)，一个用于开放访问模型的开源界面，如Open
    Assistant和Llama'
- en: '[OpenAssistant](https://open-assistant.io/), an open-source community effort
    to train LLMs in the open'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAssistant](https://open-assistant.io/)，一个开源社区努力，用于在开放环境中训练LLMs'
- en: '[nat.dev](http://nat.dev/), a playground to explore and compare LLMs.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[nat.dev](http://nat.dev/)，一个用于探索和比较LLMs的游乐场。'
