- en: LoKr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LoKr
- en: 'Original text: [https://huggingface.co/docs/peft/package_reference/lokr](https://huggingface.co/docs/peft/package_reference/lokr)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '原始文本: [https://huggingface.co/docs/peft/package_reference/lokr](https://huggingface.co/docs/peft/package_reference/lokr)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Low-Rank Kronecker Product ([LoKr](https://hf.co/papers/2309.14859)), is a LoRA-variant
    method that approximates the large weight matrix with two low-rank matrices and
    combines them with the Kronecker product. LoKr also provides an optional third
    low-rank matrix to provide better control during fine-tuning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩 Kronecker 乘积（[LoKr](https://hf.co/papers/2309.14859)）是一种 LoRA 变体方法，它用两个低秩矩阵近似大权重矩阵，并将它们与
    Kronecker 乘积结合。LoKr 还提供一个可选的第三个低秩矩阵，以在微调期间提供更好的控制。
- en: LoKrConfig
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LoKrConfig
- en: '### `class peft.LoKrConfig`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.LoKrConfig`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/lokr/config.py#L22)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/lokr/config.py#L22)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`r` (`int`) — LoKr rank.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`r` (`int`) — LoKr 等级。'
- en: '`alpha` (`int`) — The alpha parameter for LoKr scaling.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha` (`int`) — LoKr 缩放的 alpha 参数。'
- en: '`rank_dropout` (`float`) — The dropout probability for rank dimension during
    training.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rank_dropout` (`float`) — 训练期间等级维度的丢失概率。'
- en: '`module_dropout` (`float`) — The dropout probability for disabling LoKr modules
    during training.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`module_dropout` (`float`) — 训练期间禁用 LoKr 模块的丢失概率。'
- en: '`use_effective_conv2d` (`bool`) — Use parameter effective decomposition for
    Conv2d with ksize > 1 (“Proposition 3” from FedPara paper).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_effective_conv2d` (`bool`) — 对于 ksize > 1 的 Conv2d 使用参数有效分解（来自 FedPara
    论文的“命题 3”）。'
- en: '`decompose_both` (`bool`) — Perform rank decomposition of left kronecker product
    matrix.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decompose_both` (`bool`) — 对左 Kronecker 乘积矩阵执行等级分解。'
- en: '`decompose_factor` (`int`) — Kronecker product decomposition factor.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decompose_factor` (`int`) — Kronecker 乘积分解因子。'
- en: '`target_modules` (`Optional[Union[List[str], str]]`) — The names of the modules
    to apply the adapter to. If this is specified, only the modules with the specified
    names will be replaced. When passing a string, a regex match will be performed.
    When passing a list of strings, either an exact match will be performed or it
    is checked if the name of the module ends with any of the passed strings. If this
    is specified as ‘all-linear’, then all linear/Conv1D modules are chosen, excluding
    the output layer. If this is not specified, modules will be chosen according to
    the model architecture. If the architecture is not known, an error will be raised
    — in this case, you should specify the target modules manually.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_modules` (`Optional[Union[List[str], str]]`) — 要应用适配器的模块的名称。如果指定了此项，只有指定名称的模块将被替换。当传递一个字符串时，将执行正则表达式匹配。当传递一个字符串列表时，将执行精确匹配或检查模块名称是否以任何传递的字符串结尾。如果指定为
    ‘all-linear’，则选择所有线性/Conv1D 模块，不包括输出层。如果未指定，将根据模型架构选择模块。如果不知道架构，将引发错误 — 在这种情况下，应手动指定目标模块。'
- en: '`init_weights` (`bool`) — Whether to perform initialization of adapter weights.
    This defaults to `True`, passing `False` is discouraged.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_weights` (`bool`) — 是否执行适配器权重的初始化。默认为 `True`，不建议传递 `False`。'
- en: '`layers_to_transform` (`Union[List[int], int]`) — The layer indices to transform.
    If a list of ints is passed, it will apply the adapter to the layer indices that
    are specified in this list. If a single integer is passed, it will apply the transformations
    on the layer at this index.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layers_to_transform` (`Union[List[int], int]`) — 要转换的层索引。如果传递了一个整数列表，它将应用于在此列表中指定的层索引的适配器。如果传递了一个单个整数，它将在此索引处的层上应用变换。'
- en: '`layers_pattern` (`str`) — The layer pattern name, used only if `layers_to_transform`
    is different from `None`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layers_pattern` (`str`) — 层模式名称，仅在 `layers_to_transform` 与 `None` 不同的情况下使用。'
- en: '`rank_pattern` (`dict`) — The mapping from layer names or regexp expression
    to ranks which are different from the default rank specified by `r`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rank_pattern` (`dict`) — 从层名称或正则表达式到与 `r` 指定的默认等级不同的等级的映射。'
- en: '`alpha_pattern` (`dict`) — The mapping from layer names or regexp expression
    to alphas which are different from the default alpha specified by `alpha`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha_pattern` (`dict`) — 从层名称或正则表达式到与 `alpha` 指定的默认 alpha 不同的 alpha 的映射。'
- en: '`modules_to_save` (`Optional[List[str]]`) — List of modules apart from adapter
    layers to be set as trainable and saved in the final checkpoint.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modules_to_save` (`Optional[List[str]]`) — 除了适配器层之外要设置为可训练并保存在最终检查点中的模块列表。'
- en: Configuration class of [LoKrModel](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrModel).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[LoKrModel](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrModel) 的配置类。'
- en: LoKrModel
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LoKrModel
- en: '### `class peft.LoKrModel`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.LoKrModel`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/lokr/model.py#L27)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/lokr/model.py#L27)'
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to which the adapter tuner layers will
    be attached.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 适配器调谐器层将附加到的模型。'
- en: '`config` ([LoKrConfig](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrConfig))
    — The configuration of the LoKr model.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LoKrConfig](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrConfig))
    — LoKr 模型的配置。'
- en: '`adapter_name` (`str`) — The name of the adapter, defaults to `"default"`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`) — 适配器的名称，默认为 `"default"`。'
- en: Returns
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.nn.Module`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.nn.Module`'
- en: The LoKr model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LoKr 模型。
- en: Creates Low-Rank Kronecker Product model from a pretrained model. The original
    method is partially described in [https://arxiv.org/abs/2108.06098](https://arxiv.org/abs/2108.06098)
    and in [https://arxiv.org/abs/2309.14859](https://arxiv.org/abs/2309.14859) Current
    implementation heavily borrows from [https://github.com/KohakuBlueleaf/LyCORIS/blob/eb460098187f752a5d66406d3affade6f0a07ece/lycoris/modules/lokr.py](https://github.com/KohakuBlueleaf/LyCORIS/blob/eb460098187f752a5d66406d3affade6f0a07ece/lycoris/modules/lokr.py)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型创建低秩 Kronecker 乘积模型。原始方法部分描述在 [https://arxiv.org/abs/2108.06098](https://arxiv.org/abs/2108.06098)
    和 [https://arxiv.org/abs/2309.14859](https://arxiv.org/abs/2309.14859) 当前实现大量借鉴自
    [https://github.com/KohakuBlueleaf/LyCORIS/blob/eb460098187f752a5d66406d3affade6f0a07ece/lycoris/modules/lokr.py](https://github.com/KohakuBlueleaf/LyCORIS/blob/eb460098187f752a5d66406d3affade6f0a07ece/lycoris/modules/lokr.py)
- en: 'Example:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Attributes**:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**:'
- en: '`model` (`~torch.nn.Module`) — The model to be adapted.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`~torch.nn.Module`) — 要适应的模型。'
- en: '`peft_config` ([LoKrConfig](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrConfig)):
    The configuration of the LoKr model.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([LoKrConfig](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrConfig)):
    LoKr模型的配置。'
