- en: Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit7/introduction](https://huggingface.co/learn/deep-rl-course/unit7/introduction)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/learn/deep-rl-course/unit7/introduction](https://huggingface.co/learn/deep-rl-course/unit7/introduction)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![Thumbnail](../Images/191cf822590d58b820b7b1a8cc193fb2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图](../Images/191cf822590d58b820b7b1a8cc193fb2.png)'
- en: 'Since the beginning of this course, we learned to train agents in a *single-agent
    system* where our agent was alone in its environment: it was **not cooperating
    or collaborating with other agents**.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 自课程开始以来，我们学习了如何在*单代理系统*中训练代理程序，其中我们的代理程序独自在其环境中：它**不与其他代理程序合作或协作**。
- en: This worked great, and the single-agent system is useful for many applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法非常有效，单代理系统对许多应用程序都有用。
- en: '![Patchwork](../Images/0bfa9643ea17c46664be61fcfb3e7a48.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![拼贴](../Images/0bfa9643ea17c46664be61fcfb3e7a48.png)'
- en: A patchwork of all the environments you’ve trained your agents on since the
    beginning of the course
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自课程开始以来，您已经训练了代理程序的所有环境的拼贴
- en: But, as humans, **we live in a multi-agent world**. Our intelligence comes from
    interaction with other agents. And so, our **goal is to create agents that can
    interact with other humans and other agents**.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，作为人类，**我们生活在一个多代理世界中**。我们的智能来自与其他代理的互动。因此，我们的**目标是创建可以与其他人类和其他代理互动的代理程序**。
- en: Consequently, we must study how to train deep reinforcement learning agents
    in a *multi-agents system* to build robust agents that can adapt, collaborate,
    or compete.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们必须研究如何在*多代理系统*中训练深度强化学习代理程序，以构建能够适应、合作或竞争的强大代理程序。
- en: So today we’re going to **learn the basics of the fascinating topic of multi-agents
    reinforcement learning (MARL)**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，今天我们将**学习多代理强化学习（MARL）这一迷人主题的基础知识**。
- en: 'And the most exciting part is that, during this unit, you’re going to train
    your first agents in a multi-agents system: **a 2vs2 soccer team that needs to
    beat the opponent team**.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最令人兴奋的部分是，在这个单元中，您将在一个多代理系统中训练您的第一个代理程序：**一个2对2的足球队，需要击败对手队**。
- en: And you’re going to participate in **AI vs. AI challenge** where your trained
    agent will compete against other classmates’ agents every day and be ranked on
    a [new leaderboard](https://huggingface.co/spaces/huggingface-projects/AIvsAI-SoccerTwos).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您将参加**AI对AI挑战**，在这个挑战中，您训练的代理程序将每天与其他同学的代理程序竞争，并在[新排行榜](https://huggingface.co/spaces/huggingface-projects/AIvsAI-SoccerTwos)上排名。
- en: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
- en: This environment was made by the [Unity MLAgents Team](https://github.com/Unity-Technologies/ml-agents)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个环境是由[Unity MLAgents团队](https://github.com/Unity-Technologies/ml-agents)制作的
- en: So let’s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们开始吧！
