- en: Deploy models to Amazon SageMaker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹éƒ¨ç½²åˆ°Amazon SageMaker
- en: 'Original text: [https://huggingface.co/docs/sagemaker/inference](https://huggingface.co/docs/sagemaker/inference)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/sagemaker/inference](https://huggingface.co/docs/sagemaker/inference)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploying a ğŸ¤— Transformers models in SageMaker for inference is as easy as:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨SageMakerä¸­éƒ¨ç½²ğŸ¤— Transformersæ¨¡å‹è¿›è¡Œæ¨ç†å°±åƒè¿™æ ·ç®€å•ï¼š
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This guide will show you how to deploy models with zero-code using the [Inference
    Toolkit](https://github.com/aws/sagemaker-huggingface-inference-toolkit). The
    Inference Toolkit builds on top of the [`pipeline` feature](https://huggingface.co/docs/transformers/main_classes/pipelines)
    from ğŸ¤— Transformers. Learn how to:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨[æ¨ç†å·¥å…·åŒ…](https://github.com/aws/sagemaker-huggingface-inference-toolkit)é›¶ä»£ç éƒ¨ç½²æ¨¡å‹ã€‚æ¨ç†å·¥å…·åŒ…å»ºç«‹åœ¨ğŸ¤—
    Transformersçš„[`pipeline`åŠŸèƒ½](https://huggingface.co/docs/transformers/main_classes/pipelines)ä¹‹ä¸Šã€‚å­¦ä¹ å¦‚ä½•ï¼š
- en: '[Install and setup the Inference Toolkit](#installation-and-setup).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å®‰è£…å’Œè®¾ç½®æ¨ç†å·¥å…·åŒ…](#installation-and-setup)ã€‚'
- en: '[Deploy a ğŸ¤— Transformers model trained in SageMaker](#deploy-a-transformer-model-trained-in-sagemaker).'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åœ¨SageMakerä¸­éƒ¨ç½²ç»è¿‡è®­ç»ƒçš„ğŸ¤— Transformersæ¨¡å‹](#deploy-a-transformer-model-trained-in-sagemaker)ã€‚'
- en: '[Deploy a ğŸ¤— Transformers model from the Hugging Face [model Hub](https://huggingface.co/models)](#deploy-a-model-from-the-hub).'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä»Hugging Face [æ¨¡å‹Hub](https://huggingface.co/models)éƒ¨ç½²ğŸ¤— Transformersæ¨¡å‹](#deploy-a-model-from-the-hub)ã€‚'
- en: '[Run a Batch Transform Job using ğŸ¤— Transformers and Amazon SageMaker](#run-batch-transform-with-transformers-and-sagemaker).'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä½¿ç”¨ğŸ¤— Transformerså’ŒAmazon SageMakerè¿è¡Œæ‰¹é‡è½¬æ¢ä½œä¸š](#run-batch-transform-with-transformers-and-sagemaker)ã€‚'
- en: '[Create a custom inference module](#user-defined-code-and-modules).'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åˆ›å»ºè‡ªå®šä¹‰æ¨ç†æ¨¡å—](#user-defined-code-and-modules)ã€‚'
- en: Installation and setup
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®‰è£…å’Œè®¾ç½®
- en: Before deploying a ğŸ¤— Transformers model to SageMaker, you need to sign up for
    an AWS account. If you donâ€™t have an AWS account yet, learn more [here](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å°†ğŸ¤— Transformersæ¨¡å‹éƒ¨ç½²åˆ°SageMakerä¹‹å‰ï¼Œæ‚¨éœ€è¦æ³¨å†ŒAWSè´¦æˆ·ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰AWSè´¦æˆ·ï¼Œè¯·åœ¨[æ­¤å¤„](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html)äº†è§£æ›´å¤šã€‚
- en: 'Once you have an AWS account, get started using one of the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨æ‹¥æœ‰AWSè´¦æˆ·ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€å¼€å§‹ä½¿ç”¨ï¼š
- en: '[SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html)'
- en: '[SageMaker notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMakerç¬”è®°æœ¬å®ä¾‹](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)'
- en: Local environment
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ¬åœ°ç¯å¢ƒ
- en: To start training locally, you need to setup an appropriate [IAM role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¼€å§‹æœ¬åœ°è®­ç»ƒï¼Œæ‚¨éœ€è¦è®¾ç½®é€‚å½“çš„[IAMè§’è‰²](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)ã€‚
- en: Upgrade to the latest `sagemaker` version.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å‡çº§åˆ°æœ€æ–°çš„`sagemaker`ç‰ˆæœ¬ã€‚
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**SageMaker environment**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**SageMakerç¯å¢ƒ**'
- en: 'Setup your SageMaker environment as shown below:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰ç…§ä¸‹é¢æ‰€ç¤ºè®¾ç½®æ‚¨çš„SageMakerç¯å¢ƒï¼š
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Note: The execution role is only available when running a notebook within
    SageMaker. If you run `get_execution_role` in a notebook not on SageMaker, expect
    a `region` error.*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šæ‰§è¡Œè§’è‰²ä»…åœ¨SageMakerå†…è¿è¡Œç¬”è®°æœ¬æ—¶å¯ç”¨ã€‚å¦‚æœåœ¨ä¸åœ¨SageMakerä¸Šè¿è¡Œçš„ç¬”è®°æœ¬ä¸­è¿è¡Œ`get_execution_role`ï¼Œåˆ™ä¼šå‡ºç°`region`é”™è¯¯ã€‚*'
- en: '**Local environment**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ¬åœ°ç¯å¢ƒ**'
- en: 'Setup your local environment as shown below:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰ç…§ä¸‹é¢æ‰€ç¤ºè®¾ç½®æ‚¨çš„æœ¬åœ°ç¯å¢ƒï¼š
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Deploy a ğŸ¤— Transformers model trained in SageMaker
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨SageMakerä¸­éƒ¨ç½²ç»è¿‡è®­ç»ƒçš„ğŸ¤— Transformersæ¨¡å‹
- en: '[https://www.youtube.com/embed/pfBGgSGnYLs](https://www.youtube.com/embed/pfBGgSGnYLs)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/embed/pfBGgSGnYLs](https://www.youtube.com/embed/pfBGgSGnYLs)'
- en: 'There are two ways to deploy your Hugging Face model trained in SageMaker:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥éƒ¨ç½²åœ¨SageMakerä¸­è®­ç»ƒçš„Hugging Faceæ¨¡å‹ï¼š
- en: Deploy it after your training has finished.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒå®Œæˆåéƒ¨ç½²å®ƒã€‚
- en: Deploy your saved model at a later time from S3 with the `model_data`.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨åå¯ä»¥ä½¿ç”¨`model_data`ä»S3éƒ¨ç½²ä¿å­˜çš„æ¨¡å‹ã€‚
- en: ğŸ““ Open the [notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)
    for an example of how to deploy a model from S3 to SageMaker for inference.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ““æ‰“å¼€[ç¬”è®°æœ¬](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)æŸ¥çœ‹å¦‚ä½•å°†æ¨¡å‹ä»S3éƒ¨ç½²åˆ°SageMakerè¿›è¡Œæ¨ç†çš„ç¤ºä¾‹ã€‚
- en: Deploy after training
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è®­ç»ƒåéƒ¨ç½²
- en: To deploy your model directly after training, ensure all required files are
    saved in your training script, including the tokenizer and the model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒåç›´æ¥éƒ¨ç½²æ‚¨çš„æ¨¡å‹ï¼Œè¯·ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½ä¿å­˜åœ¨æ‚¨çš„è®­ç»ƒè„šæœ¬ä¸­ï¼ŒåŒ…æ‹¬åˆ†è¯å™¨å’Œæ¨¡å‹ã€‚
- en: If you use the Hugging Face `Trainer`, you can pass your tokenizer as an argument
    to the `Trainer`. It will be automatically saved when you call `trainer.save_model()`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨Hugging Faceçš„`Trainer`ï¼Œæ‚¨å¯ä»¥å°†åˆ†è¯å™¨ä½œä¸ºå‚æ•°ä¼ é€’ç»™`Trainer`ã€‚å½“æ‚¨è°ƒç”¨`trainer.save_model()`æ—¶ï¼Œå®ƒå°†è‡ªåŠ¨ä¿å­˜ã€‚
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After you run your request you can delete the endpoint as shown:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œè¯·æ±‚åï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼åˆ é™¤ç«¯ç‚¹ï¼š
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Deploy with model_data
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨model_dataéƒ¨ç½²
- en: If youâ€™ve already trained your model and want to deploy it at a later time,
    use the `model_data` argument to specify the location of your tokenizer and model
    weights.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å·²ç»è®­ç»ƒäº†æ¨¡å‹å¹¶å¸Œæœ›åœ¨ä»¥åéƒ¨ç½²å®ƒï¼Œè¯·ä½¿ç”¨`model_data`å‚æ•°æŒ‡å®šæ‚¨çš„åˆ†è¯å™¨å’Œæ¨¡å‹æƒé‡çš„ä½ç½®ã€‚
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After you run our request, you can delete the endpoint again with:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œæˆ‘ä»¬çš„è¯·æ±‚åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹é“¾æ¥å†æ¬¡åˆ é™¤ç«¯ç‚¹ï¼š
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Create a model artifact for deployment
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸ºéƒ¨ç½²åˆ›å»ºæ¨¡å‹å·¥ä»¶
- en: 'For later deployment, you can create a `model.tar.gz` file that contains all
    the required files, such as:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨åéƒ¨ç½²æ—¶ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¿…éœ€æ–‡ä»¶çš„`model.tar.gz`æ–‡ä»¶ï¼Œä¾‹å¦‚ï¼š
- en: '`pytorch_model.bin`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytorch_model.bin`'
- en: '`tf_model.h5`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf_model.h5`'
- en: '`tokenizer.json`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer.json`'
- en: '`tokenizer_config.json`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_config.json`'
- en: 'For example, your file should look like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ‚¨çš„æ–‡ä»¶åº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create your own `model.tar.gz` from a model from the ğŸ¤— Hub:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ğŸ¤— Hubåˆ›å»ºè‡ªå·±çš„`model.tar.gz`æ–‡ä»¶ï¼š
- en: 'Download a model:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸‹è½½æ¨¡å‹ï¼š
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create a `tar` file:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ª`tar`æ–‡ä»¶ï¼š
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Upload `model.tar.gz` to S3:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†`model.tar.gz`ä¸Šä¼ åˆ°S3ï¼š
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now you can provide the S3 URI to the `model_data` argument to deploy your model
    later.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å¯ä»¥æä¾›S3 URIç»™`model_data`å‚æ•°ï¼Œä»¥ä¾¿ç¨åéƒ¨ç½²æ‚¨çš„æ¨¡å‹ã€‚
- en: Deploy a model from the ğŸ¤— Hub
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»ğŸ¤— Hubéƒ¨ç½²æ¨¡å‹
- en: '[https://www.youtube.com/embed/l9QZuazbzWM](https://www.youtube.com/embed/l9QZuazbzWM)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/embed/l9QZuazbzWM](https://www.youtube.com/embed/l9QZuazbzWM)'
- en: 'To deploy a model directly from the ğŸ¤— Hub to SageMaker, define two environment
    variables when you create a `HuggingFaceModel`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ç›´æ¥ä»ğŸ¤— Hubéƒ¨ç½²æ¨¡å‹åˆ°SageMakerï¼Œåˆ›å»º`HuggingFaceModel`æ—¶å®šä¹‰ä¸¤ä¸ªç¯å¢ƒå˜é‡ï¼š
- en: '`HF_MODEL_ID` defines the model ID which is automatically loaded from [huggingface.co/models](http://huggingface.co/models)
    when you create a SageMaker endpoint. Access 10,000+ models on he ğŸ¤— Hub through
    this environment variable.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HF_MODEL_ID` å®šä¹‰äº†æ¨¡å‹ IDï¼Œå½“æ‚¨åˆ›å»º SageMaker ç«¯ç‚¹æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨ä»[huggingface.co/models](http://huggingface.co/models)åŠ è½½ã€‚é€šè¿‡è¿™ä¸ªç¯å¢ƒå˜é‡å¯ä»¥è®¿é—®
    ğŸ¤— Hub ä¸Šçš„ 10,000 å¤šä¸ªæ¨¡å‹ã€‚'
- en: '`HF_TASK` defines the task for the ğŸ¤— Transformers `pipeline`. A complete list
    of tasks can be found [here](https://huggingface.co/docs/transformers/main_classes/pipelines).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HF_TASK` å®šä¹‰äº† ğŸ¤— Transformers `pipeline` çš„ä»»åŠ¡ã€‚å®Œæ•´çš„ä»»åŠ¡åˆ—è¡¨å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/docs/transformers/main_classes/pipelines)æ‰¾åˆ°ã€‚'
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After you run our request, you can delete the endpoint again with:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‚¨è¿è¡Œæˆ‘ä»¬çš„è¯·æ±‚åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å†æ¬¡åˆ é™¤ç«¯ç‚¹ï¼š
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ğŸ““ Open the [notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)
    for an example of how to deploy a model from the ğŸ¤— Hub to SageMaker for inference.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ““ æ‰“å¼€[ç¬”è®°æœ¬](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)æŸ¥çœ‹å¦‚ä½•å°†æ¨¡å‹ä»
    ğŸ¤— Hub éƒ¨ç½²åˆ° SageMaker è¿›è¡Œæ¨æ–­çš„ç¤ºä¾‹ã€‚
- en: Run batch transform with ğŸ¤— Transformers and SageMaker
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ ğŸ¤— Transformers å’Œ SageMaker è¿è¡Œæ‰¹é‡è½¬æ¢
- en: '[https://www.youtube.com/embed/lnTixz0tUBg](https://www.youtube.com/embed/lnTixz0tUBg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/embed/lnTixz0tUBg](https://www.youtube.com/embed/lnTixz0tUBg)'
- en: After training a model, you can use [SageMaker batch transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)
    to perform inference with the model. Batch transform accepts your inference data
    as an S3 URI and then SageMaker will take care of downloading the data, running
    the prediction, and uploading the results to S3\. For more details about batch
    transform, take a look [here](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ¨¡å‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[SageMaker æ‰¹é‡è½¬æ¢](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)æ¥æ‰§è¡Œæ¨¡å‹æ¨æ–­ã€‚æ‰¹é‡è½¬æ¢æ¥å—æ‚¨çš„æ¨æ–­æ•°æ®ä½œä¸º
    S3 URIï¼Œç„¶å SageMaker å°†è´Ÿè´£ä¸‹è½½æ•°æ®ï¼Œè¿è¡Œé¢„æµ‹ï¼Œå¹¶å°†ç»“æœä¸Šä¼ åˆ° S3ã€‚æœ‰å…³æ‰¹é‡è½¬æ¢çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[è¿™é‡Œ](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)ã€‚
- en: âš ï¸ The Hugging Face Inference DLC currently only supports `.jsonl` for batch
    transform due to the complex structure of textual data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ ç›®å‰ Hugging Face æ¨æ–­ DLC ä»…æ”¯æŒ `.jsonl` ç”¨äºæ‰¹é‡è½¬æ¢ï¼Œå› ä¸ºæ–‡æœ¬æ•°æ®çš„ç»“æ„å¤æ‚ã€‚
- en: '*Note: Make sure your `inputs` fit the `max_length` of the model during preprocessing.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šç¡®ä¿æ‚¨çš„ `inputs` åœ¨é¢„å¤„ç†æœŸé—´ç¬¦åˆæ¨¡å‹çš„ `max_length`ã€‚*'
- en: 'If you trained a model using the Hugging Face Estimator, call the `transformer()`
    method to create a transform job for a model based on the training job (see [here](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform)
    for more details):'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨ Hugging Face Estimator è®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œè¯·è°ƒç”¨ `transformer()` æ–¹æ³•ä¸ºåŸºäºè®­ç»ƒä½œä¸šçš„æ¨¡å‹åˆ›å»ºä¸€ä¸ªè½¬æ¢ä½œä¸šï¼ˆæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[è¿™é‡Œ](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform)ï¼‰ï¼š
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you want to run your batch transform job later or with a model from the
    ğŸ¤— Hub, create a `HuggingFaceModel` instance and then call the `transformer()`
    method:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³ç¨åè¿è¡Œæ‰¹é‡è½¬æ¢ä½œä¸šæˆ–ä½¿ç”¨ ğŸ¤— Hub ä¸­çš„æ¨¡å‹ï¼Œåˆ›å»ºä¸€ä¸ª `HuggingFaceModel` å®ä¾‹ï¼Œç„¶åè°ƒç”¨ `transformer()`
    æ–¹æ³•ï¼š
- en: '[PRE15]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `input.jsonl` looks like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`input.jsonl` å¦‚ä¸‹æ‰€ç¤ºï¼š'
- en: '[PRE16]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ğŸ““ Open the [notebook](https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb)
    for an example of how to run a batch transform job for inference.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ““ æ‰“å¼€[ç¬”è®°æœ¬](https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb)æŸ¥çœ‹å¦‚ä½•è¿è¡Œç”¨äºæ¨æ–­çš„æ‰¹é‡è½¬æ¢ä½œä¸šçš„ç¤ºä¾‹ã€‚
- en: User defined code and modules
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨æˆ·å®šä¹‰çš„ä»£ç å’Œæ¨¡å—
- en: 'The Hugging Face Inference Toolkit allows the user to override the default
    methods of the `HuggingFaceHandlerService`. You will need to create a folder named
    `code/` with an `inference.py` file in it. See [here](#create-a-model-artifact-for-deployment)
    for more details on how to archive your model artifacts. For example:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face æ¨æ–­å·¥å…·åŒ…å…è®¸ç”¨æˆ·è¦†ç›– `HuggingFaceHandlerService` çš„é»˜è®¤æ–¹æ³•ã€‚æ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ªåä¸º `code/`
    çš„æ–‡ä»¶å¤¹ï¼Œå¹¶åœ¨å…¶ä¸­æ”¾ç½®ä¸€ä¸ª `inference.py` æ–‡ä»¶ã€‚æœ‰å…³å¦‚ä½•å½’æ¡£æ¨¡å‹å·¥ä»¶çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[è¿™é‡Œ](#create-a-model-artifact-for-deployment)ã€‚ä¾‹å¦‚ï¼š
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `inference.py` file contains your custom inference module, and the `requirements.txt`
    file contains additional dependencies that should be added. The custom module
    can override the following methods:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`inference.py` æ–‡ä»¶åŒ…å«æ‚¨çš„è‡ªå®šä¹‰æ¨æ–­æ¨¡å—ï¼Œ`requirements.txt` æ–‡ä»¶åŒ…å«åº”æ·»åŠ çš„é™„åŠ ä¾èµ–é¡¹ã€‚è‡ªå®šä¹‰æ¨¡å—å¯ä»¥è¦†ç›–ä»¥ä¸‹æ–¹æ³•ï¼š'
- en: '`model_fn(model_dir)` overrides the default method for loading a model. The
    return value `model` will be used in `predict` for predictions. `predict` receives
    argument the `model_dir`, the path to your unzipped `model.tar.gz`.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_fn(model_dir)` è¦†ç›–äº†åŠ è½½æ¨¡å‹çš„é»˜è®¤æ–¹æ³•ã€‚è¿”å›å€¼ `model` å°†åœ¨ `predict` ä¸­ç”¨äºé¢„æµ‹ã€‚`predict`
    æ¥æ”¶å‚æ•° `model_dir`ï¼Œå³æ‚¨è§£å‹åçš„ `model.tar.gz` çš„è·¯å¾„ã€‚'
- en: '`transform_fn(model, data, content_type, accept_type)` overrides the default
    transform function with your custom implementation. You will need to implement
    your own `preprocess`, `predict` and `postprocess` steps in the `transform_fn`.
    This method canâ€™t be combined with `input_fn`, `predict_fn` or `output_fn` mentioned
    below.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform_fn(model, data, content_type, accept_type)` è¦†ç›–äº†é»˜è®¤çš„è½¬æ¢å‡½æ•°ï¼Œä½¿ç”¨æ‚¨è‡ªå®šä¹‰çš„å®ç°ã€‚æ‚¨éœ€è¦åœ¨
    `transform_fn` ä¸­å®ç°è‡ªå·±çš„ `preprocess`ã€`predict` å’Œ `postprocess` æ­¥éª¤ã€‚æ­¤æ–¹æ³•ä¸èƒ½ä¸ä¸‹é¢æåˆ°çš„ `input_fn`ã€`predict_fn`
    æˆ– `output_fn` ç»“åˆä½¿ç”¨ã€‚'
- en: '`input_fn(input_data, content_type)` overrides the default method for preprocessing.
    The return value `data` will be used in `predict` for predictions. The inputs
    are:'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_fn(input_data, content_type)` è¦†ç›–äº†é¢„å¤„ç†çš„é»˜è®¤æ–¹æ³•ã€‚è¿”å›å€¼ `data` å°†åœ¨ `predict` ä¸­ç”¨äºé¢„æµ‹ã€‚è¾“å…¥æ˜¯ï¼š'
- en: '`input_data` is the raw body of your request.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data` æ˜¯æ‚¨è¯·æ±‚çš„åŸå§‹ä¸»ä½“ã€‚'
- en: '`content_type` is the content type from the request header.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`content_type` æ˜¯è¯·æ±‚å¤´ä¸­çš„å†…å®¹ç±»å‹ã€‚'
- en: '`predict_fn(processed_data, model)` overrides the default method for predictions.
    The return value `predictions` will be used in `postprocess`. The input is `processed_data`,
    the result from `preprocess`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_fn(processed_data, model)` è¦†ç›–äº†é¢„æµ‹çš„é»˜è®¤æ–¹æ³•ã€‚è¿”å›å€¼ `predictions` å°†åœ¨ `postprocess`
    ä¸­ä½¿ç”¨ã€‚è¾“å…¥æ˜¯ `processed_data`ï¼Œæ˜¯ä» `preprocess` å¾—åˆ°çš„ç»“æœã€‚'
- en: '`output_fn(prediction, accept)` overrides the default method for postprocessing.
    The return value `result` will be the response of your request (e.g.`JSON`). The
    inputs are:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_fn(prediction, accept)` è¦†ç›–äº†åå¤„ç†çš„é»˜è®¤æ–¹æ³•ã€‚è¿”å›å€¼ `result` å°†æ˜¯æ‚¨è¯·æ±‚çš„å“åº”ï¼ˆä¾‹å¦‚ `JSON`ï¼‰ã€‚è¾“å…¥æ˜¯ï¼š'
- en: '`predictions` is the result from `predict`.'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predictions`æ˜¯æ¥è‡ª`predict`çš„ç»“æœã€‚'
- en: '`accept` is the return accept type from the HTTP Request, e.g. `application/json`.'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accept`æ˜¯æ¥è‡ªHTTPè¯·æ±‚çš„è¿”å›æ¥å—ç±»å‹ï¼Œä¾‹å¦‚`application/json`ã€‚'
- en: 'Here is an example of a custom inference module with `model_fn`, `input_fn`,
    `predict_fn`, and `output_fn`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªå¸¦æœ‰`model_fn`ã€`input_fn`ã€`predict_fn`å’Œ`output_fn`çš„è‡ªå®šä¹‰æ¨ç†æ¨¡å—ç¤ºä¾‹ï¼š
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Customize your inference module with only `model_fn` and `transform_fn`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: åªä½¿ç”¨`model_fn`å’Œ`transform_fn`è‡ªå®šä¹‰æ‚¨çš„æ¨ç†æ¨¡å—ï¼š
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
