- en: Keras callbacks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keras回调
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/keras_callbacks](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/keras_callbacks)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[原文链接](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/keras_callbacks)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'When training a Transformers model with Keras, there are some library-specific
    callbacks available to automate common tasks:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Keras训练Transformers模型时，有一些特定于库的回调可用于自动化常见任务：
- en: KerasMetricCallback
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KerasMetricCallback
- en: '### `class transformers.KerasMetricCallback`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.KerasMetricCallback`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/keras_callbacks.py#L20)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/keras_callbacks.py#L20)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`metric_fn` (`Callable`) — Metric function provided by the user. It will be
    called with two arguments - `predictions` and `labels`. These contain the model’s
    outputs and matching labels from the dataset. It should return a dict mapping
    metric names to numerical values.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metric_fn`（`Callable`）- 用户提供的度量函数。它将使用两个参数调用-`predictions`和`labels`。这些包含数据集中模型的输出和匹配标签。它应返回一个将度量名称映射到数值的字典。'
- en: '`eval_dataset` (`tf.data.Dataset` or `dict` or `tuple` or `np.ndarray` or `tf.Tensor`)
    — Validation data to be used to generate predictions for the `metric_fn`.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_dataset`（`tf.data.Dataset`或`dict`或`tuple`或`np.ndarray`或`tf.Tensor`）-
    用于生成`metric_fn`预测的验证数据。'
- en: '`output_cols` (`List[str], *optional*) — A list of columns to be retained from
    the model output as the predictions. Defaults to all.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_cols`（`List[str]`，*可选*）- 从模型输出中保留的列的列表作为预测。默认为全部。'
- en: '`label_cols` (’`List[str]`, *optional*’) — A list of columns to be retained
    from the input dataset as the labels. Will be autodetected if this is not supplied.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_cols`（`List[str]`，*可选*）- 从输入数据集中保留的列的列表作为标签。如果未提供，则将自动检测。'
- en: '`batch_size` (`int`, *optional*) — Batch size. Only used when the data is not
    a pre-batched `tf.data.Dataset`.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`（`int`，*可选*）- 批量大小。仅在数据不是预先批处理的`tf.data.Dataset`时使用。'
- en: '`predict_with_generate` (`bool`, *optional*, defaults to `False`) — Whether
    we should use `model.generate()` to get outputs for the model.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_with_generate`（`bool`，*可选*，默认为`False`）- 是否应使用`model.generate()`来获取模型的输出。'
- en: '`use_xla_generation` (`bool`, *optional*, defaults to `False`) — If we’re generating,
    whether to compile model generation with XLA. This can massively increase the
    speed of generation (up to 100X speedup) but will require a new XLA compilation
    for each input shape. When using XLA generation, it’s a good idea to pad your
    inputs to the same size, or to use the `pad_to_multiple_of` argument in your `tokenizer`
    or `DataCollator`, which will reduce the number of unique input shapes and save
    a lot of compilation time. This option has no effect is `predict_with_generate`
    is `False`.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_xla_generation`（`bool`，*可选*，默认为`False`）- 如果我们正在生成，是否使用XLA编译模型生成。这可以大大提高生成速度（最多提高100倍），但将需要为每个输入形状进行新的XLA编译。在使用XLA生成时，最好将输入填充到相同大小，或者在您的`tokenizer`或`DataCollator`中使用`pad_to_multiple_of`参数，这将减少唯一输入形状的数量并节省大量编译时间。如果`predict_with_generate`为`False`，则此选项不起作用。'
- en: '`generate_kwargs` (`dict`, *optional*) — Keyword arguments to pass to `model.generate()`
    when generating. Has no effect if `predict_with_generate` is `False`.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_kwargs`（`dict`，*可选*）- 生成时传递给`model.generate()`的关键字参数。如果`predict_with_generate`为`False`，则不起作用。'
- en: Callback to compute metrics at the end of every epoch. Unlike normal Keras metrics,
    these do not need to be compilable by TF. It is particularly useful for common
    NLP metrics like BLEU and ROUGE that require string operations or generation loops
    that cannot be compiled. Predictions (or generations) will be computed on the
    `eval_dataset` before being passed to the `metric_fn` in `np.ndarray` format.
    The `metric_fn` should compute metrics and return a dict mapping metric names
    to metric values.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时代结束时计算指标的回调。与普通的Keras指标不同，这些指标不需要由TF编译。对于像BLEU和ROUGE这样需要字符串操作或无法编译的生成循环的常见NLP指标，这是特别有用的。在将预测（或生成）传递给`metric_fn`之前，将在`eval_dataset`上计算预测（或生成）并以`np.ndarray`格式传递给`metric_fn`。`metric_fn`应计算指标并返回将度量名称映射到度量值的字典。
- en: We provide an example of a suitable metric_fn that computes ROUGE scores for
    a summarization model below. Note that this example skips some post-processing
    for readability and simplicity, and should probably not be used as-is!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在下面提供了一个适合的metric_fn示例，用于计算摘要模型的ROUGE分数。请注意，为了可读性和简单起见，此示例跳过了一些后处理步骤，可能不应直接使用！
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The above function will return a dict containing values which will be logged
    like any other Keras metric:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数将返回一个包含值的字典，这些值将像其他Keras指标一样被记录：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: PushToHubCallback
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PushToHubCallback
- en: '### `class transformers.PushToHubCallback`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.PushToHubCallback`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/keras_callbacks.py#L268)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/keras_callbacks.py#L268)'
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`output_dir` (`str`) — The output directory where the model predictions and
    checkpoints will be written and synced with the repository on the Hub.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_dir`（`str`）- 模型预测和检查点将被写入并与Hub上的存储库同步的输出目录。'
- en: '`save_strategy` (`str` or [IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy),
    *optional*, defaults to `"epoch"`) — The checkpoint save strategy to adopt during
    training. Possible values are:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_strategy`（`str`或[IntervalStrategy](/docs/transformers/v4.37.2/en/internal/trainer_utils#transformers.IntervalStrategy)，*可选*，默认为`"epoch"`）-
    训练期间采用的检查点保存策略。可能的值为：'
- en: '`"no"`: Save is done at the end of training.'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"no"`：保存在训练结束时完成。'
- en: '`"epoch"`: Save is done at the end of each epoch.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"epoch"`：在每个时代结束时完成保存。'
- en: '`"steps"`: Save is done every `save_steps`'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"steps"`：每`save_steps`完成保存'
- en: '`save_steps` (`int`, *optional*) — The number of steps between saves when using
    the “steps” `save_strategy`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_steps`（`int`，*可选*）- 使用“steps”`save_strategy`时保存之间的步数。'
- en: '`tokenizer` (`PreTrainedTokenizerBase`, *optional*) — The tokenizer used by
    the model. If supplied, will be uploaded to the repo alongside the weights.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`PreTrainedTokenizerBase`，*可选*）—模型使用的分词器。如果提供，将与权重一起上传到存储库。'
- en: '`hub_model_id` (`str`, *optional*) — The name of the repository to keep in
    sync with the local `output_dir`. It can be a simple model ID in which case the
    model will be pushed in your namespace. Otherwise it should be the whole repository
    name, for instance `"user_name/model"`, which allows you to push to an organization
    you are a member of with `"organization_name/model"`.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hub_model_id`（`str`，*可选*）—要与本地`output_dir`同步的存储库的名称。它可以是一个简单的模型ID，此时模型将被推送到您的命名空间。否则，它应该是整个存储库名称，例如`"user_name/model"`，这样您就可以推送到您所属的组织，例如`"organization_name/model"`。'
- en: Will default to the name of `output_dir`.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将默认为`output_dir`的名称。
- en: '`hub_token` (`str`, *optional*) — The token to use to push the model to the
    Hub. Will default to the token in the cache folder obtained with `huggingface-cli
    login`.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hub_token`（`str`，*可选*）—用于将模型推送到Hub的令牌。将默认为使用`huggingface-cli login`获取的缓存文件夹中的令牌。'
- en: '`checkpoint` (`bool`, *optional*, defaults to `False`) — Whether to save full
    training checkpoints (including epoch and optimizer state) to allow training to
    be resumed. Only usable when `save_strategy` is `"epoch"`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`checkpoint`（`bool`，*可选*，默认为`False`）—是否保存完整的训练检查点（包括epoch和优化器状态），以允许恢复训练。仅在`save_strategy`为`"epoch"`时可用。'
- en: Callback that will save and push the model to the Hub regularly. By default,
    it pushes once per epoch, but this can be changed with the `save_strategy` argument.
    Pushed models can be accessed like any other model on the hub, such as with the
    `from_pretrained` method.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 回调函数将定期保存并推送模型到Hub。默认情况下，它每个epoch推送一次，但可以使用`save_strategy`参数进行更改。推送的模型可以像Hub上的任何其他模型一样访问，例如使用`from_pretrained`方法。
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
