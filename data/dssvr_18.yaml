- en: ClickHouse
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ClickHouse
- en: 'Original text: [https://huggingface.co/docs/datasets-server/clickhouse](https://huggingface.co/docs/datasets-server/clickhouse)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets-server/clickhouse](https://huggingface.co/docs/datasets-server/clickhouse)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[ClickHouse](https://clickhouse.com/docs/en/intro) is a fast and efficient
    column-oriented database for analytical workloads, making it easy to analyze Hub-hosted
    datasets with SQL. To get started quickly, use [`clickhouse-local`](https://clickhouse.com/docs/en/operations/utilities/clickhouse-local)
    to run SQL queries from the command line and avoid the need to fully install ClickHouse.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClickHouse](https://clickhouse.com/docs/en/intro)是一个用于分析工作负载的快速高效的列式数据库，使用SQL轻松分析Hub托管的数据集。要快速开始，请使用[`clickhouse-local`](https://clickhouse.com/docs/en/operations/utilities/clickhouse-local)在命令行中运行SQL查询，避免完全安装ClickHouse的需要。'
- en: Check this [blog](https://clickhouse.com/blog/query-analyze-hugging-face-datasets-with-clickhouse)
    for more details about how to analyze datasets on the Hub with ClickHouse.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这篇[博客](https://clickhouse.com/blog/query-analyze-hugging-face-datasets-with-clickhouse)了解如何使用ClickHouse分析Hub上的数据集的更多细节。
- en: 'To start, download and install `clickhouse-local`:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，下载并安装`clickhouse-local`：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For this example, you’ll analyze the [maharshipandya/spotify-tracks-dataset](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset)
    which contains information about Spotify tracks. Datasets on the Hub are stored
    as Parquet files and you can access it with the [`/parquet`](parquet) endpoint:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您将分析包含有关Spotify歌曲信息的[maharshipandya/spotify-tracks-dataset](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset)。Hub上的数据集存储为Parquet文件，您可以使用[`/parquet`](parquet)端点访问它：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Aggregate functions
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合函数
- en: Now you can begin to analyze the dataset. Use the `-q` argument to specify the
    query to execute, and the [`url`](https://clickhouse.com/docs/en/sql-reference/table-functions/url)
    function to create a table from the data in the Parquet file.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以开始分析数据集了。使用`-q`参数指定要执行的查询，并使用[`url`](https://clickhouse.com/docs/en/sql-reference/table-functions/url)函数从Parquet文件中的数据创建表。
- en: You should set `enable_url_encoding` to 0 to ensure the escape characters in
    the URL are preserved as intended, and `max_https_get_redirects` to 1 to redirect
    to the path of the Parquet file.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该将`enable_url_encoding`设置为0，以确保URL中的转义字符按预期保留，并将`max_https_get_redirects`设置为1，以便重定向到Parquet文件的路径。
- en: 'Let’s start by identifying the most popular artists:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从识别最受欢迎的艺术家开始：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'ClickHouse also provides functions for visualizing your queries. For example,
    you can use the [`bar`](https://clickhouse.com/docs/en/sql-reference/functions/other-functions#bar)
    function to create a bar chart of the danceability of songs:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ClickHouse还提供了用于可视化查询的函数。例如，您可以使用[`bar`](https://clickhouse.com/docs/en/sql-reference/functions/other-functions#bar)函数创建歌曲舞蹈性的柱状图：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To get a deeper understanding about a dataset, ClickHouse provides statistical
    analysis functions for determining how your data is correlated, calculating statistical
    hypothesis tests, and more. Take a look at ClickHouse’s [List of Aggregate Functions](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference)
    for a complete list of available aggregate functions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地了解数据集，ClickHouse提供了用于确定数据相关性、计算统计假设检验等的统计分析函数。查看ClickHouse的[聚合函数列表](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference)获取可用聚合函数的完整列表。
- en: User-defined function (UDFs)
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户定义函数（UDFs）
- en: A user-defined function (UDF) allows you to reuse custom logic. Many Hub datasets
    are often sharded into more than one Parquet file, so it can be easier and more
    efficient to create a UDF to list and query all the Parquet files of a given dataset
    from just the dataset name.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 用户定义函数（UDF）允许您重用自定义逻辑。许多Hub数据集通常被分片成多个Parquet文件，因此创建一个UDF来列出并查询给定数据集的所有Parquet文件可能更容易和更高效，只需使用数据集名称即可。
- en: 'For this example, you’ll need to run `clickhouse-local` in console mode so
    the UDF persists between queries:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您需要在控制台模式下运行`clickhouse-local`，这样UDF在查询之间可以持久存在：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Remember to set `enable_url_encoding` to 0 and `max_https_get_redirects` to
    1 to redirect to the path of the Parquet files:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 记得将`enable_url_encoding`设置为0，将`max_https_get_redirects`设置为1，以便重定向到Parquet文件的路径：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s create a function to return a list of Parquet files from the [`blog_authorship_corpus`](https://huggingface.co/datasets/blog_authorship_corpus):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个函数，返回[`blog_authorship_corpus`](https://huggingface.co/datasets/blog_authorship_corpus)中的Parquet文件列表：
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can make this even easier by creating another function that calls `hugging_paths`
    and outputs all the files based on the dataset name:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过创建另一个调用`hugging_paths`并基于数据集名称输出所有文件的函数来使这更加简单：
- en: '[PRE7]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now use the `hf` function to query any dataset by passing the dataset name:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用`hf`函数通过传递数据集名称来查询任何数据集：
- en: '[PRE8]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
