- en: LayoutLMV2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LayoutLMV2
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv2)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv2)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The LayoutLMV2 model was proposed in [LayoutLMv2: Multi-modal Pre-training
    for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) by
    Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei
    Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou. LayoutLMV2 improves
    [LayoutLM](layoutlm) to obtain state-of-the-art results across several document
    image understanding benchmarks:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'LayoutLMV2模型是由Yang Xu、Yiheng Xu、Tengchao Lv、Lei Cui、Furu Wei、Guoxin Wang、Yijuan
    Lu、Dinei Florencio、Cha Zhang、Wanxiang Che、Min Zhang、Lidong Zhou提出的[LayoutLMv2:
    Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740)。LayoutLMV2改进了[LayoutLM](layoutlm)以获得跨多个文档图像理解基准的最新结果：'
- en: 'information extraction from scanned documents: the [FUNSD](https://guillaumejaume.github.io/FUNSD/)
    dataset (a collection of 199 annotated forms comprising more than 30,000 words),
    the [CORD](https://github.com/clovaai/cord) dataset (a collection of 800 receipts
    for training, 100 for validation and 100 for testing), the [SROIE](https://rrc.cvc.uab.es/?ch=13)
    dataset (a collection of 626 receipts for training and 347 receipts for testing)
    and the [Kleister-NDA](https://github.com/applicaai/kleister-nda) dataset (a collection
    of non-disclosure agreements from the EDGAR database, including 254 documents
    for training, 83 documents for validation, and 203 documents for testing).'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从扫描文档中提取信息：[FUNSD](https://guillaumejaume.github.io/FUNSD/)数据集（包含超过30,000个单词的199个带注释表格）、[CORD](https://github.com/clovaai/cord)数据集（包含800张用于训练的收据、100张用于验证和100张用于测试）、[SROIE](https://rrc.cvc.uab.es/?ch=13)数据集（包含626张用于训练和347张用于测试的收据）以及[Kleister-NDA](https://github.com/applicaai/kleister-nda)数据集（包含来自EDGAR数据库的非披露协议，包括254份用于训练、83份用于验证和203份用于测试的文件）。
- en: 'document image classification: the [RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)
    dataset (a collection of 400,000 images belonging to one of 16 classes).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档图像分类：[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)数据集（包含40万张属于16个类别的图像）。
- en: 'document visual question answering: the [DocVQA](https://arxiv.org/abs/2007.00398)
    dataset (a collection of 50,000 questions defined on 12,000+ document images).'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档视觉问答：[DocVQA](https://arxiv.org/abs/2007.00398)数据集（包含在12,000多个文档图像上定义的5万个问题）。
- en: 'The abstract from the paper is the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要如下：
- en: '*Pre-training of text and layout has proved effective in a variety of visually-rich
    document understanding tasks due to its effective model architecture and the advantage
    of large-scale unlabeled scanned/digital-born documents. In this paper, we present
    LayoutLMv2 by pre-training text, layout and image in a multi-modal framework,
    where new model architectures and pre-training tasks are leveraged. Specifically,
    LayoutLMv2 not only uses the existing masked visual-language modeling task but
    also the new text-image alignment and text-image matching tasks in the pre-training
    stage, where cross-modality interaction is better learned. Meanwhile, it also
    integrates a spatial-aware self-attention mechanism into the Transformer architecture,
    so that the model can fully understand the relative positional relationship among
    different text blocks. Experiment results show that LayoutLMv2 outperforms strong
    baselines and achieves new state-of-the-art results on a wide variety of downstream
    visually-rich document understanding tasks, including FUNSD (0.7895 -> 0.8420),
    CORD (0.9493 -> 0.9601), SROIE (0.9524 -> 0.9781), Kleister-NDA (0.834 -> 0.852),
    RVL-CDIP (0.9443 -> 0.9564), and DocVQA (0.7295 -> 0.8672). The pre-trained LayoutLMv2
    model is publicly available at this https URL.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*文本和布局的预训练在各种视觉丰富的文档理解任务中已被证明是有效的，这是由于其有效的模型架构和大规模未标记的扫描/数字化文档的优势。在本文中，我们提出了LayoutLMv2，通过在多模态框架中预训练文本、布局和图像，利用了新的模型架构和预训练任务。具体来说，LayoutLMv2不仅使用现有的遮蔽视觉语言建模任务，还使用新的文本-图像对齐和文本-图像匹配任务在预训练阶段，从而更好地学习跨模态交互。同时，它还将空间感知自注意机制集成到Transformer架构中，使模型能够充分理解不同文本块之间的相对位置关系。实验结果表明，LayoutLMv2优于强基线，并在各种下游视觉丰富的文档理解任务中取得了新的最先进结果，包括FUNSD（0.7895
    -> 0.8420）、CORD（0.9493 -> 0.9601）、SROIE（0.9524 -> 0.9781）、Kleister-NDA（0.834 ->
    0.852）、RVL-CDIP（0.9443 -> 0.9564）和DocVQA（0.7295 -> 0.8672）。预训练的LayoutLMv2模型可以在此https
    URL上公开获取。*'
- en: 'LayoutLMv2 depends on `detectron2`, `torchvision` and `tesseract`. Run the
    following to install them:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMv2依赖于`detectron2`、`torchvision`和`tesseract`。运行以下命令进行安装：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: (If you are developing for LayoutLMv2, note that passing the doctests also requires
    the installation of these packages.)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: （如果您正在开发LayoutLMv2，请注意通过doctests还需要安装这些包。）
- en: Usage tips
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: The main difference between LayoutLMv1 and LayoutLMv2 is that the latter incorporates
    visual embeddings during pre-training (while LayoutLMv1 only adds visual embeddings
    during fine-tuning).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LayoutLMv1和LayoutLMv2之间的主要区别在于后者在预训练期间包含了视觉嵌入（而LayoutLMv1仅在微调期间添加了视觉嵌入）。
- en: LayoutLMv2 adds both a relative 1D attention bias as well as a spatial 2D attention
    bias to the attention scores in the self-attention layers. Details can be found
    on page 5 of the [paper](https://arxiv.org/abs/2012.14740).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LayoutLMv2在自注意力层中添加了相对1D注意力偏置和空间2D注意力偏置到注意力分数中。详细信息可在[论文](https://arxiv.org/abs/2012.14740)的第5页找到。
- en: Demo notebooks on how to use the LayoutLMv2 model on RVL-CDIP, FUNSD, DocVQA,
    CORD can be found [here](https://github.com/NielsRogge/Transformers-Tutorials).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在[此处](https://github.com/NielsRogge/Transformers-Tutorials)找到如何在RVL-CDIP、FUNSD、DocVQA、CORD上使用LayoutLMv2模型的演示笔记本。
- en: LayoutLMv2 uses Facebook AI’s [Detectron2](https://github.com/facebookresearch/detectron2/)
    package for its visual backbone. See [this link](https://detectron2.readthedocs.io/en/latest/tutorials/install.html)
    for installation instructions.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LayoutLMv2使用Facebook AI的[Detectron2](https://github.com/facebookresearch/detectron2/)包作为其视觉骨干。查看[此链接](https://detectron2.readthedocs.io/en/latest/tutorials/install.html)获取安装说明。
- en: 'In addition to `input_ids`, [forward()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model.forward)
    expects 2 additional inputs, namely `image` and `bbox`. The `image` input corresponds
    to the original document image in which the text tokens occur. The model expects
    each document image to be of size 224x224\. This means that if you have a batch
    of document images, `image` should be a tensor of shape (batch_size, 3, 224, 224).
    This can be either a `torch.Tensor` or a `Detectron2.structures.ImageList`. You
    don’t need to normalize the channels, as this is done by the model. Important
    to note is that the visual backbone expects BGR channels instead of RGB, as all
    models in Detectron2 are pre-trained using the BGR format. The `bbox` input are
    the bounding boxes (i.e. 2D-positions) of the input text tokens. This is identical
    to [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel).
    These can be obtained using an external OCR engine such as Google’s [Tesseract](https://github.com/tesseract-ocr/tesseract)
    (there’s a [Python wrapper](https://pypi.org/project/pytesseract/) available).
    Each bounding box should be in (x0, y0, x1, y1) format, where (x0, y0) corresponds
    to the position of the upper left corner in the bounding box, and (x1, y1) represents
    the position of the lower right corner. Note that one first needs to normalize
    the bounding boxes to be on a 0-1000 scale. To normalize, you can use the following
    function:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了`input_ids`，[forward()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model.forward)还需要2个额外的输入，即`image`和`bbox`。`image`输入对应于文本标记出现的原始文档图像。模型期望每个文档图像的大小为224x224。这意味着如果您有一批文档图像，`image`应该是形状为(batch_size,
    3, 224, 224)的张量。这可以是`torch.Tensor`或`Detectron2.structures.ImageList`。您不需要对通道进行归一化，因为模型会自行处理。需要注意的是，视觉主干期望BGR通道而不是RGB，因为Detectron2中的所有模型都是使用BGR格式进行预训练的。`bbox`输入是输入文本标记的边界框（即2D位置）。这与[LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)相同。可以使用外部OCR引擎（例如Google的[Tesseract](https://github.com/tesseract-ocr/tesseract)）（有一个[Python包装器](https://pypi.org/project/pytesseract/)可用）来获取这些信息。每个边界框应采用(x0,
    y0, x1, y1)格式，其中(x0, y0)对应于边界框左上角的位置，(x1, y1)表示右下角的位置。请注意，首先需要将边界框归一化为0-1000的比例。要进行归一化，可以使用以下函数：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, `width` and `height` correspond to the width and height of the original
    document in which the token occurs (before resizing the image). Those can be obtained
    using the Python Image Library (PIL) library for example, as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`width`和`height`对应于标记出现的原始文档的宽度和高度（在调整图像大小之前）。可以使用Python Image Library（PIL）库来获取这些信息，例如：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: However, this model includes a brand new [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    which can be used to directly prepare data for the model (including applying OCR
    under the hood). More information can be found in the “Usage” section below.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，该模型包含一个全新的[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)，可用于直接为模型准备数据（包括在底层应用OCR）。更多信息可以在下面的“使用”部分找到。
- en: Internally, [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    will send the `image` input through its visual backbone to obtain a lower-resolution
    feature map, whose shape is equal to the `image_feature_pool_shape` attribute
    of [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config).
    This feature map is then flattened to obtain a sequence of image tokens. As the
    size of the feature map is 7x7 by default, one obtains 49 image tokens. These
    are then concatenated with the text tokens, and send through the Transformer encoder.
    This means that the last hidden states of the model will have a length of 512
    + 49 = 561, if you pad the text tokens up to the max length. More generally, the
    last hidden states will have a shape of `seq_length` + `image_feature_pool_shape[0]`
    * `config.image_feature_pool_shape[1]`.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内部，[LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)将通过其视觉主干发送`image`输入，以获得一个分辨率较低的特征图，其形状等于[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)的`image_feature_pool_shape`属性。然后将该特征图展平以获得一系列图像标记。由于特征图的大小默认为7x7，因此获得49个图像标记。然后将这些标记与文本标记连接，并通过Transformer编码器发送。这意味着模型的最后隐藏状态将具有长度为512
    + 49 = 561，如果您将文本标记填充到最大长度。更一般地，最后的隐藏状态将具有形状`seq_length` + `image_feature_pool_shape[0]`
    * `config.image_feature_pool_shape[1]`。
- en: When calling [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained),
    a warning will be printed with a long list of parameter names that are not initialized.
    This is not a problem, as these parameters are batch normalization statistics,
    which are going to have values when fine-tuning on a custom dataset.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)时，将打印一个警告，其中包含一长串未初始化的参数名称。这不是问题，因为这些参数是批量归一化统计数据，在自定义数据集上微调时将具有值。
- en: If you want to train the model in a distributed environment, make sure to call
    `synchronize_batch_norm` on the model in order to properly synchronize the batch
    normalization layers of the visual backbone.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果要在分布式环境中训练模型，请确保在模型上调用`synchronize_batch_norm`，以便正确同步视觉主干的批量归一化层。
- en: In addition, there’s LayoutXLM, which is a multilingual version of LayoutLMv2\.
    More information can be found on [LayoutXLM’s documentation page](layoutxlm).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有LayoutXLM，这是LayoutLMv2的多语言版本。更多信息可以在[LayoutXLM的文档页面](layoutxlm)找到。
- en: Resources
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with LayoutLMv2\. If you’re interested in submitting a resource
    to be included here, please feel free to open a Pull Request and we’ll review
    it! The resource should ideally demonstrate something new instead of duplicating
    an existing resource.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 官方Hugging Face和社区（由🌎表示）资源列表，可帮助您开始使用LayoutLMv2。如果您有兴趣提交资源以包含在此处，请随时提出拉取请求，我们将对其进行审查！资源应该展示一些新内容，而不是重复现有资源。
- en: Text Classification
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类
- en: A notebook on how to [finetune LayoutLMv2 for text-classification on RVL-CDIP
    dataset](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/RVL-CDIP/Fine_tuning_LayoutLMv2ForSequenceClassification_on_RVL_CDIP.ipynb).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于如何在RVL-CDIP数据集上对LayoutLMv2进行微调以进行文本分类的笔记。
- en: 'See also: [Text classification task guide](../tasks/sequence_classification)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：文本分类任务指南
- en: Question Answering
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 问答
- en: A notebook on how to [finetune LayoutLMv2 for question-answering on DocVQA dataset](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/DocVQA/Fine_tuning_LayoutLMv2ForQuestionAnswering_on_DocVQA.ipynb).
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于如何在DocVQA数据集上对LayoutLMv2进行问答微调的笔记。
- en: 'See also: [Question answering task guide](../tasks/question_answering)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：问答任务指南
- en: 'See also: [Document question answering task guide](../tasks/document_question_answering)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：文档问答任务指南
- en: Token Classification
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 标记分类
- en: A notebook on how to [finetune LayoutLMv2 for token-classification on CORD dataset](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/CORD/Fine_tuning_LayoutLMv2ForTokenClassification_on_CORD.ipynb).
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于如何在CORD数据集上对LayoutLMv2进行微调以进行标记分类的笔记。
- en: A notebook on how to [finetune LayoutLMv2 for token-classification on FUNSD
    dataset](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Fine_tuning_LayoutLMv2ForTokenClassification_on_FUNSD_using_HuggingFace_Trainer.ipynb).
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于如何在FUNSD数据集上对LayoutLMv2进行微调以进行标记分类的笔记。
- en: 'See also: [Token classification task guide](../tasks/token_classification)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：标记分类任务指南
- en: 'Usage: LayoutLMv2Processor'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法：LayoutLMv2Processor
- en: The easiest way to prepare data for the model is to use [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor),
    which internally combines a image processor ([LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor))
    and a tokenizer ([LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    or [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast)).
    The image processor handles the image modality, while the tokenizer handles the
    text modality. A processor combines both, which is ideal for a multi-modal model
    like LayoutLMv2\. Note that you can still use both separately, if you only want
    to handle one modality.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为模型准备数据的最简单方法是使用LayoutLMv2Processor，它在内部结合了图像处理器（LayoutLMv2ImageProcessor）和标记器（LayoutLMv2Tokenizer或LayoutLMv2TokenizerFast）。图像处理器处理图像模态，而标记器处理文本模态。处理器结合了两者，这对于像LayoutLMv2这样的多模态模型是理想的。请注意，如果您只想处理一个模态，仍然可以分别使用两者。
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In short, one can provide a document image (and possibly additional data) to
    [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor),
    and it will create the inputs expected by the model. Internally, the processor
    first uses [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    to apply OCR on the image to get a list of words and normalized bounding boxes,
    as well to resize the image to a given size in order to get the `image` input.
    The words and normalized bounding boxes are then provided to [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    or [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast),
    which converts them to token-level `input_ids`, `attention_mask`, `token_type_ids`,
    `bbox`. Optionally, one can provide word labels to the processor, which are turned
    into token-level `labels`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，可以将文档图像（以及可能的其他数据）提供给LayoutLMv2Processor，它将创建模型期望的输入。在内部，处理器首先使用LayoutLMv2ImageProcessor在图像上应用OCR，以获取单词列表和标准化边界框，并将图像调整大小以获得`image`输入。然后，单词和标准化边界框提供给LayoutLMv2Tokenizer或LayoutLMv2TokenizerFast，将它们转换为标记级别的`input_ids`、`attention_mask`、`token_type_ids`、`bbox`。可选地，可以向处理器提供单词标签，这些标签将转换为标记级别的`labels`。
- en: '[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    uses [PyTesseract](https://pypi.org/project/pytesseract/), a Python wrapper around
    Google’s Tesseract OCR engine, under the hood. Note that you can still use your
    own OCR engine of choice, and provide the words and normalized boxes yourself.
    This requires initializing [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    with `apply_ocr` set to `False`.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)使用[PyTesseract](https://pypi.org/project/pytesseract/)，这是Google的Tesseract
    OCR引擎的Python封装。请注意，您仍然可以使用自己选择的OCR引擎，并自己提供单词和标准化框。这需要使用`apply_ocr`设置为`False`来初始化[LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)。'
- en: In total, there are 5 use cases that are supported by the processor. Below,
    we list them all. Note that each of these use cases work for both batched and
    non-batched inputs (we illustrate them for non-batched inputs).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 总共有5个处理器支持的使用案例。下面我们列出它们。请注意，这些使用案例对批处理和非批处理输入都适用（我们为非批处理输入进行说明）。
- en: '**Use case 1: document image classification (training, inference) + token classification
    (inference), apply_ocr = True**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例1：文档图像分类（训练、推理）+标记分类（推理），apply_ocr=True
- en: This is the simplest case, in which the processor (actually the image processor)
    will perform OCR on the image to get the words and normalized bounding boxes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最简单的情况，处理器（实际上是图像处理器）将对图像执行OCR，以获取单词和标准化边界框。
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Use case 2: document image classification (training, inference) + token classification
    (inference), apply_ocr=False**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例2：文档图像分类（训练、推理）+标记分类（推理），apply_ocr=False
- en: In case one wants to do OCR themselves, one can initialize the image processor
    with `apply_ocr` set to `False`. In that case, one should provide the words and
    corresponding (normalized) bounding boxes themselves to the processor.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果想要自己执行OCR，可以将图像处理器初始化为`apply_ocr`设置为`False`。在这种情况下，应该自己向处理器提供单词和相应的（标准化的）边界框。
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Use case 3: token classification (training), apply_ocr=False**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例3：标记分类（训练），apply_ocr=False
- en: For token classification tasks (such as FUNSD, CORD, SROIE, Kleister-NDA), one
    can also provide the corresponding word labels in order to train a model. The
    processor will then convert these into token-level `labels`. By default, it will
    only label the first wordpiece of a word, and label the remaining wordpieces with
    -100, which is the `ignore_index` of PyTorch’s CrossEntropyLoss. In case you want
    all wordpieces of a word to be labeled, you can initialize the tokenizer with
    `only_label_first_subword` set to `False`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标记分类任务（如FUNSD、CORD、SROIE、Kleister-NDA），还可以提供相应的单词标签以训练模型。处理器将把这些转换为标记级别的`labels`。默认情况下，它只会标记单词的第一个词片，并用-100标记剩余的词片，这是PyTorch的CrossEntropyLoss的`ignore_index`。如果希望标记单词的所有词片，可以将分词器初始化为`only_label_first_subword`设置为`False`。
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Use case 4: visual question answering (inference), apply_ocr=True**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例4：视觉问答（推理），apply_ocr=True
- en: For visual question answering tasks (such as DocVQA), you can provide a question
    to the processor. By default, the processor will apply OCR on the image, and create
    [CLS] question tokens [SEP] word tokens [SEP].
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于视觉问答任务（如DocVQA），您可以向处理器提供问题。默认情况下，处理器将在图像上应用OCR，并创建[CLS]问题标记[SEP]单词标记[SEP]。
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Use case 5: visual question answering (inference), apply_ocr=False**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用案例5：视觉问答（推理），apply_ocr=False
- en: For visual question answering tasks (such as DocVQA), you can provide a question
    to the processor. If you want to perform OCR yourself, you can provide your own
    words and (normalized) bounding boxes to the processor.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于视觉问答任务（如DocVQA），您可以向处理器提供问题。如果您想自己执行OCR，可以向处理器提供自己的单词和（标准化的）边界框。
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: LayoutLMv2Config
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2Config
- en: '### `class transformers.LayoutLMv2Config`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/configuration_layoutlmv2.py#L34)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/configuration_layoutlmv2.py#L34)'
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    LayoutLMv2 model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    or `TFLayoutLMv2Model`.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为30522）—LayoutLMv2模型的词汇量。定义了在调用[LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)或`TFLayoutLMv2Model`时可以表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimension of the encoder
    layers and the pooler layer.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`（`int`，*可选*，默认为768）—编码器层和池化器层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers`（`int`，*可选*，默认为12）—变换器编码器中的隐藏层数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads`（`int`，*可选*，默认为12）—变换器编码器中每个注意力层的注意力头数量。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimension of the
    “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size`（`int`，*可选*，默认为3072）—变换器编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act`（`str`或`function`，*可选*，默认为`"gelu"`）—编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob`（`float`，*可选*，默认为0.1）—嵌入层、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, 默认为0.1) — 注意力概率的丢弃比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, 默认为512) — 此模型可能使用的最大序列长度。通常设置为一个较大的值以防万一（例如512、1024或2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids` passed when calling [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    or `TFLayoutLMv2Model`.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, 默认为2) — 在调用[LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)或`TFLayoutLMv2Model`时传递的`token_type_ids`的词汇表大小。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, 默认为0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, 默认为1e-12) — 层归一化层使用的epsilon。'
- en: '`max_2d_position_embeddings` (`int`, *optional*, defaults to 1024) — The maximum
    value that the 2D position embedding might ever be used with. Typically set this
    to something large just in case (e.g., 1024).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_2d_position_embeddings` (`int`, *optional*, 默认为1024) — 2D位置嵌入可能使用的最大值。通常设置为一个较大的值以防万一（例如1024）。'
- en: '`max_rel_pos` (`int`, *optional*, defaults to 128) — The maximum number of
    relative positions to be used in the self-attention mechanism.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_rel_pos` (`int`, *optional*, 默认为128) — 自注意力机制中要使用的相对位置的最大数量。'
- en: '`rel_pos_bins` (`int`, *optional*, defaults to 32) — The number of relative
    position bins to be used in the self-attention mechanism.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rel_pos_bins` (`int`, *optional*, 默认为32) — 自注意力机制中要使用的相对位置桶的数量。'
- en: '`fast_qkv` (`bool`, *optional*, defaults to `True`) — Whether or not to use
    a single matrix for the queries, keys, values in the self-attention layers.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fast_qkv` (`bool`, *optional*, 默认为`True`) — 是否在自注意力层中使用单个矩阵作为查询、键、值。'
- en: '`max_rel_2d_pos` (`int`, *optional*, defaults to 256) — The maximum number
    of relative 2D positions in the self-attention mechanism.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_rel_2d_pos` (`int`, *optional*, 默认为256) — 自注意力机制中使用的相对2D位置的最大数量。'
- en: '`rel_2d_pos_bins` (`int`, *optional*, defaults to 64) — The number of 2D relative
    position bins in the self-attention mechanism.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rel_2d_pos_bins` (`int`, *optional*, 默认为64) — 自注意力机制中的2D相对位置桶的数量。'
- en: '`image_feature_pool_shape` (`List[int]`, *optional*, defaults to [7, 7, 256])
    — The shape of the average-pooled feature map.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_feature_pool_shape` (`List[int]`, *optional*, 默认为[7, 7, 256]) — 平均池化特征图的形状。'
- en: '`coordinate_size` (`int`, *optional*, defaults to 128) — Dimension of the coordinate
    embeddings.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`coordinate_size` (`int`, *optional*, 默认为128) — 坐标嵌入的维度。'
- en: '`shape_size` (`int`, *optional*, defaults to 128) — Dimension of the width
    and height embeddings.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shape_size` (`int`, *optional*, 默认为128) — 宽度和高度嵌入的维度。'
- en: '`has_relative_attention_bias` (`bool`, *optional*, defaults to `True`) — Whether
    or not to use a relative attention bias in the self-attention mechanism.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_relative_attention_bias` (`bool`, *optional*, 默认为`True`) — 是否在自注意力机制中使用相对注意力偏置。'
- en: '`has_spatial_attention_bias` (`bool`, *optional*, defaults to `True`) — Whether
    or not to use a spatial attention bias in the self-attention mechanism.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_spatial_attention_bias` (`bool`, *optional*, 默认为`True`) — 是否在自注意力机制中使用空间注意力偏置。'
- en: '`has_visual_segment_embedding` (`bool`, *optional*, defaults to `False`) —
    Whether or not to add visual segment embeddings.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_visual_segment_embedding` (`bool`, *optional*, 默认为`False`) — 是否添加视觉段嵌入。'
- en: '`detectron2_config_args` (`dict`, *optional*) — Dictionary containing the configuration
    arguments of the Detectron2 visual backbone. Refer to [this file](https://github.com/microsoft/unilm/blob/master/layoutlmft/layoutlmft/models/layoutlmv2/detectron2_config.py)
    for details regarding default values.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detectron2_config_args` (`dict`, *optional*) — 包含Detectron2视觉骨干配置参数的字典。有关默认值的详细信息，请参阅[此文件](https://github.com/microsoft/unilm/blob/master/layoutlmft/layoutlmft/models/layoutlmv2/detectron2_config.py)。'
- en: This is the configuration class to store the configuration of a [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model).
    It is used to instantiate an LayoutLMv2 model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the LayoutLMv2 [microsoft/layoutlmv2-base-uncased](https://huggingface.co/microsoft/layoutlmv2-base-uncased)
    architecture.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)配置的配置类。它用于根据指定的参数实例化一个LayoutLMv2模型，定义模型架构。使用默认值实例化配置将产生类似于LayoutLMv2
    [microsoft/layoutlmv2-base-uncased](https://huggingface.co/microsoft/layoutlmv2-base-uncased)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: LayoutLMv2FeatureExtractor
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2FeatureExtractor
- en: '### `class transformers.LayoutLMv2FeatureExtractor`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2FeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py#L28)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py#L28)'
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#### `__call__`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Preprocess an image or a batch of images.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或一批图像。
- en: LayoutLMv2ImageProcessor
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2ImageProcessor
- en: '### `class transformers.LayoutLMv2ImageProcessor`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2ImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/image_processing_layoutlmv2.py#L93)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/image_processing_layoutlmv2.py#L93)'
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions to `(size["height"], size["width"])`. Can be
    overridden by `do_resize` in `preprocess`.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *可选*, 默认为 `True`) — 是否将图像的 (height, width) 尺寸调整为 `(size["height"],
    size["width"])`。可以被 `preprocess` 中的 `do_resize` 覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 224, "width":
    224}`): Size of the image after resizing. Can be overridden by `size` in `preprocess`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *可选*, 默认为 `{"height" -- 224, "width": 224}`): 调整大小后的图像尺寸。可以被
    `preprocess` 中的 `size` 覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`)
    — Resampling filter to use if resizing the image. Can be overridden by the `resample`
    parameter in the `preprocess` method.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *可选*, 默认为 `Resampling.BILINEAR`) — 用于调整图像大小时使用的重采样滤波器。可以被
    `preprocess` 方法中的 `resample` 参数覆盖。'
- en: '`apply_ocr` (`bool`, *optional*, defaults to `True`) — Whether to apply the
    Tesseract OCR engine to get words + normalized bounding boxes. Can be overridden
    by `apply_ocr` in `preprocess`.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply_ocr` (`bool`, *可选*, 默认为 `True`) — 是否应用 Tesseract OCR 引擎以获取单词 + 规范化边界框。可以被
    `preprocess` 中的 `apply_ocr` 覆盖。'
- en: '`ocr_lang` (`str`, *optional*) — The language, specified by its ISO code, to
    be used by the Tesseract OCR engine. By default, English is used. Can be overridden
    by `ocr_lang` in `preprocess`.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ocr_lang` (`str`, *可选*) — 由其 ISO 代码指定的语言，用于 Tesseract OCR 引擎。默认情况下使用英语。可以被
    `preprocess` 中的 `ocr_lang` 覆盖。'
- en: '`tesseract_config` (`str`, *optional*, defaults to `""`) — Any additional custom
    configuration flags that are forwarded to the `config` parameter when calling
    Tesseract. For example: ‘—psm 6’. Can be overridden by `tesseract_config` in `preprocess`.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tesseract_config` (`str`, *可选*, 默认为 `""`) — 转发到调用 Tesseract 时 `config` 参数的任何额外自定义配置标志。例如:
    ‘—psm 6’。可以被 `preprocess` 中的 `tesseract_config` 覆盖。'
- en: Constructs a LayoutLMv2 image processor.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 LayoutLMv2 图像处理器。
- en: '#### `preprocess`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/image_processing_layoutlmv2.py#L189)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/image_processing_layoutlmv2.py#L189)'
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像。'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *可选*, 默认为 `self.do_resize`) — 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Desired size
    of the output image after resizing.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *可选*, 默认为 `self.size`) — 调整大小后输出图像的期望尺寸。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `self.resample`)
    — Resampling filter to use if resizing the image. This can be one of the enum
    `PIL.Image` resampling filter. Only has an effect if `do_resize` is set to `True`.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *可选*, 默认为 `self.resample`) — 用于调整图像大小时使用的重采样滤波器。可以是枚举
    `PIL.Image` 重采样滤波器之一。仅在 `do_resize` 设置为 `True` 时有效。'
- en: '`apply_ocr` (`bool`, *optional*, defaults to `self.apply_ocr`) — Whether to
    apply the Tesseract OCR engine to get words + normalized bounding boxes.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply_ocr` (`bool`, *可选*, 默认为 `self.apply_ocr`) — 是否应用 Tesseract OCR 引擎以获取单词
    + 规范化边界框。'
- en: '`ocr_lang` (`str`, *optional*, defaults to `self.ocr_lang`) — The language,
    specified by its ISO code, to be used by the Tesseract OCR engine. By default,
    English is used.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ocr_lang` (`str`, *可选*, 默认为 `self.ocr_lang`) — 由其 ISO 代码指定的语言，用于 Tesseract
    OCR 引擎。默认情况下使用英语。'
- en: '`tesseract_config` (`str`, *optional*, defaults to `self.tesseract_config`)
    — Any additional custom configuration flags that are forwarded to the `config`
    parameter when calling Tesseract.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tesseract_config` (`str`, *可选*, 默认为 `self.tesseract_config`) — 转发到调用 Tesseract
    时 `config` 参数的任何额外自定义配置标志。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 `TensorType`, *可选*) — 要返回的张量类型。可以是以下之一：'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '未设置: 返回一个 `np.ndarray` 列表。'
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW` 或 `''tf''`: 返回类型为 `tf.Tensor` 的批处理。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` 或 `''pt''`: 返回类型为 `torch.Tensor` 的批处理。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY` 或 `''np''`: 返回类型为 `np.ndarray` 的批处理。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX` 或 `''jax''`: 返回类型为 `jax.numpy.ndarray` 的批处理。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` 或 `str`, *可选*, 默认为 `ChannelDimension.FIRST`)
    — 输出图像的通道维度格式。可以是以下之一：'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`: 图像格式为 (num_channels, height, width)。'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`: 图像格式为 (height, width, num_channels)。'
- en: Preprocess an image or batch of images.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或一批图像。
- en: LayoutLMv2Tokenizer
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2Tokenizer
- en: '### `class transformers.LayoutLMv2Tokenizer`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2Tokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py#L206)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py#L206)'
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Construct a LayoutLMv2 tokenizer. Based on WordPiece. [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    can be used to turn words, word-level bounding boxes and optional word labels
    to token-level `input_ids`, `attention_mask`, `token_type_ids`, `bbox`, and optional
    `labels` (for token classification).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 LayoutLMv2 分词器。基于 WordPiece。[LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    可用于将单词、单词级边界框和可选单词标签转换为标记级的 `input_ids`、`attention_mask`、`token_type_ids`、`bbox`
    和可选的 `labels`（用于标记分类）。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分词器继承自 [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大部分主要方法。用户应参考这个超类以获取有关这些方法的更多信息。
- en: '[LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    runs end-to-end tokenization: punctuation splitting and wordpiece. It also turns
    the word-level bounding boxes into token-level bounding boxes.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    运行端到端的分词：标点符号拆分和 wordpiece。它还将单词级边界框转换为标记级边界框。'
- en: '#### `__call__`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py#L430)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py#L430)'
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence can be a string, a list of strings (words of a single
    example or questions of a batch of examples) or a list of list of strings (batch
    of words).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`（`str`、`List[str]`、`List[List[str]]`）— 要编码的序列或批次序列。每个序列可以是一个字符串，一个字符串列表（单个示例的单词或一批示例的问题）或一个字符串列表的列表（单词批次）。'
- en: '`text_pair` (`List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence should be a list of strings (pretokenized string).'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair`（`List[str]`、`List[List[str]]`）— 要编码的序列或批次序列。每个序列应该是一个字符串列表（预分词的字符串）。'
- en: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — Word-level bounding
    boxes. Each bounding box should be normalized to be on a 0-1000 scale.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boxes`（`List[List[int]]`、`List[List[List[int]]]`）— 单词级边界框。每个边界框应该被归一化为 0-1000
    的比例。'
- en: '`word_labels` (`List[int]`, `List[List[int]]`, *optional*) — Word-level integer
    labels (for token classification tasks such as FUNSD, CORD).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word_labels`（`List[int]`、`List[List[int]]`，*可选*）— 单词级整数标签（用于标记分类任务，如 FUNSD、CORD）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to encode the sequences with the special tokens relative to their model.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为 `True`）— 是否使用相对于其模型的特殊标记对序列进行编码。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`、`str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为
    `False`）— 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`：填充到批次中最长的序列（如果只提供单个序列，则不进行填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不进行填充（即，可以输出具有不同长度序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`、`str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)，*可选*，默认为
    `False`）— 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`：截断到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。这将逐标记截断，如果提供了一对序列（或一批对序列），则会从较长序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`：截断到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则只会截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`：截断到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则只会截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：不进行截断（即，可以输出具有大于模型最大可接受输入大小的序列长度的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*）— 控制截断/填充参数使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为`None`，则将使用预定义的模型最大长度，如果截断/填充参数之一需要最大长度。如果模型没有特定的最大输入长度（如XLNet），则截断/填充到最大长度将被停用。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为0）— 如果与`max_length`一起设置为一个数字，则当`return_overflowing_tokens=True`时返回的溢出令牌将包含截断序列末尾的一些令牌，以提供截断和溢出序列之间的一些重叠。此参数的值定义重叠令牌的数量。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. This is especially useful to enable the use
    of Tensor Cores on NVIDIA hardware with compute capability `>= 7.5` (Volta).'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of`（`int`，*可选*）— 如果设置，将填充序列到提供的值的倍数。这对于在具有计算能力`>= 7.5`（Volta）的NVIDIA硬件上启用张量核心特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）—
    如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回Numpy `np.ndarray`对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids`（`bool`，*可选*）— 是否返回令牌类型ID。如果保持默认设置，将根据特定分词器的默认值返回令牌类型ID，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 令牌类型ID是什么？
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask`（`bool`，*可选*）— 是否返回注意力蒙版。如果保持默认设置，将根据特定分词器的默认值返回注意力蒙版，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力蒙版是什么？
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens`（`bool`，*可选*，默认为`False`）— 是否返回溢出的令牌序列。如果提供了一对输入ID序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误，而不是返回溢出的令牌。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask`（`bool`，*可选*，默认为`False`）— 是否返回特殊令牌蒙版信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping`（`bool`，*可选*，默认为`False`）— 是否返回每个令牌的`(char_start, char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length`（`bool`，*可选*，默认为`False`）— 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose`（`bool`，*可选*，默认为`True`）— 是否打印更多信息和警告。**kwargs — 传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要馈送到模型的令牌ID列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入ID是什么？
- en: '`bbox` — List of bounding boxes to be fed to a model.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` — 要馈送到模型的边界框列表。'
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要馈送到模型的令牌类型ID列表（当`return_token_type_ids=True`或*“token_type_ids”*在`self.model_input_names`中时）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 令牌类型ID是什么？
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定哪些令牌应该被模型关注的索引列表（当`return_attention_mask=True`或*“attention_mask”*在`self.model_input_names`中时）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力蒙版是什么？
- en: '`labels` — List of labels to be fed to a model. (when `word_labels` is specified).'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` — 要馈送到模型的标签列表（当指定`word_labels`时）。'
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出令牌序列的列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 截断的标记数（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 由0和1组成的列表，其中1指定添加的特殊标记，0指定常规序列标记（当`add_special_tokens=True`和`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）。'
- en: Main method to tokenize and prepare for the model one or several sequence(s)
    or one or several pair(s) of sequences with word-level normalized bounding boxes
    and optional labels.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个或多个序列或一个或多个序列对进行标记化和为模型准备，具有单词级别标准化边界框和可选标签。
- en: '#### `save_vocabulary`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py#L410)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py#L410)'
- en: '[PRE17]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: LayoutLMv2TokenizerFast
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2TokenizerFast
- en: '### `class transformers.LayoutLMv2TokenizerFast`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2TokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py#L70)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py#L70)'
- en: '[PRE18]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — File containing the vocabulary.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 包含词汇表的文件。'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — 在标记化时是否将输入转换为小写。'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — 未知标记。词汇表中不存在的标记无法转换为ID，而是设置为此标记。'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — 分隔符标记，在从多个序列构建序列时使用，例如用于序列分类的两个序列或用于文本和问题的问题回答。它也用作使用特殊标记构建的序列的最后一个标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — 在进行序列分类（对整个序列而不是每个标记进行分类）时使用的分类器标记。当使用特殊标记构建序列时，它是序列的第一个标记。'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — 用于屏蔽值的标记。在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: '`cls_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [CLS] token.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — 用于特殊[CLS]标记的边界框。'
- en: '`sep_token_box` (`List[int]`, *optional*, defaults to `[1000, 1000, 1000, 1000]`)
    — The bounding box to use for the special [SEP] token.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token_box` (`List[int]`, *optional*, defaults to `[1000, 1000, 1000, 1000]`)
    — 用于特殊[SEP]标记的边界框。'
- en: '`pad_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [PAD] token.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — 用于特殊[PAD]标记的边界框。'
- en: '`pad_token_label` (`int`, *optional*, defaults to -100) — The label to use
    for padding tokens. Defaults to -100, which is the `ignore_index` of PyTorch’s
    CrossEntropyLoss.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_label` (`int`, *optional*, defaults to -100) — 用于填充标记的标签。默认为-100，这是PyTorch的CrossEntropyLoss的`ignore_index`。'
- en: '`only_label_first_subword` (`bool`, *optional*, defaults to `True`) — Whether
    or not to only label the first subword, in case word labels are provided.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`only_label_first_subword` (`bool`, *optional*, defaults to `True`) — 是否仅标记第一个子词，如果提供了单词标签。'
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — Whether
    or not to tokenize Chinese characters. This should likely be deactivated for Japanese
    (see [this issue](https://github.com/huggingface/transformers/issues/328)).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — 是否标记化中文字符。这可能应该在日语中停用（参见[此问题](https://github.com/huggingface/transformers/issues/328)）。'
- en: '`strip_accents` (`bool`, *optional*) — Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original LayoutLMv2).'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strip_accents` (`bool`, *optional*) — 是否去除所有重音符号。如果未指定此选项，则将由`lowercase`的值确定（与原始LayoutLMv2中的情况相同）。'
- en: Construct a “fast” LayoutLMv2 tokenizer (backed by HuggingFace’s *tokenizers*
    library). Based on WordPiece.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个“快速”LayoutLMv2分词器（由HuggingFace的*tokenizers*库支持）。基于WordPiece。
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 此分词器继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `__call__`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py#L179)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py#L179)'
- en: '[PRE19]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence can be a string, a list of strings (words of a single
    example or questions of a batch of examples) or a list of list of strings (batch
    of words).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]`, `List[List[str]]`) — 要编码的序列或序列批次。每个序列可以是一个字符串，一个字符串列表（单个示例的单词或一批示例的问题）或一个字符串列表的列表（单词批次）。'
- en: '`text_pair` (`List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence should be a list of strings (pretokenized string).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`List[str]`, `List[List[str]]`) — 要编码的序列或序列批次。每个序列应该是一个字符串列表（预标记化字符串）。'
- en: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — Word-level bounding
    boxes. Each bounding box should be normalized to be on a 0-1000 scale.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — 单词级别的边界框。每个边界框应标准化为0-1000的比例。'
- en: '`word_labels` (`List[int]`, `List[List[int]]`, *optional*) — Word-level integer
    labels (for token classification tasks such as FUNSD, CORD).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word_labels` (`List[int]`, `List[List[int]]`, *optional*) — 单词级别的整数标签（用于诸如FUNSD、CORD等标记分类任务）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to encode the sequences with the special tokens relative to their model.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`, *optional*, 默认为`True`) — 是否使用相对于其模型的特殊标记对序列进行编码。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, 默认为`False`) — 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 填充到由参数`max_length`指定的最大长度，或者如果未提供该参数，则填充到模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）: 不填充（即，可以输出具有不同长度的序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, 默认为`False`) — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`: 截断到由参数`max_length`指定的最大长度，或者如果未提供该参数，则截断到模型的最大可接受输入长度。这将逐标记截断，如果提供了一对序列（或一批序列），则从较长序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 截断到由参数`max_length`指定的最大长度，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 截断到由参数`max_length`指定的最大长度，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则仅截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）: 不截断（即，可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *optional*) — 控制截断/填充参数使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为`None`，则如果截断/填充参数中的一个需要最大长度，则将使用预定义的模型最大长度。如果模型没有特定的最大输入长度（如XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`, *optional*, 默认为0) — 如果设置为一个数字，并且与`max_length`一起使用，当`return_overflowing_tokens=True`时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。此参数的值定义了重叠标记的数量。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. This is especially useful to enable the use
    of Tensor Cores on NVIDIA hardware with compute capability `>= 7.5` (Volta).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *optional*) — 如果设置，将填充序列到提供的值的倍数。这对于在具有计算能力`>=
    7.5`（Volta）的NVIDIA硬件上启用Tensor Cores特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）—
    如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回 PyTorch `torch.Tensor` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回 Numpy `np.ndarray` 对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids`（`bool`，*可选*）— 是否返回令牌类型ID。如果保持默认设置，将根据特定分词器的默认设置返回令牌类型ID，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是令牌类型ID？](../glossary#token-type-ids)'
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask`（`bool`，*可选*）— 是否返回注意力掩码。如果保持默认设置，将根据特定分词器的默认设置返回注意力掩码，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens`（`bool`，*可选*，默认为`False`）— 是否返回溢出的令牌序列。如果提供一对输入id序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误，而不是返回溢出的令牌。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask`（`bool`，*可选*，默认为`False`）— 是否返回特殊令牌掩码信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping`（`bool`，*可选*，默认为`False`）— 是否返回每个令牌的`(char_start, char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length`（`bool`，*可选*，默认为`False`）— 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose`（`bool`，*可选*，默认为`True`）— 是否打印更多信息和警告。**kwargs — 传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一个带有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要提供给模型的令牌id列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`bbox` — List of bounding boxes to be fed to a model.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` — 要提供给模型的边界框列表。'
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要提供给模型的令牌类型id列表（当`return_token_type_ids=True`或者`self.model_input_names`中包含*“token_type_ids”*时）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是令牌类型ID？](../glossary#token-type-ids)'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定哪些令牌应该被模型关注的索引列表（当`return_attention_mask=True`或者`self.model_input_names`中包含*“attention_mask”*时）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`labels` — List of labels to be fed to a model. (when `word_labels` is specified).'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` — 要提供给模型的标签列表（当指定`word_labels`时）。'
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出的令牌序列列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 截断的令牌数量（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 由0和1组成的列表，其中1指定添加的特殊令牌，0指定常规序列令牌（当`add_special_tokens=True`并且`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）。'
- en: Main method to tokenize and prepare for the model one or several sequence(s)
    or one or several pair(s) of sequences with word-level normalized bounding boxes
    and optional labels.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个或多个序列或一个或多个序列对进行分词和准备模型，其中包含单词级别的归一化边界框和可选标签。
- en: LayoutLMv2Processor
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2Processor
- en: '### `class transformers.LayoutLMv2Processor`'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2Processor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/processing_layoutlmv2.py#L27)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/processing_layoutlmv2.py#L27)'
- en: '[PRE20]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` (`LayoutLMv2ImageProcessor`, *optional*) — An instance of
    [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor).
    The image processor is a required input.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor`（`LayoutLMv2ImageProcessor`，*可选*）— [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)的实例。图像处理器是必需的输入。'
- en: '`tokenizer` (`LayoutLMv2Tokenizer` or `LayoutLMv2TokenizerFast`, *optional*)
    — An instance of [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    or [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast).
    The tokenizer is a required input.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`LayoutLMv2Tokenizer`或`LayoutLMv2TokenizerFast`，*可选*）— [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)或[LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast)的实例。标记器是必需的输入。'
- en: Constructs a LayoutLMv2 processor which combines a LayoutLMv2 image processor
    and a LayoutLMv2 tokenizer into a single processor.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个LayoutLMv2处理器，将LayoutLMv2图像处理器和LayoutLMv2标记器合并为一个单一处理器。
- en: '[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    offers all the functionalities you need to prepare data for the model.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)提供了准备模型数据所需的所有功能。'
- en: It first uses [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    to resize document images to a fixed size, and optionally applies OCR to get words
    and normalized bounding boxes. These are then provided to [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    or [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast),
    which turns the words and bounding boxes into token-level `input_ids`, `attention_mask`,
    `token_type_ids`, `bbox`. Optionally, one can provide integer `word_labels`, which
    are turned into token-level `labels` for token classification tasks (such as FUNSD,
    CORD).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先使用[LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)将文档图像调整为固定大小，并可选择应用OCR以获取单词和归一化边界框。然后将它们提供给[LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)或[LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast)，将单词和边界框转换为标记级别的`input_ids`、`attention_mask`、`token_type_ids`、`bbox`。可选地，可以提供整数`word_labels`，这些标签将转换为用于标记分类任务（如FUNSD、CORD）的标记级别`labels`。
- en: '#### `__call__`'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/processing_layoutlmv2.py#L69)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/processing_layoutlmv2.py#L69)'
- en: '[PRE21]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This method first forwards the `images` argument to [**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__).
    In case [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    was initialized with `apply_ocr` set to `True`, it passes the obtained words and
    bounding boxes along with the additional arguments to [**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer.__call__)
    and returns the output, together with resized `images`. In case [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    was initialized with `apply_ocr` set to `False`, it passes the words (`text`/`text_pair`)
    and `boxes` specified by the user along with the additional arguments to [__call__()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer.__call__)
    and returns the output, together with resized `images`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法首先将`images`参数转发到[**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。如果[LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)初始化时`apply_ocr`设置为`True`，它将获取的单词和边界框连同其他参数传递给[**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer.__call__)并返回输出，以及调整大小后的`images`。如果[LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)初始化时`apply_ocr`设置为`False`，它将用户指定的单词（`text`/`text_pair`）和`boxes`连同其他参数传递给[__call__()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer.__call__)并返回输出，以及调整大小后的`images`。
- en: Please refer to the docstring of the above two methods for more information.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考上述两个方法的文档字符串以获取更多信息。
- en: LayoutLMv2Model
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2Model
- en: '### `class transformers.LayoutLMv2Model`'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L688)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L688)'
- en: '[PRE22]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare LayoutLMv2 Model transformer outputting raw hidden-states without any
    specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的LayoutLMv2模型变换器，输出没有特定头部的原始隐藏状态。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L802)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L802)'
- en: '[PRE23]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `((batch_size, sequence_length), 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor` of shape `((batch_size, sequence_length), 4)`, *optional*)
    — 每个输入序列标记的边界框。选择范围在`[0, config.max_2d_position_embeddings-1]`内。每个边界框应该是(x0, y0,
    x1, y1)格式的归一化版本，其中(x0, y0)对应于边界框左上角的位置，(x1, y1)表示右下角的位置。'
- en: '`image` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`
    or `detectron.structures.ImageList` whose `tensors` is of shape `(batch_size,
    num_channels, height, width)`) — Batch of document images.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`
    或 `detectron.structures.ImageList`，其`tensors`的形状为`(batch_size, num_channels, height,
    width)`) — 文档图像的批处理。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于避免在填充标记索引上执行注意力的掩码。选择在`[0, 1]`范围内的掩码值：'
- en: 1 for tokens that are `not masked`,
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对于未被`masked`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 指示输入的第一部分和第二部分的段标记索引。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。选择范围在`[0, config.max_position_embeddings - 1]`内。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块中的特定头部失效的掩码。选择在`[0, 1]`范围内的掩码值：'
- en: 1 indicates the head is `not masked`,
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将*input_ids*索引转换为相关向量，则这很有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    and inputs.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含各种元素，取决于配置（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）和输入。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层的隐藏状态序列。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *可选的*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    forward method, overrides the `__call__` special method.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在这个函数内定义，但应该在之后调用`Module`实例，而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE24]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: LayoutLMv2ForSequenceClassification
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2ForSequenceClassification
- en: '### `class transformers.LayoutLMv2ForSequenceClassification`'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2ForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L944)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L944)'
- en: '[PRE25]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: LayoutLMv2 Model with a sequence classification head on top (a linear layer
    on top of the concatenation of the final hidden state of the [CLS] token, average-pooled
    initial visual embeddings and average-pooled final visual embeddings, e.g. for
    document image classification tasks such as the [RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)
    dataset.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMv2模型，顶部带有一个序列分类头（在[CLS]标记的最终隐藏状态、平均池化的初始视觉嵌入和平均池化的最终视觉嵌入的串联之上的线性层，例如用于文档图像分类任务，如[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)数据集。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L967)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L967)'
- en: '[PRE26]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`) — Indices
    of input sequence tokens in the vocabulary.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`batch_size, sequence_length`) — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — 每个输入序列标记的边界框。选择范围为 `[0, config.max_2d_position_embeddings-1]`。每个边界框应该是 (x0,
    y0, x1, y1) 格式的归一化版本，其中 (x0, y0) 对应于边界框左上角的位置，而 (x1, y1) 表示右下角的位置。'
- en: '`image` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`
    or `detectron.structures.ImageList` whose `tensors` is of shape `(batch_size,
    num_channels, height, width)`) — Batch of document images.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`
    或 `detectron.structures.ImageList`，其 `tensors` 的形状为 `(batch_size, num_channels,
    height, width)`) — 文档图像的批处理。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `batch_size, sequence_length`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `batch_size, sequence_length`,
    *optional*) — 避免在填充标记索引上执行注意力的掩码。掩码值选择在 `[0, 1]` 范围内：'
- en: 1 for tokens that are `not masked`,
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被遮蔽的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被遮蔽的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — 段标记索引，指示输入的第一部分和第二部分。索引选择在 `[0, 1]` 范围内：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。选择范围为 `[0, config.max_position_embeddings -
    1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置 ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块中的特定头部失效的掩码。掩码值选择在 `[0, 1]` 范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-359
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-360
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被遮蔽。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将
    *input_ids* 索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss
    is computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — 用于计算序列分类/回归损失的标签。索引应在
    `[0, ..., config.num_labels - 1]` 范围内。如果 `config.num_labels == 1`，则计算回归损失（均方损失），如果
    `config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    and inputs.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含根据配置（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）和输入而异的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供 `labels` 时返回)
    — 分类（或如果 config.num_labels==1 则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE27]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: LayoutLMv2ForTokenClassification
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2ForTokenClassification
- en: '### `class transformers.LayoutLMv2ForTokenClassification`'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2ForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1126)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1126)'
- en: '[PRE28]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: LayoutLMv2 Model with a token classification head on top (a linear layer on
    top of the text part of the hidden states) e.g. for sequence labeling (information
    extraction) tasks such as [FUNSD](https://guillaumejaume.github.io/FUNSD/), [SROIE](https://rrc.cvc.uab.es/?ch=13),
    [CORD](https://github.com/clovaai/cord) and [Kleister-NDA](https://github.com/applicaai/kleister-nda).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在LayoutLMv2模型的顶部具有标记分类头部（隐藏状态的文本部分上的线性层）的模型，例如用于序列标记（信息提取）任务的[FUNSD](https://guillaumejaume.github.io/FUNSD/)、[SROIE](https://rrc.cvc.uab.es/?ch=13)、[CORD](https://github.com/clovaai/cord)和[Kleister-NDA](https://github.com/applicaai/kleister-nda)。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1149)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1149)'
- en: '[PRE29]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`) — Indices
    of input sequence tokens in the vocabulary.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`) — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — 每个输入序列标记的边界框。选择范围为`[0, config.max_2d_position_embeddings-1]`。每个边界框应该是一个规范化版本，格式为(x0,
    y0, x1, y1)，其中(x0, y0)对应于边界框左上角的位置，(x1, y1)表示右下角的位置。'
- en: '`image` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`
    or `detectron.structures.ImageList` whose `tensors` is of shape `(batch_size,
    num_channels, height, width)`) — Batch of document images.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`torch.FloatTensor`，形状为`(batch_size, num_channels, height, width)`或`detectron.structures.ImageList`，其`tensors`形状为`(batch_size,
    num_channels, height, width)`）— 批量文档图像。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `batch_size, sequence_length`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（`torch.FloatTensor`，形状为`batch_size, sequence_length`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是注意力掩码？
- en: '`token_type_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（`torch.LongTensor`，形状为`batch_size, sequence_length`，*可选*）—
    段标记索引，用于指示输入的第一部分和第二部分。索引选在`[0, 1]`之间：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于*句子A*的标记。
- en: 1 corresponds to a *sentence B* token.
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于*句子B*的标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是标记类型ID？
- en: '`position_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（`torch.LongTensor`，形状为`batch_size, sequence_length`，*可选*）— 每个输入序列标记在位置嵌入中的位置索引。在范围`[0,
    config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是位置ID？
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*可选*）—
    用于使自注意力模块的选定头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被`masked`。
- en: 0 indicates the head is `masked`.
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被`masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*）—
    可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将*input_ids*索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the token classification loss. Indices should be in `[0,
    ..., config.num_labels - 1]`.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*）— 用于计算标记分类损失的标签。索引应在`[0,
    ..., config.num_labels - 1]`之间。'
- en: Returns
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)或`tuple(torch.FloatTensor)`。'
- en: A [transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    and inputs.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时），包括根据配置（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification loss.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回）— 分类损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    — Classification scores (before SoftMax).'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.num_labels)`）—
    分类分数（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出之一，+
    每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE30]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: LayoutLMv2ForQuestionAnswering
  id: totrans-427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv2ForQuestionAnswering
- en: '### `class transformers.LayoutLMv2ForQuestionAnswering`'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv2ForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1258)'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1258)'
- en: '[PRE31]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: LayoutLMv2 Model with a span classification head on top for extractive question-answering
    tasks such as [DocVQA](https://rrc.cvc.uab.es/?ch=17) (a linear layer on top of
    the text part of the hidden-states output to compute `span start logits` and `span
    end logits`).
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMv2模型，在其顶部具有用于提取问答任务的跨度分类头，例如[DocVQA](https://rrc.cvc.uab.es/?ch=17)（在隐藏状态输出的文本部分顶部的线性层，用于计算`跨度起始对数`和`跨度结束对数`）。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1280)'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv2/modeling_layoutlmv2.py#L1280)'
- en: '[PRE32]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`) — Indices
    of input sequence tokens in the vocabulary.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`batch_size, sequence_length`的`torch.LongTensor`） — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox`（形状为`(batch_size, sequence_length, 4)`的`torch.LongTensor`，*可选*） — 每个输入序列标记的边界框。在范围`[0,
    config.max_2d_position_embeddings-1]`中选择。每个边界框应该是(x0, y0, x1, y1)格式的归一化版本，其中(x0,
    y0)对应于边界框左上角的位置，而(x1, y1)表示边界框右下角的位置。'
- en: '`image` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`
    or `detectron.structures.ImageList` whose `tensors` is of shape `(batch_size,
    num_channels, height, width)`) — Batch of document images.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`或`detectron.structures.ImageList`，其`tensors`的形状为`(batch_size,
    num_channels, height, width)`） — 文档图像的批处理。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `batch_size, sequence_length`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`batch_size, sequence_length`的`torch.FloatTensor`，*可选*）
    — 避免在填充标记索引上执行注意力的蒙版。蒙版值选择在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`掩码`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`掩码`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力蒙版？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`batch_size, sequence_length`的`torch.LongTensor`，*可选*）
    — 指示输入的第一部分和第二部分的段标记索引。索引选择在`[0, 1]`中：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*的标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-450
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `batch_size, sequence_length`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为 `batch_size, sequence_length`，*可选*)
    — 每个输入序列标记在位置嵌入中的位置索引。在范围 `[0, config.max_position_embeddings - 1]` 中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块的选定头部无效的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-456
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被`masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*可选*)
    — 可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制如何将 *input_ids* 索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是一个普通元组。'
- en: '`start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    — Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start_positions` (`torch.LongTensor`，形状为 `(batch_size,)`，*可选*) — 用于计算标记跨度起始位置的位置（索引）的标签，以计算标记分类损失。位置被夹紧到序列的长度
    (`sequence_length`)。超出序列范围的位置不会被考虑在内以计算损失。'
- en: '`end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) —
    Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end_positions` (`torch.LongTensor`，形状为 `(batch_size,)`，*可选*) — 用于计算标记跨度结束位置的位置（索引）的标签，以计算标记分类损失。位置被夹紧到序列的长度
    (`sequence_length`)。超出序列范围的位置不会被考虑在内以计算损失。'
- en: Returns
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config))
    and inputs.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含根据配置（[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Total span extraction loss is the sum of a Cross-Entropy for the
    start and end positions.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`损失` (`torch.FloatTensor`，形状为 `(1,)`，*可选*，当提供`labels`时返回) — 总跨度抽取损失是起始位置和结束位置的交叉熵之和。'
- en: '`start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Span-start scores (before SoftMax).'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start_logits` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length)`) —
    跨度起始分数（SoftMax之前）。'
- en: '`end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Span-end scores (before SoftMax).'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end_logits` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length)`) — 跨度结束分数（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递 `output_hidden_states=True`
    或当 `config.output_hidden_states=True` 时返回） — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组（如果模型具有嵌入层，则为嵌入的输出 + 每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *可选*，当传递 `output_attentions=True`
    或当 `config.output_attentions=True` 时返回) — 形状为 `(batch_size, num_heads, sequence_length,
    sequence_length)` 的 `torch.FloatTensor` 元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力权重在注意力 softmax 之后，用于计算自注意力头中的加权平均值。
- en: The [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在之后调用 `Module` 实例而不是这个函数，因为前者会处理运行前后的处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: In this example below, we give the LayoutLMv2 model an image (of texts) and
    ask it a question. It will give us a prediction of what it thinks the answer is
    (the span of the answer within the texts parsed from the image).
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们给 LayoutLMv2 模型一个图像（包含文本）并向其提问。它会给出一个预测，即它认为答案在从图像中解析的文本中的位置。
- en: '[PRE33]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
