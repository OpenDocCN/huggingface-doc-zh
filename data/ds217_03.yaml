- en: Quickstart
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¿«é€Ÿå…¥é—¨
- en: 'Original text: [https://huggingface.co/docs/datasets/quickstart](https://huggingface.co/docs/datasets/quickstart)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŽŸæ–‡ï¼š[https://huggingface.co/docs/datasets/quickstart](https://huggingface.co/docs/datasets/quickstart)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This quickstart is intended for developers who are ready to dive into the code
    and see an example of how to integrate ðŸ¤— Datasets into their model training workflow.
    If youâ€™re a beginner, we recommend starting with our [tutorials](./tutorial),
    where youâ€™ll get a more thorough introduction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå¿«é€Ÿå…¥é—¨æŒ‡å—é€‚ç”¨äºŽå‡†å¤‡æ·±å…¥ä»£ç å¹¶æŸ¥çœ‹å¦‚ä½•å°†ðŸ¤—æ•°æ®é›†é›†æˆåˆ°æ¨¡åž‹è®­ç»ƒå·¥ä½œæµç¨‹ä¸­çš„å¼€å‘äººå‘˜ã€‚å¦‚æžœæ‚¨æ˜¯åˆå­¦è€…ï¼Œæˆ‘ä»¬å»ºè®®ä»Žæˆ‘ä»¬çš„[æ•™ç¨‹](./tutorial)å¼€å§‹ï¼Œé‚£é‡Œæ‚¨å°†å¾—åˆ°æ›´å…¨é¢çš„ä»‹ç»ã€‚
- en: Each dataset is unique, and depending on the task, some datasets may require
    additional steps to prepare it for training. But you can always use ðŸ¤— Datasets
    tools to load and process a dataset. The fastest and easiest way to get started
    is by loading an existing dataset from the [Hugging Face Hub](https://huggingface.co/datasets).
    There are thousands of datasets to choose from, spanning many tasks. Choose the
    type of dataset you want to work with, and letâ€™s get started!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ•°æ®é›†éƒ½æ˜¯ç‹¬ç‰¹çš„ï¼Œæ ¹æ®ä»»åŠ¡çš„ä¸åŒï¼Œä¸€äº›æ•°æ®é›†å¯èƒ½éœ€è¦é¢å¤–çš„æ­¥éª¤æ¥å‡†å¤‡è®­ç»ƒã€‚ä½†æ‚¨å§‹ç»ˆå¯ä»¥ä½¿ç”¨ðŸ¤— æ•°æ®é›†å·¥å…·æ¥åŠ è½½å’Œå¤„ç†æ•°æ®é›†ã€‚å¼€å§‹çš„æœ€å¿«æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä»Ž[Hugging
    Face Hub](https://huggingface.co/datasets)åŠ è½½çŽ°æœ‰æ•°æ®é›†ã€‚æœ‰æˆåƒä¸Šä¸‡ä¸ªæ•°æ®é›†å¯ä¾›é€‰æ‹©ï¼Œæ¶µç›–è®¸å¤šä»»åŠ¡ã€‚é€‰æ‹©æ‚¨æƒ³è¦å¤„ç†çš„æ•°æ®é›†ç±»åž‹ï¼Œç„¶åŽè®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: '[Audio'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[éŸ³é¢‘'
- en: Resample an audio dataset and get it ready for a model to classify what type
    of banking issue a speaker is calling about.](#audio) [Vision
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹éŸ³é¢‘æ•°æ®é›†è¿›è¡Œé‡é‡‡æ ·ï¼Œå¹¶ä¸ºæ¨¡åž‹å‡†å¤‡å¥½ä»¥åˆ†ç±»è¯´è¯è€…æ­£åœ¨è¯¢é—®çš„é“¶è¡Œé—®é¢˜ç±»åž‹ã€‚](#audio) [è§†è§‰
- en: Apply data augmentation to an image dataset and get it ready for a model to
    diagnose disease in bean plants.](#vision) [NLP
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹å›¾åƒæ•°æ®é›†åº”ç”¨æ•°æ®å¢žå¼ºï¼Œå¹¶ä¸ºæ¨¡åž‹å‡†å¤‡å¥½ä»¥è¯Šæ–­è±†ç±»æ¤ç‰©ç–¾ç—…ã€‚](#vision) [NLP
- en: Tokenize a dataset and get it ready for a model to determine whether a pair
    of sentences have the same meaning.](#nlp)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ•°æ®é›†è¿›è¡Œæ ‡è®°åŒ–å¤„ç†ï¼Œå¹¶ä¸ºæ¨¡åž‹å‡†å¤‡å¥½ä»¥ç¡®å®šä¸€å¯¹å¥å­æ˜¯å¦å…·æœ‰ç›¸åŒçš„å«ä¹‰ã€‚](#nlp)
- en: Check out [Chapter 5](https://huggingface.co/course/chapter5/1?fw=pt) of the
    Hugging Face course to learn more about other important topics such as loading
    remote or local datasets, tools for cleaning up a dataset, and creating your own
    dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ [Hugging Face è¯¾ç¨‹](https://huggingface.co/course/chapter5/1?fw=pt) çš„ç¬¬ 5 ç« ï¼Œäº†è§£æ›´å¤šå…³äºŽåŠ è½½è¿œç¨‹æˆ–æœ¬åœ°æ•°æ®é›†ã€æ¸…ç†æ•°æ®é›†çš„å·¥å…·ä»¥åŠåˆ›å»ºè‡ªå·±çš„æ•°æ®é›†ç­‰å…¶ä»–é‡è¦ä¸»é¢˜ã€‚
- en: 'Start by installing ðŸ¤— Datasets:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆå®‰è£…ðŸ¤— æ•°æ®é›†ï¼š
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'ðŸ¤— Datasets also support audio and image data formats:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ðŸ¤— æ•°æ®é›†è¿˜æ”¯æŒéŸ³é¢‘å’Œå›¾åƒæ•°æ®æ ¼å¼ï¼š
- en: 'To work with audio datasets, install the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¦å¤„ç†éŸ³é¢‘æ•°æ®é›†ï¼Œè¯·å®‰è£… [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    åŠŸèƒ½ï¼š
- en: '[PRE1]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To work with image datasets, install the [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    feature:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¦å¤„ç†å›¾åƒæ•°æ®é›†ï¼Œè¯·å®‰è£… [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    åŠŸèƒ½ï¼š
- en: '[PRE2]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Besides ðŸ¤— Datasets, make sure your preferred machine learning framework is
    installed:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†ðŸ¤— æ•°æ®é›†ä¹‹å¤–ï¼Œç¡®ä¿æ‚¨å–œæ¬¢çš„æœºå™¨å­¦ä¹ æ¡†æž¶å·²å®‰è£…ï¼š
- en: PytorchHide Pytorch content
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè— Pytorch å†…å®¹
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: TensorFlowHide TensorFlow content
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè— TensorFlow å†…å®¹
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Audio
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éŸ³é¢‘
- en: Audio datasets are loaded just like text datasets. However, an audio dataset
    is preprocessed a bit differently. Instead of a tokenizer, youâ€™ll need a [feature
    extractor](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor).
    An audio input may also require resampling its sampling rate to match the sampling
    rate of the pretrained model youâ€™re using. In this quickstart, youâ€™ll prepare
    the [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) dataset for a model
    train on and classify the banking issue a customer is having.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: éŸ³é¢‘æ•°æ®é›†çš„åŠ è½½æ–¹å¼ä¸Žæ–‡æœ¬æ•°æ®é›†ç›¸åŒã€‚ä½†æ˜¯ï¼ŒéŸ³é¢‘æ•°æ®é›†çš„é¢„å¤„ç†æ–¹å¼ç•¥æœ‰ä¸åŒã€‚æ‚¨å°†éœ€è¦ä¸€ä¸ª [ç‰¹å¾æå–å™¨](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)
    è€Œä¸æ˜¯æ ‡è®°åŒ–å™¨ã€‚éŸ³é¢‘è¾“å…¥å¯èƒ½è¿˜éœ€è¦é‡æ–°é‡‡æ ·å…¶é‡‡æ ·çŽ‡ä»¥åŒ¹é…æ‚¨æ­£åœ¨ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡åž‹çš„é‡‡æ ·çŽ‡ã€‚åœ¨è¿™ä¸ªå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæ‚¨å°†å‡†å¤‡[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)
    æ•°æ®é›†ï¼Œç”¨äºŽè®­ç»ƒæ¨¡åž‹å¹¶å¯¹å®¢æˆ·é‡åˆ°çš„é“¶è¡Œé—®é¢˜è¿›è¡Œåˆ†ç±»ã€‚
- en: '**1**. Load the MInDS-14 dataset by providing the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function with the dataset name, dataset configuration (not all datasets will have
    a configuration), and a dataset split:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**. é€šè¿‡å‘ [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    å‡½æ•°æä¾›æ•°æ®é›†åç§°ã€æ•°æ®é›†é…ç½®ï¼ˆå¹¶éžæ‰€æœ‰æ•°æ®é›†éƒ½æœ‰é…ç½®ï¼‰å’Œæ•°æ®é›†æ‹†åˆ†æ¥åŠ è½½ MInDS-14 æ•°æ®é›†ï¼š'
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**2**. Next, load a pretrained [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)
    model and its corresponding feature extractor from the [ðŸ¤— Transformers](https://huggingface.co/transformers/)
    library. It is totally normal to see a warning after you load the model about
    some weights not being initialized. This is expected because you are loading this
    model checkpoint for training with another task.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**2**. æŽ¥ä¸‹æ¥ï¼ŒåŠ è½½é¢„è®­ç»ƒçš„ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)
    æ¨¡åž‹åŠå…¶å¯¹åº”çš„ç‰¹å¾æå–å™¨ï¼Œæ¥è‡ª [ðŸ¤— Transformers](https://huggingface.co/transformers/) åº“ã€‚åœ¨åŠ è½½æ¨¡åž‹åŽçœ‹åˆ°ä¸€äº›æƒé‡æœªåˆå§‹åŒ–çš„è­¦å‘Šæ˜¯æ­£å¸¸çš„ã€‚è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºæ‚¨æ­£åœ¨åŠ è½½æ­¤æ¨¡åž‹æ£€æŸ¥ç‚¹ä»¥ç”¨äºŽå¦ä¸€ä¸ªä»»åŠ¡çš„è®­ç»ƒã€‚'
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**3**. The [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) dataset
    card indicates the sampling rate is 8kHz, but the Wav2Vec2 model was pretrained
    on a sampling rate of 16kHZ. Youâ€™ll need to upsample the `audio` column with the
    [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    function and [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature to match the modelâ€™s sampling rate.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**3**. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) æ•°æ®é›†å¡ç‰‡æ˜¾ç¤ºé‡‡æ ·çŽ‡ä¸º
    8kHzï¼Œä½† Wav2Vec2 æ¨¡åž‹æ˜¯åœ¨ 16kHZ é‡‡æ ·çŽ‡ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„ã€‚æ‚¨éœ€è¦ä½¿ç”¨ [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    å‡½æ•°å’Œ [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    åŠŸèƒ½å¯¹ `audio` åˆ—è¿›è¡Œä¸Šé‡‡æ ·ï¼Œä»¥åŒ¹é…æ¨¡åž‹çš„é‡‡æ ·çŽ‡ã€‚'
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**4**. Create a function to preprocess the audio `array` with the feature extractor,
    and truncate and pad the sequences into tidy rectangular tensors. The most important
    thing to remember is to call the audio `array` in the feature extractor since
    the `array` - the actual speech signal - is the model input.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**4**. åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨ç‰¹å¾æå–å™¨é¢„å¤„ç†éŸ³é¢‘`array`ï¼Œå¹¶å°†åºåˆ—æˆªæ–­å’Œå¡«å……ä¸ºæ•´æ´çš„çŸ©å½¢å¼ é‡ã€‚æœ€é‡è¦çš„æ˜¯è¦è®°ä½åœ¨ç‰¹å¾æå–å™¨ä¸­è°ƒç”¨éŸ³é¢‘`array`ï¼Œå› ä¸º`array`
    - å®žé™…è¯­éŸ³ä¿¡å· - æ˜¯æ¨¡åž‹è¾“å…¥ã€‚'
- en: Once you have a preprocessing function, use the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function to speed up processing by applying the function to batches of examples
    in the dataset.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨æœ‰ä¸€ä¸ªé¢„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)å‡½æ•°ï¼Œé€šè¿‡å°†å‡½æ•°åº”ç”¨äºŽæ•°æ®é›†ä¸­çš„ç¤ºä¾‹æ‰¹æ¬¡æ¥åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**5**. Use the [rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)
    function to rename the `intent_class` column to `labels`, which is the expected
    input name in [Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**5**. ä½¿ç”¨[rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)å‡½æ•°å°†`intent_class`åˆ—é‡å‘½åä¸º`labels`ï¼Œè¿™æ˜¯[Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)ä¸­é¢„æœŸçš„è¾“å…¥åç§°ï¼š'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**6**. Set the dataset format according to the machine learning framework youâ€™re
    using.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**6**. æ ¹æ®æ‚¨æ­£åœ¨ä½¿ç”¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶è®¾ç½®æ•°æ®é›†æ ¼å¼ã€‚'
- en: PytorchHide Pytorch content
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: 'Use the [set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)
    function to set the dataset format to `torch` and specify the columns you want
    to format. This function applies formatting on-the-fly. After converting to PyTorch
    tensors, wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)å‡½æ•°å°†æ•°æ®é›†æ ¼å¼è®¾ç½®ä¸º`torch`ï¼Œå¹¶æŒ‡å®šè¦æ ¼å¼åŒ–çš„åˆ—ã€‚æ­¤å‡½æ•°ä¼šå®žæ—¶åº”ç”¨æ ¼å¼ã€‚è½¬æ¢ä¸ºPyTorchå¼ é‡åŽï¼Œå°†æ•°æ®é›†åŒ…è£…åœ¨[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)ä¸­ï¼š
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: TensorFlowHide TensorFlow content
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowHide TensorFlow content
- en: Use the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)
    method from ðŸ¤— Transformers to prepare the dataset to be compatible with TensorFlow,
    and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    as a `tf.data.Dataset` with collation and batching, so one can pass it directly
    to Keras methods like `fit()` without further modification.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ðŸ¤— Transformersçš„[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)æ–¹æ³•æ¥å‡†å¤‡æ•°æ®é›†ä»¥ä¸ŽTensorFlowå…¼å®¹ï¼Œå¹¶å‡†å¤‡å¥½è®­ç»ƒ/å¾®è°ƒæ¨¡åž‹ï¼Œå› ä¸ºå®ƒå°†HuggingFace
    [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)åŒ…è£…ä¸º`tf.data.Dataset`ï¼Œå…·æœ‰æ•´ç†å’Œæ‰¹å¤„ç†åŠŸèƒ½ï¼Œå› æ­¤å¯ä»¥ç›´æŽ¥å°†å…¶ä¼ é€’ç»™Kerasæ–¹æ³•ï¼Œå¦‚`fit()`ï¼Œæ— éœ€è¿›ä¸€æ­¥ä¿®æ”¹ã€‚
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**7**. Start training with your machine learning framework! Check out the ðŸ¤—
    Transformers [audio classification guide](https://huggingface.co/docs/transformers/tasks/audio_classification)
    for an end-to-end example of how to train a model on an audio dataset.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**7**. ä½¿ç”¨æ‚¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶å¼€å§‹è®­ç»ƒï¼æŸ¥çœ‹ðŸ¤— Transformersçš„[éŸ³é¢‘åˆ†ç±»æŒ‡å—](https://huggingface.co/docs/transformers/tasks/audio_classification)
    ï¼Œäº†è§£å¦‚ä½•åœ¨éŸ³é¢‘æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡åž‹çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ã€‚'
- en: Vision
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è§†è§‰
- en: Image datasets are loaded just like text datasets. However, instead of a tokenizer,
    youâ€™ll need a [feature extractor](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)
    to preprocess the dataset. Applying data augmentation to an image is common in
    computer vision to make the model more robust against overfitting. Youâ€™re free
    to use any data augmentation library you want, and then you can apply the augmentations
    with ðŸ¤— Datasets. In this quickstart, youâ€™ll load the [Beans](https://huggingface.co/datasets/beans)
    dataset and get it ready for the model to train on and identify disease from the
    leaf images.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒæ•°æ®é›†çš„åŠ è½½æ–¹å¼ä¸Žæ–‡æœ¬æ•°æ®é›†ç›¸åŒã€‚ä½†æ˜¯ï¼Œæ‚¨éœ€è¦ä¸€ä¸ª[ç‰¹å¾æå–å™¨](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)æ¥é¢„å¤„ç†æ•°æ®é›†ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªåˆ†è¯å™¨ã€‚åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¯¹å›¾åƒåº”ç”¨æ•°æ®å¢žå¼ºæ˜¯å¸¸è§çš„ï¼Œä»¥ä½¿æ¨¡åž‹æ›´å…·æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›ã€‚æ‚¨å¯ä»¥è‡ªç”±é€‰æ‹©ä»»ä½•æ•°æ®å¢žå¼ºåº“ï¼Œç„¶åŽå¯ä»¥ä½¿ç”¨ðŸ¤—
    Datasetsåº”ç”¨å¢žå¼ºã€‚åœ¨è¿™ä¸ªå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæ‚¨å°†åŠ è½½[Beans](https://huggingface.co/datasets/beans)æ•°æ®é›†ï¼Œå¹¶å‡†å¤‡å¥½è®©æ¨¡åž‹è®­ç»ƒå¹¶ä»Žå¶ç‰‡å›¾åƒä¸­è¯†åˆ«ç–¾ç—…ã€‚
- en: '**1**. Load the Beans dataset by providing the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function with the dataset name and a dataset split:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**. é€šè¿‡æä¾›æ•°æ®é›†åç§°å’Œæ•°æ®é›†æ‹†åˆ†ï¼Œä½¿ç”¨[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)å‡½æ•°åŠ è½½Beansæ•°æ®é›†ï¼š'
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**2**. Now you can add some data augmentations with any library ([Albumentations](https://albumentations.ai/),
    [imgaug](https://imgaug.readthedocs.io/en/latest/), [Kornia](https://kornia.readthedocs.io/en/latest/))
    you like. Here, youâ€™ll use [torchvision](https://pytorch.org/vision/stable/transforms.html)
    to randomly change the color properties of an image:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**2**. çŽ°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•åº“ï¼ˆ[Albumentations](https://albumentations.ai/)ã€[imgaug](https://imgaug.readthedocs.io/en/latest/)ã€[Kornia](https://kornia.readthedocs.io/en/latest/)ï¼‰æ·»åŠ ä¸€äº›æ•°æ®å¢žå¼ºã€‚åœ¨è¿™é‡Œï¼Œæ‚¨å°†ä½¿ç”¨[torchvision](https://pytorch.org/vision/stable/transforms.html)éšæœºæ›´æ”¹å›¾åƒçš„é¢œè‰²å±žæ€§ï¼š'
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**3**. Create a function to apply your transform to the dataset and generate
    the model input: `pixel_values`.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**3**. åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†æ‚¨çš„è½¬æ¢åº”ç”¨äºŽæ•°æ®é›†å¹¶ç”Ÿæˆæ¨¡åž‹è¾“å…¥ï¼š`pixel_values`ã€‚'
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**4**. Use the [with_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_transform)
    function to apply the data augmentations on-the-fly:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**4**. ä½¿ç”¨[with_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_transform)å‡½æ•°å®žæ—¶åº”ç”¨æ•°æ®å¢žå¼ºï¼š'
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**5**. Set the dataset format according to the machine learning framework youâ€™re
    using.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**5**. æ ¹æ®æ‚¨æ­£åœ¨ä½¿ç”¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶è®¾ç½®æ•°æ®é›†æ ¼å¼ã€‚'
- en: PytorchHide Pytorch content
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: 'Wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader).
    Youâ€™ll also need to create a collate function to collate the samples into batches:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†åŒ…è£…åœ¨[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)ä¸­ã€‚æ‚¨è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªæ•´ç†å‡½æ•°ï¼Œå°†æ ·æœ¬æ•´ç†æˆæ‰¹æ¬¡ï¼š
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: TensorFlowHide TensorFlow content
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowHide TensorFlow content
- en: Use the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)
    method from ðŸ¤— Transformers to prepare the dataset to be compatible with TensorFlow,
    and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    as a `tf.data.Dataset` with collation and batching, so one can pass it directly
    to Keras methods like `fit()` without further modification.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ðŸ¤— Transformersä¸­çš„[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)æ–¹æ³•æ¥å‡†å¤‡æ•°æ®é›†ä»¥ä¸ŽTensorFlowå…¼å®¹ï¼Œå¹¶å‡†å¤‡å¥½è®­ç»ƒ/å¾®è°ƒæ¨¡åž‹ï¼Œå› ä¸ºå®ƒå°†HuggingFaceçš„[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)åŒ…è£…ä¸ºä¸€ä¸ªå¸¦æœ‰æ•´ç†å’Œæ‰¹å¤„ç†çš„`tf.data.Dataset`ï¼Œå› æ­¤å¯ä»¥ç›´æŽ¥å°†å…¶ä¼ é€’ç»™Kerasæ–¹æ³•ï¼Œå¦‚`fit()`ï¼Œè€Œæ— éœ€è¿›ä¸€æ­¥ä¿®æ”¹ã€‚
- en: 'Before you start, make sure you have up-to-date versions of `albumentations`
    and `cv2` installed:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…`albumentations`å’Œ`cv2`çš„æœ€æ–°ç‰ˆæœ¬ï¼š
- en: '[PRE17]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**6**. Start training with your machine learning framework! Check out the ðŸ¤—
    Transformers [image classification guide](https://huggingface.co/docs/transformers/tasks/image_classification)
    for an end-to-end example of how to train a model on an image dataset.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**6**. ä½¿ç”¨æ‚¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶å¼€å§‹è®­ç»ƒï¼æŸ¥çœ‹ðŸ¤— Transformersçš„[å›¾åƒåˆ†ç±»æŒ‡å—](https://huggingface.co/docs/transformers/tasks/image_classification)
    ï¼Œäº†è§£å¦‚ä½•åœ¨å›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡åž‹çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ã€‚'
- en: NLP
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NLP
- en: Text needs to be tokenized into individual tokens by a [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer).
    For the quickstart, youâ€™ll load the [Microsoft Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc)
    training dataset to train a model to determine whether a pair of sentences mean
    the same thing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬éœ€è¦é€šè¿‡[åˆ†è¯å™¨](https://huggingface.co/docs/transformers/main_classes/tokenizer)åˆ†è¯ä¸ºå•ç‹¬çš„æ ‡è®°ã€‚åœ¨å¿«é€Ÿå…¥é—¨ä¸­ï¼Œæ‚¨å°†åŠ è½½[Microsoft
    Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc)è®­ç»ƒæ•°æ®é›†ï¼Œä»¥è®­ç»ƒæ¨¡åž‹æ¥ç¡®å®šä¸€å¯¹å¥å­æ˜¯å¦è¡¨ç¤ºç›¸åŒçš„å«ä¹‰ã€‚
- en: '**1**. Load the MRPC dataset by providing the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function with the dataset name, dataset configuration (not all datasets will have
    a configuration), and dataset split:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**. é€šè¿‡å‘[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)å‡½æ•°æä¾›æ•°æ®é›†åç§°ã€æ•°æ®é›†é…ç½®ï¼ˆå¹¶éžæ‰€æœ‰æ•°æ®é›†éƒ½æœ‰é…ç½®ï¼‰å’Œæ•°æ®é›†æ‹†åˆ†æ¥åŠ è½½MRPCæ•°æ®é›†ï¼š'
- en: '[PRE19]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**2**. Next, load a pretrained [BERT](https://huggingface.co/bert-base-uncased)
    model and its corresponding tokenizer from the [ðŸ¤— Transformers](https://huggingface.co/transformers/)
    library. It is totally normal to see a warning after you load the model about
    some weights not being initialized. This is expected because you are loading this
    model checkpoint for training with another task.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**2**. æŽ¥ä¸‹æ¥ï¼Œä»Ž[ðŸ¤— Transformers](https://huggingface.co/transformers/)åº“ä¸­åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„[BERT](https://huggingface.co/bert-base-uncased)æ¨¡åž‹åŠå…¶å¯¹åº”çš„åˆ†è¯å™¨ã€‚åœ¨åŠ è½½æ¨¡åž‹åŽçœ‹åˆ°ä¸€äº›æƒé‡æœªåˆå§‹åŒ–çš„è­¦å‘Šæ˜¯æ­£å¸¸çš„ã€‚è¿™æ˜¯å› ä¸ºæ‚¨æ­£åœ¨åŠ è½½æ­¤æ¨¡åž‹æ£€æŸ¥ç‚¹ä»¥ä¾¿ç”¨äºŽå¦ä¸€ä¸ªä»»åŠ¡çš„è®­ç»ƒã€‚'
- en: '[PRE20]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '>>> def encode(examples):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> def encode(examples):'
- en: '...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True,
    padding="max_length")'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True,
    padding="max_length")'
- en: '>>> dataset = dataset.map(encode, batched=True)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset = dataset.map(encode, batched=True)'
- en: '>>> dataset[0]'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset[0]'
- en: '{''sentence1'': ''Amrozi accused his brother , whom he called " the witness
    " , of deliberately distorting his evidence .'','
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '{''sentence1'': ''AmroziæŒ‡æŽ§ä»–çš„å…„å¼Ÿï¼Œç§°å…¶ä¸ºâ€œè¯äººâ€ï¼Œæ•…æ„æ­ªæ›²è¯æ®ã€‚'','
- en: '''sentence2'': ''Referring to him as only " the witness " , Amrozi accused
    his brother of deliberately distorting his evidence .'','
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '''sentence2'': ''AmroziæŒ‡ç§°ä»–çš„å…„å¼Ÿä¸ºâ€œè¯äººâ€ï¼ŒæŒ‡æŽ§ä»–æ•…æ„æ­ªæ›²è¯æ®ã€‚'','
- en: '''label'': 1,'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '''label'': 1,'
- en: '''idx'': 0,'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '''idx'': 0,'
- en: '''input_ids'': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292,
    1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102,
    11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938,
    4267, 12223, 21811,  1117,  2554,   119,   102]),'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '''input_ids'': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292,
    1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102,
    11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938,
    4267, 12223, 21811,  1117,  2554,   119,   102]),'
- en: '''token_type_ids'': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '''token_type_ids'': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),'
- en: '''attention_mask'': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '''attention_mask'': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}'
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)'
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '>>> import torch'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> import torch'
- en: '>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids",
    "attention_mask", "labels"])'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids",
    "attention_mask", "labels"])'
- en: '>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)'
- en: '[PRE23]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '>>> import tensorflow as tf'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> import tensorflow as tf'
- en: '>>> tf_dataset = model.prepare_tf_dataset('
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> tf_dataset = model.prepare_tf_dataset('
- en: '...     dataset,'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '...     dataset,'
- en: '...     batch_size=4,'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '...     batch_size=4,'
- en: '...     shuffle=True,'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '...     shuffle=True,'
- en: '... )'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '... )'
- en: '[PRE24]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
