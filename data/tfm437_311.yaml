- en: Pop2Piano
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pop2Piano
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/pop2piano](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/pop2piano)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/pop2piano](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/pop2piano)
- en: '[![Spaces](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/sweetcocoa/pop2piano)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Spaces](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/sweetcocoa/pop2piano)'
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The Pop2Piano model was proposed in [Pop2Piano : Pop Audio-based Piano Cover
    Generation](https://arxiv.org/abs/2211.00895) by Jongho Choi and Kyogu Lee.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Pop2Piano模型由Jongho Choi和Kyogu Lee在[Pop2Piano：基于流行音频的钢琴翻奏生成](https://arxiv.org/abs/2211.00895)中提出。
- en: Piano covers of pop music are widely enjoyed, but generating them from music
    is not a trivial task. It requires great expertise with playing piano as well
    as knowing different characteristics and melodies of a song. With Pop2Piano you
    can directly generate a cover from a song’s audio waveform. It is the first model
    to directly generate a piano cover from pop audio without melody and chord extraction
    modules.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 流行音乐的钢琴翻奏广受欢迎，但从音乐中生成它们并不是一项简单的任务。这需要对弹奏钢琴有很高的专业知识，同时还要了解歌曲的不同特征和旋律。通过Pop2Piano，您可以直接从歌曲的音频波形生成翻奏。这是第一个直接从流行音频生成钢琴翻奏的模型，而无需旋律和和弦提取模块。
- en: 'Pop2Piano is an encoder-decoder Transformer model based on [T5](https://arxiv.org/pdf/1910.10683.pdf).
    The input audio is transformed to its waveform and passed to the encoder, which
    transforms it to a latent representation. The decoder uses these latent representations
    to generate token ids in an autoregressive way. Each token id corresponds to one
    of four different token types: time, velocity, note and ‘special’. The token ids
    are then decoded to their equivalent MIDI file.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pop2Piano是基于[T5](https://arxiv.org/pdf/1910.10683.pdf)的编码器-解码器Transformer模型。输入音频被转换为其波形并传递给编码器，编码器将其转换为潜在表示。解码器使用这些潜在表示以自回归方式生成令牌id。每个令牌id对应于四种不同的令牌类型之一：时间、速度、音符和“特殊”。然后将令牌id解码为其等效的MIDI文件。
- en: 'The abstract from the paper is the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Piano covers of pop music are enjoyed by many people. However, the task of
    automatically generating piano covers of pop music is still understudied. This
    is partly due to the lack of synchronized {Pop, Piano Cover} data pairs, which
    made it challenging to apply the latest data-intensive deep learning-based methods.
    To leverage the power of the data-driven approach, we make a large amount of paired
    and synchronized {Pop, Piano Cover} data using an automated pipeline. In this
    paper, we present Pop2Piano, a Transformer network that generates piano covers
    given waveforms of pop music. To the best of our knowledge, this is the first
    model to generate a piano cover directly from pop audio without using melody and
    chord extraction modules. We show that Pop2Piano, trained with our dataset, is
    capable of producing plausible piano covers.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*许多人喜欢流行音乐的钢琴翻奏。然而，自动生成流行音乐的钢琴翻奏的任务仍然未被充分研究。部分原因是缺乏同步的{流行音乐，钢琴翻奏}数据对，这使得应用最新的数据密集型基于深度学习的方法具有挑战性。为了利用数据驱动方法的力量，我们使用自动化流水线制作了大量配对和同步的{流行音乐，钢琴翻奏}数据。在本文中，我们提出了Pop2Piano，这是一个Transformer网络，可以根据流行音乐的波形生成钢琴翻奏。据我们所知，这是第一个可以直接从流行音频生成钢琴翻奏的模型，而无需使用旋律和和弦提取模块。我们展示了使用我们的数据集训练的Pop2Piano能够生成合理的钢琴翻奏。*'
- en: This model was contributed by [Susnato Dhar](https://huggingface.co/susnato).
    The original code can be found [here](https://github.com/sweetcocoa/pop2piano).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[Susnato Dhar](https://huggingface.co/susnato)贡献。原始代码可以在[此处](https://github.com/sweetcocoa/pop2piano)找到。
- en: Usage tips
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: 'To use Pop2Piano, you will need to install the 🤗 Transformers library, as well
    as the following third party modules:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要使用Pop2Piano，您需要安装🤗 Transformers库，以及以下第三方模块：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Please note that you may need to restart your runtime after installation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您可能需要在安装后重新启动运行时。
- en: Pop2Piano is an Encoder-Decoder based model like T5.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pop2Piano是一种基于编码器-解码器的模型，类似于T5。
- en: Pop2Piano can be used to generate midi-audio files for a given audio sequence.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pop2Piano可用于为给定音频序列生成midi音频文件。
- en: Choosing different composers in `Pop2PianoForConditionalGeneration.generate()`
    can lead to variety of different results.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`Pop2PianoForConditionalGeneration.generate()`中选择不同的作曲家可以产生不同结果的多样性。
- en: Setting the sampling rate to 44.1 kHz when loading the audio file can give good
    performance.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在加载音频文件时将采样率设置为44.1 kHz可以获得良好的性能。
- en: Though Pop2Piano was mainly trained on Korean Pop music, it also does pretty
    well on other Western Pop or Hip Hop songs.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管Pop2Piano主要是在韩国流行音乐上进行训练的，但它在其他西方流行音乐或嘻哈歌曲上也表现不错。
- en: Examples
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: 'Example using HuggingFace Dataset:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用HuggingFace数据集的示例：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Example using your own audio file:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用您自己的音频文件示例：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Example of processing multiple audio files in batch:'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量处理多个音频文件的示例：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Example of processing multiple audio files in batch (Using `Pop2PianoFeatureExtractor`
    and `Pop2PianoTokenizer`):'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量处理多个音频文件的示例（使用`Pop2PianoFeatureExtractor`和`Pop2PianoTokenizer`）：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Pop2PianoConfig
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pop2PianoConfig
- en: '### `class transformers.Pop2PianoConfig`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Pop2PianoConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/configuration_pop2piano.py#L29)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/configuration_pop2piano.py#L29)'
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 2400) — Vocabulary size of the
    `Pop2PianoForConditionalGeneration` model. Defines the number of different tokens
    that can be represented by the `inputs_ids` passed when calling [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为2400）- `Pop2PianoForConditionalGeneration`模型的词汇量。定义了在调用[Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)时可以表示的不同令牌数量。'
- en: '`composer_vocab_size` (`int`, *optional*, defaults to 21) — Denotes the number
    of composers.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`composer_vocab_size`（`int`，*可选*，默认为21）- 表示作曲家的数量。'
- en: '`d_model` (`int`, *optional*, defaults to 512) — Size of the encoder layers
    and the pooler layer.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *可选*, 默认为512) — 编码器层和池化层的大小。'
- en: '`d_kv` (`int`, *optional*, defaults to 64) — Size of the key, query, value
    projections per attention head. The `inner_dim` of the projection layer will be
    defined as `num_heads * d_kv`.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_kv` (`int`, *可选*, 默认为64) — 每个注意力头中键、查询、值投影的大小。投影层的`inner_dim`将定义为`num_heads
    * d_kv`。'
- en: '`d_ff` (`int`, *optional*, defaults to 2048) — Size of the intermediate feed
    forward layer in each `Pop2PianoBlock`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_ff` (`int`, *可选*, 默认为2048) — 每个`Pop2PianoBlock`中间级前馈层的大小。'
- en: '`num_layers` (`int`, *optional*, defaults to 6) — Number of hidden layers in
    the Transformer encoder.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers` (`int`, *可选*, 默认为6) — Transformer编码器中的隐藏层数量。'
- en: '`num_decoder_layers` (`int`, *optional*) — Number of hidden layers in the Transformer
    decoder. Will use the same value as `num_layers` if not set.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_decoder_layers` (`int`, *可选*) — Transformer解码器中的隐藏层数量。如果未设置，将使用与`num_layers`相同的值。'
- en: '`num_heads` (`int`, *optional*, defaults to 8) — Number of attention heads
    for each attention layer in the Transformer encoder.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`int`, *可选*, 默认为8) — Transformer编码器中每个注意力层的注意力头数量。'
- en: '`relative_attention_num_buckets` (`int`, *optional*, defaults to 32) — The
    number of buckets to use for each attention layer.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relative_attention_num_buckets` (`int`, *可选*, 默认为32) — 每个注意力层使用的桶数量。'
- en: '`relative_attention_max_distance` (`int`, *optional*, defaults to 128) — The
    maximum distance of the longer sequences for the bucket separation.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relative_attention_max_distance` (`int`, *可选*, 默认为128) — 用于桶分离的较长序列的最大距离。'
- en: '`dropout_rate` (`float`, *optional*, defaults to 0.1) — The ratio for all dropout
    layers.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout_rate` (`float`, *可选*, 默认为0.1) — 所有dropout层的比率。'
- en: '`layer_norm_epsilon` (`float`, *optional*, defaults to 1e-6) — The epsilon
    used by the layer normalization layers.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_epsilon` (`float`, *可选*, 默认为1e-6) — 层归一化层使用的epsilon。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1.0) — A factor for
    initializing all weight matrices (should be kept to 1.0, used internally for initialization
    testing).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor` (`float`, *可选*, 默认为1.0) — 初始化所有权重矩阵的因子（应保持为1.0，用于内部初始化测试）。'
- en: '`feed_forward_proj` (`string`, *optional*, defaults to `"gated-gelu"`) — Type
    of feed forward layer to be used. Should be one of `"relu"` or `"gated-gelu"`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feed_forward_proj` (`string`, *可选*, 默认为`"gated-gelu"`) — 要使用的前馈层类型。应为`"relu"`或`"gated-gelu"`之一。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *可选*, 默认为`True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: '`dense_act_fn` (`string`, *optional*, defaults to `"relu"`) — Type of Activation
    Function to be used in `Pop2PianoDenseActDense` and in `Pop2PianoDenseGatedActDense`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dense_act_fn` (`string`, *可选*, 默认为`"relu"`) — 用于`Pop2PianoDenseActDense`和`Pop2PianoDenseGatedActDense`中的激活函数类型。'
- en: This is the configuration class to store the configuration of a [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration).
    It is used to instantiate a Pop2PianoForConditionalGeneration model according
    to the specified arguments, defining the model architecture. Instantiating a configuration
    with the defaults will yield a similar configuration to that of the Pop2Piano
    [sweetcocoa/pop2piano](https://huggingface.co/sweetcocoa/pop2piano) architecture.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)配置的配置类。根据指定的参数实例化一个Pop2PianoForConditionalGeneration模型，定义模型架构。使用默认值实例化配置将产生类似于Pop2Piano
    [sweetcocoa/pop2piano](https://huggingface.co/sweetcocoa/pop2piano)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: Pop2PianoFeatureExtractor
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pop2PianoFeatureExtractor
- en: '### `class transformers.Pop2PianoFeatureExtractor`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Pop2PianoFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py#L5)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py#L5)'
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `__call__`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Call self as a function.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 将自身作为函数调用。
- en: Pop2PianoForConditionalGeneration
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pop2PianoForConditionalGeneration
- en: '### `class transformers.Pop2PianoForConditionalGeneration`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Pop2PianoForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/modeling_pop2piano.py#L1009)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/modeling_pop2piano.py#L1009)'
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Pop2Piano Model with a `language modeling` head on top. This model inherits
    from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Pop2Piano模型在顶部带有`语言建模`头。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `前向`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/modeling_pop2piano.py#L1109)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/modeling_pop2piano.py#L1109)'
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Pop2Piano is a model with
    relative position embeddings so you should be able to pad the inputs on both the
    right and the left. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for detail. [What are input IDs?](../glossary#input-ids) To know more on how to
    prepare `input_ids` for pretraining take a look a [Pop2Pianp Training](./Pop2Piano#training).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。Pop2Piano是一个带有相对位置嵌入的模型，因此您应该能够在右侧和左侧填充输入。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)以获取详细信息。[什么是输入ID？](../glossary#input-ids)要了解有关如何为预训练准备`input_ids`的更多信息，请查看[Pop2Piano训练](./Pop2Piano#training)。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。选择的掩码值在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`未屏蔽`的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示标记为`屏蔽`的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary. Indices
    can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are decoder input IDs?](../glossary#decoder-input-ids) Pop2Piano
    uses the `pad_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`). To know more on how to prepare'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）—
    词汇表中解码器输入序列标记的索引。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)以获取详细信息。[什么是解码器输入ID？](../glossary#decoder-input-ids)Pop2Piano使用`pad_token_id`作为`decoder_input_ids`生成的起始标记。如果使用`past_key_values`，则只需选择最后的`decoder_input_ids`输入（请参阅`past_key_values`）。要了解如何准备'
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.BoolTensor`，*可选*）—
    默认行为：生成一个张量，忽略`decoder_input_ids`中的填充标记。默认情况下还将使用因果掩码。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules in
    the encoder. Mask values selected in `[0, 1]`:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使编码器中自注意力模块的选定头部失效的掩码。选择的掩码值在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`屏蔽`，
- en: 0 indicates the head is `masked`.
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`屏蔽`。
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) — Mask to nullify selected heads of the self-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使解码器中自注意力模块的选定头部失效的掩码。选择的掩码值在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`屏蔽`，
- en: 0 indicates the head is `masked`.
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`屏蔽`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) — Mask to nullify selected heads of the cross-attention
    modules in the decoder. Mask values selected in `[0, 1]`:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.Tensor`，*可选*）—
    用于使解码器中交叉注意力模块的选定头部失效的掩码。选择的掩码值在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`屏蔽`，
- en: 0 indicates the head is `masked`.
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`屏蔽`。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, `optional`: *hidden_states*, `optional`: *attentions*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` is a
    sequence of hidden states at the output of the last layer of the encoder. Used
    in the cross-attention of the decoder.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括（`last_hidden_state`，可选：*hidden_states*，可选：*attentions*）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden states
    of the attention blocks. Can be used to speed up decoding. If `past_key_values`
    are used, the user can optionally input only the last `decoder_input_ids` (those
    that don’t have their past key value states given to this model) of shape `(batch_size,
    1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，长度为`config.n_layers`，每个元组包含形状为`(batch_size,
    num_heads, sequence_length - 1, embed_size_per_head)`的4个张量） — 包含注意力块的预计算的键和值隐藏状态。可用于加速解码。如果使用`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（那些没有将其过去的键值状态提供给此模型的）的形状为`(batch_size,
    1)`的张量，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_ids`。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*optional*)
    — 可选地，可以直接传递嵌入表示，而不是传递`input_ids`。如果要更好地控制如何将`input_ids`索引转换为相关向量，这很有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Does the same task as `inputs_embeds`. If `inputs_embeds`
    is not present but `input_features` is present then `input_features` will be considered
    as `inputs_embeds`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*optional*)
    — 执行与`inputs_embeds`相同的任务。如果不存在`inputs_embeds`但存在`input_features`，则将`input_features`视为`inputs_embeds`。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix. If `decoder_input_ids` and `decoder_inputs_embeds` are
    both unset, `decoder_inputs_embeds` takes the value of `inputs_embeds`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, target_sequence_length,
    hidden_size)`，*optional*) — 可选地，可以直接传递嵌入表示，而不是传递`decoder_input_ids`。如果使用`past_key_values`，可以选择仅输入最后的`decoder_inputs_embeds`（参见`past_key_values`）。如果`decoder_input_ids`和`decoder_inputs_embeds`都未设置，则`decoder_inputs_embeds`取`inputs_embeds`的值。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[-100, 0, ..., config.vocab_size - 1]`. All labels set to `-100` are ignored
    (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size,)`，*optional*) — 用于计算序列分类/回归损失的标签。索引应在`[-100,
    0, ..., config.vocab_size - 1]`内。所有标签设置为`-100`的将被忽略（掩码），损失仅计算标签在`[0, ..., config.vocab_size]`内的。'
- en: Returns
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig))
    and inputs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或当`config.return_dict=False`时）包括根据配置（[Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)）和输入而异的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`，*optional*，在提供`labels`时返回) — 语言建模损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回
    — 长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可以用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层的输出隐藏状态以及初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层的输出隐藏状态以及初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会处理运行前后的处理步骤，而后者会默默地忽略它们。
- en: '#### `generate`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/modeling_pop2piano.py#L1217)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/pop2piano/modeling_pop2piano.py#L1217)'
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — This is the featurized version of audio generated
    by `Pop2PianoFeatureExtractor`. attention_mask — For batched generation `input_features`
    are padded to have the same shape across all examples. `attention_mask` helps
    to determine which areas were padded and which were not.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*optional*)
    — 这是由 `Pop2PianoFeatureExtractor` 生成的音频的特征化版本。attention_mask — 对于批量生成，`input_features`
    被填充以使所有示例具有相同的形状。`attention_mask` 有助于确定哪些区域被填充，哪些没有被填充。'
- en: 1 for tokens that are `not padded`,
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 用于 `未填充` 的标记。
- en: 0 for tokens that are `padded`.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 用于 `填充` 的标记。
- en: '`composer` (`str`, *optional*, defaults to `"composer1"`) — This value is passed
    to `Pop2PianoConcatEmbeddingToMel` to generate different embeddings for each `"composer"`.
    Please make sure that the composet value is present in `composer_to_feature_token`
    in `generation_config`. For an example please see [https://huggingface.co/sweetcocoa/pop2piano/blob/main/generation_config.json](https://huggingface.co/sweetcocoa/pop2piano/blob/main/generation_config.json)
    .'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`composer` (`str`, *optional*, defaults to `"composer1"`) — 传递给 `Pop2PianoConcatEmbeddingToMel`
    的值，用于为每个 `"composer"` 生成不同的嵌入。请确保 `composer` 值在 `generation_config` 的 `composer_to_feature_token`
    中存在。例如，请参阅 [https://huggingface.co/sweetcocoa/pop2piano/blob/main/generation_config.json](https://huggingface.co/sweetcocoa/pop2piano/blob/main/generation_config.json)。'
- en: '`generation_config` (`~generation.GenerationConfig`, *optional*) — The generation
    configuration to be used as base parametrization for the generation call. `**kwargs`
    passed to generate matching the attributes of `generation_config` will override
    them. If `generation_config` is not provided, the default will be used, which
    had the following loading priority: 1) from the `generation_config.json` model
    file, if it exists; 2) from the model configuration. Please note that unspecified
    parameters will inherit [GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)’s
    default values, whose documentation should be checked to parameterize generation.
    kwargs — Ad hoc parametrization of `generate_config` and/or additional model-specific
    kwargs that will be forwarded to the `forward` function of the model. If the model
    is an encoder-decoder model, encoder specific kwargs should not be prefixed and
    decoder specific kwargs should be prefixed with *decoder_*.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation_config` (`~generation.GenerationConfig`, *optional*) — 用作生成调用的基本参数化的生成配置。传递给
    generate 的 `**kwargs` 匹配 `generation_config` 的属性将覆盖它们。如果未提供 `generation_config`，将使用默认值，其加载优先级如下：1)
    从 `generation_config.json` 模型文件中，如果存在；2) 从模型配置中。请注意，未指定的参数将继承 [GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)
    的默认值，其文档应该被检查以参数化生成。kwargs — `generate_config` 的特定参数化和/或将转发到模型的 `forward` 函数的其他模型特定
    kwargs。如果模型是编码器-解码器模型，则编码器特定的 kwargs 不应该有前缀，解码器特定的 kwargs 应该以 *decoder_* 为前缀。'
- en: Returns
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    or `torch.LongTensor`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    或 `torch.LongTensor`'
- en: 'A [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    (if `return_dict_in_generate=True` or when `config.return_dict_in_generate=True`)
    or a `torch.FloatTensor`. Since Pop2Piano is an encoder-decoder model (`model.config.is_encoder_decoder=True`),
    the possible [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    types are:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)（如果
    `return_dict_in_generate=True` 或当 `config.return_dict_in_generate=True` 时）或一个
    `torch.FloatTensor`。由于 Pop2Piano 是一个编码器-解码器模型（`model.config.is_encoder_decoder=True`），可能的
    [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    类型为：
- en: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput),'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput),'
- en: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
- en: Generates token ids for midi outputs.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为 MIDI 输出生成标记 ID。
- en: Most generation-controlling parameters are set in `generation_config` which,
    if not passed, will be set to the model’s default generation configuration. You
    can override any `generation_config` by passing the corresponding parameters to
    generate(), e.g. `.generate(inputs, num_beams=4, do_sample=True)`. For an overview
    of generation strategies and code examples, check out the [following guide](./generation_strategies).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数控制生成的参数都在 `generation_config` 中设置，如果未传递，则将设置为模型的默认生成配置。您可以通过传递相应的参数到 generate()
    来覆盖任何 `generation_config`，例如 `.generate(inputs, num_beams=4, do_sample=True)`。有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: Pop2PianoTokenizer
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pop2PianoTokenizer
- en: '### `class transformers.Pop2PianoTokenizer`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Pop2PianoTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py#L12)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py#L12)'
- en: '[PRE11]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#### `__call__`'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Call self as a function.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 将自身作为函数调用。
- en: Pop2PianoProcessor
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pop2PianoProcessor
- en: '### `class transformers.Pop2PianoProcessor`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.Pop2PianoProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py#L19)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py#L19)'
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#### `__call__`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[PRE14]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Call self as a function.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将自身作为函数调用。
