- en: The cache
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存
- en: 'Original text: [https://huggingface.co/docs/datasets/about_cache](https://huggingface.co/docs/datasets/about_cache)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/about_cache](https://huggingface.co/docs/datasets/about_cache)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The cache is one of the reasons why 🤗 Datasets is so efficient. It stores previously
    downloaded and processed datasets so when you need to use them again, they are
    reloaded directly from the cache. This avoids having to download a dataset all
    over again, or reapplying processing functions. Even after you close and start
    another Python session, 🤗 Datasets will reload your dataset directly from the
    cache!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存是🤗 Datasets 如此高效的原因之一。它存储先前下载和处理过的数据集，因此当您需要再次使用它们时，它们会直接从缓存中重新加载。这避免了需要重新下载数据集，或重新应用处理函数。即使您关闭并启动另一个
    Python 会话，🤗 Datasets 也会直接从缓存中重新加载您的数据集！
- en: Fingerprint
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指纹
- en: How does the cache keeps track of what transforms are applied to a dataset?
    Well, 🤗 Datasets assigns a fingerprint to the cache file. A fingerprint keeps
    track of the current state of a dataset. The initial fingerprint is computed using
    a hash from the Arrow table, or a hash of the Arrow files if the dataset is on
    disk. Subsequent fingerprints are computed by combining the fingerprint of the
    previous state, and a hash of the latest transform applied.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存如何跟踪应用于数据集的转换？嗯，🤗 Datasets 为缓存文件分配一个指纹。指纹跟踪数据集的当前状态。初始指纹是使用 Arrow 表的哈希值计算的，或者如果数据集在磁盘上，则使用
    Arrow 文件的哈希值。后续指纹通过组合先前状态的指纹和最新应用的转换的哈希值来计算。
- en: Transforms are any of the processing methods from the [How-to Process](./process)
    guides such as [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    or [Dataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shuffle).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 转换是来自[处理方法](./process)指南的任何处理方法，例如[Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)或[Dataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shuffle)。
- en: 'Here are what the actual fingerprints look like:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这是实际指纹的样子：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In order for a transform to be hashable, it needs to be picklable by [dill](https://dill.readthedocs.io/en/latest/)
    or [pickle](https://docs.python.org/3/library/pickle).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使转换可哈希，它需要通过[dill](https://dill.readthedocs.io/en/latest/)或[pickle](https://docs.python.org/3/library/pickle)进行
    picklable。
- en: When you use a non-hashable transform, 🤗 Datasets uses a random fingerprint
    instead and raises a warning. The non-hashable transform is considered different
    from the previous transforms. As a result, 🤗 Datasets will recompute all the transforms.
    Make sure your transforms are serializable with pickle or dill to avoid this!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用不可哈希的转换时，🤗 Datasets 会使用一个随机指纹，并发出警告。不可哈希的转换被认为与先前的转换不同。因此，🤗 Datasets 将重新计算所有转换。确保您的转换可以使用
    pickle 或 dill 进行序列化，以避免这种情况！
- en: An example of when 🤗 Datasets recomputes everything is when caching is disabled.
    When this happens, the cache files are generated every time and they get written
    to a temporary directory. Once your Python session ends, the cache files in the
    temporary directory are deleted. A random hash is assigned to these cache files,
    instead of a fingerprint.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当缓存被禁用时，🤗 Datasets 重新计算所有内容的一个例子是。当这种情况发生时，缓存文件会每次生成，并写入临时目录。一旦您的 Python 会话结束，临时目录中的缓存文件将被删除。这些缓存文件被分配一个随机哈希，而不是指纹。
- en: When caching is disabled, use [Dataset.save_to_disk()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk)
    to save your transformed dataset or it will be deleted once the session ends.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当缓存被禁用时，使用[Dataset.save_to_disk()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk)来保存您的转换数据集，否则会在会话结束时被删除。
- en: Hashing
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希
- en: The fingerprint of a dataset is updated by hashing the function passed to `map`
    as well as the `map` parameters (`batch_size`, `remove_columns`, etc.).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的指纹通过对传递给 `map` 的函数以及 `map` 参数（`batch_size`、`remove_columns`等）进行哈希计算来更新。
- en: 'You can check the hash of any Python object using the [fingerprint.Hasher](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.fingerprint.Hasher):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用[fingerprint.Hasher](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.fingerprint.Hasher)检查任何
    Python 对象的哈希值：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The hash is computed by dumping the object using a `dill` pickler and hashing
    the dumped bytes. The pickler recursively dumps all the variables used in your
    function, so any change you do to an object that is used in your function, will
    cause the hash to change.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希是通过使用 `dill` pickler 转储对象并对转储的字节进行哈希计算来计算的。pickler 递归地转储您函数中使用的所有变量，因此您对函数中使用的对象进行的任何更改都将导致哈希值的更改。
- en: If one of your functions doesn’t seem to have the same hash across sessions,
    it means at least one of its variables contains a Python object that is not deterministic.
    When this happens, feel free to hash any object you find suspicious to try to
    find the object that caused the hash to change. For example, if you use a list
    for which the order of its elements is not deterministic across sessions, then
    the hash won’t be the same across sessions either.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的某个函数在不同会话中似乎没有相同的哈希值，这意味着至少其中一个变量包含一个不确定的 Python 对象。当这种情况发生时，请随时对您发现可疑的任何对象进行哈希以尝试找到导致哈希值更改的对象。例如，如果您使用一个列表，其元素的顺序在不同会话中是不确定的，那么哈希值在不同会话中也不会相同。
