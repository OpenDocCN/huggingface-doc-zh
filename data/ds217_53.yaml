- en: The cache
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¼“å­˜
- en: 'Original text: [https://huggingface.co/docs/datasets/about_cache](https://huggingface.co/docs/datasets/about_cache)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/datasets/about_cache](https://huggingface.co/docs/datasets/about_cache)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The cache is one of the reasons why ğŸ¤— Datasets is so efficient. It stores previously
    downloaded and processed datasets so when you need to use them again, they are
    reloaded directly from the cache. This avoids having to download a dataset all
    over again, or reapplying processing functions. Even after you close and start
    another Python session, ğŸ¤— Datasets will reload your dataset directly from the
    cache!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼“å­˜æ˜¯ğŸ¤— Datasets å¦‚æ­¤é«˜æ•ˆçš„åŸå› ä¹‹ä¸€ã€‚å®ƒå­˜å‚¨å…ˆå‰ä¸‹è½½å’Œå¤„ç†è¿‡çš„æ•°æ®é›†ï¼Œå› æ­¤å½“æ‚¨éœ€è¦å†æ¬¡ä½¿ç”¨å®ƒä»¬æ—¶ï¼Œå®ƒä»¬ä¼šç›´æ¥ä»ç¼“å­˜ä¸­é‡æ–°åŠ è½½ã€‚è¿™é¿å…äº†éœ€è¦é‡æ–°ä¸‹è½½æ•°æ®é›†ï¼Œæˆ–é‡æ–°åº”ç”¨å¤„ç†å‡½æ•°ã€‚å³ä½¿æ‚¨å…³é—­å¹¶å¯åŠ¨å¦ä¸€ä¸ª
    Python ä¼šè¯ï¼ŒğŸ¤— Datasets ä¹Ÿä¼šç›´æ¥ä»ç¼“å­˜ä¸­é‡æ–°åŠ è½½æ‚¨çš„æ•°æ®é›†ï¼
- en: Fingerprint
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŒ‡çº¹
- en: How does the cache keeps track of what transforms are applied to a dataset?
    Well, ğŸ¤— Datasets assigns a fingerprint to the cache file. A fingerprint keeps
    track of the current state of a dataset. The initial fingerprint is computed using
    a hash from the Arrow table, or a hash of the Arrow files if the dataset is on
    disk. Subsequent fingerprints are computed by combining the fingerprint of the
    previous state, and a hash of the latest transform applied.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼“å­˜å¦‚ä½•è·Ÿè¸ªåº”ç”¨äºæ•°æ®é›†çš„è½¬æ¢ï¼Ÿå—¯ï¼ŒğŸ¤— Datasets ä¸ºç¼“å­˜æ–‡ä»¶åˆ†é…ä¸€ä¸ªæŒ‡çº¹ã€‚æŒ‡çº¹è·Ÿè¸ªæ•°æ®é›†çš„å½“å‰çŠ¶æ€ã€‚åˆå§‹æŒ‡çº¹æ˜¯ä½¿ç”¨ Arrow è¡¨çš„å“ˆå¸Œå€¼è®¡ç®—çš„ï¼Œæˆ–è€…å¦‚æœæ•°æ®é›†åœ¨ç£ç›˜ä¸Šï¼Œåˆ™ä½¿ç”¨
    Arrow æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚åç»­æŒ‡çº¹é€šè¿‡ç»„åˆå…ˆå‰çŠ¶æ€çš„æŒ‡çº¹å’Œæœ€æ–°åº”ç”¨çš„è½¬æ¢çš„å“ˆå¸Œå€¼æ¥è®¡ç®—ã€‚
- en: Transforms are any of the processing methods from the [How-to Process](./process)
    guides such as [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    or [Dataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shuffle).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢æ˜¯æ¥è‡ª[å¤„ç†æ–¹æ³•](./process)æŒ‡å—çš„ä»»ä½•å¤„ç†æ–¹æ³•ï¼Œä¾‹å¦‚[Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)æˆ–[Dataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shuffle)ã€‚
- en: 'Here are what the actual fingerprints look like:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å®é™…æŒ‡çº¹çš„æ ·å­ï¼š
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In order for a transform to be hashable, it needs to be picklable by [dill](https://dill.readthedocs.io/en/latest/)
    or [pickle](https://docs.python.org/3/library/pickle).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿è½¬æ¢å¯å“ˆå¸Œï¼Œå®ƒéœ€è¦é€šè¿‡[dill](https://dill.readthedocs.io/en/latest/)æˆ–[pickle](https://docs.python.org/3/library/pickle)è¿›è¡Œ
    picklableã€‚
- en: When you use a non-hashable transform, ğŸ¤— Datasets uses a random fingerprint
    instead and raises a warning. The non-hashable transform is considered different
    from the previous transforms. As a result, ğŸ¤— Datasets will recompute all the transforms.
    Make sure your transforms are serializable with pickle or dill to avoid this!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨ä½¿ç”¨ä¸å¯å“ˆå¸Œçš„è½¬æ¢æ—¶ï¼ŒğŸ¤— Datasets ä¼šä½¿ç”¨ä¸€ä¸ªéšæœºæŒ‡çº¹ï¼Œå¹¶å‘å‡ºè­¦å‘Šã€‚ä¸å¯å“ˆå¸Œçš„è½¬æ¢è¢«è®¤ä¸ºä¸å…ˆå‰çš„è½¬æ¢ä¸åŒã€‚å› æ­¤ï¼ŒğŸ¤— Datasets å°†é‡æ–°è®¡ç®—æ‰€æœ‰è½¬æ¢ã€‚ç¡®ä¿æ‚¨çš„è½¬æ¢å¯ä»¥ä½¿ç”¨
    pickle æˆ– dill è¿›è¡Œåºåˆ—åŒ–ï¼Œä»¥é¿å…è¿™ç§æƒ…å†µï¼
- en: An example of when ğŸ¤— Datasets recomputes everything is when caching is disabled.
    When this happens, the cache files are generated every time and they get written
    to a temporary directory. Once your Python session ends, the cache files in the
    temporary directory are deleted. A random hash is assigned to these cache files,
    instead of a fingerprint.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç¼“å­˜è¢«ç¦ç”¨æ—¶ï¼ŒğŸ¤— Datasets é‡æ–°è®¡ç®—æ‰€æœ‰å†…å®¹çš„ä¸€ä¸ªä¾‹å­æ˜¯ã€‚å½“è¿™ç§æƒ…å†µå‘ç”Ÿæ—¶ï¼Œç¼“å­˜æ–‡ä»¶ä¼šæ¯æ¬¡ç”Ÿæˆï¼Œå¹¶å†™å…¥ä¸´æ—¶ç›®å½•ã€‚ä¸€æ—¦æ‚¨çš„ Python ä¼šè¯ç»“æŸï¼Œä¸´æ—¶ç›®å½•ä¸­çš„ç¼“å­˜æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚è¿™äº›ç¼“å­˜æ–‡ä»¶è¢«åˆ†é…ä¸€ä¸ªéšæœºå“ˆå¸Œï¼Œè€Œä¸æ˜¯æŒ‡çº¹ã€‚
- en: When caching is disabled, use [Dataset.save_to_disk()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk)
    to save your transformed dataset or it will be deleted once the session ends.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç¼“å­˜è¢«ç¦ç”¨æ—¶ï¼Œä½¿ç”¨[Dataset.save_to_disk()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk)æ¥ä¿å­˜æ‚¨çš„è½¬æ¢æ•°æ®é›†ï¼Œå¦åˆ™ä¼šåœ¨ä¼šè¯ç»“æŸæ—¶è¢«åˆ é™¤ã€‚
- en: Hashing
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å“ˆå¸Œ
- en: The fingerprint of a dataset is updated by hashing the function passed to `map`
    as well as the `map` parameters (`batch_size`, `remove_columns`, etc.).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†çš„æŒ‡çº¹é€šè¿‡å¯¹ä¼ é€’ç»™ `map` çš„å‡½æ•°ä»¥åŠ `map` å‚æ•°ï¼ˆ`batch_size`ã€`remove_columns`ç­‰ï¼‰è¿›è¡Œå“ˆå¸Œè®¡ç®—æ¥æ›´æ–°ã€‚
- en: 'You can check the hash of any Python object using the [fingerprint.Hasher](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.fingerprint.Hasher):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨[fingerprint.Hasher](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.fingerprint.Hasher)æ£€æŸ¥ä»»ä½•
    Python å¯¹è±¡çš„å“ˆå¸Œå€¼ï¼š
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The hash is computed by dumping the object using a `dill` pickler and hashing
    the dumped bytes. The pickler recursively dumps all the variables used in your
    function, so any change you do to an object that is used in your function, will
    cause the hash to change.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆå¸Œæ˜¯é€šè¿‡ä½¿ç”¨ `dill` pickler è½¬å‚¨å¯¹è±¡å¹¶å¯¹è½¬å‚¨çš„å­—èŠ‚è¿›è¡Œå“ˆå¸Œè®¡ç®—æ¥è®¡ç®—çš„ã€‚pickler é€’å½’åœ°è½¬å‚¨æ‚¨å‡½æ•°ä¸­ä½¿ç”¨çš„æ‰€æœ‰å˜é‡ï¼Œå› æ­¤æ‚¨å¯¹å‡½æ•°ä¸­ä½¿ç”¨çš„å¯¹è±¡è¿›è¡Œçš„ä»»ä½•æ›´æ”¹éƒ½å°†å¯¼è‡´å“ˆå¸Œå€¼çš„æ›´æ”¹ã€‚
- en: If one of your functions doesnâ€™t seem to have the same hash across sessions,
    it means at least one of its variables contains a Python object that is not deterministic.
    When this happens, feel free to hash any object you find suspicious to try to
    find the object that caused the hash to change. For example, if you use a list
    for which the order of its elements is not deterministic across sessions, then
    the hash wonâ€™t be the same across sessions either.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨çš„æŸä¸ªå‡½æ•°åœ¨ä¸åŒä¼šè¯ä¸­ä¼¼ä¹æ²¡æœ‰ç›¸åŒçš„å“ˆå¸Œå€¼ï¼Œè¿™æ„å‘³ç€è‡³å°‘å…¶ä¸­ä¸€ä¸ªå˜é‡åŒ…å«ä¸€ä¸ªä¸ç¡®å®šçš„ Python å¯¹è±¡ã€‚å½“è¿™ç§æƒ…å†µå‘ç”Ÿæ—¶ï¼Œè¯·éšæ—¶å¯¹æ‚¨å‘ç°å¯ç–‘çš„ä»»ä½•å¯¹è±¡è¿›è¡Œå“ˆå¸Œä»¥å°è¯•æ‰¾åˆ°å¯¼è‡´å“ˆå¸Œå€¼æ›´æ”¹çš„å¯¹è±¡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶å…ƒç´ çš„é¡ºåºåœ¨ä¸åŒä¼šè¯ä¸­æ˜¯ä¸ç¡®å®šçš„ï¼Œé‚£ä¹ˆå“ˆå¸Œå€¼åœ¨ä¸åŒä¼šè¯ä¸­ä¹Ÿä¸ä¼šç›¸åŒã€‚
