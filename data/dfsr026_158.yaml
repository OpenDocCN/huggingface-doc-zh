- en: Shap-E
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Shap-E
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/shap_e](https://huggingface.co/docs/diffusers/api/pipelines/shap_e)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/shap_e](https://huggingface.co/docs/diffusers/api/pipelines/shap_e)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The Shap-E model was proposed in [Shap-E: Generating Conditional 3D Implicit
    Functions](https://huggingface.co/papers/2305.02463) by Alex Nichol and Heewoo
    Jun from [OpenAI](https://github.com/openai).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Shap-E模型是由Alex Nichol和Heewoo Jun提出的，来自OpenAI。
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要为：
- en: '*We present Shap-E, a conditional generative model for 3D assets. Unlike recent
    work on 3D generative models which produce a single output representation, Shap-E
    directly generates the parameters of implicit functions that can be rendered as
    both textured meshes and neural radiance fields. We train Shap-E in two stages:
    first, we train an encoder that deterministically maps 3D assets into the parameters
    of an implicit function; second, we train a conditional diffusion model on outputs
    of the encoder. When trained on a large dataset of paired 3D and text data, our
    resulting models are capable of generating complex and diverse 3D assets in a
    matter of seconds. When compared to Point-E, an explicit generative model over
    point clouds, Shap-E converges faster and reaches comparable or better sample
    quality despite modeling a higher-dimensional, multi-representation output space.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了Shap-E，一个用于3D资产的条件生成模型。与最近关于3D生成模型的工作不同，这些模型产生单个输出表示，Shap-E直接生成可以呈现为纹理网格和神经辐射场的隐式函数的参数。我们分两个阶段训练Shap-E：首先，我们训练一个编码器，将3D资产确定性地映射到隐式函数的参数；其次，我们在编码器的输出上训练一个条件扩散模型。当在大型配对的3D和文本数据集上训练时，我们得到的模型能够在几秒钟内生成复杂和多样化的3D资产。与Point-E相比，Point-E是一个点云上的显式生成模型，Shap-E收敛更快，尽管对建模更高维度、多表示输出空间，但达到了可比较或更好的样本质量。*'
- en: The original codebase can be found at [openai/shap-e](https://github.com/openai/shap-e).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可以在[openai/shap-e](https://github.com/openai/shap-e)找到。
- en: See the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)部分，了解如何有效地将相同组件加载到多个管道中。
- en: ShapEPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ShapEPipeline
- en: '### `class diffusers.ShapEPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.ShapEPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e.py#L79)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e.py#L79)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonical unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior`（[PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer)）—
    用于从文本嵌入近似图像嵌入的规范unCLIP先验。'
- en: '`text_encoder` ([CLIPTextModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelWithProjection))
    — Frozen text-encoder.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（[CLIPTextModelWithProjection](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModelWithProjection)）—
    冻结的文本编码器。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)）—
    用于对文本进行标记化的`CLIPTokenizer`。'
- en: '`scheduler` ([HeunDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/heun#diffusers.HeunDiscreteScheduler))
    — A scheduler to be used in combination with the `prior` model to generate image
    embedding.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[HeunDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/heun#diffusers.HeunDiscreteScheduler)）—
    与`prior`模型结合使用的调度器，用于生成图像嵌入。'
- en: '`shap_e_renderer` (`ShapERenderer`) — Shap-E renderer projects the generated
    latents into parameters of a MLP to create 3D objects with the NeRF rendering
    method.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shap_e_renderer`（`ShapERenderer`）— Shap-E渲染器将生成的潜变量投影到MLP的参数中，以使用NeRF渲染方法创建3D对象。'
- en: Pipeline for generating latent representation of a 3D asset and rendering with
    the NeRF method.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成3D资产的潜在表示并使用NeRF方法进行渲染的管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解所有管道实现的通用方法（下载、保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e.py#L182)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e.py#L182)'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`）— 用于指导图像生成的提示或提示。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`（`int`，*可选*，默认为1）— 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 25) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`（`int`，*可选*，默认为25）— 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`或`List[torch.Generator]`，*可选*）— 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 从高斯分布中采样的预生成的嘈杂潜变量，用作图像生成的输入。可用于使用不同提示微调相同的生成。如果未提供，则通过使用提供的随机`generator`进行采样生成一个潜变量张量。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为4.0) — 更高的引导比例值鼓励模型生成与文本`prompt`密切相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`frame_size` (`int`, *optional*, default to 64) — The width and height of each
    image frame of the generated 3D output.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frame_size` (`int`, *可选*, 默认为64) — 生成的3D输出的每个图像帧的宽度和高度。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`),
    `"latent"` (`torch.Tensor`), or mesh (`MeshDecoderOutput`).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。在`"pil"`（`PIL.Image.Image`）、`"np"`（`np.array`）、`"latent"`（`torch.Tensor`）或网格（`MeshDecoderOutput`）之间进行选择。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    instead of a plain tuple.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    or `tuple`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)，否则返回一个`tuple`，其中第一个元素是包含生成图像的列表。
- en: The call function to the pipeline for generation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ShapEImg2ImgPipeline
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ShapEImg2ImgPipeline
- en: '### `class diffusers.ShapEImg2ImgPipeline`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.ShapEImg2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e_img2img.py#L80)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e_img2img.py#L80)'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入近似图像嵌入的经典unCLIP先验。'
- en: '`image_encoder` ([CLIPVisionModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel))
    — Frozen image-encoder.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_encoder` ([CLIPVisionModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel))
    — 冻结的图像编码器。'
- en: '`image_processor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to process images.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 用于处理图像的`CLIPImageProcessor`。'
- en: '`scheduler` ([HeunDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/heun#diffusers.HeunDiscreteScheduler))
    — A scheduler to be used in combination with the `prior` model to generate image
    embedding.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([HeunDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/heun#diffusers.HeunDiscreteScheduler))
    — 与`prior`模型结合使用以生成图像嵌入的调度器。'
- en: '`shap_e_renderer` (`ShapERenderer`) — Shap-E renderer projects the generated
    latents into parameters of a MLP to create 3D objects with the NeRF rendering
    method.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shap_e_renderer` (`ShapERenderer`) — Shap-E渲染器将生成的潜变量投影到MLP的参数中，以使用NeRF渲染方法创建3D对象。'
- en: Pipeline for generating latent representation of a 3D asset and rendering with
    the NeRF method from an image.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成3D资产的潜在表示并使用NeRF方法从图像渲染的管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取为所有管道实现的通用方法（下载、保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e_img2img.py#L164)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e_img2img.py#L164)'
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image` or tensor representing
    an image batch to be used as the starting point. Can also accept image latents
    as image, but if passing latents directly it is not encoded again.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 代表要用作起点的图像批次的`Image`或张量。也可以接受图像潜变量作为图像，但如果直接传递潜变量，则不会再次编码。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示要生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 25) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为25) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`List[torch.Generator]`, *可选*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 从高斯分布中抽样的预生成噪声潜变量，用作图像生成的输入。可以用来使用不同提示调整相同的生成。如果未提供，则通过使用提供的随机`generator`进行抽样生成潜变量张量。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为4.0) — 更高的引导比例值鼓励模型生成与文本`prompt`密切相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`frame_size` (`int`, *optional*, default to 64) — The width and height of each
    image frame of the generated 3D output.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frame_size` (`int`, *可选*, 默认为64) — 生成的3D输出中每个图像帧的宽度和高度。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`),
    `"latent"` (`torch.Tensor`), or mesh (`MeshDecoderOutput`).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。选择在`"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`)、`"latent"` (`torch.Tensor`)或网格 (`MeshDecoderOutput`)之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    instead of a plain tuple.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回一个[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)而不是一个普通的元组。'
- en: Returns
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    or `tuple`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[ShapEPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput)，否则返回一个元组，其中第一个元素是包含生成图像的列表。
- en: The call function to the pipeline for generation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ShapEPipelineOutput
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ShapEPipelineOutput
- en: '### `class diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.shap_e.pipeline_shap_e.ShapEPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e.py#L66)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/shap_e/pipeline_shap_e.py#L66)'
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`torch.FloatTensor`) — A list of images for 3D rendering.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`torch.FloatTensor`) — 用于3D渲染的图像列表。'
- en: Output class for [ShapEPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.ShapEPipeline)
    and [ShapEImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.ShapEImg2ImgPipeline).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[ShapEPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.ShapEPipeline)和[ShapEImg2ImgPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/shap_e#diffusers.ShapEImg2ImgPipeline)的输出类。'
