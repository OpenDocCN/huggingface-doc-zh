- en: AutoencoderKL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoencoderKL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/autoencoderkl](https://huggingface.co/docs/diffusers/api/models/autoencoderkl)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/diffusers/api/models/autoencoderkl](https://huggingface.co/docs/diffusers/api/models/autoencoderkl)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The variational autoencoder (VAE) model with KL loss was introduced in [Auto-Encoding
    Variational Bayes](https://arxiv.org/abs/1312.6114v11) by Diederik P. Kingma and
    Max Welling. The model is used in 🤗 Diffusers to encode images into latents and
    to decode latent representations into images.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自动编码器（VAE）模型与KL损失在[Diederik P. Kingma和Max Welling的《自动编码变分贝叶斯》](https://arxiv.org/abs/1312.6114v11)中引入。该模型用于将图像编码为潜在变量，并将潜在表示解码为图像。
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*How can we perform efficient inference and learning in directed probabilistic
    models, in the presence of continuous latent variables with intractable posterior
    distributions, and large datasets? We introduce a stochastic variational inference
    and learning algorithm that scales to large datasets and, under some mild differentiability
    conditions, even works in the intractable case. Our contributions are two-fold.
    First, we show that a reparameterization of the variational lower bound yields
    a lower bound estimator that can be straightforwardly optimized using standard
    stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous
    latent variables per datapoint, posterior inference can be made especially efficient
    by fitting an approximate inference model (also called a recognition model) to
    the intractable posterior using the proposed lower bound estimator. Theoretical
    advantages are reflected in experimental results.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何在连续潜在变量具有难以处理的后验分布和大型数据集的情况下，在有向概率模型中执行高效的推断和学习？我们引入了一种随机变分推断和学习算法，可扩展到大型数据集，并且在一些温和的可微条件下，甚至在难以处理的情况下也能工作。我们的贡献有两个方面。首先，我们表明变分下界的重新参数化产生了一个下界估计器，可以通过标准随机梯度方法直接优化。其次，我们表明对于具有连续潜在变量的i.i.d.数据集，通过使用提出的下界估计器将近似推断模型（也称为识别模型）拟合到难以处理的后验，可以使后验推断特别高效。理论优势在实验结果中得到体现。*'
- en: Loading from the original format
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从原始格式加载
- en: 'By default the [AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)
    should be loaded with [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained),
    but it can also be loaded from the original format using `FromOriginalVAEMixin.from_single_file`
    as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，应使用[from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)加载[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)，但也可以使用`FromOriginalVAEMixin.from_single_file`从原始格式加载，如下所示：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: AutoencoderKL
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoencoderKL
- en: '### `class diffusers.AutoencoderKL`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.AutoencoderKL`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L35)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L35)'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`in_channels` (int, *optional*, defaults to 3) — Number of channels in the
    input image.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_channels`（int，*可选*，默认为3）— 输入图像中的通道数。'
- en: '`out_channels` (int, *optional*, defaults to 3) — Number of channels in the
    output.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_channels`（int，*可选*，默认为3）— 输出中的通道数。'
- en: '`down_block_types` (`Tuple[str]`, *optional*, defaults to `("DownEncoderBlock2D",)`)
    — Tuple of downsample block types.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`down_block_types`（`Tuple[str]`，*可选*，默认为`("DownEncoderBlock2D",)`）— 下采样块类型的元组。'
- en: '`up_block_types` (`Tuple[str]`, *optional*, defaults to `("UpDecoderBlock2D",)`)
    — Tuple of upsample block types.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`up_block_types`（`Tuple[str]`，*可选*，默认为`("UpDecoderBlock2D",)`）— 上采样块类型的元组。'
- en: '`block_out_channels` (`Tuple[int]`, *optional*, defaults to `(64,)`) — Tuple
    of block output channels.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_out_channels`（`Tuple[int]`，*可选*，默认为`(64,)`）— 块输出通道的元组。'
- en: '`act_fn` (`str`, *optional*, defaults to `"silu"`) — The activation function
    to use.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`act_fn`（`str`，*可选*，默认为`"silu"`）— 要使用的激活函数。'
- en: '`latent_channels` (`int`, *optional*, defaults to 4) — Number of channels in
    the latent space.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_channels`（`int`，*可选*，默认为4）— 潜在空间中的通道数。'
- en: '`sample_size` (`int`, *optional*, defaults to `32`) — Sample input size.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_size`（`int`，*可选*，默认为`32`）— 样本输入大小。'
- en: '`scaling_factor` (`float`, *optional*, defaults to 0.18215) — The component-wise
    standard deviation of the trained latent space computed using the first batch
    of the training set. This is used to scale the latent space to have unit variance
    when training the diffusion model. The latents are scaled with the formula `z
    = z * scaling_factor` before being passed to the diffusion model. When decoding,
    the latents are scaled back to the original scale with the formula: `z = 1 / scaling_factor
    * z`. For more details, refer to sections 4.3.2 and D.1 of the [High-Resolution
    Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)
    paper.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scaling_factor`（`float`，*可选*，默认为0.18215）— 使用训练集的第一批计算出的训练潜在空间的分量标准差。在训练扩散模型时，用于将潜在空间缩放为单位方差。在传递给扩散模型之前，潜在变量使用公式`z
    = z * scaling_factor`进行缩放。解码时，潜在变量使用公式进行缩放回原始比例：`z = 1 / scaling_factor * z`。有关更多详细信息，请参阅[具有潜在扩散模型的高分辨率图像合成](https://arxiv.org/abs/2112.10752)论文的4.3.2和D.1节。'
- en: '`force_upcast` (`bool`, *optional*, default to `True`) — If enabled it will
    force the VAE to run in float32 for high image resolution pipelines, such as SD-XL.
    VAE can be fine-tuned / trained to a lower range without loosing too much precision
    in which case `force_upcast` can be set to `False` - see: [https://huggingface.co/madebyollin/sdxl-vae-fp16-fix](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_upcast`（`bool`，*可选*，默认为`True`）— 如果启用，它将强制VAE在高分辨率图像管道（如SD-XL）中以float32运行。
    VAE可以微调/训练到较低范围而不会失去太多精度，在这种情况下，`force_upcast`可以设置为`False` - 参见：[https://huggingface.co/madebyollin/sdxl-vae-fp16-fix](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)'
- en: A VAE model with KL loss for encoding images into latents and decoding latent
    representations into images.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 具有KL损失的VAE模型，用于将图像编码为潜在变量，并将潜在表示解码为图像。
- en: This model inherits from [ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin).
    Check the superclass documentation for it’s generic methods implemented for all
    models (such as downloading or saving).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)。查看超类文档以了解为所有模型实现的通用方法（例如下载或保存）。
- en: '#### `wrapper`'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `wrapper`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)'
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `wrapper`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `wrapper`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)'
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#### `disable_slicing`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L152)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L152)'
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable sliced VAE decoding. If `enable_slicing` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果之前启用了`enable_slicing`，则此方法将返回到一步计算解码。
- en: '#### `disable_tiling`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L138)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L138)'
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable tiled VAE decoding. If `enable_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺VAE解码。如果之前启用了`enable_tiling`，则此方法将返回到一步计算解码。
- en: '#### `enable_slicing`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L145)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L145)'
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。当启用此选项时，VAE将将输入张量分割成切片，以便在多个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `enable_tiling`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L130)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L130)'
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺VAE解码。当启用此选项时，VAE将将输入张量分割成瓦片，以便在多个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `forward`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L423)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L423)'
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor`) — Input sample.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（`torch.FloatTensor`）— 输入样本。'
- en: '`sample_posterior` (`bool`, *optional*, defaults to `False`) — Whether to sample
    from the posterior.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_posterior`（`bool`，*可选*，默认为`False`）— 是否从后验中抽样。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `DecoderOutput` instead of a plain tuple.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`DecoderOutput`而不是普通元组。'
- en: '#### `fuse_qkv_projections`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `fuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L452)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L452)'
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 启用融合QKV投影。对于自注意力模块，所有投影矩阵（即查询、键、值）都被融合。对于交叉注意力模块，键和值投影矩阵被融合。
- en: This API is 🧪 experimental.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此API为🧪实验性质。
- en: '#### `set_attn_processor`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_attn_processor`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L185)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L185)'
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`processor` (`dict` of `AttentionProcessor` or only `AttentionProcessor`) —
    The instantiated processor class or a dictionary of processor classes that will
    be set as the processor for **all** `Attention` layers.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processor`（`dict`或仅`AttentionProcessor`）— 实例化的处理器类或将设置为**所有**`Attention`层的处理器类字典。'
- en: If `processor` is a dict, the key needs to define the path to the corresponding
    cross attention processor. This is strongly recommended when setting trainable
    attention processors.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`processor`是一个字典，则键需要定义相应交叉注意力处理器的路径。在设置可训练的注意力处理器时，强烈建议这样做。
- en: Sets the attention processor to use to compute attention.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于计算注意力的注意力处理器。
- en: '#### `set_default_attn_processor`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_default_attn_processor`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L220)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L220)'
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Disables custom attention processors and sets the default attention implementation.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用自定义注意力处理器并设置默认的注意力实现。
- en: '#### `tiled_decode`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tiled_decode`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L375)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L375)'
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`z` (`torch.FloatTensor`) — Input batch of latent vectors.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`z`（`torch.FloatTensor`）— 潜在向量的输入批次。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `~models.vae.DecoderOutput` instead of a plain tuple.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`~models.vae.DecoderOutput`而不是普通的元组。'
- en: Returns
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`~models.vae.DecoderOutput` or `tuple`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`~models.vae.DecoderOutput`或`tuple`'
- en: If return_dict is True, a `~models.vae.DecoderOutput` is returned, otherwise
    a plain `tuple` is returned.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为True，则返回`~models.vae.DecoderOutput`，否则返回普通的`tuple`。
- en: Decode a batch of images using a tiled decoder.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用平铺解码器解码一批图像。
- en: '#### `tiled_encode`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tiled_encode`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L321)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L321)'
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`x` (`torch.FloatTensor`) — Input batch of images.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`（`torch.FloatTensor`）-图像的输入批次。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `~models.autoencoder_kl.AutoencoderKLOutput` instead of a plain tuple.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）-是否返回`~models.autoencoder_kl.AutoencoderKLOutput`而不是普通的元组。'
- en: Returns
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`~models.autoencoder_kl.AutoencoderKLOutput` or `tuple`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`~models.autoencoder_kl.AutoencoderKLOutput`或`tuple`'
- en: If return_dict is True, a `~models.autoencoder_kl.AutoencoderKLOutput` is returned,
    otherwise a plain `tuple` is returned.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果return_dict为True，则返回`~models.autoencoder_kl.AutoencoderKLOutput`，否则返回普通的`tuple`。
- en: Encode a batch of images using a tiled encoder.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用瓦片编码批量图像。
- en: When this option is enabled, the VAE will split the input tensor into tiles
    to compute encoding in several steps. This is useful to keep memory use constant
    regardless of image size. The end result of tiled encoding is different from non-tiled
    encoding because each tile uses a different encoder. To avoid tiling artifacts,
    the tiles overlap and are blended together to form a smooth output. You may still
    see tile-sized changes in the output, but they should be much less noticeable.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 启用此选项时，VAE将输入张量分割成瓦片以在几个步骤中计算编码。这对于保持内存使用量恒定而不受图像大小影响很有用。瓦片编码的最终结果与非瓦片编码不同，因为每个瓦片使用不同的编码器。为了避免瓦片伪影，瓦片重叠并混合在一起以形成平滑的输出。您仍然可能看到输出中的瓦片大小变化，但它们应该不太明显。
- en: '#### `unfuse_qkv_projections`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unfuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L476)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L476)'
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Disables the fused QKV projection if enabled.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用，禁用融合的QKV投影。
- en: This API is 🧪 experimental.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此API为🧪实验性质。
- en: AutoencoderKLOutput
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动编码器KL输出
- en: '### `class diffusers.models.modeling_outputs.AutoencoderKLOutput`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.modeling_outputs.AutoencoderKLOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_outputs.py#L6)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_outputs.py#L6)'
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`latent_dist` (`DiagonalGaussianDistribution`) — Encoded outputs of `Encoder`
    represented as the mean and logvar of `DiagonalGaussianDistribution`. `DiagonalGaussianDistribution`
    allows for sampling latents from the distribution.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_dist`（`DiagonalGaussianDistribution`）-`Encoder`的编码输出表示为`DiagonalGaussianDistribution`的均值和logvar。`DiagonalGaussianDistribution`允许从分布中采样潜在变量。'
- en: Output of AutoencoderKL encoding method.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: AutoencoderKL编码方法的输出。
- en: DecoderOutput
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DecoderOutput
- en: '### `class diffusers.models.autoencoders.vae.DecoderOutput`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.autoencoders.vae.DecoderOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/vae.py#L33)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/vae.py#L33)'
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — The decoded output sample from the last layer of the model.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）-模型最后一层的解码输出样本。'
- en: Output of decoding method.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 解码方法的输出。
- en: FlaxAutoencoderKL
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxAutoencoderKL
- en: '### `class diffusers.FlaxAutoencoderKL`'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.FlaxAutoencoderKL`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L726)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L726)'
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`in_channels` (`int`, *optional*, defaults to 3) — Number of channels in the
    input image.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_channels`（`int`，*可选*，默认为3）-输入图像中的通道数。'
- en: '`out_channels` (`int`, *optional*, defaults to 3) — Number of channels in the
    output.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_channels`（`int`，*可选*，默认为3）-输出中的通道数。'
- en: '`down_block_types` (`Tuple[str]`, *optional*, defaults to `(DownEncoderBlock2D)`)
    — Tuple of downsample block types.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`down_block_types`（`Tuple[str]`，*可选*，默认为`(DownEncoderBlock2D)`）-下采样块类型的元组。'
- en: '`up_block_types` (`Tuple[str]`, *optional*, defaults to `(UpDecoderBlock2D)`)
    — Tuple of upsample block types.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`up_block_types`（`Tuple[str]`，*可选*，默认为`(UpDecoderBlock2D)`）-上采样块类型的元组。'
- en: '`block_out_channels` (`Tuple[str]`, *optional*, defaults to `(64,)`) — Tuple
    of block output channels.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_out_channels`（`Tuple[str]`，*可选*，默认为`(64,)`）-块输出通道的元组。'
- en: '`layers_per_block` (`int`, *optional*, defaults to `2`) — Number of ResNet
    layer for each block.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layers_per_block`（`int`，*可选*，默认为`2`）-每个块的ResNet层数。'
- en: '`act_fn` (`str`, *optional*, defaults to `silu`) — The activation function
    to use.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`act_fn`（`str`，*可选*，默认为`silu`）-要使用的激活函数。'
- en: '`latent_channels` (`int`, *optional*, defaults to `4`) — Number of channels
    in the latent space.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_channels`（`int`，*可选*，默认为`4`）-潜在空间中的通道数。'
- en: '`norm_num_groups` (`int`, *optional*, defaults to `32`) — The number of groups
    for normalization.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`norm_num_groups`（`int`，*可选*，默认为`32`）-规范化的组数。'
- en: '`sample_size` (`int`, *optional*, defaults to 32) — Sample input size.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_size`（`int`，*可选*，默认为32）-样本输入大小。'
- en: '`scaling_factor` (`float`, *optional*, defaults to 0.18215) — The component-wise
    standard deviation of the trained latent space computed using the first batch
    of the training set. This is used to scale the latent space to have unit variance
    when training the diffusion model. The latents are scaled with the formula `z
    = z * scaling_factor` before being passed to the diffusion model. When decoding,
    the latents are scaled back to the original scale with the formula: `z = 1 / scaling_factor
    * z`. For more details, refer to sections 4.3.2 and D.1 of the [High-Resolution
    Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)
    paper.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scaling_factor`（`float`，*可选*，默认为0.18215）-使用训练集的第一批计算的训练潜在空间的分量标准差。这用于在训练扩散模型时将潜在空间缩放为单位方差。在传递给扩散模型之前，潜在空间使用公式`z
    = z * scaling_factor`进行缩放。解码时，潜在变量使用公式缩放回原始比例：`z = 1 / scaling_factor * z`。有关更多详细信息，请参阅[具有潜在扩散模型的高分辨率图像合成](https://arxiv.org/abs/2112.10752)论文的4.3.2和D.1节。'
- en: '`dtype` (`jnp.dtype`, *optional*, defaults to `jnp.float32`) — The `dtype`
    of the parameters.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jnp.dtype`, *可选*, 默认为 `jnp.float32`) — 参数的`dtype`。'
- en: Flax implementation of a VAE model with KL loss for decoding latent representations.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 带有KL损失的解码潜在表示的Flax VAE模型的实现。
- en: This model inherits from [FlaxModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin).
    Check the superclass documentation for it’s generic methods implemented for all
    models (such as downloading or saving).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[FlaxModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin)。查看超类文档以了解为所有模型实现的通用方法（如下载或保存）。
- en: This model is a Flax Linen [flax.linen.Module](https://flax.readthedocs.io/en/latest/flax.linen.html#module)
    subclass. Use it as a regular Flax Linen module and refer to the Flax documentation
    for all matter related to its general usage and behavior.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个Flax Linen [flax.linen.Module](https://flax.readthedocs.io/en/latest/flax.linen.html#module)子类。将其用作常规的Flax
    Linen模块，并参考Flax文档以了解与其一般使用和行为相关的所有事项。
- en: 'Inherent JAX features such as the following are supported:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 支持以下JAX特性：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时编译（JIT）](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: FlaxAutoencoderKLOutput
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxAutoencoderKLOutput
- en: '### `class diffusers.models.vae_flax.FlaxAutoencoderKLOutput`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.vae_flax.FlaxAutoencoderKLOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L47)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L47)'
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`latent_dist` (`FlaxDiagonalGaussianDistribution`) — Encoded outputs of `Encoder`
    represented as the mean and logvar of `FlaxDiagonalGaussianDistribution`. `FlaxDiagonalGaussianDistribution`
    allows for sampling latents from the distribution.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latent_dist` (`FlaxDiagonalGaussianDistribution`) — `Encoder`的编码输出，表示为`FlaxDiagonalGaussianDistribution`的均值和logvar。`FlaxDiagonalGaussianDistribution`允许从分布中采样潜在变量。'
- en: Output of AutoencoderKL encoding method.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: AutoencoderKL编码方法的输出。
- en: '#### `replace`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `replace`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
- en: '[PRE19]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: “Returns a new object replacing the specified fields with new values.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: “返回一个用新值替换指定字段的新对象。
- en: FlaxDecoderOutput
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxDecoderOutput
- en: '### `class diffusers.models.vae_flax.FlaxDecoderOutput`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.vae_flax.FlaxDecoderOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L32)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L32)'
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`jnp.ndarray` of shape `(batch_size, num_channels, height, width)`)
    — The decoded output sample from the last layer of the model.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`样本` (`形状为`(batch_size, num_channels, height, width)`的`jnp.ndarray`) — 模型最后一层的解码输出样本。'
- en: '`dtype` (`jnp.dtype`, *optional*, defaults to `jnp.float32`) — The `dtype`
    of the parameters.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jnp.dtype`, *可选*, 默认为 `jnp.float32`) — 参数的`dtype`。'
- en: Output of decoding method.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 解码方法的输出。
- en: '#### `replace`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `replace`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)'
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: “Returns a new object replacing the specified fields with new values.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: “返回一个用新值替换指定字段的新对象。
