- en: Time Series Transformer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—Transformer
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/time_series_transformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/time_series_transformer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/time_series_transformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/time_series_transformer)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: The Time Series Transformer model is a vanilla encoder-decoder Transformer for
    time series forecasting. This model was contributed by [kashif](https://huggingface.co/kashif).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—Transformeræ¨¡å‹æ˜¯ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹çš„åŸºæœ¬ç¼–ç å™¨-è§£ç å™¨Transformerã€‚æ­¤æ¨¡å‹ç”±[kashif](https://huggingface.co/kashif)è´¡çŒ®ã€‚
- en: Usage tips
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æç¤º
- en: Similar to other models in the library, [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    is the raw Transformer without any head on top, and [TimeSeriesTransformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction)
    adds a distribution head on top of the former, which can be used for time-series
    forecasting. Note that this is a so-called probabilistic forecasting model, not
    a point forecasting model. This means that the model learns a distribution, from
    which one can sample. The model doesnâ€™t directly output values.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸åº“ä¸­å…¶ä»–æ¨¡å‹ç±»ä¼¼ï¼Œ[TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)æ˜¯æ²¡æœ‰é¡¶éƒ¨å¤´éƒ¨çš„åŸå§‹Transformerï¼Œè€Œ[TimeSeriesTransformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction)åœ¨å‰è€…çš„é¡¶éƒ¨æ·»åŠ äº†ä¸€ä¸ªåˆ†å¸ƒå¤´éƒ¨ï¼Œå¯ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚è¯·æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ç§æ‰€è°“çš„æ¦‚ç‡é¢„æµ‹æ¨¡å‹ï¼Œè€Œä¸æ˜¯ç‚¹é¢„æµ‹æ¨¡å‹ã€‚è¿™æ„å‘³ç€æ¨¡å‹å­¦ä¹ ä¸€ä¸ªåˆ†å¸ƒï¼Œå¯ä»¥ä»ä¸­è¿›è¡Œé‡‡æ ·ã€‚è¯¥æ¨¡å‹ä¸ç›´æ¥è¾“å‡ºå€¼ã€‚
- en: '[TimeSeriesTransformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction)
    consists of 2 blocks: an encoder, which takes a `context_length` of time series
    values as input (called `past_values`), and a decoder, which predicts a `prediction_length`
    of time series values into the future (called `future_values`). During training,
    one needs to provide pairs of (`past_values` and `future_values`) to the model.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TimeSeriesTransformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction)ç”±2ä¸ªæ¨¡å—ç»„æˆï¼šç¼–ç å™¨ï¼Œæ¥å—æ—¶é—´åºåˆ—å€¼çš„`context_length`ä½œä¸ºè¾“å…¥ï¼ˆç§°ä¸º`past_values`ï¼‰ï¼Œè§£ç å™¨ï¼Œé¢„æµ‹æœªæ¥çš„`prediction_length`æ—¶é—´åºåˆ—å€¼ï¼ˆç§°ä¸º`future_values`ï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéœ€è¦å‘æ¨¡å‹æä¾›ï¼ˆ`past_values`å’Œ`future_values`ï¼‰çš„é…å¯¹æ•°æ®ã€‚'
- en: 'In addition to the raw (`past_values` and `future_values`), one typically provides
    additional features to the model. These can be the following:'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†åŸå§‹çš„ï¼ˆ`past_values`å’Œ`future_values`ï¼‰ä¹‹å¤–ï¼Œé€šå¸¸è¿˜å‘æ¨¡å‹æä¾›å…¶ä»–ç‰¹å¾ã€‚è¿™äº›å¯ä»¥æ˜¯ä»¥ä¸‹å†…å®¹ï¼š
- en: '`past_time_features`: temporal features which the model will add to `past_values`.
    These serve as â€œpositional encodingsâ€ for the Transformer encoder. Examples are
    â€œday of the monthâ€, â€œmonth of the yearâ€, etc. as scalar values (and then stacked
    together as a vector). e.g. if a given time-series value was obtained on the 11th
    of August, then one could have [11, 8] as time feature vector (11 being â€œday of
    the monthâ€, 8 being â€œmonth of the yearâ€).'
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_time_features`ï¼šæ¨¡å‹å°†æ·»åŠ åˆ°`past_values`çš„æ—¶é—´ç‰¹å¾ã€‚è¿™äº›ä½œä¸ºTransformerç¼–ç å™¨çš„â€œä½ç½®ç¼–ç â€ã€‚ä¾‹å¦‚ï¼Œâ€œæœˆä»½çš„æ—¥æœŸâ€ï¼Œâ€œå¹´ä»½çš„æœˆä»½â€ç­‰ä½œä¸ºæ ‡é‡å€¼ï¼ˆç„¶åå †å åœ¨ä¸€èµ·å½¢æˆå‘é‡ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç»™å®šçš„æ—¶é—´åºåˆ—å€¼æ˜¯åœ¨8æœˆ11æ—¥è·å¾—çš„ï¼Œåˆ™å¯ä»¥å°†[11,
    8]ä½œä¸ºæ—¶é—´ç‰¹å¾å‘é‡ï¼ˆ11ä»£è¡¨â€œæœˆä»½çš„æ—¥æœŸâ€ï¼Œ8ä»£è¡¨â€œå¹´ä»½çš„æœˆä»½â€ï¼‰ã€‚'
- en: '`future_time_features`: temporal features which the model will add to `future_values`.
    These serve as â€œpositional encodingsâ€ for the Transformer decoder. Examples are
    â€œday of the monthâ€, â€œmonth of the yearâ€, etc. as scalar values (and then stacked
    together as a vector). e.g. if a given time-series value was obtained on the 11th
    of August, then one could have [11, 8] as time feature vector (11 being â€œday of
    the monthâ€, 8 being â€œmonth of the yearâ€).'
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_time_features`ï¼šæ¨¡å‹å°†æ·»åŠ åˆ°`future_values`çš„æ—¶é—´ç‰¹å¾ã€‚è¿™äº›ä½œä¸ºTransformerè§£ç å™¨çš„â€œä½ç½®ç¼–ç â€ã€‚ä¾‹å¦‚ï¼Œâ€œæœˆä»½çš„æ—¥æœŸâ€ï¼Œâ€œå¹´ä»½çš„æœˆä»½â€ç­‰ä½œä¸ºæ ‡é‡å€¼ï¼ˆç„¶åå †å åœ¨ä¸€èµ·å½¢æˆå‘é‡ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç»™å®šçš„æ—¶é—´åºåˆ—å€¼æ˜¯åœ¨8æœˆ11æ—¥è·å¾—çš„ï¼Œåˆ™å¯ä»¥å°†[11,
    8]ä½œä¸ºæ—¶é—´ç‰¹å¾å‘é‡ï¼ˆ11ä»£è¡¨â€œæœˆä»½çš„æ—¥æœŸâ€ï¼Œ8ä»£è¡¨â€œå¹´ä»½çš„æœˆä»½â€ï¼‰ã€‚'
- en: '`static_categorical_features`: categorical features which are static over time
    (i.e., have the same value for all `past_values` and `future_values`). An example
    here is the store ID or region ID that identifies a given time-series. Note that
    these features need to be known for ALL data points (also those in the future).'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_categorical_features`ï¼šéšæ—¶é—´ä¿æŒä¸å˜çš„åˆ†ç±»ç‰¹å¾ï¼ˆå³æ‰€æœ‰`past_values`å’Œ`future_values`å…·æœ‰ç›¸åŒçš„å€¼ï¼‰ã€‚ä¸€ä¸ªä¾‹å­æ˜¯æ ‡è¯†ç»™å®šæ—¶é—´åºåˆ—çš„å•†åº—IDæˆ–åœ°åŒºIDã€‚è¯·æ³¨æ„ï¼Œè¿™äº›ç‰¹å¾éœ€è¦å¯¹æ‰€æœ‰æ•°æ®ç‚¹ï¼ˆåŒ…æ‹¬æœªæ¥çš„æ•°æ®ç‚¹ï¼‰éƒ½æ˜¯å·²çŸ¥çš„ã€‚'
- en: '`static_real_features`: real-valued features which are static over time (i.e.,
    have the same value for all `past_values` and `future_values`). An example here
    is the image representation of the product for which you have the time-series
    values (like the [ResNet](resnet) embedding of a â€œshoeâ€ picture, if your time-series
    is about the sales of shoes). Note that these features need to be known for ALL
    data points (also those in the future).'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_real_features`ï¼šéšæ—¶é—´ä¿æŒä¸å˜çš„å®å€¼ç‰¹å¾ï¼ˆå³æ‰€æœ‰`past_values`å’Œ`future_values`å…·æœ‰ç›¸åŒçš„å€¼ï¼‰ã€‚ä¸€ä¸ªä¾‹å­æ˜¯äº§å“çš„å›¾åƒè¡¨ç¤ºï¼Œæ‚¨æ‹¥æœ‰è¯¥äº§å“çš„æ—¶é—´åºåˆ—å€¼ï¼ˆæ¯”å¦‚å…³äºé‹å­é”€å”®çš„æ—¶é—´åºåˆ—çš„[ResNet](resnet)åµŒå…¥çš„â€œé‹å­â€å›¾ç‰‡ï¼‰ã€‚è¯·æ³¨æ„ï¼Œè¿™äº›ç‰¹å¾éœ€è¦å¯¹æ‰€æœ‰æ•°æ®ç‚¹ï¼ˆåŒ…æ‹¬æœªæ¥çš„æ•°æ®ç‚¹ï¼‰éƒ½æ˜¯å·²çŸ¥çš„ã€‚'
- en: The model is trained using â€œteacher-forcingâ€, similar to how a Transformer is
    trained for machine translation. This means that, during training, one shifts
    the `future_values` one position to the right as input to the decoder, prepended
    by the last value of `past_values`. At each time step, the model needs to predict
    the next target. So the set-up of training is similar to a GPT model for language,
    except that thereâ€™s no notion of `decoder_start_token_id` (we just use the last
    value of the context as initial input for the decoder).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ä½¿ç”¨â€œteacher-forcingâ€è¿›è¡Œè®­ç»ƒï¼Œç±»ä¼¼äºTransformerç”¨äºæœºå™¨ç¿»è¯‘çš„è®­ç»ƒæ–¹å¼ã€‚è¿™æ„å‘³ç€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå°†`future_values`å‘å³ç§»åŠ¨ä¸€ä¸ªä½ç½®ä½œä¸ºè§£ç å™¨çš„è¾“å…¥ï¼Œå‰é¢åŠ ä¸Š`past_values`çš„æœ€åä¸€ä¸ªå€¼ã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ï¼Œæ¨¡å‹éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªç›®æ ‡ã€‚å› æ­¤ï¼Œè®­ç»ƒçš„è®¾ç½®ç±»ä¼¼äºç”¨äºè¯­è¨€çš„GPTæ¨¡å‹ï¼Œåªæ˜¯æ²¡æœ‰`decoder_start_token_id`çš„æ¦‚å¿µï¼ˆæˆ‘ä»¬åªä½¿ç”¨ä¸Šä¸‹æ–‡çš„æœ€åä¸€ä¸ªå€¼ä½œä¸ºè§£ç å™¨çš„åˆå§‹è¾“å…¥ï¼‰ã€‚
- en: At inference time, we give the final value of the `past_values` as input to
    the decoder. Next, we can sample from the model to make a prediction at the next
    time step, which is then fed to the decoder in order to make the next prediction
    (also called autoregressive generation).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¨æ–­æ—¶ï¼Œæˆ‘ä»¬å°†`past_values`çš„æœ€ç»ˆå€¼ä½œä¸ºè¾“å…¥ä¼ é€’ç»™è§£ç å™¨ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ä»æ¨¡å‹ä¸­è¿›è¡Œé‡‡æ ·ï¼Œä»¥åœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥éª¤è¿›è¡Œé¢„æµ‹ï¼Œç„¶åå°†å…¶é¦ˆé€ç»™è§£ç å™¨ä»¥è¿›è¡Œä¸‹ä¸€ä¸ªé¢„æµ‹ï¼ˆä¹Ÿç§°ä¸ºè‡ªå›å½’ç”Ÿæˆï¼‰ã€‚
- en: Resources
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started. If youâ€™re interested in submitting a resource to be included
    here, please feel free to open a Pull Request and weâ€™ll review it! The resource
    should ideally demonstrate something new instead of duplicating an existing resource.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç³»åˆ—å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºï¼Œå¯å¸®åŠ©æ‚¨å…¥é—¨ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ªPull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥å±•ç¤ºä¸€äº›æ–°å†…å®¹ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: 'Check out the Time Series Transformer blog-post in HuggingFace blog: [Probabilistic
    Time Series Forecasting with ğŸ¤— Transformers](https://huggingface.co/blog/time-series-transformers)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨HuggingFaceåšå®¢ä¸­æŸ¥çœ‹æ—¶é—´åºåˆ—Transformeråšæ–‡ï¼š[ä½¿ç”¨ğŸ¤— Transformersè¿›è¡Œæ¦‚ç‡æ—¶é—´åºåˆ—é¢„æµ‹](https://huggingface.co/blog/time-series-transformers)
- en: TimeSeriesTransformerConfig
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TimeSeriesTransformerConfig
- en: '### `class transformers.TimeSeriesTransformerConfig`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TimeSeriesTransformerConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/configuration_time_series_transformer.py#L33)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/configuration_time_series_transformer.py#L33)'
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prediction_length` (`int`) â€” The prediction length for the decoder. In other
    words, the prediction horizon of the model. This value is typically dictated by
    the dataset and we recommend to set it appropriately.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_length` (`int`) â€” è§£ç å™¨çš„é¢„æµ‹é•¿åº¦ã€‚æ¢å¥è¯è¯´ï¼Œæ¨¡å‹çš„é¢„æµ‹èŒƒå›´ã€‚æ­¤å€¼é€šå¸¸ç”±æ•°æ®é›†å†³å®šï¼Œæˆ‘ä»¬å»ºè®®é€‚å½“è®¾ç½®ã€‚'
- en: '`context_length` (`int`, *optional*, defaults to `prediction_length`) â€” The
    context length for the encoder. If `None`, the context length will be the same
    as the `prediction_length`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context_length` (`int`, *å¯é€‰*, é»˜è®¤ä¸º`prediction_length`) â€” ç¼–ç å™¨çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚å¦‚æœä¸º`None`ï¼Œä¸Šä¸‹æ–‡é•¿åº¦å°†ä¸`prediction_length`ç›¸åŒã€‚'
- en: '`distribution_output` (`string`, *optional*, defaults to `"student_t"`) â€” The
    distribution emission head for the model. Could be either â€œstudent_tâ€, â€œnormalâ€
    or â€œnegative_binomialâ€.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distribution_output` (`string`, *å¯é€‰*, é»˜è®¤ä¸º`"student_t"`) â€” æ¨¡å‹çš„åˆ†å¸ƒå‘å°„å¤´ã€‚å¯ä»¥æ˜¯â€œstudent_tâ€ã€â€œnormalâ€æˆ–â€œnegative_binomialâ€ä¹‹ä¸€ã€‚'
- en: '`loss` (`string`, *optional*, defaults to `"nll"`) â€” The loss function for
    the model corresponding to the `distribution_output` head. For parametric distributions
    it is the negative log likelihood (nll) - which currently is the only supported
    one.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`string`, *å¯é€‰*, é»˜è®¤ä¸º`"nll"`) â€” ä¸`distribution_output`å¤´å¯¹åº”çš„æ¨¡å‹æŸå¤±å‡½æ•°ã€‚å¯¹äºå‚æ•°åˆ†å¸ƒï¼Œå®ƒæ˜¯è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆnllï¼‰-
    ç›®å‰æ˜¯å”¯ä¸€æ”¯æŒçš„æŸå¤±å‡½æ•°ã€‚'
- en: '`input_size` (`int`, *optional*, defaults to 1) â€” The size of the target variable
    which by default is 1 for univariate targets. Would be > 1 in case of multivariate
    targets.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º1) â€” ç›®æ ‡å˜é‡çš„å¤§å°ï¼Œé»˜è®¤æƒ…å†µä¸‹å¯¹äºå•å˜é‡ç›®æ ‡ä¸º1ã€‚å¯¹äºå¤šå˜é‡ç›®æ ‡ï¼Œå°†å¤§äº1ã€‚'
- en: '`scaling` (`string` or `bool`, *optional* defaults to `"mean"`) â€” Whether to
    scale the input targets via â€œmeanâ€ scaler, â€œstdâ€ scaler or no scaler if `None`.
    If `True`, the scaler is set to â€œmeanâ€.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scaling` (`string`æˆ–`bool`, *å¯é€‰*, é»˜è®¤ä¸º`"mean"`) â€” æ˜¯å¦é€šè¿‡â€œmeanâ€ç¼©æ”¾å™¨ã€â€œstdâ€ç¼©æ”¾å™¨æˆ–å¦‚æœä¸º`None`åˆ™ä¸è¿›è¡Œç¼©æ”¾æ¥ç¼©æ”¾è¾“å…¥ç›®æ ‡ã€‚å¦‚æœä¸º`True`ï¼Œåˆ™ç¼©æ”¾å™¨è®¾ç½®ä¸ºâ€œmeanâ€ã€‚'
- en: '`lags_sequence` (`list[int]`, *optional*, defaults to `[1, 2, 3, 4, 5, 6, 7]`)
    â€” The lags of the input time series as covariates often dictated by the frequency
    of the data. Default is `[1, 2, 3, 4, 5, 6, 7]` but we recommend to change it
    based on the dataset appropriately.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lags_sequence` (`list[int]`, *å¯é€‰*, é»˜è®¤ä¸º`[1, 2, 3, 4, 5, 6, 7]`) â€” è¾“å…¥æ—¶é—´åºåˆ—çš„æ»åä½œä¸ºåå˜é‡çš„æ»åï¼Œé€šå¸¸ç”±æ•°æ®çš„é¢‘ç‡å†³å®šã€‚é»˜è®¤ä¸º`[1,
    2, 3, 4, 5, 6, 7]`ï¼Œä½†æˆ‘ä»¬å»ºè®®æ ¹æ®æ•°æ®é›†é€‚å½“åœ°è¿›è¡Œæ›´æ”¹ã€‚'
- en: '`num_time_features` (`int`, *optional*, defaults to 0) â€” The number of time
    features in the input time series.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_time_features` (`int`, *å¯é€‰*, é»˜è®¤ä¸º0) â€” è¾“å…¥æ—¶é—´åºåˆ—ä¸­çš„æ—¶é—´ç‰¹å¾æ•°é‡ã€‚'
- en: '`num_dynamic_real_features` (`int`, *optional*, defaults to 0) â€” The number
    of dynamic real valued features.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_dynamic_real_features` (`int`, *å¯é€‰*, é»˜è®¤ä¸º0) â€” åŠ¨æ€å®å€¼ç‰¹å¾çš„æ•°é‡ã€‚'
- en: '`num_static_categorical_features` (`int`, *optional*, defaults to 0) â€” The
    number of static categorical features.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_static_categorical_features` (`int`, *å¯é€‰*, é»˜è®¤ä¸º0) â€” é™æ€åˆ†ç±»ç‰¹å¾çš„æ•°é‡ã€‚'
- en: '`num_static_real_features` (`int`, *optional*, defaults to 0) â€” The number
    of static real valued features.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_static_real_features` (`int`, *å¯é€‰*, é»˜è®¤ä¸º0) â€” é™æ€å®å€¼ç‰¹å¾çš„æ•°é‡ã€‚'
- en: '`cardinality` (`list[int]`, *optional*) â€” The cardinality (number of different
    values) for each of the static categorical features. Should be a list of integers,
    having the same length as `num_static_categorical_features`. Cannot be `None`
    if `num_static_categorical_features` is > 0.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cardinality` (`list[int]`, *å¯é€‰*) â€” æ¯ä¸ªé™æ€åˆ†ç±»ç‰¹å¾çš„åŸºæ•°ï¼ˆä¸åŒå€¼çš„æ•°é‡ï¼‰ã€‚åº”è¯¥æ˜¯ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼Œé•¿åº¦ä¸`num_static_categorical_features`ç›¸åŒã€‚å¦‚æœ`num_static_categorical_features`å¤§äº0ï¼Œåˆ™ä¸èƒ½ä¸º`None`ã€‚'
- en: '`embedding_dimension` (`list[int]`, *optional*) â€” The dimension of the embedding
    for each of the static categorical features. Should be a list of integers, having
    the same length as `num_static_categorical_features`. Cannot be `None` if `num_static_categorical_features`
    is > 0.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dimension` (`list[int]`, *å¯é€‰*) â€” æ¯ä¸ªé™æ€åˆ†ç±»ç‰¹å¾çš„åµŒå…¥ç»´åº¦ã€‚åº”è¯¥æ˜¯ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼Œé•¿åº¦ä¸`num_static_categorical_features`ç›¸åŒã€‚å¦‚æœ`num_static_categorical_features`å¤§äº0ï¼Œåˆ™ä¸èƒ½ä¸º`None`ã€‚'
- en: '`d_model` (`int`, *optional*, defaults to 64) â€” Dimensionality of the transformer
    layers.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *å¯é€‰*, é»˜è®¤ä¸º64) â€” Transformerå±‚çš„ç»´åº¦ã€‚'
- en: '`encoder_layers` (`int`, *optional*, defaults to 2) â€” Number of encoder layers.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers` (`int`, *å¯é€‰*, é»˜è®¤ä¸º2) â€” ç¼–ç å™¨å±‚æ•°ã€‚'
- en: '`decoder_layers` (`int`, *optional*, defaults to 2) â€” Number of decoder layers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *å¯é€‰*, é»˜è®¤ä¸º2) â€” è§£ç å™¨å±‚æ•°ã€‚'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads` (`int`, *å¯é€‰*, é»˜è®¤ä¸º2) â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Transformerè§£ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” Dimension of the â€œintermediateâ€
    (often named feed-forward) layer in encoder.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” ç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” Dimension of the â€œintermediateâ€
    (often named feed-forward) layer in decoder.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” è§£ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    â€” The non-linear activation function (function or string) in the encoder and decoder.
    If string, `"gelu"` and `"relu"` are supported.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    â€” ç¼–ç å™¨å’Œè§£ç å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`å’Œ`"relu"`ã€‚'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for all fully connected layers in the encoder, and decoder.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.1) â€” ç¼–ç å™¨å’Œè§£ç å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„dropoutæ¦‚ç‡ã€‚'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for the attention and fully connected layers for each encoder layer.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” æ¯ä¸ªç¼–ç å™¨å±‚çš„æ³¨æ„åŠ›å’Œå…¨è¿æ¥å±‚çš„dropoutæ¦‚ç‡ã€‚'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for the attention and fully connected layers for each decoder layer.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” æ¯ä¸ªè§£ç å™¨å±‚çš„æ³¨æ„åŠ›å’Œå…¨è¿æ¥å±‚çš„dropoutæ¦‚ç‡ã€‚'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for the attention probabilities.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, defaults to 0.1) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„dropoutæ¦‚ç‡ã€‚'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    used between the two layers of the feed-forward networks.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, defaults to 0.1) â€” åœ¨å‰é¦ˆç½‘ç»œçš„ä¸¤ä¸ªå±‚ä¹‹é—´ä½¿ç”¨çš„dropoutæ¦‚ç‡ã€‚'
- en: '`num_parallel_samples` (`int`, *optional*, defaults to 100) â€” The number of
    samples to generate in parallel for each time step of inference.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_parallel_samples` (`int`, *optional*, defaults to 100) â€” æ¯ä¸ªæ¨ç†æ—¶é—´æ­¥ç”Ÿæˆçš„å¹¶è¡Œæ ·æœ¬æ•°ã€‚'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) â€” The standard deviation
    of the truncated normal weight initialization distribution.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, defaults to 0.02) â€” æˆªæ–­æ­£æ€æƒé‡åˆå§‹åŒ–åˆ†å¸ƒçš„æ ‡å‡†å·®ã€‚'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” Whether to use the past
    key/values attentions (if applicable to the model) to speed up decoding.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦ä½¿ç”¨è¿‡å»çš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¦‚æœé€‚ç”¨äºæ¨¡å‹ï¼‰ä»¥åŠ é€Ÿè§£ç ã€‚'
- en: Example â€”
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ â€”
- en: This is the configuration class to store the configuration of a [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel).
    It is used to instantiate a Time Series Transformer model according to the specified
    arguments, defining the model architecture. Instantiating a configuration with
    the defaults will yield a similar configuration to that of the Time Series Transformer
    [huggingface/time-series-transformer-tourism-monthly](https://huggingface.co/huggingface/time-series-transformer-tourism-monthly)
    architecture.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”¨äºå­˜å‚¨[TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)é…ç½®çš„é…ç½®ç±»ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ªæ—¶é—´åºåˆ—Transformeræ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºTime
    Series Transformer [huggingface/time-series-transformer-tourism-monthly](https://huggingface.co/huggingface/time-series-transformer-tourism-monthly)æ¶æ„çš„é…ç½®ã€‚
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„é…ç½®å¯¹è±¡å¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: TimeSeriesTransformerModel
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TimeSeriesTransformerModel
- en: '### `class transformers.TimeSeriesTransformerModel`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TimeSeriesTransformerModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1182)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1182)'
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare Time Series Transformer Model outputting raw hidden-states without
    any specific head on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„æ—¶é—´åºåˆ—Transformeræ¨¡å‹ï¼Œåœ¨é¡¶éƒ¨æ²¡æœ‰ç‰¹å®šçš„å¤´è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ã€‚æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1324)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1324)'
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`past_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`) â€” Past values of the time series,
    that serve as context in order to predict the future. The sequence size of this
    tensor must be larger than the `context_length` of the model, since the model
    will use the larger size to construct lag features, i.e. additional values from
    the past which are added in order to serve as â€œextra contextâ€.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`æˆ–`(batch_size, sequence_length,
    input_size)`çš„`torch.FloatTensor`ï¼‰- æ—¶é—´åºåˆ—çš„è¿‡å»å€¼ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ä»¥é¢„æµ‹æœªæ¥ã€‚è¿™ä¸ªå¼ é‡çš„åºåˆ—å¤§å°å¿…é¡»å¤§äºæ¨¡å‹çš„`context_length`ï¼Œå› ä¸ºæ¨¡å‹å°†ä½¿ç”¨æ›´å¤§çš„å¤§å°æ¥æ„å»ºæ»åç‰¹å¾ï¼Œå³ä»è¿‡å»æ·»åŠ çš„é¢å¤–å€¼ï¼Œä»¥å……å½“â€œé¢å¤–ä¸Šä¸‹æ–‡â€ã€‚'
- en: The `sequence_length` here is equal to `config.context_length` + `max(config.lags_sequence)`,
    which if no `lags_sequence` is configured, is equal to `config.context_length`
    + 7 (as by default, the largest look-back index in `config.lags_sequence` is 7).
    The property `_past_length` returns the actual length of the past.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„`sequence_length`ç­‰äº`config.context_length` + `max(config.lags_sequence)`ï¼Œå¦‚æœæ²¡æœ‰é…ç½®`lags_sequence`ï¼Œåˆ™ç­‰äº`config.context_length`
    + 7ï¼ˆå› ä¸ºé»˜è®¤æƒ…å†µä¸‹ï¼Œ`config.lags_sequence`ä¸­æœ€å¤§çš„å›æº¯ç´¢å¼•æ˜¯7ï¼‰ã€‚å±æ€§`_past_length`è¿”å›è¿‡å»çš„å®é™…é•¿åº¦ã€‚
- en: The `past_values` is what the Transformer encoder gets as input (with optional
    additional features, such as `static_categorical_features`, `static_real_features`,
    `past_time_features` and lags).
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`past_values` æ˜¯Transformerç¼–ç å™¨çš„è¾“å…¥ï¼ˆå¯é€‰çš„é™„åŠ ç‰¹å¾ï¼Œå¦‚`static_categorical_features`ã€`static_real_features`ã€`past_time_features`å’Œlagsï¼‰ã€‚'
- en: Optionally, missing values need to be replaced with zeros and indicated via
    the `past_observed_mask`.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯é€‰åœ°ï¼Œç¼ºå¤±å€¼éœ€è¦ç”¨é›¶æ›¿æ¢ï¼Œå¹¶é€šè¿‡`past_observed_mask`æŒ‡ç¤ºã€‚
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šå˜é‡æ—¶é—´åºåˆ—ï¼Œ`input_size` > 1ç»´æ˜¯å¿…éœ€çš„ï¼Œå¹¶ä¸”å¯¹åº”äºæ¯ä¸ªæ—¶é—´æ­¥ä¸­æ—¶é—´åºåˆ—ä¸­çš„å˜é‡æ•°ã€‚
- en: '`past_time_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`) â€” Required time features, which the model internally will add
    to `past_values`. These could be things like â€œmonth of yearâ€, â€œday of the monthâ€,
    etc. encoded as vectors (for instance as Fourier features). These could also be
    so-called â€œageâ€ features, which basically help the model know â€œat which point
    in lifeâ€ a time-series is. Age features have small values for distant past time
    steps and increase monotonically the more we approach the current time step. Holiday
    features are also a good example of time features.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_time_features`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, num_features)`çš„`torch.FloatTensor`ï¼‰-
    æ¨¡å‹å†…éƒ¨å°†æ·»åŠ åˆ°`past_values`ä¸­çš„å¿…éœ€æ—¶é—´ç‰¹å¾ã€‚è¿™äº›å¯èƒ½æ˜¯åƒâ€œå¹´ä»½çš„æœˆä»½â€ã€â€œæœˆä»½çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚å‚…ç«‹å¶ç‰¹å¾ï¼‰çš„ä¸œè¥¿ã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹çŸ¥é“æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿæ´»ä¸­çš„å“ªä¸ªæ—¶åˆ»â€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿œå¤„çš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚å‡æœŸç‰¹å¾ä¹Ÿæ˜¯æ—¶é—´ç‰¹å¾çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ä½œä¸ºè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚å› æ­¤ï¼Œä¸åƒBERTè¿™æ ·çš„æ¨¡å‹ä¸åŒï¼ŒBERTçš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ—Transformeréœ€è¦æä¾›é¢å¤–çš„æ—¶é—´ç‰¹å¾ã€‚æ—¶é—´åºåˆ—Transformerä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é¢å¤–çš„åŠ¨æ€å®æ•°åå˜é‡å¯ä»¥è¿æ¥åˆ°è¿™ä¸ªå¼ é‡ä¸­ï¼Œä½†è¿™äº›ç‰¹å¾å¿…é¡»åœ¨é¢„æµ‹æ—¶å·²çŸ¥ã€‚
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„`num_features`ç­‰äº`config.num_time_features`+`config.num_dynamic_real_features`ã€‚
- en: '`past_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) â€” Boolean mask to
    indicate which `past_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_observed_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`æˆ–`(batch_size, sequence_length,
    input_size)`çš„`torch.BoolTensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºæŒ‡ç¤ºå“ªäº›`past_values`æ˜¯è§‚å¯Ÿåˆ°çš„ï¼Œå“ªäº›æ˜¯ç¼ºå¤±çš„å¸ƒå°”æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0,
    1]`ä¸­ï¼š'
- en: 1 for values that are `observed`,
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äº`observed`çš„å€¼ä¸º1ï¼Œ
- en: 0 for values that are `missing` (i.e. NaNs that were replaced by zeros).
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äº`missing`çš„å€¼ï¼ˆå³ç”¨é›¶æ›¿æ¢çš„NaNå€¼ï¼‰ï¼Œä¸º0ã€‚
- en: '`static_categorical_features` (`torch.LongTensor` of shape `(batch_size, number
    of static categorical features)`, *optional*) â€” Optional static categorical features
    for which the model will learn an embedding, which it will add to the values of
    the time series.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_categorical_features`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, number of static categorical
    features)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹å°†å­¦ä¹ ä¸€ä¸ªåµŒå…¥ï¼Œå°†å…¶æ·»åŠ åˆ°æ—¶é—´åºåˆ—å€¼ä¸­çš„å¯é€‰é™æ€åˆ†ç±»ç‰¹å¾ã€‚'
- en: Static categorical features are features which have the same value for all time
    steps (static over time).
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥é•¿ä¸Šå…·æœ‰ç›¸åŒå€¼çš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒä¸å˜ï¼‰ã€‚
- en: A typical example of a static categorical feature is a time series ID.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯æ—¶é—´åºåˆ—IDã€‚
- en: '`static_real_features` (`torch.FloatTensor` of shape `(batch_size, number of
    static real features)`, *optional*) â€” Optional static real features which the
    model will add to the values of the time series.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_real_features`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, number of static real features)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    æ¨¡å‹å°†æ·»åŠ åˆ°æ—¶é—´åºåˆ—å€¼ä¸­çš„å¯é€‰é™æ€å®æ•°ç‰¹å¾ã€‚'
- en: Static real features are features which have the same value for all time steps
    (static over time).
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®æ•°ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥é•¿ä¸Šå…·æœ‰ç›¸åŒå€¼çš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒä¸å˜ï¼‰ã€‚
- en: A typical example of a static real feature is promotion information.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®é™…ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯ä¿ƒé”€ä¿¡æ¯ã€‚
- en: '`future_values` (`torch.FloatTensor` of shape `(batch_size, prediction_length)`
    or `(batch_size, prediction_length, input_size)`, *optional*) â€” Future values
    of the time series, that serve as labels for the model. The `future_values` is
    what the Transformer needs during training to learn to output, given the `past_values`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, prediction_length)`æˆ–`(batch_size, prediction_length,
    input_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ—¶é—´åºåˆ—çš„æœªæ¥å€¼ï¼Œç”¨ä½œæ¨¡å‹çš„æ ‡ç­¾ã€‚`future_values`æ˜¯Transformeråœ¨è®­ç»ƒæœŸé—´éœ€è¦å­¦ä¹ è¾“å‡ºçš„å†…å®¹ï¼Œç»™å®š`past_values`ã€‚'
- en: The sequence length here is equal to `prediction_length`.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„åºåˆ—é•¿åº¦ç­‰äº`prediction_length`ã€‚
- en: See the demo notebook and code snippets for details.
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ¼”ç¤ºç¬”è®°æœ¬å’Œä»£ç ç‰‡æ®µã€‚
- en: Optionally, during training any missing values need to be replaced with zeros
    and indicated via the `future_observed_mask`.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒæœŸé—´ï¼Œä»»ä½•ç¼ºå¤±å€¼éƒ½éœ€è¦ç”¨é›¶æ›¿æ¢ï¼Œå¹¶é€šè¿‡`future_observed_mask`æŒ‡ç¤ºã€‚
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šå˜é‡æ—¶é—´åºåˆ—ï¼Œéœ€è¦`input_size` > 1ç»´ï¼Œå¹¶ä¸”å¯¹åº”äºæ—¶é—´åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„å˜é‡æ•°é‡ã€‚
- en: '`future_time_features` (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`) â€” Required time features for the prediction window, which the
    model internally will add to `future_values`. These could be things like â€œmonth
    of yearâ€, â€œday of the monthâ€, etc. encoded as vectors (for instance as Fourier
    features). These could also be so-called â€œageâ€ features, which basically help
    the model know â€œat which point in lifeâ€ a time-series is. Age features have small
    values for distant past time steps and increase monotonically the more we approach
    the current time step. Holiday features are also a good example of time features.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_time_features`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, prediction_length, num_features)`çš„`torch.FloatTensor`ï¼‰â€”
    é¢„æµ‹çª—å£æ‰€éœ€çš„æ—¶é—´ç‰¹å¾ï¼Œæ¨¡å‹å†…éƒ¨å°†è¿™äº›ç‰¹å¾æ·»åŠ åˆ°`future_values`ä¸­ã€‚è¿™äº›ç‰¹å¾å¯ä»¥æ˜¯è¯¸å¦‚â€œå¹´ä»½æœˆä»½â€ã€â€œæ¯æœˆæ—¥æœŸâ€ç­‰çš„å‘é‡ç¼–ç ï¼ˆä¾‹å¦‚å‚…ç«‹å¶ç‰¹å¾ï¼‰ã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹äº†è§£æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿå‘½å‘¨æœŸçš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºé¥è¿œçš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥ï¼Œå€¼ä¼šå•è°ƒå¢åŠ ã€‚å‡æœŸç‰¹å¾ä¹Ÿæ˜¯æ—¶é—´ç‰¹å¾çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ä½œä¸ºè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚ä¸BERTç­‰æ¨¡å‹ä¸åŒï¼ŒBERTçš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ—Transformeréœ€è¦æä¾›é¢å¤–çš„æ—¶é—´ç‰¹å¾ã€‚æ—¶é—´åºåˆ—Transformerä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥å°†é¢å¤–çš„åŠ¨æ€å®é™…åå˜é‡è¿æ¥åˆ°æ­¤å¼ é‡ä¸­ï¼Œä½†å¿…é¡»åœ¨é¢„æµ‹æ—¶äº†è§£è¿™äº›ç‰¹å¾ã€‚
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„`num_features`ç­‰äº`config.num_time_features`+`config.num_dynamic_real_features`ã€‚
- en: '`future_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) â€” Boolean mask to
    indicate which `future_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_observed_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`æˆ–`(batch_size, sequence_length,
    input_size)`çš„`torch.BoolTensor`ï¼Œ*å¯é€‰*ï¼‰â€” å¸ƒå°”è’™ç‰ˆï¼ŒæŒ‡ç¤ºå“ªäº›`future_values`è¢«è§‚å¯Ÿåˆ°ï¼Œå“ªäº›æ˜¯ç¼ºå¤±çš„ã€‚è’™ç‰ˆå€¼é€‰åœ¨`[0,
    1]`èŒƒå›´å†…ï¼š'
- en: 1 for values that are `observed`,
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå€¼è¢«è§‚å¯Ÿåˆ°ï¼Œ
- en: 0 for values that are `missing` (i.e. NaNs that were replaced by zeros).
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºå€¼ä¸ºâ€œmissingâ€ï¼ˆå³è¢«é›¶æ›¿æ¢çš„NaNï¼‰çš„æƒ…å†µã€‚
- en: This mask is used to filter out missing values for the final loss calculation.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ­¤è’™ç‰ˆç”¨äºè¿‡æ»¤æœ€ç»ˆæŸå¤±è®¡ç®—ä¸­çš„ç¼ºå¤±å€¼ã€‚
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼é€‰åœ¨`[0,
    1]`èŒƒå›´å†…ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºæœªè¢«è’™ç‰ˆçš„æ ‡è®°ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºè¢«è’™ç‰ˆçš„æ ‡è®°ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›è’™ç‰ˆï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. By
    default, a causal mask will be used, to make sure the model can only look at previous
    inputs in order to predict the future.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„è’™ç‰ˆã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä½¿ç”¨å› æœè’™ç‰ˆï¼Œä»¥ç¡®ä¿æ¨¡å‹åªèƒ½æŸ¥çœ‹ä»¥å‰çš„è¾“å…¥ä»¥é¢„æµ‹æœªæ¥ã€‚'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(encoder_layers, encoder_attention_heads)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿ç¼–ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼é€‰åœ¨`[0, 1]`èŒƒå›´å†…ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«è’™ç‰ˆï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«è’™ç‰ˆã€‚
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`ï¼ˆå½¢çŠ¶ä¸º`(decoder_layers, decoder_attention_heads)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿è§£ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼é€‰åœ¨`[0, 1]`èŒƒå›´å†…ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«è’™ç‰ˆï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«è’™ç‰ˆã€‚
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`ï¼ˆå½¢çŠ¶ä¸º`(decoder_layers, decoder_attention_heads)`çš„`torch.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿äº¤å‰æ³¨æ„åŠ›æ¨¡å—çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼é€‰åœ¨`[0, 1]`èŒƒå›´å†…ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«è’™ç‰ˆï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«è’™ç‰ˆã€‚
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of `last_hidden_state`, `hidden_states` (*optional*) and `attentions` (*optional*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` (*optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” å…ƒç»„åŒ…å«`last_hidden_state`ã€`hidden_states`ï¼ˆ*å¯é€‰*ï¼‰å’Œ`attentions`ï¼ˆ*å¯é€‰*ï¼‰`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size,
    sequence_length, hidden_size)`ï¼ˆ*å¯é€‰*ï¼‰ï¼Œæ˜¯ç¼–ç å™¨æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, å½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›ï¼Œç±»å‹ä¸º`tuple(tuple(torch.FloatTensor))`ï¼Œé•¿åº¦ä¸º`config.n_layers`ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å«2ä¸ªå½¢çŠ¶ä¸º`(batch_size,
    num_heads, sequence_length, embed_size_per_head)`çš„å¼ é‡å’Œ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads,
    encoder_sequence_length, embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥å½¢çŠ¶ä¸º`(batch_size, 1)`çš„æœ€åä¸€ä¸ª`decoder_input_ids`ï¼ˆè¿™äº›æ²¡æœ‰å°†å…¶è¿‡å»çš„é”®å€¼çŠ¶æ€æä¾›ç»™æ­¤æ¨¡å‹ï¼‰è€Œä¸æ˜¯å½¢çŠ¶ä¸º`(batch_size,
    sequence_length)`çš„æ‰€æœ‰`decoder_input_ids`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼‰
    â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸­çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸­çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    æˆ– `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    and inputs.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä»…ä½¿ç”¨`past_key_values`ï¼Œåˆ™è¾“å‡ºå½¢çŠ¶ä¸º`(batch_size, 1, hidden_size)`çš„åºåˆ—çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€ã€‚
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” å½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›ï¼Œç±»å‹ä¸º`tuple(tuple(torch.FloatTensor))`ï¼Œé•¿åº¦ä¸º`config.n_layers`ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å«2ä¸ªå½¢çŠ¶ä¸º`(batch_size,
    num_heads, sequence_length, embed_size_per_head)`çš„å¼ é‡å’Œ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads,
    encoder_sequence_length, embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥å±‚çš„è¾“å‡º+æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`,
    *å¯é€‰*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥å±‚çš„è¾“å‡º+æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`loc` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Shift values of each time seriesâ€™ context window which is used to
    give the model inputs of the same magnitude and then used to shift back to the
    original magnitude.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loc` (`å½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`çš„`torch.FloatTensor`,
    *å¯é€‰*) â€” æ¯ä¸ªæ—¶é—´åºåˆ—çš„ä¸Šä¸‹æ–‡çª—å£çš„åç§»å€¼ï¼Œç”¨äºç»™æ¨¡å‹è¾“å…¥ç›¸åŒæ•°é‡çº§çš„è¾“å…¥ï¼Œç„¶åç”¨äºå°†å…¶åç§»å›åŸå§‹æ•°é‡çº§ã€‚'
- en: '`scale` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Scaling values of each time seriesâ€™ context window which is used
    to give the model inputs of the same magnitude and then used to rescale back to
    the original magnitude.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale` (`å½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`çš„`torch.FloatTensor`,
    *å¯é€‰*) â€” æ¯ä¸ªæ—¶é—´åºåˆ—çš„ä¸Šä¸‹æ–‡çª—å£çš„ç¼©æ”¾å€¼ï¼Œç”¨äºç»™æ¨¡å‹è¾“å…¥ç›¸åŒæ•°é‡çº§çš„è¾“å…¥ï¼Œç„¶åç”¨äºå°†å…¶é‡æ–°ç¼©æ”¾å›åŸå§‹æ•°é‡çº§ã€‚'
- en: '`static_features` (`torch.FloatTensor` of shape `(batch_size, feature size)`,
    *optional*) â€” Static features of each time seriesâ€™ in a batch which are copied
    to the covariates at inference time.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_features` (`å½¢çŠ¶ä¸º`(batch_size, feature size)`çš„`torch.FloatTensor`, *å¯é€‰*)
    â€” æ¯ä¸ªæ—¶é—´åºåˆ—çš„é™æ€ç‰¹å¾ï¼Œåœ¨æ¨æ–­æ—¶å¤åˆ¶åˆ°åå˜é‡ä¸­ã€‚'
- en: The [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    forward method, overrides the `__call__` special method.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE4]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: TimeSeriesTransformerForPrediction
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TimeSeriesTransformerForPrediction
- en: '### `class transformers.TimeSeriesTransformerForPrediction`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`class transformers.TimeSeriesTransformerForPrediction`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1443)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1443)'
- en: '[PRE5]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    â€” æ¨¡å‹çš„é…ç½®ç±»ï¼ŒåŒ…å«æ‰€æœ‰æ¨¡å‹çš„å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The Time Series Transformer Model with a distribution head on top for time-series
    forecasting. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰æ—¶é—´åºåˆ—é¢„æµ‹åˆ†å¸ƒå¤´çš„æ—¶é—´åºåˆ—å˜æ¢å™¨æ¨¡å‹ã€‚æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚
- en: '#### `forward`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1487)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1487)'
- en: '[PRE6]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`past_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`) â€” Past values of the time series,
    that serve as context in order to predict the future. The sequence size of this
    tensor must be larger than the `context_length` of the model, since the model
    will use the larger size to construct lag features, i.e. additional values from
    the past which are added in order to serve as â€œextra contextâ€.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`æˆ–`(batch_size, sequence_length,
    input_size)`çš„`torch.FloatTensor`ï¼‰ â€” æ—¶é—´åºåˆ—çš„è¿‡å»å€¼ï¼Œç”¨ä½œä¸Šä¸‹æ–‡ä»¥é¢„æµ‹æœªæ¥ã€‚æ­¤å¼ é‡çš„åºåˆ—å¤§å°å¿…é¡»å¤§äºæ¨¡å‹çš„`context_length`ï¼Œå› ä¸ºæ¨¡å‹å°†ä½¿ç”¨è¾ƒå¤§çš„å¤§å°æ¥æ„å»ºæ»åç‰¹å¾ï¼Œå³ä»è¿‡å»æ·»åŠ çš„é¢å¤–å€¼ï¼Œä»¥å……å½“â€œé¢å¤–ä¸Šä¸‹æ–‡â€ã€‚'
- en: The `sequence_length` here is equal to `config.context_length` + `max(config.lags_sequence)`,
    which if no `lags_sequence` is configured, is equal to `config.context_length`
    + 7 (as by default, the largest look-back index in `config.lags_sequence` is 7).
    The property `_past_length` returns the actual length of the past.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„`sequence_length`ç­‰äº`config.context_length` + `max(config.lags_sequence)`ï¼Œå¦‚æœæ²¡æœ‰é…ç½®`lags_sequence`ï¼Œåˆ™ç­‰äº`config.context_length`
    + 7ï¼ˆé»˜è®¤æƒ…å†µä¸‹ï¼Œ`config.lags_sequence`ä¸­æœ€å¤§çš„å›é¡¾ç´¢å¼•ä¸º7ï¼‰ã€‚å±æ€§`_past_length`è¿”å›è¿‡å»çš„å®é™…é•¿åº¦ã€‚
- en: The `past_values` is what the Transformer encoder gets as input (with optional
    additional features, such as `static_categorical_features`, `static_real_features`,
    `past_time_features` and lags).
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`past_values`æ˜¯Transformerç¼–ç å™¨ä½œä¸ºè¾“å…¥çš„å†…å®¹ï¼ˆå¸¦æœ‰å¯é€‰çš„é™„åŠ ç‰¹å¾ï¼Œå¦‚`static_categorical_features`ã€`static_real_features`ã€`past_time_features`å’Œæ»åï¼‰ã€‚'
- en: Optionally, missing values need to be replaced with zeros and indicated via
    the `past_observed_mask`.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯é€‰åœ°ï¼Œç¼ºå¤±å€¼éœ€è¦ç”¨é›¶æ›¿æ¢ï¼Œå¹¶é€šè¿‡`past_observed_mask`æŒ‡ç¤ºã€‚
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šå˜é‡æ—¶é—´åºåˆ—ï¼Œéœ€è¦`input_size` > 1ç»´ï¼Œå¹¶å¯¹åº”äºæ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸­æ—¶é—´åºåˆ—çš„å˜é‡æ•°é‡ã€‚
- en: '`past_time_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`) â€” Required time features, which the model internally will add
    to `past_values`. These could be things like â€œmonth of yearâ€, â€œday of the monthâ€,
    etc. encoded as vectors (for instance as Fourier features). These could also be
    so-called â€œageâ€ features, which basically help the model know â€œat which point
    in lifeâ€ a time-series is. Age features have small values for distant past time
    steps and increase monotonically the more we approach the current time step. Holiday
    features are also a good example of time features.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_time_features`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, num_features)`çš„`torch.FloatTensor`ï¼‰
    â€” å¿…éœ€çš„æ—¶é—´ç‰¹å¾ï¼Œæ¨¡å‹å†…éƒ¨å°†å…¶æ·»åŠ åˆ°`past_values`ä¸­ã€‚è¿™äº›å¯èƒ½æ˜¯è¯¸å¦‚â€œå¹´ä»½ä¸­çš„æœˆä»½â€ã€â€œæœˆä»½ä¸­çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚ä½œä¸ºå‚…ç«‹å¶ç‰¹å¾ï¼‰çš„å†…å®¹ã€‚è¿™ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹çŸ¥é“æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿæ´»ä¸­çš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿œå¤„çš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚å‡æœŸç‰¹å¾ä¹Ÿæ˜¯æ—¶é—´ç‰¹å¾çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ç”¨ä½œè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚ä¸åƒBERTè¿™æ ·çš„æ¨¡å‹ç›¸åï¼ŒBERTä¸­çš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œè€Œæ—¶é—´åºåˆ—å˜æ¢å™¨éœ€è¦æä¾›é¢å¤–çš„æ—¶é—´ç‰¹å¾ã€‚æ—¶é—´åºåˆ—å˜æ¢å™¨ä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥å°†é¢å¤–çš„åŠ¨æ€å®é™…åå˜é‡è¿æ¥åˆ°æ­¤å¼ é‡ä¸­ï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯è¿™äº›ç‰¹å¾å¿…é¡»åœ¨é¢„æµ‹æ—¶å·²çŸ¥ã€‚
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„`num_features`ç­‰äº`config.num_time_features`+`config.num_dynamic_real_features`ã€‚
- en: '`past_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) â€” Boolean mask to
    indicate which `past_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) â€” å¸ƒå°”æ©ç ï¼ŒæŒ‡ç¤ºå“ªäº›`past_values`æ˜¯è§‚å¯Ÿåˆ°çš„ï¼Œå“ªäº›æ˜¯ç¼ºå¤±çš„ã€‚æ©ç å€¼é€‰åœ¨`[0,
    1]`ä¹‹é—´ï¼š'
- en: 1 for values that are `observed`,
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºâ€œè§‚å¯Ÿåˆ°â€çš„å€¼ï¼Œ
- en: 0 for values that are `missing` (i.e. NaNs that were replaced by zeros).
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºâ€œç¼ºå¤±â€çš„å€¼ï¼ˆå³è¢«é›¶æ›¿æ¢çš„NaNï¼‰ã€‚
- en: '`static_categorical_features` (`torch.LongTensor` of shape `(batch_size, number
    of static categorical features)`, *optional*) â€” Optional static categorical features
    for which the model will learn an embedding, which it will add to the values of
    the time series.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_categorical_features` (`torch.LongTensor` of shape `(batch_size, number
    of static categorical features)`, *optional*) â€” æ¨¡å‹å°†å­¦ä¹ åµŒå…¥è¿™äº›é™æ€åˆ†ç±»ç‰¹å¾ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æ—¶é—´åºåˆ—çš„å€¼ä¸­ã€‚'
- en: Static categorical features are features which have the same value for all time
    steps (static over time).
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥çš„å€¼éƒ½ç›¸åŒçš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒé™æ€ï¼‰ã€‚
- en: A typical example of a static categorical feature is a time series ID.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯æ—¶é—´åºåˆ—IDã€‚
- en: '`static_real_features` (`torch.FloatTensor` of shape `(batch_size, number of
    static real features)`, *optional*) â€” Optional static real features which the
    model will add to the values of the time series.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_real_features` (`torch.FloatTensor` of shape `(batch_size, number of
    static real features)`, *optional*) â€” å¯é€‰çš„é™æ€å®æ•°ç‰¹å¾ï¼Œæ¨¡å‹å°†æŠŠè¿™äº›ç‰¹å¾æ·»åŠ åˆ°æ—¶é—´åºåˆ—çš„å€¼ä¸­ã€‚'
- en: Static real features are features which have the same value for all time steps
    (static over time).
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®æ•°ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥çš„å€¼éƒ½ç›¸åŒçš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒé™æ€ï¼‰ã€‚
- en: A typical example of a static real feature is promotion information.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®æ•°ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯ä¿ƒé”€ä¿¡æ¯ã€‚
- en: '`future_values` (`torch.FloatTensor` of shape `(batch_size, prediction_length)`
    or `(batch_size, prediction_length, input_size)`, *optional*) â€” Future values
    of the time series, that serve as labels for the model. The `future_values` is
    what the Transformer needs during training to learn to output, given the `past_values`.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_values` (`torch.FloatTensor` of shape `(batch_size, prediction_length)`
    or `(batch_size, prediction_length, input_size)`, *optional*) â€” æ—¶é—´åºåˆ—çš„æœªæ¥å€¼ï¼Œä½œä¸ºæ¨¡å‹çš„æ ‡ç­¾ã€‚`future_values`æ˜¯Transformeråœ¨è®­ç»ƒæœŸé—´éœ€è¦å­¦ä¹ è¾“å‡ºçš„å†…å®¹ï¼Œç»™å®š`past_values`ã€‚'
- en: The sequence length here is equal to `prediction_length`.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„åºåˆ—é•¿åº¦ç­‰äº`prediction_length`ã€‚
- en: See the demo notebook and code snippets for details.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ¼”ç¤ºç¬”è®°æœ¬å’Œä»£ç ç‰‡æ®µã€‚
- en: Optionally, during training any missing values need to be replaced with zeros
    and indicated via the `future_observed_mask`.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒæœŸé—´ï¼Œä»»ä½•ç¼ºå¤±å€¼éƒ½éœ€è¦ç”¨é›¶æ›¿æ¢ï¼Œå¹¶é€šè¿‡`future_observed_mask`æŒ‡ç¤ºã€‚
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šå˜é‡æ—¶é—´åºåˆ—ï¼Œéœ€è¦`input_size` > 1ç»´ï¼Œå¹¶ä¸”å¯¹åº”äºæ—¶é—´åºåˆ—æ¯ä¸ªæ—¶é—´æ­¥ä¸­çš„å˜é‡æ•°é‡ã€‚
- en: '`future_time_features` (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`) â€” Required time features for the prediction window, which the
    model internally will add to `future_values`. These could be things like â€œmonth
    of yearâ€, â€œday of the monthâ€, etc. encoded as vectors (for instance as Fourier
    features). These could also be so-called â€œageâ€ features, which basically help
    the model know â€œat which point in lifeâ€ a time-series is. Age features have small
    values for distant past time steps and increase monotonically the more we approach
    the current time step. Holiday features are also a good example of time features.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_time_features` (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`) â€” æ¨¡å‹åœ¨å†…éƒ¨å°†è¿™äº›ç‰¹å¾æ·»åŠ åˆ°`future_values`ä¸­ï¼Œè¿™äº›ç‰¹å¾æ˜¯é¢„æµ‹çª—å£æ‰€éœ€çš„æ—¶é—´ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾å¯ä»¥æ˜¯è¯¸å¦‚â€œå¹´ä»½ä¸­çš„æœˆä»½â€ã€â€œæœˆä»½ä¸­çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚å‚…ç«‹å¶ç‰¹å¾ï¼‰çš„å†…å®¹ã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹äº†è§£æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿå‘½ä¸­çš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿œå¤„çš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚å‡æœŸç‰¹å¾ä¹Ÿæ˜¯æ—¶é—´ç‰¹å¾çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ä½œä¸ºè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚ä¸BERTç­‰æ¨¡å‹ä¸åŒï¼ŒBERTçš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ—Transformeréœ€è¦æä¾›é¢å¤–çš„æ—¶é—´ç‰¹å¾ã€‚æ—¶é—´åºåˆ—Transformerä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥å°†é¢å¤–çš„åŠ¨æ€å®æ•°åå˜é‡è¿æ¥åˆ°è¿™ä¸ªå¼ é‡ä¸­ï¼Œä½†éœ€è¦æ³¨æ„è¿™äº›ç‰¹å¾å¿…é¡»åœ¨é¢„æµ‹æ—¶å·²çŸ¥ã€‚
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„`num_features`ç­‰äº`config.num_time_features`+`config.num_dynamic_real_features`ã€‚
- en: '`future_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) â€” Boolean mask to
    indicate which `future_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) â€” å¸ƒå°”æ©ç ï¼ŒæŒ‡ç¤ºå“ªäº›`future_values`æ˜¯è§‚å¯Ÿåˆ°çš„ï¼Œå“ªäº›æ˜¯ç¼ºå¤±çš„ã€‚æ©ç å€¼é€‰åœ¨`[0,
    1]`ä¹‹é—´ï¼š'
- en: 1 for values that are `observed`,
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºâ€œè§‚å¯Ÿåˆ°â€çš„å€¼ï¼Œ
- en: 0 for values that are `missing` (i.e. NaNs that were replaced by zeros).
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºâ€œç¼ºå¤±â€çš„å€¼ï¼ˆå³è¢«é›¶æ›¿æ¢çš„NaNï¼‰ã€‚
- en: This mask is used to filter out missing values for the final loss calculation.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ©ç ç”¨äºåœ¨æœ€ç»ˆæŸå¤±è®¡ç®—ä¸­è¿‡æ»¤ç¼ºå¤±å€¼ã€‚
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºâ€œæœªè¢«æ©ç â€çš„æ ‡è®°ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºâ€œè¢«æ©ç â€çš„æ ‡è®°ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. By
    default, a causal mask will be used, to make sure the model can only look at previous
    inputs in order to predict the future.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä½¿ç”¨å› æœæ©ç ï¼Œä»¥ç¡®ä¿æ¨¡å‹åªèƒ½æŸ¥çœ‹ä»¥å‰çš„è¾“å…¥ä»¥é¢„æµ‹æœªæ¥ã€‚'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) â€” ç”¨äºå°†ç¼–ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” ç”¨äºå°†è§£ç å™¨ä¸­æ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” ç”¨äºå°†äº¤å‰æ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨ç½®é›¶çš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«å±è”½ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«å±è”½ã€‚
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of `last_hidden_state`, `hidden_states` (*optional*) and `attentions` (*optional*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` (*optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” å…ƒç»„åŒ…æ‹¬ `last_hidden_state`ã€`hidden_states`ï¼ˆ*å¯é€‰*ï¼‰å’Œ
    `attentions`ï¼ˆ*å¯é€‰*ï¼‰`last_hidden_state` çš„å½¢çŠ¶ä¸º `(batch_size, sequence_length, hidden_size)`ï¼ˆ*å¯é€‰*ï¼‰æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚çš„è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, å½“ä¼ é€’ `use_cache=True`
    æˆ– `config.use_cache=True` æ—¶è¿”å›) â€” é•¿åº¦ä¸º `config.n_layers` çš„ `tuple(torch.FloatTensor)`
    å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å« 2 ä¸ªå½¢çŠ¶ä¸º `(batch_size, num_heads, sequence_length, embed_size_per_head)`
    çš„å¼ é‡å’Œ 2 ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`
    çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§ `past_key_values` è¾“å…¥ï¼‰ã€‚
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨äº† `past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åçš„ `decoder_input_ids`ï¼ˆè¿™äº›æ²¡æœ‰å°†å…¶è¿‡å»çš„é”®å€¼çŠ¶æ€æä¾›ç»™æ­¤æ¨¡å‹ï¼‰çš„å½¢çŠ¶ä¸º
    `(batch_size, 1)`ï¼Œè€Œä¸æ˜¯æ‰€æœ‰å½¢çŠ¶ä¸º `(batch_size, sequence_length)` çš„ `decoder_input_ids`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’ `input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶æƒï¼Œä»¥ä¾¿å°† `input_ids`
    ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™è¿”å› `past_key_values` é”®å€¼çŠ¶æ€ï¼Œå¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§
    `past_key_values`ï¼‰ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„
    `attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„
    `hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    æˆ– `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    and inputs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼‰-
    æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨`past_key_values`ï¼Œåˆ™åªè¾“å‡ºå½¢çŠ¶ä¸º`(batch_size, 1, hidden_size)`çš„åºåˆ—çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€ã€‚
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`ï¼ˆ`tuple(tuple(torch.FloatTensor))`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›ï¼‰-
    é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`çš„å¼ é‡å’Œ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥è¾“å‡ºçš„ä¸€ä¸ªåŠ ä¸Šæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥è¾“å‡ºçš„ä¸€ä¸ªåŠ ä¸Šæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`loc` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Shift values of each time seriesâ€™ context window which is used to
    give the model inputs of the same magnitude and then used to shift back to the
    original magnitude.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loc`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºå°†æ¯ä¸ªæ—¶é—´åºåˆ—çš„ä¸Šä¸‹æ–‡çª—å£çš„å€¼ç§»ä½ï¼Œä»¥ä¾¿ä¸ºæ¨¡å‹æä¾›ç›¸åŒæ•°é‡çº§çš„è¾“å…¥ï¼Œç„¶åç”¨äºå°†å…¶ç§»ä½å›åŸå§‹æ•°é‡çº§ã€‚'
- en: '`scale` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Scaling values of each time seriesâ€™ context window which is used
    to give the model inputs of the same magnitude and then used to rescale back to
    the original magnitude.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    ç”¨äºå°†æ¯ä¸ªæ—¶é—´åºåˆ—çš„ä¸Šä¸‹æ–‡çª—å£çš„ç¼©æ”¾å€¼ç§»ä½ï¼Œä»¥ä¾¿ä¸ºæ¨¡å‹æä¾›ç›¸åŒæ•°é‡çº§çš„è¾“å…¥ï¼Œç„¶åç”¨äºé‡æ–°ç¼©æ”¾å›åŸå§‹æ•°é‡çº§ã€‚'
- en: '`static_features` (`torch.FloatTensor` of shape `(batch_size, feature size)`,
    *optional*) â€” Static features of each time seriesâ€™ in a batch which are copied
    to the covariates at inference time.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_features`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, feature size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰-
    æ¯ä¸ªæ—¶é—´åºåˆ—åœ¨æ‰¹å¤„ç†ä¸­çš„é™æ€ç‰¹å¾ï¼Œåœ¨æ¨æ–­æ—¶å°†å¤åˆ¶åˆ°åå˜é‡ä¸­ã€‚'
- en: The [TimeSeriesTransformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction)
    forward method, overrides the `__call__` special method.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[TimeSeriesTransformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction)çš„å‰å‘æ–¹æ³•é‡å†™äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°ä¸­å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤ä¹‹åè°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE7]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
