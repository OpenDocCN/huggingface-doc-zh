- en: Fuyu
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fuyu
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fuyu](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fuyu)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fuyu](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fuyu)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The Fuyu model was created by [ADEPT](https://www.adept.ai/blog/fuyu-8b), and
    authored by Rohan Bavishi, Erich Elsen, Curtis Hawthorne, Maxwell Nye, Augustus
    Odena, Arushi Somani, Sağnak Taşırlar.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Fuyu模型由[ADEPT](https://www.adept.ai/blog/fuyu-8b)创建，作者是Rohan Bavishi、Erich Elsen、Curtis
    Hawthorne、Maxwell Nye、Augustus Odena、Arushi Somani、Sağnak Taşırlar。
- en: The authors introduced Fuyu-8B, a decoder-only multimodal model based on the
    classic transformers architecture, with query and key normalization. A linear
    encoder is added to create multimodal embeddings from image inputs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 作者介绍了Fuyu-8B，这是一个仅解码器的基于经典transformers架构的多模态模型，具有查询和键规范化。线性编码器被添加以从图像输入创建多模态嵌入。
- en: By treating image tokens like text tokens and using a special image-newline
    character, the model knows when an image line ends. Image positional embeddings
    are removed. This avoids the need for different training phases for various image
    resolutions. With 8 billion parameters and licensed under CC-BY-NC, Fuyu-8B is
    notable for its ability to handle both text and images, its impressive context
    size of 16K, and its overall performance.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将图像标记视为文本标记，并使用特殊的图像换行符，模型知道图像行何时结束。移除了图像位置嵌入。这避免了为各种图像分辨率进行不同训练阶段的需要。Fuyu-8B具有80亿个参数，并在CC-BY-NC许可下发布，以其处理文本和图像的能力、令人印象深刻的16K上下文大小和整体性能而闻名。
- en: The `Fuyu` models were trained using `bfloat16`, but the original inference
    uses `float16` The checkpoints uploaded on the hub use `torch_dtype = 'float16'`
    which will be used by the `AutoModel` API to cast the checkpoints from `torch.float32`
    to `torch.float16`.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`Fuyu`模型是使用`bfloat16`训练的，但原始推理使用`float16`。上传到hub的检查点使用`torch_dtype = ''float16''`，`AutoModel`
    API将使用它将检查点从`torch.float32`转换为`torch.float16`。'
- en: The `dtype` of the online weights is mostly irrelevant, unless you are using
    `torch_dtype="auto"` when initializing a model using `model = AutoModelForCausalLM.from_pretrained("path",
    torch_dtype = "auto")`. The reason is that the model will first be downloaded
    ( using the `dtype` of the checkpoints online) then it will be cast to the default
    `dtype` of `torch` (becomes `torch.float32`). Users should specify the `torch_dtype`
    they want, and if they don’t it will be `torch.float32`.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在线权重的`dtype`大多数情况下并不重要，除非在使用`torch_dtype="auto"`初始化模型时使用`model = AutoModelForCausalLM.from_pretrained("path",
    torch_dtype = "auto")`。原因是模型将首先被下载（使用在线检查点的`dtype`），然后将被转换为`torch`的默认`dtype`（变为`torch.float32`）。用户应该指定他们想要的`torch_dtype`，如果他们不这样做，它将是`torch.float32`。
- en: Finetuning the model in `float16` is not recommended and known to produce `nan`,
    as such the model should be fine-tuned in `bfloat16`.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 不建议在`float16`中微调模型，因为已知会产生`nan`，因此应该在`bfloat16`中微调模型。
- en: 'Tips:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: 'To convert the model, you need to clone the original repository using `git
    clone https://github.com/persimmon-ai-labs/adept-inference`, then get the checkpoints:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要转换模型，您需要使用`git clone https://github.com/persimmon-ai-labs/adept-inference`克隆原始存储库，然后获取检查点：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For the chat model:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聊天模型：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, model can be loaded via:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型可以通过以下方式加载：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Inputs need to be passed through a specific Processor to have the correct formats.
    A processor requires an image_processor and a tokenizer. Hence, inputs can be
    loaded via:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 需要通过特定的处理器传递输入以获得正确的格式。处理器需要一个图像处理器和一个分词器。因此，输入可以通过以下方式加载：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This model was contributed by [Molbap](https://huggingface.co/Molbap). The original
    code can be found [here](https://github.com/persimmon-ai-labs/adept-inference).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[Molbap](https://huggingface.co/Molbap)贡献。原始代码可以在[此处](https://github.com/persimmon-ai-labs/adept-inference)找到。
- en: Fuyu uses a `sentencepiece` based tokenizer, with a `Unigram` model. It supports
    bytefallback, which is only available in `tokenizers==0.14.0` for the fast tokenizer.
    The `LlamaTokenizer` is used as it is a standard wrapper around sentencepiece.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fuyu使用基于`sentencepiece`的分词器，采用`Unigram`模型。它支持字节回退，仅在快速分词器的`tokenizers==0.14.0`中可用。`LlamaTokenizer`被用作它是句子片段的标准包装器。
- en: 'The authors suggest to use the following prompt for image captioning: `f"Generate
    a coco-style caption.\\n"`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者建议为图像字幕使用以下提示：`f"生成一个coco风格的字幕。\\n"`
- en: FuyuConfig
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FuyuConfig
- en: '### `class transformers.FuyuConfig`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FuyuConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fuyu/configuration_fuyu.py#L29)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fuyu/configuration_fuyu.py#L29)'
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 262144) — Vocabulary size of the
    Fuyu model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, 默认为262144) — Fuyu模型的词汇表大小。定义了在调用[FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)时可以由`inputs_ids`表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 4096) — Dimension of the hidden
    representations.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为4096) — 隐藏表示的维度。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 16384) — Dimension of the
    MLP representations.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, 默认为16384) — MLP表示的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 36) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, 默认为36) — Transformer编码器中的隐藏层数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 64) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, 默认为64) — Transformer编码器中每个注意力层的注意力头数量。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"relu2"`) — The
    non-linear activation function (function or string) in the decoder.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`或`function`, *optional*, 默认为`"relu2"`) — 解码器中的非线性激活函数（函数或字符串）。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 16384) — The maximum
    sequence length that this model might ever be used with.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings`（`int`，*可选*，默认为16384）-此模型可能使用的最大序列长度。'
- en: '`image_size` (`int`, *optional*, defaults to 300) — The input image size.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size`（`int`，*可选*，默认为300）-输入图像大小。'
- en: '`patch_size` (`int`, *optional*, defaults to 30) — The input vision transformer
    encoding patch size.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size`（`int`，*可选*，默认为30）-输入视觉变换器编码块大小。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The input image number
    of channels.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels`（`int`，*可选*，默认为3）-输入图像通道数。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range`（`float`，*可选*，默认为0.02）-用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the rms normalization layers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps`（`float`，*可选*，默认为1e-05）-rms归一化层使用的epsilon。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models). Only relevant
    if `config.is_decoder=True`. Whether to tie weight embeddings'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*，默认为`True`）-模型是否应返回最后的键/值注意力（不是所有模型都使用）。仅在`config.is_decoder=True`时相关。是否绑定权重嵌入'
- en: '`tie_word_embeddings` (`bool`, *optional*, defaults to `False`) — Whether to
    tie input and output embeddings.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tie_word_embeddings`（`bool`，*可选*，默认为`False`）-是否绑定输入和输出嵌入。'
- en: '`rope_theta` (`float`, *optional*, defaults to 25000.0) — The base period of
    the RoPE embeddings.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rope_theta`（`float`，*可选*，默认为25000.0）-RoPE嵌入的基本周期。'
- en: '`rope_scaling` (`Dict`, *optional*) — Dictionary containing the scaling configuration
    for the RoPE embeddings. Currently supports two scaling strategies: linear and
    dynamic. Their scaling factor must be a float greater than 1\. The expected format
    is `{"type": strategy name, "factor": scaling factor}`. When using this flag,
    don’t update `max_position_embeddings` to the expected new maximum. See the following
    thread for more information on how these scaling strategies behave: [https://www.reddit.com/r/LocalFuyu/comments/14mrgpr/dynamically_scaled_rope_further_increases/](https://www.reddit.com/r/LocalFuyu/comments/14mrgpr/dynamically_scaled_rope_further_increases/).
    This is an experimental feature, subject to breaking API changes in future versions.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rope_scaling`（`Dict`，*可选*）-包含RoPE嵌入的缩放配置的字典。当前支持两种缩放策略：线性和动态。它们的缩放因子必须是大于1的浮点数。预期格式为`{"type"：策略名称，"factor"：缩放因子}`。使用此标志时，不要将`max_position_embeddings`更新为预期的新最大值。有关这些缩放策略行为的更多信息，请参见以下线程：[https://www.reddit.com/r/LocalFuyu/comments/14mrgpr/dynamically_scaled_rope_further_increases/](https://www.reddit.com/r/LocalFuyu/comments/14mrgpr/dynamically_scaled_rope_further_increases/)。这是一个实验性功能，可能在将来的版本中会有破坏性的API更改。'
- en: '`qk_layernorm` (`bool`, *optional*, defaults to `True`) — Whether or not to
    normalize the Queries and Keys after projecting the hidden states'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qk_layernorm`（`bool`，*可选*，默认为`True`）-在投影隐藏状态后是否规范查询和键'
- en: '`hidden_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    after applying the MLP to the hidden states.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout`（`float`，*可选*，默认为0.0）-在将MLP应用于隐藏状态后的丢失比率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    after computing the attention scores.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout`（`float`，*可选*，默认为0.0）-计算注意力分数后的丢失比率。'
- en: '`partial_rotary_factor` (`float`, *optional*, defaults to 0.5) — Percentage
    of the query and keys which will have rotary embedding.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partial_rotary_factor`（`float`，*可选*，默认为0.5）-查询和键的百分比，将具有旋转嵌入。'
- en: '`pad_token_id` (`int`, *optional*) — The id of the *padding* token.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_id`（`int`，*可选*）- *填充* 标记的ID。'
- en: '`bos_token_id` (`int`, *optional*, defaults to 1) — The id of the *beginning-of-sequence*
    token.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token_id`（`int`，*可选*，默认为1）- *序列开始* 标记的ID。'
- en: '`eos_token_id` (`Union[int, List[int]]`, *optional*, defaults to 2) — The id
    of the *end-of-sequence* token. Optionally, use a list to set multiple *end-of-sequence*
    tokens.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id`（`Union[int，List[int]]`，*可选*，默认为2）- *序列结束* 标记的ID。可选择使用列表设置多个*序列结束*
    标记。'
- en: '`text_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize the `language[PRE5]'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_config`（`dict`，*可选*）-用于初始化`language[PRE5]`的配置选项字典'
- en: '>>> from transformers import FuyuConfig'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从转换器导入FuyuConfig
- en: '>>> # Initializing a Fuyu fuyu-7b style configuration'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化Fuyu fuyu-7b风格配置
- en: '>>> configuration = FuyuConfig()'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 配置= FuyuConfig（）
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '( config: FuyuConfig )'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: （配置：FuyuConfig）
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '( input_ids: LongTensor = None image_patches: Tensor = None image_patches_indices:
    Tensor = None attention_mask: Optional = None position_ids: Optional = None past_key_values:
    Optional = None inputs_embeds: Optional = None use_cache: Optional = None labels:
    Optional = None output_attentions: Optional = None output_hidden_states: Optional
    = None return_dict: Optional = None ) → export const metadata = ''undefined'';transformers.modeling_outputs.CausalLMOutputWithPast
    or tuple(torch.FloatTensor)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: （input_ids：LongTensor = None image_patches：Tensor = None image_patches_indices：Tensor
    = None attention_mask：Optional = None position_ids：Optional = None past_key_values：Optional
    = None inputs_embeds：Optional = None use_cache：Optional = None labels：Optional
    = None output_attentions：Optional = None output_hidden_states：Optional = None
    return_dict：Optional = None）→导出常量元数据='未定义';transformers.modeling_outputs.CausalLMOutputWithPast或元组（torch.FloatTensor）
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '>>> from transformers import FuyuProcessor, FuyuForCausalLM'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从转换器导入FuyuProcessor，FuyuForCausalLM
- en: '>>> from PIL import Image'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从PIL导入图像
- en: '>>> import requests'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 导入请求
- en: '>>> processor = FuyuProcessor.from_pretrained("adept/fuyu-8b")'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器= FuyuProcessor.from_pretrained（“adept/fuyu-8b”）
- en: '>>> model = FuyuForCausalLM.from_pretrained("adept/fuyu-8b")'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 模型= FuyuForCausalLM.from_pretrained（“adept/fuyu-8b”）
- en: '>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 网址=“http://images.cocodataset.org/val2017/000000039769.jpg”
- en: '>>> image = Image.open(requests.get(url, stream=True).raw)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 = Image.open(requests.get(url, stream=True).raw)
- en: '>>> prompt = "Generate a coco-style caption.\n"'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 提示=“生成一个coco风格的标题。\n”
- en: '>>> inputs = processor(text=text_prompt, images=image, return_tensors="pt")'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 输入=处理器（文本= text_prompt，图像=图像，return_tensors=“pt”）
- en: '>>> outputs = model(**inputs)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输出=模型（**输入）
- en: '>>> generated_ids = model.generate(**model_inputs, max_new_tokens=7)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> generated_ids = model.generate(**model_inputs, max_new_tokens=7)'
- en: '>>> generation_text = processor.batch_decode(generated_ids, skip_special_tokens=True)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> generation_text = processor.batch_decode(generated_ids, skip_special_tokens=True)'
- en: '>>> print(generation_text)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(generation_text)'
- en: '''A bus parked on the side of a road.'''
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: “停在路边的公共汽车。”
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '( do_resize: bool = True size: Optional = None resample: Resampling = <Resampling.BILINEAR:
    2> do_pad: bool = True padding_value: float = 1.0 padding_mode: str = ''constant''
    do_normalize: bool = True image_mean: Union = 0.5 image_std: Union = 0.5 do_rescale:
    bool = True rescale_factor: float = 0.00392156862745098 patch_size: Optional =
    None **kwargs )'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '（do_resize: bool=True size: Optional=None resample: Resampling=<Resampling.BILINEAR:
    2> do_pad: bool=True padding_value: float=1.0 padding_mode: str=''constant'' do_normalize:
    bool=True image_mean: Union=0.5 image_std: Union=0.5 do_rescale: bool=True rescale_factor:
    float=0.00392156862745098 patch_size: Optional=None **kwargs）'
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ( images **kwargs )
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: （images **kwargs）
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ( image_processor tokenizer )
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: （图像处理器 标记器）
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '( text = None images = None add_special_tokens: bool = True return_attention_mask:
    bool = True padding: Union = False truncation: Union = None max_length: Optional
    = None stride: int = 0 pad_to_multiple_of: Optional = None return_overflowing_tokens:
    bool = False return_special_tokens_mask: bool = False return_offsets_mapping:
    bool = False return_token_type_ids: bool = False return_length: bool = False verbose:
    bool = True return_tensors: Union = None **kwargs ) → export const metadata =
    ''undefined'';FuyuBatchEncoding'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '（text=None images=None add_special_tokens: bool=True return_attention_mask:
    bool=True padding: Union=False truncation: Union=None max_length: Optional=None
    stride: int=0 pad_to_multiple_of: Optional=None return_overflowing_tokens: bool=False
    return_special_tokens_mask: bool=False return_offsets_mapping: bool=False return_token_type_ids:
    bool=False return_length: bool=False verbose: bool=True return_tensors: Union=None
    **kwargs）→ export const metadata = ''undefined'';FuyuBatchEncoding'
- en: '```'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: Parameters
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`) — The sequence or batch of sequences to be encoded.
    Each sequence can be a string or a list of strings (pretokenized string). If the
    sequences are provided as list of strings (pretokenized), you must set `is_split_into_words=True`
    (to lift the ambiguity with a batch of sequences).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`（`str`，`List[str]`）— 要编码的序列或序列批次。每个序列可以是字符串或字符串列表（预标记化字符串）。如果将序列提供为字符串列表（预标记化），则必须设置`is_split_into_words=True`（以消除与序列批次的歧义）。'
- en: '`images` (`PIL.Image.Image`, `List[PIL.Image.Image]`) — The image or batch
    of images to be prepared. Each image can be a PIL image, NumPy array or PyTorch
    tensor. In case of a NumPy array/PyTorch tensor, each image should be of shape
    (C, H, W), where C is a number of channels, H and W are image height and width.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images`（`PIL.Image.Image`，`List[PIL.Image.Image]`）— 要准备的图像或图像批次。每个图像可以是PIL图像、NumPy数组或PyTorch张量。对于NumPy数组/PyTorch张量，每个图像的形状应为（C，H，W），其中C是通道数，H和W是图像的高度和宽度。'
- en: Returns
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`FuyuBatchEncoding`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`FuyuBatchEncoding`'
- en: 'A `FuyuBatchEncoding` with the following fields:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有以下字段的`FuyuBatchEncoding`：
- en: '`input_ids` — Tensor of token ids to be fed to a model. Returned when `text`
    is not `None`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要提供给模型的标记id张量。当`text`不是`None`时返回。'
- en: '`image_patches` — List of Tensor of image patches. Returned when `images` is
    not `None`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_patches` — 图像补丁张量列表。当`images`不是`None`时返回。'
- en: '`image_patches_indices` — Tensor of indices where patch embeddings have to
    be inserted by the model.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_patches_indices` — 指示模型应插入补丁嵌入的索引张量。'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model when `return_attention_mask=True`.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定模型在`return_attention_mask=True`时应关注哪些标记的索引列表。'
- en: Main method to prepare for the model one or several sequences(s) and image(s).
    This method forwards the `text` and `kwargs` arguments to LlamaTokenizerFast’s
    [**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    if `text` is not `None` to encode the text. To prepare the image(s), this method
    forwards the `images` and `kwargs` arguments to FuyuImageProcessor’s [**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    if `images` is not `None`. Please refer to the doctsring of the above two methods
    for more information.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 准备模型一个或多个序列和图像的主要方法。如果`text`不是`None`，此方法将`text`和`kwargs`参数转发给LlamaTokenizerFast的[**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)以对文本进行编码。要准备图像，如果`images`不是`None`，此方法将`images`和`kwargs`参数转发给FuyuImageProcessor的[**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。有关更多信息，请参考上述两种方法的文档。
