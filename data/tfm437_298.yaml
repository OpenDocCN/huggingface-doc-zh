- en: ViTMatte
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ViTMatte
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/vitmatte](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/vitmatte)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/vitmatte](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/vitmatte)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The ViTMatte model was proposed in [Boosting Image Matting with Pretrained Plain
    Vision Transformers](https://arxiv.org/abs/2305.15272) by Jingfeng Yao, Xinggang
    Wang, Shusheng Yang, Baoyuan Wang. ViTMatte leverages plain [Vision Transformers](vit)
    for the task of image matting, which is the process of accurately estimating the
    foreground object in images and videos.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ViTMatte模型是由姚景峰、王兴刚、杨树生、王宝元在[使用预训练的普通视觉Transformer增强图像抠图](https://arxiv.org/abs/2305.15272)中提出的。ViTMatte利用普通的[视觉Transformer](vit)来进行图像抠图任务，即准确估计图像和视频中的前景对象的过程。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Recently, plain vision Transformers (ViTs) have shown impressive performance
    on various computer vision tasks, thanks to their strong modeling capacity and
    large-scale pretraining. However, they have not yet conquered the problem of image
    matting. We hypothesize that image matting could also be boosted by ViTs and present
    a new efficient and robust ViT-based matting system, named ViTMatte. Our method
    utilizes (i) a hybrid attention mechanism combined with a convolution neck to
    help ViTs achieve an excellent performance-computation trade-off in matting tasks.
    (ii) Additionally, we introduce the detail capture module, which just consists
    of simple lightweight convolutions to complement the detailed information required
    by matting. To the best of our knowledge, ViTMatte is the first work to unleash
    the potential of ViT on image matting with concise adaptation. It inherits many
    superior properties from ViT to matting, including various pretraining strategies,
    concise architecture design, and flexible inference strategies. We evaluate ViTMatte
    on Composition-1k and Distinctions-646, the most commonly used benchmark for image
    matting, our method achieves state-of-the-art performance and outperforms prior
    matting works by a large margin.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*最近，普通视觉Transformer（ViTs）在各种计算机视觉任务中表现出色，这要归功于它们强大的建模能力和大规模预训练。然而，它们尚未征服图像抠图问题。我们假设图像抠图也可以通过ViTs得到提升，并提出了一种新的高效且稳健的基于ViT的抠图系统，名为ViTMatte。我们的方法利用了（i）混合注意力机制结合卷积颈部，帮助ViTs在抠图任务中实现出色的性能-计算折衷。
    （ii）此外，我们引入了细节捕获模块，它只由简单轻量级卷积组成，以补充抠图所需的详细信息。据我们所知，ViTMatte是第一个通过简洁的适应性释放ViT在图像抠图中潜力的工作。它从ViT到抠图继承了许多优越的特性，包括各种预训练策略、简洁的架构设计和灵活的推断策略。我们在Composition-1k和Distinctions-646上评估了ViTMatte，这是图像抠图最常用的基准，我们的方法取得了最先进的性能，并大幅超越了先前的抠图作品。*'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/hustvl/ViTMatte).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[nielsr](https://huggingface.co/nielsr)贡献。原始代码可在[此处](https://github.com/hustvl/ViTMatte)找到。
- en: '![drawing](../Images/7e84c30063be5fee2342c39797706d98.png) ViTMatte high-level
    overview. Taken from the [original paper.](https://arxiv.org/abs/2305.15272)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![drawing](../Images/7e84c30063be5fee2342c39797706d98.png) ViTMatte高层概述。摘自[原始论文。](https://arxiv.org/abs/2305.15272)'
- en: Resources
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with ViTMatte.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一份官方Hugging Face和社区（由🌎表示）资源列表，以帮助您开始使用ViTMatte。
- en: A demo notebook regarding inference with [VitMatteForImageMatting](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteForImageMatting),
    including background replacement, can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/ViTMatte).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于使用[VitMatteForImageMatting](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteForImageMatting)进行推断的演示笔记本，包括背景替换，可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/ViTMatte)找到。
- en: The model expects both the image and trimap (concatenated) as input. Use `ViTMatteImageProcessor`
    for this purpose.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 模型期望图像和trimap（连接在一起）作为输入。为此目的使用`ViTMatteImageProcessor`。
- en: VitMatteConfig
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VitMatteConfig
- en: '### `class transformers.VitMatteConfig`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VitMatteConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/configuration_vitmatte.py#L32)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/configuration_vitmatte.py#L32)'
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*, defaults to `VitDetConfig()`)
    — The configuration of the backbone model.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*, defaults to `VitDetConfig()`)
    — 主干模型的配置。'
- en: '`hidden_size` (`int`, *optional*, defaults to 384) — The number of input channels
    of the decoder.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 384) — 解码器的输入通道数。'
- en: '`batch_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the batch norm layers.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_norm_eps` (`float`, *optional*, defaults to 1e-05) — 批量归一化层使用的epsilon。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`convstream_hidden_sizes` (`List[int]`, *optional*, defaults to `[48, 96, 192]`)
    — The output channels of the ConvStream module.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convstream_hidden_sizes` (`List[int]`, *optional*, defaults to `[48, 96, 192]`)
    — ConvStream模块的输出通道数。'
- en: '`fusion_hidden_sizes` (`List[int]`, *optional*, defaults to `[256, 128, 64,
    32]`) — The output channels of the Fusion blocks.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fusion_hidden_sizes` (`List[int]`, *optional*, defaults to `[256, 128, 64,
    32]`) — Fusion块的输出通道数。'
- en: This is the configuration class to store the configuration of [VitMatteForImageMatting](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteForImageMatting).
    It is used to instantiate a ViTMatte model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the ViTMatte [hustvl/vitmatte-small-composition-1k](https://huggingface.co/hustvl/vitmatte-small-composition-1k)
    architecture.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储 [VitMatteForImageMatting](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteForImageMatting)
    配置的配置类。它用于根据指定的参数实例化一个 ViTMatte 模型，定义模型架构。使用默认值实例化配置将产生类似于 ViTMatte [hustvl/vitmatte-small-composition-1k](https://huggingface.co/hustvl/vitmatte-small-composition-1k)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读来自
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#### `to_dict`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/configuration_vitmatte.py#L100)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/configuration_vitmatte.py#L100)'
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Serializes this instance to a Python dictionary. Override the default [to_dict()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.to_dict).
    Returns: `Dict[str, any]`: Dictionary of all the attributes that make up this
    configuration instance,'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将此实例序列化为 Python 字典。覆盖默认的 [to_dict()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.to_dict)。返回：`Dict[str,
    any]`：构成此配置实例的所有属性的字典，
- en: VitMatteImageProcessor
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VitMatteImageProcessor
- en: '### `class transformers.VitMatteImageProcessor`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.VitMatteImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/image_processing_vitmatte.py#L41)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/image_processing_vitmatte.py#L41)'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`
    parameter in the `preprocess` method.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, 默认为 `True`) — 是否按指定比例 `rescale_factor` 重新缩放图像。可以被
    `preprocess` 方法中的 `do_rescale` 参数覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in the `preprocess` method.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` 或 `float`, *optional*, 默认为 `1/255`) — 如果重新缩放图像，则使用的缩放因子。可以被
    `preprocess` 方法中的 `rescale_factor` 参数覆盖。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, 默认为 `True`) — 是否对图像进行规范化。可以被 `preprocess`
    方法中的 `do_normalize` 参数覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *optional*, 默认为 `IMAGENET_STANDARD_MEAN`)
    — 如果规范化图像，则使用的均值。这是一个浮点数或与图像中通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_mean`
    参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *optional*, 默认为 `IMAGENET_STANDARD_STD`)
    — 如果规范化图像，则使用的标准差。这是一个浮点数或与图像中通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_std`
    参数覆盖。'
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) — Whether to pad the image
    to make the width and height divisible by `size_divisibility`. Can be overridden
    by the `do_pad` parameter in the `preprocess` method.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *optional*, 默认为 `True`) — 是否填充图像以使宽度和高度可被 `size_divisibility`
    整除。可以被 `preprocess` 方法中的 `do_pad` 参数覆盖。'
- en: '`size_divisibility` (`int`, *optional*, defaults to 32) — The width and height
    of the image will be padded to be divisible by this number.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisibility` (`int`, *optional*, 默认为 32) — 图像的宽度和高度将被填充为可被此数字整除。'
- en: Constructs a ViTMatte image processor.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 ViTMatte 图像处理器。
- en: '#### `preprocess`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/image_processing_vitmatte.py#L131)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/image_processing_vitmatte.py#L131)'
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 预处理的图像。期望单个图像或批量图像，像素值范围为 0 到 255。如果传入像素值在 0 到 1
    之间的图像，请设置 `do_rescale=False`。'
- en: '`trimaps` (`ImageInput`) — Trimap to preprocess.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trimaps` (`ImageInput`) — 预处理的 Trimap。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image values between [0 - 1].'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, 默认为 `self.do_rescale`) — 是否将图像值重新缩放到 [0 -
    1]。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    Rescale factor to rescale the image by if `do_rescale` is set to `True`.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *optional*, 默认为 `self.rescale_factor`) — 如果 `do_rescale`
    设置为 `True`，则用于重新缩放图像的重新缩放因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, 默认为 `self.do_normalize`) — 是否对图像进行规范化。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    — Image mean to use if `do_normalize` is set to `True`.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *optional*, 默认为 `self.image_mean`) —
    如果设置 `do_normalize` 为 `True`，则使用的图像均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    — Image standard deviation to use if `do_normalize` is set to `True`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std`（`float`或`List[float]`，*可选*，默认为`self.image_std`）-如果`do_normalize`设置为`True`，要使用的图像标准差。'
- en: '`do_pad` (`bool`, *optional*, defaults to `self.do_pad`) — Whether to pad the
    image.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad`（`bool`，*可选*，默认为`self.do_pad`）-是否填充图像。'
- en: '`size_divisibility` (`int`, *optional*, defaults to `self.size_divisibility`)
    — The size divisibility to pad the image to if `do_pad` is set to `True`.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisibility`（`int`，*可选*，默认为`self.size_divisibility`）-如果`do_pad`设置为`True`，则填充图像的大小可被整除。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或`TensorType`，*可选*）-要返回的张量类型。可以是以下之一：'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：返回一个`np.ndarray`列表。
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW`或`''tf''`：返回类型为`tf.Tensor`的批次。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH`或`''pt''`：返回类型为`torch.Tensor`的批次。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY`或`''np''`：返回类型为`np.ndarray`的批次。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX`或`''jax''`：返回类型为`jax.numpy.ndarray`的批次。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`（`ChannelDimension`或`str`，*可选*，默认为`ChannelDimension.FIRST`）-输出图像的通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图像以（通道数，高度，宽度）格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图像以（高度，宽度，通道数）格式。'
- en: 'Unset: Use the channel dimension format of the input image.'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：使用输入图像的通道维度格式。
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format`（`ChannelDimension`或`str`，*可选*）-输入图像的通道维度格式。如果未设置，则从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图像以（通道数，高度，宽度）格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图像以（高度，宽度，通道数）格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"`或`ChannelDimension.NONE`：图像以（高度，宽度）格式。'
- en: Preprocess an image or batch of images.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一张图像或一批图像。
- en: VitMatteForImageMatting
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VitMatteForImageMatting
- en: '### `class transformers.VitMatteForImageMatting`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.VitMatteForImageMatting`类'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/modeling_vitmatte.py#L253)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/modeling_vitmatte.py#L253)'
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`This` model is a PyTorch [torch.nn.Module](https —//pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。使用
- en: '`it` as a regular PyTorch Module and refer to the PyTorch documentation for
    all matter related to general usage and — behavior. — config ([UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)):
    Model configuration class with all the parameters of the model. Initializing with
    a config file does not load the weights associated with the model, only the configuration.
    Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。-配置（[UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig）：具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。
- en: ViTMatte framework leveraging any vision backbone e.g. for ADE20k, CityScapes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 利用任何视觉骨干的ViTMatte框架，例如ADE20k，CityScapes。
- en: '#### `forward`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/modeling_vitmatte.py#L268)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/vitmatte/modeling_vitmatte.py#L268)'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [VitMatteImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）-像素值。默认情况下，如果提供，将忽略填充。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅[VitMatteImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers in case the backbone has them. See `attentions`
    under returned tensors for more detail.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）-是否返回所有注意力层的注意力张量，如果骨干网络具有这些层。有关更多详细信息，请参阅返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers of the backbone. See `hidden_states` under returned
    tensors for more detail.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）-是否返回骨干网络所有层的隐藏状态。有关更多详细信息，请参阅返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）-是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Ground truth image matting for computing the loss.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, height, width)`的`torch.LongTensor`，*可选*）-用于计算损失的地面实况图像抠图。'
- en: Returns
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.vitmatte.modeling_vitmatte.ImageMattingOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.vitmatte.modeling_vitmatte.ImageMattingOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.vitmatte.modeling_vitmatte.ImageMattingOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([VitMatteConfig](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteConfig))
    and inputs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.vitmatte.modeling_vitmatte.ImageMattingOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（[VitMatteConfig](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteConfig)）和输入而异的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Loss.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回） — 损失。'
- en: '`alphas` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Estimated alpha values.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alphas`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）
    — 估计的alpha值。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states (also called feature maps) of the model at the output of each stage.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, patch_size, sequence_length)`.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, patch_size, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [VitMatteForImageMatting](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteForImageMatting)
    forward method, overrides the `__call__` special method.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[VitMatteForImageMatting](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteForImageMatting)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Examples:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
