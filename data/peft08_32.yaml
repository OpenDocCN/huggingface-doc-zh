- en: Configuration
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置
- en: 'Original text: [https://huggingface.co/docs/peft/package_reference/config](https://huggingface.co/docs/peft/package_reference/config)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/peft/package_reference/config](https://huggingface.co/docs/peft/package_reference/config)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '`PeftConfigMixin` is the base configuration class for storing the adapter configuration
    of a [PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel),
    and [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)
    is the base configuration class for soft prompt methods (p-tuning, prefix tuning,
    and prompt tuning). These base classes contain methods for saving and loading
    model configurations from the Hub, specifying the PEFT method to use, type of
    task to perform, and model configurations like number of layers and number of
    attention heads.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '`PeftConfigMixin`是用于存储[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)适配器配置的基本配置类，而[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)是用于软提示方法（p-tuning、prefix
    tuning和prompt tuning）的基本配置类。这些基本类包含了从Hub保存和加载模型配置的方法，指定要使用的PEFT方法、要执行的任务类型以及模型配置（如层数和注意力头数）。'
- en: PeftConfigMixin
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftConfigMixin
- en: '### `class peft.config.PeftConfigMixin`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.config.PeftConfigMixin`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L26)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L26)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`peft_type` (Union[`~peft.utils.config.PeftType`, `str`]) — The type of Peft
    method to use.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_type`（Union[`~peft.utils.config.PeftType`，`str`]）— 要使用的Peft方法的类型。'
- en: This is the base configuration class for PEFT adapter models. It contains all
    the methods that are common to all PEFT adapter models. This class inherits from
    [PushToHubMixin](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.utils.PushToHubMixin)
    which contains the methods to push your model to the Hub. The method `save_pretrained`
    will save the configuration of your adapter model in a directory. The method `from_pretrained`
    will load the configuration of your adapter model from a directory.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是PEFT适配器模型的基本配置类。它包含所有PEFT适配器模型共有的方法。此类继承自[PushToHubMixin](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.utils.PushToHubMixin)，其中包含将模型推送到Hub的方法。`save_pretrained`方法将在目录中保存适配器模型的配置。`from_pretrained`方法将从目录中加载适配器模型的配置。
- en: '#### `from_json_file`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_json_file`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L153)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L153)'
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`path_json_file` (`str`) — The path to the json file.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path_json_file`（`str`）— json文件的路径。'
- en: Loads a configuration file from a json file.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从json文件加载配置文件。
- en: '#### `from_peft_type`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_peft_type`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L82)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L82)'
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`kwargs` (configuration keyword arguments) — Keyword arguments passed along
    to the configuration initialization.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（配置关键字参数）— 传递给配置初始化的关键字参数。'
- en: This method loads the configuration of your adapter model from a set of kwargs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法从一组kwargs中加载适配器模型的配置。
- en: The appropriate configuration type is determined by the `peft_type` argument.
    If `peft_type` is not provided, the calling class type is instantiated.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 适当的配置类型由`peft_type`参数确定。如果未提供`peft_type`，则实例化调用类类型。
- en: '#### `from_pretrained`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L120)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L120)'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str`) — The directory or the Hub repository
    id where the configuration is saved.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`）— 配置保存的目录或Hub存储库id。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Additional keyword arguments
    passed along to the child class initialization.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 传递给子类初始化的额外关键字参数。'
- en: This method loads the configuration of your adapter model from a directory.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法从目录中加载适配器模型的配置。
- en: '#### `save_pretrained`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L49)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L49)'
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str`) — The directory where the configuration will be saved.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory`（`str`）— 配置将被保存的目录。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Additional keyword arguments
    passed along to the [push_to_hub](https://huggingface.co/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 传递给[push_to_hub](https://huggingface.co/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的额外关键字参数。'
- en: This method saves the configuration of your adapter model in a directory.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将适配器模型的配置保存在目录中。
- en: '#### `to_dict`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_dict`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L43)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L43)'
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Returns the configuration for your adapter model as a dictionary.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将适配器模型的配置作为字典返回。
- en: PeftConfig
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftConfig
- en: '### `class peft.PeftConfig`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftConfig`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L221)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L221)'
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`peft_type` (Union[`~peft.utils.config.PeftType`, `str`]) — The type of Peft
    method to use.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_type`（Union[`~peft.utils.config.PeftType`，`str`]）— 要使用的Peft方法的类型。'
- en: '`task_type` (Union[`~peft.utils.config.TaskType`, `str`]) — The type of task
    to perform.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_type`（Union[`~peft.utils.config.TaskType`，`str`]）— 要执行的任务类型。'
- en: '`inference_mode` (`bool`, defaults to `False`) — Whether to use the Peft model
    in inference mode.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inference_mode`（`bool`，默认为`False`）— 是否在推理模式下使用Peft模型。'
- en: This is the base configuration class to store the configuration of a [PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)配置的基本配置类。
- en: PromptLearningConfig
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PromptLearningConfig
- en: '### `class peft.PromptLearningConfig`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PromptLearningConfig`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L241)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/config.py#L241)'
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_virtual_tokens` (`int`) — The number of virtual tokens to use.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_virtual_tokens` (`int`) — 要使用的虚拟标记数量。'
- en: '`token_dim` (`int`) — The hidden embedding dimension of the base transformer
    model.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_dim` (`int`) — 基础变换器模型的隐藏嵌入维度。'
- en: '`num_transformer_submodules` (`int`) — The number of transformer submodules
    in the base transformer model.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_transformer_submodules` (`int`) — 基础变换器模型中的变换器子模块数量。'
- en: '`num_attention_heads` (`int`) — The number of attention heads in the base transformer
    model.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`) — 基础变换器模型中的注意力头数量。'
- en: '`num_layers` (`int`) — The number of layers in the base transformer model.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers` (`int`) — 基础变换器模型中的层数。'
- en: This is the base configuration class to store the configuration of `PrefixTuning`,
    [PromptEncoder](/docs/peft/v0.8.2/en/package_reference/p_tuning#peft.PromptEncoder),
    or `PromptTuning`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储`PrefixTuning`、[PromptEncoder](/docs/peft/v0.8.2/en/package_reference/p_tuning#peft.PromptEncoder)或`PromptTuning`配置的基础配置类。
