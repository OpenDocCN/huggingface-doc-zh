- en: Llama-Adapter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Llama-Adapter
- en: 'Original text: [https://huggingface.co/docs/peft/package_reference/llama_adapter](https://huggingface.co/docs/peft/package_reference/llama_adapter)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/peft/package_reference/llama_adapter](https://huggingface.co/docs/peft/package_reference/llama_adapter)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Llama-Adapter](https://hf.co/papers/2303.16199) is a PEFT method specifically
    designed for turning Llama into an instruction-following model. The Llama model
    is frozen and only a set of adaptation prompts prefixed to the input instruction
    tokens are learned. Since randomly initialized modules inserted into the model
    can cause the model to lose some of its existing knowledge, Llama-Adapter uses
    zero-initialized attention with zero gating to progressively add the instructional
    prompts to the model.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Llama-Adapter](https://hf.co/papers/2303.16199) 是一种专门设计用于将 Llama 转换为遵循指令的模型的
    PEFT 方法。Llama 模型被冻结，只学习一组附加到输入指令标记的适应提示。由于随机初始化的模块插入到模型中可能导致模型丢失部分现有知识，Llama-Adapter
    使用零初始化的注意力和零门控逐渐向模型添加指令提示。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune
    LLaMA into an instruction-following model. Using 52K self-instruct demonstrations,
    LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA
    7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically,
    we adopt a set of learnable adaption prompts, and prepend them to the input text
    tokens at higher transformer layers. Then, a zero-init attention mechanism with
    zero gating is proposed, which adaptively injects the new instructional cues into
    LLaMA, while effectively preserves its pre-trained knowledge. With efficient training,
    LLaMA-Adapter generates high-quality responses, comparable to Alpaca with fully
    fine-tuned 7B parameters. Furthermore, our approach can be simply extended to
    multi-modal input, e.g., images, for image-conditioned LLaMA, which achieves superior
    reasoning capacity on ScienceQA. We release our code at [https://github.com/ZrrSkywalker/LLaMA-Adapter](https://github.com/ZrrSkywalker/LLaMA-Adapter)*.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了 LLaMA-Adapter，一种轻量级的适应方法，可以有效地将 LLaMA 微调为一个遵循指令的模型。使用 52K 个自我指导演示，LLaMA-Adapter
    仅在冻结的 LLaMA 7B 模型上引入了 1.2M 个可学习参数，并且在 8 个 A100 GPU 上进行微调不到一小时。具体来说，我们采用一组可学习的适应提示，并将它们附加到更高的变换器层的输入文本标记中。然后，提出了一种零初始化的注意力机制和零门控，它可以自适应地将新的指令提示注入到
    LLaMA 中，同时有效地保留其预训练知识。通过高效的训练，LLaMA-Adapter 生成了高质量的响应，与完全微调的 7B 参数的 Alpaca 相媲美。此外，我们的方法可以简单地扩展到多模态输入，例如图像，用于基于图像的
    LLaMA，在 ScienceQA 上实现了更强大的推理能力。我们在 [https://github.com/ZrrSkywalker/LLaMA-Adapter](https://github.com/ZrrSkywalker/LLaMA-Adapter)
    上发布了我们的代码*。'
- en: AdaptionPromptConfig
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AdaptionPromptConfig
- en: '### `class peft.AdaptionPromptConfig`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.AdaptionPromptConfig`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/config.py#L24)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/config.py#L24)'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Stores the configuration of an [AdaptionPromptModel](/docs/peft/v0.8.2/en/package_reference/llama_adapter#peft.AdaptionPromptModel).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 存储 [AdaptionPromptModel](/docs/peft/v0.8.2/en/package_reference/llama_adapter#peft.AdaptionPromptModel)
    的配置。
- en: AdaptionPromptModel
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AdaptionPromptModel
- en: '### `class peft.AdaptionPromptModel`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.AdaptionPromptModel`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L26)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L26)'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Implements adaption prompts as described in [https://arxiv.org/pdf/2303.16199.pdf](https://arxiv.org/pdf/2303.16199.pdf).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实现如 [https://arxiv.org/pdf/2303.16199.pdf](https://arxiv.org/pdf/2303.16199.pdf)
    中描述的适应提示。
- en: The top L attention modules are replaced with AdaptedAttention modules that
    wrap the original ones, but insert trainable prompts with gates (for zero init).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部的 L 注意力模块被替换为 AdaptedAttention 模块，这些模块包装了原始模块，但插入了带有门控的可训练提示（用于零初始化）。
- en: 'Notes on the multi-adapter pattern:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 关于多适配器模式的注释：
- en: We store the states of different adapters by keeping a dictionary of AdaptedAttention
    modules indexed by adapter name.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过保持一个由适配器名称索引的 AdaptedAttention 模块字典来存储不同适配器的状态。
- en: Every time we switch adapters, we remove the modules of the currently active
    adapter from the model, store them in the dictionary, and replace them with the
    modules of the new adapter.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次切换适配器时，我们会从模型中移除当前活动适配器的模块，将其存储在字典中，并用新适配器的模块替换它们。
- en: To avoid duplicated and potentially inconsistent state, the currently active
    adapter is always removed from the dictionary.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为避免重复和潜在的不一致状态，当前活动的适配器始终从字典中移除。
- en: Disabling the adapter would also result in the modules being removed from the
    model.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用适配器也会导致模块从模型中移除。
- en: '#### `add_adapter`'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L61)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L61)'
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Add an adapter with the given name and config.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定名称和配置添加一个适配器。
- en: '#### `disable_adapter_layers`'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_adapter_layers`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L115)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L115)'
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disable adapter layers by swapping out AdaptedAttention modules.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过交换出 AdaptedAttention 模块来禁用适配器层。
- en: '#### `enable_adapter_layers`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_adapter_layers`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L110)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L110)'
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Enable adapter layers by swapping in cached AdaptedAttention modules.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过交换缓存的 AdaptedAttention 模块启用适配器层。
- en: '#### `set_adapter`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L97)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/adaption_prompt/model.py#L97)'
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Set the model to use the adapter with the given name.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 设置模型使用给定名称的适配器。
