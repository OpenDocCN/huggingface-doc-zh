- en: Deformable DETR
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Deformable DETR
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deformable_detr](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deformable_detr)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deformable_detr](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deformable_detr)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The Deformable DETR model was proposed in [Deformable DETR: Deformable Transformers
    for End-to-End Object Detection](https://arxiv.org/abs/2010.04159) by Xizhou Zhu,
    Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai. Deformable DETR mitigates
    the slow convergence issues and limited feature spatial resolution of the original
    [DETR](detr) by leveraging a new deformable attention module which only attends
    to a small set of key sampling points around a reference.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'Deformable DETR模型是由Xizhou Zhu，Weijie Su，Lewei Lu，Bin Li，Xiaogang Wang，Jifeng
    Dai在[Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159)中提出的。Deformable
    DETR通过利用一个新的可变形注意力模块，该模块只关注参考周围一小组关键采样点，从而缓解了原始[DETR](detr)的收敛速度慢和特征空间分辨率有限的问题。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*DETR has been recently proposed to eliminate the need for many hand-designed
    components in object detection while demonstrating good performance. However,
    it suffers from slow convergence and limited feature spatial resolution, due to
    the limitation of Transformer attention modules in processing image feature maps.
    To mitigate these issues, we proposed Deformable DETR, whose attention modules
    only attend to a small set of key sampling points around a reference. Deformable
    DETR can achieve better performance than DETR (especially on small objects) with
    10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate
    the effectiveness of our approach.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*DETR最近被提出，旨在消除目标检测中许多手工设计的组件的需求，同时表现良好。然而，由于Transformer注意力模块在处理图像特征图时的限制，它存在收敛速度慢和特征空间分辨率有限的问题。为了缓解这些问题，我们提出了Deformable
    DETR，其注意力模块只关注参考周围一小组关键采样点。Deformable DETR可以比DETR实现更好的性能（特别是对于小目标），并且训练时长减少了10倍。在COCO基准测试上的大量实验证明了我们方法的有效性。*'
- en: '![drawing](../Images/840536d35745dda097869c1c27a80c35.png) Deformable DETR
    architecture. Taken from the [original paper](https://arxiv.org/abs/2010.04159).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/840536d35745dda097869c1c27a80c35.png) Deformable DETR架构。摘自[原始论文](https://arxiv.org/abs/2010.04159)。'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/fundamentalvision/Deformable-DETR).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[nielsr](https://huggingface.co/nielsr)贡献。原始代码可以在[这里](https://github.com/fundamentalvision/Deformable-DETR)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: Training Deformable DETR is equivalent to training the original [DETR](detr)
    model. See the [resources](#resources) section below for demo notebooks.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练Deformable DETR等同于训练原始[DETR](detr)模型。有关演示笔记本，请参见下面的[资源](#resources)部分。
- en: Resources
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with Deformable DETR.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 官方Hugging Face和社区（由🌎表示）资源列表，可帮助您开始使用Deformable DETR。
- en: Object Detection
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测
- en: Demo notebooks regarding inference + fine-tuning on a custom dataset for [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Deformable-DETR).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于在自定义数据集上进行推理+微调的演示笔记本，可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Deformable-DETR)找到。
- en: 'See also: [Object detection task guide](../tasks/object_detection).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：[目标检测任务指南](../tasks/object_detection)。
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we’ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在此处，请随时提出拉取请求，我们将对其进行审查！资源应该展示一些新内容，而不是重复现有资源。
- en: DeformableDetrImageProcessor
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeformableDetrImageProcessor
- en: '### `class transformers.DeformableDetrImageProcessor`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeformableDetrImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L756)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L756)'
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`format` (`str`, *optional*, defaults to `"coco_detection"`) — Data format
    of the annotations. One of “coco_detection” or “coco_panoptic”.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`format` (`str`，*可选*，默认为`"coco_detection"`) — 注释的数据格式。其中之一是“coco_detection”或“coco_panoptic”。'
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Controls whether to
    resize the image’s (height, width) dimensions to the specified `size`. Can be
    overridden by the `do_resize` parameter in the `preprocess` method.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`，*可选*，默认为`True`) — 控制是否将图像的（高度，宽度）尺寸调整为指定的`size`。可以通过`preprocess`方法中的`do_resize`参数进行覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"shortest_edge" -- 800,
    "longest_edge": 1333}`): Size of the image’s (height, width) dimensions after
    resizing. Can be overridden by the `size` parameter in the `preprocess` method.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *可选*，默认为`{"shortest_edge" -- 800, "longest_edge":
    1333}`)：调整大小后的图像（高度，宽度）尺寸。可以通过`preprocess`方法中的`size`参数进行覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BILINEAR`)
    — Resampling filter to use if resizing the image.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`，*可选*，默认为`PILImageResampling.BILINEAR`) — 如果调整图像大小，则要使用的重采样滤波器。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Controls whether to
    rescale the image by the specified scale `rescale_factor`. Can be overridden by
    the `do_rescale` parameter in the `preprocess` method.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`，*可选*，默认为`True`) — 控制是否按指定比例`rescale_factor`对图像进行重新缩放。可以通过`preprocess`方法中的`do_rescale`参数进行覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in the `preprocess` method. do_normalize — Controls whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor`（`int`或`float`，*可选*，默认为`1/255`）— 如果重新缩放图像，则使用的比例因子。可以被`preprocess`方法中的`rescale_factor`参数覆盖。do_normalize
    — 控制是否规范化图像。可以被`preprocess`方法中的`do_normalize`参数覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`)
    — Mean values to use when normalizing the image. Can be a single value or a list
    of values, one for each channel. Can be overridden by the `image_mean` parameter
    in the `preprocess` method.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean`（`float`或`List[float]`，*可选*，默认为`IMAGENET_DEFAULT_MEAN`）— 在规范化图像时使用的均值。可以是单个值或值列表，每个通道一个值。可以被`preprocess`方法中的`image_mean`参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`)
    — Standard deviation values to use when normalizing the image. Can be a single
    value or a list of values, one for each channel. Can be overridden by the `image_std`
    parameter in the `preprocess` method.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std`（`float`或`List[float]`，*可选*，默认为`IMAGENET_DEFAULT_STD`）— 在规范化图像时使用的标准差值。可以是单个值或值列表，每个通道一个值。可以被`preprocess`方法中的`image_std`参数覆盖。'
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) — Controls whether to pad
    the image to the largest image in a batch and create a pixel mask. Can be overridden
    by the `do_pad` parameter in the `preprocess` method.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad`（`bool`，*可选*，默认为`True`）— 控制是否将图像填充到批次中最大的图像并创建像素掩模。可以被`preprocess`方法中的`do_pad`参数覆盖。'
- en: Constructs a Deformable DETR image processor.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 构造一个可变形DETR图像处理器。
- en: '#### `preprocess`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1097)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1097)'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image or batch of images to preprocess. Expects a
    single or batch of images with pixel values ranging from 0 to 255\. If passing
    in images with pixel values between 0 and 1, set `do_rescale=False`.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images`（`ImageInput`）— 要预处理的图像或图像批次。期望单个图像或像素值范围从0到255的图像批次。如果传入像素值在0到1之间的图像，请设置`do_rescale=False`。'
- en: '`annotations` (`AnnotationType` or `List[AnnotationType]`, *optional*) — List
    of annotations associated with the image or batch of images. If annotation is
    for object detection, the annotations should be a dictionary with the following
    keys:'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`annotations`（`AnnotationType`或`List[AnnotationType]`，*可选*）— 与图像或图像批次关联的注释列表。如果注释用于目标检测，则注释应该是一个带有以下键的字典：'
- en: '“image_id” (`int`): The image id.'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “image_id”（`int`）：图像ID。
- en: '“annotations” (`List[Dict]`): List of annotations for an image. Each annotation
    should be a dictionary. An image can have no annotations, in which case the list
    should be empty. If annotation is for segmentation, the annotations should be
    a dictionary with the following keys:'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “annotations”（`List[Dict]`）：图像的注释列表。每个注释应该是一个字典。一个图像可以没有注释，此时列表应为空。如果注释是用于分割的，注释应该是一个带有以下键的字典：
- en: '“image_id” (`int`): The image id.'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “image_id”（`int`）：图像ID。
- en: '“segments_info” (`List[Dict]`): List of segments for an image. Each segment
    should be a dictionary. An image can have no segments, in which case the list
    should be empty.'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “segments_info”（`List[Dict]`）：图像的分段列表。每个分段应该是一个字典。一个图像可以没有分段，此时列表应为空。
- en: '“file_name” (`str`): The file name of the image.'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “file_name”（`str`）：图像的文件名。
- en: '`return_segmentation_masks` (`bool`, *optional*, defaults to self.return_segmentation_masks)
    — Whether to return segmentation masks.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_segmentation_masks`（`bool`，*可选*，默认为self.return_segmentation_masks）—
    是否返回分割掩模。'
- en: '`masks_path` (`str` or `pathlib.Path`, *optional*) — Path to the directory
    containing the segmentation masks.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_path`（`str`或`pathlib.Path`，*可选*）— 包含分割掩模的目录的路径。'
- en: '`do_resize` (`bool`, *optional*, defaults to self.do_resize) — Whether to resize
    the image.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`（`bool`，*可选*，默认为self.do_resize）— 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to self.size) — Size of the
    image after resizing.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`（`Dict[str, int]`，*可选*，默认为self.size）— 调整大小后的图像尺寸。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to self.resample) —
    Resampling filter to use when resizing the image.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample`（`PILImageResampling`，*可选*，默认为self.resample）— 调整图像大小时要使用的重采样滤波器。'
- en: '`do_rescale` (`bool`, *optional*, defaults to self.do_rescale) — Whether to
    rescale the image.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale`（`bool`，*可选*，默认为self.do_rescale）— 是否重新缩放图像。'
- en: '`rescale_factor` (`float`, *optional*, defaults to self.rescale_factor) — Rescale
    factor to use when rescaling the image.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor`（`float`，*可选*，默认为self.rescale_factor）— 重新缩放图像时使用的比例因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to self.do_normalize) — Whether
    to normalize the image.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize`（`bool`，*可选*，默认为self.do_normalize）— 是否规范化图像。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to self.image_mean)
    — Mean to use when normalizing the image.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean`（`float`或`List[float]`，*可选*，默认为self.image_mean）— 在规范化图像时使用的均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to self.image_std)
    — Standard deviation to use when normalizing the image.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std`（`float`或`List[float]`，*可选*，默认为self.image_std）— 在规范化图像时使用的标准差。'
- en: '`do_pad` (`bool`, *optional*, defaults to self.do_pad) — Whether to pad the
    image.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad`（`bool`，*可选*，默认为self.do_pad）— 是否填充图像。'
- en: '`format` (`str` or `AnnotationFormat`, *optional*, defaults to self.format)
    — Format of the annotations.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`format`（`str`或`AnnotationFormat`，*可选*，默认为self.format）— 注释的格式。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*, defaults to self.return_tensors)
    — Type of tensors to return. If `None`, will return the list of images.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或`TensorType`，*可选*，默认为self.return_tensors）— 要返回的张量类型。如果为`None`，将返回图像列表。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` 或 `str`, *可选*, 默认为 `ChannelDimension.FIRST`)
    — 输出图像的通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。'
- en: 'Unset: Use the channel dimension format of the input image.'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：使用输入图像的通道维度格式。
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format` (`ChannelDimension` 或 `str`, *可选*) — 输入图像的通道维度格式。如果未设置，则从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` 或 `ChannelDimension.NONE`：图像以 (高度, 宽度) 格式。'
- en: Preprocess an image or a batch of images so that it can be used by the model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或图像批次，以便模型可以使用。
- en: '#### `post_process_object_detection`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_object_detection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1373)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1373)'
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` (`DetrObjectDetectionOutput`) — Raw outputs of the model.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs` (`DetrObjectDetectionOutput`) — 模型的原始输出。'
- en: '`threshold` (`float`, *optional*) — Score threshold to keep object detection
    predictions.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`, *可选*) — 保留目标检测预测的分数阈值。'
- en: '`target_sizes` (`torch.Tensor` or `List[Tuple[int, int]]`, *optional*) — Tensor
    of shape `(batch_size, 2)` or list of tuples (`Tuple[int, int]`) containing the
    target size (height, width) of each image in the batch. If left to None, predictions
    will not be resized.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes` (`torch.Tensor` 或 `List[Tuple[int, int]]`, *可选*) — 形状为 `(batch_size,
    2)` 的张量或包含批次中每个图像目标大小 (高度, 宽度) 的元组列表 (`Tuple[int, int]`)。如果为 None，则预测不会被调整大小。'
- en: '`top_k` (`int`, *optional*, defaults to 100) — Keep only top k bounding boxes
    before filtering by thresholding.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k` (`int`, *可选*, 默认为 100) — 在通过阈值过滤之前仅保留前 k 个边界框。'
- en: Returns
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: A list of dictionaries, each dictionary containing the scores, labels and boxes
    for an image in the batch as predicted by the model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个字典包含模型预测的批次中每个图像的分数、标签和框。
- en: Converts the raw output of [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    into final bounding boxes in (top_left_x, top_left_y, bottom_right_x, bottom_right_y)
    format. Only supports PyTorch.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 将 [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    的原始输出转换为最终的边界框，格式为 (左上角 x 坐标, 左上角 y 坐标, 右下角 x 坐标, 右下角 y 坐标)。仅支持 PyTorch。
- en: DeformableDetrFeatureExtractor
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeformableDetrFeatureExtractor
- en: '### `class transformers.DeformableDetrFeatureExtractor`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeformableDetrFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/feature_extraction_deformable_detr.py#L36)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/feature_extraction_deformable_detr.py#L36)'
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#### `__call__`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Preprocess an image or a batch of images.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或图像批次。
- en: '#### `post_process_object_detection`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_object_detection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1373)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1373)'
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` (`DetrObjectDetectionOutput`) — Raw outputs of the model.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs` (`DetrObjectDetectionOutput`) — 模型的原始输出。'
- en: '`threshold` (`float`, *optional*) — Score threshold to keep object detection
    predictions.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`, *可选*) — 保留目标检测预测的分数阈值。'
- en: '`target_sizes` (`torch.Tensor` or `List[Tuple[int, int]]`, *optional*) — Tensor
    of shape `(batch_size, 2)` or list of tuples (`Tuple[int, int]`) containing the
    target size (height, width) of each image in the batch. If left to None, predictions
    will not be resized.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes` (`torch.Tensor` 或 `List[Tuple[int, int]]`, *可选*) — 形状为 `(batch_size,
    2)` 的张量或包含批次中每个图像目标大小 (高度, 宽度) 的元组列表 (`Tuple[int, int]`)。如果为 None，则预测不会被调整大小。'
- en: '`top_k` (`int`, *optional*, defaults to 100) — Keep only top k bounding boxes
    before filtering by thresholding.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k` (`int`, *可选*, 默认为 100) — 在通过阈值过滤之前仅保留前 k 个边界框。'
- en: Returns
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: A list of dictionaries, each dictionary containing the scores, labels and boxes
    for an image in the batch as predicted by the model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个字典包含模型预测的批次中每个图像的分数、标签和框。
- en: Converts the raw output of [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    into final bounding boxes in (top_left_x, top_left_y, bottom_right_x, bottom_right_y)
    format. Only supports PyTorch.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 将 [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    的原始输出转换为最终的边界框，格式为 (左上角 x 坐标, 左上角 y 坐标, 右下角 x 坐标, 右下角 y 坐标)。仅支持 PyTorch。
- en: DeformableDetrConfig
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeformableDetrConfig
- en: '### `class transformers.DeformableDetrConfig`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeformableDetrConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/configuration_deformable_detr.py#L30)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/configuration_deformable_detr.py#L30)'
- en: '[PRE6]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`use_timm_backbone` (`bool`, *optional*, defaults to `True`) — Whether or not
    to use the `timm` library for the backbone. If set to `False`, will use the `AutoBackbone`
    API.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_timm_backbone` (`bool`, *optional*, defaults to `True`) — 是否使用 `timm`
    库作为骨干网络。如果设置为 `False`，将使用 `AutoBackbone` API。'
- en: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*) — The configuration
    of the backbone model. Only used in case `use_timm_backbone` is set to `False`
    in which case it will default to `ResNetConfig()`.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*) — 骨干模型的配置。仅在 `use_timm_backbone`
    设置为 `False` 时使用，此时默认为 `ResNetConfig()`。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, defaults to 3) — 输入通道数。'
- en: '`num_queries` (`int`, *optional*, defaults to 300) — Number of object queries,
    i.e. detection slots. This is the maximal number of objects [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    can detect in a single image. In case `two_stage` is set to `True`, we use `two_stage_num_proposals`
    instead.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_queries` (`int`, *optional*, defaults to 300) — 对象查询的数量，即检测槽位。这是 [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    在单个图像中可以检测到的对象的最大数量。如果将 `two_stage` 设置为 `True`，则使用 `two_stage_num_proposals`。'
- en: '`d_model` (`int`, *optional*, defaults to 256) — Dimension of the layers.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *optional*, defaults to 256) — 层的维度。'
- en: '`encoder_layers` (`int`, *optional*, defaults to 6) — Number of encoder layers.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers` (`int`, *optional*, defaults to 6) — 编码器层数。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 6) — Number of decoder layers.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *optional*, defaults to 6) — 解码器层数。'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads` (`int`, *optional*, defaults to 8) — Transformer
    编码器中每个注意力层的注意力头数。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, defaults to 8) — Transformer
    解码器中每个注意力层的注意力头数。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 1024) — Dimension of the
    “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, defaults to 1024) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 1024) — Dimension of the
    “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, defaults to 1024) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"relu"`)
    — The non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str` or `function`, *optional*, defaults to `"relu"`)
    — 编码器和池化层中的非线性激活函数（函数或字符串）。如果是字符串，支持 `"gelu"`、`"relu"`、`"silu"` 和 `"gelu_new"`。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化层中所有全连接层的丢失概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — 注意力概率的丢失比率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — 全连接层内激活的丢失比率。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`init_xavier_std` (`float`, *optional*, defaults to 1) — The scaling factor
    used for the Xavier initialization gain in the HM Attention map module.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_xavier_std` (`float`, *optional*, defaults to 1) — 用于 HM Attention map
    模块中的 Xavier 初始化增益的缩放因子。'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the encoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.0) — 编码器的 LayerDrop
    概率。有关更多详细信息，请参阅[LayerDrop 论文](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`auxiliary_loss` (`bool`, *optional*, defaults to `False`) — Whether auxiliary
    decoding losses (loss at each decoder layer) are to be used.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_loss` (`bool`, *optional*, defaults to `False`) — 是否使用辅助解码损失（每个解码器层的损失）。'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"sine"`) — Type
    of position embeddings to be used on top of the image features. One of `"sine"`
    or `"learned"`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *optional*, defaults to `"sine"`) — 在图像特征之上使用的位置嵌入类型。其中之一是
    `"sine"` 或 `"learned"`。'
- en: '`backbone` (`str`, *optional*, defaults to `"resnet50"`) — Name of convolutional
    backbone to use in case `use_timm_backbone` = `True`. Supports any convolutional
    backbone from the timm package. For a list of all available models, see [this
    page](https://rwightman.github.io/pytorch-image-models/#load-a-pretrained-model).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone` (`str`, *optional*, defaults to `"resnet50"`) — 在 `use_timm_backbone`
    = `True` 时要使用的卷积骨干的名称。支持来自 timm 包的任何卷积骨干。有关所有可用模型的列表，请参见[此页面](https://rwightman.github.io/pytorch-image-models/#load-a-pretrained-model)。'
- en: '`use_pretrained_backbone` (`bool`, *optional*, defaults to `True`) — Whether
    to use pretrained weights for the backbone. Only supported when `use_timm_backbone`
    = `True`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_pretrained_backbone` (`bool`, *optional*, defaults to `True`) — 是否对骨干网络使用预训练权重。仅在
    `use_timm_backbone` = `True` 时支持。'
- en: '`dilation` (`bool`, *optional*, defaults to `False`) — Whether to replace stride
    with dilation in the last convolutional block (DC5). Only supported when `use_timm_backbone`
    = `True`.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dilation` (`bool`, *optional*, defaults to `False`) — 是否在最后一个卷积块（DC5）中用膨胀替换步幅。仅在
    `use_timm_backbone` = `True` 时支持。'
- en: '`class_cost` (`float`, *optional*, defaults to 1) — Relative weight of the
    classification error in the Hungarian matching cost.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_cost` (`float`, *optional*, defaults to 1) — 匈牙利匹配成本中分类错误的相对权重。'
- en: '`bbox_cost` (`float`, *optional*, defaults to 5) — Relative weight of the L1
    error of the bounding box coordinates in the Hungarian matching cost.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox_cost` (`float`, *optional*, defaults to 5) — 匈牙利匹配成本中边界框坐标的L1误差的相对权重。'
- en: '`giou_cost` (`float`, *optional*, defaults to 2) — Relative weight of the generalized
    IoU loss of the bounding box in the Hungarian matching cost.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`giou_cost` (`float`, *optional*, defaults to 2) — 匈牙利匹配成本中边界框广义IoU损失的相对权重。'
- en: '`mask_loss_coefficient` (`float`, *optional*, defaults to 1) — Relative weight
    of the Focal loss in the panoptic segmentation loss.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_loss_coefficient` (`float`, *optional*, defaults to 1) — 全景分割损失中焦点损失的相对权重。'
- en: '`dice_loss_coefficient` (`float`, *optional*, defaults to 1) — Relative weight
    of the DICE/F-1 loss in the panoptic segmentation loss.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dice_loss_coefficient` (`float`, *optional*, defaults to 1) — DICE/F-1损失在全景分割损失中的相对权重。'
- en: '`bbox_loss_coefficient` (`float`, *optional*, defaults to 5) — Relative weight
    of the L1 bounding box loss in the object detection loss.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox_loss_coefficient` (`float`, *optional*, defaults to 5) — 目标检测损失中L1边界框损失的相对权重。'
- en: '`giou_loss_coefficient` (`float`, *optional*, defaults to 2) — Relative weight
    of the generalized IoU loss in the object detection loss.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`giou_loss_coefficient` (`float`, *optional*, defaults to 2) — 目标检测损失中广义IoU损失的相对权重。'
- en: '`eos_coefficient` (`float`, *optional*, defaults to 0.1) — Relative classification
    weight of the ‘no-object’ class in the object detection loss.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_coefficient` (`float`, *optional*, defaults to 0.1) — 目标检测损失中“无对象”类的相对分类权重。'
- en: '`num_feature_levels` (`int`, *optional*, defaults to 4) — The number of input
    feature levels.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_feature_levels` (`int`, *optional*, defaults to 4) — 输入特征级别的数量。'
- en: '`encoder_n_points` (`int`, *optional*, defaults to 4) — The number of sampled
    keys in each feature level for each attention head in the encoder.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_n_points` (`int`, *optional*, defaults to 4) — 编码器中每个注意力头的每个特征级别中采样的键的数量。'
- en: '`decoder_n_points` (`int`, *optional*, defaults to 4) — The number of sampled
    keys in each feature level for each attention head in the decoder.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_n_points` (`int`, *optional*, defaults to 4) — 解码器中每个注意力头的每个特征级别中采样的键的数量。'
- en: '`two_stage` (`bool`, *optional*, defaults to `False`) — Whether to apply a
    two-stage deformable DETR, where the region proposals are also generated by a
    variant of Deformable DETR, which are further fed into the decoder for iterative
    bounding box refinement.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`two_stage` (`bool`, *optional*, defaults to `False`) — 是否应用两阶段可变形DETR，其中区域提议也由Deformable
    DETR的变体生成，并进一步输入解码器进行迭代边界框细化。'
- en: '`two_stage_num_proposals` (`int`, *optional*, defaults to 300) — The number
    of region proposals to be generated, in case `two_stage` is set to `True`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`two_stage_num_proposals` (`int`, *optional*, defaults to 300) — 要生成的区域提议数量，如果`two_stage`设置为`True`。'
- en: '`with_box_refine` (`bool`, *optional*, defaults to `False`) — Whether to apply
    iterative bounding box refinement, where each decoder layer refines the bounding
    boxes based on the predictions from the previous layer.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`with_box_refine` (`bool`, *optional*, defaults to `False`) — 是否应用迭代边界框细化，其中每个解码器层根据前一层的预测细化边界框。'
- en: '`focal_alpha` (`float`, *optional*, defaults to 0.25) — Alpha parameter in
    the focal loss.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focal_alpha` (`float`, *optional*, defaults to 0.25) — 焦点损失中的Alpha参数。'
- en: '`disable_custom_kernels` (`bool`, *optional*, defaults to `False`) — Disable
    the use of custom CUDA and CPU kernels. This option is necessary for the ONNX
    export, as custom kernels are not supported by PyTorch ONNX export.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`disable_custom_kernels` (`bool`, *optional*, defaults to `False`) — 禁用自定义CUDA和CPU内核的使用。这个选项对ONNX导出是必要的，因为PyTorch
    ONNX导出不支持自定义内核。'
- en: This is the configuration class to store the configuration of a [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel).
    It is used to instantiate a Deformable DETR model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Deformable DETR [SenseTime/deformable-detr](https://huggingface.co/SenseTime/deformable-detr)
    architecture.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)配置的配置类。根据指定的参数实例化Deformable
    DETR模型，定义模型架构。使用默认值实例化配置将产生类似于Deformable DETR [SenseTime/deformable-detr](https://huggingface.co/SenseTime/deformable-detr)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Examples:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: DeformableDetrModel
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeformableDetrModel
- en: '### `class transformers.DeformableDetrModel`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeformableDetrModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1445)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1445)'
- en: '[PRE8]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Deformable DETR Model (consisting of a backbone and encoder-decoder
    Transformer) outputting raw hidden-states without any specific head on top.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Deformable DETR模型（由骨干和编码器-解码器Transformer组成），输出没有特定头部的原始隐藏状态。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为其所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1601)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1601)'
- en: '[PRE9]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。默认情况下将忽略填充。'
- en: Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeformableDetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。有关详细信息，请参见[DeformableDetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — 避免在填充像素值上执行注意力的蒙版。蒙版值选择在`[0, 1]`范围内：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于真实像素为1（即`not masked`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于填充的像素为0（即`masked`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力蒙版？](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — Not used by default. Can be used to mask object queries.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — 默认情况下不使用。可用于屏蔽对象查询。'
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括(`last_hidden_state`,
    *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*optional*)是编码器最后一层的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing the flattened feature
    map (output of the backbone + projection layer), you can choose to directly pass
    a flattened representation of an image.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递图像的扁平化表示，而不是传递扁平化特征图（骨干网络输出 + 投影层输出）。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Optionally, instead of initializing the queries with
    a tensor of zeros, you can choose to directly pass an embedded representation.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是使用零张量初始化查询。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig))
    and inputs.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`，则包含根据配置（[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)）和输入的各种元素。
- en: '`init_reference_points` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    4)`) — Initial reference points sent through the Transformer decoder.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_reference_points` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    4)`) — 通过Transformer解码器发送的初始参考点。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`) — 模型解码器最后一层的输出中的隐藏状态序列。'
- en: '`intermediate_hidden_states` (`torch.FloatTensor` of shape `(batch_size, config.decoder_layers,
    num_queries, hidden_size)`) — Stacked intermediate hidden states (output of each
    layer of the decoder).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_hidden_states` (`torch.FloatTensor`，形状为`(batch_size, config.decoder_layers,
    num_queries, hidden_size)`) — 堆叠的中间隐藏状态（解码器每层的输出）。'
- en: '`intermediate_reference_points` (`torch.FloatTensor` of shape `(batch_size,
    config.decoder_layers, num_queries, 4)`) — Stacked intermediate reference points
    (reference points of each layer of the decoder).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_reference_points` (`torch.FloatTensor`，形状为`(batch_size, config.decoder_layers,
    num_queries, 4)`) — 堆叠的中间参考点（解码器每层的参考点）。'
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, num_queries, hidden_size)`. Hidden-states
    of the decoder at the output of each layer plus the initial embedding outputs.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 每个层的形状为`(batch_size, num_queries, hidden_size)`的`torch.FloatTensor`元组。解码器在每个层的输出加上初始嵌入输出的隐藏状态。'
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    num_queries, num_queries)`. Attentions weights of the decoder, after the attention
    softmax, used to compute the weighted average in the self-attention heads.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 每个层的形状为`(batch_size, num_heads, num_queries, num_queries)`的`torch.FloatTensor`元组。解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_queries, num_heads, 4, 4)`. Attentions
    weights of the decoder’s cross-attention layer, after the attention softmax, used
    to compute the weighted average in the cross-attention heads.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 每个层的形状为`(batch_size, num_queries, num_heads, 4, 4)`的`torch.FloatTensor`元组。解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 每个层的形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。编码器在每个层的输出加上初始嵌入输出的隐藏状态。'
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_queries,
    num_heads, 4, 4)`. Attentions weights of the encoder, after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 每个层的形状为`(batch_size, num_queries, num_heads, 4, 4)`的`torch.FloatTensor`元组。编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`enc_outputs_class` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.num_labels)`, *optional*, returned when `config.with_box_refine=True` and
    `config.two_stage=True`) — Predicted bounding boxes scores where the top `config.two_stage_num_proposals`
    scoring bounding boxes are picked as region proposals in the first stage. Output
    of bounding box binary classification (i.e. foreground and background).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enc_outputs_class` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    config.num_labels)`，*optional*，当`config.with_box_refine=True`和`config.two_stage=True`时返回)
    — 预测的边界框分数，第一阶段选择前`config.two_stage_num_proposals`个得分最高的边界框作为区域提议。边界框二元分类的输出（即前景和背景）。'
- en: '`enc_outputs_coord_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    4)`, *optional*, returned when `config.with_box_refine=True` and `config.two_stage=True`)
    — Logits of predicted bounding boxes coordinates in the first stage.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enc_outputs_coord_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    4)`，*optional*，当`config.with_box_refine=True`和`config.two_stage=True`时返回) — 第一阶段预测的边界框坐标的logits。'
- en: The [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    forward method, overrides the `__call__` special method.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)的forward方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE10]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: DeformableDetrForObjectDetection
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeformableDetrForObjectDetection
- en: '### `class transformers.DeformableDetrForObjectDetection`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DeformableDetrForObjectDetection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1802)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1802)'
- en: '[PRE11]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Deformable DETR Model (consisting of a backbone and encoder-decoder Transformer)
    with object detection heads on top, for tasks such as COCO detection.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Deformable DETR模型（由骨干和编码器-解码器Transformer组成），顶部带有目标检测头，用于诸如COCO检测的任务。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档，了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)的子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1863)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1863)'
- en: '[PRE12]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。默认情况下将忽略填充。'
- en: Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DeformableDetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[DeformableDetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor`，形状为`(batch_size, height, width)`，*可选*) — 用于避免在填充像素值上执行注意力的掩码。选择的掩码值在`[0,
    1]`中。'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示真实像素（即`未屏蔽`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示填充像素（即`masked`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — Not used by default. Can be used to mask object queries.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.FloatTensor`，形状为`(batch_size, num_queries)`，*可选*)
    — 默认情况下不使用。可用于屏蔽对象查询。'
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`，*可选*) — 元组包含(`last_hidden_state`，*可选*:
    `hidden_states`，*可选*: `attentions`)，`last_hidden_state`的形状为`(batch_size, sequence_length,
    hidden_size)`，*可选*)是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing the flattened feature
    map (output of the backbone + projection layer), you can choose to directly pass
    a flattened representation of an image.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*)
    — 可选地，可以直接传递扁平化的特征图（骨干+投影层的输出），而不是传递图像的扁平化表示。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Optionally, instead of initializing the queries with
    a tensor of zeros, you can choose to directly pass an embedded representation.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, num_queries,
    hidden_size)`，*可选*) — 可选地，可以直接传递嵌入表示，而不是使用零张量初始化查询。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`List[Dict]` of len `(batch_size,)`, *optional*) — Labels for computing
    the bipartite matching loss. List of dicts, each dictionary containing at least
    the following 2 keys: ‘class_labels’ and ‘boxes’ (the class labels and bounding
    boxes of an image in the batch respectively). The class labels themselves should
    be a `torch.LongTensor` of len `(number of bounding boxes in the image,)` and
    the boxes a `torch.FloatTensor` of shape `(number of bounding boxes in the image,
    4)`.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`List[Dict]` of len `(batch_size,)`, *optional*) — 用于计算二部匹配损失的标签。字典列表，每个字典至少包含以下2个键：''class_labels''和''boxes''（分别是批处理中图像的类标签和边界框）。类标签本身应该是长度为`(图像中边界框的数量,)`的`torch.LongTensor`，而边界框应该是形状为`(图像中边界框的数量,
    4)`的`torch.FloatTensor`。'
- en: Returns
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig))
    and inputs.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)）和输入而异的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    are provided)) — Total loss as a linear combination of a negative log-likehood
    (cross-entropy) for class prediction and a bounding box loss. The latter is defined
    as a linear combination of the L1 loss and the generalized scale-invariant IoU
    loss.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    作为负对数似然（交叉熵）和边界框损失的线性组合的总损失。后者被定义为L1损失和广义比例不变IoU损失的线性组合。'
- en: '`loss_dict` (`Dict`, *optional*) — A dictionary containing the individual losses.
    Useful for logging.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_dict` (`Dict`, *optional*) — 包含各个损失的字典。用于记录日志。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes
    + 1)`) — Classification logits (including no-object) for all queries.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes
    + 1)`) — 所有查询的分类logits（包括无对象）。'
- en: '`pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`)
    — Normalized boxes coordinates for all queries, represented as (center_x, center_y,
    width, height). These values are normalized in [0, 1], relative to the size of
    each individual image in the batch (disregarding possible padding). You can use
    `~DeformableDetrProcessor.post_process_object_detection` to retrieve the unnormalized
    bounding boxes.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`)
    — 所有查询的规范化框坐标，表示为（中心_x，中心_y，宽度，高度）。这些值在[0, 1]范围内进行了规范化，相对于批处理中每个单独图像的大小（忽略可能的填充）。您可以使用`~DeformableDetrProcessor.post_process_object_detection`来检索未规范化的边界框。'
- en: '`auxiliary_outputs` (`list[Dict]`, *optional*) — Optional, only returned when
    auxilary losses are activated (i.e. `config.auxiliary_loss` is set to `True`)
    and labels are provided. It is a list of dictionaries containing the two above
    keys (`logits` and `pred_boxes`) for each decoder layer.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_outputs` (`list[Dict]`, *optional*) — 可选，仅在激活辅助损失（即`config.auxiliary_loss`设置为`True`）并提供标签时返回。这是一个包含每个解码器层的上述两个键（`logits`和`pred_boxes`）的字典列表。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the decoder of the model.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — 模型解码器最后一层的隐藏状态序列。'
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, num_queries, hidden_size)`. Hidden-states
    of the decoder at the output of each layer plus the initial embedding outputs.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 一个元组，包含形状为`(batch_size, num_queries, hidden_size)`的`torch.FloatTensor`（一个用于嵌入输出，一个用于每层输出）。解码器在每层输出的隐藏状态加上初始嵌入输出。'
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    num_queries, num_queries)`. Attentions weights of the decoder, after the attention
    softmax, used to compute the weighted average in the self-attention heads.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 一个元组，包含形状为`(batch_size, num_heads, num_queries, num_queries)`的`torch.FloatTensor`（每层一个）。解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_queries, num_heads, 4, 4)`. Attentions
    weights of the decoder’s cross-attention layer, after the attention softmax, used
    to compute the weighted average in the cross-attention heads.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 一个元组，包含形状为`(batch_size, num_queries, num_heads, 4, 4)`的`torch.FloatTensor`（每层一个）。解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, sequence_length,
    num_heads, 4, 4)`. Attentions weights of the encoder, after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, sequence_length,
    num_heads, 4, 4)`. Attentions weights of the encoder, after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
- en: '`intermediate_hidden_states` (`torch.FloatTensor` of shape `(batch_size, config.de`'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_hidden_states` (`torch.FloatTensor` of shape `(batch_size, config.de`'
