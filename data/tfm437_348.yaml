- en: IDEFICS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IDEFICS
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/idefics](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/idefics)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/idefics](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/idefics)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The IDEFICS model was proposed in [OBELICS: An Open Web-Scale Filtered Dataset
    of Interleaved Image-Text Documents](https://huggingface.co/papers/2306.16527)
    by Hugo Laurençon, Lucile Saulnier, Léo Tronchon, Stas Bekman, Amanpreet Singh,
    Anton Lozhkov, Thomas Wang, Siddharth Karamcheti, Alexander M. Rush, Douwe Kiela,
    Matthieu Cord, Victor Sanh'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: IDEFICS模型是由Hugo Laurençon、Lucile Saulnier、Léo Tronchon、Stas Bekman、Amanpreet
    Singh、Anton Lozhkov、Thomas Wang、Siddharth Karamcheti、Alexander M. Rush、Douwe Kiela、Matthieu
    Cord、Victor Sanh提出的。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Large multimodal models trained on natural documents, which interleave images
    and text, outperform models trained on image-text pairs on various multimodal
    benchmarks that require reasoning over one or multiple images to generate a text.
    However, the datasets used to train these models have not been released, and the
    collection process has not been fully specified. We introduce the OBELICS dataset,
    an open web-scale filtered dataset of interleaved image-text documents comprising
    141 million web pages extracted from Common Crawl, 353 million associated images,
    and 115 billion text tokens. We describe the dataset creation process, present
    comprehensive filtering rules, and provide an analysis of the dataset’s content.
    To show the viability of OBELISC, we train an 80 billion parameters vision and
    language model on the dataset and obtain competitive performance on various multimodal
    benchmarks. We release the code to reproduce the dataset along with the dataset
    itself.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*在自然文档上训练的大型多模型，交替显示图像和文本，比在各种多模基准上训练的图像-文本对模型表现更好，这些基准需要对一个或多个图像进行推理以生成文本。然而，用于训练这些模型的数据集尚未发布，并且收集过程尚未完全指定。我们介绍了OBELICS数据集，这是一个包含来自Common
    Crawl的141亿个网页、3.53亿个相关图像和1150亿个文本标记的开放式网络规模过滤数据集。我们描述了数据集创建过程，提出了全面的过滤规则，并对数据集内容进行了分析。为了展示OBELISC的可行性，我们在数据集上训练了一个拥有800亿参数的视觉和语言模型，并在各种多模基准上获得了竞争性能。我们发布了用于重现数据集的代码以及数据集本身。*'
- en: 'This model was contributed by [HuggingFaceM4](https://huggingface.co/HuggingFaceM4).
    The original code can be found [here](INSERT%20LINK%20TO%20GITHUB%20REPO%20HERE).
    (TODO: don’t have a public link yet).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[HuggingFaceM4](https://huggingface.co/HuggingFaceM4)贡献。原始代码可以在[这里](INSERT%20LINK%20TO%20GITHUB%20REPO%20HERE)找到。（TODO：目前没有公开链接）。
- en: IDEFICS modeling code in Transformers is for finetuning and inferencing the
    pre-trained IDEFICS models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers中的IDEFICS建模代码用于微调和推理预训练的IDEFICS模型。
- en: To train a new IDEFICS model from scratch use the m4 codebase (a link will be
    provided once it’s made public)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要从头开始训练一个新的IDEFICS模型，请使用m4代码库（一旦公开，将提供链接）
- en: IdeficsConfig
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IdeficsConfig
- en: '### `class transformers.IdeficsConfig`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.IdeficsConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/configuration_idefics.py#L161)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/configuration_idefics.py#L161)'
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`additional_vocab_size` (`int`, *optional`, defaults to 0) — Additional vocabulary
    size of the model, typically for the special ”” token. Additional vocab tokens
    are always trainable whereas regular vocab tokens can be frozen or not.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`additional_vocab_size` (`int`, *optional`, defaults to 0) — 模型的额外词汇量，通常用于特殊的“”标记。额外的词汇标记始终是可训练的，而常规词汇标记可以冻结或不冻结。'
- en: '`vocab_size` (`int`, *optional*, defaults to 32000) — Vocabulary size of the
    Idefics model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [~IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 32000) — Idefics模型的词汇量。定义了在调用[~IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)时可以表示的不同标记的数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 4096) — Dimension of the hidden
    representations.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 4096) — 隐藏表示的维度。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 11008) — Dimension of the
    MLP representations.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, defaults to 11008) — MLP表示的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 32) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 32) — Transformer编码器中隐藏层的数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 32) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 32) — Transformer编码器中每个注意力层的注意力头数。'
- en: '`dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.0) — 嵌入层、编码器和池化器中所有全连接层的dropout概率。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"silu"`) — The
    non-linear activation function (function or string) in the decoder.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"silu"`) — 解码器中的非线性激活函数（函数或字符串）。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的truncated_normal_initializer的标准差。'
- en: '`alpha_initializer` (`str`, *optional*, defaults to `"zeros"`) — Initialization
    type for the alphas.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha_initializer` (`str`, *optional*, defaults to `"zeros"`) — alphas的初始化类型。'
- en: '`alphas_initializer_range` (`float`, *optional*, defaults to 0.0) — The standard
    deviation of the truncated_normal_initializer for initializing the alphas in the
    Gated Cross Attention.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alphas_initializer_range` (`float`, *optional*, defaults to 0.0) — 初始化Gated
    Cross Attention中alphas的truncated_normal_initializer的标准差。'
- en: '`alpha_type` (`str`, *optional*, defaults to `"float"`) — Whether the gating
    alphas should be vectors or single floats.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha_type` (`str`, *optional*, defaults to `"float"`) — 门控alphas应该是向量还是单个浮点数。'
- en: '`rms_norm_eps` (`float`, *optional*, defaults to 1e-6) — The epsilon used by
    the rms normalization layers.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rms_norm_eps` (`float`, *optional*, defaults to 1e-6) — rms归一化层使用的epsilon。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models). Only relevant
    if `config.is_decoder=True`.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。仅在`config.is_decoder=True`时相关。'
- en: '`pad_token_id` (`int`, *optional*, defaults to 0) — Padding token id.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_id` (`int`, *optional*, defaults to 0) — 填充标记id。'
- en: '`bos_token_id` (`int`, *optional*, defaults to 1) — Beginning of stream token
    id.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token_id` (`int`, *optional*, defaults to 1) — 流的开始标记id。'
- en: '`eos_token_id` (`int`, *optional*, defaults to 2) — End of stream token id.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id` (`int`, *optional*, defaults to 2) — 流的结束标记id。'
- en: '`tie_word_embeddings(bool,` *optional*, defaults to `False`) — Whether to tie
    weight embeddings'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tie_word_embeddings(bool,` *optional*, defaults to `False`) — 是否绑定权重嵌入'
- en: '`cross_layer_interval` (`int`, *optional*, default to 1) — Interval for cross
    attention (from text to image) layers.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_layer_interval` (`int`, *optional*, default to 1) — 交叉注意力（从文本到图像）层的间隔。'
- en: '`qk_layer_norms` (`bool`, *optional*, defaults to `False`) — Whether to add
    layer norm after q and k'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qk_layer_norms` (`bool`, *optional*, defaults to `False`) — 是否在q和k之后添加层归一化'
- en: '`freeze_text_layers` (`bool`, *optional*, defaults to `True`) — Whether to
    freeze text layers'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`freeze_text_layers` (`bool`, *optional*, defaults to `True`) — 是否冻结文本层'
- en: '`freeze_text_module_exceptions` (`bool`, *optional*, defaults to `[]`) — Exceptions
    to freezing text layers when `freeze_text_layers` is `True`'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`freeze_text_module_exceptions` (`bool`, *optional*, defaults to `[]`) — 当`freeze_text_layers`为`True`时，冻结文本层的异常'
- en: '`freeze_lm_head` (`bool`, *optional*, defaults to `False`) — Whether to freeze
    lm head'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`freeze_lm_head` (`bool`, *optional*, defaults to `False`) — 是否冻结lm头'
- en: '`freeze_vision_layers` (`bool`, *optional*, defaults to `True`) — Whether to
    freeze vision layers'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`freeze_vision_layers` (`bool`, *optional*, defaults to `True`) — 是否冻结视觉层'
- en: '`freeze_vision_module_exceptions` (`bool`, *optional*, defaults to `[]`) —
    Exceptions to freezing vision layers when `freeze_vision_layers` is `True`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`freeze_vision_module_exceptions` (`bool`, *optional*, defaults to `[]`) —
    当`freeze_vision_layers`为`True`时，冻结视觉层的异常'
- en: '`use_resampler` (`bool`, *optional*, defaults to `False`) — Whether to use
    the Resampler'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_resampler` (`bool`, *optional*, defaults to `False`) — 是否使用重采样器'
- en: '`vision_config` (`IdeficsVisionConfig`, *optional*) — Custom vision config
    or dict'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_config` (`IdeficsVisionConfig`, *optional*) — 自定义视觉配置或字典'
- en: '`perceiver_config` (`IdeficsPerceiverConfig`, *optional*) — Custom perceiver
    config or dict'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver_config` (`IdeficsPerceiverConfig`, *optional*) — 自定义感知器配置或字典'
- en: This is the configuration class to store the configuration of a [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel).
    It is used to instantiate an Idefics model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Idefics-9B.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)配置的配置类。根据指定的参数实例化一个Idefics模型，定义模型架构。使用默认值实例化配置将产生类似于Idefics-9B的配置。
- en: e.g. [HuggingFaceM4/idefics-9b](https://huggingface.co/HuggingFaceM4/idefics-9b)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如[HuggingFaceM4/idefics-9b](https://huggingface.co/HuggingFaceM4/idefics-9b)
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: IdeficsModel
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IdeficsModel
- en: '### `class transformers.IdeficsModel`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.IdeficsModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1064)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1064)'
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights. config — IdeficsConfig'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。config
    — IdeficsConfig'
- en: The bare LLaMA Model outputting raw hidden-states without any specific head
    on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的LLaMA模型输出原始隐藏状态，没有特定的头部。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有信息。
- en: Transformer decoder consisting of `config.num_hidden_layers` layers. Each layer
    is a `IdeficsDecoderLayer`
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由`config.num_hidden_layers`层组成的Transformer解码器。每一层都是一个`IdeficsDecoderLayer`
- en: '#### `forward`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1145)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1145)'
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`）— 词汇表中输入序列标记的索引。默认情况下，如果提供填充，则将被忽略。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0,
    1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记，为1。
- en: 0 for tokens that are `masked`.
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记，为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，可以选择仅输入最后的`decoder_input_ids`（请参阅`past_key_values`）。
- en: If you want to change padding behavior, you should read `modeling_opt._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，您应该阅读`modeling_opt._prepare_decoder_attention_mask`并根据您的需求进行修改。有关默认策略的更多信息，请参阅[论文中的图表1](https://arxiv.org/abs/1910.13461)。
- en: 1 indicates the head is `not masked`,
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.n_positions - 1]`. [What are position
    IDs?](../glossary#position-ids)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*）—
    每个输入序列标记在位置嵌入中的位置索引。在范围`[0, config.n_positions - 1]`中选择。[什么是位置ID？](../glossary#position-ids)'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或当`config.use_cache=True`时返回）—
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可以用于加速顺序解码（请参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入形状为`(batch_size, 1)`的最后一个`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的）而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*）—
    可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果您想要更多控制权来将`input_ids`索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）— 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（请参阅`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    forward method, overrides the `__call__` special method.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: IdeficsForVisionText2Text
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IdeficsForVisionText2Text
- en: '### `class transformers.IdeficsForVisionText2Text`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.IdeficsForVisionText2Text`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1403)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1403)'
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `forward`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1461)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/modeling_idefics.py#L1461)'
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`）— 词汇表中输入序列标记的索引。默认情况下，如果提供填充，则将忽略填充。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*）— 用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0,
    1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被“掩码”的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被“掩码”的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，可以选择仅输入最后的`decoder_input_ids`（参见`past_key_values`）。
- en: If you want to change padding behavior, you should read `modeling_opt._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`modeling_opt._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: 1 indicates the head is `not masked`,
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被“掩码”，
- en: 0 indicates the head is `masked`.
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“掩码”。
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.n_positions - 1]`. [What are position
    IDs?](../glossary#position-ids)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*）—
    每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.n_positions - 1]`。[什么是位置ID？](../glossary#position-ids)'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）—
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（即没有将其过去键值状态提供给此模型的那些）的形状为`(batch_size,
    1)`的张量，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制权来将`input_ids`索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为`True`，则返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: 'Args — labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*): Labels for computing the masked language modeling loss. Indices should
    either be in `[0, ..., config.vocab_size]` or -100 (see `input_ids` docstring).
    Tokens with indices set to `-100` are ignored (masked), the loss is only computed
    for the tokens with labels in `[0, ..., config.vocab_size]`.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '参数 — labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
    用于计算掩码语言建模损失的标签。索引应该在`[0, ..., config.vocab_size]`范围内，或者为-100（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有`[0,
    ..., config.vocab_size]`标签的标记。'
- en: Returns
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`transformers.models.idefics.modeling_idefics.IdeficsCausalLMOutputWithPast`
    or `tuple(torch.FloatTensor)`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.idefics.modeling_idefics.IdeficsCausalLMOutputWithPast`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.idefics.modeling_idefics.IdeficsCausalLMOutputWithPast`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig))
    and inputs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.idefics.modeling_idefics.IdeficsCausalLMOutputWithPast`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`），包含根据配置（[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss (for next-token prediction).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    语言建模损失（用于下一个标记预测）。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 一个长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size,
    num_heads, sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块中的键和值），可用于加速顺序解码。
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 一个元组，包含形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`（如果模型有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 一个元组，包含形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`image_hidden_states` (`tuple(torch.FloatTensor)`, *optional*) — Tuple of `torch.FloatTensor`
    (one for the output of the image embeddings, `(batch_size, num_images, sequence_length,
    hidden_size)`.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_hidden_states` (`tuple(torch.FloatTensor)`, *optional*) — 一个元组，包含形状为`(batch_size,
    num_images, sequence_length, hidden_size)`的`torch.FloatTensor`（用于图像嵌入的输出）。'
- en: image_hidden_states of the model produced by the vision encoder, and optionally
    by the perceiver
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由视觉编码器生成的模型的图像隐藏状态，以及可选的感知器
- en: The [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    forward method, overrides the `__call__` special method.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE6]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: IdeficsImageProcessor
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IdeficsImageProcessor
- en: '### `class transformers.IdeficsImageProcessor`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.IdeficsImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/image_processing_idefics.py#L51)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/image_processing_idefics.py#L51)'
- en: '[PRE7]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_size` (`int`, *optional*, defaults to 224) — Resize to image size'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *可选*, 默认为 224) — 调整到图像大小'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IDEFICS_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method. Can be overridden by the `image_mean` parameter
    in the `preprocess` method.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `IDEFICS_STANDARD_MEAN`) —
    用于归一化图像的均值。这是一个浮点数或与图像中通道数相同长度的浮点数列表。可以通过`preprocess`方法中的`image_mean`参数覆盖。可以通过`preprocess`方法中的`image_mean`参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IDEFICS_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method. Can be overridden by
    the `image_std` parameter in the `preprocess` method.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *可选*, 默认为 `IDEFICS_STANDARD_STD`) — 用于归一化图像的标准差。这是一个浮点数或与图像中通道数相同长度的浮点数列表。可以通过`preprocess`方法中的`image_std`参数覆盖。可以通过`preprocess`方法中的`image_std`参数覆盖。'
- en: '`image_num_channels` (`int`, *optional*, defaults to 3) — Number of image channels.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_num_channels` (`int`, *可选*, 默认为 3) — 图像通道数。'
- en: Constructs a Idefics image processor.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Idefics图像处理器。
- en: '#### `preprocess`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/image_processing_idefics.py#L87)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/image_processing_idefics.py#L87)'
- en: '[PRE8]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — A list of images to preprocess.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像列表。'
- en: '`image_size` (`int`, *optional*, defaults to `self.image_size`) — Resize to
    image size'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *可选*, 默认为 `self.image_size`) — 调整到图像大小'
- en: '`image_num_channels` (`int`, *optional*, defaults to `self.image_num_channels`)
    — Number of image channels.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_num_channels` (`int`, *可选*, 默认为 `self.image_num_channels`) — 图像通道数。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IDEFICS_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method. Can be overridden by the `image_mean` parameter
    in the `preprocess` method.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `IDEFICS_STANDARD_MEAN`) —
    用于归一化图像的均值。这是一个浮点数或与图像中通道数相同长度的浮点数列表。可以通过`preprocess`方法中的`image_mean`参数覆盖。可以通过`preprocess`方法中的`image_mean`参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IDEFICS_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method. Can be overridden by
    the `image_std` parameter in the `preprocess` method.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *可选*, 默认为 `IDEFICS_STANDARD_STD`) — 用于归一化图像的标准差。这是一个浮点数或与图像中通道数相同长度的浮点数列表。可以通过`preprocess`方法中的`image_std`参数覆盖。可以通过`preprocess`方法中的`image_std`参数覆盖。'
- en: '`transform` (`Callable`, *optional*, defaults to `None`) — A custom transform
    function that accepts a single image can be passed for training. For example,
    `torchvision.Compose` can be used to compose multiple transforms. If `None` -
    an inference mode is assumed - and then a preset of inference-specific transforms
    will be applied to the images'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform` (`Callable`, *可选*, 默认为 `None`) — 可以传递一个接受单个图像的自定义转换函数进行训练。例如，可以使用`torchvision.Compose`来组合多个转换。如果为`None`
    - 则假定为推断模式 - 然后将应用一组预设的推断特定转换到图像。'
- en: Preprocess a batch of images.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一批图像。
- en: IdeficsProcessor
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IdeficsProcessor
- en: '### `class transformers.IdeficsProcessor`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.IdeficsProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/processing_idefics.py#L108)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/processing_idefics.py#L108)'
- en: '[PRE9]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` (`IdeficsImageProcessor`) — An instance of [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor).
    The image processor is a required input.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` (`IdeficsImageProcessor`) — [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor)的一个实例。图像处理器是一个必需的输入。'
- en: '`tokenizer` (`LlamaTokenizerFast`) — An instance of [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast).
    The tokenizer is a required input.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`LlamaTokenizerFast`) — [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)的一个实例。分词器是一个必需的输入。'
- en: '`image_size` (`int`, *optional*, defaults to 224) — Image size (assuming a
    square image)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *可选*, 默认为 224) — 图像大小（假设为正方形图像）'
- en: Constructs a IDEFICS processor which wraps a LLama tokenizer and IDEFICS image
    processor into a single processor.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个IDEFICS处理器，将LLama分词器和IDEFICS图像处理器封装成一个处理器。
- en: '[IdeficsProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor)
    offers all the functionalities of [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor)
    and [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast).
    See the docstring of [**call**()](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor.__call__)
    and `decode()` for more information.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[IdeficsProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor)
    提供了 [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor)
    和 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    的所有功能。查看 [**call**()](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor.__call__)
    和 `decode()` 的文档字符串以获取更多信息。'
- en: '#### `__call__`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/processing_idefics.py#L149)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/idefics/processing_idefics.py#L149)'
- en: '[PRE10]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompts` (`Union[List[TextInput], [List[List[TextInput]]]]`) — either a single
    prompt or a batched list of prompts - see the detailed description immediately
    after the end of the arguments doc section.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompts`（`Union[List[TextInput], [List[List[TextInput]]]]`）— 单个提示或批处理提示的列表
    - 请查看参数文档部分结束后的详细描述。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Select a strategy to pad the returned sequences
    (according to the model’s padding side and padding index) among:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`，`str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为
    `False`）— 选择一种策略来填充返回的序列（根据模型的填充方向和填充索引）：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`：填充到批次中最长的序列（如果只提供了单个序列，则不进行填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到指定的最大长度，或者如果未提供该参数，则填充到模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不填充（即，可以输出具有不同长度序列的批次）。'
- en: '`max_length` (`int`, *optional*) — Maximum length of the returned list and
    optionally padding length (see above).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*）— 返回列表的最大长度和可选填充长度（见上文）。'
- en: '`truncation` (`bool`, *optional*) — Activates truncation to cut input sequences
    longer than `max_length` to `max_length`.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`，*可选*）— 激活截断，将输入序列截断为比 `max_length` 更长的序列至 `max_length`。'
- en: '`transform` (`Callable`, *optional*) — A custom transform function that accepts
    a single image can be passed for training. For example, `torchvision.Compose`
    can be used to compose multiple functions. If `None` a preset inference-specific
    set of transforms will be applied to the images'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform`（`Callable`，*可选*）— 可以传递一个接受单个图像的自定义转换函数进行训练。例如，可以使用 `torchvision.Compose`
    来组合多个函数。如果为 `None`，则将应用预设的推理特定转换集合到图像上。'
- en: '`add_eos_token` (`bool`, *optional*, defaults to `False`) — Adds `eos_token`
    at the end of the final prompt if True`'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_eos_token`（`bool`，*可选*，默认为 `False`）— 如果为 True，则在最终提示的末尾添加 `eos_token`'
- en: '`add_end_of_utterance_token` (`bool`, *optional*) — Whether to automatically
    add `<end_of_utterance>` after each prompt’s text input (unless followed by an
    image). If `None` the tokenizer will be checked instead and if this token is found
    in `additional_special_tokens` then the value will be `True`.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_end_of_utterance_token`（`bool`，*可选*）— 是否在每个提示的文本输入后自动添加 `<end_of_utterance>`（除非后面跟着一个图像）。如果为
    `None`，则将检查分词器，如果在 `additional_special_tokens` 中找到该标记，则值将为 `True`。'
- en: '`debug` (`bool`, *optional*, defaults to `False`) — `True` value will help
    debug prompt generation by dumping useful information'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`debug`（`bool`，*可选*，默认为 `False`）— `True` 值将通过转储有用信息来帮助调试提示生成'
- en: '`return_tensors` (`str` or `TensorType`, *optional*, defaults to `TensorType.PYTORCH`)
    — The type of tensors to return. Can be one of:'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str` 或 `TensorType`，*可选*，默认为 `TensorType.PYTORCH`）— 要返回的张量类型。可以是以下之一：'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` 或 `''pt''`：返回类型为 `torch.Tensor` 的批处理。'
- en: Returns
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: a dict with entries
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含条目的字典
- en: '`input_ids`, `attention_mask`, `pixel_values`, `image_attention_mask` which
    can be directly passed to `model.generate`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`input_ids`、`attention_mask`、`pixel_values`、`image_attention_mask` 可以直接传递给
    `model.generate`'
- en: This method takes batched or non-batched prompts made of text and images and
    converts them into prompts that the model was trained on and prepares the image
    pixel values for the model to process.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法接受由文本和图像组成的批处理或非批处理提示，并将它们转换为模型训练的提示，并准备图像像素值供模型处理。
- en: 'Detailed explanation:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 详细说明：
- en: Each entry in `prompts` is either a text to be passed as is or an image that
    will be processed.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`prompts` 中的每个条目都是要原样传递的文本或将被处理的图像。'
- en: An image can be either an image object (`PIL.Image`) or a url from which the
    image can be retrieved.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图像可以是图像对象（`PIL.Image`）或可以检索图像的url。
- en: When the processor encounters an image it’ll inject `<fake_token_around_image><image><fake_token_around_image>`
    entry into the prompt.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理器遇到图像时，它将在提示中注入 `<fake_token_around_image><image><fake_token_around_image>`
    条目。
- en: 'Example:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 例子：
- en: '[PRE11]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In this example the `prompts` will be converted into:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`prompts` 将被转换为：
- en: '[PRE12]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: and the two images will be massaged using [IdeficsImageProcessor.**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    method and placed inside the `pixel_values` dict entry of the return value.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 两个图像将使用 [IdeficsImageProcessor.**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    方法进行处理，并放置在返回值的 `pixel_values` 字典条目中。
- en: This example also examplifies that images can be passed as objects or as text
    urls. It can be seen that the first image is passed as object and the second one
    as a url.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子还说明了图像可以作为对象或文本url传递。可以看到第一个图像作为对象传递，第二个图像作为url传递。
- en: 'To do training do:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 进行训练时：
- en: '[PRE13]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In order to help debug prompt generation enable `debug=True` which will show
    you what’s happening.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助调试提示生成，启用`debug=True`，这将向您展示发生了什么。
