- en: Distilled Stable Diffusion inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精炼稳定扩散推断
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd](https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd](https://huggingface.co/docs/diffusers/using-diffusers/distilled_sd)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion inference can be a computationally intensive process because
    it must iteratively denoise the latents to generate an image. To reduce the computational
    burden, you can use a *distilled* version of the Stable Diffusion model from [Nota
    AI](https://huggingface.co/nota-ai). The distilled version of their Stable Diffusion
    model eliminates some of the residual and attention blocks from the UNet, reducing
    the model size by 51% and improving latency on CPU/GPU by 43%.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散推断可能是一个计算密集型的过程，因为它必须迭代去噪潜变量以生成图像。为了减少计算负担，您可以使用[Nota AI](https://huggingface.co/nota-ai)的稳定扩散模型的*精炼*版本。他们稳定扩散模型的精炼版本消除了UNet中的一些残差和注意力块，将模型大小减少了51%，在CPU/GPU上的延迟提高了43%。
- en: Read this [blog post](https://huggingface.co/blog/sd_distillation) to learn
    more about how knowledge distillation training works to produce a faster, smaller,
    and cheaper generative model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读这篇[博文](https://huggingface.co/blog/sd_distillation)以了解更多关于知识蒸馏训练如何工作以产生更快、更小、更便宜的生成模型。
- en: 'Let’s load the distilled Stable Diffusion model and compare it against the
    original Stable Diffusion model:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载精炼稳定扩散模型并将其与原始稳定扩散模型进行比较：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Given a prompt, get the inference time for the original model:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个提示，获取原始模型的推断时间：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Time the distilled model inference:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 计时精炼模型推断：
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/f82acf1004076b7b492a9df026e46793.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f82acf1004076b7b492a9df026e46793.png)'
- en: original Stable Diffusion (45781.5 ms)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 原始稳定扩散（45781.5毫秒）
- en: '![](../Images/fdcbeffef0420159642acccb6336a302.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdcbeffef0420159642acccb6336a302.png)'
- en: distilled Stable Diffusion (29884.2 ms)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 精炼稳定扩散（29884.2毫秒）
- en: Tiny AutoEncoder
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微型自动编码器
- en: 'To speed inference up even more, use a tiny distilled version of the [Stable
    Diffusion VAE](https://huggingface.co/sayakpaul/taesdxl-diffusers) to denoise
    the latents into images. Replace the VAE in the distilled Stable Diffusion model
    with the tiny VAE:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步加快推断速度，使用[Stable Diffusion VAE](https://huggingface.co/sayakpaul/taesdxl-diffusers)的微型精炼版本将潜变量去噪成图像。将微型VAE替换为精炼稳定扩散模型中的VAE：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Time the distilled model and distilled VAE inference:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 计时精炼模型和精炼VAE推断：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/3eae18d18492330797db5d70b23824f7.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eae18d18492330797db5d70b23824f7.png)'
- en: distilled Stable Diffusion + Tiny AutoEncoder (27165.7 ms)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 精炼稳定扩散 + 微型自动编码器（27165.7毫秒）
