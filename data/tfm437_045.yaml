- en: Text generation strategies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本生成策略
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/generation_strategies](https://huggingface.co/docs/transformers/v4.37.2/en/generation_strategies)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/transformers/v4.37.2/en/generation_strategies](https://huggingface.co/docs/transformers/v4.37.2/en/generation_strategies)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Text generation is essential to many NLP tasks, such as open-ended text generation,
    summarization, translation, and more. It also plays a role in a variety of mixed-modality
    applications that have text as an output like speech-to-text and vision-to-text.
    Some of the models that can generate text include GPT2, XLNet, OpenAI GPT, CTRL,
    TransformerXL, XLM, Bart, T5, GIT, Whisper.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成对于许多NLP任务至关重要，例如开放式文本生成、摘要、翻译等。它还在各种混合模态应用中发挥作用，这些应用的输出是文本，如语音转文本和视觉转文本。一些可以生成文本的模型包括GPT2、XLNet、OpenAI
    GPT、CTRL、TransformerXL、XLM、Bart、T5、GIT、Whisper。
- en: 'Check out a few examples that use [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    method to produce text outputs for different tasks:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 查看一些使用[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)方法为不同任务生成文本输出的示例：
- en: '[Text summarization](./tasks/summarization#inference)'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本摘要](./tasks/summarization#inference)'
- en: '[Image captioning](./model_doc/git#transformers.GitForCausalLM.forward.example)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像标题](./model_doc/git#transformers.GitForCausalLM.forward.example)'
- en: '[Audio transcription](./model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[音频转录](./model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example)'
- en: Note that the inputs to the generate method depend on the model’s modality.
    They are returned by the model’s preprocessor class, such as AutoTokenizer or
    AutoProcessor. If a model’s preprocessor creates more than one kind of input,
    pass all the inputs to generate(). You can learn more about the individual model’s
    preprocessor in the corresponding model’s documentation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，生成方法的输入取决于模型的模态。它们由模型的预处理器类返回，例如AutoTokenizer或AutoProcessor。如果模型的预处理器创建多种类型的输入，请将所有输入传递给generate()。您可以在相应模型的文档中了解更多关于各个模型的预处理器的信息。
- en: The process of selecting output tokens to generate text is known as decoding,
    and you can customize the decoding strategy that the `generate()` method will
    use. Modifying a decoding strategy does not change the values of any trainable
    parameters. However, it can have a noticeable impact on the quality of the generated
    output. It can help reduce repetition in the text and make it more coherent.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 选择生成文本的输出标记的过程称为解码，您可以自定义`generate()`方法将使用的解码策略。修改解码策略不会改变任何可训练参数的值。但是，它可能会显著影响生成输出的质量。它可以帮助减少文本中的重复，并使其更连贯。
- en: 'This guide describes:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南描述：
- en: default generation configuration
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认生成配置
- en: common decoding strategies and their main parameters
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的解码策略及其主要参数
- en: saving and sharing custom generation configurations with your fine-tuned model
    on 🤗 Hub
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在🤗 Hub上保存和共享自定义生成配置与您的微调模型
- en: Default text generation configuration
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 默认文本生成配置
- en: A decoding strategy for a model is defined in its generation configuration.
    When using pre-trained models for inference within a [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline),
    the models call the `PreTrainedModel.generate()` method that applies a default
    generation configuration under the hood. The default configuration is also used
    when no custom configuration has been saved with the model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的解码策略在其生成配置中定义。在管道内使用预训练模型进行推断时，模型调用`PreTrainedModel.generate()`方法，在幕后应用默认生成配置。当没有保存自定义配置与模型一起时，也会使用默认配置。
- en: 'When you load a model explicitly, you can inspect the generation configuration
    that comes with it through `model.generation_config`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当您显式加载模型时，您可以通过`model.generation_config`检查随之提供的生成配置：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Printing out the `model.generation_config` reveals only the values that are
    different from the default generation configuration, and does not list any of
    the default values.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出`model.generation_config`只显示与默认生成配置不同的值，并不列出任何默认值。
- en: The default generation configuration limits the size of the output combined
    with the input prompt to a maximum of 20 tokens to avoid running into resource
    limitations. The default decoding strategy is greedy search, which is the simplest
    decoding strategy that picks a token with the highest probability as the next
    token. For many tasks and small output sizes this works well. However, when used
    to generate longer outputs, greedy search can start producing highly repetitive
    results.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 默认生成配置限制输出与输入提示的组合大小最多为20个标记，以避免遇到资源限制。默认解码策略是贪婪搜索，这是一种最简单的解码策略，它选择具有最高概率的标记作为下一个标记。对于许多任务和小输出大小，这种方法效果很好。然而，当用于生成较长的输出时，贪婪搜索可能会开始产生高度重复的结果。
- en: Customize text generation
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义文本生成
- en: 'You can override any `generation_config` by passing the parameters and their
    values directly to the `generate` method:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过直接将参数及其值传递给`generate`方法来覆盖任何`generation_config`：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Even if the default decoding strategy mostly works for your task, you can still
    tweak a few things. Some of the commonly adjusted parameters include:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 即使默认解码策略对您的任务大部分有效，您仍然可以微调一些内容。一些常调整的参数包括：
- en: '`max_new_tokens`: the maximum number of tokens to generate. In other words,
    the size of the output sequence, not including the tokens in the prompt. As an
    alternative to using the output’s length as a stopping criteria, you can choose
    to stop generation whenever the full generation exceeds some amount of time. To
    learn more, check [StoppingCriteria](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.StoppingCriteria).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens`：要生成的标记的最大数量。换句话说，输出序列的大小，不包括提示中的标记。作为使用输出长度作为停止标准的替代方案，您可以选择在完整生成超过某个时间量时停止生成。要了解更多信息，请查看[StoppingCriteria](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.StoppingCriteria)。'
- en: '`num_beams`: by specifying a number of beams higher than 1, you are effectively
    switching from greedy search to beam search. This strategy evaluates several hypotheses
    at each time step and eventually chooses the hypothesis that has the overall highest
    probability for the entire sequence. This has the advantage of identifying high-probability
    sequences that start with a lower probability initial tokens and would’ve been
    ignored by the greedy search.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_beams`：通过指定高于1的波束数量，您实际上是从贪婪搜索切换到波束搜索。这种策略在每个时间步评估几个假设，最终选择具有整个序列的最高概率的假设。这有一个优点，可以识别以较低概率初始标记开头的高概率序列，并且会被贪婪搜索忽略。'
- en: '`do_sample`: if set to `True`, this parameter enables decoding strategies such
    as multinomial sampling, beam-search multinomial sampling, Top-K sampling and
    Top-p sampling. All these strategies select the next token from the probability
    distribution over the entire vocabulary with various strategy-specific adjustments.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_sample`：如果设置为`True`，此参数将启用解码策略，如多项式采样、波束搜索多项式采样、Top-K采样和Top-p采样。所有这些策略从整个词汇表的概率分布中选择下一个标记，具有各种特定策略的调整。'
- en: '`num_return_sequences`: the number of sequence candidates to return for each
    input. This option is only available for the decoding strategies that support
    multiple sequence candidates, e.g. variations of beam search and sampling. Decoding
    strategies like greedy search and contrastive search return a single output sequence.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_return_sequences`：要为每个输入返回的序列候选数。此选项仅适用于支持多个序列候选的解码策略，例如波束搜索和采样的变体。贪婪搜索和对比搜索等解码策略返回单个输出序列。'
- en: Save a custom decoding strategy with your model
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存带有您的模型的自定义解码策略
- en: 'If you would like to share your fine-tuned model with a specific generation
    configuration, you can:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要与特定生成配置共享您微调的模型，您可以：
- en: Create a [GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)
    class instance
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)类实例
- en: Specify the decoding strategy parameters
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定解码策略参数
- en: Save your generation configuration with [GenerationConfig.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.save_pretrained),
    making sure to leave its `config_file_name` argument empty
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[GenerationConfig.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.save_pretrained)保存您的生成配置，确保将其`config_file_name`参数留空
- en: Set `push_to_hub` to `True` to upload your config to the model’s repo
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`push_to_hub`设置为`True`，将您的配置上传到模型的存储库
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can also store several generation configurations in a single directory,
    making use of the `config_file_name` argument in [GenerationConfig.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.save_pretrained).
    You can later instantiate them with [GenerationConfig.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.from_pretrained).
    This is useful if you want to store several generation configurations for a single
    model (e.g. one for creative text generation with sampling, and one for summarization
    with beam search). You must have the right Hub permissions to add configuration
    files to a model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在单个目录中存储多个生成配置，利用[GenerationConfig.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.save_pretrained)中的`config_file_name`参数。您可以稍后使用[GenerationConfig.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig.from_pretrained)实例化它们。如果您想为单个模型存储多个生成配置（例如，一个用于采样的创意文本生成，一个用于波束搜索的摘要），则必须具有正确的Hub权限以向模型添加配置文件。
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Streaming
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流式传输
- en: 'The `generate()` supports streaming, through its `streamer` input. The `streamer`
    input is compatible with any instance from a class that has the following methods:
    `put()` and `end()`. Internally, `put()` is used to push new tokens and `end()`
    is used to flag the end of text generation.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`generate()`支持流式传输，通过其`streamer`输入。`streamer`输入与具有以下方法的类的任何实例兼容：`put()`和`end()`。在内部，`put()`用于推送新标记，`end()`用于标记文本生成的结束。'
- en: The API for the streamer classes is still under development and may change in
    the future.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 流媒体类的API仍在开发中，可能会在未来发生变化。
- en: 'In practice, you can craft your own streaming class for all sorts of purposes!
    We also have basic streaming classes ready for you to use. For example, you can
    use the [TextStreamer](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.TextStreamer)
    class to stream the output of `generate()` into your screen, one word at a time:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，您可以为各种目的制作自己的流式传输类！我们还为您准备了基本的流式传输类供您使用。例如，您可以使用[TextStreamer](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.TextStreamer)类将`generate()`的输出流式传输到屏幕上，每次一个词：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Decoding strategies
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码策略
- en: Certain combinations of the `generate()` parameters, and ultimately `generation_config`,
    can be used to enable specific decoding strategies. If you are new to this concept,
    we recommend reading [this blog post that illustrates how common decoding strategies
    work](https://huggingface.co/blog/how-to-generate).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 某些`generate()`参数的组合，最终`generation_config`可以用于启用特定的解码策略。如果您对这个概念还不熟悉，我们建议阅读[这篇博文，展示了常见的解码策略如何工作](https://huggingface.co/blog/how-to-generate)。
- en: Here, we’ll show some of the parameters that control the decoding strategies
    and illustrate how you can use them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将展示控制解码策略的一些参数，并说明如何使用它们。
- en: Greedy Search
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 贪婪搜索
- en: '`generate` uses greedy search decoding by default so you don’t have to pass
    any parameters to enable it. This means the parameters `num_beams` is set to 1
    and `do_sample=False`.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`generate`默认使用贪婪搜索解码，因此您无需传递任何参数来启用它。这意味着参数`num_beams`设置为1，`do_sample=False`。'
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Contrastive search
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对比搜索
- en: 'The contrastive search decoding strategy was proposed in the 2022 paper [A
    Contrastive Framework for Neural Text Generation](https://arxiv.org/abs/2202.06417).
    It demonstrates superior results for generating non-repetitive yet coherent long
    outputs. To learn how contrastive search works, check out [this blog post](https://huggingface.co/blog/introducing-csearch).
    The two main parameters that enable and control the behavior of contrastive search
    are `penalty_alpha` and `top_k`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对比搜索解码策略是在2022年的论文[A Contrastive Framework for Neural Text Generation](https://arxiv.org/abs/2202.06417)中提出的。它展示了生成非重复但连贯的长输出的优越结果。要了解对比搜索的工作原理，请查看[这篇博客文章](https://huggingface.co/blog/introducing-csearch)。启用和控制对比搜索行为的两个主要参数是`penalty_alpha`和`top_k`：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Multinomial sampling
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多项式抽样
- en: As opposed to greedy search that always chooses a token with the highest probability
    as the next token, multinomial sampling (also called ancestral sampling) randomly
    selects the next token based on the probability distribution over the entire vocabulary
    given by the model. Every token with a non-zero probability has a chance of being
    selected, thus reducing the risk of repetition.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 与总是选择具有最高概率的标记作为下一个标记的贪婪搜索相反，多项式抽样（也称为祖先抽样）根据模型给出的整个词汇表上的概率分布随机选择下一个标记。每个具有非零概率的标记都有被选择的机会，从而降低重复的风险。
- en: To enable multinomial sampling set `do_sample=True` and `num_beams=1`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用多项式抽样，请设置`do_sample=True`和`num_beams=1`。
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Beam-search decoding
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 束搜索解码
- en: Unlike greedy search, beam-search decoding keeps several hypotheses at each
    time step and eventually chooses the hypothesis that has the overall highest probability
    for the entire sequence. This has the advantage of identifying high-probability
    sequences that start with lower probability initial tokens and would’ve been ignored
    by the greedy search.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 与贪婪搜索不同，束搜索解码在每个时间步保留几个假设，并最终选择整个序列的总体概率最高的假设。这有助于识别以较低概率初始标记开头的高概率序列，这些序列在贪婪搜索中会被忽略。
- en: To enable this decoding strategy, specify the `num_beams` (aka number of hypotheses
    to keep track of) that is greater than 1.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用这种解码策略，请指定`num_beams`（即要跟踪的假设数量）大于1。
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Beam-search multinomial sampling
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 束搜索多项式抽样
- en: As the name implies, this decoding strategy combines beam search with multinomial
    sampling. You need to specify the `num_beams` greater than 1, and set `do_sample=True`
    to use this decoding strategy.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，这种解码策略将束搜索与多项式抽样结合在一起。您需要指定`num_beams`大于1，并设置`do_sample=True`以使用这种解码策略。
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Diverse beam search decoding
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多样束搜索解码
- en: 'The diverse beam search decoding strategy is an extension of the beam search
    strategy that allows for generating a more diverse set of beam sequences to choose
    from. To learn how it works, refer to [Diverse Beam Search: Decoding Diverse Solutions
    from Neural Sequence Models](https://arxiv.org/pdf/1610.02424.pdf). This approach
    has three main parameters: `num_beams`, `num_beam_groups`, and `diversity_penalty`.
    The diversity penalty ensures the outputs are distinct across groups, and beam
    search is used within each group.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '多样束搜索解码策略是束搜索策略的扩展，允许生成更多样化的束序列供选择。要了解其工作原理，请参考[Diverse Beam Search: Decoding
    Diverse Solutions from Neural Sequence Models](https://arxiv.org/pdf/1610.02424.pdf)。这种方法有三个主要参数：`num_beams`、`num_beam_groups`和`diversity_penalty`。多样性惩罚确保输出在组间是不同的，并且在每个组内使用束搜索。'
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This guide illustrates the main parameters that enable various decoding strategies.
    More advanced parameters exist for the `generate` method, which gives you even
    further control over the `generate` method’s behavior. For the complete list of
    the available parameters, refer to the [API documentation](./main_classes/text_generation.md).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南说明了启用各种解码策略的主要参数。`generate`方法还有更高级的参数，可以进一步控制`generate`方法的行为。有关可用参数的完整列表，请参考[API文档](./main_classes/text_generation.md)。
- en: Speculative Decoding
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推测解码
- en: Speculative decoding (also known as assisted decoding) is a modification of
    the decoding strategies above, that uses an assistant model (ideally a much smaller
    one) with the same tokenizer, to generate a few candidate tokens. The main model
    then validates the candidate tokens in a single forward pass, which speeds up
    the decoding process. If `do_sample=True`, then the token validation with resampling
    introduced in the [speculative decoding paper](https://arxiv.org/pdf/2211.17192.pdf)
    is used.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 推测解码（也称为辅助解码）是上述解码策略的修改版本，它使用一个助理模型（理想情况下是一个更小的模型）与相同的分词器，生成一些候选标记。然后主模型在单个前向传递中验证候选标记，从而加快解码过程。如果`do_sample=True`，则使用[推测解码论文](https://arxiv.org/pdf/2211.17192.pdf)中引入的重新抽样进行标记验证。
- en: Currently, only greedy search and sampling are supported with assisted decoding,
    and assisted decoding doesn’t support batched inputs. To learn more about assisted
    decoding, check [this blog post](https://huggingface.co/blog/assisted-generation).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，只支持贪婪搜索和抽样与辅助解码，并且辅助解码不支持批量输入。要了解更多关于辅助解码的信息，请查看[这篇博客文章](https://huggingface.co/blog/assisted-generation)。
- en: To enable assisted decoding, set the `assistant_model` argument with a model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用辅助解码，请使用一个模型设置`assistant_model`参数。
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When using assisted decoding with sampling methods, you can use the `temperature`
    argument to control the randomness, just like in multinomial sampling. However,
    in assisted decoding, reducing the temperature may help improve the latency.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用辅助解码与抽样方法时，您可以使用`temperature`参数来控制随机性，就像在多项式抽样中一样。然而，在辅助解码中，降低温度可能有助于提高延迟。
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
