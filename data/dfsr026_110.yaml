- en: Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡å‹
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/overview](https://huggingface.co/docs/diffusers/api/models/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/api/models/overview](https://huggingface.co/docs/diffusers/api/models/overview)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ¤— Diffusers provides pretrained models for popular algorithms and modules to
    create custom diffusion systems. The primary function of models is to denoise
    an input sample as modeled by the distribution <math><semantics><mrow><msub><mi>p</mi><mi>Î¸</mi></msub><mo
    stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mi
    mathvariant="normal">âˆ£</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math>pÎ¸â€‹(xtâˆ’1â€‹âˆ£xtâ€‹).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Diffusersä¸ºæµè¡Œçš„ç®—æ³•å’Œæ¨¡å—æä¾›é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥åˆ›å»ºè‡ªå®šä¹‰æ‰©æ•£ç³»ç»Ÿã€‚æ¨¡å‹çš„ä¸»è¦åŠŸèƒ½æ˜¯å»å™ªè¾“å…¥æ ·æœ¬ï¼Œå…¶æ¨¡å‹ç”±åˆ†å¸ƒ<math><semantics><mrow><msub><mi>p</mi><mi>Î¸</mi></msub><mo
    stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mi
    mathvariant="normal">âˆ£</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math>pÎ¸â€‹(xtâˆ’1â€‹âˆ£xtâ€‹)å»ºæ¨¡ã€‚
- en: All models are built from the base [ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)
    class which is a [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)
    providing basic functionality for saving and loading models, locally and from
    the Hugging Face Hub.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯ä»åŸºç¡€[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)ç±»æ„å»ºçš„ï¼Œè¯¥ç±»æ˜¯ä¸€ä¸ª[`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)ï¼Œæä¾›äº†ä¿å­˜å’ŒåŠ è½½æ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½ï¼Œå¯ä»¥åœ¨æœ¬åœ°å’Œä»Hugging
    Face Hubä¸­åŠ è½½ã€‚
- en: ModelMixin
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ModelMixin
- en: '### `class diffusers.ModelMixin`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.ModelMixin`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L186)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L186)'
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Base class for all models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ã€‚
- en: '[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)
    takes care of storing the model configuration and provides methods for loading,
    downloading and saving models.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)è´Ÿè´£å­˜å‚¨æ¨¡å‹é…ç½®ï¼Œå¹¶æä¾›äº†åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚'
- en: '`config_name` (`str`) â€” Filename to save a model to when calling [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_name` (`str`) â€” åœ¨è°ƒç”¨[save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained)æ—¶ä¿å­˜æ¨¡å‹çš„æ–‡ä»¶åã€‚'
- en: '#### `disable_gradient_checkpointing`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_gradient_checkpointing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L238)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L238)'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Deactivates gradient checkpointing for the current model (may be referred to
    as *activation checkpointing* or *checkpoint activations* in other frameworks).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºå½“å‰æ¨¡å‹åœç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆåœ¨å…¶ä»–æ¡†æ¶ä¸­å¯èƒ½è¢«ç§°ä¸º*æ¿€æ´»æ£€æŸ¥ç‚¹*æˆ–*æ£€æŸ¥ç‚¹æ¿€æ´»*ï¼‰ã€‚
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L299)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L299)'
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä»[xFormers](https://facebookresearch.github.io/xformers/)ç¦ç”¨å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚
- en: '#### `enable_gradient_checkpointing`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_gradient_checkpointing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L229)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L229)'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Activates gradient checkpointing for the current model (may be referred to as
    *activation checkpointing* or *checkpoint activations* in other frameworks).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºå½“å‰æ¨¡å‹æ¿€æ´»æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆåœ¨å…¶ä»–æ¡†æ¶ä¸­å¯èƒ½è¢«ç§°ä¸º*æ¿€æ´»æ£€æŸ¥ç‚¹*æˆ–*æ£€æŸ¥ç‚¹æ¿€æ´»*ï¼‰ã€‚
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_xformers_memory_efficient_attention`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L263)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L263)'
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`attention_op` (`Callable`, *optional*) â€” Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_op` (`Callable`, *optional*) â€” ç”¨ä½œxFormersçš„[`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)å‡½æ•°çš„`op`å‚æ•°çš„é»˜è®¤`None`è¿ç®—ç¬¦çš„è¦†ç›–ã€‚'
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä»[xFormers](https://facebookresearch.github.io/xformers/)å¯ç”¨å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚
- en: When this option is enabled, you should observe lower GPU memory usage and a
    potential speed up during inference. Speed up during training is not guaranteed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ‚¨åº”è¯¥è§‚å¯Ÿåˆ°è¾ƒä½çš„GPUå†…å­˜ä½¿ç”¨é‡ï¼Œå¹¶ä¸”åœ¨æ¨æ–­æœŸé—´å¯èƒ½ä¼šåŠ é€Ÿã€‚ä¸èƒ½ä¿è¯åœ¨è®­ç»ƒæœŸé—´åŠ é€Ÿã€‚
- en: âš ï¸ When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å½“å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ä¼˜å…ˆã€‚
- en: 'Examples:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `from_pretrained`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L393)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L393)'
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) â€” Can
    be either:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`, *optional*) â€” å¯ä»¥æ˜¯ï¼š'
- en: A string, the *model id* (for example `google/ddpm-celebahq-256`) of a pretrained
    model hosted on the Hub.
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨Hubä¸Šæ‰˜ç®¡çš„*æ¨¡å‹id*ï¼ˆä¾‹å¦‚`google/ddpm-celebahq-256`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved with [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained).
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*ç›®å½•*è·¯å¾„ï¼ˆä¾‹å¦‚`./my_model_directory`ï¼‰ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨[save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained)ä¿å­˜çš„æ¨¡å‹æƒé‡ã€‚
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” å¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ï¼Œåˆ™ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®å°†è¢«ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ã€‚'
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) â€” Override the default `torch.dtype`
    and load the model with another dtype. If `"auto"` is passed, the dtype is automatically
    derived from the modelâ€™s weights.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype` (`str` æˆ– `torch.dtype`, *å¯é€‰*) â€” è¦†ç›–é»˜è®¤çš„ `torch.dtype` å¹¶ä½¿ç”¨å¦ä¸€ç§ dtype
    åŠ è½½æ¨¡å‹ã€‚å¦‚æœä¼ é€’ `"auto"`ï¼Œdtype å°†è‡ªåŠ¨ä»æ¨¡å‹çš„æƒé‡ä¸­æ´¾ç”Ÿã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶å°†è¢«åˆ é™¤ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *å¯é€‰*) â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†å°†åœ¨æ¯ä¸ªè¯·æ±‚ä¸­ä½¿ç”¨ã€‚'
- en: '`output_loading_info` (`bool`, *optional*, defaults to `False`) â€” Whether or
    not to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿˜è¿”å›ä¸€ä¸ªåŒ…å«ç¼ºå¤±é”®ã€æ„å¤–é”®å’Œé”™è¯¯æ¶ˆæ¯çš„å­—å…¸ã€‚'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™ä¸ä¼šä»
    Hub ä¸‹è½½æ¨¡å‹ã€‚'
- en: '`token` (`str` or *bool*, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` æˆ– *bool*, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œåˆ™ä½¿ç”¨ä»
    `diffusers-cli login` ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID æˆ– Git
    å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`from_flax` (`bool`, *optional*, defaults to `False`) â€” Load the model weights
    from a Flax checkpoint save file.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_flax` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” ä» Flax æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) â€” The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `""`) â€” Hub æˆ–æœ¬åœ°è¾ƒå¤§æ¨¡å‹å­˜å‚¨åº“ä¸­æ¨¡å‹æ–‡ä»¶çš„å­æ–‡ä»¶å¤¹ä½ç½®ã€‚'
- en: '`mirror` (`str`, *optional*) â€” Mirror source to resolve accessibility issues
    if youâ€™re downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mirror` (`str`, *å¯é€‰*) â€” é•œåƒæºä»¥è§£å†³åœ¨ä¸­å›½ä¸‹è½½æ¨¡å‹æ—¶çš„å¯è®¿é—®æ€§é—®é¢˜ã€‚æˆ‘ä»¬ä¸ä¿è¯æºçš„åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ï¼Œæ‚¨åº”å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚'
- en: '`device_map` (`str` or `Dict[str, Union[int, str, torch.device]]`, *optional*)
    â€” A map that specifies where each submodule should go. It doesnâ€™t need to be defined
    for each parameter/buffer name; once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map` (`str` æˆ– `Dict[str, Union[int, str, torch.device]]`, *å¯é€‰*) â€” ä¸€ä¸ªæŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥æ”¾åœ¨å“ªé‡Œçš„æ˜ å°„ã€‚ä¸éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°å®šä¹‰ï¼›ä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…éƒ¨ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°ç›¸åŒçš„è®¾å¤‡ã€‚'
- en: Set `device_map="auto"` to have ğŸ¤— Accelerate automatically compute the most
    optimized `device_map`. For more information about each option see [designing
    a device map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®¾ç½® `device_map="auto"` ä»¥ä½¿ ğŸ¤— Accelerate è‡ªåŠ¨è®¡ç®—æœ€ä¼˜åŒ–çš„ `device_map`ã€‚æœ‰å…³æ¯ä¸ªé€‰é¡¹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[è®¾è®¡è®¾å¤‡æ˜ å°„](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)ã€‚
- en: '`max_memory` (`Dict`, *optional*) â€” A dictionary device identifier for the
    maximum memory. Will default to the maximum memory available for each GPU and
    the available CPU RAM if unset.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory` (`Dict`, *å¯é€‰*) â€” ç”¨äºæœ€å¤§å†…å­˜çš„è®¾å¤‡æ ‡è¯†ç¬¦å­—å…¸ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºæ¯ä¸ª GPU å’Œå¯ç”¨ CPU RAM çš„æœ€å¤§å†…å­˜ã€‚'
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) â€” The path to offload
    weights if `device_map` contains the value `"disk"`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_folder` (`str` æˆ– `os.PathLike`, *å¯é€‰*) â€” å¦‚æœ `device_map` åŒ…å«å€¼ `"disk"`ï¼Œåˆ™æ˜¯å¸è½½æƒé‡çš„è·¯å¾„ã€‚'
- en: '`offload_state_dict` (`bool`, *optional*) â€” If `True`, temporarily offloads
    the CPU state dict to the hard drive to avoid running out of CPU RAM if the weight
    of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults
    to `True` when there is some disk offload.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offload_state_dict` (`bool`, *å¯é€‰*) â€” å¦‚æœä¸º `True`ï¼Œåˆ™ä¸´æ—¶å°† CPU çŠ¶æ€å­—å…¸è½¬ç§»åˆ°ç¡¬ç›˜ä»¥é¿å… CPU
    RAM ä¸è¶³ï¼Œå¦‚æœ CPU çŠ¶æ€å­—å…¸çš„é‡é‡ + æ£€æŸ¥ç‚¹çš„æœ€å¤§åˆ†ç‰‡çš„é‡é‡ä¸é€‚åˆã€‚å½“å­˜åœ¨ä¸€äº›ç£ç›˜å¸è½½æ—¶ï¼Œé»˜è®¤ä¸º `True`ã€‚'
- en: '`low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) â€” Speed up model loading only loading the pretrained weights
    and not initializing the weights. This also tries to not use more than 1x model
    size in CPU memory (including peak memory) while loading the model. Only supported
    for PyTorch >= 1.9.0\. If you are using an older version of PyTorch, setting this
    argument to `True` will raise an error.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_cpu_mem_usage` (`bool`, *å¯é€‰*, å¦‚æœ torch ç‰ˆæœ¬ >= 1.9.0 åˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`)
    â€” åŠ é€Ÿæ¨¡å‹åŠ è½½ï¼Œä»…åŠ è½½é¢„è®­ç»ƒæƒé‡è€Œä¸åˆå§‹åŒ–æƒé‡ã€‚åœ¨åŠ è½½æ¨¡å‹æ—¶ï¼Œè¿˜å°è¯•ä¸ä½¿ç”¨è¶…è¿‡ CPU å†…å­˜ä¸­çš„ 1x æ¨¡å‹å¤§å°ï¼ˆåŒ…æ‹¬å³°å€¼å†…å­˜ï¼‰ã€‚ä»…æ”¯æŒ PyTorch
    >= 1.9.0ã€‚å¦‚æœæ‚¨ä½¿ç”¨è¾ƒæ—§ç‰ˆæœ¬çš„ PyTorchï¼Œå°†æ­¤å‚æ•°è®¾ç½®ä¸º `True` å°†å¼•å‘é”™è¯¯ã€‚'
- en: '`variant` (`str`, *optional*) â€” Load weights from a specified `variant` filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *å¯é€‰*) â€” ä»æŒ‡å®šçš„ `variant` æ–‡ä»¶ååŠ è½½æƒé‡ï¼Œä¾‹å¦‚ `"fp16"` æˆ– `"ema"`ã€‚åœ¨åŠ è½½
    `from_flax` æ—¶ä¼šè¢«å¿½ç•¥ã€‚'
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) â€” If set to `None`,
    the `safetensors` weights are downloaded if theyâ€™re available **and** if the `safetensors`
    library is installed. If set to `True`, the model is forcibly loaded from `safetensors`
    weights. If set to `False`, `safetensors` weights are not loaded.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_safetensors` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `None`) â€” å¦‚æœè®¾ç½®ä¸º `None`ï¼Œåˆ™ä¼šä¸‹è½½ `safetensors`
    æƒé‡ï¼ˆå¦‚æœå¯ç”¨ä¸”å·²å®‰è£… `safetensors` åº“ï¼‰ã€‚å¦‚æœè®¾ç½®ä¸º `True`ï¼Œåˆ™ä¼šå¼ºåˆ¶ä» `safetensors` æƒé‡åŠ è½½æ¨¡å‹ã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œåˆ™ä¸ä¼šåŠ è½½
    `safetensors` æƒé‡ã€‚'
- en: Instantiate a pretrained PyTorch model from a pretrained model configuration.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–é¢„è®­ç»ƒçš„ PyTorch æ¨¡å‹ã€‚
- en: The model is set in evaluation mode - `model.eval()` - by default, and dropout
    modules are deactivated. To train the model, set it back in training mode with
    `model.train()`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼ - `model.eval()` - å¹¶ä¸”å…³é—­äº† dropout æ¨¡å—ã€‚è¦è®­ç»ƒæ¨¡å‹ï¼Œè¯·ä½¿ç”¨ `model.train()`
    å°†å…¶è®¾ç½®å›è®­ç»ƒæ¨¡å¼ã€‚
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`. You can also activate the special [â€œoffline-modeâ€](https://huggingface.co/diffusers/installation.html#offline-mode)
    to use this method in a firewalled environment.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨ç§æœ‰æˆ–[é—¨æ§æ¨¡å‹](https://huggingface.co/docs/hub/models-gated#gated-models)ï¼Œè¯·ä½¿ç”¨
    `huggingface-cli login` ç™»å½•ã€‚æ‚¨è¿˜å¯ä»¥æ¿€æ´»ç‰¹æ®Šçš„[â€œç¦»çº¿æ¨¡å¼â€](https://huggingface.co/diffusers/installation.html#offline-mode)ä»¥åœ¨å—é˜²ç«å¢™ä¿æŠ¤çš„ç¯å¢ƒä¸­ä½¿ç”¨æ­¤æ–¹æ³•ã€‚
- en: 'Example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ”¶åˆ°ä¸‹é¢çš„é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™éœ€è¦ä¸ºä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæƒé‡ï¼š
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `num_parameters`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `num_parameters`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L893)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L893)'
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`only_trainable` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to return only the number of trainable parameters.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`only_trainable` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…è¿”å›å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚'
- en: '`exclude_embeddings` (`bool`, *optional*, defaults to `False`) â€” Whether or
    not to return only the number of non-embedding parameters.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exclude_embeddings` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…è¿”å›éåµŒå…¥å‚æ•°çš„æ•°é‡ã€‚'
- en: Returns
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`int`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The number of parameters.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°æ•°é‡ã€‚
- en: Get number of (trainable or non-embedding) parameters in the module.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è·å–æ¨¡å—ä¸­ï¼ˆå¯è®­ç»ƒæˆ–éåµŒå…¥ï¼‰å‚æ•°çš„æ•°é‡ã€‚
- en: 'Example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `save_pretrained`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L305)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L305)'
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to save a model and its
    configuration file to. Will be created if it doesnâ€™t exist.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†ä¼šåˆ›å»ºã€‚'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) â€” Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®
    `is_main_process=True` ä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚'
- en: '`save_function` (`Callable`) â€” The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_function` (`Callable`) â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ï¼Œå½“æ‚¨éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢ `torch.save`
    æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡ `DIFFUSERS_SAVE_MODE` è¿›è¡Œé…ç½®ã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors` æˆ–ä¼ ç»Ÿçš„ PyTorch
    æ–¹æ³•ä¸ `pickle` ä¿å­˜æ¨¡å‹ã€‚'
- en: '`variant` (`str`, *optional*) â€” If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥ `pytorch_model.<variant>.bin` æ ¼å¼ä¿å­˜ã€‚'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    push your model to the Hugging Face Hub after saving it. You can specify the repository
    you want to push to with `repo_id` (will default to the name of `save_directory`
    in your namespace).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ° Hugging Face Hubã€‚æ‚¨å¯ä»¥ä½¿ç”¨
    `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°ï¼‰ã€‚'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) â€” Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚'
- en: Save a model and its configuration file to a directory so that it can be reloaded
    using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)
    class method.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)
    ç±»æ–¹æ³•é‡æ–°åŠ è½½å®ƒã€‚
- en: FlaxModelMixin
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxModelMixin
- en: '### `class diffusers.FlaxModelMixin`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.FlaxModelMixin`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L50)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L50)'
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Base class for all Flax models.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ Flax æ¨¡å‹çš„åŸºç±»ã€‚
- en: '[FlaxModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin)
    takes care of storing the model configuration and provides methods for loading,
    downloading and saving models.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin)
    è´Ÿè´£å­˜å‚¨æ¨¡å‹é…ç½®ï¼Œå¹¶æä¾›åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚'
- en: '`config_name` (`str`) â€” Filename to save a model to when calling [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained).'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_name` (`str`) â€” åœ¨è°ƒç”¨ [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained)
    æ—¶ä¿å­˜æ¨¡å‹çš„æ–‡ä»¶åã€‚'
- en: '#### `from_pretrained`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L203)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L203)'
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) â€” Can be either:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` æˆ– `os.PathLike`) â€” å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š'
- en: A string, the *model id* (for example `runwayml/stable-diffusion-v1-5`) of a
    pretrained model hosted on the Hub.
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ Hub ä¸Šæ‰˜ç®¡çš„*æ¨¡å‹ ID*ï¼ˆä¾‹å¦‚ `runwayml/stable-diffusion-v1-5`ï¼‰ã€‚
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained).
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒ‡å‘åŒ…å«ä½¿ç”¨[save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained)ä¿å­˜çš„æ¨¡å‹æƒé‡çš„*ç›®å½•*çš„è·¯å¾„ï¼ˆä¾‹å¦‚
    `./my_model_directory`ï¼‰ã€‚
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) â€”
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *optional*, é»˜è®¤ä¸º `jax.numpy.float32`) â€” è®¡ç®—çš„æ•°æ®ç±»å‹ã€‚å¯ä»¥æ˜¯
    `jax.numpy.float32`ã€`jax.numpy.float16`ï¼ˆåœ¨ GPU ä¸Šï¼‰å’Œ `jax.numpy.bfloat16`ï¼ˆåœ¨ TPU ä¸Šï¼‰ä¹‹ä¸€ã€‚'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified, all the computation will be performed with the
    given `dtype`.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™å¯ç”¨äºåœ¨ GPU æˆ– TPU ä¸Šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒæˆ–åŠç²¾åº¦æ¨æ–­ã€‚å¦‚æœæŒ‡å®šï¼Œæ‰€æœ‰è®¡ç®—å°†ä½¿ç”¨ç»™å®šçš„ `dtype` æ‰§è¡Œã€‚
- en: This only specifies the dtype of the *computation* and does not influence the
    dtype of model parameters.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™ä»…æŒ‡å®š*è®¡ç®—*çš„æ•°æ®ç±»å‹ï¼Œä¸å½±å“æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ã€‚
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_fp16)
    and [to_bf16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_bf16).
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè¦æ›´æ”¹æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ï¼Œè¯·å‚é˜…[to_fp16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_fp16)å’Œ[to_bf16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_bf16)ã€‚
- en: '`model_args` (sequence of positional arguments, *optional*) â€” All remaining
    positional arguments are passed to the underlying modelâ€™s `__init__` method.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`ï¼ˆä½ç½®å‚æ•°åºåˆ—ï¼Œ*optional*ï¼‰ â€” æ‰€æœ‰å‰©ä½™çš„ä½ç½®å‚æ•°éƒ½ä¼ é€’ç»™åŸºç¡€æ¨¡å‹çš„ `__init__` æ–¹æ³•ã€‚'
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœæœªä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) â€” Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦æ¢å¤ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º
    `False`ï¼Œåˆ™åˆ é™¤ä»»ä½•æœªå®Œå…¨ä¸‹è½½çš„æ–‡ä»¶ã€‚'
- en: '`proxies` (`Dict[str, str]`, *optional*) â€” A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) â€” ç”¨äºæ¯ä¸ªè¯·æ±‚çš„åè®®æˆ–ç«¯ç‚¹çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`ã€‚ä»£ç†æœåŠ¡å™¨åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) â€” Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model wonâ€™t be downloaded from the Hub.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…åŠ è½½æœ¬åœ°æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®ä¸º
    `True`ï¼Œåˆ™æ¨¡å‹ä¸ä¼šä» Hub ä¸‹è½½ã€‚'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) â€” The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°ã€æäº¤ ID
    æˆ– Git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) â€” Load the model weights
    from a PyTorch checkpoint save file.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” ä» PyTorch æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) â€” Can be used
    to update the configuration object (after it is loaded) and initiate the model
    (for example, `output_attentions=True`). Behaves differently depending on whether
    a `config` is provided or automatically loaded:'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`ï¼ˆå‰©ä½™çš„å…³é”®å­—å‚æ•°å­—å…¸ï¼Œ*optional*ï¼‰ â€” å¯ç”¨äºæ›´æ–°é…ç½®å¯¹è±¡ï¼ˆåŠ è½½åï¼‰å¹¶å¯åŠ¨æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ`output_attentions=True`ï¼‰ã€‚æ ¹æ®æ˜¯å¦æä¾›æˆ–è‡ªåŠ¨åŠ è½½äº†
    `config`ï¼Œè¡Œä¸ºä¸åŒã€‚'
- en: If a configuration is provided with `config`, `kwargs` are directly passed to
    the underlying modelâ€™s `__init__` method (we assume all relevant updates to the
    configuration have already been done).
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæä¾›äº† `config`ï¼Œåˆ™ `kwargs` ç›´æ¥ä¼ é€’ç»™åŸºç¡€æ¨¡å‹çš„ `__init__` æ–¹æ³•ï¼ˆæˆ‘ä»¬å‡è®¾é…ç½®çš„æ‰€æœ‰ç›¸å…³æ›´æ–°å·²ç»å®Œæˆï¼‰ã€‚
- en: If a configuration is not provided, `kwargs` are first passed to the configuration
    class initialization function [from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config).
    Each key of the `kwargs` that corresponds to a configuration attribute is used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute are passed to the underlying
    modelâ€™s `__init__` function.
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæœªæä¾›é…ç½®ï¼Œåˆ™é¦–å…ˆå°† `kwargs` ä¼ é€’ç»™é…ç½®ç±»åˆå§‹åŒ–å‡½æ•°[from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config)ã€‚ä¸é…ç½®å±æ€§å¯¹åº”çš„
    `kwargs` çš„æ¯ä¸ªé”®éƒ½ç”¨æä¾›çš„ `kwargs` å€¼è¦†ç›–è¯¥å±æ€§ã€‚ä¸å¯¹åº”ä»»ä½•é…ç½®å±æ€§çš„å‰©ä½™é”®å°†ä¼ é€’ç»™åŸºç¡€æ¨¡å‹çš„ `__init__` å‡½æ•°ã€‚
- en: Instantiate a pretrained Flax model from a pretrained model configuration.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–é¢„è®­ç»ƒçš„ Flax æ¨¡å‹ã€‚
- en: 'Examples:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE14]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ”¶åˆ°ä¸‹é¢çš„é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™éœ€è¦ä¸ºæ‚¨çš„ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæƒé‡ï¼š
- en: '[PRE15]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#### `save_pretrained`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L502)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L502)'
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory to save a model and its
    configuration file to. Will be created if it doesnâ€™t exist.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str`æˆ–`os.PathLike`) â€” è¦ä¿å­˜æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œå°†ä¼šåˆ›å»ºã€‚'
- en: '`params` (`Union[Dict, FrozenDict]`) â€” A `PyTree` of model parameters.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚'
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) â€” Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­éå¸¸æœ‰ç”¨ï¼Œå½“æ‚¨éœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®`is_main_process=True`ä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ°Hugging Faceæ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨`repo_id`æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆé»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„`save_directory`åç§°ï¼‰ã€‚'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) â€” Additional key word arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™[push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚'
- en: Save a model and its configuration file to a directory so that it can be reloaded
    using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.from_pretrained)
    class method.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨[from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.from_pretrained)ç±»æ–¹æ³•é‡æ–°åŠ è½½ã€‚
- en: '#### `to_bf16`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_bf16`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L95)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L95)'
- en: '[PRE17]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`params` (`Union[Dict, FrozenDict]`) â€” A `PyTree` of model parameters.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚'
- en: '`mask` (`Union[Dict, FrozenDict]`) â€” A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask` (`Union[Dict, FrozenDict]`) â€” ä¸€ä¸ªä¸`params`æ ‘ç»“æ„ç›¸åŒçš„`PyTree`ã€‚å¶å­èŠ‚ç‚¹åº”ä¸ºå¸ƒå°”å€¼ã€‚å¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º`True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º`False`ã€‚'
- en: Cast the floating-point `params` to `jax.numpy.bfloat16`. This returns a new
    `params` tree and does not cast the `params` in place.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æµ®ç‚¹`params`è½¬æ¢ä¸º`jax.numpy.bfloat16`ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„`params`æ ‘ï¼Œä¸ä¼šç›´æ¥è½¬æ¢`params`ã€‚
- en: This method can be used on a TPU to explicitly convert the model parameters
    to bfloat16 precision to do full half-precision training or to save weights in
    bfloat16 for inference in order to save memory and improve speed.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•å¯ä»¥åœ¨TPUä¸Šä½¿ç”¨ï¼Œæ˜¾å¼åœ°å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºbfloat16ç²¾åº¦ï¼Œä»¥è¿›è¡Œå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒæˆ–è€…ä¿å­˜æƒé‡ä¸ºbfloat16ä»¥èŠ‚çœå†…å­˜å¹¶æé«˜é€Ÿåº¦ã€‚
- en: 'Examples:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¤ºä¾‹:'
- en: '[PRE18]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#### `to_fp16`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_fp16`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L161)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L161)'
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`params` (`Union[Dict, FrozenDict]`) â€” A `PyTree` of model parameters.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚'
- en: '`mask` (`Union[Dict, FrozenDict]`) â€” A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask` (`Union[Dict, FrozenDict]`) â€” ä¸€ä¸ªä¸`params`æ ‘ç»“æ„ç›¸åŒçš„`PyTree`ã€‚å¶å­èŠ‚ç‚¹åº”ä¸ºå¸ƒå°”å€¼ã€‚å¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º`True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º`False`ã€‚'
- en: Cast the floating-point `params` to `jax.numpy.float16`. This returns a new
    `params` tree and does not cast the `params` in place.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æµ®ç‚¹`params`è½¬æ¢ä¸º`jax.numpy.float16`ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„`params`æ ‘ï¼Œä¸ä¼šç›´æ¥è½¬æ¢`params`ã€‚
- en: This method can be used on a GPU to explicitly convert the model parameters
    to float16 precision to do full half-precision training or to save weights in
    float16 for inference in order to save memory and improve speed.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•å¯ä»¥åœ¨GPUä¸Šä½¿ç”¨ï¼Œæ˜¾å¼åœ°å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºfloat16ç²¾åº¦ï¼Œä»¥è¿›è¡Œå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒæˆ–è€…ä¿å­˜æƒé‡ä¸ºfloat16ä»¥èŠ‚çœå†…å­˜å¹¶æé«˜é€Ÿåº¦ã€‚
- en: 'Examples:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `to_fp32`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_fp32`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L134)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L134)'
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`params` (`Union[Dict, FrozenDict]`) â€” A `PyTree` of model parameters.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„`PyTree`ã€‚'
- en: '`mask` (`Union[Dict, FrozenDict]`) â€” A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask` (`Union[Dict, FrozenDict]`) â€” ä¸€ä¸ªä¸`params`æ ‘ç»“æ„ç›¸åŒçš„`PyTree`ã€‚å¶å­èŠ‚ç‚¹åº”ä¸ºå¸ƒå°”å€¼ã€‚å¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º`True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º`False`ã€‚'
- en: Cast the floating-point `params` to `jax.numpy.float32`. This method can be
    used to explicitly convert the model parameters to fp32 precision. This returns
    a new `params` tree and does not cast the `params` in place.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æµ®ç‚¹`params`è½¬æ¢ä¸º`jax.numpy.float32`ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ç”¨äºæ˜¾å¼åœ°å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºfp32ç²¾åº¦ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„`params`æ ‘ï¼Œä¸ä¼šç›´æ¥è½¬æ¢`params`ã€‚
- en: 'Examples:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: PushToHubMixin
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PushToHubMixin
- en: '### `class diffusers.utils.PushToHubMixin`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.utils.PushToHubMixin`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)'
- en: '[PRE23]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: A Mixin to push a model, scheduler, or pipeline to the Hugging Face Hub.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–æµæ°´çº¿æ¨é€åˆ°Hugging Face Hubçš„Mixinã€‚
- en: '#### `push_to_hub`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`push_to_hub`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)'
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`repo_id` (`str`) â€” The name of the repository you want to push your model,
    scheduler, or pipeline files to. It should contain your organization name when
    pushing to an organization. `repo_id` can also be a path to a local directory.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) â€” æ‚¨è¦æ¨é€æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–æµæ°´çº¿æ–‡ä»¶çš„å­˜å‚¨åº“åç§°ã€‚åœ¨æ¨é€åˆ°ç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚`repo_id`ä¹Ÿå¯ä»¥æ˜¯æœ¬åœ°ç›®å½•çš„è·¯å¾„ã€‚'
- en: '`commit_message` (`str`, *optional*) â€” Message to commit while pushing. Default
    to `"Upload {object}"`.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message` (`str`, *optional*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º`"Upload {object}"`ã€‚'
- en: '`private` (`bool`, *optional*) â€” Whether or not the repository created should
    be private.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private` (`bool`, *optional*) â€” æ˜¯å¦åº”å°†åˆ›å»ºçš„å­˜å‚¨åº“è®¾ç½®ä¸ºç§æœ‰ã€‚'
- en: '`token` (`str`, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. The token generated when running `huggingface-cli login` (stored
    in `~/.huggingface`).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„HTTP beareræˆæƒçš„ä»¤ç‰Œã€‚åœ¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) â€” Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„PRæˆ–ç›´æ¥æäº¤ã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether or
    not to convert the model weights to the `safetensors` format.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º`safetensors`æ ¼å¼ã€‚'
- en: '`variant` (`str`, *optional*) â€” If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥`pytorch_model.<variant>.bin`æ ¼å¼ä¿å­˜ã€‚'
- en: Upload model, scheduler, or pipeline files to the ğŸ¤— Hugging Face Hub.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹ã€è°ƒåº¦å™¨æˆ–æµæ°´çº¿æ–‡ä»¶ä¸Šä¼ åˆ°ğŸ¤— Hugging Face Hubã€‚
- en: 'Examples:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE25]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
