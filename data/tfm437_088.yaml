- en: How to convert a 🤗 Transformers model to TensorFlow?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何将🤗 Transformers模型转换为TensorFlow？
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/add_tensorflow_model](https://huggingface.co/docs/transformers/v4.37.2/en/add_tensorflow_model)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/add_tensorflow_model](https://huggingface.co/docs/transformers/v4.37.2/en/add_tensorflow_model)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Having multiple frameworks available to use with 🤗 Transformers gives you flexibility
    to play their strengths when designing your application, but it implies that compatibility
    must be added on a per-model basis. The good news is that adding TensorFlow compatibility
    to an existing model is simpler than [adding a new model from scratch](add_new_model)!
    Whether you wish to have a deeper understanding of large TensorFlow models, make
    a major open-source contribution, or enable TensorFlow for your model of choice,
    this guide is for you.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在🤗 Transformers中有多个可用的框架可以使用，这使您在设计应用程序时可以灵活发挥其优势，但这意味着必须根据每个模型添加兼容性。好消息是，将TensorFlow兼容性添加到现有模型比[从头开始添加新模型](add_new_model)更简单！无论您希望更深入地了解大型TensorFlow模型，做出重大的开源贡献，还是为您选择的模型启用TensorFlow，本指南都适合您。
- en: This guide empowers you, a member of our community, to contribute TensorFlow
    model weights and/or architectures to be used in 🤗 Transformers, with minimal
    supervision from the Hugging Face team. Writing a new model is no small feat,
    but hopefully this guide will make it less of a rollercoaster 🎢 and more of a
    walk in the park 🚶. Harnessing our collective experiences is absolutely critical
    to make this process increasingly easier, and thus we highly encourage that you
    suggest improvements to this guide!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南授权您，我们社区的一员，贡献TensorFlow模型权重和/或架构，以供在🤗 Transformers中使用，几乎不需要Hugging Face团队的监督。编写一个新模型并不是一件小事，但希望这个指南能让它不再像坐过山车🎢那样，而更像在公园里散步🚶。利用我们的集体经验绝对是使这个过程变得更加容易的关键，因此我们强烈鼓励您对本指南提出改进建议！
- en: 'Before you dive deeper, it is recommended that you check the following resources
    if you’re new to 🤗 Transformers:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究之前，建议您查看以下资源，如果您对🤗 Transformers还不熟悉：
- en: '[General overview of 🤗 Transformers](add_new_model#general-overview-of-transformers)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[🤗 Transformers的概述](add_new_model#general-overview-of-transformers)'
- en: '[Hugging Face’s TensorFlow Philosophy](https://huggingface.co/blog/tensorflow-philosophy)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[拥抱面的TensorFlow哲学](https://huggingface.co/blog/tensorflow-philosophy)'
- en: In the remainder of this guide, you will learn what’s needed to add a new TensorFlow
    model architecture, the procedure to convert PyTorch into TensorFlow model weights,
    and how to efficiently debug mismatches across ML frameworks. Let’s get started!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南的其余部分，您将学习添加新的TensorFlow模型架构所需的内容，将PyTorch转换为TensorFlow模型权重的过程，以及如何有效地调试跨ML框架的不匹配。让我们开始吧！
- en: Are you unsure whether the model you wish to use already has a corresponding
    TensorFlow architecture?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否不确定您想要使用的模型是否已经有相应的TensorFlow架构？
- en: Check the `model_type` field of the `config.json` of your model of choice ([example](https://huggingface.co/bert-base-uncased/blob/main/config.json#L14)).
    If the corresponding model folder in 🤗 Transformers has a file whose name starts
    with “modeling_tf”, it means that it has a corresponding TensorFlow architecture
    ([example](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 检查您选择的模型的`config.json`文件中的`model_type`字段（[示例](https://huggingface.co/bert-base-uncased/blob/main/config.json#L14)）。如果🤗
    Transformers中相应的模型文件夹有一个以“modeling_tf”开头的文件，这意味着它有一个相应的TensorFlow架构（[示例](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert)）。
- en: Step-by-step guide to add TensorFlow model architecture code
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逐步指南添加TensorFlow模型架构代码
- en: 'There are many ways to design a large model architecture, and multiple ways
    of implementing said design. However, you might recall from our [general overview
    of 🤗 Transformers](add_new_model#general-overview-of-transformers) that we are
    an opinionated bunch - the ease of use of 🤗 Transformers relies on consistent
    design choices. From experience, we can tell you a few important things about
    adding TensorFlow models:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 设计大型模型架构的方法有很多，实现该设计的方式也有多种。然而，您可能还记得我们在[🤗 Transformers的概述](add_new_model#general-overview-of-transformers)中提到，我们是一个有主见的团队
    - 🤗 Transformers的易用性依赖于一致的设计选择。从经验中，我们可以告诉您一些关于添加TensorFlow模型的重要事项：
- en: 'Don’t reinvent the wheel! More often than not, there are at least two reference
    implementations you should check: the PyTorch equivalent of the model you are
    implementing and other TensorFlow models for the same class of problems.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要重复造轮子！往往至少有两个参考实现您应该检查：您正在实现的模型的PyTorch等效版本以及同一类问题的其他TensorFlow模型。
- en: Great model implementations survive the test of time. This doesn’t happen because
    the code is pretty, but rather because the code is clear, easy to debug and build
    upon. If you make the life of the maintainers easy with your TensorFlow implementation,
    by replicating the same patterns as in other TensorFlow models and minimizing
    the mismatch to the PyTorch implementation, you ensure your contribution will
    be long lived.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出色的模型实现经得起时间的考验。这不是因为代码漂亮，而是因为代码清晰，易于调试和构建。如果您通过在TensorFlow实现中复制其他TensorFlow模型中的相同模式并最小化与PyTorch实现的不匹配，使维护者的生活变得轻松，您就确保您的贡献将长期存在。
- en: Ask for help when you’re stuck! The 🤗 Transformers team is here to help, and
    we’ve probably found solutions to the same problems you’re facing.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当遇到困难时寻求帮助！🤗 Transformers团队在这里帮助您，我们可能已经找到了您面临的相同问题的解决方案。
- en: 'Here’s an overview of the steps needed to add a TensorFlow model architecture:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是添加TensorFlow模型架构所需步骤的概述：
- en: Select the model you wish to convert
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您希望转换的模型
- en: Prepare transformers dev environment
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备transformers开发环境
- en: (Optional) Understand theoretical aspects and the existing implementation
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）理解理论方面和现有实现
- en: Implement the model architecture
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现模型架构
- en: Implement model tests
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现模型测试
- en: Submit the pull request
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交拉取请求
- en: (Optional) Build demos and share with the world
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）构建演示并与世界分享
- en: 1.-3\. Prepare your model contribution
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.-3\. 准备您的模型贡献
- en: '**1\. Select the model you wish to convert**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\.选择要转换的模型**'
- en: 'Let’s start off with the basics: the first thing you need to know is the architecture
    you want to convert. If you don’t have your eyes set on a specific architecture,
    asking the 🤗 Transformers team for suggestions is a great way to maximize your
    impact - we will guide you towards the most prominent architectures that are missing
    on the TensorFlow side. If the specific model you want to use with TensorFlow
    already has a TensorFlow architecture implementation in 🤗 Transformers but is
    lacking weights, feel free to jump straight into the [weight conversion section](#adding-tensorflow-weights-to-hub)
    of this page.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基础知识开始：您需要了解要转换的架构。如果您没有特定的架构，向🤗 Transformers团队寻求建议是最大化影响的好方法 - 我们将指导您选择在TensorFlow方面缺失的最突出的架构。如果您想要在TensorFlow中使用的特定模型已经在🤗
    Transformers中具有TensorFlow架构实现，但缺少权重，请随时直接转到本页的[添加TensorFlow权重到hub](#adding-tensorflow-weights-to-hub)部分。
- en: For simplicity, the remainder of this guide assumes you’ve decided to contribute
    with the TensorFlow version of *BrandNewBert* (the same example as in the [guide](add_new_model)
    to add a new model from scratch).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为简单起见，本指南的其余部分假定您已决定使用TensorFlow版本的*BrandNewBert*（与[指南](add_new_model)中添加新模型的示例相同）做出贡献。
- en: Before starting the work on a TensorFlow model architecture, double-check that
    there is no ongoing effort to do so. You can search for `BrandNewBert` on the
    [pull request GitHub page](https://github.com/huggingface/transformers/pulls?q=is%3Apr)
    to confirm that there is no TensorFlow-related pull request.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始TensorFlow模型架构的工作之前，请仔细检查是否有正在进行的工作。您可以在[拉取请求GitHub页面](https://github.com/huggingface/transformers/pulls?q=is%3Apr)上搜索`BrandNewBert`以确认是否有与TensorFlow相关的拉取请求。
- en: '**2\. Prepare transformers dev environment**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\.准备transformers开发环境**'
- en: Having selected the model architecture, open a draft PR to signal your intention
    to work on it. Follow the instructions below to set up your environment and open
    a draft PR.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 选择模型架构后，打开一个草稿PR以表示您打算进行工作。按照以下说明设置您的环境并打开草稿PR。
- en: Fork the [repository](https://github.com/huggingface/transformers) by clicking
    on the ‘Fork’ button on the repository’s page. This creates a copy of the code
    under your GitHub user account.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过单击存储库页面上的“Fork”按钮来分叉[存储库](https://github.com/huggingface/transformers)。这将在您的GitHub用户帐户下创建代码副本。
- en: 'Clone your `transformers` fork to your local disk, and add the base repository
    as a remote:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的`transformers`分支克隆到本地磁盘，并将基础存储库添加为远程存储库：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Set up a development environment, for instance by running the following command:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立一个开发环境，例如通过运行以下命令：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Depending on your OS, and since the number of optional dependencies of Transformers
    is growing, you might get a failure with this command. If that’s the case make
    sure to install TensorFlow then do:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的操作系统，由于Transformers的可选依赖项数量正在增加，您可能会在此命令中失败。如果是这种情况，请确保安装TensorFlow，然后执行：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Note:** You don’t need to have CUDA installed. Making the new model work
    on CPU is sufficient.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：**您不需要安装CUDA。使新模型在CPU上运行就足够了。'
- en: Create a branch with a descriptive name from your main branch
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从主分支创建一个具有描述性名称的分支
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Fetch and rebase to current main
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取并将当前主分支重新设置为基础
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Add an empty `.py` file in `transformers/src/models/brandnewbert/` named `modeling_tf_brandnewbert.py`.
    This will be your TensorFlow model file.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`transformers/src/models/brandnewbert/`中添加一个名为`modeling_tf_brandnewbert.py`的空`.py`文件。这将是您的TensorFlow模型文件。
- en: 'Push the changes to your account using:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将更改推送到您的帐户：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once you are satisfied, go to the webpage of your fork on GitHub. Click on “Pull
    request”. Make sure to add the GitHub handle of some members of the Hugging Face
    team as reviewers, so that the Hugging Face team gets notified for future changes.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您满意了，转到GitHub上您的分支的网页。点击“拉取请求”。确保将Hugging Face团队的一些成员的GitHub句柄添加为审阅者，以便Hugging
    Face团队在未来的更改中收到通知。
- en: Change the PR into a draft by clicking on “Convert to draft” on the right of
    the GitHub pull request web page.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过单击GitHub拉取请求网页右侧的“转换为草稿”将PR更改为草稿。
- en: Now you have set up a development environment to port *BrandNewBert* to TensorFlow
    in 🤗 Transformers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经设置了一个开发环境，可以将*BrandNewBert*移植到🤗 Transformers中的TensorFlow中。
- en: '**3\. (Optional) Understand theoretical aspects and the existing implementation**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\.（可选）了解理论方面和现有实现**'
- en: You should take some time to read *BrandNewBert’s* paper, if such descriptive
    work exists. There might be large sections of the paper that are difficult to
    understand. If this is the case, this is fine - don’t worry! The goal is not to
    get a deep theoretical understanding of the paper, but to extract the necessary
    information required to effectively re-implement the model in 🤗 Transformers using
    TensorFlow. That being said, you don’t have to spend too much time on the theoretical
    aspects, but rather focus on the practical ones, namely the existing model documentation
    page (e.g. [model docs for BERT](model_doc/bert)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该花一些时间阅读*BrandNewBert*的论文，如果存在这样的描述性工作。论文中可能有一些难以理解的大段内容。如果是这种情况，没关系 - 不要担心！目标不是深入理解论文的理论，而是提取在🤗
    Transformers中使用TensorFlow有效重新实现模型所需的必要信息。也就是说，您不必花太多时间在理论方面，而是要专注于实践方面，即现有模型文档页面（例如[BERT的模型文档](model_doc/bert)）。
- en: After you’ve grasped the basics of the models you are about to implement, it’s
    important to understand the existing implementation. This is a great chance to
    confirm that a working implementation matches your expectations for the model,
    as well as to foresee technical challenges on the TensorFlow side.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了即将实现的模型的基础知识之后，了解现有的实现是很重要的。这是确认工作实现是否符合您对模型的期望，以及预见TensorFlow方面的技术挑战的绝佳机会。
- en: It’s perfectly natural that you feel overwhelmed with the amount of information
    that you’ve just absorbed. It is definitely not a requirement that you understand
    all facets of the model at this stage. Nevertheless, we highly encourage you to
    clear any pressing questions in our [forum](https://discuss.huggingface.co/).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你感到不知所措刚刚吸收了大量信息是非常自然的。在这个阶段，你并不需要理解模型的所有方面。尽管如此，我们强烈鼓励你在我们的[论坛](https://discuss.huggingface.co/)中解决任何紧迫的问题。
- en: 4\. Model implementation
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 模型实现
- en: 'Now it’s time to finally start coding. Our suggested starting point is the
    PyTorch file itself: copy the contents of `modeling_brand_new_bert.py` inside
    `src/transformers/models/brand_new_bert/` into `modeling_tf_brand_new_bert.py`.
    The goal of this section is to modify the file and update the import structure
    of 🤗 Transformers such that you can import `TFBrandNewBert` and `TFBrandNewBert.from_pretrained(model_repo,
    from_pt=True)` successfully loads a working TensorFlow *BrandNewBert* model.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候开始编码了。我们建议的起点是PyTorch文件本身：将`modeling_brand_new_bert.py`的内容复制到`src/transformers/models/brand_new_bert/`中的`modeling_tf_brand_new_bert.py`。本节的目标是修改文件并更新🤗
    Transformers的导入结构，以便你可以成功导入`TFBrandNewBert`和`TFBrandNewBert.from_pretrained(model_repo,
    from_pt=True)`，从而加载一个可工作的TensorFlow *BrandNewBert*模型。
- en: 'Sadly, there is no prescription to convert a PyTorch model into TensorFlow.
    You can, however, follow our selection of tips to make the process as smooth as
    possible:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 遗憾的是，没有将PyTorch模型转换为TensorFlow的规定。但是，你可以遵循我们的一些提示，使这个过程尽可能顺利：
- en: Prepend `TF` to the name of all classes (e.g. `BrandNewBert` becomes `TFBrandNewBert`).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有类的名称前加上`TF`（例如，`BrandNewBert`变为`TFBrandNewBert`）。
- en: Most PyTorch operations have a direct TensorFlow replacement. For example, `torch.nn.Linear`
    corresponds to `tf.keras.layers.Dense`, `torch.nn.Dropout` corresponds to `tf.keras.layers.Dropout`,
    etc. If you’re not sure about a specific operation, you can use the [TensorFlow
    documentation](https://www.tensorflow.org/api_docs/python/tf) or the [PyTorch
    documentation](https://pytorch.org/docs/stable/).
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数PyTorch操作都有直接的TensorFlow替代。例如，`torch.nn.Linear`对应于`tf.keras.layers.Dense`，`torch.nn.Dropout`对应于`tf.keras.layers.Dropout`等。如果对特定操作不确定，可以使用[TensorFlow文档](https://www.tensorflow.org/api_docs/python/tf)或[PyTorch文档](https://pytorch.org/docs/stable/)。
- en: Look for patterns in the 🤗 Transformers codebase. If you come across a certain
    operation that doesn’t have a direct replacement, the odds are that someone else
    already had the same problem.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在🤗 Transformers代码库中寻找模式。如果你遇到某个操作没有直接替代，那么很可能有其他人已经遇到了同样的问题。
- en: By default, keep the same variable names and structure as in PyTorch. This will
    make it easier to debug, track issues, and add fixes down the line.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，保持与PyTorch相同的变量名称和结构。这将使调试、跟踪问题和添加修复更容易。
- en: Some layers have different default values in each framework. A notable example
    is the batch normalization layer’s epsilon (`1e-5` in [PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d)
    and `1e-3` in [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)).
    Double-check the documentation!
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些层在每个框架中具有不同的默认值。一个显著的例子是批量归一化层的epsilon（在[PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d)中为`1e-5`，在[TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)中为`1e-3`）。务必仔细检查文档！
- en: 'PyTorch’s `nn.Parameter` variables typically need to be initialized within
    TF Layer’s `build()`. See the following example: [PyTorch](https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_vit_mae.py#L212)
    / [TensorFlow](https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_tf_vit_mae.py#L220)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch的`nn.Parameter`变量通常需要在TF Layer的`build()`中初始化。参见以下示例：[PyTorch](https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_vit_mae.py#L212)
    / [TensorFlow](https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_tf_vit_mae.py#L220)
- en: If the PyTorch model has a `#copied from ...` on top of a function, the odds
    are that your TensorFlow model can also borrow that function from the architecture
    it was copied from, assuming it has a TensorFlow architecture.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果PyTorch模型在函数顶部有`#copied from ...`，那么你的TensorFlow模型很可能也可以从被复制的架构中借用该函数，假设它有一个TensorFlow架构。
- en: Assigning the `name` attribute correctly in TensorFlow functions is critical
    to do the `from_pt=True` weight cross-loading. `name` is almost always the name
    of the corresponding variable in the PyTorch code. If `name` is not properly set,
    you will see it in the error message when loading the model weights.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在TensorFlow函数中正确设置`name`属性对于进行`from_pt=True`权重交叉加载至关重要。`name`几乎总是PyTorch代码中相应变量的名称。如果`name`没有正确设置，加载模型权重时会在错误消息中看到。
- en: The logic of the base model class, `BrandNewBertModel`, will actually reside
    in `TFBrandNewBertMainLayer`, a Keras layer subclass ([example](https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L719)).
    `TFBrandNewBertModel` will simply be a wrapper around this layer.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础模型类`BrandNewBertModel`的逻辑实际上将驻留在`TFBrandNewBertMainLayer`中，这是一个Keras层子类（[示例](https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L719)）。`TFBrandNewBertModel`将简单地是这个层的包装器。
- en: Keras models need to be built in order to load pretrained weights. For that
    reason, `TFBrandNewBertPreTrainedModel` will need to hold an example of inputs
    to the model, the `dummy_inputs` ([example](https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L916)).
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras模型需要被构建以加载预训练权重。因此，`TFBrandNewBertPreTrainedModel`将需要保存模型的输入示例，即`dummy_inputs`（[示例](https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L916)）。
- en: If you get stuck, ask for help - we’re here to help you! 🤗
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果遇到困难，请寻求帮助 - 我们在这里帮助你！🤗
- en: 'In addition to the model file itself, you will also need to add the pointers
    to the model classes and related documentation pages. You can complete this part
    entirely following the patterns in other PRs ([example](https://github.com/huggingface/transformers/pull/18020/files)).
    Here’s a list of the needed manual changes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模型文件本身，您还需要添加指向模型类和相关文档页面的指针。您可以完全按照其他 PR 中的模式完成此部分（[示例](https://github.com/huggingface/transformers/pull/18020/files)）。以下是所需手动更改的列表：
- en: Include all public classes of *BrandNewBert* in `src/transformers/__init__.py`
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `src/transformers/__init__.py` 中包含 *BrandNewBert* 的所有公共类
- en: Add *BrandNewBert* classes to the corresponding Auto classes in `src/transformers/models/auto/modeling_tf_auto.py`
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `src/transformers/models/auto/modeling_tf_auto.py` 中将 *BrandNewBert* 类添加到相应的
    Auto 类中
- en: Add the lazy loading classes related to *BrandNewBert* in `src/transformers/utils/dummy_tf_objects.py`
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `src/transformers/utils/dummy_tf_objects.py` 中添加与 *BrandNewBert* 相关的延迟加载类
- en: Update the import structures for the public classes in `src/transformers/models/brand_new_bert/__init__.py`
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新 `src/transformers/models/brand_new_bert/__init__.py` 中公共类的导入结构
- en: Add the documentation pointers to the public methods of *BrandNewBert* in `docs/source/en/model_doc/brand_new_bert.md`
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `docs/source/en/model_doc/brand_new_bert.md` 中为 *BrandNewBert* 的公共方法添加文档指针
- en: Add yourself to the list of contributors to *BrandNewBert* in `docs/source/en/model_doc/brand_new_bert.md`
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `docs/source/en/model_doc/brand_new_bert.md` 中将自己添加到 *BrandNewBert* 的贡献者列表中
- en: Finally, add a green tick ✅ to the TensorFlow column of *BrandNewBert* in `docs/source/en/index.md`
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，在 `docs/source/en/index.md` 中 *BrandNewBert* 的 TensorFlow 列中添加一个绿色勾 ✅
- en: 'When you’re happy with your implementation, run the following checklist to
    confirm that your model architecture is ready:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当您对实现感到满意时，请运行以下检查表以确认您的模型架构已准备就绪：
- en: All layers that behave differently at train time (e.g. Dropout) are called with
    a `training` argument, which is propagated all the way from the top-level classes
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练时行为不同的所有层（例如 Dropout）都使用 `training` 参数调用，并且该参数从顶层类一直传播下去
- en: You have used `#copied from ...` whenever possible
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在可能的情况下，您已经使用了 `#copied from ...`
- en: '`TFBrandNewBertMainLayer` and all classes that use it have their `call` function
    decorated with `@unpack_inputs`'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TFBrandNewBertMainLayer` 和所有使用它的类都将其 `call` 函数装饰为 `@unpack_inputs`'
- en: '`TFBrandNewBertMainLayer` is decorated with `@keras_serializable`'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TFBrandNewBertMainLayer` 被装饰为 `@keras_serializable`'
- en: A TensorFlow model can be loaded from PyTorch weights using `TFBrandNewBert.from_pretrained(model_repo,
    from_pt=True)`
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用 `TFBrandNewBert.from_pretrained(model_repo, from_pt=True)` 从 PyTorch 权重加载
    TensorFlow 模型
- en: You can call the TensorFlow model using the expected input format
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用预期的输入格式调用 TensorFlow 模型
- en: 5\. Add model tests
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 添加模型测试
- en: Hurray, you’ve implemented a TensorFlow model! Now it’s time to add tests to
    make sure that your model behaves as expected. As in the previous section, we
    suggest you start by copying the `test_modeling_brand_new_bert.py` file in `tests/models/brand_new_bert/`
    into `test_modeling_tf_brand_new_bert.py`, and continue by making the necessary
    TensorFlow replacements. For now, in all `.from_pretrained()` calls, you should
    use the `from_pt=True` flag to load the existing PyTorch weights.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 万岁，您已经实现了一个 TensorFlow 模型！现在是添加测试以确保您的模型表现如预期的时候了。与前一节一样，我们建议您首先将 `tests/models/brand_new_bert/`
    中的 `test_modeling_brand_new_bert.py` 文件复制到 `test_modeling_tf_brand_new_bert.py`
    中，然后继续进行必要的 TensorFlow 替换。目前，在所有 `.from_pretrained()` 调用中，您应该使用 `from_pt=True`
    标志来加载现有的 PyTorch 权重。
- en: 'After you’re done, it’s time for the moment of truth: run the tests! 😬'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，是真相时刻：运行测试！😬
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The most likely outcome is that you’ll see a bunch of errors. Don’t worry, this
    is expected! Debugging ML models is notoriously hard, and the key ingredient to
    success is patience (and `breakpoint()`). In our experience, the hardest problems
    arise from subtle mismatches between ML frameworks, for which we have a few pointers
    at the end of this guide. In other cases, a general test might not be directly
    applicable to your model, in which case we suggest an override at the model test
    class level. Regardless of the issue, don’t hesitate to ask for help in your draft
    pull request if you’re stuck.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最有可能的结果是您会看到一堆错误。不要担心，这是正常的！调试 ML 模型是非常困难的，成功的关键因素是耐心（和 `breakpoint()`）。根据我们的经验，最困难的问题来自于
    ML 框架之间的微妙不匹配，我们在本指南末尾提供了一些指针。在其他情况下，一般测试可能不直接适用于您的模型，这种情况下，我们建议在模型测试类级别进行覆盖。无论问题是什么，请不要犹豫在您的草稿拉取请求中寻求帮助，如果您遇到困难。
- en: When all tests pass, congratulations, your model is nearly ready to be added
    to the 🤗 Transformers library! 🎉
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有测试通过时，恭喜，您的模型几乎可以添加到 🤗 Transformers 库中了！🎉
- en: 6.-7\. Ensure everyone can use your model
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.-7\. 确保每个人都可以使用您的模型
- en: '**6\. Submit the pull request**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. 提交拉取请求**'
- en: Once you’re done with the implementation and the tests, it’s time to submit
    a pull request. Before pushing your code, run our code formatting utility, `make
    fixup` 🪄. This will automatically fix any formatting issues, which would cause
    our automatic checks to fail.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 完成实现和测试后，现在是提交拉取请求的时候了。在推送代码之前，请运行我们的代码格式化工具 `make fixup` 🪄。这将自动修复任何格式问题，否则会导致我们的自动检查失败。
- en: It’s now time to convert your draft pull request into a real pull request. To
    do so, click on the “Ready for review” button and add Joao (`@gante`) and Matt
    (`@Rocketknight1`) as reviewers. A model pull request will need at least 3 reviewers,
    but they will take care of finding appropriate additional reviewers for your model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是将草稿拉取请求转换为真正拉取请求的时候了。为此，请点击“准备好审查”按钮，并将 Joao (`@gante`) 和 Matt (`@Rocketknight1`)
    添加为审阅者。模型拉取请求将需要至少3名审阅者，但他们会负责为您的模型找到合适的额外审阅者。
- en: After all reviewers are happy with the state of your PR, the final action point
    is to remove the `from_pt=True` flag in `.from_pretrained()` calls. Since there
    are no TensorFlow weights, you will have to add them! Check the section below
    for instructions on how to do it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有审阅者对您的 PR 的状态满意后，最后一个行动点是在 `.from_pretrained()` 调用中移除 `from_pt=True` 标志。由于没有
    TensorFlow 权重，您将需要添加它们！查看下面的部分以获取如何执行此操作的说明。
- en: Finally, when the TensorFlow weights get merged, you have at least 3 reviewer
    approvals, and all CI checks are green, double-check the tests locally one last
    time
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当TensorFlow权重合并时，你至少有3个审阅者的批准，并且所有CI检查都是绿色的时候，最后再本地再次检查测试
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: and we will merge your PR! Congratulations on the milestone 🎉
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将合并你的PR！祝贺你达到的里程碑🎉
- en: '**7\. (Optional) Build demos and share with the world**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\. （可选）构建演示并与世界分享**'
- en: One of the hardest parts about open-source is discovery. How can the other users
    learn about the existence of your fabulous TensorFlow contribution? With proper
    communication, of course! 📣
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 开源项目中最困难的部分之一是发现。其他用户如何了解你出色的TensorFlow贡献的存在？当然是通过适当的沟通！
- en: 'There are two main ways to share your model with the community:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种主要的方法可以与社区分享你的模型：
- en: Build demos. These include Gradio demos, notebooks, and other fun ways to show
    off your model. We highly encourage you to add a notebook to our [community-driven
    demos](https://huggingface.co/docs/transformers/community).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建演示。这些包括Gradio演示、笔记本和其他有趣的方式来展示你的模型。我们强烈鼓励你向我们的[社区驱动演示](https://huggingface.co/docs/transformers/community)添加一个笔记本。
- en: Share stories on social media like Twitter and LinkedIn. You should be proud
    of your work and share your achievement with the community - your model can now
    be used by thousands of engineers and researchers around the world 🌍! We will
    be happy to retweet your posts and help you share your work with the community.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在社交媒体上分享故事，比如Twitter和LinkedIn。你应该为自己的工作感到自豪，并与社区分享你的成就 - 你的模型现在可以被全球数千名工程师和研究人员使用！我们将很乐意转发你的帖子，并帮助你与社区分享你的工作。
- en: Adding TensorFlow weights to 🤗 Hub
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将TensorFlow权重添加到🤗 Hub
- en: Assuming that the TensorFlow model architecture is available in 🤗 Transformers,
    converting PyTorch weights into TensorFlow weights is a breeze!
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 假设TensorFlow模型架构在🤗 Transformers中可用，将PyTorch权重转换为TensorFlow权重将变得轻而易举！
- en: 'Here’s how to do it:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何做到这一点：
- en: Make sure you are logged into your Hugging Face account in your terminal. You
    can log in using the command `huggingface-cli login` (you can find your access
    tokens [here](https://huggingface.co/settings/tokens))
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你已经在终端中登录到你的Hugging Face账户。你可以使用命令`huggingface-cli login`登录（你可以在[这里](https://huggingface.co/settings/tokens)找到你的访问令牌）
- en: Run `transformers-cli pt-to-tf --model-name foo/bar`, where `foo/bar` is the
    name of the model repository containing the PyTorch weights you want to convert
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`transformers-cli pt-to-tf --model-name foo/bar`，其中`foo/bar`是包含你想要转换的PyTorch权重的模型存储库的名称
- en: Tag `@joaogante` and `@Rocketknight1` in the 🤗 Hub PR the command above has
    just created
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在🤗 Hub PR中标记`@joaogante`和`@Rocketknight1`，这是上面命令创建的
- en: That’s it! 🎉
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！
- en: Debugging mismatches across ML frameworks 🐛
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨ML框架调试不匹配🐛
- en: At some point, when adding a new architecture or when creating TensorFlow weights
    for an existing architecture, you might come across errors complaining about mismatches
    between PyTorch and TensorFlow. You might even decide to open the model architecture
    code for the two frameworks, and find that they look identical. What’s going on?
    🤔
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加新架构或为现有架构创建TensorFlow权重时，你可能会遇到关于PyTorch和TensorFlow之间不匹配的错误。你甚至可能决定打开两个框架的模型架构代码，并发现它们看起来是相同的。发生了什么？
- en: First of all, let’s talk about why understanding these mismatches matters. Many
    community members will use 🤗 Transformers models out of the box, and trust that
    our models behave as expected. When there is a large mismatch between the two
    frameworks, it implies that the model is not following the reference implementation
    for at least one of the frameworks. This might lead to silent failures, in which
    the model runs but has poor performance. This is arguably worse than a model that
    fails to run at all! To that end, we aim at having a framework mismatch smaller
    than `1e-5` at all stages of the model.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们谈谈为什么理解这些不匹配很重要。许多社区成员将直接使用🤗 Transformers模型，并相信我们的模型表现如预期。当两个框架之间存在较大的不匹配时，这意味着模型至少在一个框架中没有遵循参考实现。这可能导致悄无声息的失败，即模型运行但性能不佳。这可能比根本无法运行的模型更糟！因此，我们的目标是在模型的所有阶段都有小于`1e-5`的框架不匹配。
- en: 'As in other numerical problems, the devil is in the details. And as in any
    detail-oriented craft, the secret ingredient here is patience. Here is our suggested
    workflow for when you come across this type of issues:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 就像其他数值问题一样，魔鬼就在细节中。就像任何注重细节的工艺一样，耐心是秘密的关键。以下是我们建议的工作流程，当你遇到这种类型的问题时：
- en: Locate the source of mismatches. The model you’re converting probably has near
    identical inner variables up to a certain point. Place `breakpoint()` statements
    in the two frameworks’ architectures, and compare the values of the numerical
    variables in a top-down fashion until you find the source of the problems.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到不匹配的源头。你要转换的模型可能在某个特定点上有几乎相同的内部变量。在两个框架的架构中放置`breakpoint()`语句，并以自上而下的方式比较数值变量的值，直到找到问题的源头。
- en: Now that you’ve pinpointed the source of the issue, get in touch with the 🤗
    Transformers team. It is possible that we’ve seen a similar problem before and
    can promptly provide a solution. As a fallback, scan popular pages like StackOverflow
    and GitHub issues.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经找到了问题的源头，请与🤗 Transformers团队联系。可能我们之前见过类似的问题，并且可以迅速提供解决方案。作为备选方案，浏览像StackOverflow和GitHub问题这样的热门页面。
- en: If there is no solution in sight, it means you’ll have to go deeper. The good
    news is that you’ve located the issue, so you can focus on the problematic instruction,
    abstracting away the rest of the model! The bad news is that you’ll have to venture
    into the source implementation of said instruction. In some cases, you might find
    an issue with a reference implementation - don’t abstain from opening an issue
    in the upstream repository.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果看不到解决方案，这意味着你将不得不深入研究。好消息是你已经找到了问题所在，所以你可以专注于有问题的指令，将模型的其余部分抽象出来！坏消息是你将不得不深入研究该指令的源实现。在某些情况下，你可能会发现参考实现存在问题
    - 不要放弃在上游存储库中开启问题。
- en: In some cases, in discussion with the 🤗 Transformers team, we might find that
    fixing the mismatch is infeasible. When the mismatch is very small in the output
    layers of the model (but potentially large in the hidden states), we might decide
    to ignore it in favor of distributing the model. The `pt-to-tf` CLI mentioned
    above has a `--max-error` flag to override the error message at weight conversion
    time.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，在与🤗 Transformers团队讨论后，我们可能会发现修复不匹配是不可行的。当模型的输出层中不匹配非常小（但在隐藏状态中可能很大）时，我们可能会决定忽略它，以便分发模型。上面提到的`pt-to-tf`
    CLI具有一个`--max-error`标志，可以在权重转换时覆盖错误消息。
