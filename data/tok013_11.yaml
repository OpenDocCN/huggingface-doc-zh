- en: Tokenizer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分词器
- en: 'Original text: [https://huggingface.co/docs/tokenizers/api/tokenizer](https://huggingface.co/docs/tokenizers/api/tokenizer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/tokenizers/api/tokenizer](https://huggingface.co/docs/tokenizers/api/tokenizer)
- en: PythonRustNode
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: PythonRustNode
- en: Tokenizer
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分词器
- en: '### `class tokenizers.Tokenizer`'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.Tokenizer`'
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model))
    — The core algorithm that this `Tokenizer` should be using.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（[Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model)）
    - 此`Tokenizer`应使用的核心算法。'
- en: A `Tokenizer` works as a pipeline. It processes some raw text as input and outputs
    an [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`Tokenizer`作为一个管道工作。它将一些原始文本作为输入进行处理，并输出一个[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)。
- en: property decoder
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 属性解码器
- en: The *optional* `Decoder` in use by the Tokenizer
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器使用的*可选*`Decoder`
- en: property model
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 属性模型
- en: The [Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model)
    in use by the Tokenizer
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器使用的[Model](/docs/tokenizers/v0.13.4.rc2/en/api/models#tokenizers.models.Model)
- en: property normalizer
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 属性规范化器
- en: The *optional* [Normalizer](/docs/tokenizers/v0.13.4.rc2/en/api/normalizers#tokenizers.normalizers.Normalizer)
    in use by the Tokenizer
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器使用的*可选*[Normalizer](/docs/tokenizers/v0.13.4.rc2/en/api/normalizers#tokenizers.normalizers.Normalizer)
- en: property padding
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 属性填充
- en: Returns
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: (`dict`, *optional*)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: （`dict`，*可选*）
- en: A dict with the current padding parameters if padding is enabled
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了填充，则具有当前填充参数的字典
- en: Get the current padding parameters
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 获取当前填充参数
- en: '*Cannot be set, use* `enable_padding()` *instead*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*无法设置，使用* `enable_padding()` *代替*'
- en: property post_processor
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 属性后处理器
- en: The *optional* `PostProcessor` in use by the Tokenizer
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器使用的*可选*`PostProcessor`
- en: property pre_tokenizer
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 属性预分词器
- en: The *optional* [PreTokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/pre-tokenizers#tokenizers.pre_tokenizers.PreTokenizer)
    in use by the Tokenizer
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器使用的*可选*[PreTokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/pre-tokenizers#tokenizers.pre_tokenizers.PreTokenizer)
- en: property truncation
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 属性截断
- en: Returns
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: (`dict`, *optional*)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: （`dict`，*可选*）
- en: A dict with the current truncation parameters if truncation is enabled
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了截断，则具有当前截断参数的字典
- en: Get the currently set truncation parameters
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 获取当前设置的截断参数
- en: '*Cannot set, use* `enable_truncation()` *instead*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*无法设置，使用* `enable_truncation()` *代替*'
- en: '#### `add_special_tokens`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_special_tokens`'
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tokens` (A `List` of [AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)
    or `str`) — The list of special tokens we want to add to the vocabulary. Each
    token can either be a string or an instance of [AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)
    for more customization.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokens`（一个[AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)或`str`的`List`）
    - 我们要添加到词汇表中的特殊令牌列表。每个令牌可以是一个字符串或[AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)的实例，以进行更多自定义。'
- en: Returns
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The number of tokens that were created in the vocabulary
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在词汇表中创建的令牌数
- en: Add the given special tokens to the Tokenizer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将给定的特殊标记添加到分词器中。
- en: If these tokens are already part of the vocabulary, it just let the Tokenizer
    know about them. If they don’t exist, the Tokenizer creates them, giving them
    a new id.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些令牌已经是词汇表的一部分，它只是让分词器知道它们。如果它们不存在，分词器会创建它们，并为它们分配一个新的id。
- en: These special tokens will never be processed by the model (ie won’t be split
    into multiple tokens), and they can be removed from the output when decoding.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特殊标记永远不会被模型处理（即不会被拆分为多个令牌），并且在解码时可以从输出中删除。
- en: '#### `add_tokens`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_tokens`'
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tokens` (A `List` of [AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)
    or `str`) — The list of tokens we want to add to the vocabulary. Each token can
    be either a string or an instance of [AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)
    for more customization.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokens`（一个[AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)或`str`的`List`）
    - 我们要添加到词汇表中的令牌列表。每个令牌可以是一个字符串或[AddedToken](/docs/tokenizers/v0.13.4.rc2/en/api/added-tokens#tokenizers.AddedToken)的实例，以进行更多自定义。'
- en: Returns
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The number of tokens that were created in the vocabulary
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在词汇表中创建的令牌数
- en: Add the given tokens to the vocabulary
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 将给定的令牌添加到词汇表
- en: The given tokens are added only if they don’t already exist in the vocabulary.
    Each token then gets a new attributed id.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 仅当词汇表中不存在这些令牌时才添加给定的令牌。然后，每个令牌都会获得一个新的属性id。
- en: '#### `decode`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`ids` (A `List/Tuple` of `int`) — The list of ids that we want to decode'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ids`（一个`List/Tuple`的`int`） - 我们要解码的id列表'
- en: '`skip_special_tokens` (`bool`, defaults to `True`) — Whether the special tokens
    should be removed from the decoded string'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，默认为`True`） - 是否应从解码字符串中删除特殊标记'
- en: Returns
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The decoded string
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的字符串
- en: Decode the given list of ids back to a string
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 将给定的id列表解码回字符串
- en: This is used to decode anything coming back from a Language Model
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 用于解码从语言模型返回的任何内容
- en: '#### `decode_batch`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode_batch`'
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequences` (`List` of `List[int]`) — The batch of sequences we want to decode'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequences`（`List`的`List[int]`） - 我们要解码的序列批次'
- en: '`skip_special_tokens` (`bool`, defaults to `True`) — Whether the special tokens
    should be removed from the decoded strings'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，默认为`True`） - 是否应从解码字符串中删除特殊标记'
- en: Returns
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: A list of decoded strings
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的字符串列表
- en: Decode a batch of ids back to their corresponding string
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 将一批id解码回其对应的字符串
- en: '#### `enable_padding`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_padding`'
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`direction` (`str`, *optional*, defaults to `right`) — The direction in which
    to pad. Can be either `right` or `left`'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`direction`（`str`，*可选*，默认为`right`） - 填充的方向。可以是`right`或`left`'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If specified, the padding length
    should always snap to the next multiple of the given value. For example if we
    were going to pad witha length of 250 but `pad_to_multiple_of=8` then we will
    pad to 256.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`，*可选*) — 如果指定，填充长度应始终对齐到给定值的下一个倍数。例如，如果我们要填充长度为250，但`pad_to_multiple_of=8`，那么我们将填充到256。'
- en: '`pad_id` (`int`, defaults to 0) — The id to be used when padding'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_id` (`int`，默认为0) — 在填充时要使用的id'
- en: '`pad_type_id` (`int`, defaults to 0) — The type id to be used when padding'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_type_id` (`int`，默认为0) — 在填充时要使用的类型id'
- en: '`pad_token` (`str`, defaults to `[PAD]`) — The pad token to be used when padding'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`，默认为`[PAD]`) — 在填充时要使用的填充标记'
- en: '`length` (`int`, *optional*) — If specified, the length at which to pad. If
    not specified we pad using the size of the longest sequence in a batch.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` (`int`，*可选*) — 如果指定，填充的长度。如果未指定，我们将使用批次中最长序列的大小进行填充。'
- en: Enable the padding
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 启用填充
- en: '#### `enable_truncation`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_truncation`'
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`max_length` (`int`) — The max length at which to truncate'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`) — 截断的最大长度'
- en: '`stride` (`int`, *optional*) — The length of the previous first sequence to
    be included in the overflowing sequence'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`，*可选*) — 要包含在溢出序列中的先前第一个序列的长度'
- en: '`strategy` (`str`, *optional*, defaults to `longest_first`) — The strategy
    used to truncation. Can be one of `longest_first`, `only_first` or `only_second`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strategy` (`str`，*可选*，默认为`longest_first`) — 用于截断的策略。可以是`longest_first`、`only_first`或`only_second`之一。'
- en: '`direction` (`str`, defaults to `right`) — Truncate direction'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`direction` (`str`，默认为`right`) — 截断方向'
- en: Enable truncation
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 启用截断
- en: '#### `encode`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode`'
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequence` (`~tokenizers.InputSequence`) — The main input sequence we want
    to encode. This sequence can be either raw text or pre-tokenized, according to
    the `is_pretokenized` argument:'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequence` (`~tokenizers.InputSequence`) — 我们要编码的主要输入序列。根据`is_pretokenized`参数，此序列可以是原始文本或预标记的：'
- en: 'If `is_pretokenized=False`: `TextInputSequence`'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`is_pretokenized=False`：`TextInputSequence`
- en: 'If `is_pretokenized=True`: `PreTokenizedInputSequence()`'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`is_pretokenized=True`：`PreTokenizedInputSequence()`
- en: '`pair` (`~tokenizers.InputSequence`, *optional*) — An optional input sequence.
    The expected format is the same that for `sequence`.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pair`（`~tokenizers.InputSequence`，*可选*） — 一个可选的输入序列。期望的格式与`sequence`相同。'
- en: '`is_pretokenized` (`bool`, defaults to `False`) — Whether the input is already
    pre-tokenized'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_pretokenized` (`bool`，默认为`False`) — 输入是否已经预标记'
- en: '`add_special_tokens` (`bool`, defaults to `True`) — Whether to add the special
    tokens'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`，默认为`True`) — 是否添加特殊标记'
- en: Returns
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)'
- en: The encoded result
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 编码结果
- en: Encode the given sequence and pair. This method can process raw text sequences
    as well as already pre-tokenized sequences.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定的序列和对进行编码。此方法可以处理原始文本序列以及已经预标记的序列。
- en: 'Example:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'Here are some examples of the inputs that are accepted:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些被接受的输入示例：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `encode_batch`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_batch`'
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input` (A `List`/``Tuple` of `~tokenizers.EncodeInput`) — A list of single
    sequences or pair sequences to encode. Each sequence can be either raw text or
    pre-tokenized, according to the `is_pretokenized` argument:'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`（`List`/`Tuple` of `~tokenizers.EncodeInput`） — 要编码的单个序列或对序列的列表。每个序列可以是原始文本或根据`is_pretokenized`参数进行预标记：'
- en: 'If `is_pretokenized=False`: `TextEncodeInput()`'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`is_pretokenized=False`：`TextEncodeInput()`
- en: 'If `is_pretokenized=True`: `PreTokenizedEncodeInput()`'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`is_pretokenized=True`：`PreTokenizedEncodeInput()`
- en: '`is_pretokenized` (`bool`, defaults to `False`) — Whether the input is already
    pre-tokenized'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_pretokenized` (`bool`，默认为`False`) — 输入是否已经预标记'
- en: '`add_special_tokens` (`bool`, defaults to `True`) — Whether to add the special
    tokens'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`，默认为`True`) — 是否添加特殊标记'
- en: Returns
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A `List` of [`~tokenizers.Encoding“]
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[`~tokenizers.Encoding`]的`List`
- en: The encoded batch
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 编码的批次
- en: Encode the given batch of inputs. This method accept both raw text sequences
    as well as already pre-tokenized sequences.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定的输入批次进行编码。此方法接受原始文本序列以及已经预标记的序列。
- en: 'Example:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'Here are some examples of the inputs that are accepted:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些被接受的输入示例：
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `from_buffer`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_buffer`'
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`buffer` (`bytes`) — A buffer containing a previously serialized [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`buffer` (`bytes`) — 包含先前序列化的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)的缓冲区'
- en: Returns
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
- en: The new tokenizer
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 新的分词器
- en: Instantiate a new [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    from the given buffer.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定缓冲区实例化一个新的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)。
- en: '#### `from_file`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_file`'
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`path` (`str`) — A path to a local JSON file representing a previously serialized
    [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path` (`str`) — 表示先前序列化的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)的本地JSON文件的路径'
- en: Returns
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
- en: The new tokenizer
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 新的分词器
- en: Instantiate a new [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    from the file at the given path.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定路径的文件实例化一个新的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)。
- en: '#### `from_pretrained`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`identifier` (`str`) — The identifier of a Model on the Hugging Face Hub, that
    contains a tokenizer.json file'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`identifier` (`str`) — Hugging Face Hub上模型的标识符，其中包含一个tokenizer.json文件'
- en: '`revision` (`str`, defaults to *main*) — A branch or commit id'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`，默认为*main*) — 分支或提交ID'
- en: '`auth_token` (`str`, *optional*, defaults to *None*) — An optional auth token
    used to access private repositories on the Hugging Face Hub'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auth_token` (`str`，*可选*，默认为*None*) — 用于访问Hugging Face Hub上私有存储库的可选身份验证令牌'
- en: Returns
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
- en: The new tokenizer
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 新的分词器
- en: Instantiate a new [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    from an existing file on the Hugging Face Hub.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 从Hugging Face Hub上的现有文件实例化一个新的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)。
- en: '#### `from_str`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_str`'
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`json` (`str`) — A valid JSON string representing a previously serialized [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`json` (`str`) — 代表先前序列化的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)的有效JSON字符串'
- en: Returns
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)'
- en: The new tokenizer
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 新的分词器
- en: Instantiate a new [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    from the given JSON string.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定的JSON字符串实例化一个新的[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)。
- en: '#### `get_vocab`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_vocab`'
- en: '[PRE15]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`with_added_tokens` (`bool`, defaults to `True`) — Whether to include the added
    tokens'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`with_added_tokens` (`bool`，默认为`True`) — 是否包括添加的标记'
- en: Returns
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, int]`'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, int]`'
- en: The vocabulary
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇表
- en: Get the underlying vocabulary
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 获取底层词汇表
- en: '#### `get_vocab_size`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_vocab_size`'
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`with_added_tokens` (`bool`, defaults to `True`) — Whether to include the added
    tokens'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`with_added_tokens` (`bool`，默认为`True`) — 是否包括添加的标记'
- en: Returns
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: The size of the vocabulary
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇表的大小
- en: Get the size of the underlying vocabulary
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 获取底层词汇表的大小
- en: '#### `id_to_token`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `id_to_token`'
- en: '[PRE17]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`id` (`int`) — The id to convert'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` (`int`) — 要转换的id'
- en: Returns
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Optional[str]`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`Optional[str]`'
- en: An optional token, `None` if out of vocabulary
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可选的标记，如果超出词汇表则为`None`
- en: Convert the given id to its corresponding token if it exists
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在，将给定的id转换为相应的标记
- en: '#### `no_padding`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `no_padding`'
- en: '[PRE18]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Disable padding
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用填充
- en: '#### `no_truncation`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `no_truncation`'
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Disable truncation
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用截断
- en: '#### `num_special_tokens_to_add`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `num_special_tokens_to_add`'
- en: '[PRE20]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Return the number of special tokens that would be added for single/pair sentences.
    :param is_pair: Boolean indicating if the input would be a single sentence or
    a pair :return:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '返回单/配对句子将添加的特殊标记数量。:param is_pair: 指示输入是单个句子还是一对的布尔值 :return:'
- en: '#### `post_process`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process`'
- en: '[PRE21]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`encoding` ([Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding))
    — The [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
    corresponding to the main sequence.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoding` ([Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding))
    — 对应于主序列的[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)。'
- en: '`pair` ([Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding),
    *optional*) — An optional [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
    corresponding to the pair sequence.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pair` ([Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)，*可选*)
    — 与配对序列对应的可选[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)。'
- en: '`add_special_tokens` (`bool`) — Whether to add the special tokens'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`) — 是否添加特殊标记'
- en: Returns
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)'
- en: The final post-processed encoding
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的后处理编码
- en: Apply all the post-processing steps to the given encodings.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定的编码应用所有后处理步骤。
- en: 'The various steps are:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 各个步骤是：
- en: Truncate according to the set truncation params (provided with `enable_truncation()`)
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据设置的截断参数截断（使用`enable_truncation()`提供）
- en: Apply the `PostProcessor`
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用`PostProcessor`
- en: Pad according to the set padding params (provided with `enable_padding()`)
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据设置的填充参数填充（使用`enable_padding()`提供）
- en: '#### `save`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save`'
- en: '[PRE22]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`path` (`str`) — A path to a file in which to save the serialized tokenizer.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path` (`str`) — 要保存序列化分词器的文件路径。'
- en: '`pretty` (`bool`, defaults to `True`) — Whether the JSON file should be pretty
    formatted.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretty` (`bool`，默认为`True`) — JSON文件是否应该格式化。'
- en: Save the [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    to the file at the given path.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 将[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)保存到给定路径的文件中。
- en: '#### `to_str`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_str`'
- en: '[PRE23]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretty` (`bool`, defaults to `False`) — Whether the JSON string should be
    pretty formatted.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretty` (`bool`，默认为`False`) — JSON字符串是否应该格式化。'
- en: Returns
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: A string representing the serialized Tokenizer
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 表示序列化Tokenizer的字符串
- en: Gets a serialized string representing this [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 获取表示此[Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)的序列化字符串。
- en: '#### `token_to_id`'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `token_to_id`'
- en: '[PRE24]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token` (`str`) — The token to convert'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`) — 要转换的标记'
- en: Returns
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Optional[int]`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`Optional[int]`'
- en: An optional id, `None` if out of vocabulary
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可选的id，如果超出词汇表则为`None`
- en: Convert the given token to its corresponding id if it exists
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在，将给定的标记转换为相应的id
- en: '#### `train`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `train`'
- en: '[PRE25]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`files` (`List[str]`) — A list of path to the files that we should use for
    training'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`files` (`List[str]`) — 应该用于训练的文件路径列表'
- en: '`trainer` (`~tokenizers.trainers.Trainer`, *optional*) — An optional trainer
    that should be used to train our Model'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainer` (`~tokenizers.trainers.Trainer`，*可选*) — 应该用于训练我们的模型的可选训练器'
- en: Train the Tokenizer using the given files.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定的文件训练Tokenizer。
- en: Reads the files line by line, while keeping all the whitespace, even new lines.
    If you want to train from data store in-memory, you can check `train_from_iterator()`
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 逐行读取文件，保留所有空格，甚至包括换行符。如果要从内存中存储的数据进行训练，可以查看`train_from_iterator()`
- en: '#### `train_from_iterator`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `train_from_iterator`'
- en: '[PRE26]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`iterator` (`Iterator`) — Any iterator over strings or list of strings'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterator` (`Iterator`) — 任何字符串或字符串列表的迭代器'
- en: '`trainer` (`~tokenizers.trainers.Trainer`, *optional*) — An optional trainer
    that should be used to train our Model'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainer` (`~tokenizers.trainers.Trainer`，*可选*) — 应该用于训练我们的模型的可选训练器'
- en: '`length` (`int`, *optional*) — The total number of sequences in the iterator.
    This is used to provide meaningful progress tracking'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` (`int`, *可选*) — 迭代器中序列的总数。这用于提供有意义的进度跟踪'
- en: Train the Tokenizer using the provided iterator.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提供的迭代器训练分词器。
- en: You can provide anything that is a Python Iterator
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以提供任何Python迭代器
- en: A list of sequences `List[str]`
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个序列的列表`List[str]`
- en: A generator that yields `str` or `List[str]`
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个生成器，产生`str`或`List[str]`
- en: A Numpy array of strings
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串的Numpy数组
- en: …
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: …
