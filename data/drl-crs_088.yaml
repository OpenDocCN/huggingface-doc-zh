- en: An introduction to Multi-Agents Reinforcement Learning (MARL)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多代理强化学习（MARL）简介
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit7/introduction-to-marl](https://huggingface.co/learn/deep-rl-course/unit7/introduction-to-marl)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/learn/deep-rl-course/unit7/introduction-to-marl](https://huggingface.co/learn/deep-rl-course/unit7/introduction-to-marl)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: From single agent to multiple agents
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从单一代理到多个代理
- en: 'In the first unit, we learned to train agents in a single-agent system. When
    our agent was alone in its environment: **it was not cooperating or collaborating
    with other agents**.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个单元中，我们学习了如何在单一代理系统中训练代理。当我们的代理在环境中独自一人时：**它并不是在与其他代理合作或协作**。
- en: '![Patchwork](../Images/0bfa9643ea17c46664be61fcfb3e7a48.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![拼图](../Images/0bfa9643ea17c46664be61fcfb3e7a48.png)'
- en: A patchwork of all the environments you've trained your agents on since the
    beginning of the course
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一个由你在课程开始以来训练你的代理的所有环境拼凑而成的图案
- en: When we do multi-agents reinforcement learning (MARL), we are in a situation
    where we have multiple agents **that share and interact in a common environment**.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行多代理强化学习（MARL）时，我们处于一个情况，其中我们有多个代理**共享并在一个共同的环境中互动**。
- en: For instance, you can think of a warehouse where **multiple robots need to navigate
    to load and unload packages**.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以想象一个仓库，**多个机器人需要导航以装载和卸载包裹**。
- en: '![Warehouse](../Images/2e1d606f26899a2b71fe8753420674f7.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![仓库](../Images/2e1d606f26899a2b71fe8753420674f7.png)'
- en: '[Image by upklyak](https://www.freepik.com/free-vector/robots-warehouse-interior-automated-machines_32117680.htm#query=warehouse
    robot&position=17&from_view=keyword) on Freepik'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源：upklyak](https://www.freepik.com/free-vector/robots-warehouse-interior-automated-machines_32117680.htm#query=warehouse
    robot&position=17&from_view=keyword)'
- en: Or a road with **several autonomous vehicles**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 或者一条有**多辆自动驾驶车辆**的道路。
- en: '![Self driving cars](../Images/df2e97029db297cd2432fa0827f04c5d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![自动驾驶汽车](../Images/df2e97029db297cd2432fa0827f04c5d.png)'
- en: '[Image by jcomp](https://www.freepik.com/free-vector/autonomous-smart-car-automatic-wireless-sensor-driving-road-around-car-autonomous-smart-car-goes-scans-roads-observe-distance-automatic-braking-system_26413332.htm#query=self
    driving cars highway&position=34&from_view=search&track=ais) on Freepik'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源：jcomp](https://www.freepik.com/free-vector/autonomous-smart-car-automatic-wireless-sensor-driving-road-around-car-autonomous-smart-car-goes-scans-roads-observe-distance-automatic-braking-system_26413332.htm#query=self
    driving cars highway&position=34&from_view=search&track=ais)'
- en: In these examples, we have **multiple agents interacting in the environment
    and with the other agents**. This implies defining a multi-agents system. But
    first, let’s understand the different types of multi-agent environments.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些例子中，我们有**多个代理在环境中互动并与其他代理互动**。这意味着定义一个多代理系统。但首先，让我们了解不同类型的多代理环境。
- en: Different types of multi-agent environments
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同类型的多代理环境
- en: 'Given that, in a multi-agent system, agents interact with other agents, we
    can have different types of environments:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于在多代理系统中，代理与其他代理互动，我们可以有不同类型的环境：
- en: '*Cooperative environments*: where your agents need **to maximize the common
    benefits**.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*合作环境*：在这种环境中，你的代理需要**最大化共同利益**。'
- en: For instance, in a warehouse, **robots must collaborate to load and unload the
    packages efficiently (as fast as possible)**.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一个仓库中，**机器人必须合作以高效地装载和卸载包裹（尽快地）**。
- en: '*Competitive/Adversarial environments*: in this case, your agent **wants to
    maximize its benefits by minimizing the opponent’s**.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*竞争/对抗环境*：在这种情况下，你的代理**希望通过最小化对手的利益来最大化自己的利益**。'
- en: For example, in a game of tennis, **each agent wants to beat the other agent**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一场网球比赛中，**每个代理都希望击败另一个代理**。
- en: '![Tennis](../Images/614a5ed542429a87559635bca3dc68a4.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![网球](../Images/614a5ed542429a87559635bca3dc68a4.png)'
- en: '*Mixed of both adversarial and cooperative*: like in our SoccerTwos environment,
    two agents are part of a team (blue or purple): they need to cooperate with each
    other and beat the opponent team.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*既有对抗性又有合作性*：就像在我们的SoccerTwos环境中，两个代理是一个团队的一部分（蓝色或紫色）：他们需要彼此合作并击败对手团队。'
- en: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
- en: This environment was made by the [Unity MLAgents Team](https://github.com/Unity-Technologies/ml-agents)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个环境是由[Unity MLAgents团队](https://github.com/Unity-Technologies/ml-agents)创建的
- en: 'So now we might wonder: how can we design these multi-agent systems? Said differently,
    **how can we train agents in a multi-agent setting** ?'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么现在我们可能会想：我们如何设计这些多代理系统呢？换句话说，**我们如何在多代理设置中训练代理**？
