- en: Inferentia Exporter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Inferentia导出器
- en: 'Original text: [https://huggingface.co/docs/optimum-neuron/package_reference/export](https://huggingface.co/docs/optimum-neuron/package_reference/export)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/optimum-neuron/package_reference/export](https://huggingface.co/docs/optimum-neuron/package_reference/export)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: You can export a PyTorch model to Neuron with 🤗 Optimum to run inference on
    AWS [Inferntia 1](https://aws.amazon.com/ec2/instance-types/inf1/) and [Inferentia
    2](https://aws.amazon.com/ec2/instance-types/inf2/).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用🤗 Optimum将PyTorch模型导出到Neuron，以在AWS上运行推理[Inferntia 1](https://aws.amazon.com/ec2/instance-types/inf1/)和[Inferentia
    2](https://aws.amazon.com/ec2/instance-types/inf2/)。
- en: Export functions
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出函数
- en: There is an export function for each generation of the Inferentia accelerator,
    `export_neuron` for INF1 and `export_neuronx` on INF2, but you will be able to
    use directly the export function `export`, which will select the proper exporting
    function according to the environment.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 每一代Inferentia加速器都有一个导出函数，`export_neuron`用于INF1，`export_neuronx`用于INF2，但您可以直接使用导出函数`export`，它会根据环境选择适当的导出函数。
- en: Besides, you can check if the exported model is valid via `validate_model_outputs`,
    which compares the compiled model’s output on Neuron devices to the PyTorch model’s
    output on CPU.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以通过`validate_model_outputs`检查导出的模型是否有效，该函数会比较Neuron设备上编译模型的输出与PyTorch模型在CPU上的输出。
- en: Supported architectures
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持的架构
- en: '| Architecture | Task |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 架构 | 任务 |'
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| ALBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| ALBERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| BERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| BERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| BLOOM | text-generation |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| BLOOM | 文本生成 |'
- en: '| CamemBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| CamemBERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| ConvBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| ConvBERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| DeBERTa (INF2 only) | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| DeBERTa (仅限INF2) | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| DeBERTa-v2 (INF2 only) | feature-extraction, fill-mask, multiple-choice,
    question-answering, text-classification, token-classification |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| DeBERTa-v2 (仅限INF2) | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| DistilBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| ELECTRA | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| ELECTRA | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| FlauBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| FlauBERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| GPT2 | text-generation |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| GPT2 | 文本生成 |'
- en: '| Llama, Llama 2 | text-generation |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Llama, Llama 2 | 文本生成 |'
- en: '| Mistral | text-generation |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| Mistral | 文本生成 |'
- en: '| MobileBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| MobileBERT | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| MPNet | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| MPNet | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| OPT | text-generation |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| OPT | 文本生成 |'
- en: '| RoBERTa | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| RoFormer | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| RoFormer | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| XLM | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| XLM | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| XLM-RoBERTa | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| XLM-RoBERTa | 特征提取，填充掩码，多项选择，问答，文本分类，标记分类 |'
- en: '| Stable Diffusion | text-to-image, image-to-image, inpaint |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Stable Diffusion | 文本到图像，图像到图像，修复 |'
- en: '| Stable Diffusion XL Base | text-to-image, image-to-image, inpaint |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Stable Diffusion XL Base | 文本到图像，图像到图像，修复 |'
- en: '| Stable Diffusion XL Refiner | image-to-image, inpaint |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Stable Diffusion XL Refiner | 图像到图像，修复 |'
- en: More details for checking supported tasks [here](https://huggingface.co/docs/optimum-neuron/guides/export_model#selecting-a-task).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 更多检查支持任务的详细信息[在此处](https://huggingface.co/docs/optimum-neuron/guides/export_model#selecting-a-task)。
- en: More architectures coming soon, stay tuned! 🚀
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 更多架构即将推出，敬请关注！🚀
