- en: Wuerstchen
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Wuerstchen
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/wuerstchen](https://huggingface.co/docs/diffusers/training/wuerstchen)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/wuerstchen](https://huggingface.co/docs/diffusers/training/wuerstchen)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The [Wuerstchen](https://hf.co/papers/2306.00637) model drastically reduces
    computational costs by compressing the latent space by 42x, without compromising
    image quality and accelerating inference. During training, Wuerstchen uses two
    models (VQGAN + autoencoder) to compress the latents, and then a third model (text-conditioned
    latent diffusion model) is conditioned on this highly compressed space to generate
    an image.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wuerstchen](https://hf.co/papers/2306.00637)æ¨¡å‹é€šè¿‡å°†æ½œåœ¨ç©ºé—´å‹ç¼©42å€ï¼Œå¤§å¹…é™ä½è®¡ç®—æˆæœ¬ï¼Œè€Œä¸å½±å“å›¾åƒè´¨é‡å¹¶åŠ é€Ÿæ¨ç†ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒWuerstchenä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹ï¼ˆVQGAN
    + è‡ªåŠ¨ç¼–ç å™¨ï¼‰æ¥å‹ç¼©æ½œåœ¨ç©ºé—´ï¼Œç„¶åç¬¬ä¸‰ä¸ªæ¨¡å‹ï¼ˆæ–‡æœ¬æ¡ä»¶æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰åœ¨è¿™ä¸ªé«˜åº¦å‹ç¼©çš„ç©ºé—´ä¸Šè¿›è¡Œæ¡ä»¶ç”Ÿæˆå›¾åƒã€‚'
- en: To fit the prior model into GPU memory and to speedup training, try enabling
    `gradient_accumulation_steps`, `gradient_checkpointing`, and `mixed_precision`
    respectively.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†å…ˆéªŒæ¨¡å‹é€‚é…åˆ°GPUå†…å­˜å¹¶åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œè¯·å°è¯•åˆ†åˆ«å¯ç”¨`gradient_accumulation_steps`ã€`gradient_checkpointing`å’Œ`mixed_precision`ã€‚
- en: This guide explores the [train_text_to_image_prior.py](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—æ¢è®¨äº†[train_text_to_image_prior.py](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)è„šæœ¬ï¼Œä»¥å¸®åŠ©æ‚¨æ›´ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºè‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨ä»æºä»£ç å®‰è£…åº“ï¼š
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then navigate to the example folder containing the training script and install
    the required dependencies for the script youâ€™re using:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶ä¸ºæ‚¨æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬å®‰è£…æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ğŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Accelerateæ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ªGPU/TPUä¸Šè¿›è¡Œè®­ç»ƒæˆ–ä½¿ç”¨æ··åˆç²¾åº¦çš„åº“ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤— Accelerate
    [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šã€‚
- en: 'Initialize an ğŸ¤— Accelerate environment:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–ğŸ¤— Accelerateç¯å¢ƒï¼š
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default ğŸ¤— Accelerate environment without choosing any configurations:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è®¾ç½®é»˜è®¤çš„ğŸ¤— Accelerateç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesnâ€™t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼shellï¼Œæ¯”å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºä¸€ä¸ªé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚
- en: The following sections highlight parts of the training scripts that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the [script](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)
    in detail. If youâ€™re interested in learning more, feel free to read through the
    scripts and let us know if you have any questions or concerns.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹éƒ¨åˆ†çªå‡ºäº†è®­ç»ƒè„šæœ¬ä¸­é‡è¦çš„éƒ¨åˆ†ï¼Œä»¥ä¾¿äº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»è„šæœ¬ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬æ‚¨æ˜¯å¦æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚
- en: Script parameters
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è„šæœ¬å‚æ•°
- en: The training scripts provides many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L192)
    function. It provides default values for each parameter, such as the training
    batch size and learning rate, but you can also set your own values in the training
    command if youâ€™d like.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°ï¼Œä»¥å¸®åŠ©æ‚¨è‡ªå®šä¹‰è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L192)å‡½æ•°ä¸­æ‰¾åˆ°ã€‚å®ƒä¸ºæ¯ä¸ªå‚æ•°æä¾›äº†é»˜è®¤å€¼ï¼Œå¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚
- en: 'For example, to speedup training with mixed precision using the fp16 format,
    add the `--mixed_precision` parameter to the training command:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨fp16æ ¼å¼åŠ é€Ÿè®­ç»ƒï¼Œè¯·åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--mixed_precision`å‚æ•°ï¼š
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Most of the parameters are identical to the parameters in the [Text-to-image](text2image#script-parameters)
    training guide, so letâ€™s dive right into the Wuerstchen training script!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°å‚æ•°ä¸[æ–‡æœ¬åˆ°å›¾åƒ](text2image#script-parameters)è®­ç»ƒæŒ‡å—ä¸­çš„å‚æ•°ç›¸åŒï¼Œå› æ­¤è®©æˆ‘ä»¬ç›´æ¥è¿›å…¥Wuerstchenè®­ç»ƒè„šæœ¬ï¼
- en: Training script
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬
- en: The training script is also similar to the [Text-to-image](text2image#training-script)
    training guide, but itâ€™s been modified to support Wuerstchen. This guide focuses
    on the code that is unique to the Wuerstchen training script.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬ä¹Ÿç±»ä¼¼äº[æ–‡æœ¬åˆ°å›¾åƒ](text2image#training-script)è®­ç»ƒæŒ‡å—ï¼Œä½†å·²ç»ä¿®æ”¹ä»¥æ”¯æŒWuerstchenã€‚æœ¬æŒ‡å—é‡ç‚¹ä»‹ç»äº†ä¸Wuerstchenè®­ç»ƒè„šæœ¬ç‹¬æœ‰çš„ä»£ç ã€‚
- en: The [`main()`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L441)
    function starts by initializing the image encoder - an [EfficientNet](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/modeling_efficient_net_encoder.py)
    - in addition to the usual scheduler and tokenizer.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[`main()`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L441)å‡½æ•°é¦–å…ˆé€šè¿‡åˆå§‹åŒ–å›¾åƒç¼–ç å™¨
    - ä¸€ä¸ª[EfficientNet](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/modeling_efficient_net_encoder.py)
    - ä»¥åŠé€šå¸¸çš„è°ƒåº¦ç¨‹åºå’Œæ ‡è®°å™¨æ¥å¼€å§‹ã€‚'
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Youâ€™ll also load the `WuerstchenPrior` model for optimization.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å°†åŠ è½½`WuerstchenPrior`æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, youâ€™ll apply some [transforms](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)
    to the images and [tokenize](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L637)
    the captions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæ‚¨å°†å¯¹å›¾åƒåº”ç”¨ä¸€äº›[è½¬æ¢](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)ï¼Œå¹¶[æ ‡è®°åŒ–](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L637)æ ‡é¢˜ï¼š
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, the [training loop](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)
    handles compressing the images to latent space with the `EfficientNetEncoder`,
    adding noise to the latents, and predicting the noise residual with the `WuerstchenPrior`
    model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)å¤„ç†å°†å›¾åƒå‹ç¼©åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œä½¿ç”¨`EfficientNetEncoder`å‘æ½œåœ¨ç©ºé—´æ·»åŠ å™ªå£°ï¼Œå¹¶ä½¿ç”¨`WuerstchenPrior`æ¨¡å‹é¢„æµ‹å™ªå£°æ®‹å·®ã€‚
- en: '[PRE9]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers](../using-diffusers/write_own_pipeline) tutorial
    which breaks down the basic pattern of the denoising process.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[äº†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨](../using-diffusers/write_own_pipeline)æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è¯¦ç»†ä»‹ç»äº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚
- en: Launch the script
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯åŠ¨è„šæœ¬
- en: Once youâ€™ve made all your changes or youâ€™re okay with the default configuration,
    youâ€™re ready to launch the training script! ğŸš€
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨å®Œæˆæ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€
- en: Set the `DATASET_NAME` environment variable to the dataset name from the Hub.
    This guide uses the [PokÃ©mon BLIP captions](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)
    dataset, but you can create and train on your own datasets as well (see the [Create
    a dataset for training](create_dataset) guide).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å°†`DATASET_NAME`ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºHubä¸­çš„æ•°æ®é›†åç§°ã€‚æœ¬æŒ‡å—ä½¿ç”¨[PokÃ©mon BLIP captions](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)æ•°æ®é›†ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥åˆ›å»ºå’Œè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼ˆè¯·å‚é˜…[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼‰ã€‚
- en: To monitor training progress with Weights & Biases, add the `--report_to=wandb`
    parameter to the training command. Youâ€™ll also need to add the `--validation_prompt`
    to the training command to keep track of results. This can be really useful for
    debugging the model and viewing intermediate results.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨Weights & Biasesç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œè¯·åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--report_to=wandb`å‚æ•°ã€‚æ‚¨è¿˜éœ€è¦åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--validation_prompt`ä»¥è·Ÿè¸ªç»“æœã€‚è¿™å¯¹äºè°ƒè¯•æ¨¡å‹å’ŒæŸ¥çœ‹ä¸­é—´ç»“æœéå¸¸æœ‰ç”¨ã€‚
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once training is complete, you can use your newly trained model for inference!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next steps
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥
- en: 'Congratulations on training a Wuerstchen model! To learn more about how to
    use your new model, the following may be helpful:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥è´ºæ‚¨è®­ç»ƒäº†ä¸€ä¸ªWuerstchenæ¨¡å‹ï¼è¦äº†è§£å¦‚ä½•ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š
- en: Take a look at the [Wuerstchen](../api/pipelines/wuerstchen#text-to-image-generation)
    API documentation to learn more about how to use the pipeline for text-to-image
    generation and its limitations.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[Wuerstchen](../api/pipelines/wuerstchen#text-to-image-generation) APIæ–‡æ¡£ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“åŠå…¶é™åˆ¶ã€‚
