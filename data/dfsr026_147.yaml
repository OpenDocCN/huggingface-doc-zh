- en: Kandinsky 2.2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kandinsky 2.2
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/kandinsky_v22](https://huggingface.co/docs/diffusers/api/pipelines/kandinsky_v22)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/kandinsky_v22](https://huggingface.co/docs/diffusers/api/pipelines/kandinsky_v22)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Kandinsky 2.2 is created by [Arseniy Shakhmatov](https://github.com/cene555),
    [Anton Razzhigaev](https://github.com/razzant), [Aleksandr Nikolich](https://github.com/AlexWortega),
    [Vladimir Arkhipkin](https://github.com/oriBetelgeuse), [Igor Pavlov](https://github.com/boomb0om),
    [Andrey Kuznetsov](https://github.com/kuznetsoffandrey), and [Denis Dimitrov](https://github.com/denndimitrov).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.2 由 [Arseniy Shakhmatov](https://github.com/cene555)、[Anton Razzhigaev](https://github.com/razzant)、[Aleksandr
    Nikolich](https://github.com/AlexWortega)、[Vladimir Arkhipkin](https://github.com/oriBetelgeuse)、[Igor
    Pavlov](https://github.com/boomb0om)、[Andrey Kuznetsov](https://github.com/kuznetsoffandrey)
    和 [Denis Dimitrov](https://github.com/denndimitrov) 创建。
- en: 'The description from it’s GitHub page is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 其 GitHub 页面的描述为：
- en: '*Kandinsky 2.2 brings substantial improvements upon its predecessor, Kandinsky
    2.1, by introducing a new, more powerful image encoder - CLIP-ViT-G and the ControlNet
    support. The switch to CLIP-ViT-G as the image encoder significantly increases
    the model’s capability to generate more aesthetic pictures and better understand
    text, thus enhancing the model’s overall performance. The addition of the ControlNet
    mechanism allows the model to effectively control the process of generating images.
    This leads to more accurate and visually appealing outputs and opens new possibilities
    for text-guided image manipulation.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*Kandinsky 2.2 在其前身 Kandinsky 2.1 的基础上带来了实质性的改进，引入了一个新的、更强大的图像编码器 - CLIP-ViT-G
    和 ControlNet 支持。将 CLIP-ViT-G 作为图像编码器显著增加了模型生成更美观图片和更好理解文本的能力，从而提升了模型的整体性能。ControlNet
    机制的添加使模型能够有效地控制生成图像的过程。这导致更准确和视觉上吸引人的输出，并为文本引导的图像操作开辟了新的可能性。*'
- en: The original codebase can be found at [ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可在 [ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2)
    找到。
- en: Check out the [Kandinsky Community](https://huggingface.co/kandinsky-community)
    organization on the Hub for the official model checkpoints for tasks like text-to-image,
    image-to-image, and inpainting.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 Hub 上的 [Kandinsky Community](https://huggingface.co/kandinsky-community)
    组织，获取官方模型检查点，用于文本到图像、图像到图像和修补等任务。
- en: Make sure to check out the schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保查看调度器的 [指南](../../using-diffusers/schedulers) 以了解如何探索调度器速度和质量之间的权衡，并查看 [跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)
    部分，以了解如何有效地将相同组件加载到多个管道中。
- en: KandinskyV22PriorPipeline
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22PriorPipeline
- en: '### `class diffusers.KandinskyV22PriorPipeline`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22PriorPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py#L84)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py#L84)'
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入近似图像嵌入的标准 unCLIP 先验。'
- en: '`image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`CLIPTokenizer`) — 类 [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)
    的分词器。'
- en: '`scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination with
    `prior` to generate image embedding.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (`UnCLIPScheduler`) — 与 `prior` 结合使用的调度器，用于生成图像嵌入。'
- en: '`image_processor` (`CLIPImageProcessor`) — A image_processor to be used to
    preprocess image from clip.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` (`CLIPImageProcessor`) — 用于从 clip 预处理图像的 image_processor。'
- en: Pipeline for generating image prior for Kandinsky
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成 Kandinsky 图像先验的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py#L370)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py#L370)'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`) — 用于引导图像生成的提示或提示。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于引导图像生成的提示或提示。如果不使用引导（即如果
    `guidance_scale` 小于 `1`），则忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个 [torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html) 用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 如 [无分类器扩散引导](https://arxiv.org/abs/2207.12598)
    中定义的引导比例。`guidance_scale` 定义为 [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)
    中方程式 2 的 `w`。通过设置 `guidance_scale > 1` 启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`output_type` (`str`, *optional*, defaults to `"pt"`) — The output format of
    the generate image. Choose between: `"np"` (`np.array`) or `"pt"` (`torch.Tensor`).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pt"`) — 生成图像的输出格式。可选择 `"np"` (`np.array`)
    或 `"pt"` (`torch.Tensor`)。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是普通的元组。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *可选*) — 在推断过程中每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`
    将包括由 `callback_on_step_end_tensor_inputs` 指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *可选*) — `callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: Returns
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`KandinskyPriorPipelineOutput` or `tuple`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`KandinskyPriorPipelineOutput` 或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `interpolate`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `interpolate`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py#L131)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py#L131)'
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images_and_prompts` (`List[Union[str, PIL.Image.Image, torch.FloatTensor]]`)
    — list of prompts and images to guide the image generation. weights — (`List[float]`):
    list of weights for each condition in `images_and_prompts`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images_and_prompts` (`List[Union[str, PIL.Image.Image, torch.FloatTensor]]`)
    — 用于引导图像生成的提示和图像列表。权重 — (`List[float]`): `images_and_prompts` 中每个条件的权重列表'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但推断速度较慢。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个 [torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html) 用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`negative_prior_prompt` (`str`, *optional*) — The prompt not to guide the prior
    diffusion process. Ignored when not using guidance (i.e., ignored if `guidance_scale`
    is less than `1`).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prior_prompt` (`str`, *可选*) — 不用来引导先前扩散过程的提示。如果不使用引导（即如果 `guidance_scale`
    小于 `1`，则忽略）。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt not to guide
    the image generation. Ignored when not using guidance (i.e., ignored if `guidance_scale`
    is less than `1`).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用来引导图像生成的提示。如果不使用引导（即如果 `guidance_scale`
    小于 `1`，则忽略）。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale`（`float`，*可选*，默认为4.0）— 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。
    `guidance_scale`被定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式2的`w`。通过设置`guidance_scale
    > 1`启用引导比例。更高的引导比例鼓励生成与文本`prompt`紧密相关的图像，通常以降低图像质量为代价。'
- en: Returns
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`KandinskyPriorPipelineOutput` or `tuple`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`KandinskyPriorPipelineOutput`或`tuple`'
- en: Function invoked when using the prior pipeline for interpolation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用先前的管道进行插值时调用的函数。
- en: 'Examples:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: KandinskyV22Pipeline
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22Pipeline
- en: '### `class diffusers.KandinskyV22Pipeline`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22Pipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2.py#L64)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2.py#L64)'
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（Union[`DDIMScheduler`,`DDPMScheduler`]）— 与`unet`结合使用的调度器以生成图像潜在特征。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)）—
    用于降噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq`（[VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel)）—
    MoVQ解码器，用于从潜在特征生成图像。'
- en: Pipeline for text-to-image generation using Kandinsky
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用Kandinsky进行文本到图像生成的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存，运行在特定设备上等）。
- en: '#### `__call__`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2.py#L122)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2.py#L122)'
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds`（`torch.FloatTensor`或`List[torch.FloatTensor]`）— 用于文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds`（`torch.FloatTensor`或`List[torch.FloatTensor]`）— 用于负文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height`（`int`，*可选*，默认为512）— 生成图像的高度（以像素为单位）。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width`（`int`，*可选*，默认为512）— 生成图像的宽度（以像素为单位）。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`（`int`，*可选*，默认为100）— 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale`（`float`，*可选*，默认为4.0）— 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。
    `guidance_scale`被定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式2的`w`。通过设置`guidance_scale
    > 1`启用引导比例。更高的引导比例鼓励生成与文本`prompt`紧密相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`（`int`，*可选*，默认为1）— 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`或`List[torch.Generator]`，*可选*）— 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents`（`torch.FloatTensor`，*可选*）— 预先生成的噪声潜在特征，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，将使用提供的随机`generator`进行采样生成潜在特征。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type`（`str`，*可选*，默认为`"pil"`）— 生成图像的输出格式。可选择：`"pil"`（`PIL.Image.Image`），`"np"`（`np.array`）或`"pt"`（`torch.Tensor`）。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *可选*) — 在推断期间每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`
    将包含由 `callback_on_step_end_tensor_inputs` 指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *可选*) — `callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: Returns
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用生成管道时调用的函数。
- en: 'Examples:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: KandinskyV22CombinedPipeline
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22CombinedPipeline
- en: '### `class diffusers.KandinskyV22CombinedPipeline`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22CombinedPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L107)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L107)'
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 与 `unet` 结合使用的调度器，用于生成图像潜变量。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件 U-Net 架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜变量生成图像的 MoVQ 解码器。'
- en: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入逼近图像嵌入的标准 unCLIP 先验。'
- en: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`prior_tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_tokenizer` (`CLIPTokenizer`) — 类 [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)
    的分词器。'
- en: '`prior_scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination
    with `prior` to generate image embedding.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_scheduler` (`UnCLIPScheduler`) — 与 `prior` 结合使用的调度器，用于生成图像嵌入。'
- en: '`prior_image_processor` (`CLIPImageProcessor`) — A image_processor to be used
    to preprocess image from clip.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_processor` (`CLIPImageProcessor`) — 用于从 clip 预处理图像的图像处理器。'
- en: Combined Pipeline for text-to-image generation using Kandinsky
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kandinsky 进行文本到图像生成的组合管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L201)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L201)'
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`) — 用于指导图像生成的提示或提示。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *可选*) — 不用于指导图像生成的提示或提示。如果不使用指导（即如果
    `guidance_scale` 小于 `1`），则忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推断速度。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 512) — 生成图像的像素宽度。'
- en: '`prior_guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale
    as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_guidance_scale` (`float`, *optional*, 默认为 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`
    定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程 2 的 `w`。通过设置 `guidance_scale
    > 1` 启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`prior_num_inference_steps` (`int`, *optional*, defaults to 100) — The number
    of denoising steps. More denoising steps usually lead to a higher quality image
    at the expense of slower inference.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_num_inference_steps` (`int`, *optional*, 默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但推理速度会变慢。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认为 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`
    定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程 2 的 `w`。通过设置 `guidance_scale
    > 1` 启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 一个或多个[torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 预生成的噪声潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同的生成。如果未提供，将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为 `"pil"`) — 生成图像的输出格式。可选择 `"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为 `True`) — 是否返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是普通元组。'
- en: '`prior_callback_on_step_end` (`Callable`, *optional*) — A function that calls
    at the end of each denoising steps during the inference of the prior pipeline.
    The function is called with the following arguments: `prior_callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_callback_on_step_end` (`Callable`, *optional*) — 在先验管道推理期间的每个降噪步骤结束时调用的函数。该函数将使用以下参数调用：`prior_callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。'
- en: '`prior_callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list
    of tensor inputs for the `prior_callback_on_step_end` function. The tensors specified
    in the list will be passed as `callback_kwargs` argument. You will only be able
    to include variables listed in the `._callback_tensor_inputs` attribute of your
    prior pipeline class.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_callback_on_step_end_tensor_inputs` (`List`, *optional*) — `prior_callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在您的先验管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference of the decoder pipeline.
    The function is called with the following arguments: `callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs`
    will include a list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) — 在解码器管道推理期间的每个降噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`
    将包括由 `callback_on_step_end_tensor_inputs` 指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — `callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在您的管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: Returns
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道生成时调用的函数。
- en: 'Examples:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L181)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L181)'
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Offloads all models to CPU using accelerate, significantly reducing memory usage.
    When called, unet, text_encoder, vae and safety checker have their state dicts
    saved to CPU and then are moved to a `torch.device('meta') and loaded to GPU only
    when their specific submodule has its` forward`method called. Note that offloading
    happens on a submodule basis. Memory savings are higher than with`enable_model_cpu_offload`,
    but performance is lower.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有模型转移到CPU，显著减少内存使用。调用时，unet、text_encoder、vae和safety checker的状态字典被保存到CPU，然后移动到`torch.device('meta')，仅在特定子模块的`forward`方法被调用时加载到GPU。请注意，转移是基于子模块的。与`enable_model_cpu_offload`相比，内存节省更多，但性能较低。
- en: KandinskyV22ControlnetPipeline
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22ControlnetPipeline
- en: '### `class diffusers.KandinskyV22ControlnetPipeline`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22ControlnetPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet.py#L106)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet.py#L106)'
- en: '[PRE12]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `unet` to generate image latents.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — 与`unet`一起使用的调度器，用于生成图像潜变量。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于降噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ解码器，用于从潜变量生成图像。'
- en: Pipeline for text-to-image generation using Kandinsky
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行文本到图像生成的流水线
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有流水线实现的通用方法（如下载或保存，运行在特定设备上等）。
- en: '#### `__call__`'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet.py#L151)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet.py#L151)'
- en: '[PRE13]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str`或`List[str]`) — 用于指导图像生成的提示或提示。'
- en: '`hint` (`torch.FloatTensor`) — The controlnet condition.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hint` (`torch.FloatTensor`) — 控制网络条件。'
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor`或`List[torch.FloatTensor]`) — 用于条件图像生成的clip图像嵌入。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor`或`List[torch.FloatTensor]`) — 用于负文本提示的clip图像嵌入，将用于条件图像生成。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`或`List[str]`, *可选*) — 不用于指导图像生成的提示或提示。如果不使用指导（即如果`guidance_scale`小于`1`，则忽略）。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*，默认为512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*，默认为512) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*，默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*，默认为4.0) — 在[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2的`w`。通过设置`guidance_scale > 1`来启用指导比例。更高的指导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*，默认为1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`List[torch.Generator]`, *可选*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，使生成具有确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可以用不同的提示调整相同的生成。如果未提供，将使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。可选择的值包括：`"pil"`（`PIL.Image.Image`）、`"np"`（`np.array`）或`"pt"`（`torch.Tensor`）。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推理过程中每`callback_steps`步调用的函数。该函数使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为1) — 调用`callback`函数的频率。如果未指定，则在每一步调用回调。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 调用生成流水线时调用的函数。
- en: 'Examples:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: KandinskyV22PriorEmb2EmbPipeline
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22PriorEmb2EmbPipeline
- en: '### `class diffusers.KandinskyV22PriorEmb2EmbPipeline`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22PriorEmb2EmbPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py#L102)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py#L102)'
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入近似图像嵌入的标准unCLIP先验。'
- en: '`image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`CLIPTokenizer`) — 类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination with
    `prior` to generate image embedding.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (`UnCLIPScheduler`) — 与`prior`结合使用以生成图像嵌入的调度器。'
- en: Pipeline for generating image prior for Kandinsky
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成Kandinsky图像先验的流水线
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有流水线实现的通用方法（如下载或保存，运行在特定设备上等）。
- en: '#### `__call__`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py#L396)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py#L396)'
- en: '[PRE15]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`) — 用于指导图像生成的提示或提示。'
- en: '`strength` (`float`, *optional*, defaults to 0.8) — Conceptually, indicates
    how much to transform the reference `emb`. Must be between 0 and 1\. `image` will
    be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *可选*, 默认为0.8) — 在概念上，指示要转换参考`emb`的程度。必须介于0和1之间。`image`将被用作起点，添加更多噪音会使`strength`越大。降噪步骤的数量取决于最初添加的噪音量。'
- en: '`emb` (`torch.FloatTensor`) — The image embedding.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`emb` (`torch.FloatTensor`) — 图像嵌入。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于指导图像生成的提示或提示。如果不使用指导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，以使生成过程确定性。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*，默认为4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2的`w`。通过设置`guidance_scale > 1`来启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`output_type` (`str`, *optional*, defaults to `"pt"`) — The output format of
    the generate image. Choose between: `"np"` (`np.array`) or `"pt"` (`torch.Tensor`).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`，*可选*，默认为`"pt"`) — 生成图像的输出格式。选择在`"np"`（`np.array`）和`"pt"`（`torch.Tensor`）之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*，默认为`True`) — 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`KandinskyPriorPipelineOutput` or `tuple`'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`KandinskyPriorPipelineOutput`或元组'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道生成时调用的函数。
- en: 'Examples:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#### `interpolate`'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `插值`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py#L155)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py#L155)'
- en: '[PRE17]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images_and_prompts` (`List[Union[str, PIL.Image.Image, torch.FloatTensor]]`)
    — list of prompts and images to guide the image generation. weights — (`List[float]`):
    list of weights for each condition in `images_and_prompts`'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images_and_prompts` (`List[Union[str, PIL.Image.Image, torch.FloatTensor]]`)
    — 用于指导图像生成的提示和图像列表。权重 — (`List[float]`): `images_and_prompts`中每个条件的权重列表'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`，*可选*，默认为1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`，*可选*，默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`List[torch.Generator]`，*可选*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`，*可选*) — 预先生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则将通过使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`negative_prior_prompt` (`str`, *optional*) — The prompt not to guide the prior
    diffusion process. Ignored when not using guidance (i.e., ignored if `guidance_scale`
    is less than `1`).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prior_prompt` (`str`，*可选*) — 不指导先前扩散过程的提示。如果不使用引导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt not to guide
    the image generation. Ignored when not using guidance (i.e., ignored if `guidance_scale`
    is less than `1`).'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`或`List[str]`，*可选*) — 不指导图像生成的提示。如果不使用引导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`，*可选*，默认为4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2的`w`。通过设置`guidance_scale > 1`来启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: Returns
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`KandinskyPriorPipelineOutput` or `tuple`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`KandinskyPriorPipelineOutput`或元组'
- en: Function invoked when using the prior pipeline for interpolation.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用先前管道进行插值时调用的函数。
- en: 'Examples:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE18]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: KandinskyV22Img2ImgPipeline
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22Img2ImgPipeline
- en: '### `class diffusers.KandinskyV22Img2ImgPipeline`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22Img2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_img2img.py#L92)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_img2img.py#L92)'
- en: '[PRE19]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `unet` to generate image latents.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — 与`unet`结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ解码器，用于从潜变量生成图像。'
- en: Pipeline for image-to-image generation using Kandinsky
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行图像到图像生成的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_img2img.py#L190)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[< 源代码 >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_img2img.py#L190)'
- en: '[PRE20]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) — 用于文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process. Can also
    accept image latents as `image`, if passing latents directly, it will not be encoded
    again.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`、`PIL.Image.Image`、`np.ndarray`、`List[torch.FloatTensor]`、`List[PIL.Image.Image]`
    或 `List[np.ndarray]`) — 作为过程起点使用的 `Image` 或表示图像批次的张量。如果直接传递潜在变量，则不会再次编码。'
- en: '`strength` (`float`, *optional*, defaults to 0.8) — Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *可选*, 默认为 0.8) — 在概念上，指示要转换参考 `image` 的程度。必须介于 0 和 1 之间。`image`
    将被用作起点，添加的噪声越大，`strength` 越大。降噪步骤的数量取决于最初添加的噪声量。当 `strength` 为 1 时，添加的噪声将达到最大值，并且降噪过程将运行指定的
    `num_inference_steps` 的全部迭代次数。因此，值为 1 的情况下，基本上忽略了 `image`。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) —
    用于负文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 512) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 在 [无分类器扩散引导](https://arxiv.org/abs/2207.12598)
    中定义的引导比例。`guidance_scale` 定义为 [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)
    中方程式 2 的 `w`。通过设置 `guidance_scale > 1` 启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个 [torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html) 以使生成结果确定性。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。可选择 `"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回一个 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是一个普通元组。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *可选*) — 在推理期间每个降噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`
    将包含由 `callback_on_step_end_tensor_inputs` 指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *可选*) — `callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在您的管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: Returns
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道以进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: KandinskyV22Img2ImgCombinedPipeline
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22Img2ImgCombinedPipeline
- en: '### `class diffusers.KandinskyV22Img2ImgCombinedPipeline`'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22Img2ImgCombinedPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L334)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L334)'
- en: '[PRE21]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 用于与`unet`结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜变量生成图像的MoVQ解码器。'
- en: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入近似图像嵌入的规范unCLIP先验。'
- en: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`prior_tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_tokenizer` (`CLIPTokenizer`) — 类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`prior_scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination
    with `prior` to generate image embedding.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_scheduler` (`UnCLIPScheduler`) — 用于与`prior`结合使用以生成图像嵌入的调度器。'
- en: '`prior_image_processor` (`CLIPImageProcessor`) — A image_processor to be used
    to preprocess image from clip.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_processor` (`CLIPImageProcessor`) — 用于从clip预处理图像的图像处理器。'
- en: Combined Pipeline for image-to-image generation using Kandinsky
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行图像生成的组合管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L438)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L438)'
- en: '[PRE22]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`) — 用于指导图像生成的提示。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process. Can also
    accept image latents as `image`, if passing latents directly, it will not be encoded
    again.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — 作为过程起点使用的`Image`或表示图像批次的张量。如果直接传递潜变量，则不会再次编码。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *可选*) — 不用来指导图像生成的提示。如果不使用指导（即如果`guidance_scale`小于`1`），则忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为4.0) — 如[Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2的`w`。通过设置`guidance_scale > 1`启用指导比例。更高的指导比例鼓励生成与文本`prompt`紧密相关的图像，通常以降低图像质量为代价。'
- en: '`strength` (`float`, *optional*, defaults to 0.3) — Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *可选*, 默认为0.3) — 在概念上，指示要转换参考`image`的程度。必须介于0和1之间。`image`将被用作起点，添加的噪声越大，`strength`越大。去噪步骤的数量取决于最初添加的噪声量。当`strength`为1时，添加的噪声将是最大的，去噪过程将运行指定的`num_inference_steps`的完整迭代次数。因此，值为1基本上忽略了`image`。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*, 默认为512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*, 默认为512) — 生成图像的像素宽度。'
- en: '`prior_guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale
    as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_guidance_scale` (`float`, *optional*, 默认为4.0) — 如[Classifier-Free Diffusion
    Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale` 定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2中的`w`。通过设置 `guidance_scale > 1`
    来启用指导比例。更高的指导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`prior_num_inference_steps` (`int`, *optional*, defaults to 100) — The number
    of denoising steps. More denoising steps usually lead to a higher quality image
    at the expense of slower inference.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_num_inference_steps` (`int`, *optional*, 默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)列表，使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 预先生成的嘈杂潜在变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则将使用提供的随机`generator`进行采样生成潜在变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。可选择：`"pil"` (`PIL.Image.Image`)，`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 在推理过程中每`callback_steps`步调用的函数。该函数调用以下参数：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, 默认为1) — 调用`callback`函数的频率。如果未指定，则在每一步调用回调函数。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为`True`) — 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 调用生成管道时调用的函数。
- en: 'Examples:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE23]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '#### `enable_model_cpu_offload`'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_model_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L408)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L408)'
- en: '[PRE24]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Offloads all models to CPU using accelerate, reducing memory usage with a low
    impact on performance. Compared to `enable_sequential_cpu_offload`, this method
    moves one whole model at a time to the GPU when its `forward` method is called,
    and the model remains in GPU until the next model runs. Memory savings are lower
    than with `enable_sequential_cpu_offload`, but performance is much better due
    to the iterative execution of the `unet`.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速将所有模型转移到CPU，减少内存使用量，对性能影响较小。与`enable_sequential_cpu_offload`相比，此方法在调用其`forward`方法时将整个模型一次性移至GPU，并且模型保持在GPU中，直到下一个模型运行。与`enable_sequential_cpu_offload`相比，内存节省较少，但由于`unet`的迭代执行，性能要好得多。
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L418)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L418)'
- en: '[PRE25]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Offloads all models to CPU using accelerate, significantly reducing memory usage.
    When called, unet, text_encoder, vae and safety checker have their state dicts
    saved to CPU and then are moved to a `torch.device('meta') and loaded to GPU only
    when their specific submodule has its` forward`method called. Note that offloading
    happens on a submodule basis. Memory savings are higher than with`enable_model_cpu_offload`,
    but performance is lower.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速将所有模型转移到CPU，显著减少内存使用量。调用时，`unet`、`text_encoder`、`vae`和`safety checker`的状态字典保存到CPU，然后移至`torch.device('meta')`，仅在其特定子模块调用`forward`方法时加载到GPU。请注意，卸载是基于子模块的。与`enable_model_cpu_offload`相比，内存节省更高，但性能较低。
- en: KandinskyV22ControlnetImg2ImgPipeline
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22ControlnetImg2ImgPipeline
- en: '### `class diffusers.KandinskyV22ControlnetImg2ImgPipeline`'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22ControlnetImg2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet_img2img.py#L120)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet_img2img.py#L120)'
- en: '[PRE26]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `unet` to generate image latents.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — 用于与`unet`结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜变量生成图像的MoVQ解码器。'
- en: Pipeline for image-to-image generation using Kandinsky
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行图像生成的流程
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有流程实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet_img2img.py#L206)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet_img2img.py#L206)'
- en: '[PRE27]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) — 用于文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process. Can also
    accept image latents as `image`, if passing latents directly, it will not be encoded
    again.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 作为过程起点使用的`Image`或表示图像批次的张量。如果直接传递潜变量作为`image`，则不会再次编码。'
- en: '`strength` (`float`, *optional*, defaults to 0.8) — Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *可选*, 默认为0.8) — 在概念上，指示要转换参考`image`的程度。必须在0和1之间。`image`将被用作起点，添加的噪音越大，`strength`越大。去噪步骤的数量取决于最初添加的噪音量。当`strength`为1时，添加的噪音将达到最大值，并且去噪过程将运行指定的`num_inference_steps`的全部迭代次数。因此，值为1基本上忽略了`image`。'
- en: '`hint` (`torch.FloatTensor`) — The controlnet condition.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hint` (`torch.FloatTensor`) — 控制网络条件。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) —
    用于负文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为512) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式2的`w`。通过设置`guidance_scale > 1`启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。可选择：`"pil"` (`PIL.Image.Image`)，`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 在推理过程中每隔 `callback_steps` 步调用一次的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, 默认为 1) — 调用 `callback` 函数的频率。如果未指定，则在每一步都会调用回调函数。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为 `True`) — 是否返回一个 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是一个普通的元组。'
- en: Returns
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道生成时调用的函数。
- en: 'Examples:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: KandinskyV22InpaintPipeline
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22InpaintPipeline
- en: '### `class diffusers.KandinskyV22InpaintPipeline`'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22InpaintPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_inpainting.py#L235)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_inpainting.py#L235)'
- en: '[PRE28]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `unet` to generate image latents.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — 用于与 `unet` 结合使用以生成图像潜在空间的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于降噪图像嵌入的条件 U-Net 架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ 解码器，用于从潜在空间生成图像。'
- en: Pipeline for text-guided image inpainting using Kandinsky2.1
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kandinsky2.1 进行文本引导图像修复的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_inpainting.py#L294)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_inpainting.py#L294)'
- en: '[PRE29]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) — 用于文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`image` (`PIL.Image.Image`) — `Image`, or tensor representing an image batch
    which will be inpainted, *i.e.* parts of the image will be masked out with `mask_image`
    and repainted according to `prompt`.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`PIL.Image.Image`) — `Image`，或表示图像批次的张量，将被修复，即图像的部分将被用 `mask_image`
    掩盖并根据 `prompt` 重新绘制。'
- en: '`mask_image` (`np.array`) — Tensor representing an image batch, to mask `image`.
    White pixels in the mask will be repainted, while black pixels will be preserved.
    If `mask_image` is a PIL image, it will be converted to a single channel (luminance)
    before use. If it’s a tensor, it should contain one color channel (L) instead
    of 3, so the expected shape would be `(B, H, W, 1)`.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`np.array`) — 表示图像批次的张量，用于遮罩 `image`。遮罩中的白色像素将被重新绘制，而黑色像素将被保留。如果
    `mask_image` 是一个 PIL 图像，它将在使用之前转换为单通道（亮度）。如果它是一个张量，则应该包含一个颜色通道（L）而不是 3 个，因此预期的形状将是
    `(B, H, W, 1)`。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) —
    用于负文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*, 默认为 512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*, 默认为 512) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认为 4.0) — 在 [Classifier-Free Diffusion
    Guidance](https://arxiv.org/abs/2207.12598) 中定义的指导尺度。`guidance_scale` 被定义为 [Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf) 中方程式 2 的 `w`。通过设置 `guidance_scale
    > 1` 来启用指导尺度。更高的指导尺度鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 预生成的嘈杂潜在变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，将使用提供的随机`generator`进行采样生成潜在变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。可选择`"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`) 或`"pt"` (`torch.Tensor`)。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为`True`) — 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) — 在推断过程中每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`将包括由`callback_on_step_end_tensor_inputs`指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — 用于`callback_on_step_end`函数的张量输入列表。列表中指定的张量将作为`callback_kwargs`参数传递。您只能包含在管道类的`._callback_tensor_inputs`属性中列出的变量。'
- en: Returns
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: KandinskyV22InpaintCombinedPipeline
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyV22InpaintCombinedPipeline
- en: '### `class diffusers.KandinskyV22InpaintCombinedPipeline`'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyV22InpaintCombinedPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L582)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L582)'
- en: '[PRE30]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 用于与`unet`结合使用的调度器以生成图像潜在变量。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜在变量生成图像的MoVQ解码器。'
- en: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入近似图像嵌入的标准unCLIP先验。'
- en: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`prior_tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_tokenizer` (`CLIPTokenizer`) — 类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`prior_scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination
    with `prior` to generate image embedding.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_scheduler` (`UnCLIPScheduler`) — 用于与`prior`结合使用的调度器以生成图像嵌入。'
- en: '`prior_image_processor` (`CLIPImageProcessor`) — A image_processor to be used
    to preprocess image from clip.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_processor` (`CLIPImageProcessor`) — 用于预处理来自clip的图像的图像处理器。'
- en: Combined Pipeline for inpainting generation using Kandinsky
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行修复生成的组合管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L676)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L676)'
- en: '[PRE31]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`) — 用于指导图像生成的提示或提示。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process. Can also
    accept image latents as `image`, if passing latents directly, it will not be encoded
    again.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 代表图像批次的`Image`或张量，将被用作过程的起点。如果直接传递潜在图像，则也可以接受图像潜在作为`image`，那么它将不会再次被编码。'
- en: '`mask_image` (`np.array`) — Tensor representing an image batch, to mask `image`.
    White pixels in the mask will be repainted, while black pixels will be preserved.
    If `mask_image` is a PIL image, it will be converted to a single channel (luminance)
    before use. If it’s a tensor, it should contain one color channel (L) instead
    of 3, so the expected shape would be `(B, H, W, 1)`.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`np.array`) — 代表图像批次的张量，用于遮罩`image`。遮罩中的白色像素将被重新绘制，而黑色像素将被保留。如果`mask_image`是PIL图像，则在使用之前将其转换为单通道（亮度）。如果它是张量，则应该包含一个颜色通道（L）而不是3，因此预期形状将是`(B,
    H, W, 1)`。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用来引导图像生成的提示或提示。当不使用引导时被忽略（即如果`guidance_scale`小于`1`，则被忽略）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为4.0) — 如[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2的`w`。通过设置`guidance_scale > 1`启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但推理速度较慢。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为512) — 生成图像的像素宽度。'
- en: '`prior_guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale
    as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_guidance_scale` (`float`, *可选*, 默认为4.0) — 如[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程2的`w`。通过设置`guidance_scale > 1`启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`prior_num_inference_steps` (`int`, *optional*, defaults to 100) — The number
    of denoising steps. More denoising steps usually lead to a higher quality image
    at the expense of slower inference.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_num_inference_steps` (`int`, *可选*, 默认为100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但推理速度较慢。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的噪声潜在图像，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则将使用提供的随机`generator`进行采样生成潜在张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。可选择：`"pil"`（`PIL.Image.Image`）、`"np"`（`np.array`）或`"pt"`（`torch.Tensor`）。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: '`prior_callback_on_step_end` (`Callable`, *optional*) — A function that calls
    at the end of each denoising steps during the inference. The function is called
    with the following arguments: `prior_callback_on_step_end(self: DiffusionPipeline,
    step: int, timestep: int, callback_kwargs: Dict)`.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_callback_on_step_end` (`Callable`, *可选*) — 在推理过程中每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`prior_callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。'
- en: '`prior_callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list
    of tensor inputs for the `prior_callback_on_step_end` function. The tensors specified
    in the list will be passed as `callback_kwargs` argument. You will only be able
    to include variables listed in the `._callback_tensor_inputs` attribute of your
    pipeline class.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_callback_on_step_end_tensor_inputs` (`List`, *optional*) — `prior_callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在您的管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) — 在推理过程中每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`
    将包含由 `callback_on_step_end_tensor_inputs` 指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — `callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在您的管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: Returns
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用生成管道时调用的函数。
- en: 'Examples:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE32]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L656)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py#L656)'
- en: '[PRE33]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Offloads all models to CPU using accelerate, significantly reducing memory usage.
    When called, unet, text_encoder, vae and safety checker have their state dicts
    saved to CPU and then are moved to a `torch.device('meta') and loaded to GPU only
    when their specific submodule has its` forward`method called. Note that offloading
    happens on a submodule basis. Memory savings are higher than with`enable_model_cpu_offload`,
    but performance is lower.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有模型转移到 CPU，显着减少内存使用。调用时，unet、text_encoder、vae 和 safety checker 的状态字典将保存到
    CPU，然后移动到 `torch.device('meta')`，仅在它们特定的子模块调用`forward`方法时才加载到 GPU。请注意，卸载是基于子模块的。与`enable_model_cpu_offload`
    相比，内存节省更高，但性能较低。
