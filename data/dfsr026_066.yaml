- en: Textual Inversion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本反转
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Textual Inversion](https://hf.co/papers/2208.01618) is a training technique
    for personalizing image generation models with just a few example images of what
    you want it to learn. This technique works by learning and updating the text embeddings
    (the new embeddings are tied to a special word you must use in the prompt) to
    match the example images you provide.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Textual Inversion](https://hf.co/papers/2208.01618)是一种训练技术，用于个性化图像生成模型，只需提供几个示例图像，让模型学习。该技术通过学习和更新文本嵌入（新嵌入与您在提示中必须使用的特殊单词相关联）来匹配您提供的示例图像。'
- en: If you’re training on a GPU with limited vRAM, you should try enabling the `gradient_checkpointing`
    and `mixed_precision` parameters in the training command. You can also reduce
    your memory footprint by using memory-efficient attention with [xFormers](../optimization/xformers).
    JAX/Flax training is also supported for efficient training on TPUs and GPUs, but
    it doesn’t support gradient checkpointing or xFormers. With the same configuration
    and setup as PyTorch, the Flax training script should be at least ~70% faster!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在具有有限vRAM的GPU上进行训练，您应该尝试在训练命令中启用`gradient_checkpointing`和`mixed_precision`参数。您还可以通过使用[xFormers](../optimization/xformers)的内存高效注意力来减少内存占用。JAX/Flax训练也支持在TPU和GPU上进行高效训练，但不支持梯度检查点或xFormers。与PyTorch相同的配置和设置，Flax训练脚本应至少快约70%！
- en: This guide will explore the [textual_inversion.py](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将探讨[textual_inversion.py](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)脚本，帮助您更熟悉它，并了解如何为自己的用例进行调整。
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行脚本之前，请确保您从源代码安装库：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Navigate to the example folder with the training script and install the required
    dependencies for the script you’re using:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到包含训练脚本的示例文件夹，并安装您正在使用的脚本所需的依赖项：
- en: PyTorchFlax
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 🤗 Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. It’ll automatically configure your training setup based on your
    hardware and environment. Take a look at the 🤗 Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Accelerate是一个库，可以帮助您在多个GPU/TPU上进行训练，或者使用混合精度。它将根据您的硬件和环境自动配置您的训练设置。查看🤗 Accelerate
    [快速入门](https://huggingface.co/docs/accelerate/quicktour)以了解更多信息。
- en: 'Initialize an 🤗 Accelerate environment:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化🤗 Accelerate环境：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default 🤗 Accelerate environment without choosing any configurations:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置默认的🤗 Accelerate环境而不选择任何配置：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesn’t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您的环境不支持交互式shell，比如笔记本，您可以使用：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您想在自己的数据集上训练模型，请查看[创建用于训练的数据集](create_dataset)指南，了解如何创建适用于训练脚本的数据集。
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesn’t cover every aspect of the script
    in detail. If you’re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)
    and let us know if you have any questions or concerns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分突出显示了训练脚本的重要部分，有助于了解如何修改它，但并未详细涵盖脚本的每个方面。如果您有兴趣了解更多，请随时阅读[脚本](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)，如果您有任何问题或疑虑，请告诉我们。
- en: Script parameters
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚本参数
- en: The training script has many parameters to help you tailor the training run
    to your needs. All of the parameters and their descriptions are listed in the
    [`parse_args()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L176)
    function. Where applicable, Diffusers provides default values for each parameter
    such as the training batch size and learning rate, but feel free to change these
    values in the training command if you’d like.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本有许多参数，可帮助您根据需要定制训练运行。所有参数及其描述都列在[`parse_args()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L176)函数中。在适用的情况下，Diffusers为每个参数提供默认值，如训练批量大小和学习率，但如果您愿意，可以在训练命令中更改这些值。
- en: 'For example, to increase the number of gradient accumulation steps above the
    default value of 1:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要增加梯度累积步数，超过默认值1：
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Some other basic and important parameters to specify include:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他基本和重要的参数需要指定：
- en: '`--pretrained_model_name_or_path`: the name of the model on the Hub or a local
    path to the pretrained model'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--pretrained_model_name_or_path`: Hub上模型的名称或预训练模型的本地路径'
- en: '`--train_data_dir`: path to a folder containing the training dataset (example
    images)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--train_data_dir`: 指向包含训练数据集（例如图像）的文件夹路径'
- en: '`--output_dir`: where to save the trained model'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_dir`: 保存训练模型的位置'
- en: '`--push_to_hub`: whether to push the trained model to the Hub'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--push_to_hub`: 是否将训练好的模型推送到Hub'
- en: '`--checkpointing_steps`: frequency of saving a checkpoint as the model trains;
    this is useful if for some reason training is interrupted, you can continue training
    from that checkpoint by adding `--resume_from_checkpoint` to your training command'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--checkpointing_steps`: 保存检查点的频率，当模型训练时；如果由于某种原因训练中断，您可以通过在训练命令中添加`--resume_from_checkpoint`来从该检查点继续训练'
- en: '`--num_vectors`: the number of vectors to learn the embeddings with; increasing
    this parameter helps the model learn better but it comes with increased training
    costs'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_vectors`：要学习嵌入的向量数量；增加此参数有助于模型学习更好，但会增加训练成本'
- en: '`--placeholder_token`: the special word to tie the learned embeddings to (you
    must use the word in your prompt for inference)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--placeholder_token`：将学习的嵌入与之关联的特殊单词（您必须在推理中使用该单词）'
- en: '`--initializer_token`: a single-word that roughly describes the object or style
    you’re trying to train on'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--initializer_token`：大致描述您要训练的对象或风格的单词'
- en: '`--learnable_property`: whether you’re training the model to learn a new “style”
    (for example, Van Gogh’s painting style) or “object” (for example, your dog)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--learnable_property`：您是否正在训练模型学习新的“风格”（例如，梵高的绘画风格）或“对象”（例如，您的狗）'
- en: Training script
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练脚本
- en: Unlike some of the other training scripts, textual_inversion.py has a custom
    dataset class, [`TextualInversionDataset`](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L487)
    for creating a dataset. You can customize the image size, placeholder token, interpolation
    method, whether to crop the image, and more. If you need to change how the dataset
    is created, you can modify `TextualInversionDataset`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他一些训练脚本不同，textual_inversion.py具有一个自定义数据集类，[`TextualInversionDataset`](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L487)用于创建数据集。您可以自定义图像大小、占位符标记、插值方法、是否裁剪图像等。如果您需要更改数据集的创建方式，可以修改`TextualInversionDataset`。
- en: Next, you’ll find the dataset preprocessing code and training loop in the [`main()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L573)
    function.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将在[`main()`](https://github.com/huggingface/diffusers/blob/839c2a5ece0af4e75530cb520d77bc7ed8acf474/examples/textual_inversion/textual_inversion.py#L573)函数中找到数据集预处理代码和训练循环。
- en: 'The script starts by loading the [tokenizer](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L616),
    [scheduler and model](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L622):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本首先加载[tokenizer](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L616)、[scheduler和model](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L622)：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The special [placeholder token](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L632)
    is added next to the tokenizer, and the embedding is readjusted to account for
    the new token.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来在tokenizer旁边添加特殊的[占位符标记](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L632)，并调整嵌入以考虑新标记。
- en: 'Then, the script [creates a dataset](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L716)
    from the `TextualInversionDataset`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，脚本从`TextualInversionDataset`中[创建数据集](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L716)：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finally, the [training loop](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L784)
    handles everything else from predicting the noisy residual to updating the embedding
    weights of the special placeholder token.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，[训练循环](https://github.com/huggingface/diffusers/blob/b81c69e489aad3a0ba73798c459a33990dc4379c/examples/textual_inversion/textual_inversion.py#L784)处理从预测嘈杂残差到更新特殊占位符标记的嵌入权重的所有其他内容。
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers](../using-diffusers/write_own_pipeline) tutorial
    which breaks down the basic pattern of the denoising process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解训练循环的工作原理，请查看[理解管道、模型和调度器](../using-diffusers/write_own_pipeline)教程，该教程解释了去噪过程的基本模式。
- en: Launch the script
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动脚本
- en: Once you’ve made all your changes or you’re okay with the default configuration,
    you’re ready to launch the training script! 🚀
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您完成了所有更改或对默认配置满意，您就可以启动训练脚本了！🚀
- en: For this guide, you’ll download some images of a [cat toy](https://huggingface.co/datasets/diffusers/cat_toy_example)
    and store them in a directory. But remember, you can create and use your own dataset
    if you want (see the [Create a dataset for training](create_dataset) guide).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本指南，您将下载一些[猫玩具的图像](https://huggingface.co/datasets/diffusers/cat_toy_example)并将它们存储在一个目录中。但请记住，如果您愿意，您可以创建并使用自己的数据集（请参阅[创建用于训练的数据集](create_dataset)指南）。
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set the environment variable `MODEL_NAME` to a model id on the Hub or a path
    to a local model, and `DATA_DIR` to the path where you just downloaded the cat
    images to. The script creates and saves the following files to your repository:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 将环境变量`MODEL_NAME`设置为Hub上的模型ID或本地模型的路径，并将`DATA_DIR`设置为您刚下载猫图像的路径。脚本将以下文件创建并保存到您的存储库中：
- en: '`learned_embeds.bin`: the learned embedding vectors corresponding to your example
    images'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learned_embeds.bin`：与您的示例图像对应的学习嵌入向量'
- en: '`token_identifier.txt`: the special placeholder token'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_identifier.txt`：特殊的占位符标记'
- en: '`type_of_concept.txt`: the type of concept you’re training on (either “object”
    or “style”)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_of_concept.txt`：您正在训练的概念类型（“对象”或“风格”）'
- en: A full training run takes ~1 hour on a single V100 GPU.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个V100 GPU上进行完整的训练需要约1小时。
- en: 'One more thing before you launch the script. If you’re interested in following
    along with the training process, you can periodically save generated images as
    training progresses. Add the following parameters to the training command:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动脚本之前还有一件事。如果您有兴趣跟踪训练过程，您可以在训练过程中定期保存生成的图像。将以下参数添加到训练命令中：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: PyTorchFlax
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After training is complete, you can use your newly trained model for inference
    like:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，您可以像这样使用您新训练的模型进行推理：
- en: PyTorchFlax
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorchFlax
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next steps
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: 'Congratulations on training your own Textual Inversion model! 🎉 To learn more
    about how to use your new model, the following guides may be helpful:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您训练出自己的文本反转模型！🎉 要了解如何使用您的新模型，以下指南可能会有所帮助：
- en: Learn how to [load Textual Inversion embeddings](../using-diffusers/loading_adapters)
    and also use them as negative embeddings.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何[加载文本反转嵌入](../using-diffusers/loading_adapters)，并将其用作负嵌入。
- en: Learn how to use [Textual Inversion](textual_inversion_inference) for inference
    with Stable Diffusion 1/2 and Stable Diffusion XL.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何使用[文本反转](textual_inversion_inference)进行推理，包括 Stable Diffusion 1/2 和 Stable
    Diffusion XL。
