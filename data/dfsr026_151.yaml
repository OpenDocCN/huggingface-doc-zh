- en: MultiDiffusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MultiDiffusion
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/panorama](https://huggingface.co/docs/diffusers/api/pipelines/panorama)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/diffusers/api/pipelines/panorama](https://huggingface.co/docs/diffusers/api/pipelines/panorama)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation](https://huggingface.co/papers/2302.08113)
    is by Omer Bar-Tal, Lior Yariv, Yaron Lipman, and Tali Dekel.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[MultiDiffusion: 融合扩散路径以控制图像生成](https://huggingface.co/papers/2302.08113) 由
    Omer Bar-Tal、Lior Yariv、Yaron Lipman 和 Tali Dekel 撰写。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Recent advances in text-to-image generation with diffusion models present
    transformative capabilities in image quality. However, user controllability of
    the generated image, and fast adaptation to new tasks still remains an open challenge,
    currently mostly addressed by costly and long re-training and fine-tuning or ad-hoc
    adaptations to specific image generation tasks. In this work, we present MultiDiffusion,
    a unified framework that enables versatile and controllable image generation,
    using a pre-trained text-to-image diffusion model, without any further training
    or finetuning. At the center of our approach is a new generation process, based
    on an optimization task that binds together multiple diffusion generation processes
    with a shared set of parameters or constraints. We show that MultiDiffusion can
    be readily applied to generate high quality and diverse images that adhere to
    user-provided controls, such as desired aspect ratio (e.g., panorama), and spatial
    guiding signals, ranging from tight segmentation masks to bounding boxes.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*最近在扩散模型中的文本到图像生成方面取得了重大进展，展示了图像质量的变革能力。然而，生成图像的用户可控性和快速适应新任务仍然是一个开放性挑战，目前主要通过昂贵和长时间的重新训练和微调或针对特定图像生成任务的临时适应来解决。在这项工作中，我们提出了
    MultiDiffusion，这是一个统一的框架，利用预训练的文本到图像扩散模型实现多功能和可控的图像生成，无需进一步训练或微调。我们的方法的核心是一种新的生成过程，基于一个优化任务，将多个扩散生成过程与一组共享的参数或约束绑定在一起。我们展示了
    MultiDiffusion 可以轻松应用于生成符合用户提供的控制要求的高质量和多样化图像，例如所需的宽高比（例如全景图像）和空间引导信号，从紧密的分割掩模到边界框。*'
- en: You can find additional information about MultiDiffusion on the [project page](https://multidiffusion.github.io/),
    [original codebase](https://github.com/omerbt/MultiDiffusion), and try it out
    in a [demo](https://huggingface.co/spaces/weizmannscience/MultiDiffusion).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[项目页面](https://multidiffusion.github.io/)、[原始代码库](https://github.com/omerbt/MultiDiffusion)和[演示](https://huggingface.co/spaces/weizmannscience/MultiDiffusion)中找到有关
    MultiDiffusion 的额外信息。
- en: Tips
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示
- en: While calling [StableDiffusionPanoramaPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/panorama#diffusers.StableDiffusionPanoramaPipeline),
    it’s possible to specify the `view_batch_size` parameter to be > 1. For some GPUs
    with high performance, this can speedup the generation process and increase VRAM
    usage.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用[StableDiffusionPanoramaPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/panorama#diffusers.StableDiffusionPanoramaPipeline)时，可以指定`view_batch_size`参数为
    > 1。对于一些性能较高的 GPU，这可以加快生成过程并增加 VRAM 使用率。
- en: To generate panorama-like images make sure you pass the width parameter accordingly.
    We recommend a width value of 2048 which is the default.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成类似全景的图像，请确保相应传递宽度参数。我们推荐使用默认值为 2048 的宽度值。
- en: Circular padding is applied to ensure there are no stitching artifacts when
    working with panoramas to ensure a seamless transition from the rightmost part
    to the leftmost part. By enabling circular padding (set `circular_padding=True`),
    the operation applies additional crops after the rightmost point of the image,
    allowing the model to “see” the transition from the rightmost part to the leftmost
    part. This helps maintain visual consistency in a 360-degree sense and creates
    a proper “panorama” that can be viewed using 360-degree panorama viewers. When
    decoding latents in Stable Diffusion, circular padding is applied to ensure that
    the decoded latents match in the RGB space.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理全景图像时，应用循环填充以确保没有拼接伪影，以确保从图像的最右侧到最左侧的无缝过渡。通过启用循环填充（设置`circular_padding=True`），该操作在图像的最右点之后应用额外的裁剪，使模型能够“看到”从最右侧到最左侧的过渡。这有助于在
    360 度意义上保持视觉一致性，并创建一个可以使用 360 度全景查看器查看的适当“全景”。在 Stable Diffusion 中解码潜在变量时，应用循环填充以确保解码的潜在变量在
    RGB 空间中匹配。
- en: 'For example, without circular padding, there is a stitching artifact (default):
    ![img](../Images/a5ac3193d3295af05af44c22e03fdb89.png)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，没有循环填充时，存在拼接伪影（默认）：![img](../Images/a5ac3193d3295af05af44c22e03fdb89.png)
- en: 'But with circular padding, the right and the left parts are matching (`circular_padding=True`):
    ![img](../Images/c152da6ac83e370333abc0e6d4d97ebf.png)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但是通过循环填充，右侧和左侧部分匹配（`circular_padding=True`）：![img](../Images/c152da6ac83e370333abc0e6d4d97ebf.png)
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 请务必查看调度程序[指南](../../using-diffusers/schedulers)，以了解如何探索调度程序速度和质量之间的权衡，并查看[跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)部分，以了解如何有效地将相同组件加载到多个管道中。
- en: StableDiffusionPanoramaPipeline
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPanoramaPipeline
- en: '### `class diffusers.StableDiffusionPanoramaPipeline`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionPanoramaPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L62)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L62)'
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — 变分自动编码器（VAE）模型，用于对图像进行编码和解码以及从潜在表示中。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)）—
    冻结的文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)）—
    用于对文本进行标记化的`CLIPTokenizer`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)）—
    用于去噪编码图像潜在特征的`UNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)）—
    与`unet`结合使用的调度器，用于去噪编码图像潜在特征。可以是[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)、[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)或[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)之一。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker`（`StableDiffusionSafetyChecker`）— 用于估计生成的图像是否可能被认为具有冒犯性或有害的分类模块。请参考[model
    card](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`（[CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)）—
    用于从生成的图像中提取特征的`CLIPImageProcessor`；作为输入传递给`safety_checker`。'
- en: Pipeline for text-to-image generation using MultiDiffusion.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MultiDiffusion进行文本到图像生成的流水线。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有流水线实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该流水线还继承了以下加载方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    用于加载LoRA权重'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    用于保存LoRA权重'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    用于加载IP适配器'
- en: '#### `__call__`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L577)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L577)'
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`，*可选*）— 用于引导图像生成的提示或提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height`（`int`，*可选*，默认为512）— 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 2048) — The width in pixels of the
    generated image. The width is kept high because the pipeline is supposed generate
    panorama-like images.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width`（`int`，*可选*，默认为2048）— 生成图像的像素宽度。宽度保持较高，因为该流水线应该生成类似全景的图像。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`（`int`，*可选*，默认为50）— 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale`（`float`，*可选*，默认为7.5）— 更高的引导比例值鼓励模型生成与文本`prompt`密切相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`view_batch_size` (`int`, *optional*, defaults to 1) — The batch size to denoise
    split views. For some GPUs with high performance, higher view batch size can speedup
    the generation and increase the VRAM usage.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`view_batch_size`（`int`，*可选*，默认为1）— 用于去噪分割视图的批处理大小。对于一些性能较高的GPU，更高的视图批处理大小可以加快生成速度并增加VRAM的使用量。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *optional*) — 指导图像生成中不包括的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用指导（`guidance_scale
    < 1`）时忽略。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, defaults to 0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数
    eta (η)。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度器中被忽略。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中采样的预生成的嘈杂潜变量，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则通过使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument. ip_adapter_image — (`PipelineImageInput`, *optional*): Optional
    image input to work with IP Adapters.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`negative_prompt`输入参数生成`negative_prompt_embeds`。ip_adapter_image
    — (`PipelineImageInput`, *optional*): 可选的图像输入，用于与IP适配器一起使用。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回一个[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是一个普通的元组。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 推理过程中每`callback_steps`步调用的函数。该函数接受以下参数：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, defaults to 1) — 调用`callback`函数的频率。如果未指定，将在每一步调用回调函数。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给`AttentionProcessor`的kwargs字典，如在[diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)中的`self.processor`下定义的。'
- en: '`circular_padding` (`bool`, *optional*, defaults to `False`) — If set to `True`,
    circular padding is applied to ensure there are no stitching artifacts. Circular
    padding allows the model to seamlessly generate a transition from the rightmost
    part of the image to the leftmost part, maintaining consistency in a 360-degree
    sense.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`circular_padding` (`bool`, *optional*, defaults to `False`) — 如果设置为`True`，则应用圆形填充以确保没有拼接伪影。圆形填充允许模型无缝地从图像的最右侧部分过渡到最左侧部分，从而在360度意义上保持一致性。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 在计算提示嵌入时要从CLIP跳过的层数。值为1表示将使用预最终层的输出来计算提示嵌入。'
- en: Returns
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `return_dict` 为 `True`，则返回 [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个
    `tuple`，其中第一个元素是生成的图像列表，第二个元素是一个包含相应生成图像是否包含“不安全内容”（nsfw）的 `bool` 列表。
- en: The call function to the pipeline for generation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `disable_vae_slicing`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L152)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L152)'
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片 VAE 解码。如果之前启用了 `enable_vae_slicing`，则此方法将返回到一步计算解码。
- en: '#### `enable_vae_slicing`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L144)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L144)'
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片 VAE 解码。启用此选项时，VAE 将将输入张量分割成片段，以便在几个步骤中计算解码。这对于节省一些内存并允许更大的批量大小很有用。
- en: '#### `encode_prompt`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L193)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py#L193)'
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) — 要编码的提示设备 — (`torch.device`):
    torch 设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用分类器自由指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 不指导图像生成的提示或提示。如果未定义，则必须传递
    `negative_prompt_embeds`。在不使用指导时忽略（即，如果 `guidance_scale` 小于 `1`，则忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，*例如*
    提示加权。如果未提供，文本嵌入将从 `prompt` 输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入，*例如*
    提示加权。如果未提供，将从 `negative_prompt` 输入参数生成负提示嵌入。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *optional*) — 如果加载了 LoRA 层，则将应用于文本编码器的所有 LoRA 层的 LoRA
    比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 在计算提示嵌入时要从 CLIP 跳过的层数。值为 1 表示将使用前一层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
- en: StableDiffusionPipelineOutput
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — 长度为 `batch_size` 的去噪 PIL
    图像列表或形状为 `(batch_size, height, width, num_channels)` 的 NumPy 数组。'
- en: '`nsfw_content_detected` (`List[bool]`) — List indicating whether the corresponding
    generated image contains “not-safe-for-work” (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) — 列表指示相应生成的图像是否包含“不安全内容”（nsfw）或 `None`
    如果无法执行安全检查。'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散管道的输出类。
