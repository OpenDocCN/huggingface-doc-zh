- en: SeamlessM4T-v2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SeamlessM4T-v2
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The SeamlessM4T-v2 model was proposed in [Seamless: Multilingual Expressive
    and Streaming Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)
    by the Seamless Communication team from Meta AI.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'SeamlessM4T-v2模型是由Meta AI的Seamless Communication团队在[Seamless: Multilingual
    Expressive and Streaming Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)中提出的。'
- en: SeamlessM4T-v2 is a collection of models designed to provide high quality translation,
    allowing people from different linguistic communities to communicate effortlessly
    through speech and text. It is an improvement on the [previous version](https://huggingface.co/docs/transformers/main/model_doc/seamless_m4t).
    For more details on the differences between v1 and v2, refer to section [Difference
    with SeamlessM4T-v1](#difference-with-seamlessm4t-v1).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: SeamlessM4T-v2是一系列旨在提供高质量翻译的模型，使来自不同语言社区的人们能够通过语音和文本轻松交流。这是对[先前版本](https://huggingface.co/docs/transformers/main/model_doc/seamless_m4t)的改进。有关v1和v2之间的差异的更多详细信息，请参阅[与SeamlessM4T-v1的差异](#difference-with-seamlessm4t-v1)部分。
- en: 'SeamlessM4T-v2 enables multiple tasks without relying on separate models:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: SeamlessM4T-v2实现多个任务，无需依赖单独的模型：
- en: Speech-to-speech translation (S2ST)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音到语音翻译（S2ST）
- en: Speech-to-text translation (S2TT)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音到文本翻译（S2TT）
- en: Text-to-speech translation (T2ST)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本到语音翻译（T2ST）
- en: Text-to-text translation (T2TT)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本到文本翻译（T2TT）
- en: Automatic speech recognition (ASR)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动语音识别（ASR）
- en: '[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    can perform all the above tasks, but each task also has its own dedicated sub-model.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)可以执行上述所有任务，但每个任务也有自己专用的子模型。'
- en: 'The abstract from the paper is the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Recent advancements in automatic speech translation have dramatically expanded
    language coverage, improved multimodal capabilities, and enabled a wide range
    of tasks and functionalities. That said, large-scale automatic speech translation
    systems today lack key features that help machine-mediated communication feel
    seamless when compared to human-to-human dialogue. In this work, we introduce
    a family of models that enable end-to-end expressive and multilingual translations
    in a streaming fashion. First, we contribute an improved version of the massively
    multilingual and multimodal SeamlessM4T model—SeamlessM4T v2\. This newer model,
    incorporating an updated UnitY2 framework, was trained on more low-resource language
    data. The expanded version of SeamlessAlign adds 114,800 hours of automatically
    aligned data for a total of 76 languages. SeamlessM4T v2 provides the foundation
    on which our two newest models, SeamlessExpressive and SeamlessStreaming, are
    initiated. SeamlessExpressive enables translation that preserves vocal styles
    and prosody. Compared to previous efforts in expressive speech research, our work
    addresses certain underexplored aspects of prosody, such as speech rate and pauses,
    while also preserving the style of one’s voice. As for SeamlessStreaming, our
    model leverages the Efficient Monotonic Multihead Attention (EMMA) mechanism to
    generate low-latency target translations without waiting for complete source utterances.
    As the first of its kind, SeamlessStreaming enables simultaneous speech-to-speech/text
    translation for multiple source and target languages. To understand the performance
    of these models, we combined novel and modified versions of existing automatic
    metrics to evaluate prosody, latency, and robustness. For human evaluations, we
    adapted existing protocols tailored for measuring the most relevant attributes
    in the preservation of meaning, naturalness, and expressivity. To ensure that
    our models can be used safely and responsibly, we implemented the first known
    red-teaming effort for multimodal machine translation, a system for the detection
    and mitigation of added toxicity, a systematic evaluation of gender bias, and
    an inaudible localized watermarking mechanism designed to dampen the impact of
    deepfakes. Consequently, we bring major components from SeamlessExpressive and
    SeamlessStreaming together to form Seamless, the first publicly available system
    that unlocks expressive cross-lingual communication in real-time. In sum, Seamless
    gives us a pivotal look at the technical foundation needed to turn the Universal
    Speech Translator from a science fiction concept into a real-world technology.
    Finally, contributions in this work—including models, code, and a watermark detector—are
    publicly released and accessible at the link below.*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动语音翻译的最新进展已经大大扩展了语言覆盖范围，改进了多模态功能，并实现了广泛的任务和功能。尽管如此，今天的大规模自动语音翻译系统缺乏与人与人对话相比帮助机器中介通信感觉无缝的关键功能。在这项工作中，我们介绍了一系列模型，这些模型能够以流式方式实现端到端的表达和多语言翻译。首先，我们贡献了一个改进版本的大规模多语言和多模态SeamlessM4T模型—SeamlessM4T
    v2。这个更新的模型采用了更新的UnitY2框架，训练了更多的低资源语言数据。扩展版本的SeamlessAlign增加了114,800小时的自动对齐数据，涵盖了76种语言。SeamlessM4T
    v2为我们的两个最新模型SeamlessExpressive和SeamlessStreaming提供了基础。SeamlessExpressive实现了保留语音风格和韵律的翻译。与以往在表达性语音研究中的努力相比，我们的工作解决了一些未充分探索的韵律方面，如语速和停顿，同时也保留了个人声音的风格。至于SeamlessStreaming，我们的模型利用了高效单调多头注意力（EMMA）机制，生成低延迟的目标翻译，无需等待完整的源话语。作为首创，SeamlessStreaming实现了多源和目标语言的同时语音到语音/文本翻译。为了了解这些模型的性能，我们结合了新颖和修改过的现有自动度量标准的版本，以评估韵律、延迟和稳健性。对于人类评估，我们改编了现有的旨在衡量保留意义、自然性和表现力最相关属性的协议。为了确保我们的模型可以安全和负责任地使用，我们实施了已知的第一个多模态机器翻译红队行动，一个用于检测和减轻添加毒性的系统，一个系统性评估性别偏见，以及一个设计用于减轻深度伪造影响的不可听见的本地化水印机制。因此，我们将SeamlessExpressive和SeamlessStreaming的主要组件结合起来，形成了Seamless，这是第一个公开可用的系统，可以实时解锁具有表现力的跨语言交流。总的来说，Seamless为我们提供了将通用语音翻译器从科幻概念变成现实技术所需的技术基础的关键视角。最后，这项工作中的贡献，包括模型、代码和水印检测器，已经公开发布并可在下面的链接中访问。*'
- en: Usage
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法
- en: In the following example, we’ll load an Arabic audio sample and an English text
    sample and convert them into Russian speech and French text.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将加载一个阿拉伯语音样本和一个英文文本样本，并将它们转换为俄语语音和法语文本。
- en: 'First, load the processor and a checkpoint of the model:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，加载处理器和模型的检查点：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can seamlessly use this model on text or on audio, to generated either translated
    text or translated audio.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以无缝地在文本或音频上使用这个模型，生成翻译文本或翻译音频。
- en: 'Here is how to use the processor to process text and audio:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用处理器处理文本和音频的方法：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Speech
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语音
- en: '[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    can *seamlessly* generate text or speech with few or no changes. Let’s target
    Russian voice translation:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)可以*无缝地*生成文本或语音，几乎没有或没有任何变化。让我们以俄语语音翻译为目标：'
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With basically the same code, I’ve translated English text and Arabic speech
    to Russian speech samples.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基本相同的代码，我已经将英文文本和阿拉伯语音翻译成了俄语语音样本。
- en: Text
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本
- en: Similarly, you can generate translated text from audio files or from text with
    the same model. You only have to pass `generate_speech=False` to [SeamlessM4Tv2Model.generate()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model.generate).
    This time, let’s translate to French.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，您可以使用相同的模型从音频文件或文本生成翻译文本。您只需要将`generate_speech=False`传递给[SeamlessM4Tv2Model.generate()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model.generate)。这次，让我们翻译成法语。
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tips
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 1\. Use dedicated models
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1. 使用专用模型
- en: '[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    is transformers top level model to generate speech and text, but you can also
    use dedicated models that perform the task without additional components, thus
    reducing the memory footprint. For example, you can replace the audio-to-audio
    generation snippet with the model dedicated to the S2ST task, the rest is exactly
    the same code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)是transformers的顶级模型，用于生成语音和文本，但您也可以使用专用模型执行任务而不需要额外组件，从而减少内存占用。例如，您可以用专门用于S2ST任务的模型替换音频到音频生成片段，其余代码完全相同：'
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Or you can replace the text-to-text generation snippet with the model dedicated
    to the T2TT task, you only have to remove `generate_speech=False`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您可以用专门用于T2TT任务的模型替换文本到文本生成片段，只需删除`generate_speech=False`。
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Feel free to try out [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    and [SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech)
    as well.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随时尝试[SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)和[SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech)。
- en: 2\. Change the speaker identity
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更改说话者身份
- en: You have the possibility to change the speaker used for speech synthesis with
    the `speaker_id` argument. Some `speaker_id` works better than other for some
    languages!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`speaker_id`参数更改用于语音合成的说话者。一些`speaker_id`对某些语言效果更好！
- en: 3\. Change the generation strategy
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更改生成策略
- en: You can use different [generation strategies](../generation_strategies) for
    text generation, e.g `.generate(input_ids=input_ids, text_num_beams=4, text_do_sample=True)`
    which will perform multinomial beam-search decoding on the text model. Note that
    speech generation only supports greedy - by default - or multinomial sampling,
    which can be used with e.g. `.generate(..., speech_do_sample=True, speech_temperature=0.6)`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为文本生成使用不同的[生成策略](../generation_strategies)，例如`.generate(input_ids=input_ids,
    text_num_beams=4, text_do_sample=True)`，它将在文本模型上执行多项式波束搜索解码。请注意，语音生成只支持贪婪 - 默认情况下
    - 或多项式采样，可以使用例如`.generate(..., speech_do_sample=True, speech_temperature=0.6)`。
- en: 4\. Generate speech and text at the same time
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生成语音和文本同时进行
- en: Use `return_intermediate_token_ids=True` with [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    to return both speech and text !
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`return_intermediate_token_ids=True`与[SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)来返回语音和文本！
- en: Model architecture
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型架构
- en: SeamlessM4T-v2 features a versatile architecture that smoothly handles the sequential
    generation of text and speech. This setup comprises two sequence-to-sequence (seq2seq)
    models. The first model translates the input modality into translated text, while
    the second model generates speech tokens, known as “unit tokens,” from the translated
    text.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: SeamlessM4T-v2具有一个多功能的架构，可以平稳处理文本和语音的顺序生成。这个设置包括两个序列到序列（seq2seq）模型。第一个模型将输入模态转换为翻译文本，而第二个模型从翻译文本生成语音单元标记，称为“单元标记”。
- en: Each modality has its own dedicated encoder with a unique architecture. Additionally,
    for speech output, a vocoder inspired by the [HiFi-GAN](https://arxiv.org/abs/2010.05646)
    architecture is placed on top of the second seq2seq model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 每种模态都有自己独特的架构的专用编码器。此外，对于语音输出，一个受[HiFi-GAN](https://arxiv.org/abs/2010.05646)架构启发的声码器被放置在第二个seq2seq模型的顶部。
- en: Difference with SeamlessM4T-v1
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与SeamlessM4T-v1的不同之处
- en: 'The architecture of this new version differs from the first in a few aspects:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新版本的架构在几个方面与第一个版本不同：
- en: Improvements on the second-pass model
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第二次模型的改进
- en: 'The second seq2seq model, named text-to-unit model, is now non-auto regressive,
    meaning that it computes units in a **single forward pass**. This achievement
    is made possible by:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个seq2seq模型，称为文本到单元模型，现在是非自回归的，这意味着它在**单次前向传递**中计算单元。这一成就得以实现是因为：
- en: the use of **character-level embeddings**, meaning that each character of the
    predicted translated text has its own embeddings, which are then used to predict
    the unit tokens.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**字符级嵌入**，这意味着预测的翻译文本的每个字符都有自己的嵌入，然后用于预测单元标记。
- en: the use of an intermediate duration predictor, that predicts speech duration
    at the **character-level** on the predicted translated text.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用中间持续预测器，在预测的翻译文本上以**字符级**预测语音持续时间。
- en: the use of a new text-to-unit decoder mixing convolutions and self-attention
    to handle longer context.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个新的文本到单元解码器，混合卷积和自注意力来处理更长的上下文。
- en: Difference in the speech encoder
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语音编码器的不同之处
- en: 'The speech encoder, which is used during the first-pass generation process
    to predict the translated text, differs mainly from the previous speech encoder
    through these mechanisms:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次生成过程中用于预测翻译文本的语音编码器，主要通过以下机制与以前的语音编码器不同：
- en: the use of chunked attention mask to prevent attention across chunks, ensuring
    that each position attends only to positions within its own chunk and a fixed
    number of previous chunks.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分块注意力掩码来防止跨块的注意力，确保每个位置只关注其自己块内的位置和固定数量的先前块。
- en: the use of relative position embeddings which only considers distance between
    sequence elements rather than absolute positions. Please refer to [Self-Attentionwith
    Relative Position Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)
    for more details.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相对位置嵌入，它只考虑序列元素之间的距离，而不是绝对位置。更多细节请参考[Self-Attentionwith Relative Position
    Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)。
- en: the use of a causal depth-wise convolution instead of a non-causal one.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用因果深度卷积而不是非因果卷积。
- en: Generation process
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成过程
- en: 'Here’s how the generation process works:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 生成过程如下：
- en: Input text or speech is processed through its specific encoder.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入文本或语音通过其特定编码器处理。
- en: A decoder creates text tokens in the desired language.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器以所需语言创建文本标记。
- en: If speech generation is required, the second seq2seq model, generates unit tokens
    in an non auto-regressive way.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要生成语音，第二个seq2seq模型以非自回归方式生成单元标记。
- en: These unit tokens are then passed through the final vocoder to produce the actual
    speech.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，这些单元标记通过最终的声码器传递，以产生实际的语音。
- en: This model was contributed by [ylacombe](https://huggingface.co/ylacombe). The
    original code can be found [here](https://github.com/facebookresearch/seamless_communication).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[ylacombe](https://huggingface.co/ylacombe)贡献。原始代码可以在[这里](https://github.com/facebookresearch/seamless_communication)找到。
- en: SeamlessM4Tv2Model
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SeamlessM4Tv2Model
- en: '### `class transformers.SeamlessM4Tv2Model`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SeamlessM4Tv2Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4288)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4288)'
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`current_modality` (`str`, *optional*, defaults to `"text"`) — Default modality.
    Used only to initialize the model. It can be set to `"text"` or `"speech"`. This
    will be updated automatically according to the modality passed to the forward
    and generate passes (`input_ids` for text and `input_features` for audio).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`current_modality` (`str`, *optional*, 默认为`"text"`) — 默认模态。仅用于初始化模型。可以设置为`"text"`或`"speech"`。这将根据传递给前向和生成传递的模态（文本的`input_ids`和音频的`input_features`）自动更新。'
- en: The original SeamlessM4Tv2 Model transformer which can be used for every tasks
    available (S2ST, S2TT, T2TT, T2ST). This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的SeamlessM4Tv2模型变压器，可用于所有可用任务（S2ST、S2TT、T2TT、T2ST）。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `generate`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4512)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4512)'
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*optional*)
    — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_banks)`, *optional*) — Input audio features. This should be returnes by the
    [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    class or the [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    class. See [SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)
    for details.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, num_banks)`，*optional*)
    — 输入音频特征。这应该由[SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)类或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)类返回。有关详细信息，请参阅[SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)。'
- en: '`return_intermediate_token_ids` (`bool`, *optional*) — If `True`, also returns
    the intermediate generated text and unit tokens. Set to `True` if you also want
    to get translated text alongside the audio. Note that if `generate_speech=True`,
    this parameter will be ignored.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_intermediate_token_ids` (`bool`, *optional*) — 如果设置为`True`，还会返回生成的中间文本和单元标记。如果您还想获取音频旁边的翻译文本，请将其设置为`True`。请注意，如果`generate_speech=True`，则此参数将被忽略。'
- en: '`tgt_lang` (`str`, *optional*) — The language to use as target language for
    translation.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_lang` (`str`, *optional*) — 用作翻译目标语言的语言。'
- en: '`speaker_id` (`int`, *optional*, defaults to 0) — The id of the speaker used
    for speech synthesis. Must be lower than `config.vocoder_num_spkrs`.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_id` (`int`, *optional*, 默认为0) — 用于语音合成的说话者的ID。必须小于`config.vocoder_num_spkrs`。'
- en: '`generate_speech` (`bool`, *optional*, defaults to `True`) — If `False`, will
    only returns the text tokens and won’t generate speech.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_speech` (`bool`, *optional*, 默认为`True`) — 如果设置为`False`，将仅返回文本标记，不会生成语音。'
- en: '`kwargs` (*optional*) — Remaining dictioy of keyword arguments that will be
    passed to [GenerationMixin.generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate).
    Keyword arguments are of two types:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（*可选*）—将传递给[GenerationMixin.generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)的剩余关键字参数字典。关键字参数有两种类型：'
- en: Without a prefix, they will be entered as `**kwargs` for the `generate` method
    of each sub-model, except for `decoder_input_ids` which will only be passed through
    the text components.
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有前缀，它们将作为每个子模型的`generate`方法的`**kwargs`输入，除了`decoder_input_ids`将仅通过文本组件传递。
- en: With a *text_* or *speech_* prefix, they will be input for the `generate` method
    of the text model and speech model respectively. It has the priority over the
    keywords without a prefix.
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*text_*或*speech_*前缀，它们将分别作为文本模型和语音模型的`generate`方法的输入。它优先于没有前缀的关键字。
- en: This means you can, for example, specify a generation strategy for one generation
    but not for the other.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着您可以为一个生成策略指定一个生成策略，但不能为另一个生成策略指定生成策略。
- en: Returns
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Union[SeamlessM4Tv2GenerationOutput, Tuple[Tensor], ModelOutput]`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`Union[SeamlessM4Tv2GenerationOutput, Tuple[Tensor], ModelOutput]`'
- en: If `generate_speech` and `return_intermediate_token_ids`, returns `SeamlessM4Tv2GenerationOutput`.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`generate_speech`和`return_intermediate_token_ids`，则返回`SeamlessM4Tv2GenerationOutput`。
- en: If `generate_speech` and not `return_intermediate_token_ids`, returns a tuple
    composed of waveforms of shape `(batch_size, sequence_length)`and and `waveform_lengths`
    which gives the length of each sample.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`generate_speech`且不是`return_intermediate_token_ids`，则返回一个由形状为`(batch_size,
    sequence_length)`的波形和给出每个样本长度的`waveform_lengths`组成的元组。
- en: If `generate_speech=False`, it will returns `ModelOutput`.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`generate_speech=False`，它将返回`ModelOutput`。
- en: Generates translated token ids and/or translated audio waveforms.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 生成翻译的标记ID和/或翻译的音频波形。
- en: 'This method successively calls the `.generate` function of two different sub-models.
    You can specify keyword arguments at two different levels: general arguments that
    will be passed to both models, or prefixed arguments that will be passed to one
    of them.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法连续调用两个不同子模型的`.generate`函数。您可以在两个不同级别指定关键字参数：将传递给两个模型的通用参数，或将传递给其中一个模型的带前缀的参数。
- en: For example, calling `.generate(input_ids=input_ids, num_beams=4, speech_do_sample=True)`
    will successively perform beam-search decoding on the text model, and multinomial
    beam-search sampling on the speech model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，调用`.generate(input_ids=input_ids, num_beams=4, speech_do_sample=True)`将在文本模型上连续执行波束搜索解码，并在语音模型上执行多项式波束搜索采样。
- en: For an overview of generation strategies and code examples, check out the [following
    guide](./generation_strategies).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: SeamlessM4Tv2ForTextToSpeech
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SeamlessM4Tv2ForTextToSpeech
- en: '### `class transformers.SeamlessM4Tv2ForTextToSpeech`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SeamlessM4Tv2ForTextToSpeech`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3491)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3491)'
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config））—具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The text-to-speech SeamlessM4Tv2 Model transformer which can be used for T2ST.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到语音SeamlessM4Tv2模型转换器，可用于T2ST。该模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `generate`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3652)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3652)'
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）—词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`return_intermediate_token_ids` (`bool`, *optional*) — If `True`, also returns
    the intermediate generated text and unit tokens. Set to `True` if you also want
    to get translated text alongside the audio.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_intermediate_token_ids`（`bool`，*可选*）—如果为`True`，还返回中间生成的文本和单元标记。如果您还想在音频旁边获取翻译文本，请将其设置为`True`。'
- en: '`tgt_lang` (`str`, *optional*) — The language to use as target language for
    translation.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_lang`（`str`，*可选*）- 用作翻译目标语言的语言。'
- en: '`speaker_id` (`int`, *optional*, defaults to 0) — The id of the speaker used
    for speech synthesis. Must be lower than `config.vocoder_num_spkrs`.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_id`（`int`，*可选*，默认为0）- 用于语音合成的说话者ID。必须小于`config.vocoder_num_spkrs`。'
- en: '`kwargs` (*optional*) — Remaining dictionary of keyword arguments that will
    be passed to [GenerationMixin.generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate).
    Keyword arguments are of two types:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（*可选*）- 剩余的关键字参数字典将传递给[GenerationMixin.generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)。关键字参数有两种类型：'
- en: Without a prefix, they will be entered as `**kwargs` for the `generate` method
    of each sub-model, except for `decoder_input_ids` which will only be passed through
    the text components.
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有前缀，它们将作为每个子模型的`generate`方法的`**kwargs`输入，除了`decoder_input_ids`将仅通过文本组件传递。
- en: With a *text_* or *speech_* prefix, they will be input for the `generate` method
    of the text model and speech model respectively. It has the priority over the
    keywords without a prefix.
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*text_*或*speech_*前缀，它们将分别作为文本模型和语音模型的`generate`方法的输入。它优先于没有前缀的关键字。
- en: This means you can, for example, specify a generation strategy for one generation
    but not for the other.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着您可以为一个生成指定一种生成策略，但对另一个生成不指定。
- en: Returns
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Union[SeamlessM4Tv2GenerationOutput, Tuple[Tensor]]`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`Union[SeamlessM4Tv2GenerationOutput, Tuple[Tensor]]`'
- en: If `return_intermediate_token_ids`, returns `SeamlessM4Tv2GenerationOutput`.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`return_intermediate_token_ids`，则返回`SeamlessM4Tv2GenerationOutput`。
- en: If not `return_intermediate_token_ids`, returns a tuple composed of waveforms
    of shape `(batch_size, sequence_length)`and and `waveform_lengths` which gives
    the length of each sample.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不是`return_intermediate_token_ids`，则返回一个由形状为`(batch_size, sequence_length)`的波形和`waveform_lengths`组成的元组，其中给出了每个样本的长度。
- en: Generates translated audio waveforms.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 生成翻译后的音频波形。
- en: 'This method successively calls the `.generate` function of two different sub-models.
    You can specify keyword arguments at two different levels: general arguments that
    will be passed to both models, or prefixed arguments that will be passed to one
    of them.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法连续调用两个不同子模型的`.generate`函数。您可以在两个不同级别指定关键字参数：将传递给两个模型的一般参数，或者将传递给其中一个模型的带前缀的参数。
- en: For example, calling `.generate(input_ids, num_beams=4, speech_do_sample=True)`
    will successively perform beam-search decoding on the text model, and multinomial
    beam-search sampling on the speech model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，调用`.generate(input_ids, num_beams=4, speech_do_sample=True)`将在文本模型上连续执行波束搜索解码，并在语音模型上执行多项式波束搜索采样。
- en: For an overview of generation strategies and code examples, check out the [following
    guide](./generation_strategies).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: SeamlessM4Tv2ForSpeechToSpeech
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SeamlessM4Tv2ForSpeechToSpeech
- en: '### `class transformers.SeamlessM4Tv2ForSpeechToSpeech`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SeamlessM4Tv2ForSpeechToSpeech`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3885)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3885)'
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)）-
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The speech-to-speech SeamlessM4Tv2 Model transformer which can be used for S2ST.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于S2ST的语音到语音SeamlessM4Tv2模型转换器。该模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)的子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `generate`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4049)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4049)'
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_banks)`) — Input audio features. This should be returnes by the [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    class or the [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    class. See [SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)
    for details.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, sequence_length, num_banks)`的`torch.FloatTensor`）-
    输入音频特征。这应该由[SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)类或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)类返回。有关详细信息，请参阅[SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)。'
- en: '`return_intermediate_token_ids` (`bool`, *optional*) — If `True`, also returns
    the intermediate generated text and unit tokens. Set to `True` if you also want
    to get translated text alongside the audio.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_intermediate_token_ids`（`bool`，*可选*）- 如果为`True`，还会返回中间生成的文本和单元标记。如果您还想在音频旁边获取翻译文本，则设置为`True`。'
- en: '`tgt_lang` (`str`, *optional*) — The language to use as target language for
    translation.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_lang`（`str`，*可选*）- 用作翻译目标语言的语言。'
- en: '`speaker_id` (`int`, *optional*, defaults to 0) — The id of the speaker used
    for speech synthesis. Must be lower than `config.vocoder_num_spkrs`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_id`（`int`，*可选*，默认为0）— 用于语音合成的说话者ID。必须小于`config.vocoder_num_spkrs`。'
- en: '`kwargs` (*optional*) — Remaining dictionary of keyword arguments that will
    be passed to [GenerationMixin.generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate).
    Keyword arguments are of two types:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（*可选*）— 将传递给[GenerationMixin.generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)的剩余关键字参数字典。关键字参数有两种类型：'
- en: Without a prefix, they will be entered as `**kwargs` for the `generate` method
    of each sub-model, except for `decoder_input_ids` which will only be passed through
    the text components.
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有前缀，它们将作为`**kwargs`输入到每个子模型的`generate`方法中，除了`decoder_input_ids`只会通过文本组件传递。
- en: With a *text_* or *speech_* prefix, they will be input for the `generate` method
    of the text model and speech model respectively. It has the priority over the
    keywords without a prefix.
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*text_*或*speech_*前缀，它们将分别作为文本模型和语音模型的`generate`方法的输入。它优先于没有前缀的关键字。
- en: This means you can, for example, specify a generation strategy for one generation
    but not for the other.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着您可以为一个生成指定一种生成策略，但对另一个生成不指定。
- en: Returns
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Union[SeamlessM4Tv2GenerationOutput, Tuple[Tensor]]`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`Union[SeamlessM4Tv2GenerationOutput, Tuple[Tensor]]`'
- en: If `return_intermediate_token_ids`, returns `SeamlessM4Tv2GenerationOutput`.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`return_intermediate_token_ids`，则返回`SeamlessM4Tv2GenerationOutput`。
- en: If not `return_intermediate_token_ids`, returns a tuple composed of waveforms
    of shape `(batch_size, sequence_length)`and and `waveform_lengths` which gives
    the length of each sample.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不是`return_intermediate_token_ids`，则返回一个由形状为`(batch_size, sequence_length)`的波形和`waveform_lengths`组成的元组，其中给出每个样本的长度。
- en: Generates translated audio waveforms.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 生成翻译的音频波形。
- en: 'This method successively calls the `.generate` function of two different sub-models.
    You can specify keyword arguments at two different levels: general arguments that
    will be passed to both models, or prefixed arguments that will be passed to one
    of them.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法连续调用两个不同子模型的`.generate`函数。您可以在两个不同级别指定关键字参数：将传递给两个模型的通用参数，或者将传递给其中一个模型的前缀参数。
- en: For example, calling `.generate(input_features, num_beams=4, speech_do_sample=True)`
    will successively perform beam-search decoding on the text model, and multinomial
    beam-search sampling on the speech model.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，调用`.generate(input_features, num_beams=4, speech_do_sample=True)`将在文本模型上连续执行波束搜索解码，并在语音模型上执行多项式波束搜索采样。
- en: For an overview of generation strategies and code examples, check out the [following
    guide](./generation_strategies).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: SeamlessM4Tv2ForTextToText
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SeamlessM4Tv2ForTextToText
- en: '### `class transformers.SeamlessM4Tv2ForTextToText`'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SeamlessM4Tv2ForTextToText`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L2901)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L2901)'
- en: '[PRE12]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The text-to-text SeamlessM4Tv2 Model transformer which can be used for T2TT.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到文本SeamlessM4Tv2模型变压器，可用于T2TT。该模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L2954)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L2954)'
- en: '[PRE13]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是输入ID？
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—
    用于避免在填充标记索引上执行注意力的掩码。选择的掩码值在`[0, 1]`中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“未屏蔽”的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“屏蔽”的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids` (`torch.LongTensor`的形状为`(batch_size, target_sequence_length)`，*optional*)
    — 解码器输入序列标记在词汇表中的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是解码器输入ID？](../glossary#decoder-input-ids)'
- en: Bart uses the `eos_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Bart使用`eos_token_id`作为`decoder_input_ids`生成的起始标记。如果使用了`past_key_values`，则只需输入最后的`decoder_input_ids`（参见`past_key_values`）。 '
- en: For translation and summarization training, `decoder_input_ids` should be provided.
    If no `decoder_input_ids` is provided, the model will create this tensor by shifting
    the `input_ids` to the right for denoising pre-training following the paper.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于翻译和摘要训练，应提供`decoder_input_ids`。如果未提供`decoder_input_ids`，模型将通过将`input_ids`向右移动来创建此张量，用于去噪预训练，遵循论文。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.LongTensor`的形状为`(batch_size, target_sequence_length)`，*optional*)
    — 默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果掩码也将默认使用。'
- en: If you want to change padding behavior, you should read `modeling_bart._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`modeling_bart._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括(`last_hidden_state`,
    *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*optional*) 是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入形状为`(batch_size, 1)`的最后一个`decoder_input_ids`（这些没有将其过去的键值状态提供给此模型）而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape`(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`的形状为`(batch_size, sequence_length, hidden_size)`，*optional*)
    — 可选地，可以直接传递嵌入表示而不是传递`input_ids`。如果要更好地控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor`的形状为`(batch_size, target_sequence_length,
    hidden_size)`，*optional*) — 可选地，可以直接传递嵌入表示而不是传递`decoder_input_ids`。如果使用了`past_key_values`，则只需输入最后的`decoder_inputs_embeds`（参见`past_key_values`）。如果要更好地控制如何将`decoder_input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`decoder_input_ids`和`decoder_inputs_embeds`都未设置，则`decoder_inputs_embeds`取`inputs_embeds`的值。
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 用于计算掩码语言建模损失的标签。索引应在`[-100, 0, ..., config.vocab_size]`范围内（参见`input_ids`文档）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`范围内的标记。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`，*optional*) — 如果设置为`True`，将返回`past_key_values`键值状态，可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    forward method, overrides the `__call__` special method.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: '#### `generate`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3046)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3046)'
- en: '[PRE14]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.Tensor` of varying shape depending on the modality, *optional*)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.Tensor`，根据模态性质的不同形状，*optional*) — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`tgt_lang` (`str`, *optional*) — The language to use as target language for
    translation.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_lang` (`str`，*optional*) — 用作翻译目标语言的语言。'
- en: '`generation_config` (`~generation.GenerationConfig`, *optional*) — The generation
    configuration to be used as base parametrization for the generation call. `**kwargs`
    passed to generate matching the attributes of `generation_config` will override
    them. If `generation_config` is not provided, the default will be used, which
    had the following loading priority: 1) from the `generation_config.json` model
    file, if it exists; 2) from the model configuration. Please note that unspecified
    parameters will inherit [GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)’s
    default values, whose documentation should be checked to parameterize generation.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation_config` (`~generation.GenerationConfig`，*optional*) — 用作生成调用的基本参数化的生成配置。传递给生成的`**kwargs`与`generation_config`的属性匹配将覆盖它们。如果未提供`generation_config`，将使用默认值，其加载优先级如下：1）从`generation_config.json`模型文件中获取；2）从模型配置中获取。请注意，未指定的参数将继承[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)的默认值，应检查文档以参数化生成。'
- en: '`logits_processor` (`LogitsProcessorList`, *optional*) — Custom logits processors
    that complement the default logits processors built from arguments and generation
    config. If a logit processor is passed that is already created with the arguments
    or a generation config an error is thrown. This feature is intended for advanced
    users.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits_processor` (`LogitsProcessorList`，*optional*) — 自定义对数处理器，补充了从参数和生成配置构建的默认对数处理器。如果传递的对数处理器已经使用参数或生成配置创建，则会抛出错误。此功能适用于高级用户。'
- en: '`stopping_criteria` (`StoppingCriteriaList`, *optional*) — Custom stopping
    criteria that complement the default stopping criteria built from arguments and
    a generation config. If a stopping criteria is passed that is already created
    with the arguments or a generation config an error is thrown. This feature is
    intended for advanced users.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stopping_criteria` (`StoppingCriteriaList`, *optional*) — 自定义停止标准，补充了从参数和生成配置构建的默认停止标准。如果传递的停止标准已经使用参数或生成配置创建，则会抛出错误。此功能适用于高级用户。'
- en: '`prefix_allowed_tokens_fn` (`Callable[[int, torch.Tensor], List[int]]`, *optional*)
    — If provided, this function constraints the beam search to allowed tokens only
    at each step. If not provided no constraint is applied. This function takes 2
    arguments: the batch ID `batch_id` and `input_ids`. It has to return a list with
    the allowed tokens for the next generation step conditioned on the batch ID `batch_id`
    and the previously generated tokens `inputs_ids`. This argument is useful for
    constrained generation conditioned on the prefix, as described in [Autoregressive
    Entity Retrieval](https://arxiv.org/abs/2010.00904).'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefix_allowed_tokens_fn`（`Callable[[int, torch.Tensor], List[int]]`，*可选*）-
    如果提供，此函数将在每个步骤中将束搜索限制为仅允许的令牌。如果未提供，则不应用约束。此函数接受2个参数：批次ID`batch_id`和`input_ids`。它必须返回一个列表，其中包含下一代步骤的允许令牌，条件是批次ID`batch_id`和先前生成的令牌`inputs_ids`。此参数对于受前缀约束的生成很有用，如[自回归实体检索](https://arxiv.org/abs/2010.00904)中所述。'
- en: '`synced_gpus` (`bool`, *optional*, defaults to `False`) — Whether to continue
    running the while loop until max_length (needed for ZeRO stage 3)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`synced_gpus`（`bool`，*可选*，默认为`False`）- 是否继续运行while循环直到max_length（ZeRO阶段3所需）'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Ad hoc parametrization of `generate_config`
    and/or additional model-specific kwargs that will be forwarded to the `forward`
    function of the model.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*）- `generate_config`的特定参数化和/或将转发到模型的`forward`函数的其他模型特定kwargs的临时参数化。'
- en: Returns
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    or `torch.LongTensor`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)或`torch.LongTensor`'
- en: 'A [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    (if `return_dict_in_generate=True` or when `config.return_dict_in_generate=True`)
    or a `torch.FloatTensor`. The possible [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    types are:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)（如果`return_dict_in_generate=True`或当`config.return_dict_in_generate=True`时）或一个`torch.FloatTensor`。可能的[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)类型为：
- en: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput),'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput)，'
- en: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
- en: Generates sequences of token ids.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 生成令牌id序列。
- en: Most generation-controlling parameters are set in `generation_config` which,
    if not passed, will be set to the model’s default generation configuration. You
    can override any `generation_config` by passing the corresponding parameters to
    generate(), e.g. `.generate(inputs, num_beams=4, do_sample=True)`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数生成控制参数都在`generation_config`中设置，如果未传递，则将设置为模型的默认生成配置。您可以通过将相应的参数传递给generate()来覆盖任何`generation_config`，例如`.generate(inputs,
    num_beams=4, do_sample=True)`。
- en: For an overview of generation strategies and code examples, check out the [following
    guide](./generation_strategies).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: SeamlessM4Tv2ForSpeechToText
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SeamlessM4Tv2ForSpeechToText
- en: '### `class transformers.SeamlessM4Tv2ForSpeechToText`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SeamlessM4Tv2ForSpeechToText`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3189)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3189)'
- en: '[PRE15]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[~SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)）-
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The speech-to-text SeamlessM4Tv2 Model transformer which can be used for S2TT.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 可用于S2TT的语音到文本SeamlessM4Tv2模型变压器。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3244)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3244)'
- en: '[PRE16]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_banks)`) — Input audio features. This should be returnes by the [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    class or the [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    class. See [SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)
    for details.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, sequence_length, num_banks)`的`torch.FloatTensor`）-
    输入音频特征。这应该由[SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)类或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)类返回。有关详细信息，请参阅[SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）-
    用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被掩码`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`被掩码`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    词汇表中解码器输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)来获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是解码器输入ID？](../glossary#decoder-input-ids)'
- en: Bart uses the `eos_token_id` as the starting token for `decoder_input_ids` generation.
    If `past_key_values` is used, optionally only the last `decoder_input_ids` have
    to be input (see `past_key_values`).
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Bart使用`eos_token_id`作为`decoder_input_ids`生成的起始标记。如果使用`past_key_values`，可以选择仅输入最后的`decoder_input_ids`（参见`past_key_values`）。
- en: For translation and summarization training, `decoder_input_ids` should be provided.
    If no `decoder_input_ids` is provided, the model will create this tensor by shifting
    the `input_ids` to the right for denoising pre-training following the paper.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于翻译和摘要训练，应提供`decoder_input_ids`。如果未提供`decoder_input_ids`，模型将通过将`input_ids`向右移动来创建此张量，以进行去噪预训练，遵循论文中的方法。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果掩码也将默认使用。'
- en: If you want to change padding behavior, you should read `modeling_bart._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`modeling_bart._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（形状为`tuple(tuple(torch.FloatTensor)`，*可选*）- 元组包括（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*）是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（形状为`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的元组，每个元组有2个形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量，以及2个额外的形状为`(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（即未将其过去键值状态提供给此模型的那些）的形状为`(batch_size,
    1)`，而不是所有形状为`(batch_size, sequence_length)`的`decoder_input_ids`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape`(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）-
    可选地，您可以选择直接传递嵌入表示，而不是传递`input_ids`。如果您希望更好地控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds`（形状为`(batch_size, target_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）-
    可选地，您可以选择直接传递嵌入表示，而不是传递`decoder_input_ids`。如果使用了`past_key_values`，则可选择仅输入最后的`decoder_inputs_embeds`（请参阅`past_key_values`）。如果您想要更多控制如何将`decoder_input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds`
    takes the value of `inputs_embeds`.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果`decoder_input_ids`和`decoder_inputs_embeds`都未设置，则`decoder_inputs_embeds`取`inputs_embeds`的值。
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）- 用于计算掩码语言建模损失的标签。索引应在`[-100,
    0, ..., config.vocab_size]`范围内（请参阅`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`范围内的标记。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）- 如果设置为`True`，则会返回`past_key_values`键值状态，并且可以用于加速解码（请参阅`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    forward method, overrides the `__call__` special method.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: '#### `generate`'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3345)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L3345)'
- en: '[PRE17]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_banks)`) — Input audio features. This should be returnes by the [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    class or the [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    class. See [SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)
    for details.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, sequence_length, num_banks)`的`torch.FloatTensor`）-
    输入音频特征。这应该由[SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)类或[SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)类返回。有关详细信息，请参阅[SeamlessM4TFeatureExtractor.`call`()](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor.__call__)。'
- en: '`tgt_lang` (`str`, *optional*) — The language to use as target language for
    translation.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_lang`（`str`，*可选*）- 用作翻译目标语言的语言。'
- en: '`generation_config` (`~generation.GenerationConfig`, *optional*) — The generation
    configuration to be used as base parametrization for the generation call. `**kwargs`
    passed to generate matching the attributes of `generation_config` will override
    them. If `generation_config` is not provided, the default will be used, which
    had the following loading priority: 1) from the `generation_config.json` model
    file, if it exists; 2) from the model configuration. Please note that unspecified
    parameters will inherit [GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)’s
    default values, whose documentation should be checked to parameterize generation.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation_config`（`~generation.GenerationConfig`，*可选*）- 用作生成调用的基本参数化的生成配置。传递给生成匹配`generation_config`属性的`**kwargs`将覆盖它们。如果未提供`generation_config`，将使用默认值，其加载优先级如下：1）从`generation_config.json`模型文件中获取，如果存在；2）从模型配置中获取。请注意，未指定的参数将继承[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)的默认值，其文档应该被检查以参数化生成。'
- en: '`logits_processor` (`LogitsProcessorList`, *optional*) — Custom logits processors
    that complement the default logits processors built from arguments and generation
    config. If a logit processor is passed that is already created with the arguments
    or a generation config an error is thrown. This feature is intended for advanced
    users.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits_processor`（`LogitsProcessorList`，*可选*）—自定义logits处理器，补充从参数和生成配置构建的默认logits处理器。如果传递的logit处理器已经使用参数或生成配置创建，则会抛出错误。此功能适用于高级用户。'
- en: '`stopping_criteria` (`StoppingCriteriaList`, *optional*) — Custom stopping
    criteria that complement the default stopping criteria built from arguments and
    a generation config. If a stopping criteria is passed that is already created
    with the arguments or a generation config an error is thrown. This feature is
    intended for advanced users.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stopping_criteria`（`StoppingCriteriaList`，*可选*）—自定义停止标准，补充从参数和生成配置构建的默认停止标准。如果传递的停止标准已经使用参数或生成配置创建，则会抛出错误。此功能适用于高级用户。'
- en: '`prefix_allowed_tokens_fn` (`Callable[[int, torch.Tensor], List[int]]`, *optional*)
    — If provided, this function constraints the beam search to allowed tokens only
    at each step. If not provided no constraint is applied. This function takes 2
    arguments: the batch ID `batch_id` and `input_ids`. It has to return a list with
    the allowed tokens for the next generation step conditioned on the batch ID `batch_id`
    and the previously generated tokens `inputs_ids`. This argument is useful for
    constrained generation conditioned on the prefix, as described in [Autoregressive
    Entity Retrieval](https://arxiv.org/abs/2010.00904).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefix_allowed_tokens_fn`（`Callable[[int, torch.Tensor], List[int]]`，*可选*）—如果提供，此函数将在每个步骤将束搜索限制为仅允许的令牌。如果未提供，则不应用约束。此函数接受2个参数：批次ID`batch_id`和`input_ids`。它必须返回一个列表，其中包含下一代步骤的允许令牌，条件是批次ID`batch_id`和先前生成的令牌`inputs_ids`。此参数对于基于前缀的约束生成非常有用，如[自回归实体检索](https://arxiv.org/abs/2010.00904)中所述。'
- en: '`synced_gpus` (`bool`, *optional*, defaults to `False`) — Whether to continue
    running the while loop until max_length (needed for ZeRO stage 3)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`synced_gpus`（`bool`，*可选*，默认为`False`）—是否继续运行while循环直到max_length（需要ZeRO阶段3）'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Ad hoc parametrization of `generate_config`
    and/or additional model-specific kwargs that will be forwarded to the `forward`
    function of the model.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*）—`generate_config`的特殊参数化和/或将转发到模型的`forward`函数的其他模型特定kwargs。'
- en: Returns
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    or `torch.LongTensor`'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)或`torch.LongTensor`'
- en: 'A [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    (if `return_dict_in_generate=True` or when `config.return_dict_in_generate=True`)
    or a `torch.FloatTensor`. The possible [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    types are:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)（如果`return_dict_in_generate=True`或`config.return_dict_in_generate=True`）或`torch.FloatTensor`。可能的[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)类型为：'
- en: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput),'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput)'
- en: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
- en: Generates sequences of token ids.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 生成令牌id序列。
- en: Most generation-controlling parameters are set in `generation_config` which,
    if not passed, will be set to the model’s default generation configuration. You
    can override any `generation_config` by passing the corresponding parameters to
    generate(), e.g. `.generate(inputs, num_beams=4, do_sample=True)`.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数生成控制参数都在`generation_config`中设置，如果未传递，则将设置为模型的默认生成配置。您可以通过将相应的参数传递给generate()来覆盖任何`generation_config`，例如`.generate(inputs,
    num_beams=4, do_sample=True)`。
- en: For an overview of generation strategies and code examples, check out the [following
    guide](./generation_strategies).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: SeamlessM4Tv2Config
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SeamlessM4Tv2Config
- en: '### `class transformers.SeamlessM4Tv2Config`'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SeamlessM4Tv2Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py#L28)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py#L28)'
- en: '[PRE18]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 256102) — Vocabulary size of the
    text modality of the SeamlessM4Tv2 model. Defines the number of different tokens
    that can be represented by the `inputs_ids` passed when calling [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model),
    [~SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech)
    or [~SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为256102）—SeamlessM4Tv2模型文本模态的词汇大小。定义了在调用[~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)、[~SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech)或[~SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)时传递的不同令牌数量。inputs_ids。'
- en: '`t2u_vocab_size` (`int`, *optional*, defaults to 10082) — Unit vocabulary size
    of the SeamlessM4Tv2 model. Defines the number of different “unit tokens” that
    can be represented by the `inputs_ids` passed when calling the Text-To-Units sub-model
    of [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model),
    [~SeamlessM4Tv2ForSpeechToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToSpeech)
    or [~SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_vocab_size` (`int`, *optional*, 默认为10082) — SeamlessM4Tv2模型的单元词汇量。定义了在调用[~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)的Text-To-Units子模型时可以表示的不同“单元标记”的数量。'
- en: '`char_vocab_size` (`int`, *optional*, defaults to 10943) — Character vocabulary
    size of the SeamlessM4Tv2 model. Defines the number of different character tokens
    that can be represented by the `char_inputs_ids` passed when calling the Text-To-Units
    sub-model of [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model),
    [~SeamlessM4Tv2ForSpeechToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToSpeech)
    or [~SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech).'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`char_vocab_size` (`int`, *optional*, 默认为10943) — SeamlessM4Tv2模型的字符词汇量。定义了在调用[~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)的Text-To-Units子模型时可以表示的不同字符标记的数量。'
- en: Parameters shared across sub-models
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在子模型之间共享的参数
- en: '`hidden_size` (`int`, *optional*, defaults to 1024) — Dimensionality of the
    “intermediate” layers in the architecture.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为1024) — 架构中“中间”层的维度。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, 默认为0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, 默认为1e-05) — 层归一化层使用的epsilon。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, 默认为`True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 4096) — The maximum
    sequence length that this model text encoder and decoder might ever be used with.
    Typically set this to something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, 默认为4096) — 此模型文本编码器和解码器可能会使用的最大序列长度。通常将其设置为较大的值以防万一（例如512、1024或2048）。'
- en: '`is_encoder_decoder` (`bool`, *optional*, defaults to `True`) — Whether the
    model is used as an encoder/decoder or not.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_encoder_decoder` (`bool`, *optional*, 默认为`True`) — 模型是否用作编码器/解码器。'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.05) — The LayerDrop
    probability for the encoders. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, 默认为0.05) — 编码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop论文](参见[https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.05) — The LayerDrop
    probability for the decoders. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop` (`float`, *optional*, 默认为0.05) — 解码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop论文](参见[https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"relu"`)
    — The non-linear activation function (function or string) in the decoder and feed-forward
    layers. If string, `"gelu"`, `"relu"`, `"selu"`, `"swish"` and `"gelu_new"` are
    supported.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str`或`function`, *optional*, 默认为`"relu"`) — 解码器和前馈层中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`、`"swish"`和`"gelu_new"`。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, decoder, and pooler.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, 默认为0.1) — 嵌入层、编码器、解码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all attention layers.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, 默认为0.1) — 所有注意力层的dropout概率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for all activation layers in the model.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, 默认为0.0) — 模型中所有激活层的dropout概率。'
- en: '`scale_embedding` (`bool`, *optional*, defaults to `True`) — Scale embeddings
    by diving by sqrt(d_model).'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale_embedding` (`bool`, *optional*, 默认为`True`) — 通过将d_model开方来缩放嵌入。'
- en: Text encoder and text decoder specific parameters
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 文本编码器和文本解码器特定参数
- en: '`encoder_layers` (`int`, *optional*, defaults to 24) — Number of hidden layers
    in the Transformer text encoder.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers` (`int`, *optional*, 默认为24) — Transformer文本编码器中的隐藏层数。'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 8192) — Dimension of the
    “intermediate” (i.e., feed-forward) layer in the Transformer text encoder.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, 默认为8192) — Transformer文本编码器中“中间”（即前馈）层的维度。'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 16) — Number of attention
    heads for each attention layer in the Transformer text encoder.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads` (`int`, *optional*, 默认为16) — Transformer文本编码器中每个注意力层的注意力头数。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 24) — Number of hidden layers
    in the Transformer text decoder.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *optional*, 默认为24) — Transformer文本解码器中的隐藏层数。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 8192) — Dimension of the
    “intermediate” (i.e., feed-forward) layer in the Transformer text decoder.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, defaults to 8192) — Transformer 文本解码器中“中间”（即前馈）层的维度。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 16) — Number of attention
    heads for each attention layer in the Transformer text decoder.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, defaults to 16) — Transformer
    文本解码器中每个注意力层的注意力头数。'
- en: '`decoder_start_token_id` (`int`, *optional*, defaults to 3) — If an encoder-decoder
    model starts decoding with a different token than *bos*, the id of that token.
    Only applied in the text decoder.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_start_token_id` (`int`, *optional*, defaults to 3) — 如果编码器-解码器模型以与
    *bos* 不同的标记开始解码，则该标记的 id。仅适用于文本解码器。'
- en: '`max_new_tokens` (`int`, *optional*, defaults to 256) — The maximum numbers
    of text tokens to generate, ignoring the number of tokens in the prompt.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens` (`int`, *optional*, defaults to 256) — 要生成的文本标记的最大数量，忽略提示中的标记数量。'
- en: '`pad_token_id` (`int`, *optional*, defaults to 0) — The id of the *padding*
    text token. Only applied to the text-decoder model.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_id` (`int`, *optional*, defaults to 0) — *padding* 文本标记的 id。仅适用于文本解码器模型。'
- en: '`bos_token_id` (`int`, *optional*, defaults to 2) — The id of the *beginning-of-stream*
    text token. Only applied to the text-decoder model.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token_id` (`int`, *optional*, defaults to 2) — *流开始* 文本标记的 id。仅适用于文本解码器模型。'
- en: '`eos_token_id` (`int`, *optional*, defaults to 3) — The id of the *end-of-stream*
    text token. Only applied to the text-decoder model.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id` (`int`, *optional*, defaults to 3) — *流结束* 文本标记的 id。仅适用于文本解码器模型。'
- en: Speech encoder specific parameters
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 语音编码器特定参数
- en: '`speech_encoder_layers` (`int`, *optional*, defaults to 24) — Number of hidden
    layers in the Transformer speech encoder.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_layers` (`int`, *optional*, defaults to 24) — Transformer 语音编码器中的隐藏层数量。'
- en: '`speech_encoder_attention_heads` (`int`, *optional*, defaults to 16) — Number
    of attention heads for each attention layer in the Transformer speech encoder.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_attention_heads` (`int`, *optional*, defaults to 16) — Transformer
    语音编码器中每个注意力层的注意力头数。'
- en: '`speech_encoder_intermediate_size` (`int`, *optional*, defaults to 4096) —
    Dimension of the “intermediate” (i.e., feed-forward) layer in the Transformer
    speech encoder.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_intermediate_size` (`int`, *optional*, defaults to 4096) —
    Transformer 语音编码器中“中间”（即前馈）层的维度。'
- en: '`speech_encoder_hidden_act` (`str` or `function`, *optional*, defaults to `"swish"`)
    — The non-linear activation function (function or string) in the speech encoder.
    If string, `"gelu"`, `"relu"`, `"selu"`, `"swish"` and `"gelu_new"` are supported.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_hidden_act` (`str` 或 `function`, *optional*, defaults to `"swish"`)
    — 语音编码器中的非线性激活函数（函数或字符串）。如果是字符串，支持 `"gelu"`, `"relu"`, `"selu"`, `"swish"` 和 `"gelu_new"`。'
- en: '`speech_encoder_dropout` (`float`, *optional*, defaults to 0.0) — The dropout
    probability for all layers in the speech encoder.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_dropout` (`float`, *optional*, defaults to 0.0) — 语音编码器中所有层的
    dropout 概率。'
- en: '`add_adapter` (`bool`, *optional*, defaults to `True`) — Add an adapter layer
    on top of the speech encoder.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_adapter` (`bool`, *optional*, defaults to `True`) — 在语音编码器顶部添加一个适配器层。'
- en: '`speech_encoder_layerdrop` (`float`, *optional*, defaults to 0.1) — The LayerDrop
    probability for the speech encoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_layerdrop` (`float`, *optional*, defaults to 0.1) — 语音编码器的
    LayerDrop 概率。有关更多详细信息，请参阅 [LayerDrop 论文](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`feature_projection_input_dim` (`int`, *optional*, defaults to 160) — Input
    dimension of the input feature projection of the speech encoder, i.e the dimension
    after processing input audios with [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_projection_input_dim` (`int`, *optional*, defaults to 160) — 语音编码器输入特征投影的维度，即使用
    [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    处理输入音频后的维度。'
- en: '`adaptor_kernel_size` (`int`, *optional*, defaults to 8) — Kernel size of the
    convolutional layers in the adapter network. Only relevant if `add_adapter is
    True`.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adaptor_kernel_size` (`int`, *optional*, defaults to 8) — 适配器网络中卷积层的核大小。仅在
    `add_adapter` 为 True 时相关。'
- en: '`adaptor_stride` (`int`, *optional*, defaults to 8) — Stride of the convolutional
    layers in the adapter network. Only relevant if `add_adapter is True`.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adaptor_stride` (`int`, *optional*, defaults to 8) — 适配器网络中卷积层的步幅。仅在 `add_adapter`
    为 True 时相关。'
- en: '`adaptor_dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all layers in the speech adapter.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adaptor_dropout` (`float`, *optional*, defaults to 0.1) — 语音适配器中所有层的 dropout
    概率。'
- en: '`num_adapter_layers` (`int`, *optional*, defaults to 1) — Number of convolutional
    layers that should be used in the adapter network. Only relevant if `add_adapter
    is True`.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_adapter_layers` (`int`, *optional*, defaults to 1) — 适配器网络中应使用的卷积层数量。仅在
    `add_adapter` 为 True 时相关。'
- en: '`position_embeddings_type` (`str`, *optional*, defaults to `"relative_key"`)
    — Can be specified to `relative_key`. If left to `None`, no relative position
    embedding is applied. Only applied to the speech encoder. For more information
    on `"relative_key"`, please refer to [Self-Attention with Relative Position Representations
    (Shaw et al.)](https://arxiv.org/abs/1803.02155).'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embeddings_type` (`str`, *optional*, defaults to `"relative_key"`)
    — 可指定为 `relative_key`。如果保持为 `None`，则不应用相对位置嵌入。仅适用于语音编码器。有关 `"relative_key"` 的更多信息，请参阅
    [Self-Attention with Relative Position Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)。'
- en: '`conv_depthwise_kernel_size` (`int`, *optional*, defaults to 31) — Kernel size
    of convolutional depthwise 1D layer in Conformer blocks. Only applied to the speech
    encoder.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv_depthwise_kernel_size` (`int`, *optional*, defaults to 31) — Conformer
    块中深度可分离 1D 卷积层的核大小。仅适用于语音编码器。'
- en: '`left_max_position_embeddings` (`int`, *optional*, defaults to 64) — The left
    clipping value for relative positions.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`left_max_position_embeddings` (`int`, *optional*, defaults to 64) — 相对位置的左裁剪值。'
- en: '`right_max_position_embeddings` (`int`, *optional*, defaults to 8) — The right
    clipping value for relative positions.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`right_max_position_embeddings` (`int`, *optional*, defaults to 8) — 相对位置的右裁剪值。'
- en: '`speech_encoder_chunk_size` (`int`, *optional*, defaults to 20000) — The size
    of each attention chunk.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_chunk_size` (`int`, *optional*, 默认为20000) — 每个注意力块的大小。'
- en: '`speech_encoder_left_chunk_num` (`int`, *optional*, defaults to 128) — Number
    of chunks on the left up to which lookahead is allowed.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_encoder_left_chunk_num` (`int`, *optional*, 默认为128) — 允许向左查看的块数。'
- en: Text-To-Unit (t2u) model specific parameters
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到单元（t2u）模型特定参数
- en: '`t2u_bos_token_id` (`int`, *optional*, defaults to 0) — The id of the *beginning-of-stream*
    unit token. Only applied to the text-to-unit seq2seq model.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_bos_token_id` (`int`, *optional*, 默认为0) — *流开始* 单元标记的id。仅适用于文本到单元的seq2seq模型。'
- en: '`t2u_pad_token_id` (`int`, *optional*, defaults to 1) — The id of the *padding*
    unit token. Only applied to the text-to-unit seq2seq model.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_pad_token_id` (`int`, *optional*, 默认为1) — *填充* 单元标记的id。仅适用于文本到单元的seq2seq模型。'
- en: '`t2u_eos_token_id` (`int`, *optional*, defaults to 2) — The id of the *end-of-stream*
    unit token. Only applied to the text-to-unit seq2seq model.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_eos_token_id` (`int`, *optional*, 默认为2) — *流结束* 单元标记的id。仅适用于文本到单元的seq2seq模型。'
- en: '`t2u_encoder_layers` (`int`, *optional*, defaults to 6) — Number of hidden
    layers in the Transformer text-to-unit encoder.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_encoder_layers` (`int`, *optional*, 默认为6) — Transformer文本到单元编码器中的隐藏层数量。'
- en: '`t2u_encoder_ffn_dim` (`int`, *optional*, defaults to 8192) — Dimension of
    the “intermediate” (i.e., feed-forward) layer in the Transformer text-to-unit
    encoder.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_encoder_ffn_dim` (`int`, *optional*, 默认为8192) — Transformer文本到单元编码器中“中间”（即前馈）层的维度。'
- en: '`t2u_encoder_attention_heads` (`int`, *optional*, defaults to 16) — Number
    of attention heads for each attention layer in the Transformer text-to-unit encoder.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_encoder_attention_heads` (`int`, *optional*, 默认为16) — Transformer文本到单元编码器中每个注意力层的注意力头数量。'
- en: '`t2u_decoder_layers` (`int`, *optional*, defaults to 6) — Number of hidden
    layers in the Transformer text-to-unit decoder.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_decoder_layers` (`int`, *optional*, 默认为6) — Transformer文本到单元解码器中的隐藏层数量。'
- en: '`t2u_decoder_ffn_dim` (`int`, *optional*, defaults to 8192) — Dimension of
    the “intermediate” (i.e., feed-forward) layer in the Transformer text-to-unit
    decoder.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_decoder_ffn_dim` (`int`, *optional*, 默认为8192) — Transformer文本到单元解码器中“中间”（即前馈）层的维度。'
- en: '`t2u_decoder_attention_heads` (`int`, *optional*, defaults to 16) — Number
    of attention heads for each attention layer in the Transformer text-to-unit decoder.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_decoder_attention_heads` (`int`, *optional*, 默认为16) — Transformer文本到单元解码器中每个注意力层的注意力头数量。'
- en: '`t2u_max_position_embeddings` (`int`, *optional*, defaults to 4096) — The maximum
    sequence length that this model text-to-unit component might ever be used with.
    Typically set this to something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_max_position_embeddings` (`int`, *optional*, 默认为4096) — 该模型文本到单元组件可能被使用的最大序列长度。通常设置为较大的值以防万一（例如512、1024或2048）。'
- en: '`t2u_variance_predictor_embed_dim` (`int`, *optional*, defaults to 1024) —
    The projection dimension of the text-to-unit’s duration predictor.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_variance_predictor_embed_dim` (`int`, *optional*, 默认为1024) — 文本到单元的持续时间预测器的投影维度。'
- en: '`t2u_variance_predictor_hidden_dim` (`int`, *optional*, defaults to 256) —
    Internal dimension of the text-to-unit’s duration predictor.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_variance_predictor_hidden_dim` (`int`, *optional*, 默认为256) — 文本到单元的持续时间预测器的内部维度。'
- en: '`t2u_variance_predictor_kernel_size` (`int`, *optional*, defaults to 3) — Kernel
    size of the convolutional layers of the text-to-unit’s duration predictor.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_variance_predictor_kernel_size` (`int`, *optional*, 默认为3) — 文本到单元的持续时间预测器的卷积层的内核大小。'
- en: '`t2u_variance_pred_dropout` (`float`, *optional*, defaults to 0.5) — The dropout
    probabilitiy of the text-to-unit’s duration predictor.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t2u_variance_pred_dropout` (`float`, *optional*, 默认为0.5) — 文本到单元的持续时间预测器的dropout概率。'
- en: Hifi-Gan Vocoder specific parameters
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Hifi-Gan声码器特定参数
- en: '`sampling_rate` (`int`, *optional*, defaults to 16000) — The sampling rate
    at which the output audio will be generated, expressed in hertz (Hz).'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *optional*, 默认为16000) — 生成输出音频的采样率，以赫兹（Hz）表示。'
- en: '`upsample_initial_channel` (`int`, *optional*, defaults to 512) — The number
    of input channels into the hifi-gan upsampling network. Applies to the vocoder
    only.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsample_initial_channel` (`int`, *optional*, 默认为512) — hifi-gan上采样网络的输入通道数。仅适用于声码器。'
- en: '`upsample_rates` (`Tuple[int]` or `List[int]`, *optional*, defaults to `[5,
    4, 4, 2, 2]`) — A tuple of integers defining the stride of each 1D convolutional
    layer in the vocoder upsampling network. The length of *upsample_rates* defines
    the number of convolutional layers and has to match the length of *upsample_kernel_sizes*.
    Applies to the vocoder only.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsample_rates` (`Tuple[int]` 或 `List[int]`, *optional*, 默认为`[5, 4, 4, 2,
    2]`) — 一个整数元组，定义声码器上采样网络中每个1D卷积层的步幅。*upsample_rates*的长度定义了卷积层的数量，并且必须与*upsample_kernel_sizes*的长度匹配。仅适用于声码器。'
- en: '`upsample_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[11, 8, 8, 4, 4]`) — A tuple of integers defining the kernel size of each
    1D convolutional layer in the vocoder upsampling network. The length of *upsample_kernel_sizes*
    defines the number of convolutional layers and has to match the length of *upsample_rates*.
    Applies to the vocoder only.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsample_kernel_sizes` (`Tuple[int]` 或 `List[int]`, *optional*, 默认为`[11, 8,
    8, 4, 4]`) — 一个整数元组，定义声码器上采样网络中每个1D卷积层的内核大小。*upsample_kernel_sizes*的长度定义了卷积层的数量，并且必须与*upsample_rates*的长度匹配。仅适用于声码器。'
- en: '`resblock_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[3, 7, 11]`) — A tuple of integers defining the kernel sizes of the vocoder
    1D convolutional layers in the multi-receptive field fusion (MRF) module. Applies
    to the vocoder only.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_kernel_sizes` (`Tuple[int]` 或 `List[int]`, *optional*, 默认为`[3, 7,
    11]`) — 一个整数元组，定义多接受域融合（MRF）模块中声码器1D卷积层的内核大小。仅适用于声码器。'
- en: '`resblock_dilation_sizes` (`Tuple[Tuple[int]]` or `List[List[int]]`, *optional*,
    defaults to `[[1, 3, 5], [1, 3, 5], [1, 3, 5]]`) — A nested tuple of integers
    defining the dilation rates of the vocoder dilated 1D convolutional layers in
    the multi-receptive field fusion (MRF) module. Applies to the vocoder only.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_dilation_sizes` (`Tuple[Tuple[int]]` 或 `List[List[int]]`, *optional*,
    默认为 `[[1, 3, 5], [1, 3, 5], [1, 3, 5]]`) — 一个嵌套的整数元组，定义了多接受域融合（MRF）模块中语音编码器膨胀1D卷积层的扩张率。仅适用于语音编码器。'
- en: '`leaky_relu_slope` (`float`, *optional*, defaults to 0.1) — The angle of the
    negative slope used by the leaky ReLU activation in the vocoder. Applies to the
    vocoder only.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaky_relu_slope` (`float`, *optional*, 默认为0.1) — 语音编码器中 leaky ReLU 激活使用的负斜率的角度。仅适用于语音编码器。'
- en: '`unit_hifi_gan_vocab_size` (`int`, *optional*, defaults to 10000) — Vocabulary
    size of the SeamlessM4Tv2 vocoder. Defines the number of different unit tokens
    that can be represented by the `inputs_ids` passed when calling the vocoder of
    [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model),
    [~SeamlessM4Tv2ForSpeechToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToSpeech)
    or [~SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech).'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unit_hifi_gan_vocab_size` (`int`, *optional*, 默认为10000) — SeamlessM4Tv2 语音编码器的词汇表大小。定义了在调用
    [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)、[~SeamlessM4Tv2ForSpeechToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToSpeech)
    或 [~SeamlessM4Tv2ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToSpeech)
    时可以表示的不同单元标记数量。'
- en: '`unit_embed_dim` (`int`, *optional*, defaults to 1280) — The projection dimension
    of the input ids given to the hifi-gan vocoder. Applies to the vocoder only.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unit_embed_dim` (`int`, *optional*, 默认为1280) — 给予 hifi-gan 语音编码器的输入id的投影维度。仅适用于语音编码器。'
- en: '`lang_embed_dim` (`int`, *optional*, defaults to 256) — The projection dimension
    of the target language given to the hifi-gan vocoder. Applies to the vocoder only.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lang_embed_dim` (`int`, *optional*, 默认为256) — 给予 hifi-gan 语音编码器的目标语言的投影维度。仅适用于语音编码器。'
- en: '`spkr_embed_dim` (`int`, *optional*, defaults to 256) — The projection dimension
    of the speaker id given to the hifi-gan vocoder. Applies to the vocoder only.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spkr_embed_dim` (`int`, *optional*, 默认为256) — 给予 hifi-gan 语音编码器的说话者id的投影维度。仅适用于语音编码器。'
- en: '`vocoder_num_langs` (`int`, *optional*, defaults to 36) — Number of langs supported
    by the vocoder. Might be different from `t2u_num_langs`.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocoder_num_langs` (`int`, *optional*, 默认为36) — 语音编码器支持的语言数量。可能与 `t2u_num_langs`
    不同。'
- en: '`vocoder_num_spkrs` (`int`, *optional*, defaults to 200) — Number of speakers
    supported by the vocoder.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocoder_num_spkrs` (`int`, *optional*, 默认为200) — 语音编码器支持的说话者数量。'
- en: '`variance_predictor_kernel_size` (`int`, *optional*, defaults to 3) — Kernel
    size of the duration predictor. Applies to the vocoder only.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variance_predictor_kernel_size` (`int`, *optional*, 默认为3) — 持续时间预测器的核大小。仅适用于语音编码器。'
- en: '`var_pred_dropout` (`float`, *optional*, defaults to 0.5) — The dropout probabilitiy
    of the duration predictor. Applies to the vocoder only.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`var_pred_dropout` (`float`, *optional*, 默认为0.5) — 持续时间预测器的dropout概率。仅适用于语音编码器。'
- en: '`vocoder_offset` (`int`, *optional*, defaults to 4) — Offset the unit token
    ids by this number to account for symbol tokens. Applies to the vocoder only.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocoder_offset` (`int`, *optional*, 默认为4) — 将单元标记的id偏移此数字以考虑符号标记。仅适用于语音编码器。'
- en: This is the configuration class to store the configuration of a [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model).
    It is used to instantiate an SeamlessM4Tv2 model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the SeamlessM4Tv2 [""](https://huggingface.co/%22%22)
    architecture.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储 [~SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    配置的配置类。根据指定的参数实例化一个 SeamlessM4Tv2 模型，定义模型架构。使用默认值实例化配置将产生类似于 SeamlessM4Tv2 [""](https://huggingface.co/%22%22)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: '[PRE19]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
