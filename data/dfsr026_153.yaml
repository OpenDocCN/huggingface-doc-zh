- en: Paint by Example
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Paint by Example
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example](https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example](https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Paint by Example: Exemplar-based Image Editing with Diffusion Models](https://huggingface.co/papers/2211.13227)
    is by Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun,
    Dong Chen, Fang Wen.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Paint by Example: åŸºäºç¤ºä¾‹çš„å›¾åƒç¼–è¾‘ä¸æ‰©æ•£æ¨¡å‹](https://huggingface.co/papers/2211.13227)ç”±Binxin
    Yangã€Shuyang Guã€Bo Zhangã€Ting Zhangã€Xuejin Chenã€Xiaoyan Sunã€Dong Chenã€Fang Wenæ’°å†™ã€‚'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è®ºæ–‡çš„æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*Language-guided image editing has achieved great success recently. In this
    paper, for the first time, we investigate exemplar-guided image editing for more
    precise control. We achieve this goal by leveraging self-supervised training to
    disentangle and re-organize the source image and the exemplar. However, the naive
    approach will cause obvious fusing artifacts. We carefully analyze it and propose
    an information bottleneck and strong augmentations to avoid the trivial solution
    of directly copying and pasting the exemplar image. Meanwhile, to ensure the controllability
    of the editing process, we design an arbitrary shape mask for the exemplar image
    and leverage the classifier-free guidance to increase the similarity to the exemplar
    image. The whole framework involves a single forward of the diffusion model without
    any iterative optimization. We demonstrate that our method achieves an impressive
    performance and enables controllable editing on in-the-wild images with high fidelity.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ€è¿‘ï¼Œè¯­è¨€å¼•å¯¼çš„å›¾åƒç¼–è¾‘å–å¾—äº†å·¨å¤§æˆåŠŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡ç ”ç©¶äº†ç¤ºä¾‹å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼Œä»¥å®ç°æ›´ç²¾ç¡®çš„æ§åˆ¶ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨è‡ªç›‘ç£è®­ç»ƒæ¥è§£å¼€å’Œé‡æ–°ç»„ç»‡æºå›¾åƒå’Œç¤ºä¾‹å›¾åƒæ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ç„¶è€Œï¼Œæœ´ç´ çš„æ–¹æ³•ä¼šå¯¼è‡´æ˜æ˜¾çš„èåˆä¼ªå½±ã€‚æˆ‘ä»¬ä»”ç»†åˆ†æäº†è¿™ä¸€ç‚¹ï¼Œå¹¶æå‡ºäº†ä¿¡æ¯ç“¶é¢ˆå’Œå¼ºå¤§çš„å¢å¼ºï¼Œä»¥é¿å…ç›´æ¥å¤åˆ¶å’Œç²˜è´´ç¤ºä¾‹å›¾åƒçš„å¹³å‡¡è§£å†³æ–¹æ¡ˆã€‚åŒæ—¶ï¼Œä¸ºäº†ç¡®ä¿ç¼–è¾‘è¿‡ç¨‹çš„å¯æ§æ€§ï¼Œæˆ‘ä»¬ä¸ºç¤ºä¾‹å›¾åƒè®¾è®¡äº†ä»»æ„å½¢çŠ¶çš„è’™ç‰ˆï¼Œå¹¶åˆ©ç”¨æ— åˆ†ç±»å™¨çš„æŒ‡å¯¼æ¥å¢åŠ ä¸ç¤ºä¾‹å›¾åƒçš„ç›¸ä¼¼æ€§ã€‚æ•´ä¸ªæ¡†æ¶æ¶‰åŠæ‰©æ•£æ¨¡å‹çš„å•å‘ä¼ æ’­ï¼Œæ²¡æœ‰ä»»ä½•è¿­ä»£ä¼˜åŒ–ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œå¹¶å®ç°äº†å¯¹é‡å¤–å›¾åƒçš„å¯æ§ç¼–è¾‘ï¼Œå…·æœ‰é«˜ä¿çœŸåº¦ã€‚*'
- en: The original codebase can be found at [Fantasy-Studio/Paint-by-Example](https://github.com/Fantasy-Studio/Paint-by-Example),
    and you can try it out in a [demo](https://huggingface.co/spaces/Fantasy-Studio/Paint-by-Example).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹ä»£ç åº“å¯åœ¨[Fantasy-Studio/Paint-by-Example](https://github.com/Fantasy-Studio/Paint-by-Example)æ‰¾åˆ°ï¼Œå¹¶ä¸”æ‚¨å¯ä»¥åœ¨[æ¼”ç¤º](https://huggingface.co/spaces/Fantasy-Studio/Paint-by-Example)ä¸­å°è¯•å®ƒã€‚
- en: Tips
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æç¤º
- en: Paint by Example is supported by the official [Fantasy-Studio/Paint-by-Example](https://huggingface.co/Fantasy-Studio/Paint-by-Example)
    checkpoint. The checkpoint is warm-started from [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)
    to inpaint partly masked images conditioned on example and reference images.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Paint by Exampleç”±å®˜æ–¹[Fantasy-Studio/Paint-by-Example](https://huggingface.co/Fantasy-Studio/Paint-by-Example)æ£€æŸ¥ç‚¹æ”¯æŒã€‚è¯¥æ£€æŸ¥ç‚¹ä»[CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)å¼€å§‹ï¼Œç”¨äºä¿®å¤éƒ¨åˆ†é®ç½©å›¾åƒï¼Œæ¡ä»¶æ˜¯ç¤ºä¾‹å’Œå‚è€ƒå›¾åƒã€‚
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·åŠ¡å¿…æŸ¥çœ‹è°ƒåº¦ç¨‹åº[æŒ‡å—](../../using-diffusers/schedulers)ä»¥äº†è§£å¦‚ä½•æ¢ç´¢è°ƒåº¦ç¨‹åºé€Ÿåº¦å’Œè´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶æŸ¥çœ‹[åœ¨å¤šä¸ªç®¡é“ä¸­é‡ç”¨ç»„ä»¶](../../using-diffusers/loading#reuse-components-across-pipelines)éƒ¨åˆ†ï¼Œä»¥äº†è§£å¦‚ä½•æœ‰æ•ˆåœ°å°†ç›¸åŒç»„ä»¶åŠ è½½åˆ°å¤šä¸ªç®¡é“ä¸­ã€‚
- en: PaintByExamplePipeline
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PaintByExamplePipeline
- en: '### `class diffusers.PaintByExamplePipeline`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.PaintByExamplePipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L151)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L151)'
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKLï¼‰ï¼‰-
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`image_encoder` (`PaintByExampleImageEncoder`) â€” Encodes the example input
    image. The `unet` is conditioned on the example image instead of a text prompt.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_encoder`ï¼ˆ`PaintByExampleImageEncoder`ï¼‰- å¯¹ç¤ºä¾‹è¾“å…¥å›¾åƒè¿›è¡Œç¼–ç ã€‚`unet`æ˜¯æ ¹æ®ç¤ºä¾‹å›¾åƒè€Œä¸æ˜¯æ–‡æœ¬æç¤ºè¿›è¡Œæ¡ä»¶åŒ–çš„ã€‚'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    â€” A `CLIPTokenizer` to tokenize text.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerï¼‰ï¼‰-
    ç”¨äºå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°çš„`CLIPTokenizer`ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModelï¼‰ï¼‰-
    ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨è¡¨ç¤ºçš„`UNet2DConditionModel`ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`ï¼ˆ[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixinï¼‰ï¼‰-
    ç”¨äºä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨è¡¨ç¤ºçš„è°ƒåº¦ç¨‹åºã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ã€[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)æˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a modelâ€™s potential harms.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) â€” ç”¨äºä¼°è®¡ç”Ÿæˆå›¾åƒæ˜¯å¦å¯èƒ½è¢«è§†ä¸ºå…·æœ‰å†’çŠ¯æ€§æˆ–æœ‰å®³çš„åˆ†ç±»æ¨¡å—ã€‚è¯·å‚è€ƒ
    [æ¨¡å‹å¡ç‰‡](https://huggingface.co/runwayml/stable-diffusion-v1-5) ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    â€” ç”¨äºä»ç”Ÿæˆçš„å›¾åƒä¸­æå–ç‰¹å¾çš„ `CLIPImageProcessor`ï¼›ä½œä¸º `safety_checker` çš„è¾“å…¥ã€‚'
- en: ğŸ§ª This is an experimental feature!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ§ª è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼
- en: Pipeline for image-guided image inpainting using Stable Diffusion.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Stable Diffusion è¿›è¡Œå›¾åƒå¼•å¯¼ä¿®å¤çš„æµæ°´çº¿ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ª [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥è·å–æ‰€æœ‰æµæ°´çº¿å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: '#### `__call__`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L388)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L388)'
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`example_image` (`torch.FloatTensor` or `PIL.Image.Image` or `List[PIL.Image.Image]`)
    â€” An example image to guide image generation.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`example_image` (`torch.FloatTensor` æˆ– `PIL.Image.Image` æˆ– `List[PIL.Image.Image]`)
    â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„ç¤ºä¾‹å›¾åƒã€‚'
- en: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `List[PIL.Image.Image]`)
    â€” `Image` or tensor representing an image batch to be inpainted (parts of the
    image are masked out with `mask_image` and repainted according to `prompt`).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` æˆ– `PIL.Image.Image` æˆ– `List[PIL.Image.Image]`)
    â€” è¡¨ç¤ºè¦ä¿®å¤çš„å›¾åƒæ‰¹æ¬¡çš„å›¾åƒæˆ–å¼ é‡ï¼ˆå›¾åƒçš„éƒ¨åˆ†è¢« `mask_image` æ©ç›–ï¼Œæ ¹æ® `prompt` é‡æ–°ç»˜åˆ¶ï¼‰ã€‚'
- en: '`mask_image` (`torch.FloatTensor` or `PIL.Image.Image` or `List[PIL.Image.Image]`)
    â€” `Image` or tensor representing an image batch to mask `image`. White pixels
    in the mask are repainted, while black pixels are preserved. If `mask_image` is
    a PIL image, it is converted to a single channel (luminance) before use. If itâ€™s
    a tensor, it should contain one color channel (L) instead of 3, so the expected
    shape would be `(B, H, W, 1)`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`torch.FloatTensor` æˆ– `PIL.Image.Image` æˆ– `List[PIL.Image.Image]`)
    â€” ä»£è¡¨è¦æ©ç›– `image` çš„å›¾åƒæ‰¹æ¬¡çš„å›¾åƒæˆ–å¼ é‡ã€‚æ©ç›–ä¸­çš„ç™½è‰²åƒç´ è¢«é‡æ–°ç»˜åˆ¶ï¼Œè€Œé»‘è‰²åƒç´ è¢«ä¿ç•™ã€‚å¦‚æœ `mask_image` æ˜¯ PIL å›¾åƒï¼Œåˆ™åœ¨ä½¿ç”¨ä¹‹å‰å°†å…¶è½¬æ¢ä¸ºå•é€šé“ï¼ˆäº®åº¦ï¼‰ã€‚å¦‚æœæ˜¯å¼ é‡ï¼Œåˆ™åº”è¯¥åŒ…å«ä¸€ä¸ªé¢œè‰²é€šé“ï¼ˆLï¼‰è€Œä¸æ˜¯
    3ï¼Œå› æ­¤é¢„æœŸå½¢çŠ¶å°†æ˜¯ `(B, H, W, 1)`ã€‚'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” The height in pixels of the generated image.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” The width in pixels of the generated image.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `self.unet.config.sample_size * self.vae_scale_factor`)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 50) â€” é™å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„é™å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†ä¼šé™ä½æ¨ç†é€Ÿåº¦ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 7.5) â€” æ›´é«˜çš„å¼•å¯¼æ¯”ä¾‹å€¼é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ `prompt` å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œä½†ä¼šé™ä½å›¾åƒè´¨é‡ã€‚å½“
    `guidance_scale > 1` æ—¶å¯ç”¨å¼•å¯¼æ¯”ä¾‹ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆä¸­ä¸åŒ…æ‹¬çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™éœ€è¦ä¼ é€’
    `negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨å¼•å¯¼æ—¶ï¼ˆ`guidance_scale < 1`ï¼‰å°†è¢«å¿½ç•¥ã€‚'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *å¯é€‰*, é»˜è®¤ä¸º 0.0) â€” å¯¹åº”äº [DDIM](https://arxiv.org/abs/2010.02502)
    è®ºæ–‡ä¸­çš„å‚æ•° eta (Î·)ã€‚ä»…é€‚ç”¨äº [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œåœ¨å…¶ä»–è°ƒåº¦ç¨‹åºä¸­å°†è¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` æˆ– `List[torch.Generator]`, *å¯é€‰*) â€” ç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§çš„
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)ã€‚'
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *å¯é€‰*) â€” ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„é¢„ç”Ÿæˆå˜ˆæ‚æ½œå˜é‡ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é€šè¿‡ä½¿ç”¨æä¾›çš„éšæœº
    `generator` è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚é€‰æ‹© `PIL.Image` æˆ– `np.array`
    ä¹‹é—´çš„ä¸€ä¸ªã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å› [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`callback` (`Callable`, *optional*) â€” A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *å¯é€‰*) â€” åœ¨æ¨æ–­è¿‡ç¨‹ä¸­æ¯ `callback_steps` æ­¥è°ƒç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°ä½¿ç”¨ä»¥ä¸‹å‚æ•°è°ƒç”¨ï¼š`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`ã€‚'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) â€” The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” è°ƒç”¨ `callback` å‡½æ•°çš„é¢‘ç‡ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™åœ¨æ¯ä¸€æ­¥è°ƒç”¨å›è°ƒã€‚'
- en: Returns
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    æˆ– `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains â€œnot-safe-for-workâ€ (nsfw)
    content.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ `return_dict` ä¸º `True`ï¼Œåˆ™è¿”å› [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ª
    `tuple`ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰ã€‚
- en: The call function to the pipeline for generation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç®¡é“è°ƒç”¨å‡½æ•°ç”¨äºç”Ÿæˆã€‚
- en: 'Example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: StableDiffusionPipelineOutput
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) â€” List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` æˆ– `np.ndarray`) â€” é•¿åº¦ä¸º `batch_size` çš„å»å™ª PIL
    å›¾åƒåˆ—è¡¨æˆ–å½¢çŠ¶ä¸º `(batch_size, height, width, num_channels)` çš„ NumPy æ•°ç»„ã€‚'
- en: '`nsfw_content_detected` (`List[bool]`) â€” List indicating whether the corresponding
    generated image contains â€œnot-safe-for-workâ€ (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) â€” åˆ—è¡¨ï¼ŒæŒ‡ç¤ºç›¸åº”ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«â€œä¸å®‰å…¨å†…å®¹â€ï¼ˆnsfwï¼‰æˆ–å¦‚æœæ— æ³•æ‰§è¡Œå®‰å…¨æ£€æŸ¥ï¼Œåˆ™ä¸º
    `None`ã€‚'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£ç®¡é“çš„è¾“å‡ºç±»ã€‚
