- en: ğŸ¤— Accelerateâ€™s internal mechanisms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¤— Accelerateçš„å†…éƒ¨æœºåˆ¶
- en: 'Original text: [https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism](https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism](https://huggingface.co/docs/accelerate/concept_guides/internal_mechanism)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Internally, ğŸ¤— Accelerate works by first analyzing the environment in which the
    script is launched to determine which kind of distributed setup is used, how many
    different processes there are and which one the current script is in. All that
    information is stored in the `~AcceleratorState`.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å†…éƒ¨ï¼ŒğŸ¤— Accelerateé¦–å…ˆåˆ†æå¯åŠ¨è„šæœ¬çš„ç¯å¢ƒï¼Œä»¥ç¡®å®šä½¿ç”¨äº†å“ªç§ç±»å‹çš„åˆ†å¸ƒå¼è®¾ç½®ï¼Œæœ‰å¤šå°‘ä¸ªä¸åŒçš„è¿›ç¨‹ä»¥åŠå½“å‰è„šæœ¬åœ¨å“ªä¸ªè¿›ç¨‹ä¸­ã€‚æ‰€æœ‰è¿™äº›ä¿¡æ¯éƒ½å­˜å‚¨åœ¨`~AcceleratorState`ä¸­ã€‚
- en: This class is initialized the first time you instantiate an [~Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    as well as performing any specific initialization your distributed setup needs.
    Its state is then uniquely shared through all instances of [AcceleratorState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.state.AcceleratorState).
    (The same can also be done with the [PartialState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.PartialState),
    a more barebones version it inherits)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç±»åœ¨æ‚¨ç¬¬ä¸€æ¬¡å®ä¾‹åŒ–[~Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)æ—¶åˆå§‹åŒ–ï¼Œä»¥åŠæ‰§è¡Œä»»ä½•ç‰¹å®šäºæ‚¨çš„åˆ†å¸ƒå¼è®¾ç½®éœ€è¦çš„åˆå§‹åŒ–ã€‚ç„¶åï¼Œå®ƒçš„çŠ¶æ€é€šè¿‡æ‰€æœ‰[AcceleratorState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.state.AcceleratorState)å®ä¾‹å”¯ä¸€å…±äº«ã€‚ï¼ˆä¹Ÿå¯ä»¥ä½¿ç”¨[PartialState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.PartialState)æ¥å®Œæˆç›¸åŒçš„æ“ä½œï¼Œå®ƒæ˜¯ä¸€ä¸ªæ›´ç®€åŒ–çš„ç‰ˆæœ¬ï¼‰
- en: 'Then, when calling [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare),
    the library:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œåœ¨è°ƒç”¨[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)æ—¶ï¼Œåº“ï¼š
- en: wraps your model(s) in the container adapted for the distributed setup,
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‚¨çš„æ¨¡å‹åŒ…è£…åœ¨é€‚ç”¨äºåˆ†å¸ƒå¼è®¾ç½®çš„å®¹å™¨ä¸­ï¼Œ
- en: wraps your optimizer(s) in an [AcceleratedOptimizer](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.optimizer.AcceleratedOptimizer),
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‚¨çš„ä¼˜åŒ–å™¨åŒ…è£…åœ¨[AcceleratedOptimizer](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.optimizer.AcceleratedOptimizer)ä¸­ï¼Œ
- en: wraps your scheduler(s) in an [AcceleratedScheduler](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.scheduler.AcceleratedScheduler)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‚¨çš„è°ƒåº¦ç¨‹åºåŒ…è£…åœ¨[AcceleratedScheduler](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.scheduler.AcceleratedScheduler)ä¸­
- en: creates a new version of your dataloader(s) in a [DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)
    or [DataLoaderDispatcher](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderDispatcher)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨[DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)æˆ–[DataLoaderDispatcher](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderDispatcher)ä¸­åˆ›å»ºæ‚¨çš„æ•°æ®åŠ è½½å™¨çš„æ–°ç‰ˆæœ¬
- en: While the model(s), optimizer(s), and scheduler(s) are just put in simple wrappers,
    the dataloader(s) are re-created. This is mostly because PyTorch does not let
    the user change the `batch_sampler` of a dataloader once itâ€™s been created and
    the library handles the sharding of your data between processes by changing that
    `batch_sampler` to yield every other `num_processes` batches (if enabled).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦ç¨‹åºåªæ˜¯ç®€å•çš„åŒ…è£…å™¨ï¼Œä½†æ•°æ®åŠ è½½å™¨æ˜¯é‡æ–°åˆ›å»ºçš„ã€‚è¿™ä¸»è¦æ˜¯å› ä¸ºPyTorchä¸å…è®¸ç”¨æˆ·åœ¨åˆ›å»ºåæ›´æ”¹æ•°æ®åŠ è½½å™¨çš„`batch_sampler`ï¼Œè€Œåº“é€šè¿‡å°†`batch_sampler`æ›´æ”¹ä¸ºæ¯éš”å…¶ä»–`num_processes`æ‰¹æ¬¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰æ¥å¤„ç†æ•°æ®åœ¨è¿›ç¨‹ä¹‹é—´çš„åˆ†ç‰‡ã€‚
- en: 'The [DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)
    subclasses `DataLoader` to add the following functionality:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)å­ç±»`DataLoader`ä»¥æ·»åŠ ä»¥ä¸‹åŠŸèƒ½ï¼š'
- en: it synchronizes the appropriate random number generator of all processes at
    each new iteration, to ensure any randomization (like shuffling) is done the exact
    same way across processes.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒåœ¨æ¯æ¬¡æ–°è¿­ä»£æ—¶åŒæ­¥æ‰€æœ‰è¿›ç¨‹çš„é€‚å½“éšæœºæ•°ç”Ÿæˆå™¨ï¼Œä»¥ç¡®ä¿ä»»ä½•éšæœºåŒ–ï¼ˆå¦‚æ´—ç‰Œï¼‰åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­éƒ½ä»¥å®Œå…¨ç›¸åŒçš„æ–¹å¼è¿›è¡Œã€‚
- en: it puts the batches on the proper device before yielding them (unless you have
    opted out of `device_placement=True`).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨äº§ç”Ÿæ‰¹æ¬¡ä¹‹å‰å°†æ‰¹æ¬¡æ”¾åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆé™¤éæ‚¨é€‰æ‹©äº†`device_placement=True`ï¼‰ã€‚
- en: The [DataLoaderDispatcher](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderDispatcher)
    subclasses differs from the [DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)
    in that when iterating through the `DataLoader`, the data is all starting from
    process 0 and *then* split and sent off to each process rather than it happening
    at the dataset level.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[DataLoaderDispatcher](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderDispatcher)å­ç±»ä¸[DataLoaderShard](/docs/accelerate/v0.27.2/en/package_reference/torch_wrappers#accelerate.data_loader.DataLoaderShard)ä¸åŒä¹‹å¤„åœ¨äºï¼Œå½“é€šè¿‡`DataLoader`è¿­ä»£æ—¶ï¼Œæ•°æ®éƒ½æ˜¯ä»è¿›ç¨‹0å¼€å§‹ï¼Œç„¶åå†åˆ†å‰²å¹¶å‘é€åˆ°æ¯ä¸ªè¿›ç¨‹ï¼Œè€Œä¸æ˜¯åœ¨æ•°æ®é›†çº§åˆ«å‘ç”Ÿã€‚'
- en: 'The random number generator synchronization will by default synchronize:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œéšæœºæ•°ç”Ÿæˆå™¨åŒæ­¥å°†åŒæ­¥ï¼š
- en: the `generator` attribute of a given sampler (like the PyTorch `RandomSampler`)
    for PyTorch >= 1.6
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé‡‡æ ·å™¨ï¼ˆå¦‚PyTorchçš„`RandomSampler`ï¼‰çš„`generator`å±æ€§ï¼Œé€‚ç”¨äºPyTorch >= 1.6
- en: the main random number generator in PyTorch <=1.5.1
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch <=1.5.1ä¸­çš„ä¸»éšæœºæ•°ç”Ÿæˆå™¨
- en: You can choose which random number generator(s) to synchronize with the `rng_types`
    argument of the main [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator).
    In PyTorch >= 1.6, it is recommended to rely on a local `generator` to avoid setting
    the same seed in the main random number generator in all processes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡ä¸»[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)çš„`rng_types`å‚æ•°é€‰æ‹©è¦ä¸ä¹‹åŒæ­¥çš„éšæœºæ•°ç”Ÿæˆå™¨ã€‚åœ¨PyTorch
    >= 1.6ä¸­ï¼Œå»ºè®®ä¾èµ–äºæœ¬åœ°`generator`ï¼Œä»¥é¿å…åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­è®¾ç½®ç›¸åŒçš„ç§å­ã€‚
- en: Synchronization of the main torch (or CUDA or XLA) random number generator will
    affect any other potential random artifacts you could have in your dataset (like
    random data augmentation) in the sense that all processes will get the same random
    numbers from the torch random modules (so will apply the same random data augmentation
    if itâ€™s controlled by torch).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦torchï¼ˆæˆ–CUDAæˆ–XLAï¼‰éšæœºæ•°ç”Ÿæˆå™¨çš„åŒæ­¥å°†å½±å“æ•°æ®é›†ä¸­å¯èƒ½å­˜åœ¨çš„ä»»ä½•å…¶ä»–éšæœºç°è±¡ï¼ˆå¦‚éšæœºæ•°æ®å¢å¼ºï¼‰ï¼Œå› ä¸ºæ‰€æœ‰è¿›ç¨‹å°†ä»torchéšæœºæ¨¡å—ä¸­è·å¾—ç›¸åŒçš„éšæœºæ•°ï¼ˆå› æ­¤å¦‚æœç”±torchæ§åˆ¶ï¼Œåˆ™å°†åº”ç”¨ç›¸åŒçš„éšæœºæ•°æ®å¢å¼ºï¼‰ã€‚
- en: The randomization part of your custom sampler, batch sampler or iterable dataset
    should be done using a local `torch.Generator` object (in PyTorch >= 1.6), see
    the traditional `RandomSampler`, as an example.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è‡ªå®šä¹‰é‡‡æ ·å™¨ã€æ‰¹é‡é‡‡æ ·å™¨æˆ–å¯è¿­ä»£æ•°æ®é›†çš„éšæœºåŒ–éƒ¨åˆ†åº”è¯¥ä½¿ç”¨æœ¬åœ°çš„`torch.Generator`å¯¹è±¡æ¥å®Œæˆï¼ˆåœ¨PyTorch >= 1.6ä¸­ï¼‰ï¼Œå¯ä»¥å‚è€ƒä¼ ç»Ÿçš„`RandomSampler`ä½œä¸ºç¤ºä¾‹ã€‚
- en: For more details about the internals, see the [Internals page](package_reference/torch_wrappers).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³å†…éƒ¨è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[å†…éƒ¨é¡µé¢](package_reference/torch_wrappers)ã€‚
