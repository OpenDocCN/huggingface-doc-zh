- en: Checkpointing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查点
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/checkpoint](https://huggingface.co/docs/accelerate/usage_guides/checkpoint)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/accelerate/usage_guides/checkpoint](https://huggingface.co/docs/accelerate/usage_guides/checkpoint)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'When training a PyTorch model with 🤗 Accelerate, you may often want to save
    and continue a state of training. Doing so requires saving and loading the model,
    optimizer, RNG generators, and the GradScaler. Inside 🤗 Accelerate are two convenience
    functions to achieve this quickly:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用🤗 Accelerate训练PyTorch模型时，您可能经常希望保存和继续训练状态。为此，需要保存和加载模型、优化器、RNG生成器和GradScaler。在🤗
    Accelerate内部有两个便利函数可以快速实现这一点：
- en: Use [save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)
    for saving everything mentioned above to a folder location
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)将上述所有内容保存到文件夹位置
- en: Use [load_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.load_state)
    for loading everything stored from an earlier `save_state`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[load_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.load_state)加载先前`save_state`存储的所有内容
- en: To further customize where and how states are saved through [save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)
    the [ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)
    class can be used. For example if `automatic_checkpoint_naming` is enabled each
    saved checkpoint will be located then at `Accelerator.project_dir/checkpoints/checkpoint_{checkpoint_number}`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通过[save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)进一步自定义状态保存的位置和方式，可以使用[ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)类。例如，如果启用了`automatic_checkpoint_naming`，每个保存的检查点将位于`Accelerator.project_dir/checkpoints/checkpoint_{checkpoint_number}`。
- en: It should be noted that the expectation is that those states come from the same
    training script, they should not be from two separate scripts.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意到，期望是这些状态来自相同的训练脚本，而不应该来自两个单独的脚本。
- en: By using [register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing),
    you can register custom objects to be automatically stored or loaded from the
    two prior functions, so long as the object has a `state_dict` **and** a `load_state_dict`
    functionality. This could include objects such as a learning rate scheduler.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用[register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)，您可以注册自定义对象，以便从前两个函数中自动存储或加载，只要该对象具有`state_dict`
    **和** `load_state_dict`功能。这可能包括学习率调度器等对象。
- en: 'Below is a brief example using checkpointing to save and reload a state during
    training:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简短的示例，使用检查点来在训练过程中保存和重新加载状态：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Restoring the state of the DataLoader
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 恢复DataLoader的状态
- en: After resuming from a checkpoint, it may also be desirable to resume from a
    particular point in the active `DataLoader` if the state was saved during the
    middle of an epoch. You can use [skip_first_batches()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.skip_first_batches)
    to do so.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从检查点恢复后，如果在一个epoch的中间保存了状态，可能还希望从活动的`DataLoader`中的特定点恢复。您可以使用[skip_first_batches()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.skip_first_batches)来实现。
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
