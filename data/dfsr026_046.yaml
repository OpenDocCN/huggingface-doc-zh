- en: Create reproducible pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建可复现的流水线
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/reproducibility](https://huggingface.co/docs/diffusers/using-diffusers/reproducibility)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/reproducibility](https://huggingface.co/docs/diffusers/using-diffusers/reproducibility)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility is important for testing, replicating results, and can even
    be used to [improve image quality](reusing_seeds). However, the randomness in
    diffusion models is a desired property because it allows the pipeline to generate
    different images every time it is run. While you can’t expect to get the exact
    same results across platforms, you can expect results to be reproducible across
    releases and platforms within a certain tolerance range. Even then, tolerance
    varies depending on the diffusion pipeline and checkpoint.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 可复现性对于测试、复制结果甚至用于[改善图像质量](reusing_seeds)都很重要。然而，在扩散模型中的随机性是一种期望的属性，因为它允许流水线每次运行时生成不同的图像。虽然您不能期望在不同平台上获得完全相同的结果，但您可以期望在一定容差范围内在发布和平台之间复现结果。即使如此，容差也取决于扩散流水线和检查点。
- en: This is why it’s important to understand how to control sources of randomness
    in diffusion models or use deterministic algorithms.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么重要了解如何控制扩散模型中的随机源或使用确定性算法。
- en: '💡 We strongly recommend reading PyTorch’s [statement about reproducibility](https://pytorch.org/docs/stable/notes/randomness.html):'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 我们强烈建议阅读PyTorch关于可复现性的[声明](https://pytorch.org/docs/stable/notes/randomness.html)：
- en: Completely reproducible results are not guaranteed across PyTorch releases,
    individual commits, or different platforms. Furthermore, results may not be reproducible
    between CPU and GPU executions, even when using identical seeds.
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 无法保证在PyTorch发布、单个提交或不同平台之间完全可复现的结果。此外，即使使用相同的种子，在CPU和GPU执行之间也可能无法复现结果。
- en: Control randomness
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制随机性
- en: During inference, pipelines rely heavily on random sampling operations which
    include creating the Gaussian noise tensors to denoise and adding noise to the
    scheduling step.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，流水线严重依赖随机抽样操作，包括创建高斯噪声张量以去噪和在调度步骤中添加噪声。
- en: 'Take a look at the tensor values in the [DDIMPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/ddim#diffusers.DDIMPipeline)
    after two inference steps:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个推理步骤之后查看[DDIMPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/ddim#diffusers.DDIMPipeline)中的张量值：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Running the code above prints one value, but if you run it again you get a different
    value. What is going on here?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上面的代码会打印一个值，但如果再次运行，会得到不同的值。这是怎么回事？
- en: Every time the pipeline is run, [`torch.randn`](https://pytorch.org/docs/stable/generated/torch.randn.html)
    uses a different random seed to create Gaussian noise which is denoised stepwise.
    This leads to a different result each time it is run, which is great for diffusion
    pipelines since it generates a different random image each time.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行流水线时，[`torch.randn`](https://pytorch.org/docs/stable/generated/torch.randn.html)使用不同的随机种子创建高斯噪声，逐步去噪。这导致每次运行时都会产生不同的结果，这对于扩散流水线是很好的，因为它每次生成不同的随机图像。
- en: But if you need to reliably generate the same image, that’ll depend on whether
    you’re running the pipeline on a CPU or GPU.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您需要可靠地生成相同的图像，则取决于您是在CPU还是GPU上运行流水线。
- en: CPU
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU
- en: 'To generate reproducible results on a CPU, you’ll need to use a PyTorch [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    and set a seed:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要在CPU上生成可复现的结果，您需要使用PyTorch [`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)并设置一个种子：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now when you run the code above, it always prints a value of `1491.1711` no
    matter what because the `Generator` object with the seed is passed to all the
    random functions of the pipeline.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当您运行上面的代码时，无论如何都会打印一个值`1491.1711`，因为`Generator`对象与种子一起传递给流水线的所有随机函数。
- en: If you run this code example on your specific hardware and PyTorch version,
    you should get a similar, if not the same, result.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在您的特定硬件和PyTorch版本上运行此代码示例，您应该获得类似的结果，如果不是相同的话。
- en: 💡 It might be a bit unintuitive at first to pass `Generator` objects to the
    pipeline instead of just integer values representing the seed, but this is the
    recommended design when dealing with probabilistic models in PyTorch, as `Generator`s
    are *random states* that can be passed to multiple pipelines in a sequence.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 一开始可能有点不直观，将`Generator`对象传递给流水线而不仅仅是表示种子的整数值，但这是处理PyTorch中概率模型时推荐的设计，因为`Generator`是可以传递给多个流水线的*随机状态*。
- en: GPU
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPU
- en: 'Writing a reproducible pipeline on a GPU is a bit trickier, and full reproducibility
    across different hardware is not guaranteed because matrix multiplication - which
    diffusion pipelines require a lot of - is less deterministic on a GPU than a CPU.
    For example, if you run the same code example above on a GPU:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU上编写可复现的流水线有点棘手，不保证在不同硬件上完全可复现，因为矩阵乘法 - 扩散流水线需要大量的矩阵乘法 - 在GPU上比在CPU上不太确定。例如，如果您在GPU上运行上面的相同代码示例：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The result is not the same even though you’re using an identical seed because
    the GPU uses a different random number generator than the CPU.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用相同的种子，结果也不相同，因为GPU使用的随机数生成器与CPU不同。
- en: To circumvent this problem, 🧨 Diffusers has a `randn_tensor()` function for
    creating random noise on the CPU, and then moving the tensor to a GPU if necessary.
    The `randn_tensor` function is used everywhere inside the pipeline, allowing the
    user to **always** pass a CPU `Generator` even if the pipeline is run on a GPU.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，🧨 Diffusers有一个`randn_tensor()`函数，用于在CPU上创建随机噪声，然后将张量移动到GPU（如果需要）。`randn_tensor`函数在流水线内的各处都被使用，允许用户**始终**传递一个CPU
    `Generator`，即使流水线在GPU上运行。
- en: You’ll see the results are much closer now!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您会看到结果现在更接近了！
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 💡 If reproducibility is important, we recommend always passing a CPU generator.
    The performance loss is often neglectable, and you’ll generate much more similar
    values than if the pipeline had been run on a GPU.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 如果可复现性很重要，我们建议始终传递一个CPU生成器。性能损失通常可以忽略不计，并且您将生成比在GPU上运行流水线时更相似的值。
- en: Finally, for more complex pipelines such as [UnCLIPPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/unclip#diffusers.UnCLIPPipeline),
    these are often extremely susceptible to precision error propagation. Don’t expect
    similar results across different GPU hardware or PyTorch versions. In this case,
    you’ll need to run exactly the same hardware and PyTorch version for full reproducibility.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的流水线，比如[UnCLIPPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/unclip#diffusers.UnCLIPPipeline)，这些通常极易受到精度误差传播的影响。不要期望在不同的GPU硬件或PyTorch版本上获得类似的结果。在这种情况下，您需要在完全相同的硬件和PyTorch版本上运行以实现完全的可重现性。
- en: Deterministic algorithms
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定性算法
- en: You can also configure PyTorch to use deterministic algorithms to create a reproducible
    pipeline. However, you should be aware that deterministic algorithms may be slower
    than nondeterministic ones and you may observe a decrease in performance. But
    if reproducibility is important to you, then this is the way to go!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以配置PyTorch使用确定性算法来创建可重现的流水线。但是，您应该意识到确定性算法可能比非确定性算法慢，您可能会观察到性能下降。但如果对您来说可重现性很重要，那么这就是正确的方式！
- en: Nondeterministic behavior occurs when operations are launched in more than one
    CUDA stream. To avoid this, set the environment variable [`CUBLAS_WORKSPACE_CONFIG`](https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility)
    to `:16:8` to only use one buffer size during runtime.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当操作在多个CUDA流中启动时，会发生非确定性行为。为了避免这种情况，将环境变量[`CUBLAS_WORKSPACE_CONFIG`](https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility)设置为`:16:8`，以在运行时仅使用一个缓冲区大小。
- en: PyTorch typically benchmarks multiple algorithms to select the fastest one,
    but if you want reproducibility, you should disable this feature because the benchmark
    may select different algorithms each time. Lastly, pass `True` to [`torch.use_deterministic_algorithms`](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)
    to enable deterministic algorithms.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch通常会对多个算法进行基准测试，以选择最快的算法，但如果您希望实现可重现性，应该禁用此功能，因为基准测试可能会每次选择不同的算法。最后，将`True`传递给[`torch.use_deterministic_algorithms`](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)以启用确定性算法。
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now when you run the same pipeline twice, you’ll get identical results.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当您两次运行相同的流水线时，您将获得相同的结果。
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
