- en: Example Zoo
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例动物园
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/training_zoo](https://huggingface.co/docs/accelerate/usage_guides/training_zoo)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '原始文本: [https://huggingface.co/docs/accelerate/usage_guides/training_zoo](https://huggingface.co/docs/accelerate/usage_guides/training_zoo)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Below contains a non-exhaustive list of tutorials and scripts showcasing 🤗 Accelerate
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是展示 🤗 Accelerate 的教程和脚本的非详尽列表
- en: 'Official Accelerate Examples:'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '官方 Accelerate 示例:'
- en: Basic Examples
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本示例
- en: These examples showcase the base features of Accelerate and are a great starting
    point
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了 Accelerate 的基本功能，是一个很好的起点
- en: '[Barebones NLP example](https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基本 NLP 示例](https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py)'
- en: '[Barebones distributed NLP example in a Jupyter Notebook](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_nlp_example.ipynb)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基本分布式 NLP 示例在 Jupyter Notebook 中](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_nlp_example.ipynb)'
- en: '[Barebones computer vision example](https://github.com/huggingface/accelerate/blob/main/examples/cv_example.py)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基本计算机视觉示例](https://github.com/huggingface/accelerate/blob/main/examples/cv_example.py)'
- en: '[Barebones distributed computer vision example in a Jupyter Notebook](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_cv_example.ipynb)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基本分布式计算机视觉示例在 Jupyter Notebook 中](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_cv_example.ipynb)'
- en: '[Using Accelerate in Kaggle](https://www.kaggle.com/code/muellerzr/multi-gpu-and-accelerate)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Kaggle 中使用 Accelerate](https://www.kaggle.com/code/muellerzr/multi-gpu-and-accelerate)'
- en: Feature Specific Examples
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特定功能示例
- en: These examples showcase specific features that the Accelerate framework offers
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了 Accelerate 框架提供的特定功能
- en: '[Automatic memory-aware gradient accumulation](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/automatic_gradient_accumulation.py)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动内存感知梯度累积](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/automatic_gradient_accumulation.py)'
- en: '[Checkpointing states](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/checkpointing.py)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检查点状态](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/checkpointing.py)'
- en: '[Cross validation](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/cross_validation.py)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[交叉验证](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/cross_validation.py)'
- en: '[DeepSpeed](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/deepspeed_with_config_support.py)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepSpeed](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/deepspeed_with_config_support.py)'
- en: '[Fully Sharded Data Parallelism](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/fsdp_with_peak_mem_tracking.py)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完全分片数据并行](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/fsdp_with_peak_mem_tracking.py)'
- en: '[Gradient accumulation](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/gradient_accumulation.py)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梯度累积](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/gradient_accumulation.py)'
- en: '[Memory-aware batch size finder](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/memory.py)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[内存感知批量大小查找器](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/memory.py)'
- en: '[Metric Computation](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/multi_process_metrics.py)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[度量计算](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/multi_process_metrics.py)'
- en: '[Using Trackers](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/tracking.py)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用跟踪器](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/tracking.py)'
- en: '[Using Megatron-LM](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/megatron_lm_gpt_pretraining.py)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Megatron-LM](https://github.com/huggingface/accelerate/blob/main/examples/by_feature/megatron_lm_gpt_pretraining.py)'
- en: Full Examples
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整示例
- en: These examples showcase every feature in Accelerate at once that was shown in
    “Feature Specific Examples”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例一次展示了 Accelerate 中显示的“特定功能示例”中的所有功能
- en: '[Complete NLP example](https://github.com/huggingface/accelerate/blob/main/examples/complete_nlp_example.py)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完整 NLP 示例](https://github.com/huggingface/accelerate/blob/main/examples/complete_nlp_example.py)'
- en: '[Complete computer vision example](https://github.com/huggingface/accelerate/blob/main/examples/complete_cv_example.py)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完整计算机视觉示例](https://github.com/huggingface/accelerate/blob/main/examples/complete_cv_example.py)'
- en: '[Very complete and extensible vision example showcasing SLURM, hydra, and a
    very extensible usage of the framework](https://github.com/yuvalkirstain/PickScore)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[非常完整和可扩展的视觉示例，展示了 SLURM、hydra 和框架的非常可扩展的用法](https://github.com/yuvalkirstain/PickScore)'
- en: '[Causal language model fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm_no_trainer.py)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[因果语言模型微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm_no_trainer.py)'
- en: '[Masked language model fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm_no_trainer.py)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掩码语言模型微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm_no_trainer.py)'
- en: '[Speech pretraining example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语音预训练示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py)'
- en: '[Translation fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/translation/run_translation_no_trainer.py)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[翻译微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/translation/run_translation_no_trainer.py)'
- en: '[Text classification fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue_no_trainer.py)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本分类微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue_no_trainer.py)'
- en: '[Semantic segmentation fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义分割微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py)'
- en: '[Question answering fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa_no_trainer.py)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问答微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa_no_trainer.py)'
- en: '[Beam search question answering fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Beam search 进行问题回答微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py)'
- en: '[Multiple choice question answering fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/multiple-choice/run_swag_no_trainer.py)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多项选择问题回答微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/multiple-choice/run_swag_no_trainer.py)'
- en: '[Named entity recognition fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/token-classification/run_ner_no_trainer.py)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[命名实体识别微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/token-classification/run_ner_no_trainer.py)'
- en: '[Image classification fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/image-classification/run_image_classification_no_trainer.py)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像分类微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/image-classification/run_image_classification_no_trainer.py)'
- en: '[Summarization fine-tuning example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/summarization/run_summarization_no_trainer.py)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[摘要微调示例](https://github.com/huggingface/transformers/blob/main/examples/pytorch/summarization/run_summarization_no_trainer.py)'
- en: '[End-to-end examples on how to use AWS SageMaker integration of Accelerate](https://github.com/huggingface/notebooks/blob/main/sagemaker/22_accelerate_sagemaker_examples/README.md)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于如何使用 AWS SageMaker 加速集成的端到端示例](https://github.com/huggingface/notebooks/blob/main/sagemaker/22_accelerate_sagemaker_examples/README.md)'
- en: '[Megatron-LM examples for various NLp tasks](https://github.com/pacman100/accelerate-megatron-test)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Megatron-LM 用于各种 NLP 任务的示例](https://github.com/pacman100/accelerate-megatron-test)'
- en: Integration Examples
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成示例
- en: 'These are tutorials from libraries that integrate with 🤗 Accelerate:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是与 🤗 加速集成的库的教程：
- en: Don’t find your integration here? Make a PR to include it!
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 找不到您的集成？提交 PR 进行包含！
- en: Amphion
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amphion
- en: '[Training Text-to-Speech Models with Amphion](https://github.com/open-mmlab/Amphion/blob/main/egs/tts/README.md)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Amphion 训练文本到语音模型](https://github.com/open-mmlab/Amphion/blob/main/egs/tts/README.md)'
- en: '[Training Singing Voice Conversion Models with Amphion](https://github.com/open-mmlab/Amphion/blob/main/egs/svc/README.md)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Amphion 训练歌声转换模型](https://github.com/open-mmlab/Amphion/blob/main/egs/svc/README.md)'
- en: '[Training Vocoders with Amphion](https://github.com/open-mmlab/Amphion/blob/main/egs/vocoder/README.md)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Amphion 训练 Vocoders](https://github.com/open-mmlab/Amphion/blob/main/egs/vocoder/README.md)'
- en: Catalyst
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Catalyst
- en: '[Distributed training tutorial with Catalyst](https://catalyst-team.github.io/catalyst/tutorials/ddp.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Catalyst 进行分布式训练教程](https://catalyst-team.github.io/catalyst/tutorials/ddp.html)'
- en: DALLE2-pytorch
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DALLE2-pytorch
- en: '[Fine-tuning DALLE2](https://github.com/lucidrains/DALLE2-pytorch#usage)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DALLE2微调](https://github.com/lucidrains/DALLE2-pytorch#usage)'
- en: 🤗 diffusers
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 🤗 扩散器
- en: '[Performing textual inversion with diffusers](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用扩散器进行文本反演](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)'
- en: '[Training DreamBooth with diffusers](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用扩散器训练 DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)'
- en: fastai
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: fastai
- en: '[Distributed training from Jupyter Notebooks with fastai](https://docs.fast.ai/tutorial.distributed.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从 Jupyter Notebooks 进行分布式训练与 fastai](https://docs.fast.ai/tutorial.distributed.html)'
- en: '[Basic distributed training examples with fastai](https://docs.fast.ai/examples/distributed_app_examples.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基本的 fastai 分布式训练示例](https://docs.fast.ai/examples/distributed_app_examples.html)'
- en: GradsFlow
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GradsFlow
- en: '[Auto Image Classification with GradsFlow](https://docs.gradsflow.com/en/latest/examples/nbs/01-ImageClassification/)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 GradsFlow 进行自动图像分类](https://docs.gradsflow.com/en/latest/examples/nbs/01-ImageClassification/)'
- en: imagen-pytorch
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: imagen-pytorch
- en: '[Fine-tuning Imagen](https://github.com/lucidrains/imagen-pytorch#usage)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[微调 Imagen](https://github.com/lucidrains/imagen-pytorch#usage)'
- en: Kornia
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kornia
- en: '[Fine-tuning vision models with Kornia’s Trainer](https://kornia.readthedocs.io/en/latest/get-started/training.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Kornia 的 Trainer 进行视觉模型微调](https://kornia.readthedocs.io/en/latest/get-started/training.html)'
- en: PyTorch Accelerated
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 加速
- en: '[Quickstart distributed training tutorial with PyTorch Accelerated](https://pytorch-accelerated.readthedocs.io/en/latest/quickstart.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 加速的快速分布式训练教程](https://pytorch-accelerated.readthedocs.io/en/latest/quickstart.html)'
- en: PyTorch3D
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch3D
- en: '[Perform Deep Learning with 3D data](https://pytorch3d.org/tutorials/)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 3D 数据进行深度学习](https://pytorch3d.org/tutorials/)'
- en: Stable-Dreamfusion
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Stable-Dreamfusion
- en: '[Training with Stable-Dreamfusion to convert text to a 3D model](https://colab.research.google.com/drive/1MXT3yfOFvO0ooKEfiUUvTKwUkrrlCHpF?usp=sharing)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Stable-Dreamfusion 进行文本转换为 3D 模型的训练](https://colab.research.google.com/drive/1MXT3yfOFvO0ooKEfiUUvTKwUkrrlCHpF?usp=sharing)'
- en: Tez
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tez
- en: '[Leaf disease detection with Tez and Accelerate](https://www.kaggle.com/code/abhishek/tez-faster-and-easier-training-for-leaf-detection/notebook)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tez 和加速进行叶子病害检测](https://www.kaggle.com/code/abhishek/tez-faster-and-easier-training-for-leaf-detection/notebook)'
- en: trlx
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: trlx
- en: '[How to implement a sentiment learning task with trlx](https://github.com/CarperAI/trlx#example-how-to-add-a-task)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 trlx 实现情感学习任务](https://github.com/CarperAI/trlx#example-how-to-add-a-task)'
- en: Comfy-UI
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Comfy-UI
- en: '[Enabling using large Stable Diffusion Models in low-vram settings using Accelerate](https://github.com/comfyanonymous/ComfyUI/blob/master/comfy/model_management.py#L291-L296)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用加速在低 VRAM 环境中使用大型 Stable Diffusion 模型](https://github.com/comfyanonymous/ComfyUI/blob/master/comfy/model_management.py#L291-L296)'
- en: In Science
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在科学中
- en: Below contains a non-exhaustive list of papers utilizing 🤗 Accelerate.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是利用 🤗 加速的论文的非详尽列表。
- en: Don’t find your paper here? Make a PR to include it!
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 找不到您的论文？提交 PR 进行包含！
- en: 'Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, Omer
    Levy: “Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation”,
    2023; [arXiv:2305.01569](http://arxiv.org/abs/2305.01569).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, Omer
    Levy: “Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation”,
    2023; [arXiv:2305.01569](http://arxiv.org/abs/2305.01569).'
- en: 'Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng
    Lim: “Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning
    by Large Language Models”, 2023; [arXiv:2305.04091](http://arxiv.org/abs/2305.04091).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng
    Lim: “计划和解决提示：通过大型语言模型改进零样本思维链推理”, 2023; [arXiv:2305.04091](http://arxiv.org/abs/2305.04091).'
- en: 'Arthur Câmara, Claudia Hauff: “Moving Stuff Around: A study on efficiency of
    moving documents into memory for Neural IR models”, 2022; [arXiv:2205.08343](http://arxiv.org/abs/2205.08343).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Arthur Câmara, Claudia Hauff: “移动文件的效率研究：将文件移入内存以用于神经IR模型”, 2022; [arXiv:2205.08343](http://arxiv.org/abs/2205.08343).'
- en: 'Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y.
    Fu, Zhiqiang Xie, Beidi Chen, Clark Barrett, Joseph E. Gonzalez, Percy Liang,
    Christopher Ré, Ion Stoica, Ce Zhang: “High-throughput Generative Inference of
    Large Language Models with a Single GPU”, 2023; [arXiv:2303.06865](http://arxiv.org/abs/2303.06865).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y.
    Fu, Zhiqiang Xie, Beidi Chen, Clark Barrett, Joseph E. Gonzalez, Percy Liang,
    Christopher Ré, Ion Stoica, Ce Zhang: “使用单个GPU进行大型语言模型的高吞吐生成推理”, 2023; [arXiv:2303.06865](http://arxiv.org/abs/2303.06865).'
- en: 'Peter Melchior, Yan Liang, ChangHoon Hahn, Andy Goulding: “Autoencoding Galaxy
    Spectra I: Architecture”, 2022; [arXiv:2211.07890](http://arxiv.org/abs/2211.07890).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Peter Melchior, Yan Liang, ChangHoon Hahn, Andy Goulding: “自动编码星系光谱I：架构”, 2022;
    [arXiv:2211.07890](http://arxiv.org/abs/2211.07890).'
- en: 'Jiaao Chen, Aston Zhang, Mu Li, Alex Smola, Diyi Yang: “A Cheaper and Better
    Diffusion Language Model with Soft-Masked Noise”, 2023; [arXiv:2304.04746](http://arxiv.org/abs/2304.04746).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiaao Chen, Aston Zhang, Mu Li, Alex Smola, Diyi Yang: “具有软掩码噪声的更便宜更好的扩散语言模型”,
    2023; [arXiv:2304.04746](http://arxiv.org/abs/2304.04746).'
- en: 'Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa:
    “Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions”, 2023; [arXiv:2303.12789](http://arxiv.org/abs/2303.12789).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa:
    “Instruct-NeRF2NeRF: 使用说明编辑3D场景”, 2023; [arXiv:2303.12789](http://arxiv.org/abs/2303.12789).'
- en: 'Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, Andrea Vedaldi: “RealFusion:
    360° Reconstruction of Any Object from a Single Image”, 2023; [arXiv:2302.10663](http://arxiv.org/abs/2302.10663).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, Andrea Vedaldi: “RealFusion:
    从单个图像重建任何对象的360°”, 2023; [arXiv:2302.10663](http://arxiv.org/abs/2302.10663).'
- en: 'Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li: “Better Aligning
    Text-to-Image Models with Human Preference”, 2023; [arXiv:2303.14420](http://arxiv.org/abs/2303.14420).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li: “通过人类偏好更好地对齐文本到图像模型”,
    2023; [arXiv:2303.14420](http://arxiv.org/abs/2303.14420).'
- en: 'Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang:
    “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace”, 2023;
    [arXiv:2303.17580](http://arxiv.org/abs/2303.17580).'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang:
    “HuggingGPT: 使用ChatGPT及其HuggingFace朋友解决AI任务”, 2023; [arXiv:2303.17580](http://arxiv.org/abs/2303.17580).'
- en: 'Yue Yang, Wenlin Yao, Hongming Zhang, Xiaoyang Wang, Dong Yu, Jianshu Chen:
    “Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination”, 2022; [arXiv:2210.12261](http://arxiv.org/abs/2210.12261).'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yue Yang, Wenlin Yao, Hongming Zhang, Xiaoyang Wang, Dong Yu, Jianshu Chen:
    “Z-LaVI: 由视觉想象力推动的零样本语言求解器”, 2022; [arXiv:2210.12261](http://arxiv.org/abs/2210.12261).'
- en: 'Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho: “How to Backdoor Diffusion Models?”,
    2022; [arXiv:2212.05400](http://arxiv.org/abs/2212.05400).'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho: “如何给扩散模型留后门？”, 2022; [arXiv:2212.05400](http://arxiv.org/abs/2212.05400).'
- en: 'Junyoung Seo, Wooseok Jang, Min-Seop Kwak, Jaehoon Ko, Hyeonsu Kim, Junho Kim,
    Jin-Hwa Kim, Jiyoung Lee, Seungryong Kim: “Let 2D Diffusion Model Know 3D-Consistency
    for Robust Text-to-3D Generation”, 2023; [arXiv:2303.07937](http://arxiv.org/abs/2303.07937).'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Junyoung Seo, Wooseok Jang, Min-Seop Kwak, Jaehoon Ko, Hyeonsu Kim, Junho Kim,
    Jin-Hwa Kim, Jiyoung Lee, Seungryong Kim: “让2D扩散模型了解3D一致性以实现鲁棒的文本到3D生成”, 2023;
    [arXiv:2303.07937](http://arxiv.org/abs/2303.07937).'
- en: 'Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, Daniel Cohen-Or:
    “Localizing Object-level Shape Variations with Text-to-Image Diffusion Models”,
    2023; [arXiv:2303.11306](http://arxiv.org/abs/2303.11306).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, Daniel Cohen-Or:
    “使用文本到图像扩散模型定位对象级形状变化”, 2023; [arXiv:2303.11306](http://arxiv.org/abs/2303.11306).'
- en: 'Dídac Surís, Sachit Menon, Carl Vondrick: “ViperGPT: Visual Inference via Python
    Execution for Reasoning”, 2023; [arXiv:2303.08128](http://arxiv.org/abs/2303.08128).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dídac Surís, Sachit Menon, Carl Vondrick: “ViperGPT: 通过Python执行进行推理的视觉推断”,
    2023; [arXiv:2303.08128](http://arxiv.org/abs/2303.08128).'
- en: 'Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan,
    Qifeng Chen: “FateZero: Fusing Attentions for Zero-shot Text-based Video Editing”,
    2023; [arXiv:2303.09535](http://arxiv.org/abs/2303.09535).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan,
    Qifeng Chen: “FateZero: 融合注意力进行零样本基于文本的视频编辑”, 2023; [arXiv:2303.09535](http://arxiv.org/abs/2303.09535).'
- en: 'Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi, Yejin Choi: “NaturalProver:
    Grounded Mathematical Proof Generation with Language Models”, 2022; [arXiv:2205.12910](http://arxiv.org/abs/2205.12910).'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi, Yejin Choi: “NaturalProver:
    基于语言模型的数学证明生成”, 2022; [arXiv:2205.12910](http://arxiv.org/abs/2205.12910).'
- en: 'Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or: “TEXTure:
    Text-Guided Texturing of 3D Shapes”, 2023; [arXiv:2302.01721](http://arxiv.org/abs/2302.01721).'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or: “TEXTure:
    文本引导的3D形状纹理”, 2023; [arXiv:2302.01721](http://arxiv.org/abs/2302.01721).'
- en: 'Puijin Cheng, Li Lin, Yijin Huang, Huaqing He, Wenhan Luo, Xiaoying Tang: “Learning
    Enhancement From Degradation: A Diffusion Model For Fundus Image Enhancement”,
    2023; [arXiv:2303.04603](http://arxiv.org/abs/2303.04603).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Puijin Cheng, Li Lin, Yijin Huang, Huaqing He, Wenhan Luo, Xiaoying Tang: “从退化中学习增强：一种用于眼底图像增强的扩散模型”,
    2023; [arXiv:2303.04603](http://arxiv.org/abs/2303.04603).'
- en: 'Shun Shao, Yftah Ziser, Shay Cohen: “Erasure of Unaligned Attributes from Neural
    Representations”, 2023; [arXiv:2302.02997](http://arxiv.org/abs/2302.02997).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shun Shao, Yftah Ziser, Shay Cohen: “从神经表示中消除不对齐属性”, 2023; [arXiv:2302.02997](http://arxiv.org/abs/2302.02997).'
- en: 'Seonghyeon Ye, Hyeonbin Hwang, Sohee Yang, Hyeongu Yun, Yireun Kim, Minjoon
    Seo: “In-Context Instruction Learning”, 2023; [arXiv:2302.14691](http://arxiv.org/abs/2302.14691).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Seonghyeon Ye, Hyeonbin Hwang, Sohee Yang, Hyeongu Yun, Yireun Kim, Minjoon
    Seo: “上下文指导学习”，2023; [arXiv:2302.14691](http://arxiv.org/abs/2302.14691).'
- en: 'Shikun Liu, Linxi Fan, Edward Johns, Zhiding Yu, Chaowei Xiao, Anima Anandkumar:
    “Prismer: A Vision-Language Model with An Ensemble of Experts”, 2023; [arXiv:2303.02506](http://arxiv.org/abs/2303.02506).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shikun Liu, Linxi Fan, Edward Johns, Zhiding Yu, Chaowei Xiao, Anima Anandkumar:
    “Prismer: 一种具有专家集合的视觉语言模型”，2023; [arXiv:2303.02506](http://arxiv.org/abs/2303.02506).'
- en: 'Haoyu Chen, Zhihua Wang, Yang Yang, Qilin Sun, Kede Ma: “Learning a Deep Color
    Difference Metric for Photographic Images”, 2023; [arXiv:2303.14964](http://arxiv.org/abs/2303.14964).'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Haoyu Chen, Zhihua Wang, Yang Yang, Qilin Sun, Kede Ma: “学习用于摄影图像的深度色差度量”，2023;
    [arXiv:2303.14964](http://arxiv.org/abs/2303.14964).'
- en: 'Van-Hoang Le, Hongyu Zhang: “Log Parsing with Prompt-based Few-shot Learning”,
    2023; [arXiv:2302.07435](http://arxiv.org/abs/2302.07435).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Van-Hoang Le, Hongyu Zhang: “基于提示的少样本学习的日志解析”，2023; [arXiv:2302.07435](http://arxiv.org/abs/2302.07435).'
- en: 'Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Ana Brassard, Masashi Yoshikawa,
    Keisuke Sakaguchi, Kentaro Inui: “Do Deep Neural Networks Capture Compositionality
    in Arithmetic Reasoning?”, 2023; [arXiv:2302.07866](http://arxiv.org/abs/2302.07866).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Ana Brassard, Masashi Yoshikawa,
    Keisuke Sakaguchi, Kentaro Inui: “深度神经网络是否捕捉算术推理中的组合性？”，2023; [arXiv:2302.07866](http://arxiv.org/abs/2302.07866).'
- en: 'Ruoyao Wang, Peter Jansen, Marc-Alexandre Côté, Prithviraj Ammanabrolu: “Behavior
    Cloned Transformers are Neurosymbolic Reasoners”, 2022; [arXiv:2210.07382](http://arxiv.org/abs/2210.07382).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ruoyao Wang, Peter Jansen, Marc-Alexandre Côté, Prithviraj Ammanabrolu: “行为克隆变压器是神经符号推理者”，2022;
    [arXiv:2210.07382](http://arxiv.org/abs/2210.07382).'
- en: 'Martin Wessel, Tomáš Horych, Terry Ruas, Akiko Aizawa, Bela Gipp, Timo Spinde:
    “Introducing MBIB — the first Media Bias Identification Benchmark Task and Dataset
    Collection”, 2023; [arXiv:2304.13148](http://arxiv.org/abs/2304.13148). DOI: [https://dx.doi.org/10.1145/3539618.3591882
    10.1145/3539618.3591882].'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Martin Wessel, Tomáš Horych, Terry Ruas, Akiko Aizawa, Bela Gipp, Timo Spinde:
    “介绍MBIB——第一个媒体偏见识别基准任务和数据集收集”，2023; [arXiv:2304.13148](http://arxiv.org/abs/2304.13148).
    DOI: [https://dx.doi.org/10.1145/3539618.3591882 10.1145/3539618.3591882].'
- en: 'Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, Daniel Cohen-Or: “Attend-and-Excite:
    Attention-Based Semantic Guidance for Text-to-Image Diffusion Models”, 2023; [arXiv:2301.13826](http://arxiv.org/abs/2301.13826).'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, Daniel Cohen-Or: “Attend-and-Excite:
    基于注意力的语义引导用于文本到图像扩散模型”，2023; [arXiv:2301.13826](http://arxiv.org/abs/2301.13826).'
- en: 'Marcio Fonseca, Yftah Ziser, Shay B. Cohen: “Factorizing Content and Budget
    Decisions in Abstractive Summarization of Long Documents”, 2022; [arXiv:2205.12486](http://arxiv.org/abs/2205.12486).'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Marcio Fonseca, Yftah Ziser, Shay B. Cohen: “在长文档的抽象摘要中分解内容和预算决策”，2022; [arXiv:2205.12486](http://arxiv.org/abs/2205.12486).'
- en: 'Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or: “TEXTure:
    Text-Guided Texturing of 3D Shapes”, 2023; [arXiv:2302.01721](http://arxiv.org/abs/2302.01721).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or: “TEXTure:
    三维形状的文本引导纹理化”，2023; [arXiv:2302.01721](http://arxiv.org/abs/2302.01721).'
- en: 'Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James
    Glass, Yulia Tsvetkov: “On the Blind Spots of Model-Based Evaluation Metrics for
    Text Generation”, 2022; [arXiv:2212.10020](http://arxiv.org/abs/2212.10020).'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James
    Glass, Yulia Tsvetkov: “关于文本生成模型评估指标的盲点”，2022; [arXiv:2212.10020](http://arxiv.org/abs/2212.10020).'
- en: 'Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown,
    Yoav Shoham: “In-Context Retrieval-Augmented Language Models”, 2023; [arXiv:2302.00083](http://arxiv.org/abs/2302.00083).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown,
    Yoav Shoham: “上下文检索增强语言模型”，2023; [arXiv:2302.00083](http://arxiv.org/abs/2302.00083).'
- en: 'Dacheng Li, Rulin Shao, Hongyi Wang, Han Guo, Eric P. Xing, Hao Zhang: “MPCFormer:
    fast, performant and private Transformer inference with MPC”, 2022; [arXiv:2211.01452](http://arxiv.org/abs/2211.01452).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dacheng Li, Rulin Shao, Hongyi Wang, Han Guo, Eric P. Xing, Hao Zhang: “MPCFormer:
    使用MPC进行快速、高性能和私密的Transformer推断”，2022; [arXiv:2211.01452](http://arxiv.org/abs/2211.01452).'
- en: 'Baolin Peng, Michel Galley, Pengcheng He, Chris Brockett, Lars Liden, Elnaz
    Nouri, Zhou Yu, Bill Dolan, Jianfeng Gao: “GODEL: Large-Scale Pre-Training for
    Goal-Directed Dialog”, 2022; [arXiv:2206.11309](http://arxiv.org/abs/2206.11309).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Baolin Peng, Michel Galley, Pengcheng He, Chris Brockett, Lars Liden, Elnaz
    Nouri, Zhou Yu, Bill Dolan, Jianfeng Gao: “GODEL: 面向目标导向对话的大规模预训练”，2022; [arXiv:2206.11309](http://arxiv.org/abs/2206.11309).'
- en: 'Egil Rønningstad, Erik Velldal, Lilja Øvrelid: “Entity-Level Sentiment Analysis
    (ELSA): An exploratory task survey”, 2023, Proceedings of the 29th International
    Conference on Computational Linguistics, 2022, pages 6773-6783; [arXiv:2304.14241](http://arxiv.org/abs/2304.14241).'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Egil Rønningstad, Erik Velldal, Lilja Øvrelid: “实体级情感分析（ELSA）：一项探索性任务调查”，2023，第29届国际计算语言学会议论文集，2022，6773-6783页;
    [arXiv:2304.14241](http://arxiv.org/abs/2304.14241).'
- en: 'Charlie Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, Sergey Levine: “Offline
    RL for Natural Language Generation with Implicit Language Q Learning”, 2022; [arXiv:2206.11871](http://arxiv.org/abs/2206.11871).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Charlie Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, Sergey Levine: “自然语言生成的离线RL与隐式语言Q学习”，2022;
    [arXiv:2206.11871](http://arxiv.org/abs/2206.11871).'
- en: 'Zhiruo Wang, Shuyan Zhou, Daniel Fried, Graham Neubig: “Execution-Based Evaluation
    for Open-Domain Code Generation”, 2022; [arXiv:2212.10481](http://arxiv.org/abs/2212.10481).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhiruo Wang, Shuyan Zhou, Daniel Fried, Graham Neubig: “基于执行的评估用于开放领域代码生成”，2022;
    [arXiv:2212.10481](http://arxiv.org/abs/2212.10481).'
- en: 'Minh-Long Luu, Zeyi Huang, Eric P. Xing, Yong Jae Lee, Haohan Wang: “Expeditious
    Saliency-guided Mix-up through Random Gradient Thresholding”, 2022; [arXiv:2212.04875](http://arxiv.org/abs/2212.04875).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Minh-Long Luu, Zeyi Huang, Eric P. Xing, Yong Jae Lee, Haohan Wang: “通过随机梯度阈值进行快速显著性引导的混合”，2022;
    [arXiv:2212.04875](http://arxiv.org/abs/2212.04875).'
- en: 'Jun Hao Liew, Hanshu Yan, Daquan Zhou, Jiashi Feng: “MagicMix: Semantic Mixing
    with Diffusion Models”, 2022; [arXiv:2210.16056](http://arxiv.org/abs/2210.16056).'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jun Hao Liew, Hanshu Yan, Daquan Zhou, Jiashi Feng: “MagicMix: 与扩散模型的语义混合”，2022;
    [arXiv:2210.16056](http://arxiv.org/abs/2210.16056).'
- en: 'Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah,
    Jianfeng Gao: “LiST: Lite Prompted Self-training Makes Parameter-Efficient Few-shot
    Learners”, 2021; [arXiv:2110.06274](http://arxiv.org/abs/2110.06274).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王雅青，苏布拉塔·穆克吉，刘晓东，高静，艾哈迈德·哈桑·阿瓦达拉，高建峰：“LiST：轻量级提示式自训练使参数高效的少样本学习器”，2021年；[arXiv:2110.06274](http://arxiv.org/abs/2110.06274)。
