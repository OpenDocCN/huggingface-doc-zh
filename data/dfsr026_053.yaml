- en: Overview
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/overview](https://huggingface.co/docs/diffusers/training/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/overview](https://huggingface.co/docs/diffusers/training/overview)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ¤— Diffusers provides a collection of training scripts for you to train your
    own diffusion models. You can find all of our training scripts in [diffusers/examples](https://github.com/huggingface/diffusers/tree/main/examples).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Diffusersä¸ºæ‚¨æä¾›äº†ä¸€ç³»åˆ—è®­ç»ƒè„šæœ¬ï¼Œè®©æ‚¨å¯ä»¥è®­ç»ƒè‡ªå·±çš„æ‰©æ•£æ¨¡å‹ã€‚æ‚¨å¯ä»¥åœ¨[diffusers/examples](https://github.com/huggingface/diffusers/tree/main/examples)ä¸­æ‰¾åˆ°æˆ‘ä»¬æ‰€æœ‰çš„è®­ç»ƒè„šæœ¬ã€‚
- en: 'Each training script is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªè®­ç»ƒè„šæœ¬éƒ½æ˜¯ï¼š
- en: '**Self-contained**: the training script does not depend on any local files,
    and all packages required to run the script are installed from the `requirements.txt`
    file.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‡ªåŒ…å«**ï¼šè®­ç»ƒè„šæœ¬ä¸ä¾èµ–äºä»»ä½•æœ¬åœ°æ–‡ä»¶ï¼Œæ‰€æœ‰è¿è¡Œè„šæœ¬æ‰€éœ€çš„è½¯ä»¶åŒ…éƒ½ä»`requirements.txt`æ–‡ä»¶ä¸­å®‰è£…ã€‚'
- en: '**Easy-to-tweak**: the training scripts are an example of how to train a diffusion
    model for a specific task and wonâ€™t work out-of-the-box for every training scenario.
    Youâ€™ll likely need to adapt the training script for your specific use-case. To
    help you with that, weâ€™ve fully exposed the data preprocessing code and the training
    loop so you can modify it for your own use.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ˜“äºè°ƒæ•´**ï¼šè®­ç»ƒè„šæœ¬æ˜¯å¦‚ä½•ä¸ºç‰¹å®šä»»åŠ¡è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç¤ºä¾‹ï¼Œå¹¶ä¸é€‚ç”¨äºæ¯ç§è®­ç»ƒåœºæ™¯ã€‚æ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“ç”¨ä¾‹è°ƒæ•´è®­ç»ƒè„šæœ¬ã€‚ä¸ºäº†å¸®åŠ©æ‚¨ï¼Œæˆ‘ä»¬å·²å®Œå…¨æš´éœ²äº†æ•°æ®é¢„å¤„ç†ä»£ç å’Œè®­ç»ƒå¾ªç¯ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¿®æ”¹ã€‚'
- en: '**Beginner-friendly**: the training scripts are designed to be beginner-friendly
    and easy to understand, rather than including the latest state-of-the-art methods
    to get the best and most competitive results. Any training methods we consider
    too complex are purposefully left out.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€‚åˆåˆå­¦è€…**ï¼šè®­ç»ƒè„šæœ¬æ—¨åœ¨é€‚åˆåˆå­¦è€…å¹¶æ˜“äºç†è§£ï¼Œè€Œä¸æ˜¯åŒ…å«æœ€æ–°çš„æœ€å…ˆè¿›æ–¹æ³•ä»¥è·å¾—æœ€ä½³å’Œæœ€å…·ç«äº‰åŠ›çš„ç»“æœã€‚æˆ‘ä»¬è®¤ä¸ºè¿‡äºå¤æ‚çš„ä»»ä½•è®­ç»ƒæ–¹æ³•éƒ½è¢«æœ‰æ„åœ°æ’é™¤åœ¨å¤–ã€‚'
- en: '**Single-purpose**: each training script is expressly designed for only one
    task to keep it readable and understandable.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å•ä¸€ç”¨é€”**ï¼šæ¯ä¸ªè®­ç»ƒè„šæœ¬ä¸“é—¨è®¾è®¡ç”¨äºä¸€ä¸ªä»»åŠ¡ï¼Œä»¥ä¿æŒå¯è¯»æ€§å’Œæ˜“ç†è§£æ€§ã€‚'
- en: 'Our current collection of training scripts include:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å½“å‰çš„è®­ç»ƒè„šæœ¬é›†åˆåŒ…æ‹¬ï¼š
- en: '| Training | SDXL-support | LoRA-support | Flax-support |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| è®­ç»ƒ | SDXLæ”¯æŒ | LoRAæ”¯æŒ | Flaxæ”¯æŒ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [unconditional image generation](https://github.com/huggingface/diffusers/tree/main/examples/unconditional_image_generation)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb)
    |  |  |  |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [æ— æ¡ä»¶å›¾åƒç”Ÿæˆ](https://github.com/huggingface/diffusers/tree/main/examples/unconditional_image_generation)
    [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb)
    |  |  |  |'
- en: '| [text-to-image](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image)
    | ğŸ‘ | ğŸ‘ | ğŸ‘ |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬åˆ°å›¾åƒ](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image)
    | ğŸ‘ | ğŸ‘ | ğŸ‘ |'
- en: '| [textual inversion](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb)
    |  |  | ğŸ‘ |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [æ–‡æœ¬åè½¬](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)
    [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb)
    |  |  | ğŸ‘ |'
- en: '| [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb)
    | ğŸ‘ | ğŸ‘ | ğŸ‘ |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [æ¢¦å¹»å±•å°](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)
    [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb)
    | ğŸ‘ | ğŸ‘ | ğŸ‘ |'
- en: '| [ControlNet](https://github.com/huggingface/diffusers/tree/main/examples/controlnet)
    | ğŸ‘ |  | ğŸ‘ |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [ControlNet](https://github.com/huggingface/diffusers/tree/main/examples/controlnet)
    | ğŸ‘ |  | ğŸ‘ |'
- en: '| [InstructPix2Pix](https://github.com/huggingface/diffusers/tree/main/examples/instruct_pix2pix)
    | ğŸ‘ |  |  |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [InstructPix2Pix](https://github.com/huggingface/diffusers/tree/main/examples/instruct_pix2pix)
    | ğŸ‘ |  |  |'
- en: '| [Custom Diffusion](https://github.com/huggingface/diffusers/tree/main/examples/custom_diffusion)
    |  |  |  |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| [è‡ªå®šä¹‰æ‰©æ•£](https://github.com/huggingface/diffusers/tree/main/examples/custom_diffusion)
    |  |  |  |'
- en: '| [T2I-Adapters](https://github.com/huggingface/diffusers/tree/main/examples/t2i_adapter)
    | ğŸ‘ |  |  |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [T2I-é€‚é…å™¨](https://github.com/huggingface/diffusers/tree/main/examples/t2i_adapter)
    | ğŸ‘ |  |  |'
- en: '| [Kandinsky 2.2](https://github.com/huggingface/diffusers/tree/main/examples/kandinsky2_2/text_to_image)
    |  | ğŸ‘ |  |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [åä¸æ–¯åŸº 2.2](https://github.com/huggingface/diffusers/tree/main/examples/kandinsky2_2/text_to_image)
    |  | ğŸ‘ |  |'
- en: '| [Wuerstchen](https://github.com/huggingface/diffusers/tree/main/examples/wuerstchen/text_to_image)
    |  | ğŸ‘ |  |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [ç»´æ–¯ç‰¹ç´](https://github.com/huggingface/diffusers/tree/main/examples/wuerstchen/text_to_image)
    |  | ğŸ‘ |  |'
- en: These examples are **actively** maintained, so please feel free to open an issue
    if they arenâ€™t working as expected. If you feel like another training example
    should be included, youâ€™re more than welcome to start a [Feature Request](https://github.com/huggingface/diffusers/issues/new?assignees=&labels=&template=feature_request.md&title=)
    to discuss your feature idea with us and whether it meets our criteria of being
    self-contained, easy-to-tweak, beginner-friendly, and single-purpose.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç¤ºä¾‹æ˜¯**ç§¯æ**ç»´æŠ¤çš„ï¼Œå¦‚æœå®ƒä»¬çš„å·¥ä½œæ–¹å¼ä¸ç¬¦åˆé¢„æœŸï¼Œè¯·éšæ—¶æå‡ºé—®é¢˜ã€‚å¦‚æœæ‚¨è®¤ä¸ºåº”è¯¥åŒ…å«å¦ä¸€ä¸ªè®­ç»ƒç¤ºä¾‹ï¼Œæ¬¢è¿æ‚¨å¼€å§‹ä¸€ä¸ª[åŠŸèƒ½è¯·æ±‚](https://github.com/huggingface/diffusers/issues/new?assignees=&labels=&template=feature_request.md&title=)ï¼Œä¸æˆ‘ä»¬è®¨è®ºæ‚¨çš„åŠŸèƒ½æƒ³æ³•ä»¥åŠå®ƒæ˜¯å¦ç¬¦åˆæˆ‘ä»¬çš„è‡ªåŒ…å«ã€æ˜“äºè°ƒæ•´ã€é€‚åˆåˆå­¦è€…å’Œå•ä¸€ç”¨é€”çš„æ ‡å‡†ã€‚
- en: Install
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®‰è£…
- en: 'Make sure you can successfully run the latest versions of the example scripts
    by installing the library from source in a new virtual environment:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿æ‚¨å¯ä»¥é€šè¿‡åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­ä»æºä»£ç å®‰è£…åº“æ¥æˆåŠŸè¿è¡Œæœ€æ–°ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼š
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then navigate to the folder of the training script (for example, [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth))
    and install the `requirements.txt` file. Some training scripts have a specific
    requirement file for SDXL, LoRA or Flax. If youâ€™re using one of these scripts,
    make sure you install its corresponding requirements file.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¼èˆªåˆ°è®­ç»ƒè„šæœ¬çš„æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚ï¼Œ[DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)ï¼‰å¹¶å®‰è£…`requirements.txt`æ–‡ä»¶ã€‚ä¸€äº›è®­ç»ƒè„šæœ¬æœ‰ç‰¹å®šçš„è¦æ±‚æ–‡ä»¶ï¼Œé€‚ç”¨äºSDXLã€LoRAæˆ–Flaxã€‚å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªè„šæœ¬ï¼Œè¯·ç¡®ä¿å®‰è£…å…¶ç›¸åº”çš„è¦æ±‚æ–‡ä»¶ã€‚
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To speedup training and reduce memory-usage, we recommend:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åŠ å¿«è®­ç»ƒé€Ÿåº¦å¹¶å‡å°‘å†…å­˜ä½¿ç”¨é‡ï¼Œæˆ‘ä»¬å»ºè®®ï¼š
- en: using PyTorch 2.0 or higher to automatically use [scaled dot product attention](../optimization/torch2.0#scaled-dot-product-attention)
    during training (you donâ€™t need to make any changes to the training code)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨PyTorch 2.0æˆ–æ›´é«˜ç‰ˆæœ¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨ä½¿ç”¨[ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)ï¼ˆæ‚¨æ— éœ€å¯¹è®­ç»ƒä»£ç è¿›è¡Œä»»ä½•æ›´æ”¹ï¼‰ã€‚
- en: installing [xFormers](../optimization/xformers) to enable memory-efficient attention
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®‰è£…[xFormers](../optimization/xformers)ä»¥å¯ç”¨å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚
