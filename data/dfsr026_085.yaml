- en: ONNX Runtime
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ONNX Runtime
- en: 'Original text: [https://huggingface.co/docs/diffusers/optimization/onnx](https://huggingface.co/docs/diffusers/optimization/onnx)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/optimization/onnx](https://huggingface.co/docs/diffusers/optimization/onnx)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '🤗 [Optimum](https://github.com/huggingface/optimum) provides a Stable Diffusion
    pipeline compatible with ONNX Runtime. You’ll need to install 🤗 Optimum with the
    following command for ONNX Runtime support:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 [Optimum](https://github.com/huggingface/optimum)提供了与ONNX Runtime兼容的稳定扩散管道。您需要使用以下命令安装🤗
    Optimum以支持ONNX Runtime：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This guide will show you how to use the Stable Diffusion and Stable Diffusion
    XL (SDXL) pipelines with ONNX Runtime.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将向您展示如何使用ONNX Runtime与稳定扩散和稳定扩散XL（SDXL）管道。
- en: Stable Diffusion
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散
- en: 'To load and run inference, use the [ORTStableDiffusionPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionPipeline).
    If you want to load a PyTorch model and convert it to the ONNX format on-the-fly,
    set `export=True`:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载并运行推理，请使用[ORTStableDiffusionPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionPipeline)。如果您想加载PyTorch模型并将其即时转换为ONNX格式，请设置`export=True`：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Generating multiple prompts in a batch seems to take too much memory. While
    we look into it, you may need to iterate instead of batching.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在批处理中生成多个提示似乎会占用太多内存。在我们研究此问题时，您可能需要逐个迭代而不是批处理。
- en: 'To export the pipeline in the ONNX format offline and use it later for inference,
    use the [`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)
    command:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 将管道以离线ONNX格式导出，并稍后用于推理，请使用[`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)命令：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then to perform inference (you don’t have to specify `export=True` again):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然后执行推理（您不必再次指定`export=True`）：
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/fef3f7dc8a705f8b94622883fd936702.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fef3f7dc8a705f8b94622883fd936702.png)'
- en: You can find more examples in 🤗 Optimum [documentation](https://huggingface.co/docs/optimum/),
    and Stable Diffusion is supported for text-to-image, image-to-image, and inpainting.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在🤗 Optimum [文档](https://huggingface.co/docs/optimum/)中找到更多示例，并且支持文本到图像、图像到图像和修复的稳定扩散。
- en: Stable Diffusion XL
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散XL
- en: 'To load and run inference with SDXL, use the [ORTStableDiffusionXLPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionXLPipeline):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载并运行SDXL推理，请使用[ORTStableDiffusionXLPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionXLPipeline)：
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To export the pipeline in the ONNX format and use it later for inference, use
    the [`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)
    command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要将管道以ONNX格式导出并稍后用于推理，请使用[`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)命令：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: SDXL in the ONNX format is supported for text-to-image and image-to-image.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 支持文本到图像和图像到图像的SDXL格式。
