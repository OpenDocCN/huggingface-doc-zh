- en: ONNX Runtime
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ONNX Runtime
- en: 'Original text: [https://huggingface.co/docs/diffusers/optimization/onnx](https://huggingface.co/docs/diffusers/optimization/onnx)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/optimization/onnx](https://huggingface.co/docs/diffusers/optimization/onnx)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'ğŸ¤— [Optimum](https://github.com/huggingface/optimum) provides a Stable Diffusion
    pipeline compatible with ONNX Runtime. Youâ€™ll need to install ğŸ¤— Optimum with the
    following command for ONNX Runtime support:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— [Optimum](https://github.com/huggingface/optimum)æä¾›äº†ä¸ONNX Runtimeå…¼å®¹çš„ç¨³å®šæ‰©æ•£ç®¡é“ã€‚æ‚¨éœ€è¦ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ğŸ¤—
    Optimumä»¥æ”¯æŒONNX Runtimeï¼š
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This guide will show you how to use the Stable Diffusion and Stable Diffusion
    XL (SDXL) pipelines with ONNX Runtime.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ONNX Runtimeä¸ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰ç®¡é“ã€‚
- en: Stable Diffusion
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£
- en: 'To load and run inference, use the [ORTStableDiffusionPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionPipeline).
    If you want to load a PyTorch model and convert it to the ONNX format on-the-fly,
    set `export=True`:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½å¹¶è¿è¡Œæ¨ç†ï¼Œè¯·ä½¿ç”¨[ORTStableDiffusionPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionPipeline)ã€‚å¦‚æœæ‚¨æƒ³åŠ è½½PyTorchæ¨¡å‹å¹¶å°†å…¶å³æ—¶è½¬æ¢ä¸ºONNXæ ¼å¼ï¼Œè¯·è®¾ç½®`export=True`ï¼š
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Generating multiple prompts in a batch seems to take too much memory. While
    we look into it, you may need to iterate instead of batching.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰¹å¤„ç†ä¸­ç”Ÿæˆå¤šä¸ªæç¤ºä¼¼ä¹ä¼šå ç”¨å¤ªå¤šå†…å­˜ã€‚åœ¨æˆ‘ä»¬ç ”ç©¶æ­¤é—®é¢˜æ—¶ï¼Œæ‚¨å¯èƒ½éœ€è¦é€ä¸ªè¿­ä»£è€Œä¸æ˜¯æ‰¹å¤„ç†ã€‚
- en: 'To export the pipeline in the ONNX format offline and use it later for inference,
    use the [`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)
    command:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç®¡é“ä»¥ç¦»çº¿ONNXæ ¼å¼å¯¼å‡ºï¼Œå¹¶ç¨åç”¨äºæ¨ç†ï¼Œè¯·ä½¿ç”¨[`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)å‘½ä»¤ï¼š
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then to perform inference (you donâ€™t have to specify `export=True` again):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ‰§è¡Œæ¨ç†ï¼ˆæ‚¨ä¸å¿…å†æ¬¡æŒ‡å®š`export=True`ï¼‰ï¼š
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/fef3f7dc8a705f8b94622883fd936702.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fef3f7dc8a705f8b94622883fd936702.png)'
- en: You can find more examples in ğŸ¤— Optimum [documentation](https://huggingface.co/docs/optimum/),
    and Stable Diffusion is supported for text-to-image, image-to-image, and inpainting.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨ğŸ¤— Optimum [æ–‡æ¡£](https://huggingface.co/docs/optimum/)ä¸­æ‰¾åˆ°æ›´å¤šç¤ºä¾‹ï¼Œå¹¶ä¸”æ”¯æŒæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒå’Œä¿®å¤çš„ç¨³å®šæ‰©æ•£ã€‚
- en: Stable Diffusion XL
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XL
- en: 'To load and run inference with SDXL, use the [ORTStableDiffusionXLPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionXLPipeline):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½å¹¶è¿è¡ŒSDXLæ¨ç†ï¼Œè¯·ä½¿ç”¨[ORTStableDiffusionXLPipeline](https://huggingface.co/docs/optimum/v1.16.2/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTStableDiffusionXLPipeline)ï¼š
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To export the pipeline in the ONNX format and use it later for inference, use
    the [`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)
    command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å°†ç®¡é“ä»¥ONNXæ ¼å¼å¯¼å‡ºå¹¶ç¨åç”¨äºæ¨ç†ï¼Œè¯·ä½¿ç”¨[`optimum-cli export`](https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)å‘½ä»¤ï¼š
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: SDXL in the ONNX format is supported for text-to-image and image-to-image.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¯æŒæ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒåˆ°å›¾åƒçš„SDXLæ ¼å¼ã€‚
