- en: Understanding how big of a model can fit on your machine
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解一个模型有多大可以适合您的机器
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator](https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator](https://huggingface.co/docs/accelerate/usage_guides/model_size_estimator)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: One very difficult aspect when exploring potential models to use on your machine
    is knowing just how big of a model will *fit* into memory with your current graphics
    card (such as loading the model onto CUDA).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索潜在模型在您的机器上是否适合内存（例如将模型加载到CUDA）时，一个非常困难的方面是知道一个模型有多大，才能适合您当前的显卡。
- en: To help alleviate this, 🤗 Accelerate has a CLI interface through `accelerate
    estimate-memory`. This tutorial will help walk you through using it, what to expect,
    and at the end link to the interactive demo hosted on the 🤗 Hub which will even
    let you post those results directly on the model repo!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助缓解这一问题，🤗 Accelerate通过`accelerate estimate-memory`提供了一个CLI界面。本教程将帮助您了解如何使用它，预期结果，并在最后链接到🤗
    Hub上托管的交互式演示，甚至让您直接发布这些结果到模型仓库！
- en: Currently we support searching for models that can be used in `timm` and `transformers`.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们支持搜索可以在`timm`和`transformers`中使用的模型。
- en: This API will load the model into memory on the `meta` device, so we are not
    actually downloading and loading the full weights of the model into memory, nor
    do we need to. As a result it’s perfectly fine to measure 8 billion parameter
    models (or more), without having to worry about if your CPU can handle it!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 此API将在`meta`设备上将模型加载到内存中，因此我们实际上并没有下载和加载模型的全部权重到内存中，也不需要。因此，可以完全放心地测量80亿参数模型（甚至更多），而不必担心您的CPU是否能够处理！
- en: Gradio Demos
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gradio演示
- en: 'Below are a few gradio demos related to what was described above. The first
    is the official Hugging Face memory estimation space, utilizing Accelerate directly:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是与上述描述相关的一些gradio演示。第一个是官方的Hugging Face内存估算空间，直接利用Accelerate：
- en: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=light](https://hf-accelerate-model-memory-usage.hf.space?__theme=light)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=light](https://hf-accelerate-model-memory-usage.hf.space?__theme=light)'
- en: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=dark](https://hf-accelerate-model-memory-usage.hf.space?__theme=dark)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://hf-accelerate-model-memory-usage.hf.space?__theme=dark](https://hf-accelerate-model-memory-usage.hf.space?__theme=dark)'
- en: A community member has taken the idea and expended it further, allowing you
    to filter models directly and see if you can run a particular LLM given GPU constraints
    and LoRA configurations. To play with it, see [here](https://huggingface.co/spaces/Vokturz/can-it-run-llm)
    for more details.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 社区成员进一步发展了这个想法，使您可以直接筛选模型，看看是否可以在给定GPU约束和LoRA配置下运行特定的LLM。要尝试，请查看[此处](https://huggingface.co/spaces/Vokturz/can-it-run-llm)以获取更多详细信息。
- en: The Command
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令
- en: When using `accelerate estimate-memory`, you need to pass in the name of the
    model you want to use, potentially the framework that model utilizing (if it can’t
    be found automatically), and the data types you want the model to be loaded in
    with.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`accelerate estimate-memory`时，您需要传入要使用的模型的名称，可能是该模型使用的框架（如果无法自动找到），以及您希望模型加载的数据类型。
- en: 'For example, here is how we can calculate the memory footprint for `bert-base-cased`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是如何计算`bert-base-cased`的内存占用量的方法：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will download the `config.json` for `bert-based-cased`, load the model
    on the `meta` device, and report back how much space it will use:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这将下载`bert-based-cased`的`config.json`，将模型加载到`meta`设备上，并报告它将使用多少空间：
- en: 'Memory Usage for loading `bert-base-cased`:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 加载`bert-base-cased`的内存使用情况：
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | 最大层 | 总大小 | 使用Adam进行训练 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 84.95 MB | 418.18 MB | 1.61 GB |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 84.95 MB | 418.18 MB | 1.61 GB |'
- en: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
- en: '| int8 | 21.24 MB | 103.29 MB | 413.18 MB |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| int8 | 21.24 MB | 103.29 MB | 413.18 MB |'
- en: '| int4 | 10.62 MB | 51.65 MB | 206.59 MB |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| int4 | 10.62 MB | 51.65 MB | 206.59 MB |'
- en: By default it will return all the supported dtypes (`int4` through `float32`),
    but if you are interested in specific ones these can be filtered.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，它将返回所有支持的数据类型（从`int4`到`float32`），但如果您对特定数据类型感兴趣，可以进行筛选。
- en: Specific libraries
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特定库
- en: If the source library cannot be determined automatically (like it could in the
    case of `bert-base-cased`), a library name can be passed in.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果无法自动确定源库（就像在`bert-base-cased`的情况下），则可以传入库名称。
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Memory Usage for loading `HuggingFaceM4/idefics-80b-instruct`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 加载`HuggingFaceM4/idefics-80b-instruct`的内存使用情况：
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | 最大层 | 总大小 | 使用Adam进行训练 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 3.02 GB | 297.12 GB | 1.16 TB |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 3.02 GB | 297.12 GB | 1.16 TB |'
- en: '| float16 | 1.51 GB | 148.56 GB | 594.24 GB |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 1.51 GB | 148.56 GB | 594.24 GB |'
- en: '| int8 | 772.52 MB | 74.28 GB | 297.12 GB |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| int8 | 772.52 MB | 74.28 GB | 297.12 GB |'
- en: '| int4 | 386.26 MB | 37.14 GB | 148.56 GB |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| int4 | 386.26 MB | 37.14 GB | 148.56 GB |'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Memory Usage for loading `timm/resnet50.a1_in1k`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 加载`timm/resnet50.a1_in1k`的内存使用情况：
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | 最大层 | 总大小 | 使用Adam进行训练 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 9.0 MB | 97.7 MB | 390.78 MB |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 9.0 MB | 97.7 MB | 390.78 MB |'
- en: '| float16 | 4.5 MB | 48.85 MB | 195.39 MB |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 4.5 MB | 48.85 MB | 195.39 MB |'
- en: '| int8 | 2.25 MB | 24.42 MB | 97.7 MB |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| int8 | 2.25 MB | 24.42 MB | 97.7 MB |'
- en: '| int4 | 1.12 MB | 12.21 MB | 48.85 MB |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| int4 | 1.12 MB | 12.21 MB | 48.85 MB |'
- en: Specific dtypes
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特定数据类型
- en: As mentioned earlier, while we return `int4` through `float32` by default, any
    dtype can be used from `float32`, `float16`, `int8`, and `int4`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，虽然默认情况下我们返回`int4`到`float32`，但任何数据类型都可以使用，包括`float32`、`float16`、`int8`和`int4`。
- en: 'To do so, pass them in after specifying `--dtypes`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，在指定`--dtypes`后传入它们：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Memory Usage for loading `bert-base-cased`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 加载`bert-base-cased`的内存使用情况：
- en: '| dtype | Largest Layer | Total Size | Training using Adam |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | 最大层 | 总大小 | 使用Adam进行训练 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| float32 | 84.95 MB | 413.18 MB | 1.61 GB |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| float32 | 84.95 MB | 413.18 MB | 1.61 GB |'
- en: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| float16 | 42.47 MB | 206.59 MB | 826.36 MB |'
- en: Caveats with this calculator
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这个计算器的注意事项
- en: This calculator will tell you how much memory is needed to purely load the model
    in, *not* to perform inference.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计算器将告诉您加载模型所需的内存量，*而不是*执行推断。
- en: This calculation is accurate within a few % of the actual value, so it is a
    very good view of just how much memory it will take. For instance loading `bert-base-cased`
    actually takes `413.68 MB` when loaded on CUDA in full precision, and the calculator
    estimates `413.18 MB`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计算准确度在实际值的几个百分点内，因此它非常好地展示了需要多少内存。例如，完整精度下加载`bert-base-cased`实际上需要`413.68
    MB`，而计算器估计为`413.18 MB`。
- en: When performing inference you can expect to add up to an additional 20% as found
    by [EleutherAI](https://blog.eleuther.ai/transformer-math/). We’ll be conducting
    research into finding a more accurate estimate to these values, and will update
    this calculator once done.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行推断时，您可以期望额外增加高达20%，这是由[EleutherAI](https://blog.eleuther.ai/transformer-math/)发现的。我们将进行研究，以找到这些值更准确的估计，并在完成后更新这个计算器。
