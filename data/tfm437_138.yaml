- en: BERTweet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BERTweet
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bertweet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bertweet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bertweet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bertweet)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The BERTweet model was proposed in [BERTweet: A pre-trained language model
    for English Tweets](https://www.aclweb.org/anthology/2020.emnlp-demos.2.pdf) by
    Dat Quoc Nguyen, Thanh Vu, Anh Tuan Nguyen.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'BERTweet模型是由Dat Quoc Nguyen、Thanh Vu和Anh Tuan Nguyen在[BERTweet: A pre-trained
    language model for English Tweets](https://www.aclweb.org/anthology/2020.emnlp-demos.2.pdf)中提出的。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从论文中摘录如下：
- en: '*We present BERTweet, the first public large-scale pre-trained language model
    for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin
    et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al.,
    2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base
    and XLM-R-base (Conneau et al., 2020), producing better performance results than
    the previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech
    tagging, Named-entity recognition and text classification.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们提出了BERTweet，这是第一个用于英文推文的公开大规模预训练语言模型。我们的BERTweet与BERT-base（Devlin等人，2019）具有相同的架构，使用RoBERTa预训练过程进行训练（Liu等人，2019）。实验表明，BERTweet优于强基线RoBERTa-base和XLM-R-base（Conneau等人，2020），在三个推文NLP任务（词性标注、命名实体识别和文本分类）上产生比先前最先进模型更好的性能结果。*'
- en: This model was contributed by [dqnguyen](https://huggingface.co/dqnguyen). The
    original code can be found [here](https://github.com/VinAIResearch/BERTweet).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[dqnguyen](https://huggingface.co/dqnguyen)贡献。原始代码可在[此处](https://github.com/VinAIResearch/BERTweet)找到。
- en: Usage example
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法示例
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This implementation is the same as BERT, except for tokenization method. Refer
    to [BERT documentation](bert) for API reference information.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现与BERT相同，仅在分词方法上有所不同。有关API参考信息，请参考[BERT文档](bert)。
- en: BertweetTokenizer
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BertweetTokenizer
- en: '### `class transformers.BertweetTokenizer`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BertweetTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L68)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L68)'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 词汇文件的路径。'
- en: '`merges_file` (`str`) — Path to the merges file.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges_file` (`str`) — 合并文件的路径。'
- en: '`normalization` (`bool`, *optional*, defaults to `False`) — Whether or not
    to apply a normalization preprocess.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalization` (`bool`, *optional*, defaults to `False`) — 是否应用规范化预处理。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — The beginning of sequence
    token that was used during pretraining. Can be used a sequence classifier token.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — 在预训练期间使用的序列开始标记。可用作序列分类器标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the beginning of sequence. The token used is the `cls_token`.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在使用特殊标记构建序列时，这不是用于序列开头的标记。使用的标记是`cls_token`。
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — The end of sequence
    token.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — 序列结束标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the end of sequence. The token used is the `sep_token`.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在使用特殊标记构建序列时，这不是用于序列结束的标记。使用的标记是`sep_token`。
- en: '`sep_token` (`str`, *optional*, defaults to `"</s>"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *optional*, defaults to `"</s>"`) — 分隔符标记，在从多个序列构建序列时使用，例如用于序列分类的两个序列或用于问题回答的文本和问题。它还用作使用特殊标记构建的序列的最后一个标记。'
- en: '`cls_token` (`str`, *optional*, defaults to `"<s>"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *optional*, defaults to `"<s>"`) — 用于进行序列分类时使用的分类器标记（对整个序列进行分类而不是每个标记进行分类）。在使用特殊标记构建时，它是序列的第一个标记。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — 未知标记。词汇表中不存在的标记无法转换为ID，而是设置为此标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`mask_token` (`str`, *optional*, defaults to `"<mask>"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *optional*, defaults to `"<mask>"`) — 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: Constructs a BERTweet tokenizer, using Byte-Pair-Encoding.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个使用字节对编码的BERTweet分词器。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此分词器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大部分主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `add_from_file`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_from_file`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L418)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L418)'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Loads a pre-existing dictionary from a text file and adds its symbols to this
    instance.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本文件加载预先存在的字典，并将其符号添加到此实例。
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L183)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L183)'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— 要添加特殊标记的ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 带有适当特殊标记的[input IDs](../glossary#input-ids)列表。
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A BERTweet sequence has the
    following format:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从序列或序列对构建用于序列分类任务的模型输入，通过连接和添加特殊标记。BERTweet序列的格式如下：
- en: 'single sequence: `<s> X </s>`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`<s> X </s>`
- en: 'pair of sequences: `<s> A </s></s> B </s>`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`<s> A </s></s> B </s>`
- en: '#### `convert_tokens_to_string`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `convert_tokens_to_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L384)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L384)'
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Converts a sequence of tokens (string) in a single string.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将一系列标记（字符串）转换为单个字符串。
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L237)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L237)'
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of zeros.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 零列表。
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. BERTweet does not make use of token type ids, therefore a list of zeros
    is returned.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从传递的两个序列创建一个用于序列对分类任务的掩码。BERTweet不使用标记类型ID，因此返回一个零列表。
- en: '#### `get_special_tokens_mask`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L209)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L209)'
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个ID列表。'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens`（`bool`，*可选*，默认为`False`）— 标记列表是否已经使用特殊标记格式化。'
- en: Returns
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个整数列表，范围为[0, 1]：1表示特殊标记，0表示序列标记。
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的标记列表中检索序列ID。在使用分词器`prepare_for_model`方法添加特殊标记时调用此方法。
- en: '#### `normalizeToken`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `normalizeToken`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L357)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L357)'
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Normalize tokens in a Tweet
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 规范化推文中的标记
- en: '#### `normalizeTweet`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `normalizeTweet`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L323)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bertweet/tokenization_bertweet.py#L323)'
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Normalize a raw Tweet
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 规范化原始推文
