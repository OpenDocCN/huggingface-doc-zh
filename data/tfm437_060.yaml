- en: Benchmarks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/benchmarks](https://huggingface.co/docs/transformers/v4.37.2/en/benchmarks)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/benchmarks](https://huggingface.co/docs/transformers/v4.37.2/en/benchmarks)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face’s Benchmarking tools are deprecated and it is advised to use external
    Benchmarking libraries to measure the speed and memory complexity of Transformer
    models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face的基准测试工具已被弃用，建议使用外部基准测试库来衡量Transformer模型的速度和内存复杂性。
- en: Let’s take a look at how 🤗 Transformers models can be benchmarked, best practices,
    and already available benchmarks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何对🤗 Transformers模型进行基准测试，最佳实践以及已有的基准测试。
- en: A notebook explaining in more detail how to benchmark 🤗 Transformers models
    can be found [here](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[此处](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb)找到更详细解释如何对🤗
    Transformers模型进行基准测试的笔记本。
- en: How to benchmark 🤗 Transformers models
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何对🤗 Transformers模型进行基准测试
- en: The classes `PyTorchBenchmark` and `TensorFlowBenchmark` allow to flexibly benchmark
    🤗 Transformers models. The benchmark classes allow us to measure the *peak memory
    usage* and *required time* for both *inference* and *training*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`PyTorchBenchmark`和`TensorFlowBenchmark`类允许灵活地对🤗 Transformers模型进行基准测试。基准类允许我们测量*峰值内存使用量*和*所需时间*，用于*推理*和*训练*。'
- en: Hereby, *inference* is defined by a single forward pass, and *training* is defined
    by a single forward pass and backward pass.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在此，*推理*由单个前向传递定义，*训练*由单个前向传递和反向传递定义。
- en: The benchmark classes `PyTorchBenchmark` and `TensorFlowBenchmark` expect an
    object of type `PyTorchBenchmarkArguments` and `TensorFlowBenchmarkArguments`,
    respectively, for instantiation. `PyTorchBenchmarkArguments` and `TensorFlowBenchmarkArguments`
    are data classes and contain all relevant configurations for their corresponding
    benchmark class. In the following example, it is shown how a BERT model of type
    *bert-base-cased* can be benchmarked.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基准类`PyTorchBenchmark`和`TensorFlowBenchmark`分别期望使用`PyTorchBenchmarkArguments`和`TensorFlowBenchmarkArguments`类型的对象进行实例化。`PyTorchBenchmarkArguments`和`TensorFlowBenchmarkArguments`是数据类，包含其对应基准类的所有相关配置。在以下示例中，展示了如何对类型为*bert-base-cased*的BERT模型进行基准测试。
- en: PytorchHide Pytorch content
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch隐藏了Pytorch内容
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: TensorFlowHide TensorFlow content
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow隐藏了TensorFlow内容
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, three arguments are given to the benchmark argument data classes, namely
    `models`, `batch_sizes`, and `sequence_lengths`. The argument `models` is required
    and expects a `list` of model identifiers from the [model hub](https://huggingface.co/models)
    The `list` arguments `batch_sizes` and `sequence_lengths` define the size of the
    `input_ids` on which the model is benchmarked. There are many more parameters
    that can be configured via the benchmark argument data classes. For more detail
    on these one can either directly consult the files `src/transformers/benchmark/benchmark_args_utils.py`,
    `src/transformers/benchmark/benchmark_args.py` (for PyTorch) and `src/transformers/benchmark/benchmark_args_tf.py`
    (for Tensorflow). Alternatively, running the following shell commands from root
    will print out a descriptive list of all configurable parameters for PyTorch and
    Tensorflow respectively.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，基准参数数据类给出了三个参数，分别是`models`、`batch_sizes`和`sequence_lengths`。参数`models`是必需的，期望从[model
    hub](https://huggingface.co/models)中的模型标识符列表。`list`参数`batch_sizes`和`sequence_lengths`定义了对模型进行基准测试的`input_ids`的大小。还有许多其他参数可以通过基准参数数据类进行配置。有关这些参数的更多详细信息，可以直接查阅文件`src/transformers/benchmark/benchmark_args_utils.py`、`src/transformers/benchmark/benchmark_args.py`（用于PyTorch）和`src/transformers/benchmark/benchmark_args_tf.py`（用于Tensorflow）。或者，从根目录运行以下shell命令将分别打印出PyTorch和Tensorflow的所有可配置参数的描述性列表。
- en: PytorchHide Pytorch content
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch隐藏了Pytorch内容
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: An instantiated benchmark object can then simply be run by calling `benchmark.run()`.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过调用`benchmark.run()`来简单运行实例化的基准对象。
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: TensorFlowHide TensorFlow content
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow隐藏了TensorFlow内容
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: An instantiated benchmark object can then simply be run by calling `benchmark.run()`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过调用`benchmark.run()`来简单运行实例化的基准对象。
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By default, the *time* and the *required memory* for *inference* are benchmarked.
    In the example output above the first two sections show the result corresponding
    to *inference time* and *inference memory*. In addition, all relevant information
    about the computing environment, *e.g.* the GPU type, the system, the library
    versions, etc… are printed out in the third section under *ENVIRONMENT INFORMATION*.
    This information can optionally be saved in a *.csv* file when adding the argument
    `save_to_csv=True` to `PyTorchBenchmarkArguments` and `TensorFlowBenchmarkArguments`
    respectively. In this case, every section is saved in a separate *.csv* file.
    The path to each *.csv* file can optionally be defined via the argument data classes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，对*推理*的*时间*和*所需内存*进行基准测试。在上面的示例输出中，前两个部分显示了与*推理时间*和*推理内存*对应的结果。此外，关于计算环境的所有相关信息，*例如*
    GPU类型、系统、库版本等，都会在第三部分的*环境信息*下打印出来。当向`PyTorchBenchmarkArguments`和`TensorFlowBenchmarkArguments`分别添加参数`save_to_csv=True`时，此信息可以选择保存在*.csv*文件中。在这种情况下，每个部分都保存在单独的*.csv*文件中。可以通过参数数据类可选地定义每个*.csv*文件的路径。
- en: Instead of benchmarking pre-trained models via their model identifier, *e.g.*
    `bert-base-uncased`, the user can alternatively benchmark an arbitrary configuration
    of any available model class. In this case, a `list` of configurations must be
    inserted with the benchmark args as follows.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以选择通过其模型标识符，*例如* `bert-base-uncased`，对预训练模型进行基准测试，也可以选择对任何可用模型类的任意配置进行基准测试。在这种情况下，必须在基准参数中插入一组配置列表。如下所示。
- en: PytorchHide Pytorch content
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch隐藏了Pytorch内容
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: TensorFlowHide TensorFlow content
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow隐藏了TensorFlow内容
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Again, *inference time* and *required memory* for *inference* are measured,
    but this time for customized configurations of the `BertModel` class. This feature
    can especially be helpful when deciding for which configuration the model should
    be trained.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，*推理时间*和*所需内存*用于*推理*的测量，但这次是针对`BertModel`类的自定义配置。在决定应该为哪种配置训练模型时，此功能尤其有帮助。
- en: Benchmark best practices
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试最佳实践
- en: This section lists a couple of best practices one should be aware of when benchmarking
    a model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本节列出了在对模型进行基准测试时应注意的一些最佳实践。
- en: Currently, only single device benchmarking is supported. When benchmarking on
    GPU, it is recommended that the user specifies on which device the code should
    be run by setting the `CUDA_VISIBLE_DEVICES` environment variable in the shell,
    *e.g.* `export CUDA_VISIBLE_DEVICES=0` before running the code.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前仅支持单设备基准测试。在GPU上进行基准测试时，建议用户通过在shell中设置`CUDA_VISIBLE_DEVICES`环境变量来指定代码应在哪个设备上运行，例如在运行代码之前设置`export
    CUDA_VISIBLE_DEVICES=0`。
- en: The option `no_multi_processing` should only be set to `True` for testing and
    debugging. To ensure accurate memory measurement it is recommended to run each
    memory benchmark in a separate process by making sure `no_multi_processing` is
    set to `True`.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选项`no_multi_processing`应仅在测试和调试时设置为`True`。为了确保准确的内存测量，建议通过确保将`no_multi_processing`设置为`True`来在单独的进程中运行每个内存基准测试。
- en: One should always state the environment information when sharing the results
    of a model benchmark. Results can vary heavily between different GPU devices,
    library versions, etc., so that benchmark results on their own are not very useful
    for the community.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分享模型基准测试结果时，应始终说明环境信息。由于不同的GPU设备、库版本等之间的结果可能会有很大差异，因此单独的基准测试结果对社区来说并不是非常有用。
- en: Sharing your benchmark
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分享您的基准测试
- en: 'Previously all available core models (10 at the time) have been benchmarked
    for *inference time*, across many different settings: using PyTorch, with and
    without TorchScript, using TensorFlow, with and without XLA. All of those tests
    were done across CPUs (except for TensorFlow XLA) and GPUs.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，所有可用的核心模型（当时为10个）都已针对*推理时间*进行了基准测试，涵盖了许多不同的设置：使用PyTorch，使用TorchScript或不使用，使用TensorFlow，使用XLA或不使用。所有这些测试都是在CPU（除了TensorFlow
    XLA）和GPU上进行的。
- en: The approach is detailed in the [following blogpost](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2)
    and the results are available [here](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法在[以下博文](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2)中有详细说明，结果可在[此处](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing)查看。
- en: With the new *benchmark* tools, it is easier than ever to share your benchmark
    results with the community
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 有了新的*基准*工具，与社区分享基准测试结果比以往更容易
- en: '[PyTorch Benchmarking Results](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch基准测试结果](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md)。'
- en: '[TensorFlow Benchmarking Results](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow基准测试结果](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md)。'
