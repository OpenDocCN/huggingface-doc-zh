- en: ğŸ¤— Hugging Face Agents.js
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¤— Hugging Face Agents.js
- en: 'Original text: [https://huggingface.co/docs/huggingface.js/agents/README](https://huggingface.co/docs/huggingface.js/agents/README)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/huggingface.js/agents/README](https://huggingface.co/docs/huggingface.js/agents/README)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: A way to call Hugging Face models and Inference Endpoints from natural language,
    using an LLM.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§ä»è‡ªç„¶è¯­è¨€ä¸­è°ƒç”¨Hugging Faceæ¨¡å‹å’Œæ¨ç†ç«¯ç‚¹çš„æ–¹æ³•ï¼Œä½¿ç”¨LLMã€‚
- en: Install
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®‰è£…
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Deno
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Deno
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Usage
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨æ³•
- en: Agents.js leverages LLMs hosted as Inference Endpoints on HF, so you need to
    create an account and generate an [access token](https://huggingface.co/settings/tokens).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Agents.jsåˆ©ç”¨åœ¨HFä¸Šæ‰˜ç®¡çš„LLMä½œä¸ºæ¨ç†ç«¯ç‚¹ï¼Œå› æ­¤æ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ªå¸æˆ·å¹¶ç”Ÿæˆä¸€ä¸ª[è®¿é—®ä»¤ç‰Œ](https://huggingface.co/settings/tokens)ã€‚
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Choose your LLM
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é€‰æ‹©æ‚¨çš„LLM
- en: You can also use your own LLM, by calling one of the `LLMFrom*` functions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥é€šè¿‡è°ƒç”¨`LLMFrom*`å‡½æ•°ä¹‹ä¸€æ¥ä½¿ç”¨è‡ªå·±çš„LLMã€‚
- en: From the hub
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ¥è‡ªhub
- en: You can specify any valid model on the hub as long as they have an API.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åªè¦å®ƒä»¬æœ‰APIï¼Œæ‚¨å¯ä»¥æŒ‡å®šhubä¸Šçš„ä»»ä½•æœ‰æ•ˆæ¨¡å‹ã€‚
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: From your own endpoints
  id: totrans-16
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä»æ‚¨è‡ªå·±çš„ç«¯ç‚¹
- en: You can also specify your own endpoint, as long as it implements the same API,
    for exemple using [text generation inference](https://github.com/huggingface/text-generation-inference)
    and [Inference Endpoints](https://huggingface.co/inference-endpoints).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥æŒ‡å®šè‡ªå·±çš„ç«¯ç‚¹ï¼Œåªè¦å®ƒå®ç°ç›¸åŒçš„APIï¼Œä¾‹å¦‚ä½¿ç”¨[text generation inference](https://github.com/huggingface/text-generation-inference)å’Œ[Inference
    Endpoints](https://huggingface.co/inference-endpoints)ã€‚
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Custom LLM
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰LLM
- en: 'A LLM in this context is defined as any async function that takes a string
    input and returns a string. For example if you wanted to use the OpenAI API you
    could do so like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLLMè¢«å®šä¹‰ä¸ºä»»ä½•å¼‚æ­¥å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²è¾“å…¥å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨OpenAI APIï¼Œæ‚¨å¯ä»¥è¿™æ ·åšï¼š
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Tools
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å·¥å…·
- en: By default, agents ship with 4 tools. (textToImage, textToSpeech, imageToText,
    speechToText)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œä»£ç†ç¨‹åºé…å¤‡æœ‰4ç§å·¥å…·ã€‚ ï¼ˆtextToImageï¼ŒtextToSpeechï¼ŒimageToTextï¼ŒspeechToTextï¼‰
- en: But you can expand the list of tools easily by creating new tools and passing
    them at initialization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æ‚¨å¯ä»¥é€šè¿‡åˆ›å»ºæ–°å·¥å…·å¹¶åœ¨åˆå§‹åŒ–æ—¶ä¼ é€’å®ƒä»¬æ¥è½»æ¾æ‰©å±•å·¥å…·åˆ—è¡¨ã€‚
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Dependencies
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¾èµ–
- en: '`@huggingface/inference` : Required to call the inference endpoints themselves.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@huggingface/inference`ï¼šéœ€è¦è°ƒç”¨æ¨ç†ç«¯ç‚¹æœ¬èº«ã€‚'
