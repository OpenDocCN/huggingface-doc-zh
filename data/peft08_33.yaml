- en: Tuners
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调谐器
- en: 'Original text: [https://huggingface.co/docs/peft/package_reference/tuners](https://huggingface.co/docs/peft/package_reference/tuners)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/peft/package_reference/tuners](https://huggingface.co/docs/peft/package_reference/tuners)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: A tuner (or adapter) is a module that can be plugged into a `torch.nn.Module`.
    `BaseTuner` base class for other tuners and provides shared methods and attributes
    for preparing an adapter configuration and replacing a target module with the
    adapter module. `BaseTunerLayer` is a base class for adapter layers. It offers
    methods and attributes for managing adapters such as activating and disabling
    adapters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 调谐器（或适配器）是可以插入到`torch.nn.Module`中的模块。`BaseTuner`是其他调谐器的基类，并为准备适配器配置和用适配器模块替换目标模块提供共享方法和属性。`BaseTunerLayer`是适配器层的基类。它提供了管理适配器的方法和属性，如激活和禁用适配器。
- en: BaseTuner
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BaseTuner
- en: '### `class peft.tuners.tuners_utils.BaseTuner`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.tuners.tuners_utils.BaseTuner`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L91)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L91)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to which the adapter tuner layers will
    be attached.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`torch.nn.Module`）— 适配器调谐器层将附加到的模型。'
- en: '`forward` (`Callable`) — The forward method of the model.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forward`（`Callable`）— 模型的前向方法。'
- en: '`peft_config` (`Union[`PeftConfig`, dict[str, PeftConfig]]`) — The adapter
    configuration object, it should be a dictionary of `str` to `PeftConfig` objects.
    One can also pass a PeftConfig object and a new adapter will be created with the
    default name `adapter` or create a new dictionary with a key `adapter_name` and
    a value of that peft config.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config`（`Union[`PeftConfig`, dict[str, PeftConfig]]`）— 适配器配置对象，应该是一个`str`到`PeftConfig`对象的字典。也可以传递一个PeftConfig对象，将创建一个默认名称为`adapter`的新适配器，或创建一个具有键`adapter_name`和该peft配置值的新字典。'
- en: '`config` (`dict[str, Any]`) — The model configuration object, it should be
    a dictionary of `str` to `Any` objects.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（`dict[str, Any]`）— 模型配置对象，应该是一个`str`到`Any`对象的字典。'
- en: '`targeted_module_names` (`list[str]`) — The list of module names that were
    actually adapted. Can be useful to inspect if you want to quickly double-check
    that the `config.target_modules` where specified correctly.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`targeted_module_names`（`list[str]`）— 实际上被调整的模块名称列表。如果要快速检查`config.target_modules`是否被正确指定，这可能很有用。'
- en: A base tuner model that provides the common methods and attributes for all tuners
    that are injectable into a torch.nn.Module
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提供所有可注入到torch.nn.Module中的调谐器共有方法和属性的基本调谐器模型
- en: 'For adding a new Tuner class, one needs to overwrite the following methods:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加一个新的Tuner类，需要重写以下方法：
- en: '`_prepare_adapter_config`: A private method to eventually prepare the adapter
    config, for example in case the field `target_modules` is missing.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_prepare_adapter_config`：一个私有方法，最终准备适配器配置，例如在缺少字段`target_modules`的情况下。 '
- en: '`_create_and_replace`: A private method to create and replace the target module
    with the adapter module.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_create_and_replace`：一个私有方法，用于创建并替换目标模块为适配器模块。'
- en: '`_check_target_module_exists`: A private helper method to check if the passed
    module’s key name matches any of the target modules in the adapter_config.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_check_target_module_exists`：一个私有辅助方法，用于检查传递的模块键名称是否与适配器配置中的任何目标模块匹配。'
- en: The easiest is to check what is done in the `peft.tuners.lora.LoraModel` class.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是查看`peft.tuners.lora.LoraModel`类中的操作。
- en: '#### `inject_adapter`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `inject_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L245)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L245)'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`nn.Module`) — The model to be tuned.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`nn.Module`）— 要调整的模型。'
- en: '`adapter_name` (`str`) — The adapter name.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`（`str`）— 适配器名称。'
- en: Creates adapter layers and replaces the target modules with the adapter layers.
    This method is called under the hood by `peft.mapping.get_peft_model` if a non-prompt
    tuning adapter class is passed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 创建适配器层并用适配器层替换目标模块。如果传递了一个非提示调谐适配器类，则此方法将在幕后被`peft.mapping.get_peft_model`调用。
- en: The corresponding PEFT config is directly retrieved from the `peft_config` attribute
    of the BaseTuner class.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的PEFT配置直接从BaseTuner类的`peft_config`属性中检索。
- en: '#### `merge_adapter`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `merge_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L323)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L323)'
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`safe_merge` (`bool`, *optional*) — If `True`, the merge operation will be
    performed in a copy of the original weights and check for NaNs before merging
    the weights. This is useful if you want to check if the merge operation will produce
    NaNs. Defaults to `False`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_merge`（`bool`，*可选*）— 如果为`True`，将在原始权重的副本中执行合并操作，并在合并权重之前检查NaN。如果要检查合并操作是否会产生NaN，则这很有用。默认为`False`。'
- en: '`adapter_names` (`list[str]`, *optional*) — The list of adapter names that
    should be merged. If `None`, all active adapters will be merged. Defaults to `None`.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_names`（`list[str]`，*可选*）— 应该合并的适配器名称列表。如果为`None`，则将合并所有活动适配器。默认为`None`。'
- en: This method merges the adapter layers into the base model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将适配器层合并到基本模型中。
- en: Merging adapters can lead to a speed up of the forward pass. A copy of the adapter
    weights is still kept in memory, which is required to unmerge the adapters. In
    order to merge the adapter weights without keeping them in memory, please call
    `merge_and_unload`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 合并适配器可以加快前向传递的速度。适配器权重的副本仍然保存在内存中，这是解除合并适配器所必需的。为了在不保留内存中的情况下合并适配器权重，请调用`merge_and_unload`。
- en: '#### `unmerge_adapter`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unmerge_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L345)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L345)'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This method unmerges all merged adapter layers from the base model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法从基本模型中取消合并所有合并的适配器层。
- en: BaseTunerLayer
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BaseTunerLayer
- en: '### `class peft.tuners.tuners_utils.BaseTunerLayer`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.tuners.tuners_utils.BaseTunerLayer`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L363)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L363)'
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`is_pluggable` (`bool`, *optional*) — Whether the adapter layer can be plugged
    to any pytorch module'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_pluggable`（`bool`，*可选*) — 适配器层是否可以插入到任何pytorch模块中'
- en: '`active_adapters` (Union[List`str`, `str`], *optional*) — The name of the active
    adapter.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`active_adapters`（Union[List`str`，`str`], *可选*) — 活动适配器的名称。'
- en: A tuner layer mixin that provides the common methods and attributes for all
    tuners.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个调谐器层mixin，为所有调谐器提供共同的方法和属性。
- en: '#### `delete_adapter`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `delete_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L505)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L505)'
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`adapter_name` (`str`) — The name of the adapter to delete'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`（`str`） — 要删除的适配器的名称'
- en: Delete an adapter from the layer
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从层中删除一个适配器
- en: This should be called on all adapter layers, or else we will get an inconsistent
    state.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该在所有适配器层上调用，否则我们将得到一个不一致的状态。
- en: This method will also set a new active adapter if the deleted adapter was an
    active adapter. It is important that the new adapter is chosen in a deterministic
    way, so that the same adapter is chosen on all layers.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果删除的适配器是活动适配器，此方法还将设置一个新的活动适配器。重要的是选择新的适配器是以确定性方式进行的，以便在所有层上选择相同的适配器。
- en: '#### `enable_adapters`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_adapters`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L445)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L445)'
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`enabled` (bool) — True to enable adapters, False to disable adapters'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enabled`（bool） — True表示启用适配器，False表示禁用适配器'
- en: Toggle the enabling and disabling of adapters
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 切换适配器的启用和禁用
- en: Takes care of setting the requires_grad flag for the adapter weights.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 负责设置适配器权重的requires_grad标志。
- en: '#### `get_base_layer`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_base_layer`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L390)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L390)'
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: (Recursively) get the base_layer.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: （递归地）获取基础层。
- en: This is necessary for the case that the tuner layer wraps another tuner layer.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于调谐器层包装另一个调谐器层的情况是必要的。
- en: '#### `set_adapter`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L463)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/tuners_utils.py#L463)'
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`adapter_name` (`str` or `List[str]`) — Name of the adapter(s) to be activated.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`（`str`或`List[str]`） — 要激活的适配器的名称。'
- en: Set the active adapter(s).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 设置活动适配器。
- en: Additionally, this function will set the specified adapters to trainable (i.e.,
    requires_grad=True). If this is not desired, use the following code.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，此函数将设置指定的适配器为可训练（即requires_grad=True）。如果不需要此功能，请使用以下代码。
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
