- en: Builder classes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„å»ºå™¨ç±»
- en: 'Original text: [https://huggingface.co/docs/datasets/package_reference/builder_classes](https://huggingface.co/docs/datasets/package_reference/builder_classes)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'åŸæ–‡é“¾æ¥: [https://huggingface.co/docs/datasets/package_reference/builder_classes](https://huggingface.co/docs/datasets/package_reference/builder_classes)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Builders
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ„å»ºå™¨
- en: 'ğŸ¤— Datasets relies on two main classes during the dataset building process:
    [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    and [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— æ•°æ®é›†åœ¨æ•°æ®é›†æ„å»ºè¿‡ç¨‹ä¸­ä¾èµ–äºä¸¤ä¸ªä¸»è¦ç±»ï¼š[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    å’Œ [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)ã€‚
- en: '### `class datasets.DatasetBuilder`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.DatasetBuilder`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L214)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L214)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`cache_dir` (`str`, *optional*) â€” Directory to cache data. Defaults to `"~/.cache/huggingface/datasets"`.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str`, *å¯é€‰*) â€” ç¼“å­˜æ•°æ®çš„ç›®å½•ã€‚é»˜è®¤ä¸º `"~/.cache/huggingface/datasets"`ã€‚'
- en: '`dataset_name` (`str`, *optional*) â€” Name of the dataset, if different from
    the builder name. Useful for packaged builders like csv, imagefolder, audiofolder,
    etc. to reflect the difference between datasets that use the same packaged builder.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_name` (`str`, *å¯é€‰*) â€” æ•°æ®é›†çš„åç§°ï¼Œå¦‚æœä¸æ„å»ºå™¨åç§°ä¸åŒã€‚å¯¹äºæ‰“åŒ…çš„æ„å»ºå™¨ï¼ˆå¦‚ csvã€imagefolderã€audiofolder
    ç­‰ï¼‰ï¼Œç”¨äºåæ˜ ä½¿ç”¨ç›¸åŒæ‰“åŒ…æ„å»ºå™¨çš„æ•°æ®é›†ä¹‹é—´çš„å·®å¼‚ã€‚'
- en: '`config_name` (`str`, *optional*) â€” Name of the dataset configuration. It affects
    the data generated on disk. Different configurations will have their own subdirectories
    and versions. If not provided, the default configuration is used (if it exists).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_name` (`str`, *å¯é€‰*) â€” æ•°æ®é›†é…ç½®çš„åç§°ã€‚å®ƒä¼šå½±å“ç£ç›˜ä¸Šç”Ÿæˆçš„æ•°æ®ã€‚ä¸åŒçš„é…ç½®å°†æœ‰è‡ªå·±çš„å­ç›®å½•å’Œç‰ˆæœ¬ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚'
- en: Added in 2.3.0
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨ 2.3.0 ä¸­æ·»åŠ 
- en: Parameter `name` was renamed to `config_name`.
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å‚æ•° `name` å·²é‡å‘½åä¸º `config_name`ã€‚
- en: '`hash` (`str`, *optional*) â€” Hash specific to the dataset code. Used to update
    the caching directory when the dataset loading script code is updated (to avoid
    reusing old data). The typical caching directory (defined in `self._relative_data_dir`)
    is `name/version/hash/`.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hash` (`str`, *å¯é€‰*) â€” ç‰¹å®šäºæ•°æ®é›†ä»£ç çš„å“ˆå¸Œå€¼ã€‚ç”¨äºåœ¨æ•°æ®é›†åŠ è½½è„šæœ¬ä»£ç æ›´æ–°æ—¶æ›´æ–°ç¼“å­˜ç›®å½•ï¼ˆä»¥é¿å…é‡ç”¨æ—§æ•°æ®ï¼‰ã€‚å…¸å‹çš„ç¼“å­˜ç›®å½•ï¼ˆåœ¨
    `self._relative_data_dir` ä¸­å®šä¹‰ï¼‰æ˜¯ `name/version/hash/`ã€‚'
- en: '`base_path` (`str`, *optional*) â€” Base path for relative paths that are used
    to download files. This can be a remote URL.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_path` (`str`, *å¯é€‰*) â€” ç”¨äºä¸‹è½½æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„çš„åŸºæœ¬è·¯å¾„ã€‚è¿™å¯ä»¥æ˜¯è¿œç¨‹ URLã€‚'
- en: '`features` ([Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features),
    *optional*) â€” Features types to use with this dataset. It can be used to change
    the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    types of a dataset, for example.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`features` ([Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features),
    *å¯é€‰*) â€” ç”¨äºæ­¤æ•°æ®é›†çš„ç‰¹å¾ç±»å‹ã€‚å®ƒå¯ä»¥ç”¨äºæ›´æ”¹æ•°æ®é›†çš„ [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    ç±»å‹ï¼Œä¾‹å¦‚ã€‚'
- en: '`token` (`str` or `bool`, *optional*) â€” String or boolean to use as Bearer
    token for remote files on the Datasets Hub. If `True`, will get token from `"~/.huggingface"`.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œæ•°æ®é›†ä¸­è¿œç¨‹æ–‡ä»¶çš„ Bearer token çš„å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º `True`ï¼Œå°†ä»
    `"~/.huggingface"` è·å–ä»¤ç‰Œã€‚'
- en: '`repo_id` (`str`, *optional*) â€” ID of the dataset repository. Used to distinguish
    builders with the same name but not coming from the same namespace, for example
    â€œsquadâ€ and â€œlhoestq/squadâ€ repo IDs. In the latter, the builder name would be
    â€œlhoestq___squadâ€.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`, *å¯é€‰*) â€” æ•°æ®é›†å­˜å‚¨åº“çš„ IDã€‚ç”¨äºåŒºåˆ†å…·æœ‰ç›¸åŒåç§°ä½†ä¸æ¥è‡ªç›¸åŒå‘½åç©ºé—´çš„æ„å»ºå™¨ï¼Œä¾‹å¦‚â€œsquadâ€å’Œâ€œlhoestq/squadâ€å­˜å‚¨åº“
    IDã€‚åœ¨åè€…ä¸­ï¼Œæ„å»ºå™¨åç§°å°†æ˜¯â€œlhoestq___squadâ€ã€‚'
- en: '`data_files` (`str` or `Sequence` or `Mapping`, *optional*) â€” Path(s) to source
    data file(s). For builders like â€œcsvâ€ or â€œjsonâ€ that need the user to specify
    data files. They can be either local or remote files. For convenience, you can
    use a `DataFilesDict`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_files` (`str` æˆ– `Sequence` æˆ– `Mapping`, *å¯é€‰*) â€” æºæ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚å¯¹äºåƒâ€œcsvâ€æˆ–â€œjsonâ€è¿™æ ·éœ€è¦ç”¨æˆ·æŒ‡å®šæ•°æ®æ–‡ä»¶çš„æ„å»ºå™¨ã€‚å®ƒä»¬å¯ä»¥æ˜¯æœ¬åœ°æ–‡ä»¶æˆ–è¿œç¨‹æ–‡ä»¶ã€‚ä¸ºæ–¹ä¾¿èµ·è§ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨
    `DataFilesDict`ã€‚'
- en: '`data_dir` (`str`, *optional*) â€” Path to directory containing source data file(s).
    Use only if `data_files` is not passed, in which case it is equivalent to passing
    `os.path.join(data_dir, "**")` as `data_files`. For builders that require manual
    download, it must be the path to the local directory containing the manually downloaded
    data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_dir` (`str`, *å¯é€‰*) â€” åŒ…å«æºæ•°æ®æ–‡ä»¶çš„ç›®å½•è·¯å¾„ã€‚ä»…åœ¨æœªä¼ é€’ `data_files` çš„æƒ…å†µä¸‹ä½¿ç”¨ï¼Œæ­¤æ—¶å®ƒç­‰æ•ˆäºå°† `os.path.join(data_dir,
    "**")` ä½œä¸º `data_files`ã€‚å¯¹äºéœ€è¦æ‰‹åŠ¨ä¸‹è½½çš„æ„å»ºå™¨ï¼Œå®ƒå¿…é¡»æ˜¯åŒ…å«æ‰‹åŠ¨ä¸‹è½½æ•°æ®çš„æœ¬åœ°ç›®å½•çš„è·¯å¾„ã€‚'
- en: '`storage_options` (`dict`, *optional*) â€” Key/value pairs to be passed on to
    the dataset file-system backend, if any.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`storage_options` (`dict`, *å¯é€‰*) â€” è¦ä¼ é€’ç»™æ•°æ®é›†æ–‡ä»¶ç³»ç»Ÿåç«¯çš„é”®/å€¼å¯¹ï¼Œå¦‚æœæœ‰çš„è¯ã€‚'
- en: '`writer_batch_size` (`int`, *optional*) â€” Batch size used by the ArrowWriter.
    It defines the number of samples that are kept in memory before writing them and
    also the length of the arrow chunks. None means that the ArrowWriter will use
    its default value.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`writer_batch_size` (`int`, *å¯é€‰*) â€” ArrowWriter ä½¿ç”¨çš„æ‰¹å¤„ç†å¤§å°ã€‚å®ƒå®šä¹‰äº†åœ¨å†™å…¥ä¹‹å‰åœ¨å†…å­˜ä¸­ä¿ç•™çš„æ ·æœ¬æ•°é‡ï¼Œä¹Ÿå®šä¹‰äº†ç®­å¤´å—çš„é•¿åº¦ã€‚None
    è¡¨ç¤º ArrowWriter å°†ä½¿ç”¨å…¶é»˜è®¤å€¼ã€‚'
- en: '`name` (`str`) â€” Configuration name for the dataset.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name` (`str`) â€” æ•°æ®é›†çš„é…ç½®åç§°ã€‚'
- en: Deprecated in 2.3.0
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨ 2.3.0 ä¸­å·²å¼ƒç”¨
- en: Use `config_name` instead.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯·ä½¿ç”¨ `config_name`ã€‚
- en: '*`*config_kwargs` (additional keyword arguments) â€” Keyword arguments to be
    passed to the corresponding builder configuration class, set on the class attribute
    [DatasetBuilder.BUILDER_CONFIG_CLASS](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig).
    The builder configuration class is [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    or a subclass of it.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*config_kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼‰ â€” è¦ä¼ é€’ç»™ç›¸åº”æ„å»ºå™¨é…ç½®ç±»çš„å…³é”®å­—å‚æ•°ï¼Œè®¾ç½®åœ¨ç±»å±æ€§ [DatasetBuilder.BUILDER_CONFIG_CLASS](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ä¸Šã€‚æ„å»ºå™¨é…ç½®ç±»æ˜¯ [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    æˆ–å…¶å­ç±»ã€‚'
- en: Abstract base class for all datasets.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ•°æ®é›†çš„æŠ½è±¡åŸºç±»ã€‚
- en: '`DatasetBuilder` has 3 key methods:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`DatasetBuilder` æœ‰ 3 ä¸ªå…³é”®æ–¹æ³•ï¼š'
- en: '`DatasetBuilder.info`: Documents the dataset, including feature names, types,
    shapes, version, splits, citation, etc.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder.info`ï¼šè®°å½•æ•°æ®é›†ï¼ŒåŒ…æ‹¬ç‰¹å¾åç§°ã€ç±»å‹ã€å½¢çŠ¶ã€ç‰ˆæœ¬ã€æ‹†åˆ†ã€å¼•ç”¨ç­‰ã€‚'
- en: '[DatasetBuilder.download_and_prepare()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder.download_and_prepare):
    Downloads the source data and writes it to disk.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DatasetBuilder.download_and_prepare()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder.download_and_prepare):
    ä¸‹è½½æºæ•°æ®å¹¶å°†å…¶å†™å…¥ç£ç›˜ã€‚'
- en: '[DatasetBuilder.as_dataset()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder.as_dataset):
    Generates a [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DatasetBuilder.as_dataset()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder.as_dataset):
    ç”Ÿæˆä¸€ä¸ª[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)ã€‚'
- en: Some `DatasetBuilder`s expose multiple variants of the dataset by defining a
    [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    subclass and accepting a config object (or name) on construction. Configurable
    datasets expose a pre-defined set of configurations in `DatasetBuilder.builder_configs()`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›`DatasetBuilder`é€šè¿‡å®šä¹‰ä¸€ä¸ª[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)å­ç±»å¹¶åœ¨æ„é€ æ—¶æ¥å—ä¸€ä¸ªé…ç½®å¯¹è±¡ï¼ˆæˆ–åç§°ï¼‰æ¥å…¬å¼€æ•°æ®é›†çš„å¤šä¸ªå˜ä½“ã€‚å¯é…ç½®çš„æ•°æ®é›†åœ¨`DatasetBuilder.builder_configs()`ä¸­å…¬å¼€äº†ä¸€ç»„é¢„å®šä¹‰çš„é…ç½®ã€‚
- en: '#### `as_dataset`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `as_dataset`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L1166)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L1166)'
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`split` (`datasets.Split`) â€” Which subset of the data to return.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split` (`datasets.Split`) â€” è¦è¿”å›çš„æ•°æ®çš„å“ªä¸ªå­é›†ã€‚'
- en: '`run_post_process` (`bool`, defaults to `True`) â€” Whether to run post-processing
    dataset transforms and/or add indexes.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`run_post_process` (`bool`ï¼Œé»˜è®¤ä¸º`True`) â€” æ˜¯å¦è¿è¡Œåå¤„ç†æ•°æ®é›†è½¬æ¢å’Œ/æˆ–æ·»åŠ ç´¢å¼•ã€‚'
- en: '`verification_mode` ([VerificationMode](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.VerificationMode)
    or `str`, defaults to `BASIC_CHECKS`) â€” Verification mode determining the checks
    to run on the downloaded/processed dataset information (checksums/size/splits/â€¦).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verification_mode` ([VerificationMode](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.VerificationMode)æˆ–`str`ï¼Œé»˜è®¤ä¸º`BASIC_CHECKS`)
    â€” ç¡®å®šè¦åœ¨ä¸‹è½½/å¤„ç†çš„æ•°æ®é›†ä¿¡æ¯ä¸Šè¿è¡Œçš„æ£€æŸ¥çš„éªŒè¯æ¨¡å¼ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†/...ï¼‰ã€‚'
- en: Added in 2.9.1
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.9.1ä¸­æ·»åŠ 
- en: '`ignore_verifications` (`bool`, defaults to `False`) â€” Whether to ignore the
    verifications of the downloaded/processed dataset information (checksums/size/splits/â€¦).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_verifications` (`bool`ï¼Œé»˜è®¤ä¸º`False`) â€” æ˜¯å¦å¿½ç•¥ä¸‹è½½/å¤„ç†çš„æ•°æ®é›†ä¿¡æ¯çš„éªŒè¯ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†/...ï¼‰ã€‚'
- en: Deprecated in 2.9.1
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.9.1ä¸­å¼ƒç”¨
- en: '`ignore_verifications` was deprecated in version 2.9.1 and will be removed
    in 3.0.0. Please use `verification_mode` instead.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`ignore_verifications`åœ¨ç‰ˆæœ¬2.9.1ä¸­å·²å¼ƒç”¨ï¼Œå°†åœ¨3.0.0ä¸­åˆ é™¤ã€‚è¯·æ”¹ç”¨`verification_mode`ã€‚'
- en: '`in_memory` (`bool`, defaults to `False`) â€” Whether to copy the data in-memory.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_memory` (`bool`ï¼Œé»˜è®¤ä¸º`False`) â€” æ˜¯å¦å°†æ•°æ®å¤åˆ¶åˆ°å†…å­˜ä¸­ã€‚'
- en: Return a Dataset for the specified split.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›æŒ‡å®šæ‹†åˆ†çš„æ•°æ®é›†ã€‚
- en: 'Example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `download_and_prepare`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download_and_prepare`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L744)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L744)'
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`output_dir` (`str`, *optional*) â€” Output directory for the dataset. Default
    to this builderâ€™s `cache_dir`, which is inside `~/.cache/huggingface/datasets`
    by default.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_dir` (`str`ï¼Œ*å¯é€‰çš„*) â€” æ•°æ®é›†çš„è¾“å‡ºç›®å½•ã€‚é»˜è®¤ä¸ºæ­¤æ„å»ºå™¨çš„`cache_dir`ï¼Œé»˜è®¤æƒ…å†µä¸‹ä½äº`~/.cache/huggingface/datasets`å†…ã€‚'
- en: Added in 2.5.0
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.5.0ä¸­æ·»åŠ 
- en: '`download_config` (`DownloadConfig`, *optional*) â€” Specific download configuration
    parameters.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`download_config` (`DownloadConfig`ï¼Œ*å¯é€‰çš„*) â€” ç‰¹å®šçš„ä¸‹è½½é…ç½®å‚æ•°ã€‚'
- en: '`download_mode` ([DownloadMode](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadMode)
    or `str`, *optional*) â€” Select the download/generate mode, default to `REUSE_DATASET_IF_EXISTS`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`download_mode` ([DownloadMode](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadMode)æˆ–`str`ï¼Œ*å¯é€‰çš„*)
    â€” é€‰æ‹©ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ï¼Œé»˜è®¤ä¸º`REUSE_DATASET_IF_EXISTS`ã€‚'
- en: '`verification_mode` ([VerificationMode](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.VerificationMode)
    or `str`, defaults to `BASIC_CHECKS`) â€” Verification mode determining the checks
    to run on the downloaded/processed dataset information (checksums/size/splits/â€¦).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verification_mode` ([VerificationMode](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.VerificationMode)æˆ–`str`ï¼Œé»˜è®¤ä¸º`BASIC_CHECKS`)
    â€” ç¡®å®šè¦åœ¨ä¸‹è½½/å¤„ç†çš„æ•°æ®é›†ä¿¡æ¯ä¸Šè¿è¡Œçš„æ£€æŸ¥çš„éªŒè¯æ¨¡å¼ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†/...ï¼‰ã€‚'
- en: Added in 2.9.1
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.9.1ä¸­æ·»åŠ 
- en: '`ignore_verifications` (`bool`, defaults to `False`) â€” Ignore the verifications
    of the downloaded/processed dataset information (checksums/size/splits/â€¦).'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_verifications` (`bool`ï¼Œé»˜è®¤ä¸º`False`) â€” å¿½ç•¥ä¸‹è½½/å¤„ç†çš„æ•°æ®é›†ä¿¡æ¯çš„éªŒè¯ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†/...ï¼‰ã€‚'
- en: Deprecated in 2.9.1
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.9.1ä¸­å¼ƒç”¨
- en: '`ignore_verifications` was deprecated in version 2.9.1 and will be removed
    in 3.0.0. Please use `verification_mode` instead.'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`ignore_verifications`åœ¨ç‰ˆæœ¬2.9.1ä¸­å·²å¼ƒç”¨ï¼Œå°†åœ¨3.0.0ä¸­åˆ é™¤ã€‚è¯·æ”¹ç”¨`verification_mode`ã€‚'
- en: '`try_from_hf_gcs` (`bool`) â€” If `True`, it will try to download the already
    prepared dataset from the HF Google cloud storage.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`try_from_hf_gcs` (`bool`) â€” å¦‚æœä¸º`True`ï¼Œå°†å°è¯•ä»HF Googleäº‘å­˜å‚¨ä¸­ä¸‹è½½å·²å‡†å¤‡å¥½çš„æ•°æ®é›†ã€‚'
- en: '`dl_manager` (`DownloadManager`, *optional*) â€” Specific `DownloadManger` to
    use.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dl_manager` (`DownloadManager`ï¼Œ*å¯é€‰çš„*) â€” è¦ä½¿ç”¨çš„ç‰¹å®š`DownloadManger`ã€‚'
- en: '`base_path` (`str`, *optional*) â€” Base path for relative paths that are used
    to download files. This can be a remote url. If not specified, the value of the
    `base_path` attribute (`self.base_path`) will be used instead.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_path` (`str`ï¼Œ*å¯é€‰çš„*) â€” ç”¨äºä¸‹è½½æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„çš„åŸºæœ¬è·¯å¾„ã€‚è¿™å¯ä»¥æ˜¯ä¸€ä¸ªè¿œç¨‹urlã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨`base_path`å±æ€§ï¼ˆ`self.base_path`ï¼‰çš„å€¼ã€‚'
- en: '`use_auth_token` (`Union[str, bool]`, *optional*) â€” Optional string or boolean
    to use as Bearer token for remote files on the Datasets Hub. If True, or not specified,
    will get token from ~/.huggingface.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_auth_token` (`Union[str, bool]`ï¼Œ*å¯é€‰çš„*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶åœ¨æ•°æ®é›†ä¸­å¿ƒçš„Bearerä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸ºTrueï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä»~/.huggingfaceè·å–ä»¤ç‰Œã€‚'
- en: Deprecated in 2.7.1
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.7.1ä¸­å¼ƒç”¨
- en: Pass `use_auth_token` to `load_dataset_builder` instead.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†`use_auth_token`ä¼ é€’ç»™`load_dataset_builder`ã€‚
- en: '`file_format` (`str`, *optional*) â€” Format of the data files in which the dataset
    will be written. Supported formats: â€œarrowâ€, â€œparquetâ€. Default to â€œarrowâ€ format.
    If the format is â€œparquetâ€, then image and audio data are embedded into the Parquet
    files instead of pointing to local files.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`file_format` (`str`, *å¯é€‰*) â€” æ•°æ®æ–‡ä»¶çš„æ ¼å¼ï¼Œæ•°æ®é›†å°†è¢«å†™å…¥å…¶ä¸­ã€‚æ”¯æŒçš„æ ¼å¼: â€œarrowâ€, â€œparquetâ€ã€‚é»˜è®¤ä¸ºâ€œarrowâ€æ ¼å¼ã€‚å¦‚æœæ ¼å¼ä¸ºâ€œparquetâ€ï¼Œåˆ™å›¾åƒå’ŒéŸ³é¢‘æ•°æ®å°†åµŒå…¥åˆ°Parquetæ–‡ä»¶ä¸­ï¼Œè€Œä¸æ˜¯æŒ‡å‘æœ¬åœ°æ–‡ä»¶ã€‚'
- en: Added in 2.5.0
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.5.0ä¸­æ·»åŠ 
- en: '`max_shard_size` (`Union[str, int]`, *optional*) â€” Maximum number of bytes
    written per shard, default is â€œ500MBâ€. The size is based on uncompressed data
    size, so in practice your shard files may be smaller than `max_shard_size` thanks
    to Parquet compression for example.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`Union[str, int]`, *å¯é€‰*) â€” æ¯ä¸ªåˆ†ç‰‡å†™å…¥çš„æœ€å¤§å­—èŠ‚æ•°ï¼Œé»˜è®¤ä¸ºâ€œ500MBâ€ã€‚è¯¥å¤§å°åŸºäºæœªå‹ç¼©æ•°æ®å¤§å°ï¼Œå› æ­¤å®é™…ä¸Šï¼Œç”±äºParquetå‹ç¼©ï¼Œæ‚¨çš„åˆ†ç‰‡æ–‡ä»¶å¯èƒ½æ¯”`max_shard_size`å°ã€‚'
- en: Added in 2.5.0
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.5.0ä¸­æ·»åŠ 
- en: '`num_proc` (`int`, *optional*, defaults to `None`) â€” Number of processes when
    downloading and generating the dataset locally. Multiprocessing is disabled by
    default.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_proc` (`int`, *å¯é€‰*, é»˜è®¤ä¸º `None`) â€” ä¸‹è½½å’Œæœ¬åœ°ç”Ÿæˆæ•°æ®é›†æ—¶çš„è¿›ç¨‹æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ç¦ç”¨å¤šè¿›ç¨‹ã€‚'
- en: Added in 2.7.0
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.7.0ä¸­æ·»åŠ 
- en: '`storage_options` (`dict`, *optional*) â€” Key/value pairs to be passed on to
    the caching file-system backend, if any.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`storage_options` (`dict`, *å¯é€‰*) â€” è¦ä¼ é€’ç»™ç¼“å­˜æ–‡ä»¶ç³»ç»Ÿåç«¯çš„é”®/å€¼å¯¹ã€‚'
- en: Added in 2.5.0
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.5.0ä¸­æ·»åŠ 
- en: '*`*download_and_prepare_kwargs` (additional keyword arguments) â€” Keyword arguments.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*download_and_prepare_kwargs` (é¢å¤–çš„å…³é”®å­—å‚æ•°) â€” å…³é”®å­—å‚æ•°ã€‚'
- en: Downloads and prepares dataset for reading.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å‡†å¤‡ç”¨äºè¯»å–çš„æ•°æ®é›†ã€‚
- en: 'Example:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: 'Download and prepare the dataset as Arrow files that can be loaded as a Dataset
    using `builder.as_dataset()`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å‡†å¤‡å¯ä»¥ä½¿ç”¨`builder.as_dataset()`åŠ è½½ä¸ºæ•°æ®é›†çš„Arrowæ–‡ä»¶ï¼š
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Download and prepare the dataset as sharded Parquet files locally:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å‡†å¤‡æœ¬åœ°ä½œä¸ºåˆ†ç‰‡Parquetæ–‡ä»¶çš„æ•°æ®é›†ï¼š
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Download and prepare the dataset as sharded Parquet files in a cloud storage:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å‡†å¤‡ä½œä¸ºåˆ†ç‰‡Parquetæ–‡ä»¶åœ¨äº‘å­˜å‚¨ä¸­çš„æ•°æ®é›†ï¼š
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `get_all_exported_dataset_infos`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_all_exported_dataset_infos`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L530)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L530)'
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Empty dict if doesnâ€™t exist
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä¸ºç©ºå­—å…¸
- en: 'Example:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `get_exported_dataset_info`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_exported_dataset_info`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L545)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L545)'
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Empty `DatasetInfo` if doesnâ€™t exist
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä¸ºç©º`DatasetInfo`
- en: 'Example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `get_imported_module_dir`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_imported_module_dir`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L736)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L736)'
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Return the path of the module of this class or subclass.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›æ­¤ç±»æˆ–å­ç±»çš„æ¨¡å—è·¯å¾„ã€‚
- en: '### `class datasets.GeneratorBasedBuilder`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.GeneratorBasedBuilder`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L1514)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L1514)'
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Base class for datasets with data generation based on dict generators.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºå­—å…¸ç”Ÿæˆå™¨çš„æ•°æ®ç”Ÿæˆçš„æ•°æ®é›†çš„åŸºç±»ã€‚
- en: '`GeneratorBasedBuilder` is a convenience class that abstracts away much of
    the data writing and reading of `DatasetBuilder`. It expects subclasses to implement
    generators of feature dictionaries across the dataset splits (`_split_generators`).
    See the method docstrings for details.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`GeneratorBasedBuilder`æ˜¯ä¸€ä¸ªæ–¹ä¾¿çš„ç±»ï¼Œå®ƒæŠ½è±¡äº†`DatasetBuilder`çš„è®¸å¤šæ•°æ®å†™å…¥å’Œè¯»å–ã€‚å®ƒæœŸæœ›å­ç±»å®ç°æ•°æ®é›†åˆ†å‰²ä¸­ç‰¹å¾å­—å…¸çš„ç”Ÿæˆå™¨ï¼ˆ`_split_generators`ï¼‰ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ–¹æ³•æ–‡æ¡£å­—ç¬¦ä¸²ã€‚'
- en: '### `class datasets.BeamBasedBuilder`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.BeamBasedBuilder`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L2028)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L2028)'
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Beam-based Builder.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºBeamçš„Builderã€‚
- en: '### `class datasets.ArrowBasedBuilder`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.ArrowBasedBuilder`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L1779)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L1779)'
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Base class for datasets with data generation based on Arrow loading functions
    (CSV/JSON/Parquet).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºArrowåŠ è½½å‡½æ•°ï¼ˆCSV/JSON/Parquetï¼‰çš„æ•°æ®ç”Ÿæˆçš„æ•°æ®é›†çš„åŸºç±»ã€‚
- en: '### `class datasets.BuilderConfig`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.BuilderConfig`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L100)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L100)'
- en: '[PRE15]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`name` (`str`, defaults to `default`) â€” The name of the configuration.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name` (`str`, é»˜è®¤ä¸º `default`) â€” é…ç½®çš„åç§°ã€‚'
- en: '`version` (`Version` or `str`, defaults to `0.0.0`) â€” The version of the configuration.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version` (`Version` æˆ– `str`, é»˜è®¤ä¸º `0.0.0`) â€” é…ç½®çš„ç‰ˆæœ¬ã€‚'
- en: '`data_dir` (`str`, *optional*) â€” Path to the directory containing the source
    data.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_dir` (`str`, *å¯é€‰*) â€” åŒ…å«æºæ•°æ®çš„ç›®å½•çš„è·¯å¾„ã€‚'
- en: '`data_files` (`str` or `Sequence` or `Mapping`, *optional*) â€” Path(s) to source
    data file(s).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_files` (`str` æˆ– `Sequence` æˆ– `Mapping`, *å¯é€‰*) â€” æºæ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚'
- en: '`description` (`str`, *optional*) â€” A human description of the configuration.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`description` (`str`, *å¯é€‰*) â€” é…ç½®çš„äººç±»æè¿°ã€‚'
- en: Base class for `DatasetBuilder` data configuration.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`DatasetBuilder`æ•°æ®é…ç½®çš„åŸºç±»ã€‚'
- en: '`DatasetBuilder` subclasses with data configuration options should subclass
    `BuilderConfig` and add their own properties.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰æ•°æ®é…ç½®é€‰é¡¹çš„`DatasetBuilder`å­ç±»åº”è¯¥ç»§æ‰¿`BuilderConfig`å¹¶æ·»åŠ è‡ªå·±çš„å±æ€§ã€‚
- en: '#### `create_config_id`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_config_id`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L144)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/builder.py#L144)'
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The config id is used to build the cache directory. By default it is equal
    to the config name. However the name of a config is not sufficient to have a unique
    identifier for the dataset being generated since it doesnâ€™t take into account:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®idç”¨äºæ„å»ºç¼“å­˜ç›®å½•ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒç­‰äºé…ç½®åç§°ã€‚ä½†æ˜¯ï¼Œé…ç½®çš„åç§°ä¸è¶³ä»¥ä¸ºç”Ÿæˆçš„æ•°æ®é›†æä¾›å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå› ä¸ºå®ƒæ²¡æœ‰è€ƒè™‘åˆ°ï¼š
- en: the config kwargs that can be used to overwrite attributes
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ä»¥ç”¨æ¥è¦†ç›–å±æ€§çš„é…ç½®kwargs
- en: the custom features used to write the dataset
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºç¼–å†™æ•°æ®é›†çš„è‡ªå®šä¹‰ç‰¹å¾
- en: the data_files for json/text/csv/pandas datasets
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: json/text/csv/pandasæ•°æ®é›†çš„æ•°æ®æ–‡ä»¶
- en: Therefore the config id is just the config name with an optional suffix based
    on these.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œé…ç½®IDåªæ˜¯é…ç½®åç§°ï¼Œæ ¹æ®è¿™äº›ï¼Œå¯ä»¥é€‰æ‹©æ·»åŠ åç¼€ã€‚
- en: Download
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹è½½
- en: '### `class datasets.DownloadManager`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.DownloadManager`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L263)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L263)'
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `download`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L406)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L406)'
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`url_or_urls` (`str` or `list` or `dict`) â€” URL or `list` or `dict` of URLs
    to download. Each URL is a `str`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_or_urls`ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰ - è¦ä¸‹è½½çš„URLæˆ–`list`æˆ–`dict`ã€‚æ¯ä¸ªURLéƒ½æ˜¯`str`ã€‚'
- en: Returns
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`str` or `list` or `dict`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`æˆ–`list`æˆ–`dict`'
- en: The downloaded paths matching the given input `url_or_urls`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½çš„è·¯å¾„ä¸ç»™å®šçš„è¾“å…¥`url_or_urls`åŒ¹é…ã€‚
- en: Download given URL(s).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½ç»™å®šçš„URLã€‚
- en: By default, only one process is used for download. Pass customized `download_config.num_proc`
    to change this behavior.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹ï¼Œä»…ä½¿ç”¨ä¸€ä¸ªè¿›ç¨‹è¿›è¡Œä¸‹è½½ã€‚ä¼ é€’è‡ªå®šä¹‰çš„`download_config.num_proc`ä»¥æ›´æ”¹æ­¤è¡Œä¸ºã€‚
- en: 'Example:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#### `download_and_extract`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download_and_extract`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L554)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L554)'
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`url_or_urls` (`str` or `list` or `dict`) â€” URL or `list` or `dict` of URLs
    to download and extract. Each URL is a `str`.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_or_urls`ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰ - è¦ä¸‹è½½å’Œæå–çš„URLæˆ–`list`æˆ–`dict`ã€‚æ¯ä¸ªURLéƒ½æ˜¯`str`ã€‚'
- en: Returns
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: extracted_path(s)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æå–çš„è·¯å¾„
- en: '`str`, extracted paths of given URL(s).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`ï¼Œæå–ç»™å®šURLçš„è·¯å¾„ã€‚'
- en: Download and extract given `url_or_urls`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶æå–ç»™å®šçš„`url_or_urls`ã€‚
- en: 'Is roughly equivalent to:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§è‡´ç›¸å½“äºï¼š
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#### `download_custom`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download_custom`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L359)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L359)'
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`url_or_urls` (`str` or `list` or `dict`) â€” URL or `list` or `dict` of URLs
    to download and extract. Each URL is a `str`.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_or_urls`ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰ - è¦ä¸‹è½½å’Œæå–çš„URLæˆ–`list`æˆ–`dict`ã€‚æ¯ä¸ªURLéƒ½æ˜¯`str`ã€‚'
- en: '`custom_download` (`Callable[src_url, dst_path]`) â€” The source URL and destination
    path. For example `tf.io.gfile.copy`, that lets you download from Google storage.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_download`ï¼ˆ`Callable[src_url, dst_path]`ï¼‰ - æºURLå’Œç›®æ ‡è·¯å¾„ã€‚ä¾‹å¦‚`tf.io.gfile.copy`ï¼Œå¯è®©æ‚¨ä»Googleå­˜å‚¨ä¸‹è½½ã€‚'
- en: Returns
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: downloaded_path(s)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½çš„è·¯å¾„
- en: '`str`, The downloaded paths matching the given input `url_or_urls`.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`ï¼ŒåŒ¹é…ç»™å®šè¾“å…¥`url_or_urls`çš„ä¸‹è½½è·¯å¾„ã€‚'
- en: Download given urls(s) by calling `custom_download`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è°ƒç”¨`custom_download`ä¸‹è½½ç»™å®šçš„URLã€‚
- en: 'Example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '#### `extract`'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `extract`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L508)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L508)'
- en: '[PRE24]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`path_or_paths` (path or `list` or `dict`) â€” Path of file to extract. Each
    path is a `str`.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path_or_paths`ï¼ˆè·¯å¾„æˆ–`list`æˆ–`dict`ï¼‰ - è¦æå–çš„æ–‡ä»¶è·¯å¾„ã€‚æ¯ä¸ªè·¯å¾„éƒ½æ˜¯`str`ã€‚'
- en: '`num_proc` (`int`) â€” Use multi-processing if `num_proc` > 1 and the length
    of `path_or_paths` is larger than `num_proc`.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_proc`ï¼ˆ`int`ï¼‰ - å¦‚æœ`num_proc` > 1ä¸”`path_or_paths`çš„é•¿åº¦å¤§äº`num_proc`ï¼Œåˆ™ä½¿ç”¨å¤šè¿›ç¨‹ã€‚'
- en: Deprecated in 2.6.2
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.6.2ä¸­å·²å¼ƒç”¨
- en: Pass `DownloadConfig(num_proc=<num_proc>)` to the initializer instead.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†`DownloadConfig(num_proc=<num_proc>)`ä¼ é€’ç»™åˆå§‹åŒ–ç¨‹åºã€‚
- en: Returns
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: extracted_path(s)
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: æå–çš„è·¯å¾„
- en: '`str`, The extracted paths matching the given input path_or_paths.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`ï¼ŒåŒ¹é…ç»™å®šè¾“å…¥`path_or_paths`çš„æå–è·¯å¾„ã€‚'
- en: Extract given path(s).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: æå–ç»™å®šçš„è·¯å¾„ã€‚
- en: 'Example:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#### `iter_archive`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `iter_archive`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L464)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L464)'
- en: '[PRE26]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`path_or_buf` (`str` or `io.BufferedReader`) â€” Archive path or archive binary
    file object.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path_or_buf`ï¼ˆ`str`æˆ–`io.BufferedReader`ï¼‰ - å­˜æ¡£è·¯å¾„æˆ–å­˜æ¡£äºŒè¿›åˆ¶æ–‡ä»¶å¯¹è±¡ã€‚'
- en: Yields
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: äº§å‡º
- en: '`tuple[str, io.BufferedReader]`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`tuple[str, io.BufferedReader]`'
- en: Iterate over files within an archive.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: è¿­ä»£å½’æ¡£ä¸­çš„æ–‡ä»¶ã€‚
- en: 'Example:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE27]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '#### `iter_files`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `iter_files`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L489)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L489)'
- en: '[PRE28]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`paths` (`str` or `list` of `str`) â€” Root paths.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`paths`ï¼ˆ`str`æˆ–`str`çš„`list`ï¼‰ - æ ¹è·¯å¾„ã€‚'
- en: Yields
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: äº§å‡º
- en: '`str`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: Iterate over file paths.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: è¿­ä»£æ–‡ä»¶è·¯å¾„ã€‚
- en: 'Example:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE29]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#### `ship_files_with_pipeline`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `ship_files_with_pipeline`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L310)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L310)'
- en: '[PRE30]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`downloaded_path_or_paths` (`str` or `list[str]` or `dict[str, str]`) â€” Nested
    structure containing the downloaded path(s).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`downloaded_path_or_paths`ï¼ˆ`str`æˆ–`list[str]`æˆ–`dict[str, str]ï¼‰ - åŒ…å«ä¸‹è½½è·¯å¾„çš„åµŒå¥—ç»“æ„ã€‚'
- en: '`pipeline` (`utils.beam_utils.BeamPipeline`) â€” Apache Beam Pipeline.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pipeline`ï¼ˆ`utils.beam_utils.BeamPipeline`ï¼‰ - Apache Beam Pipelineã€‚'
- en: Ship the files using Beam FileSystems to the pipeline temp dir.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Beam FileSystemså°†æ–‡ä»¶ä¼ é€åˆ°ç®¡é“ä¸´æ—¶ç›®å½•ã€‚
- en: '### `class datasets.StreamingDownloadManager`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.StreamingDownloadManager`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L969)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L969)'
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Download manager that uses the â€::â€ separator to navigate through (possibly
    remote) compressed archives. Contrary to the regular `DownloadManager`, the `download`
    and `extract` methods donâ€™t actually download nor extract data, but they rather
    return the path or url that could be opened using the `xopen` function which extends
    the built-in `open` function to stream data from remote files.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨â€::â€åˆ†éš”ç¬¦å¯¼èˆªï¼ˆå¯èƒ½æ˜¯è¿œç¨‹ï¼‰å‹ç¼©å­˜æ¡£çš„ä¸‹è½½ç®¡ç†å™¨ã€‚ä¸å¸¸è§„`DownloadManager`ç›¸åï¼Œ`download`å’Œ`extract`æ–¹æ³•å®é™…ä¸Šä¸ä¼šä¸‹è½½æˆ–æå–æ•°æ®ï¼Œè€Œæ˜¯è¿”å›å¯ä»¥ä½¿ç”¨`xopen`å‡½æ•°æ‰“å¼€çš„è·¯å¾„æˆ–URLï¼Œè¯¥å‡½æ•°æ‰©å±•äº†å†…ç½®çš„`open`å‡½æ•°ä»¥ä»è¿œç¨‹æ–‡ä»¶æµå¼ä¼ è¾“æ•°æ®ã€‚
- en: '#### `download`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L995)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L995)'
- en: '[PRE32]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`url_or_urls` (`str` or `list` or `dict`) â€” URL(s) of files to stream data
    from. Each url is a `str`.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_or_urls`ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰â€”è¦ä»ä¸­æµå¼ä¼ è¾“æ•°æ®çš„æ–‡ä»¶çš„URL(s)ã€‚æ¯ä¸ªURLéƒ½æ˜¯ä¸€ä¸ª`str`ã€‚'
- en: Returns
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: url(s)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: url(s)
- en: (`str` or `list` or `dict`), URL(s) to stream data from matching the given input
    url_or_urls.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰ï¼ŒURL(s)ä»¥åŒ¹é…ç»™å®šè¾“å…¥`url_or_urls`çš„æ•°æ®æµã€‚
- en: Normalize URL(s) of files to stream data from. This is the lazy version of `DownloadManager.download`
    for streaming.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: è§„èŒƒåŒ–è¦ä»ä¸­æµå¼ä¼ è¾“æ•°æ®çš„æ–‡ä»¶çš„URL(s)ã€‚è¿™æ˜¯ç”¨äºæµå¼ä¼ è¾“çš„`DownloadManager.download`çš„å»¶è¿Ÿç‰ˆæœ¬ã€‚
- en: 'Example:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE33]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '#### `download_and_extract`'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `download_and_extract`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1071)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1071)'
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`url_or_urls` (`str` or `list` or `dict`) â€” URL(s) to stream from data from.
    Each url is a `str`.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_or_urls`ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰â€”è¦ä»ä¸­æµå¼ä¼ è¾“æ•°æ®çš„URL(s)ã€‚æ¯ä¸ªURLéƒ½æ˜¯ä¸€ä¸ª`str`ã€‚'
- en: Returns
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: url(s)
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: url(s)
- en: (`str` or `list` or `dict`), URL(s) to stream data from matching the given input
    `url_or_urls`.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰ï¼ŒURL(s)ä»¥åŒ¹é…ç»™å®šè¾“å…¥`url_or_urls`çš„æ•°æ®æµã€‚
- en: Prepare given `url_or_urls` for streaming (add extraction protocol).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: å‡†å¤‡å¥½ç”¨äºæµå¼ä¼ è¾“çš„`url_or_urls`ï¼ˆæ·»åŠ æå–åè®®ï¼‰ã€‚
- en: This is the lazy version of `DownloadManager.download_and_extract` for streaming.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”¨äºæµå¼ä¼ è¾“çš„`DownloadManager.download_and_extract`çš„å»¶è¿Ÿç‰ˆæœ¬ã€‚
- en: 'Is equivalent to:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ç­‰åŒäºï¼š
- en: '[PRE35]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '#### `extract`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `extract`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1022)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1022)'
- en: '[PRE36]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`url_or_urls` (`str` or `list` or `dict`) â€” URL(s) of files to stream data
    from. Each url is a `str`.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_or_urls`ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰â€”è¦ä»ä¸­æµå¼ä¼ è¾“æ•°æ®çš„æ–‡ä»¶çš„URL(s)ã€‚æ¯ä¸ªURLéƒ½æ˜¯ä¸€ä¸ª`str`ã€‚'
- en: Returns
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: url(s)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: url(s)
- en: (`str` or `list` or `dict`), URL(s) to stream data from matching the given input
    `url_or_urls`.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆ`str`æˆ–`list`æˆ–`dict`ï¼‰ï¼ŒURL(s)ä»¥åŒ¹é…ç»™å®šè¾“å…¥`url_or_urls`çš„æ•°æ®æµã€‚
- en: Add extraction protocol for given url(s) for streaming.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºç»™å®šçš„URL(s)æ·»åŠ æå–åè®®ä»¥è¿›è¡Œæµå¼ä¼ è¾“ã€‚
- en: This is the lazy version of `DownloadManager.extract` for streaming.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”¨äºæµå¼ä¼ è¾“çš„`DownloadManager.extract`çš„å»¶è¿Ÿç‰ˆæœ¬ã€‚
- en: 'Example:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE37]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '#### `iter_archive`'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `iter_archive`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1091)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1091)'
- en: '[PRE38]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`urlpath_or_buf` (`str` or `io.BufferedReader`) â€” Archive path or archive binary
    file object.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urlpath_or_buf`ï¼ˆ`str`æˆ–`io.BufferedReader`ï¼‰â€”å­˜æ¡£è·¯å¾„æˆ–å­˜æ¡£äºŒè¿›åˆ¶æ–‡ä»¶å¯¹è±¡ã€‚'
- en: Yields
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: äº§é‡
- en: '`tuple[str, io.BufferedReader]`'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '`tuple[str, io.BufferedReader]`'
- en: Iterate over files within an archive.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å­˜æ¡£ä¸­éå†æ–‡ä»¶ã€‚
- en: 'Example:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE39]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '#### `iter_files`'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `iter_files`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1116)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/streaming_download_manager.py#L1116)'
- en: '[PRE40]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`urlpaths` (`str` or `list` of `str`) â€” Root paths.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urlpaths`ï¼ˆ`str`æˆ–`str`åˆ—è¡¨ï¼‰â€”æ ¹è·¯å¾„ã€‚'
- en: Yields
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: äº§é‡
- en: str
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: Iterate over files.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: éå†æ–‡ä»¶ã€‚
- en: 'Example:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE41]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '### `class datasets.DownloadConfig`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.DownloadConfig`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_config.py#L10)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_config.py#L10)'
- en: '[PRE42]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`cache_dir` (`str` or `Path`, *optional*) â€” Specify a cache directory to save
    the file to (overwrite the default cache dir).'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`ï¼ˆ`str`æˆ–`Path`ï¼Œ*å¯é€‰*ï¼‰â€”æŒ‡å®šä¸€ä¸ªç¼“å­˜ç›®å½•ä»¥ä¿å­˜æ–‡ä»¶ï¼ˆè¦†ç›–é»˜è®¤ç¼“å­˜ç›®å½•ï¼‰ã€‚'
- en: '`force_download` (`bool`, defaults to `False`) â€” If `True`, re-dowload the
    file even if itâ€™s already cached in the cache dir.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`ï¼ˆé»˜è®¤ä¸º`False`çš„`bool`ï¼‰â€”å¦‚æœä¸º`True`ï¼Œå³ä½¿æ–‡ä»¶å·²ç»ç¼“å­˜åœ¨ç¼“å­˜ç›®å½•ä¸­ï¼Œä¹Ÿä¼šé‡æ–°ä¸‹è½½æ–‡ä»¶ã€‚'
- en: '`resume_download` (`bool`, defaults to `False`) â€” If `True`, resume the download
    if an incompletely received file is found.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`ï¼ˆé»˜è®¤ä¸º`False`çš„`bool`ï¼‰â€”å¦‚æœä¸º`True`ï¼Œåˆ™åœ¨å‘ç°æœªå®Œå…¨æ¥æ”¶çš„æ–‡ä»¶æ—¶æ¢å¤ä¸‹è½½ã€‚'
- en: '`proxies` (`dict`, *optional*) â€”'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€”'
- en: '`user_agent` (`str`, *optional*) â€” Optional string or dict that will be appended
    to the user-agent on remote requests.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_agent`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€”å°†é™„åŠ åˆ°è¿œç¨‹è¯·æ±‚çš„ç”¨æˆ·ä»£ç†çš„å¯é€‰å­—ç¬¦ä¸²æˆ–å­—å…¸ã€‚'
- en: '`extract_compressed_file` (`bool`, defaults to `False`) â€” If `True` and the
    path point to a zip or tar file, extract the compressed file in a folder along
    the archive.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extract_compressed_file`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€”å¦‚æœä¸º`True`ä¸”è·¯å¾„æŒ‡å‘zipæˆ–taræ–‡ä»¶ï¼Œåˆ™åœ¨å­˜æ¡£æ—è¾¹æå–å‹ç¼©æ–‡ä»¶ã€‚'
- en: '`force_extract` (`bool`, defaults to `False`) â€” If `True` when `extract_compressed_file`
    is `True` and the archive was already extracted, re-extract the archive and override
    the folder where it was extracted.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_extract`ï¼ˆé»˜è®¤ä¸º`False`çš„`bool`ï¼‰â€”å¦‚æœ`extract_compressed_file`ä¸º`True`ä¸”å­˜æ¡£å·²ç»è¢«æå–ï¼Œåˆ™é‡æ–°æå–å­˜æ¡£å¹¶è¦†ç›–æå–å­˜æ¡£çš„æ–‡ä»¶å¤¹ã€‚'
- en: '`delete_extracted` (`bool`, defaults to `False`) â€” Whether to delete (or keep)
    the extracted files.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delete_extracted`ï¼ˆé»˜è®¤ä¸º`False`çš„`bool`ï¼‰â€”æ˜¯å¦åˆ é™¤ï¼ˆæˆ–ä¿ç•™ï¼‰æå–çš„æ–‡ä»¶ã€‚'
- en: '`use_etag` (`bool`, defaults to `True`) â€” Whether to use the ETag HTTP response
    header to validate the cached files.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_etag`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€”æ˜¯å¦ä½¿ç”¨ETag HTTPå“åº”å¤´æ¥éªŒè¯ç¼“å­˜æ–‡ä»¶ã€‚'
- en: '`num_proc` (`int`, *optional*) â€” The number of processes to launch to download
    the files in parallel.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_proc`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰â€”è¦å¹¶è¡Œä¸‹è½½æ–‡ä»¶çš„è¿›ç¨‹æ•°ã€‚'
- en: '`max_retries` (`int`, default to `1`) â€” The number of times to retry an HTTP
    request if it fails.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_retries`ï¼ˆé»˜è®¤ä¸º`1`çš„`int`ï¼‰â€”å¦‚æœHTTPè¯·æ±‚å¤±è´¥ï¼Œåˆ™é‡è¯•çš„æ¬¡æ•°ã€‚'
- en: '`token` (`str` or `bool`, *optional*) â€” Optional string or boolean to use as
    Bearer token for remote files on the Datasets Hub. If `True`, or not specified,
    will get token from `~/.huggingface`.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`ï¼ˆ`str`æˆ–`bool`ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨ä½œDatasets Hubä¸Šè¿œç¨‹æ–‡ä»¶çš„Bearerä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º`True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä»`~/.huggingface`è·å–ä»¤ç‰Œã€‚'
- en: '`use_auth_token` (`str` or `bool`, *optional*) â€” Optional string or boolean
    to use as Bearer token for remote files on the Datasets Hub. If `True`, or not
    specified, will get token from `~/.huggingface`.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_auth_token`ï¼ˆ`str`æˆ–`bool`ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨ä½œDatasets Hubä¸Šè¿œç¨‹æ–‡ä»¶çš„Bearerä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º`True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä»`~/.huggingface`è·å–ä»¤ç‰Œã€‚'
- en: Deprecated in 2.14.0
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨2.14.0ä¸­å·²å¼ƒç”¨
- en: '`use_auth_token` was deprecated in favor of `token` in version 2.14.0 and will
    be removed in 3.0.0.'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`use_auth_token`åœ¨ç‰ˆæœ¬2.14.0ä¸­å·²å¼ƒç”¨ï¼Œæ”¹ç”¨`token`ï¼Œå¹¶å°†åœ¨3.0.0ä¸­åˆ é™¤ã€‚'
- en: '`ignore_url_params` (`bool`, defaults to `False`) â€” Whether to strip all query
    parameters and fragments from the download URL before using it for caching the
    file.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_url_params`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€”åœ¨å°†å…¶ç”¨äºç¼“å­˜æ–‡ä»¶ä¹‹å‰ï¼Œæ˜¯å¦å‰¥ç¦»ä¸‹è½½URLä¸­çš„æ‰€æœ‰æŸ¥è¯¢å‚æ•°å’Œç‰‡æ®µã€‚'
- en: '`storage_options` (`dict`, *optional*) â€” Key/value pairs to be passed on to
    the dataset file-system backend, if any.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`storage_options`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€”è¦ä¼ é€’ç»™æ•°æ®é›†æ–‡ä»¶ç³»ç»Ÿåç«¯çš„é”®/å€¼å¯¹ã€‚'
- en: '`download_desc` (`str`, *optional*) â€” A description to be displayed alongside
    with the progress bar while downloading the files.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`download_desc`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€”åœ¨ä¸‹è½½æ–‡ä»¶æ—¶æ˜¾ç¤ºåœ¨è¿›åº¦æ¡æ—è¾¹çš„æè¿°ã€‚'
- en: Configuration for our cached path manager.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç¼“å­˜è·¯å¾„ç®¡ç†å™¨çš„é…ç½®ã€‚
- en: '### `class datasets.DownloadMode`'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.DownloadMode`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L85)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/download/download_manager.py#L85)'
- en: '[PRE43]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '`Enum` for how to treat pre-existing downloads and data.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '`Enum`ç”¨äºå¤„ç†é¢„å…ˆå­˜åœ¨çš„ä¸‹è½½å’Œæ•°æ®ã€‚'
- en: The default mode is `REUSE_DATASET_IF_EXISTS`, which will reuse both raw downloads
    and the prepared dataset if they exist.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æ¨¡å¼æ˜¯`REUSE_DATASET_IF_EXISTS`ï¼Œå¦‚æœå­˜åœ¨åŸå§‹ä¸‹è½½å’Œå‡†å¤‡å¥½çš„æ•°æ®é›†ï¼Œåˆ™å°†é‡ç”¨å®ƒä»¬ã€‚
- en: 'The generations modes:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæ¨¡å¼ï¼š
- en: '|  | Downloads | Dataset |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '|  | ä¸‹è½½ | æ•°æ®é›† |'
- en: '| --- | --- | --- |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `REUSE_DATASET_IF_EXISTS` (default) | Reuse | Reuse |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| `REUSE_DATASET_IF_EXISTS`ï¼ˆé»˜è®¤ï¼‰| é‡ç”¨ | é‡ç”¨ |'
- en: '| `REUSE_CACHE_IF_EXISTS` | Reuse | Fresh |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| `REUSE_CACHE_IF_EXISTS` | é‡ç”¨ | æ–°é²œ |'
- en: '| `FORCE_REDOWNLOAD` | Fresh | Fresh |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| `FORCE_REDOWNLOAD` | æ–°é²œ | æ–°é²œ |'
- en: Verification
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éªŒè¯
- en: '### `class datasets.VerificationMode`'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.VerificationMode`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/utils/info_utils.py#L14)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/utils/info_utils.py#L14)'
- en: '[PRE44]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '`Enum` that specifies which verification checks to run.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡å®šè¦è¿è¡Œå“ªäº›éªŒè¯æ£€æŸ¥çš„`Enum`ã€‚
- en: The default mode is `BASIC_CHECKS`, which will perform only rudimentary checks
    to avoid slowdowns when generating/downloading a dataset for the first time.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æ¨¡å¼æ˜¯`BASIC_CHECKS`ï¼Œä»…æ‰§è¡ŒåŸºæœ¬æ£€æŸ¥ï¼Œä»¥é¿å…åœ¨é¦–æ¬¡ç”Ÿæˆ/ä¸‹è½½æ•°æ®é›†æ—¶å‡æ…¢é€Ÿåº¦ã€‚
- en: 'The verification modes:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: éªŒè¯æ¨¡å¼ï¼š
- en: '|  | Verification checks |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '|  | éªŒè¯æ£€æŸ¥ |'
- en: '| --- | --- |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `ALL_CHECKS` | Split checks, uniqueness of the keys yielded in case of the
    GeneratorBuilder |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| `ALL_CHECKS` | æ‹†åˆ†æ£€æŸ¥ï¼ŒGeneratorBuilderä¸­ç”Ÿæˆçš„é”®çš„å”¯ä¸€æ€§ |'
- en: '|  | and the validity (number of files, checksums, etc.) of downloaded files
    |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '|  | ä»¥åŠä¸‹è½½æ–‡ä»¶çš„æœ‰æ•ˆæ€§ï¼ˆæ–‡ä»¶æ•°é‡ï¼Œæ ¡éªŒå’Œç­‰ï¼‰ |'
- en: '| `BASIC_CHECKS` (default) | Same as `ALL_CHECKS` but without checking downloaded
    files |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| `BASIC_CHECKS`ï¼ˆé»˜è®¤ï¼‰| ä¸`ALL_CHECKS`ç›¸åŒï¼Œä½†ä¸æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶ |'
- en: '| `NO_CHECKS` | None |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| `NO_CHECKS` | æ—  |'
- en: Splits
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‹†åˆ†
- en: '### `class datasets.SplitGenerator`'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.SplitGenerator`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L604)'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L604)'
- en: '[PRE45]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`name` (`str`) â€” Name of the `Split` for which the generator will create the
    examples.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`ï¼ˆ`str`ï¼‰â€”ç”Ÿæˆå™¨å°†ä¸ºå…¶åˆ›å»ºç¤ºä¾‹çš„`Split`çš„åç§°ã€‚'
- en: '*`*gen_kwargs` (additional keyword arguments) â€” Keyword arguments to forward
    to the `DatasetBuilder._generate_examples` method of the builder.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*gen_kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼‰â€”è¦è½¬å‘åˆ°æ„å»ºå™¨çš„`DatasetBuilder._generate_examples`æ–¹æ³•çš„å…³é”®å­—å‚æ•°ã€‚'
- en: Defines the split information for the generator.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºç”Ÿæˆå™¨å®šä¹‰æ‹†åˆ†ä¿¡æ¯ã€‚
- en: This should be used as returned value of `GeneratorBasedBuilder._split_generators`.
    See `GeneratorBasedBuilder._split_generators` for more info and example of usage.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: åº”å°†æ­¤ç”¨ä½œ`GeneratorBasedBuilder._split_generators`çš„è¿”å›å€¼ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯å’Œç”¨æ³•ç¤ºä¾‹ï¼Œè¯·å‚é˜…`GeneratorBasedBuilder._split_generators`ã€‚
- en: 'Example:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE46]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '### `class datasets.Split`'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.Split`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L407)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L407)'
- en: '[PRE47]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`Enum` for dataset splits.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æ‹†åˆ†çš„`Enum`ã€‚
- en: Datasets are typically split into different subsets to be used at various stages
    of training and evaluation.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†é€šå¸¸è¢«æ‹†åˆ†ä¸ºä¸åŒçš„å­é›†ï¼Œä»¥åœ¨è®­ç»ƒå’Œè¯„ä¼°çš„å„ä¸ªé˜¶æ®µä½¿ç”¨ã€‚
- en: '`TRAIN`: the training data.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TRAIN`ï¼šè®­ç»ƒæ•°æ®ã€‚'
- en: '`VALIDATION`: the validation data. If present, this is typically used as evaluation
    data while iterating on a model (e.g. changing hyperparameters, model architecture,
    etc.).'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VALIDATION`ï¼šéªŒè¯æ•°æ®ã€‚å¦‚æœå­˜åœ¨ï¼Œé€šå¸¸åœ¨è¿­ä»£æ¨¡å‹æ—¶ç”¨ä½œè¯„ä¼°æ•°æ®ï¼ˆä¾‹å¦‚æ›´æ”¹è¶…å‚æ•°ï¼Œæ¨¡å‹æ¶æ„ç­‰ï¼‰ã€‚'
- en: '`TEST`: the testing data. This is the data to report metrics on. Typically
    you do not want to use this during model iteration as you may overfit to it.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TEST`ï¼šæµ‹è¯•æ•°æ®ã€‚è¿™æ˜¯è¦æŠ¥å‘ŠæŒ‡æ ‡çš„æ•°æ®ã€‚é€šå¸¸åœ¨æ¨¡å‹è¿­ä»£è¿‡ç¨‹ä¸­ä¸å¸Œæœ›ä½¿ç”¨æ­¤æ•°æ®ï¼Œå› ä¸ºå¯èƒ½ä¼šè¿‡æ‹Ÿåˆã€‚'
- en: '`ALL`: the union of all defined dataset splits.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ALL`ï¼šæ‰€æœ‰å®šä¹‰çš„æ•°æ®é›†æ‹†åˆ†çš„å¹¶é›†ã€‚'
- en: All splits, including compositions inherit from `datasets.SplitBase`.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ‹†åˆ†ï¼ŒåŒ…æ‹¬ç»„åˆï¼Œéƒ½ç»§æ‰¿è‡ª`datasets.SplitBase`ã€‚
- en: See the [guide](../load_hub#splits) on splits for more information.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æŒ‡å—](../load_hub#splits)ã€‚
- en: 'Example:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE48]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '### `class datasets.NamedSplit`'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.NamedSplit`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L315)'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L315)'
- en: '[PRE49]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Descriptor corresponding to a named split (train, test, â€¦).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å‘½åæ‹†åˆ†ï¼ˆè®­ç»ƒï¼Œæµ‹è¯•ç­‰ï¼‰å¯¹åº”çš„æè¿°ç¬¦ã€‚
- en: 'Example:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: 'Each descriptor can be composed with other using addition or slice:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæè¿°ç¬¦éƒ½å¯ä»¥ä½¿ç”¨åŠ æ³•æˆ–åˆ‡ç‰‡ä¸å…¶ä»–æè¿°ç¬¦ç»„åˆï¼š
- en: '[PRE50]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The resulting split will correspond to 25% of the train split merged with 100%
    of the test split.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„æ‹†åˆ†å°†å¯¹åº”äºè®­ç»ƒæ‹†åˆ†çš„25%ä¸æµ‹è¯•æ‹†åˆ†çš„100%åˆå¹¶ã€‚
- en: 'A split cannot be added twice, so the following will fail:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹†åˆ†ä¸èƒ½æ·»åŠ ä¸¤æ¬¡ï¼Œå› æ­¤ä»¥ä¸‹å°†å¤±è´¥ï¼š
- en: '[PRE51]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The slices can be applied only one time. So the following are valid:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ‡ç‰‡åªèƒ½åº”ç”¨ä¸€æ¬¡ã€‚å› æ­¤ä»¥ä¸‹æ˜¯æœ‰æ•ˆçš„ï¼š
- en: '[PRE52]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'But this is not valid:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™æ˜¯æ— æ•ˆçš„ï¼š
- en: '[PRE53]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '### `class datasets.NamedSplitAll`'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.NamedSplitAll`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L392)'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/splits.py#L392)'
- en: '[PRE54]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Split corresponding to the union of all defined dataset splits.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰å®šä¹‰çš„æ•°æ®é›†æ‹†åˆ†çš„å¹¶é›†æ‹†åˆ†ã€‚
- en: '### `class datasets.ReadInstruction`'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.ReadInstruction`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/arrow_reader.py#L495)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/arrow_reader.py#L495)'
- en: '[PRE55]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Reading instruction for a dataset.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†çš„è¯»å–æŒ‡ä»¤ã€‚
- en: 'Examples:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE56]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '#### `from_spec`'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_spec`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/arrow_reader.py#L575)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/arrow_reader.py#L575)'
- en: '[PRE57]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Parameters
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`spec` (`str`) â€” Split(s) + optional slice(s) to read + optional rounding if
    percents are used as the slicing unit. A slice can be specified, using absolute
    numbers (`int`) or percentages (`int`).'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec`ï¼ˆ`str`ï¼‰â€” æ‹†åˆ† + å¯é€‰åˆ‡ç‰‡ + å¦‚æœç™¾åˆ†æ¯”ç”¨ä½œåˆ‡ç‰‡å•ä½ï¼Œåˆ™å¯é€‰å››èˆäº”å…¥ã€‚å¯ä»¥æŒ‡å®šä¸€ä¸ªåˆ‡ç‰‡ï¼Œä½¿ç”¨ç»å¯¹æ•°å­—ï¼ˆ`int`ï¼‰æˆ–ç™¾åˆ†æ¯”ï¼ˆ`int`ï¼‰ã€‚'
- en: Creates a `ReadInstruction` instance out of a string spec.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å­—ç¬¦ä¸²è§„èŒƒåˆ›å»ºä¸€ä¸ª`ReadInstruction`å®ä¾‹ã€‚
- en: 'Examples:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE58]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '#### `to_absolute`'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_absolute`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/arrow_reader.py#L647)'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/arrow_reader.py#L647)'
- en: '[PRE59]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Parameters
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`name2len` (`dict`) â€” Associating split names to number of examples.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name2len`ï¼ˆ`dict`ï¼‰â€” å°†æ‹†åˆ†åç§°ä¸ç¤ºä¾‹æ•°é‡å…³è”èµ·æ¥ã€‚'
- en: Translate instruction into a list of absolute instructions.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æŒ‡ä»¤ç¿»è¯‘æˆç»å¯¹æŒ‡ä»¤åˆ—è¡¨ã€‚
- en: Those absolute instructions are then to be added together.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå°†è¿™äº›ç»å¯¹æŒ‡ä»¤ç›¸åŠ ã€‚
- en: Version
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‰ˆæœ¬
- en: '### `class datasets.Version`'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class datasets.Version`'
- en: '[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/utils/version.py#L28)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/utils/version.py#L28)'
- en: '[PRE60]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Parameters
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`version_str` (`str`) â€” The dataset version.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version_str`ï¼ˆ`str`ï¼‰â€” æ•°æ®é›†ç‰ˆæœ¬ã€‚'
- en: '`description` (`str`) â€” A description of what is new in this version.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`description`ï¼ˆ`str`ï¼‰â€” è¿™ä¸ªç‰ˆæœ¬ä¸­çš„æ–°å†…å®¹æè¿°ã€‚'
- en: '`major` (`str`) â€”'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`major`ï¼ˆ`str`ï¼‰â€”'
- en: '`minor` (`str`) â€”'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minor`ï¼ˆ`str`ï¼‰â€”'
- en: '`patch` (`str`) â€”'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch`ï¼ˆ`str`ï¼‰â€”'
- en: Dataset version `MAJOR.MINOR.PATCH`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†ç‰ˆæœ¬ `MAJOR.MINOR.PATCH`ã€‚
- en: 'Example:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE61]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
