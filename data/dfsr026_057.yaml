- en: Unconditional image generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无条件图像生成
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/unconditional_training](https://huggingface.co/docs/diffusers/training/unconditional_training)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/training/unconditional_training](https://huggingface.co/docs/diffusers/training/unconditional_training)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Unconditional image generation models are not conditioned on text or images
    during training. It only generates images that resemble its training data distribution.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 无条件图像生成模型在训练过程中不受文本或图像的限制。它只生成类似于其训练数据分布的图像。
- en: This guide will explore the [train_unconditional.py](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)
    training script to help you become familiar with it, and how you can adapt it
    for your own use-case.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将探索[train_unconditional.py](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)训练脚本，帮助您熟悉它，以及如何为您自己的用例进行调整。
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行脚本之前，请确保您从源代码安装了库：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then navigate to the example folder containing the training script and install
    the required dependencies:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然后导航到包含训练脚本的示例文件夹，并安装所需的依赖项：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 🤗 Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. It’ll automatically configure your training setup based on your
    hardware and environment. Take a look at the 🤗 Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Accelerate是一个帮助您在多个GPU/TPU上训练或使用混合精度的库。它将根据您的硬件和环境自动配置您的训练设置。查看🤗 Accelerate
    [快速入门](https://huggingface.co/docs/accelerate/quicktour)以了解更多信息。
- en: 'Initialize an 🤗 Accelerate environment:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化一个🤗 Accelerate环境：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default 🤗 Accelerate environment without choosing any configurations:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置一个默认的🤗 Accelerate环境而不选择任何配置：
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesn’t support an interactive shell like a notebook,
    you can use:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 或者如果您的环境不支持像笔记本这样的交互式shell，您可以使用：
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您想在自己的数据集上训练模型，请查看[创建用于训练的数据集](create_dataset)指南，了解如何创建一个适用于训练脚本的数据集。
- en: Script parameters
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚本参数
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesn’t cover every aspect of the script
    in detail. If you’re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)
    and let us know if you have any questions or concerns.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分突出显示了训练脚本中重要的部分，以便了解如何修改它，但并未详细涵盖脚本的每个方面。如果您有兴趣了解更多，请随时阅读[脚本](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)，并告诉我们如果您有任何问题或疑虑。
- en: The training script provides many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L55)
    function. It provides default values for each parameter, such as the training
    batch size and learning rate, but you can also set your own values in the training
    command if you’d like.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本提供了许多参数，帮助您定制您的训练运行。所有参数及其描述都在[`parse_args()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L55)函数中找到。它为每个参数提供了默认值，如训练批量大小和学习率，但如果您愿意，也可以在训练命令中设置自己的值。
- en: 'For example, to speedup training with mixed precision using the bf16 format,
    add the `--mixed_precision` parameter to the training command:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要使用bf16格式加速混合精度训练，请在训练命令中添加`--mixed_precision`参数：
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Some basic and important parameters to specify include:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一些基本和重要的要指定的参数包括：
- en: '`--dataset_name`: the name of the dataset on the Hub or a local path to the
    dataset to train on'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--dataset_name`：Hub上的数据集名称或要训练的本地路径数据集'
- en: '`--output_dir`: where to save the trained model'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_dir`：保存训练模型的位置'
- en: '`--push_to_hub`: whether to push the trained model to the Hub'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--push_to_hub`：是否将训练好的模型推送到Hub'
- en: '`--checkpointing_steps`: frequency of saving a checkpoint as the model trains;
    this is useful if training is interrupted, you can continue training from that
    checkpoint by adding `--resume_from_checkpoint` to your training command'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--checkpointing_steps`：在模型训练过程中保存检查点的频率；如果训练被中断，您可以通过在训练命令中添加`--resume_from_checkpoint`来从该检查点继续训练'
- en: Bring your dataset, and let the training script handle everything else!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 带上您的数据集，让训练脚本处理其他一切！
- en: Training script
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练脚本
- en: The code for preprocessing the dataset and the training loop is found in the
    [`main()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L275)
    function. If you need to adapt the training script, this is where you’ll need
    to make your changes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 用于预处理数据集和训练循环的代码位于[`main()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L275)函数中。如果您需要调整训练脚本，这就是您需要进行更改的地方。
- en: 'The `train_unconditional` script [initializes a `UNet2DModel`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L356)
    if you don’t provide a model configuration. You can configure the UNet here if
    you’d like:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有提供模型配置，`train_unconditional`脚本将[初始化一个`UNet2DModel`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L356)。如果您愿意，您可以在这里配置UNet：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, the script initializes a [scheduler](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L418)
    and [optimizer](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L429):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，脚本初始化一个[调度器](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L418)
    和[优化器](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L429)：
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then it [loads a dataset](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L451)
    and you can specify how to [preprocess](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L455)
    it:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它[加载数据集](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L451)
    ，您可以指定如何[预处理](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L455)
    它：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, the [training loop](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L540)
    handles everything else such as adding noise to the images, predicting the noise
    residual, calculating the loss, saving checkpoints at specified steps, and saving
    and pushing the model to the Hub. If you want to learn more about how the training
    loop works, check out the [Understanding pipelines, models and schedulers](../using-diffusers/write_own_pipeline)
    tutorial which breaks down the basic pattern of the denoising process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，[训练循环](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L540)
    处理其他所有事项，如向图像添加噪声，预测噪声残差，计算损失，保存指定步骤的检查点，并保存并推送模型到 Hub。如果您想了解训练循环的工作原理，请查看[理解管道、模型和调度器](../using-diffusers/write_own_pipeline)
    教程，该教程详细解释了去噪过程的基本模式。
- en: Launch the script
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动脚本
- en: Once you’ve made all your changes or you’re okay with the default configuration,
    you’re ready to launch the training script! 🚀
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您完成所有更改或对默认配置满意，您就可以启动训练脚本！🚀
- en: A full training run takes 2 hours on 4xV100 GPUs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的训练运行在4xV100 GPU上需要2小时。
- en: single GPUmulti-GPU
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 单GPU多GPU
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The training script creates and saves a checkpoint file in your repository.
    Now you can load and use your trained model for inference:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本会在您的存储库中创建并保存一个检查点文件。现在您可以加载和使用训练好的模型进行推断：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
