- en: Unconditional image generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ— æ¡ä»¶å›¾åƒç”Ÿæˆ
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/unconditional_training](https://huggingface.co/docs/diffusers/training/unconditional_training)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/unconditional_training](https://huggingface.co/docs/diffusers/training/unconditional_training)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Unconditional image generation models are not conditioned on text or images
    during training. It only generates images that resemble its training data distribution.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ— æ¡ä»¶å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å—æ–‡æœ¬æˆ–å›¾åƒçš„é™åˆ¶ã€‚å®ƒåªç”Ÿæˆç±»ä¼¼äºå…¶è®­ç»ƒæ•°æ®åˆ†å¸ƒçš„å›¾åƒã€‚
- en: This guide will explore the [train_unconditional.py](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)
    training script to help you become familiar with it, and how you can adapt it
    for your own use-case.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†æ¢ç´¢[train_unconditional.py](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)è®­ç»ƒè„šæœ¬ï¼Œå¸®åŠ©æ‚¨ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºæ‚¨è‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨ä»æºä»£ç å®‰è£…äº†åº“ï¼š
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then navigate to the example folder containing the training script and install
    the required dependencies:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ğŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Accelerateæ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ªGPU/TPUä¸Šè®­ç»ƒæˆ–ä½¿ç”¨æ··åˆç²¾åº¦çš„åº“ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤— Accelerate
    [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚
- en: 'Initialize an ğŸ¤— Accelerate environment:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–ä¸€ä¸ªğŸ¤— Accelerateç¯å¢ƒï¼š
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default ğŸ¤— Accelerate environment without choosing any configurations:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„ğŸ¤— Accelerateç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesnâ€™t support an interactive shell like a notebook,
    you can use:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…å¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒåƒç¬”è®°æœ¬è¿™æ ·çš„äº¤äº’å¼shellï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºä¸€ä¸ªé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚
- en: Script parameters
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è„šæœ¬å‚æ•°
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the script
    in detail. If youâ€™re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)
    and let us know if you have any questions or concerns.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹éƒ¨åˆ†çªå‡ºæ˜¾ç¤ºäº†è®­ç»ƒè„šæœ¬ä¸­é‡è¦çš„éƒ¨åˆ†ï¼Œä»¥ä¾¿äº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/unconditional_image_generation/train_unconditional.py)ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚
- en: The training script provides many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L55)
    function. It provides default values for each parameter, such as the training
    batch size and learning rate, but you can also set your own values in the training
    command if youâ€™d like.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°ï¼Œå¸®åŠ©æ‚¨å®šåˆ¶æ‚¨çš„è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L55)å‡½æ•°ä¸­æ‰¾åˆ°ã€‚å®ƒä¸ºæ¯ä¸ªå‚æ•°æä¾›äº†é»˜è®¤å€¼ï¼Œå¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚
- en: 'For example, to speedup training with mixed precision using the bf16 format,
    add the `--mixed_precision` parameter to the training command:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨bf16æ ¼å¼åŠ é€Ÿæ··åˆç²¾åº¦è®­ç»ƒï¼Œè¯·åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--mixed_precision`å‚æ•°ï¼š
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Some basic and important parameters to specify include:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›åŸºæœ¬å’Œé‡è¦çš„è¦æŒ‡å®šçš„å‚æ•°åŒ…æ‹¬ï¼š
- en: '`--dataset_name`: the name of the dataset on the Hub or a local path to the
    dataset to train on'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--dataset_name`ï¼šHubä¸Šçš„æ•°æ®é›†åç§°æˆ–è¦è®­ç»ƒçš„æœ¬åœ°è·¯å¾„æ•°æ®é›†'
- en: '`--output_dir`: where to save the trained model'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_dir`ï¼šä¿å­˜è®­ç»ƒæ¨¡å‹çš„ä½ç½®'
- en: '`--push_to_hub`: whether to push the trained model to the Hub'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--push_to_hub`ï¼šæ˜¯å¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ°Hub'
- en: '`--checkpointing_steps`: frequency of saving a checkpoint as the model trains;
    this is useful if training is interrupted, you can continue training from that
    checkpoint by adding `--resume_from_checkpoint` to your training command'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--checkpointing_steps`ï¼šåœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜æ£€æŸ¥ç‚¹çš„é¢‘ç‡ï¼›å¦‚æœè®­ç»ƒè¢«ä¸­æ–­ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--resume_from_checkpoint`æ¥ä»è¯¥æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ'
- en: Bring your dataset, and let the training script handle everything else!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦ä¸Šæ‚¨çš„æ•°æ®é›†ï¼Œè®©è®­ç»ƒè„šæœ¬å¤„ç†å…¶ä»–ä¸€åˆ‡ï¼
- en: Training script
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬
- en: The code for preprocessing the dataset and the training loop is found in the
    [`main()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L275)
    function. If you need to adapt the training script, this is where youâ€™ll need
    to make your changes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºé¢„å¤„ç†æ•°æ®é›†å’Œè®­ç»ƒå¾ªç¯çš„ä»£ç ä½äº[`main()`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L275)å‡½æ•°ä¸­ã€‚å¦‚æœæ‚¨éœ€è¦è°ƒæ•´è®­ç»ƒè„šæœ¬ï¼Œè¿™å°±æ˜¯æ‚¨éœ€è¦è¿›è¡Œæ›´æ”¹çš„åœ°æ–¹ã€‚
- en: 'The `train_unconditional` script [initializes a `UNet2DModel`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L356)
    if you donâ€™t provide a model configuration. You can configure the UNet here if
    youâ€™d like:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ²¡æœ‰æä¾›æ¨¡å‹é…ç½®ï¼Œ`train_unconditional`è„šæœ¬å°†[åˆå§‹åŒ–ä¸€ä¸ª`UNet2DModel`](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L356)ã€‚å¦‚æœæ‚¨æ„¿æ„ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œé…ç½®UNetï¼š
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, the script initializes a [scheduler](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L418)
    and [optimizer](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L429):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè„šæœ¬åˆå§‹åŒ–ä¸€ä¸ª[è°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L418)
    å’Œ[ä¼˜åŒ–å™¨](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L429)ï¼š
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then it [loads a dataset](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L451)
    and you can specify how to [preprocess](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L455)
    it:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå®ƒ[åŠ è½½æ•°æ®é›†](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L451)
    ï¼Œæ‚¨å¯ä»¥æŒ‡å®šå¦‚ä½•[é¢„å¤„ç†](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L455)
    å®ƒï¼š
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, the [training loop](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L540)
    handles everything else such as adding noise to the images, predicting the noise
    residual, calculating the loss, saving checkpoints at specified steps, and saving
    and pushing the model to the Hub. If you want to learn more about how the training
    loop works, check out the [Understanding pipelines, models and schedulers](../using-diffusers/write_own_pipeline)
    tutorial which breaks down the basic pattern of the denoising process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/096f84b05f9514fae9f185cbec0a4d38fbad9919/examples/unconditional_image_generation/train_unconditional.py#L540)
    å¤„ç†å…¶ä»–æ‰€æœ‰äº‹é¡¹ï¼Œå¦‚å‘å›¾åƒæ·»åŠ å™ªå£°ï¼Œé¢„æµ‹å™ªå£°æ®‹å·®ï¼Œè®¡ç®—æŸå¤±ï¼Œä¿å­˜æŒ‡å®šæ­¥éª¤çš„æ£€æŸ¥ç‚¹ï¼Œå¹¶ä¿å­˜å¹¶æ¨é€æ¨¡å‹åˆ° Hubã€‚å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[ç†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨](../using-diffusers/write_own_pipeline)
    æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è¯¦ç»†è§£é‡Šäº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚
- en: Launch the script
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯åŠ¨è„šæœ¬
- en: Once youâ€™ve made all your changes or youâ€™re okay with the default configuration,
    youâ€™re ready to launch the training script! ğŸš€
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨å®Œæˆæ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬ï¼ğŸš€
- en: A full training run takes 2 hours on 4xV100 GPUs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„è®­ç»ƒè¿è¡Œåœ¨4xV100 GPUä¸Šéœ€è¦2å°æ—¶ã€‚
- en: single GPUmulti-GPU
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å•GPUå¤šGPU
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The training script creates and saves a checkpoint file in your repository.
    Now you can load and use your trained model for inference:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬ä¼šåœ¨æ‚¨çš„å­˜å‚¨åº“ä¸­åˆ›å»ºå¹¶ä¿å­˜ä¸€ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶ã€‚ç°åœ¨æ‚¨å¯ä»¥åŠ è½½å’Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼š
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
