- en: How to create a custom pipeline?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰ç®¡é“ï¼Ÿ
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/add_new_pipeline](https://huggingface.co/docs/transformers/v4.37.2/en/add_new_pipeline)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/add_new_pipeline](https://huggingface.co/docs/transformers/v4.37.2/en/add_new_pipeline)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In this guide, we will see how to create a custom pipeline and share it on the
    [Hub](https://hf.co/models) or add it to the ğŸ¤— Transformers library.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰ç®¡é“å¹¶åœ¨[Hub](https://hf.co/models)ä¸Šå…±äº«å®ƒæˆ–å°†å…¶æ·»åŠ åˆ°ğŸ¤— Transformersåº“ä¸­ã€‚
- en: First and foremost, you need to decide the raw entries the pipeline will be
    able to take. It can be strings, raw bytes, dictionaries or whatever seems to
    be the most likely desired input. Try to keep these inputs as pure Python as possible
    as it makes compatibility easier (even through other languages via JSON). Those
    will be the `inputs` of the pipeline (`preprocess`).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæ‚¨éœ€è¦å†³å®šç®¡é“å°†èƒ½å¤Ÿæ¥å—çš„åŸå§‹æ¡ç›®ã€‚å®ƒå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€åŸå§‹å­—èŠ‚ã€å­—å…¸æˆ–ä»»ä½•çœ‹èµ·æ¥æœ€æœ‰å¯èƒ½çš„æœŸæœ›è¾“å…¥ã€‚å°½é‡ä¿æŒè¿™äº›è¾“å…¥å°½å¯èƒ½çº¯ç²¹çš„Pythonï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ä½¿å…¼å®¹æ€§æ›´å®¹æ˜“ï¼ˆç”šè‡³é€šè¿‡JSONé€šè¿‡å…¶ä»–è¯­è¨€ï¼‰ã€‚è¿™äº›å°†æ˜¯ç®¡é“çš„`inputs`ï¼ˆ`preprocess`ï¼‰ã€‚
- en: Then define the `outputs`. Same policy as the `inputs`. The simpler, the better.
    Those will be the outputs of `postprocess` method.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®šä¹‰`outputs`ã€‚ä¸`inputs`ç›¸åŒçš„ç­–ç•¥ã€‚è¶Šç®€å•è¶Šå¥½ã€‚è¿™äº›å°†æ˜¯`postprocess`æ–¹æ³•çš„è¾“å‡ºã€‚
- en: Start by inheriting the base class `Pipeline` with the 4 methods needed to implement
    `preprocess`, `_forward`, `postprocess`, and `_sanitize_parameters`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆé€šè¿‡ç»§æ‰¿åŸºç±»`Pipeline`ï¼Œå…·æœ‰å®ç°`preprocess`ã€`_forward`ã€`postprocess`å’Œ`_sanitize_parameters`æ‰€éœ€çš„4ä¸ªæ–¹æ³•ã€‚
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The structure of this breakdown is to support relatively seamless support for
    CPU/GPU, while supporting doing pre/postprocessing on the CPU on different threads
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§åˆ†è§£çš„ç»“æ„æ”¯æŒç›¸å¯¹æ— ç¼åœ°æ”¯æŒCPU/GPUï¼ŒåŒæ—¶æ”¯æŒåœ¨ä¸åŒçº¿ç¨‹ä¸Šåœ¨CPUä¸Šè¿›è¡Œé¢„å¤„ç†/åå¤„ç†
- en: '`preprocess` will take the originally defined inputs, and turn them into something
    feedable to the model. It might contain more information and is usually a `Dict`.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`preprocess`å°†è·å–æœ€åˆå®šä¹‰çš„è¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¯ä¾›æ¨¡å‹ä½¿ç”¨çš„å†…å®¹ã€‚å®ƒå¯èƒ½åŒ…å«æ›´å¤šä¿¡æ¯ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ª`Dict`ã€‚'
- en: '`_forward` is the implementation detail and is not meant to be called directly.
    `forward` is the preferred called method as it contains safeguards to make sure
    everything is working on the expected device. If anything is linked to a real
    model it belongs in the `_forward` method, anything else is in the preprocess/postprocess.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '`_forward`æ˜¯å®ç°ç»†èŠ‚ï¼Œä¸åº”ç›´æ¥è°ƒç”¨ã€‚`forward`æ˜¯é¦–é€‰çš„è°ƒç”¨æ–¹æ³•ï¼Œå› ä¸ºå®ƒåŒ…å«äº†ç¡®ä¿ä¸€åˆ‡åœ¨é¢„æœŸè®¾å¤‡ä¸Šå·¥ä½œçš„ä¿éšœæªæ–½ã€‚å¦‚æœä»»ä½•å†…å®¹ä¸çœŸå®æ¨¡å‹ç›¸å…³ï¼Œåˆ™åº”è¯¥æ”¾åœ¨`_forward`æ–¹æ³•ä¸­ï¼Œå…¶ä»–å†…å®¹åº”è¯¥æ”¾åœ¨é¢„å¤„ç†/åå¤„ç†ä¸­ã€‚'
- en: '`postprocess` methods will take the output of `_forward` and turn it into the
    final output that was decided earlier.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`postprocess`æ–¹æ³•å°†è·å–`_forward`çš„è¾“å‡ºå¹¶å°†å…¶è½¬æ¢ä¸ºä¹‹å‰å†³å®šçš„æœ€ç»ˆè¾“å‡ºã€‚'
- en: '`_sanitize_parameters` exists to allow users to pass any parameters whenever
    they wish, be it at initialization time `pipeline(...., maybe_arg=4)` or at call
    time `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '`_sanitize_parameters`å­˜åœ¨æ˜¯ä¸ºäº†å…è®¸ç”¨æˆ·åœ¨ä»»ä½•æ—¶å€™ä¼ é€’ä»»ä½•å‚æ•°ï¼Œæ— è®ºæ˜¯åœ¨åˆå§‹åŒ–æ—¶`pipeline(...., maybe_arg=4)`è¿˜æ˜¯åœ¨è°ƒç”¨æ—¶`pipe
    = pipeline(...); output = pipe(...., maybe_arg=4)`ã€‚'
- en: The returns of `_sanitize_parameters` are the 3 dicts of kwargs that will be
    passed directly to `preprocess`, `_forward`, and `postprocess`. Donâ€™t fill anything
    if the caller didnâ€™t call with any extra parameter. That allows to keep the default
    arguments in the function definition which is always more â€œnaturalâ€.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`_sanitize_parameters`çš„è¿”å›å€¼æ˜¯å°†ç›´æ¥ä¼ é€’ç»™`preprocess`ã€`_forward`å’Œ`postprocess`çš„3ä¸ªkwargså­—å…¸ã€‚å¦‚æœè°ƒç”¨è€…æ²¡æœ‰ä½¿ç”¨ä»»ä½•é¢å¤–å‚æ•°ï¼Œåˆ™ä¸è¦å¡«å†™ä»»ä½•å†…å®¹ã€‚è¿™æ ·å¯ä»¥ä¿æŒå‡½æ•°å®šä¹‰ä¸­çš„é»˜è®¤å‚æ•°ï¼Œè¿™æ€»æ˜¯æ›´â€œè‡ªç„¶â€çš„ã€‚'
- en: A classic example would be a `top_k` argument in the post processing in classification
    tasks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç»å…¸çš„ä¾‹å­æ˜¯åœ¨åˆ†ç±»ä»»åŠ¡çš„åå¤„ç†ä¸­æ·»åŠ ä¸€ä¸ª`top_k`å‚æ•°ã€‚
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In order to achieve that, weâ€™ll update our `postprocess` method with a default
    parameter to `5`. and edit `_sanitize_parameters` to allow this new parameter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé»˜è®¤å‚æ•°`5`æ¥æ›´æ–°æˆ‘ä»¬çš„`postprocess`æ–¹æ³•ï¼Œå¹¶ç¼–è¾‘`_sanitize_parameters`ä»¥å…è®¸è¿™ä¸ªæ–°å‚æ•°ã€‚
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Try to keep the inputs/outputs very simple and ideally JSON-serializable as
    it makes the pipeline usage very easy without requiring users to understand new
    kinds of objects. Itâ€™s also relatively common to support many different types
    of arguments for ease of use (audio files, which can be filenames, URLs or pure
    bytes)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å°½é‡ä¿æŒè¾“å…¥/è¾“å‡ºéå¸¸ç®€å•ï¼Œæœ€å¥½æ˜¯å¯JSONåºåˆ—åŒ–çš„ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ä½¿ç®¡é“çš„ä½¿ç”¨éå¸¸ç®€å•ï¼Œè€Œä¸éœ€è¦ç”¨æˆ·ç†è§£æ–°ç±»å‹çš„å¯¹è±¡ã€‚é€šå¸¸ä¹Ÿæ”¯æŒè®¸å¤šä¸åŒç±»å‹çš„å‚æ•°ï¼Œä»¥ä¾¿äºä½¿ç”¨ï¼ˆä¾‹å¦‚éŸ³é¢‘æ–‡ä»¶ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶åã€URLæˆ–çº¯å­—èŠ‚ï¼‰
- en: Adding it to the list of supported tasks
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°†å…¶æ·»åŠ åˆ°æ”¯æŒä»»åŠ¡åˆ—è¡¨ä¸­
- en: 'To register your `new-task` to the list of supported tasks, you have to add
    it to the `PIPELINE_REGISTRY`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å°†æ‚¨çš„`new-task`æ³¨å†Œåˆ°æ”¯æŒä»»åŠ¡åˆ—è¡¨ä¸­ï¼Œæ‚¨å¿…é¡»å°†å…¶æ·»åŠ åˆ°`PIPELINE_REGISTRY`ä¸­ï¼š
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can specify a default model if you want, in which case it should come with
    a specific revision (which can be the name of a branch or a commit hash, here
    we took `"abcdef"`) as well as the type:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥æŒ‡å®šä¸€ä¸ªé»˜è®¤æ¨¡å‹ï¼Œæ­¤æ—¶åº”è¯¥é™„å¸¦ä¸€ä¸ªç‰¹å®šçš„ä¿®è®¢ç‰ˆï¼ˆå¯ä»¥æ˜¯åˆ†æ”¯åç§°æˆ–æäº¤å“ˆå¸Œï¼Œè¿™é‡Œæˆ‘ä»¬å–`"abcdef"`ï¼‰ä»¥åŠç±»å‹ï¼š
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Share your pipeline on the Hub
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨Hubä¸Šå…±äº«æ‚¨çš„ç®¡é“
- en: 'To share your custom pipeline on the Hub, you just have to save the custom
    code of your `Pipeline` subclass in a python file. For instance, letâ€™s say we
    want to use a custom pipeline for sentence pair classification like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨Hubä¸Šå…±äº«æ‚¨çš„è‡ªå®šä¹‰ç®¡é“ï¼Œåªéœ€å°†`Pipeline`å­ç±»çš„è‡ªå®šä¹‰ä»£ç ä¿å­˜åœ¨ä¸€ä¸ªpythonæ–‡ä»¶ä¸­ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æƒ³è¦åƒè¿™æ ·ä¸ºå¥å¯¹åˆ†ç±»ä½¿ç”¨è‡ªå®šä¹‰ç®¡é“ï¼š
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The implementation is framework agnostic, and will work for PyTorch and TensorFlow
    models. If we have saved this in a file named `pair_classification.py`, we can
    then import it and register it like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå®ç°æ˜¯ä¸æ¡†æ¶æ— å…³çš„ï¼Œå°†é€‚ç”¨äºPyTorchå’ŒTensorFlowæ¨¡å‹ã€‚å¦‚æœæˆ‘ä»¬å°†å…¶ä¿å­˜åœ¨ä¸€ä¸ªåä¸º`pair_classification.py`çš„æ–‡ä»¶ä¸­ï¼Œç„¶åå¯ä»¥åƒè¿™æ ·å¯¼å…¥å¹¶æ³¨å†Œå®ƒï¼š
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Once this is done, we can use it with a pretrained model. For instance `sgugger/finetuned-bert-mrpc`
    has been fine-tuned on the MRPC dataset, which classifies pairs of sentences as
    paraphrases or not.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚ä¾‹å¦‚`sgugger/finetuned-bert-mrpc`å·²åœ¨MRPCæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œç”¨äºå°†å¥å­å¯¹åˆ†ç±»ä¸ºé‡Šä¹‰æˆ–éé‡Šä¹‰ã€‚
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then we can share it on the Hub by using the `save_pretrained` method in a
    `Repository`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨`Repository`ä¸­ä½¿ç”¨`save_pretrained`æ–¹æ³•åœ¨Hubä¸Šå…±äº«å®ƒï¼š
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will copy the file where you defined `PairClassificationPipeline` inside
    the folder `"test-dynamic-pipeline"`, along with saving the model and tokenizer
    of the pipeline, before pushing everything into the repository `{your_username}/test-dynamic-pipeline`.
    After that, anyone can use it as long as they provide the option `trust_remote_code=True`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†å¤åˆ¶æ‚¨åœ¨æ–‡ä»¶ä¸­å®šä¹‰`PairClassificationPipeline`çš„æ–‡ä»¶å¤¹`"test-dynamic-pipeline"`ä¸­ï¼ŒåŒæ—¶ä¿å­˜ç®¡é“çš„æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œç„¶åå°†æ‰€æœ‰å†…å®¹æ¨é€åˆ°å­˜å‚¨åº“`{your_username}/test-dynamic-pipeline`ä¸­ã€‚ä¹‹åï¼Œä»»ä½•äººåªè¦æä¾›é€‰é¡¹`trust_remote_code=True`å°±å¯ä»¥ä½¿ç”¨å®ƒï¼š
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Add the pipeline to ğŸ¤— Transformers
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°†ç®¡é“æ·»åŠ åˆ°ğŸ¤— Transformers
- en: If you want to contribute your pipeline to ğŸ¤— Transformers, you will need to
    add a new module in the `pipelines` submodule with the code of your pipeline,
    then add it to the list of tasks defined in `pipelines/__init__.py`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³å°†æ‚¨çš„ç®¡é“è´¡çŒ®ç»™ğŸ¤— Transformersï¼Œæ‚¨éœ€è¦åœ¨`pipelines`å­æ¨¡å—ä¸­æ·»åŠ ä¸€ä¸ªæ–°æ¨¡å—ï¼Œå…¶ä¸­åŒ…å«æ‚¨çš„ç®¡é“çš„ä»£ç ï¼Œç„¶åå°†å…¶æ·»åŠ åˆ°`pipelines/__init__.py`ä¸­å®šä¹‰çš„ä»»åŠ¡åˆ—è¡¨ä¸­ã€‚
- en: Then you will need to add tests. Create a new file `tests/test_pipelines_MY_PIPELINE.py`
    with examples of the other tests.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæ‚¨éœ€è¦æ·»åŠ æµ‹è¯•ã€‚åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶`tests/test_pipelines_MY_PIPELINE.py`ï¼Œå…¶ä¸­åŒ…å«å…¶ä»–æµ‹è¯•çš„ç¤ºä¾‹ã€‚
- en: The `run_pipeline_test` function will be very generic and run on small random
    models on every possible architecture as defined by `model_mapping` and `tf_model_mapping`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`run_pipeline_test`å‡½æ•°å°†éå¸¸é€šç”¨ï¼Œå¹¶åœ¨ç”±`model_mapping`å’Œ`tf_model_mapping`å®šä¹‰çš„æ¯ç§å¯èƒ½çš„æ¶æ„ä¸Šè¿è¡Œå°å‹éšæœºæ¨¡å‹ã€‚'
- en: This is very important to test future compatibility, meaning if someone adds
    a new model for `XXXForQuestionAnswering` then the pipeline test will attempt
    to run on it. Because the models are random itâ€™s impossible to check for actual
    values, thatâ€™s why there is a helper `ANY` that will simply attempt to match the
    output of the pipeline TYPE.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹äºæµ‹è¯•æœªæ¥çš„å…¼å®¹æ€§éå¸¸é‡è¦ï¼Œè¿™æ„å‘³ç€å¦‚æœæœ‰äººä¸º`XXXForQuestionAnswering`æ·»åŠ äº†ä¸€ä¸ªæ–°æ¨¡å‹ï¼Œé‚£ä¹ˆç®¡é“æµ‹è¯•å°†å°è¯•åœ¨å…¶ä¸Šè¿è¡Œã€‚ç”±äºæ¨¡å‹æ˜¯éšæœºçš„ï¼Œæ— æ³•æ£€æŸ¥å®é™…å€¼ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰ä¸€ä¸ªè¾…åŠ©`ANY`ï¼Œå®ƒå°†ç®€å•åœ°å°è¯•åŒ¹é…ç®¡é“ç±»å‹çš„è¾“å‡ºã€‚
- en: You also *need* to implement 2 (ideally 4) tests.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜*éœ€è¦*å®ç°2ï¼ˆç†æƒ³æƒ…å†µä¸‹4ï¼‰ä¸ªæµ‹è¯•ã€‚
- en: '`test_small_model_pt` : Define 1 small model for this pipeline (doesnâ€™t matter
    if the results donâ€™t make sense) and test the pipeline outputs. The results should
    be the same as `test_small_model_tf`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_small_model_pt`ï¼šä¸ºè¿™ä¸ªç®¡é“å®šä¹‰ä¸€ä¸ªå°æ¨¡å‹ï¼ˆç»“æœæ˜¯å¦æœ‰æ„ä¹‰å¹¶ä¸é‡è¦ï¼‰ï¼Œå¹¶æµ‹è¯•ç®¡é“çš„è¾“å‡ºã€‚ç»“æœåº”è¯¥ä¸`test_small_model_tf`ç›¸åŒã€‚'
- en: '`test_small_model_tf` : Define 1 small model for this pipeline (doesnâ€™t matter
    if the results donâ€™t make sense) and test the pipeline outputs. The results should
    be the same as `test_small_model_pt`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_small_model_tf`ï¼šä¸ºè¿™ä¸ªç®¡é“å®šä¹‰ä¸€ä¸ªå°æ¨¡å‹ï¼ˆç»“æœæ˜¯å¦æœ‰æ„ä¹‰å¹¶ä¸é‡è¦ï¼‰ï¼Œå¹¶æµ‹è¯•ç®¡é“çš„è¾“å‡ºã€‚ç»“æœåº”è¯¥ä¸`test_small_model_pt`ç›¸åŒã€‚'
- en: '`test_large_model_pt` (`optional`): Tests the pipeline on a real pipeline where
    the results are supposed to make sense. These tests are slow and should be marked
    as such. Here the goal is to showcase the pipeline and to make sure there is no
    drift in future releases.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_large_model_pt` (`optional`): åœ¨ä¸€ä¸ªçœŸå®çš„ç®¡é“ä¸Šæµ‹è¯•ç®¡é“ï¼Œç»“æœåº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™äº›æµ‹è¯•å¾ˆæ…¢ï¼Œåº”è¯¥æ ‡è®°ä¸ºè¿™æ ·ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯å±•ç¤ºç®¡é“ï¼Œå¹¶ç¡®ä¿å°†æ¥çš„å‘å¸ƒä¸­æ²¡æœ‰æ¼‚ç§»ã€‚'
- en: '`test_large_model_tf` (`optional`): Tests the pipeline on a real pipeline where
    the results are supposed to make sense. These tests are slow and should be marked
    as such. Here the goal is to showcase the pipeline and to make sure there is no
    drift in future releases.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_large_model_tf` (`optional`): åœ¨ä¸€ä¸ªçœŸå®çš„ç®¡é“ä¸Šæµ‹è¯•ç®¡é“ï¼Œç»“æœåº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™äº›æµ‹è¯•å¾ˆæ…¢ï¼Œåº”è¯¥æ ‡è®°ä¸ºè¿™æ ·ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯å±•ç¤ºç®¡é“ï¼Œå¹¶ç¡®ä¿å°†æ¥çš„å‘å¸ƒä¸­æ²¡æœ‰æ¼‚ç§»ã€‚'
