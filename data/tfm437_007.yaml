- en: Load pretrained instances with an AutoClass
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨AutoClassåŠ è½½é¢„è®­ç»ƒå®ä¾‹
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial](https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial](https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: With so many different Transformer architectures, it can be challenging to create
    one for your checkpoint. As a part of ğŸ¤— Transformers core philosophy to make the
    library easy, simple and flexible to use, an `AutoClass` automatically infers
    and loads the correct architecture from a given checkpoint. The `from_pretrained()`
    method lets you quickly load a pretrained model for any architecture so you donâ€™t
    have to devote time and resources to train a model from scratch. Producing this
    type of checkpoint-agnostic code means if your code works for one checkpoint,
    it will work with another checkpoint - as long as it was trained for a similar
    task - even if the architecture is different.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæœ‰è¿™ä¹ˆå¤šä¸åŒçš„Transformeræ¶æ„ï¼Œä¸ºæ‚¨çš„æ£€æŸ¥ç‚¹åˆ›å»ºä¸€ä¸ªå¯èƒ½æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚ä½œä¸ºğŸ¤— Transformersæ ¸å¿ƒç†å¿µçš„ä¸€éƒ¨åˆ†ï¼Œä½¿åº“æ˜“äºä½¿ç”¨ã€ç®€å•çµæ´»ï¼Œ`AutoClass`ä¼šè‡ªåŠ¨æ¨æ–­å¹¶ä»ç»™å®šçš„æ£€æŸ¥ç‚¹åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚`from_pretrained()`æ–¹æ³•è®©æ‚¨å¿«é€ŸåŠ è½½ä»»ä½•æ¶æ„çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™æ ·æ‚¨å°±ä¸å¿…èŠ±æ—¶é—´å’Œèµ„æºä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚ç”Ÿæˆè¿™ç§ä¸æ£€æŸ¥ç‚¹æ— å…³çš„ä»£ç æ„å‘³ç€ï¼Œå¦‚æœæ‚¨çš„ä»£ç é€‚ç”¨äºä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œå®ƒå°†é€‚ç”¨äºå¦ä¸€ä¸ªæ£€æŸ¥ç‚¹
    - åªè¦å®ƒæ˜¯ä¸ºç±»ä¼¼ä»»åŠ¡è®­ç»ƒçš„ - å³ä½¿æ¶æ„ä¸åŒã€‚
- en: Remember, architecture refers to the skeleton of the model and checkpoints are
    the weights for a given architecture. For example, [BERT](https://huggingface.co/bert-base-uncased)
    is an architecture, while `bert-base-uncased` is a checkpoint. Model is a general
    term that can mean either architecture or checkpoint.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œæ¶æ„æŒ‡çš„æ˜¯æ¨¡å‹çš„éª¨æ¶ï¼Œæ£€æŸ¥ç‚¹æ˜¯ç»™å®šæ¶æ„çš„æƒé‡ã€‚ä¾‹å¦‚ï¼Œ[BERT](https://huggingface.co/bert-base-uncased)æ˜¯ä¸€ä¸ªæ¶æ„ï¼Œè€Œ`bert-base-uncased`æ˜¯ä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚æ¨¡å‹æ˜¯ä¸€ä¸ªé€šç”¨æœ¯è¯­ï¼Œå¯ä»¥æŒ‡ä»£æ¶æ„æˆ–æ£€æŸ¥ç‚¹ã€‚
- en: 'In this tutorial, learn to:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œå­¦ä¹ ï¼š
- en: Load a pretrained tokenizer.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒåˆ†è¯å™¨ã€‚
- en: Load a pretrained image processor
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒå›¾åƒå¤„ç†å™¨
- en: Load a pretrained feature extractor.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒç‰¹å¾æå–å™¨ã€‚
- en: Load a pretrained processor.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒå¤„ç†å™¨ã€‚
- en: Load a pretrained model.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚
- en: Load a model as a backbone.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªä½œä¸ºéª¨å¹²çš„æ¨¡å‹ã€‚
- en: AutoTokenizer
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoTokenizer
- en: Nearly every NLP task begins with a tokenizer. A tokenizer converts your input
    into a format that can be processed by the model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä¹æ¯ä¸ªNLPä»»åŠ¡éƒ½ä»¥åˆ†è¯å™¨å¼€å§‹ã€‚åˆ†è¯å™¨å°†æ‚¨çš„è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚
- en: 'Load a tokenizer with [AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained)åŠ è½½ä¸€ä¸ªåˆ†è¯å™¨ï¼š
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then tokenize your input as shown below:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæŒ‰ç…§ä¸‹é¢æ‰€ç¤ºå¯¹æ‚¨çš„è¾“å…¥è¿›è¡Œæ ‡è®°åŒ–ï¼š
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: AutoImageProcessor
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoImageProcessor
- en: For vision tasks, an image processor processes the image into the correct input
    format.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œå›¾åƒå¤„ç†å™¨å°†å›¾åƒå¤„ç†æˆæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: AutoFeatureExtractor
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoFeatureExtractor
- en: For audio tasks, a feature extractor processes the audio signal the correct
    input format.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºéŸ³é¢‘ä»»åŠ¡ï¼Œç‰¹å¾æå–å™¨å°†éŸ³é¢‘ä¿¡å·å¤„ç†æˆæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚
- en: 'Load a feature extractor with [AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained)åŠ è½½ä¸€ä¸ªç‰¹å¾æå–å™¨ï¼š
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: AutoProcessor
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoProcessor
- en: Multimodal tasks require a processor that combines two types of preprocessing
    tools. For example, the [LayoutLMV2](model_doc/layoutlmv2) model requires an image
    processor to handle images and a tokenizer to handle text; a processor combines
    both of them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šæ¨¡æ€ä»»åŠ¡éœ€è¦ä¸€ä¸ªç»“åˆä¸¤ç§é¢„å¤„ç†å·¥å…·çš„å¤„ç†å™¨ã€‚ä¾‹å¦‚ï¼Œ[LayoutLMV2](model_doc/layoutlmv2)æ¨¡å‹éœ€è¦ä¸€ä¸ªå›¾åƒå¤„ç†å™¨æ¥å¤„ç†å›¾åƒï¼Œä¸€ä¸ªåˆ†è¯å™¨æ¥å¤„ç†æ–‡æœ¬ï¼›å¤„ç†å™¨å°†ä¸¤è€…ç»“åˆèµ·æ¥ã€‚
- en: 'Load a processor with [AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained)åŠ è½½ä¸€ä¸ªå¤„ç†å™¨ï¼š
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: AutoModel
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoModel
- en: PytorchHide Pytorch content
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: 'The `AutoModelFor` classes let you load a pretrained model for a given task
    (see [here](model_doc/auto) for a complete list of available tasks). For example,
    load a model for sequence classification with [AutoModelForSequenceClassification.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`AutoModelFor`ç±»è®©æ‚¨åŠ è½½ç»™å®šä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè¯·å‚é˜…[æ­¤å¤„](model_doc/auto)ä»¥è·å–å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨[AutoModelForSequenceClassification.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)åŠ è½½ä¸€ä¸ªç”¨äºåºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼š'
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Easily reuse the same checkpoint to load an architecture for a different task:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è½»æ¾é‡ç”¨ç›¸åŒçš„æ£€æŸ¥ç‚¹æ¥åŠ è½½ä¸åŒä»»åŠ¡çš„æ¶æ„ï¼š
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For PyTorch models, the `from_pretrained()` method uses `torch.load()` which
    internally uses `pickle` and is known to be insecure. In general, never load a
    model that could have come from an untrusted source, or that could have been tampered
    with. This security risk is partially mitigated for public models hosted on the
    Hugging Face Hub, which are [scanned for malware](https://huggingface.co/docs/hub/security-malware)
    at each commit. See the [Hub documentation](https://huggingface.co/docs/hub/security)
    for best practices like [signed commit verification](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg)
    with GPG.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºPyTorchæ¨¡å‹ï¼Œ`from_pretrained()`æ–¹æ³•ä½¿ç”¨`torch.load()`ï¼Œå†…éƒ¨ä½¿ç”¨`pickle`ï¼Œå·²çŸ¥å­˜åœ¨å®‰å…¨é£é™©ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ°¸è¿œä¸è¦åŠ è½½å¯èƒ½æ¥è‡ªä¸å—ä¿¡ä»»æ¥æºæˆ–å¯èƒ½è¢«ç¯¡æ”¹çš„æ¨¡å‹ã€‚å¯¹äºåœ¨Hugging
    Face Hubä¸Šæ‰˜ç®¡çš„å…¬å…±æ¨¡å‹ï¼Œè¿™ç§å®‰å…¨é£é™©éƒ¨åˆ†å¾—åˆ°ç¼“è§£ï¼Œè¿™äº›æ¨¡å‹åœ¨æ¯æ¬¡æäº¤æ—¶éƒ½ä¼šè¿›è¡Œ[æ¶æ„è½¯ä»¶æ‰«æ](https://huggingface.co/docs/hub/security-malware)ã€‚æŸ¥çœ‹[Hubæ–‡æ¡£](https://huggingface.co/docs/hub/security)ä»¥è·å–æœ€ä½³å®è·µï¼Œå¦‚ä½¿ç”¨GPGè¿›è¡Œ[ç­¾åæäº¤éªŒè¯](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg)ã€‚
- en: TensorFlow and Flax checkpoints are not affected, and can be loaded within PyTorch
    architectures using the `from_tf` and `from_flax` kwargs for the `from_pretrained`
    method to circumvent this issue.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowå’ŒFlaxæ£€æŸ¥ç‚¹ä¸å—å½±å“ï¼Œå¯ä»¥åœ¨PyTorchæ¶æ„ä¸­ä½¿ç”¨`from_tf`å’Œ`from_flax`å‚æ•°åŠ è½½ï¼Œä»¥ç»•è¿‡æ­¤é—®é¢˜ã€‚
- en: Generally, we recommend using the `AutoTokenizer` class and the `AutoModelFor`
    class to load pretrained instances of models. This will ensure you load the correct
    architecture every time. In the next [tutorial](preprocessing), learn how to use
    your newly loaded tokenizer, image processor, feature extractor and processor
    to preprocess a dataset for fine-tuning.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨`AutoTokenizer`ç±»å’Œ`AutoModelFor`ç±»æ¥åŠ è½½æ¨¡å‹çš„é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™å°†ç¡®ä¿æ‚¨æ¯æ¬¡åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚åœ¨ä¸‹ä¸€ä¸ª[æ•™ç¨‹](preprocessing)ä¸­ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨æ–°åŠ è½½çš„åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨å’Œå¤„ç†å™¨æ¥é¢„å¤„ç†æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚
- en: TensorFlowHide TensorFlow content
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè—TensorFlowå†…å®¹
- en: 'Finally, the `TFAutoModelFor` classes let you load a pretrained model for a
    given task (see [here](model_doc/auto) for a complete list of available tasks).
    For example, load a model for sequence classification with [TFAutoModelForSequenceClassification.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œ`TFAutoModelFor`ç±»è®©æ‚¨åŠ è½½ç»™å®šä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè¯·å‚é˜…[æ­¤å¤„](model_doc/auto)ä»¥è·å–å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨[TFAutoModelForSequenceClassification.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)åŠ è½½ç”¨äºåºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼š
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Easily reuse the same checkpoint to load an architecture for a different task:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è½»æ¾åœ°é‡å¤ä½¿ç”¨ç›¸åŒçš„æ£€æŸ¥ç‚¹æ¥åŠ è½½ä¸åŒä»»åŠ¡çš„æ¶æ„ï¼š
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Generally, we recommend using the `AutoTokenizer` class and the `TFAutoModelFor`
    class to load pretrained instances of models. This will ensure you load the correct
    architecture every time. In the next [tutorial](preprocessing), learn how to use
    your newly loaded tokenizer, image processor, feature extractor and processor
    to preprocess a dataset for fine-tuning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨`AutoTokenizer`ç±»å’Œ`TFAutoModelFor`ç±»æ¥åŠ è½½æ¨¡å‹çš„é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™å°†ç¡®ä¿æ‚¨æ¯æ¬¡åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚åœ¨ä¸‹ä¸€ä¸ª[æ•™ç¨‹](preprocessing)ä¸­ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨æ–°åŠ è½½çš„åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨å’Œå¤„ç†å™¨æ¥é¢„å¤„ç†æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚
- en: AutoBackbone
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoBackbone
- en: '`AutoBackbone` lets you use pretrained models as backbones and get feature
    maps as outputs from different stages of the models. Below you can see how to
    get feature maps from a [Swin](model_doc/swin) checkpoint.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`AutoBackbone`å…è®¸æ‚¨å°†é¢„è®­ç»ƒæ¨¡å‹ç”¨ä½œéª¨å¹²ï¼Œå¹¶ä»æ¨¡å‹çš„ä¸åŒé˜¶æ®µè·å¾—ç‰¹å¾å›¾ä½œä¸ºè¾“å‡ºã€‚ä¸‹é¢æ‚¨å¯ä»¥çœ‹åˆ°å¦‚ä½•ä»[Swin](model_doc/swin)æ£€æŸ¥ç‚¹è·å–ç‰¹å¾å›¾ã€‚'
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
