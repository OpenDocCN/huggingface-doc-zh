- en: Installation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/installation](https://huggingface.co/docs/transformers/v4.37.2/en/installation)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/transformers/v4.37.2/en/installation](https://huggingface.co/docs/transformers/v4.37.2/en/installation)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Install 🤗 Transformers for whichever deep learning library you’re working with,
    setup your cache, and optionally configure 🤗 Transformers to run offline.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为您正在使用的任何深度学习库安装🤗 Transformers，设置您的缓存，并可选择配置🤗 Transformers以离线运行。
- en: '🤗 Transformers is tested on Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, and
    Flax. Follow the installation instructions below for the deep learning library
    you are using:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers在Python 3.6+、PyTorch 1.1.0+、TensorFlow 2.0+和Flax上进行了测试。按照下面的安装说明为您正在使用的深度学习库安装：
- en: '[PyTorch](https://pytorch.org/get-started/locally/) installation instructions.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch](https://pytorch.org/get-started/locally/)安装说明。'
- en: '[TensorFlow 2.0](https://www.tensorflow.org/install/pip) installation instructions.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow 2.0](https://www.tensorflow.org/install/pip)安装说明。'
- en: '[Flax](https://flax.readthedocs.io/en/latest/) installation instructions.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Flax](https://flax.readthedocs.io/en/latest/)安装说明。'
- en: Install with pip
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用pip安装
- en: You should install 🤗 Transformers in a [virtual environment](https://docs.python.org/3/library/venv.html).
    If you’re unfamiliar with Python virtual environments, take a look at this [guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).
    A virtual environment makes it easier to manage different projects, and avoid
    compatibility issues between dependencies.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在[virtual environment](https://docs.python.org/3/library/venv.html)中安装🤗 Transformers。如果您不熟悉Python虚拟环境，请查看这个[guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)。虚拟环境使得管理不同项目更容易，并避免依赖项之间的兼容性问题。
- en: 'Start by creating a virtual environment in your project directory:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在项目目录中创建一个虚拟环境：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Activate the virtual environment. On Linux and MacOs:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 激活虚拟环境。在Linux和MacOs上：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Activate Virtual environment on Windows
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上激活虚拟环境
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now you’re ready to install 🤗 Transformers with the following command:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以使用以下命令安装🤗 Transformers：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For CPU-support only, you can conveniently install 🤗 Transformers and a deep
    learning library in one line. For example, install 🤗 Transformers and PyTorch
    with:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 仅支持CPU的情况下，您可以方便地在一行中安装🤗 Transformers和一个深度学习库。例如，使用以下命令安装🤗 Transformers和PyTorch：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '🤗 Transformers and TensorFlow 2.0:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers和TensorFlow 2.0：
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: M1 / ARM Users
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: M1 / ARM用户
- en: You will need to install the following before installing TensorFLow 2.0
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装TensorFLow 2.0之前，您需要安装以下内容
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '🤗 Transformers and Flax:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers和Flax：
- en: '[PRE7]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, check if 🤗 Transformers has been properly installed by running the
    following command. It will download a pretrained model:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过运行以下命令检查🤗 Transformers是否已正确安装。它将下载一个预训练模型：
- en: '[PRE8]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then print out the label and score:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然后打印标签和分数：
- en: '[PRE9]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Install from source
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从源代码安装
- en: 'Install 🤗 Transformers from source with the following command:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令从源代码安装🤗 Transformers：
- en: '[PRE10]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This command installs the bleeding edge `main` version rather than the latest
    `stable` version. The `main` version is useful for staying up-to-date with the
    latest developments. For instance, if a bug has been fixed since the last official
    release but a new release hasn’t been rolled out yet. However, this means the
    `main` version may not always be stable. We strive to keep the `main` version
    operational, and most issues are usually resolved within a few hours or a day.
    If you run into a problem, please open an [Issue](https://github.com/huggingface/transformers/issues)
    so we can fix it even sooner!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令安装最新的`stable`版本而不是最新的`main`版本。`main`版本对于保持与最新发展保持最新是有用的。例如，如果自上次官方发布以来修复了错误但尚未推出新版本。但是，这意味着`main`版本可能不总是稳定的。我们努力保持`main`版本的运行，并且大多数问题通常在几个小时或一天内解决。如果遇到问题，请打开一个[Issue](https://github.com/huggingface/transformers/issues)，以便我们更快地解决！
- en: 'Check if 🤗 Transformers has been properly installed by running the following
    command:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令检查🤗 Transformers是否已正确安装：
- en: '[PRE11]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Editable install
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可编辑安装
- en: 'You will need an editable install if you’d like to:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要，您将需要一个可编辑的安装：
- en: Use the `main` version of the source code.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用源代码的`main`版本。
- en: Contribute to 🤗 Transformers and need to test changes in the code.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为🤗 Transformers做出贡献并需要测试代码更改。
- en: 'Clone the repository and install 🤗 Transformers with the following commands:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆存储库并使用以下命令安装🤗 Transformers：
- en: '[PRE12]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'These commands will link the folder you cloned the repository to and your Python
    library paths. Python will now look inside the folder you cloned to in addition
    to the normal library paths. For example, if your Python packages are typically
    installed in `~/anaconda3/envs/main/lib/python3.7/site-packages/`, Python will
    also search the folder you cloned to: `~/transformers/`.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令将链接您克隆存储库的文件夹和您的Python库路径。现在Python将在您克隆到的文件夹中查找，除了正常的库路径。例如，如果您的Python包通常安装在`~/anaconda3/envs/main/lib/python3.7/site-packages/`中，Python还将搜索您克隆到的文件夹：`~/transformers/`。
- en: You must keep the `transformers` folder if you want to keep using the library.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要继续使用该库，必须保留`transformers`文件夹。
- en: 'Now you can easily update your clone to the latest version of 🤗 Transformers
    with the following command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以使用以下命令轻松将克隆更新到最新版本的🤗 Transformers：
- en: '[PRE13]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Your Python environment will find the `main` version of 🤗 Transformers on the
    next run.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 您的Python环境将在下一次运行时找到🤗 Transformers的`main`版本。
- en: Install with conda
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用conda安装
- en: 'Install from the conda channel `conda-forge`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从conda频道`conda-forge`安装：
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Cache setup
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存设置
- en: 'Pretrained models are downloaded and locally cached at: `~/.cache/huggingface/hub`.
    This is the default directory given by the shell environment variable `TRANSFORMERS_CACHE`.
    On Windows, the default directory is given by `C:\Users\username\.cache\huggingface\hub`.
    You can change the shell environment variables shown below - in order of priority
    - to specify a different cache directory:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型将被下载并在`~/.cache/huggingface/hub`中本地缓存。这是由shell环境变量`TRANSFORMERS_CACHE`给出的默认目录。在Windows上，默认目录由`C:\Users\username\.cache\huggingface\hub`给出。您可以更改下面显示的shell环境变量
    - 以优先顺序列出 - 以指定不同的缓存目录：
- en: 'Shell environment variable (default): `HUGGINGFACE_HUB_CACHE` or `TRANSFORMERS_CACHE`.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Shell环境变量（默认）：`HUGGINGFACE_HUB_CACHE`或`TRANSFORMERS_CACHE`。
- en: 'Shell environment variable: `HF_HOME`.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Shell环境变量：`HF_HOME`。
- en: 'Shell environment variable: `XDG_CACHE_HOME` + `/huggingface`.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Shell环境变量：`XDG_CACHE_HOME` + `/huggingface`。
- en: 🤗 Transformers will use the shell environment variables `PYTORCH_TRANSFORMERS_CACHE`
    or `PYTORCH_PRETRAINED_BERT_CACHE` if you are coming from an earlier iteration
    of this library and have set those environment variables, unless you specify the
    shell environment variable `TRANSFORMERS_CACHE`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers将使用shell环境变量`PYTORCH_TRANSFORMERS_CACHE`或`PYTORCH_PRETRAINED_BERT_CACHE`，如果您来自此库的早期版本并设置了这些环境变量，除非您指定shell环境变量`TRANSFORMERS_CACHE`。
- en: Offline mode
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离线模式
- en: Run 🤗 Transformers in a firewalled or offline environment with locally cached
    files by setting the environment variable `TRANSFORMERS_OFFLINE=1`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置环境变量`TRANSFORMERS_OFFLINE=1`在防火墙或离线环境中运行🤗 Transformers，并使用本地缓存文件。
- en: Add [🤗 Datasets](https://huggingface.co/docs/datasets/) to your offline training
    workflow with the environment variable `HF_DATASETS_OFFLINE=1`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过环境变量`HF_DATASETS_OFFLINE=1`将[🤗 Datasets](https://huggingface.co/docs/datasets/)添加到您的离线训练工作流程。
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This script should run without hanging or waiting to timeout because it won’t
    attempt to download the model from the Hub.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本应该可以在不挂起或等待超时的情况下运行，因为它不会尝试从Hub下载模型。
- en: 'You can also bypass loading a model from the Hub from each [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    call with the `local_files_only` parameter. When set to `True`, only local files
    are loaded:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过`local_files_only`参数在每个[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)调用中绕过从Hub加载模型。当设置为`True`时，只加载本地文件：
- en: '[PRE16]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Fetch models and tokenizers to use offline
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取模型和分词器以离线使用
- en: 'Another option for using 🤗 Transformers offline is to download the files ahead
    of time, and then point to their local path when you need to use them offline.
    There are three ways to do this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种离线使用🤗 Transformers的选项是提前下载文件，然后在需要离线使用时指向它们的本地路径。有三种方法可以做到这一点：
- en: Download a file through the user interface on the [Model Hub](https://huggingface.co/models)
    by clicking on the ↓ icon.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过点击↓图标在[Model Hub](https://huggingface.co/models)上的用户界面下载文件。
- en: '![download-icon](../Images/454f62526609aa00b3e6e8a4acfbc9bc.png)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![download-icon](../Images/454f62526609aa00b3e6e8a4acfbc9bc.png)'
- en: 'Use the [PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    and [PreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    workflow:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)和[PreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)工作流程：
- en: 'Download your files ahead of time with [PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained):'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)提前下载您的文件：
- en: '[PRE17]'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Save your files to a specified directory with [PreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained):'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[PreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)将文件保存到指定目录：
- en: '[PRE18]'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now when you’re offline, reload your files with [PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    from the specified directory:'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在当您离线时，通过从指定目录重新加载您的文件使用[PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)：
- en: '[PRE19]'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Programmatically download files with the [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub)
    library:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub)库以编程方式下载文件：
- en: 'Install the `huggingface_hub` library in your virtual environment:'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的虚拟环境中安装`huggingface_hub`库：
- en: '[PRE20]'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Use the [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub)
    function to download a file to a specific path. For example, the following command
    downloads the `config.json` file from the [T0](https://huggingface.co/bigscience/T0_3B)
    model to your desired path:'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub)函数将文件下载到特定路径。例如，以下命令将从[T0](https://huggingface.co/bigscience/T0_3B)模型下载`config.json`文件到您想要的路径：
- en: '[PRE21]'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once your file is downloaded and locally cached, specify it’s local path to
    load and use it:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的文件被下载并本地缓存，指定它的本地路径以加载和使用它：
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: See the [How to download files from the Hub](https://huggingface.co/docs/hub/how-to-downstream)
    section for more details on downloading files stored on the Hub.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[如何从Hub下载文件](https://huggingface.co/docs/hub/how-to-downstream)部分，了解有关下载存储在Hub上的文件的更多详细信息。
