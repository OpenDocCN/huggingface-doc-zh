- en: Monocular depth estimation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单目深度估计
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/tasks/monocular_depth_estimation](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/monocular_depth_estimation)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/tasks/monocular_depth_estimation](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/monocular_depth_estimation)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Monocular depth estimation is a computer vision task that involves predicting
    the depth information of a scene from a single image. In other words, it is the
    process of estimating the distance of objects in a scene from a single camera
    viewpoint.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 单目深度估计是一个涉及从单个图像预测场景深度信息的计算机视觉任务。换句话说，它是从单个摄像机视角估计场景中物体的距离的过程。
- en: Monocular depth estimation has various applications, including 3D reconstruction,
    augmented reality, autonomous driving, and robotics. It is a challenging task
    as it requires the model to understand the complex relationships between objects
    in the scene and the corresponding depth information, which can be affected by
    factors such as lighting conditions, occlusion, and texture.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 单目深度估计具有各种应用，包括3D重建，增强现实，自动驾驶和机器人技术。这是一个具有挑战性的任务，因为它要求模型理解场景中物体之间以及相应深度信息之间的复杂关系，这些关系可能受到光照条件、遮挡和纹理等因素的影响。
- en: 'The task illustrated in this tutorial is supported by the following model architectures:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中展示的任务由以下模型架构支持：
- en: '[DPT](../model_doc/dpt), [GLPN](../model_doc/glpn)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[DPT](../model_doc/dpt), [GLPN](../model_doc/glpn)'
- en: 'In this guide you’ll learn how to:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，您将学习如何：
- en: create a depth estimation pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建深度估计管道
- en: run depth estimation inference by hand
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动运行深度估计推断
- en: 'Before you begin, make sure you have all the necessary libraries installed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已安装所有必要的库：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Depth estimation pipeline
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度估计管道
- en: 'The simplest way to try out inference with a model supporting depth estimation
    is to use the corresponding [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline).
    Instantiate a pipeline from a [checkpoint on the Hugging Face Hub](https://huggingface.co/models?pipeline_tag=depth-estimation&sort=downloads):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用支持深度估计的模型进行推断的最简单方法是使用相应的[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。从[Hugging
    Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=depth-estimation&sort=downloads)实例化一个管道：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, choose an image to analyze:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，选择要分析的图像：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Photo of a busy street](../Images/7c44a18801e68f14d4d1cb85510d1bdc.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![繁忙街道的照片](../Images/7c44a18801e68f14d4d1cb85510d1bdc.png)'
- en: Pass the image to the pipeline.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像传递给管道。
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The pipeline returns a dictionary with two entries. The first one, called `predicted_depth`,
    is a tensor with the values being the depth expressed in meters for each pixel.
    The second one, `depth`, is a PIL image that visualizes the depth estimation result.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 管道返回一个带有两个条目的字典。第一个条目名为`predicted_depth`，是一个张量，其值为每个像素的以米为单位的深度。第二个条目`depth`是一个PIL图像，可视化深度估计结果。
- en: 'Let’s take a look at the visualized result:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下可视化结果：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Depth estimation visualization](../Images/dac09b39a795bd23817e4cff71d4b6a8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![深度估计可视化](../Images/dac09b39a795bd23817e4cff71d4b6a8.png)'
- en: Depth estimation inference by hand
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动进行深度估计推断
- en: Now that you’ve seen how to use the depth estimation pipeline, let’s see how
    we can replicate the same result by hand.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到如何使用深度估计管道，让我们看看如何手动复制相同的结果。
- en: 'Start by loading the model and associated processor from a [checkpoint on the
    Hugging Face Hub](https://huggingface.co/models?pipeline_tag=depth-estimation&sort=downloads).
    Here we’ll use the same checkpoint as before:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从[Hugging Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=depth-estimation&sort=downloads)加载模型和相关处理器开始。这里我们将使用与之前相同的检查点：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Prepare the image input for the model using the `image_processor` that will
    take care of the necessary image transformations such as resizing and normalization:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`image_processor`准备模型的图像输入，该处理器将处理必要的图像转换，如调整大小和归一化：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Pass the prepared inputs through the model:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模型传递准备好的输入：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Visualize the results:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化结果：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Depth estimation visualization](../Images/dac09b39a795bd23817e4cff71d4b6a8.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![深度估计可视化](../Images/dac09b39a795bd23817e4cff71d4b6a8.png)'
