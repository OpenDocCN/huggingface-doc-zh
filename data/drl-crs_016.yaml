- en: Quiz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit1/quiz](https://huggingface.co/learn/deep-rl-course/unit1/quiz)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/learn/deep-rl-course/unit1/quiz](https://huggingface.co/learn/deep-rl-course/unit1/quiz)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)
    **is to test yourself.** This will help you to find **where you need to reinforce
    your knowledge**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 学习和[避免能力错觉](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)的最佳方法是测试自己。这将帮助你找到需要加强知识的地方。
- en: 'Q1: What is Reinforcement Learning?'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q1：什么是强化学习？
- en: <details data-svelte-h="svelte-hwjwin"><summary>Solution</summary>
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-hwjwin"><summary>解决方案</summary>
- en: Reinforcement learning is a **framework for solving control tasks (also called
    decision problems)** by building agents that learn from the environment by interacting
    with it through trial and error and **receiving rewards (positive or negative)
    as unique feedback**.</details>
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是通过与环境进行试错交互并接收奖励（积极或消极）作为独特反馈来解决控制任务（也称为决策问题）的框架。</details>
- en: 'Q2: Define the RL Loop'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q2：定义RL循环
- en: '![Exercise RL Loop](../Images/7dd50ea3f5814cad587739a6db3ce516.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![练习RL循环](../Images/7dd50ea3f5814cad587739a6db3ce516.png)'
- en: 'At every step:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步：
- en: Our Agent receives **__** from the environment
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的Agent从环境中接收__。
- en: Based on that **__** the Agent takes an **__**
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于那个__，Agent采取一个__。
- en: Our Agent will move to the right
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的Agent将向右移动
- en: The Environment goes to a **__**
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境进入一个__。
- en: The Environment gives a **__** to the Agent
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境给Agent一个__。
- en: 'Q3: What’s the difference between a state and an observation?'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q3：状态和观察之间有什么区别？
- en: 'Q4: A task is an instance of a Reinforcement Learning problem. What are the
    two types of tasks?'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q4：任务是强化学习问题的一个实例。有哪两种类型的任务？
- en: 'Q5: What is the exploration/exploitation tradeoff?'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q5：什么是探索/开发权衡？
- en: <details data-svelte-h="svelte-lhagbu"><summary>Solution</summary>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-lhagbu"><summary>解决方案</summary>
- en: In Reinforcement Learning, we need to **balance how much we explore the environment
    and how much we exploit what we know about the environment**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，我们需要平衡探索环境和利用我们对环境的了解的程度。
- en: '*Exploration* is exploring the environment by **trying random actions in order
    to find more information about the environment**.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*探索*是通过尝试随机动作来探索环境，以便更多地了解环境。'
- en: '*Exploitation* is **exploiting known information to maximize the reward**.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发*是利用已知信息来最大化奖励。'
- en: '![Exploration Exploitation Tradeoff](../Images/3a59b593e994b9d356515c58b0fa6a24.png)</details>'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![探索开发权衡](../Images/3a59b593e994b9d356515c58b0fa6a24.png)</details>'
- en: 'Q6: What is a policy?'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q6：什么是策略？
- en: <details data-svelte-h="svelte-su9zbv"><summary>Solution</summary>
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-su9zbv"><summary>解决方案</summary>
- en: The Policy π **is the brain of our Agent**. It’s the function that tells us
    what action to take given the state we are in. So it defines the agent’s behavior
    at a given time.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 策略π是我们Agent的大脑。它是告诉我们在特定状态下应该采取什么行动的函数。因此，它定义了Agent在特定时间的行为。
- en: '![Policy](../Images/83518e23a957f171ab1fe3fa7a6bbe35.png)</details>'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![策略](../Images/83518e23a957f171ab1fe3fa7a6bbe35.png)</details>'
- en: 'Q7: What are value-based methods?'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q7：什么是基于价值的方法？
- en: <details data-svelte-h="svelte-g9n3n1"><summary>Solution</summary>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-g9n3n1"><summary>解决方案</summary>
- en: Value-based methods is one of the main approaches for solving RL problems.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于价值的方法是解决RL问题的主要方法之一。
- en: In Value-based methods, instead of training a policy function, **we train a
    value function that maps a state to the expected value of being at that state**.</details>
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在基于价值的方法中，我们不是训练一个策略函数，而是训练一个价值函数，将一个状态映射到在该状态的预期价值。</details>
- en: 'Q8: What are policy-based methods?'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q8：什么是基于策略的方法？
- en: <details data-svelte-h="svelte-aae5od"><summary>Solution</summary>
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-aae5od"><summary>解决方案</summary>
- en: In *Policy-Based Methods*, we learn a **policy function directly**.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*基于策略的方法*中，我们直接学习一个策略函数。
- en: This policy function will **map from each state to the best corresponding action
    at that state**. Or a **probability distribution over the set of possible actions
    at that state**.</details>
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个策略函数将从每个状态映射到该状态的最佳对应动作。或者是该状态可能动作集合上的概率分布。</details>
- en: 'Congrats on finishing this Quiz 🥳, if you missed some elements, take time to
    read again the chapter to reinforce (😏) your knowledge, but **do not worry**:
    during the course we’ll go over again of these concepts, and you’ll **reinforce
    your theoretical knowledge with hands-on**.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了这个测验🥳，如果你错过了一些元素，请花时间再次阅读章节，以加强（😏）你的知识，但不要担心：在课程中，我们将再次讨论这些概念，并且你将通过实践加强你的理论知识。
