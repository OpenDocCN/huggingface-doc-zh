- en: Create an audio dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ›å»ºéŸ³é¢‘æ•°æ®é›†
- en: 'Original text: [https://huggingface.co/docs/datasets/audio_dataset](https://huggingface.co/docs/datasets/audio_dataset)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/datasets/audio_dataset](https://huggingface.co/docs/datasets/audio_dataset)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'You can share a dataset with your team or with anyone in the community by creating
    a dataset repository on the Hugging Face Hub:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡åœ¨Hugging Face Hubä¸Šåˆ›å»ºæ•°æ®é›†å­˜å‚¨åº“ä¸å›¢é˜Ÿæˆ–ç¤¾åŒºä¸­çš„ä»»ä½•äººå…±äº«æ•°æ®é›†ï¼š
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'There are several methods for creating and sharing an audio dataset:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ç§æ–¹æ³•å¯ä»¥åˆ›å»ºå’Œå…±äº«éŸ³é¢‘æ•°æ®é›†ï¼š
- en: Create an audio dataset from local files in python with [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub).
    This is an easy way that requires only a few steps in python.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)åœ¨Pythonä¸­ä»æœ¬åœ°æ–‡ä»¶åˆ›å»ºéŸ³é¢‘æ•°æ®é›†ã€‚è¿™æ˜¯ä¸€ç§åªéœ€è¦åœ¨Pythonä¸­è¿›è¡Œå‡ ä¸ªæ­¥éª¤çš„ç®€å•æ–¹æ³•ã€‚
- en: Create an audio dataset repository with the `AudioFolder` builder. This is a
    no-code solution for quickly creating an audio dataset with several thousand audio
    files.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`AudioFolder`æ„å»ºå™¨åˆ›å»ºéŸ³é¢‘æ•°æ®é›†å­˜å‚¨åº“ã€‚è¿™æ˜¯ä¸€ç§æ— ä»£ç è§£å†³æ–¹æ¡ˆï¼Œå¯å¿«é€Ÿåˆ›å»ºåŒ…å«æ•°åƒä¸ªéŸ³é¢‘æ–‡ä»¶çš„éŸ³é¢‘æ•°æ®é›†ã€‚
- en: Create an audio dataset by writing a loading script. This method is for advanced
    users and requires more effort and coding, but you have greater flexibility over
    how a dataset is defined, downloaded, and generated which can be useful for more
    complex or large scale audio datasets.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ç¼–å†™åŠ è½½è„šæœ¬åˆ›å»ºéŸ³é¢‘æ•°æ®é›†ã€‚è¿™ç§æ–¹æ³•é€‚ç”¨äºé«˜çº§ç”¨æˆ·ï¼Œéœ€è¦æ›´å¤šçš„åŠªåŠ›å’Œç¼–ç ï¼Œä½†æ‚¨å¯ä»¥æ›´çµæ´»åœ°å®šä¹‰ã€ä¸‹è½½å’Œç”Ÿæˆæ•°æ®é›†ï¼Œè¿™å¯¹äºæ›´å¤æ‚æˆ–å¤§è§„æ¨¡çš„éŸ³é¢‘æ•°æ®é›†å¯èƒ½å¾ˆæœ‰ç”¨ã€‚
- en: You can control access to your dataset by requiring users to share their contact
    information first. Check out the [Gated datasets](https://huggingface.co/docs/hub/datasets-gated)
    guide for more information about how to enable this feature on the Hub.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡è¦æ±‚ç”¨æˆ·é¦–å…ˆå…±äº«å…¶è”ç³»ä¿¡æ¯æ¥æ§åˆ¶å¯¹æ•°æ®é›†çš„è®¿é—®æƒé™ã€‚æŸ¥çœ‹[Hugging Face Hubä¸Šçš„Gatedæ•°æ®é›†](https://huggingface.co/docs/hub/datasets-gated)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åœ¨Hubä¸Šå¯ç”¨æ­¤åŠŸèƒ½çš„æ›´å¤šä¿¡æ¯ã€‚
- en: Local files
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ¬åœ°æ–‡ä»¶
- en: 'You can load your own dataset using the paths to your audio files. Use the
    [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    function to take a column of audio file paths, and cast it to the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„åŠ è½½è‡ªå·±çš„æ•°æ®é›†ã€‚ä½¿ç”¨[cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)å‡½æ•°å°†éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è½¬æ¢ä¸º[Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)ç‰¹å¾ï¼š
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then upload the dataset to the Hugging Face Hub using [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½¿ç”¨[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)å°†æ•°æ®é›†ä¸Šä¼ åˆ°Hugging
    Face Hubï¼š
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will create a dataset repository containing your audio dataset:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åˆ›å»ºä¸€ä¸ªåŒ…å«æ‚¨éŸ³é¢‘æ•°æ®é›†çš„æ•°æ®é›†å­˜å‚¨åº“ï¼š
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: AudioFolder
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AudioFolder
- en: The `AudioFolder` is a dataset builder designed to quickly load an audio dataset
    with several thousand audio files without requiring you to write any code. Any
    additional information about your dataset - such as transcription, speaker accent,
    or speaker intent - is automatically loaded by `AudioFolder` as long as you include
    this information in a metadata file (`metadata.csv`/`metadata.jsonl`).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`AudioFolder`æ˜¯ä¸€ä¸ªæ•°æ®é›†æ„å»ºå™¨ï¼Œæ—¨åœ¨å¿«é€ŸåŠ è½½åŒ…å«æ•°åƒä¸ªéŸ³é¢‘æ–‡ä»¶çš„éŸ³é¢‘æ•°æ®é›†ï¼Œè€Œæ— éœ€æ‚¨ç¼–å†™ä»»ä½•ä»£ç ã€‚åªè¦åœ¨å…ƒæ•°æ®æ–‡ä»¶ï¼ˆ`metadata.csv`/`metadata.jsonl`ï¼‰ä¸­åŒ…å«æ­¤ä¿¡æ¯ï¼Œ`AudioFolder`ä¼šè‡ªåŠ¨åŠ è½½æœ‰å…³æ•°æ®é›†çš„ä»»ä½•å…¶ä»–ä¿¡æ¯
    - å¦‚è½¬å½•ã€è¯´è¯è€…å£éŸ³æˆ–è¯´è¯è€…æ„å›¾ã€‚'
- en: ğŸ’¡ Take a look at the [Split pattern hierarchy](repository_structure#split-pattern-hierarchy)
    to learn more about how `AudioFolder` creates dataset splits based on your dataset
    repository structure.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡æŸ¥çœ‹[Split pattern hierarchy](repository_structure#split-pattern-hierarchy)ä»¥äº†è§£æœ‰å…³`AudioFolder`å¦‚ä½•æ ¹æ®æ•°æ®é›†å­˜å‚¨åº“ç»“æ„åˆ›å»ºæ•°æ®é›†æ‹†åˆ†çš„æ›´å¤šä¿¡æ¯ã€‚
- en: 'Create a dataset repository on the Hugging Face Hub and upload your dataset
    directory following the `AudioFolder` structure:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Hugging Face Hubä¸Šåˆ›å»ºä¸€ä¸ªæ•°æ®é›†å­˜å‚¨åº“ï¼Œå¹¶æŒ‰ç…§`AudioFolder`ç»“æ„ä¸Šä¼ æ‚¨çš„æ•°æ®é›†ç›®å½•ï¼š
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `data` folder can be any name you want.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`data`æ–‡ä»¶å¤¹å¯ä»¥æ˜¯ä»»ä½•æ‚¨æƒ³è¦çš„åç§°ã€‚'
- en: It can be helpful to store your metadata as a `jsonl` file if the data columns
    contain a more complex format (like a list of floats) to avoid parsing errors
    or reading complex values as strings.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ•°æ®åˆ—åŒ…å«æ›´å¤æ‚çš„æ ¼å¼ï¼ˆå¦‚æµ®ç‚¹æ•°åˆ—è¡¨ï¼‰æ—¶ï¼Œå°†å…ƒæ•°æ®å­˜å‚¨ä¸º`jsonl`æ–‡ä»¶å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼Œä»¥é¿å…è§£æé”™è¯¯æˆ–å°†å¤æ‚å€¼è¯»å–ä¸ºå­—ç¬¦ä¸²ã€‚
- en: 'The metadata file should include a `file_name` column to link an audio file
    to itâ€™s metadata:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å…ƒæ•°æ®æ–‡ä»¶åº”åŒ…æ‹¬ä¸€ä¸ª`file_name`åˆ—ï¼Œå°†éŸ³é¢‘æ–‡ä»¶ä¸å…¶å…ƒæ•°æ®é“¾æ¥èµ·æ¥ï¼š
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then you can store your dataset in a directory structure like this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ‚¨å¯ä»¥å°†æ•°æ®é›†å­˜å‚¨åœ¨è¿™æ ·çš„ç›®å½•ç»“æ„ä¸­ï¼š
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Users can now load your dataset and the associated metadata by specifying `audiofolder`
    in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    and the dataset directory in `data_dir`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·ç°åœ¨å¯ä»¥é€šè¿‡åœ¨[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)ä¸­æŒ‡å®š`audiofolder`å’Œåœ¨`data_dir`ä¸­æŒ‡å®šæ•°æ®é›†ç›®å½•æ¥åŠ è½½æ‚¨çš„æ•°æ®é›†å’Œç›¸å…³å…ƒæ•°æ®ï¼š
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can also use `audiofolder` to load datasets involving multiple splits.
    To do so, your dataset directory might have the following structure:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥ä½¿ç”¨`audiofolder`åŠ è½½æ¶‰åŠå¤šä¸ªæ‹†åˆ†çš„æ•°æ®é›†ã€‚ä¸ºæ­¤ï¼Œæ‚¨çš„æ•°æ®é›†ç›®å½•å¯èƒ½å…·æœ‰ä»¥ä¸‹ç»“æ„ï¼š
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that if audio files are located not right next to a metadata file, `file_name`
    column should be a full relative path to an audio file, not just its filename.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸æ˜¯ç´§é‚»å…ƒæ•°æ®æ–‡ä»¶ï¼Œ`file_name`åˆ—åº”è¯¥æ˜¯éŸ³é¢‘æ–‡ä»¶çš„å®Œæ•´ç›¸å¯¹è·¯å¾„ï¼Œè€Œä¸ä»…ä»…æ˜¯æ–‡ä»¶åã€‚
- en: 'For audio datasets that donâ€™t have any associated metadata, `AudioFolder` automatically
    infers the class labels of the dataset based on the directory name. It might be
    useful for audio classification tasks. Your dataset directory might look like:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ²¡æœ‰ä»»ä½•å…³è”å…ƒæ•°æ®çš„éŸ³é¢‘æ•°æ®é›†ï¼Œ`AudioFolder`ä¼šæ ¹æ®ç›®å½•åç§°è‡ªåŠ¨æ¨æ–­æ•°æ®é›†çš„ç±»æ ‡ç­¾ã€‚è¿™å¯¹äºéŸ³é¢‘åˆ†ç±»ä»»åŠ¡å¯èƒ½å¾ˆæœ‰ç”¨ã€‚æ‚¨çš„æ•°æ®é›†ç›®å½•å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Load the dataset with `AudioFolder`, and it will create a `label` column from
    the directory name (language id):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`AudioFolder`åŠ è½½æ•°æ®é›†ï¼Œå®ƒå°†ä»ç›®å½•åç§°ï¼ˆè¯­è¨€IDï¼‰åˆ›å»ºä¸€ä¸ª`label`åˆ—ï¼š
- en: '[PRE10]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If all audio files are contained in a single directory or if they are not on
    the same level of directory structure, `label` column wonâ€™t be added automatically.
    If you need it, set `drop_labels=False` explicitly.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‰€æœ‰éŸ³é¢‘æ–‡ä»¶éƒ½åŒ…å«åœ¨ä¸€ä¸ªå•ç‹¬çš„ç›®å½•ä¸­ï¼Œæˆ–è€…å®ƒä»¬ä¸åœ¨ç›¸åŒçº§åˆ«çš„ç›®å½•ç»“æ„ä¸­ï¼Œ`label` åˆ—ä¸ä¼šè‡ªåŠ¨æ·»åŠ ã€‚å¦‚æœéœ€è¦å®ƒï¼Œè¯·æ˜¾å¼è®¾ç½® `drop_labels=False`ã€‚
- en: Some audio datasets, like those found in [Kaggle competitions](https://www.kaggle.com/competitions/kaggle-pog-series-s01e02/overview),
    have separate metadata files for each split. Provided the metadata features are
    the same for each split, `audiofolder` can be used to load all splits at once.
    If the metadata features differ across each split, you should load them with separate
    `load_dataset()` calls.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›éŸ³é¢‘æ•°æ®é›†ï¼Œæ¯”å¦‚åœ¨[Kaggle ç«èµ›](https://www.kaggle.com/competitions/kaggle-pog-series-s01e02/overview)ä¸­å‘ç°çš„é‚£äº›ï¼Œä¸ºæ¯ä¸ªæ‹†åˆ†å•ç‹¬æä¾›äº†å…ƒæ•°æ®æ–‡ä»¶ã€‚åªè¦æ¯ä¸ªæ‹†åˆ†çš„å…ƒæ•°æ®ç‰¹å¾ç›¸åŒï¼Œ`audiofolder`
    å°±å¯ä»¥ç”¨æ¥ä¸€æ¬¡åŠ è½½æ‰€æœ‰æ‹†åˆ†ã€‚å¦‚æœæ¯ä¸ªæ‹†åˆ†çš„å…ƒæ•°æ®ç‰¹å¾ä¸åŒï¼Œæ‚¨åº”è¯¥ä½¿ç”¨å•ç‹¬çš„ `load_dataset()` è°ƒç”¨æ¥åŠ è½½å®ƒä»¬ã€‚
- en: Loading script
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½è„šæœ¬
- en: 'Write a dataset loading script to manually create a dataset. It defines a datasetâ€™s
    splits and configurations, and handles downloading and generating the dataset
    examples. The script should have the same name as your dataset folder or repository:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªæ•°æ®é›†åŠ è½½è„šæœ¬æ¥æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªæ•°æ®é›†ã€‚å®ƒå®šä¹‰äº†æ•°æ®é›†çš„æ‹†åˆ†å’Œé…ç½®ï¼Œå¹¶å¤„ç†ä¸‹è½½å’Œç”Ÿæˆæ•°æ®é›†ç¤ºä¾‹ã€‚è„šæœ¬çš„åç§°åº”ä¸æ‚¨çš„æ•°æ®é›†æ–‡ä»¶å¤¹æˆ–å­˜å‚¨åº“ç›¸åŒï¼š
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `data` folder can be any name you want, it doesnâ€™t have to be `data`. This
    folder is optional, unless youâ€™re hosting your dataset on the Hub.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`data` æ–‡ä»¶å¤¹å¯ä»¥æ˜¯æ‚¨æƒ³è¦çš„ä»»ä½•åç§°ï¼Œä¸ä¸€å®šæ˜¯ `data`ã€‚é™¤éæ‚¨å°†æ•°æ®é›†æ‰˜ç®¡åœ¨ Hub ä¸Šï¼Œå¦åˆ™æ­¤æ–‡ä»¶å¤¹æ˜¯å¯é€‰çš„ã€‚'
- en: 'This directory structure allows your dataset to be loaded in one line:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç›®å½•ç»“æ„å…è®¸æ‚¨çš„æ•°æ®é›†åœ¨ä¸€è¡Œä¸­åŠ è½½ï¼š
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This guide will show you how to create a dataset loading script for audio datasets,
    which is a bit different from [creating a loading script for text datasets](./dataset_script).
    Audio datasets are commonly stored in `tar.gz` archives which requires a particular
    approach to support streaming mode. While streaming is not required, we highly
    encourage implementing streaming support in your audio dataset because users without
    a lot of disk space can use your dataset without downloading it. Learn more about
    streaming in the [Stream](./stream) guide!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä¸ºéŸ³é¢‘æ•°æ®é›†åˆ›å»ºä¸€ä¸ªæ•°æ®é›†åŠ è½½è„šæœ¬ï¼Œè¿™ä¸[ä¸ºæ–‡æœ¬æ•°æ®é›†åˆ›å»ºåŠ è½½è„šæœ¬](./dataset_script)æœ‰äº›ä¸åŒã€‚éŸ³é¢‘æ•°æ®é›†é€šå¸¸å­˜å‚¨åœ¨
    `tar.gz` å­˜æ¡£ä¸­ï¼Œè¿™éœ€è¦ä¸€ç§ç‰¹æ®Šçš„æ–¹æ³•æ¥æ”¯æŒæµå¼æ¨¡å¼ã€‚è™½ç„¶æµå¼ä¼ è¾“ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®åœ¨æ‚¨çš„éŸ³é¢‘æ•°æ®é›†ä¸­å®ç°æµå¼æ”¯æŒï¼Œå› ä¸ºæ²¡æœ‰å¤ªå¤šç£ç›˜ç©ºé—´çš„ç”¨æˆ·å¯ä»¥åœ¨ä¸ä¸‹è½½æ•°æ®é›†çš„æƒ…å†µä¸‹ä½¿ç”¨æ‚¨çš„æ•°æ®é›†ã€‚åœ¨[Stream](./stream)æŒ‡å—ä¸­äº†è§£æ›´å¤šå…³äºæµå¼ä¼ è¾“çš„ä¿¡æ¯ï¼
- en: 'Here is an example using TAR archives:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªä½¿ç”¨ TAR å­˜æ¡£çš„ç¤ºä¾‹ï¼š
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In addition to learning how to create a streamable dataset, youâ€™ll also learn
    how to:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†å­¦ä¹ å¦‚ä½•åˆ›å»ºä¸€ä¸ªå¯æµå¼ä¼ è¾“çš„æ•°æ®é›†ï¼Œæ‚¨è¿˜å°†å­¦ä¹ å¦‚ä½•ï¼š
- en: Create a dataset builder class.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ•°æ®é›†æ„å»ºå™¨ç±»ã€‚
- en: Create dataset configurations.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºæ•°æ®é›†é…ç½®ã€‚
- en: Add dataset metadata.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ æ•°æ®é›†å…ƒæ•°æ®ã€‚
- en: Download and define the dataset splits.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å®šä¹‰æ•°æ®é›†æ‹†åˆ†ã€‚
- en: Generate the dataset.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæ•°æ®é›†ã€‚
- en: Upload the dataset to the Hub.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†ä¸Šä¼ åˆ° Hubã€‚
- en: The best way to learn is to open up an existing audio dataset loading script,
    like [Vivos](https://huggingface.co/datasets/vivos/blob/main/vivos.py), and follow
    along!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ çš„æœ€ä½³æ–¹æ³•æ˜¯æ‰“å¼€ä¸€ä¸ªç°æœ‰çš„éŸ³é¢‘æ•°æ®é›†åŠ è½½è„šæœ¬ï¼Œæ¯”å¦‚[Vivos](https://huggingface.co/datasets/vivos/blob/main/vivos.py)ï¼Œå¹¶è·Ÿç€åšï¼
- en: This guide shows how to process audio data stored in TAR archives - the most
    frequent case for audio datasets. Check out [minds14](https://huggingface.co/datasets/PolyAI/minds14/blob/main/minds14.py)
    dataset for an example of an audio script which uses ZIP archives.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å±•ç¤ºäº†å¦‚ä½•å¤„ç†å­˜å‚¨åœ¨ TAR å­˜æ¡£ä¸­çš„éŸ³é¢‘æ•°æ® - è¿™æ˜¯éŸ³é¢‘æ•°æ®é›†çš„æœ€å¸¸è§æƒ…å†µã€‚æŸ¥çœ‹[minds14](https://huggingface.co/datasets/PolyAI/minds14/blob/main/minds14.py)
    æ•°æ®é›†ï¼Œäº†è§£ä¸€ä¸ªä½¿ç”¨ ZIP å­˜æ¡£çš„éŸ³é¢‘è„šæœ¬ç¤ºä¾‹ã€‚
- en: To help you get started, we created a loading script [template](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)
    you can copy and use as a starting point!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¸®åŠ©æ‚¨å…¥é—¨ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŠ è½½è„šæœ¬[æ¨¡æ¿](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)ï¼Œæ‚¨å¯ä»¥å¤åˆ¶å¹¶ç”¨ä½œèµ·ç‚¹ï¼
- en: Create a dataset builder class
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ•°æ®é›†æ„å»ºå™¨ç±»
- en: '[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    is the base class for datasets generated from a dictionary generator. Within this
    class, there are three methods to help create your dataset:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    æ˜¯ä»å­—å…¸ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®é›†çš„åŸºç±»ã€‚åœ¨è¿™ä¸ªç±»ä¸­ï¼Œæœ‰ä¸‰ç§æ–¹æ³•å¯ä»¥å¸®åŠ©æ‚¨åˆ›å»ºæ•°æ®é›†ï¼š'
- en: '`_info` stores information about your dataset like its description, license,
    and features.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_info` å­˜å‚¨æœ‰å…³æ•°æ®é›†çš„ä¿¡æ¯ï¼Œå¦‚æè¿°ã€è®¸å¯è¯å’Œç‰¹å¾ã€‚'
- en: '`_split_generators` downloads the dataset and defines its splits.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_split_generators` ä¸‹è½½æ•°æ®é›†å¹¶å®šä¹‰å…¶æ‹†åˆ†ã€‚'
- en: '`_generate_examples` generates the datasetâ€™s samples containing the audio data
    and other features specified in `info` for each split.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_generate_examples` ä¸ºæ¯ä¸ªæ‹†åˆ†ç”ŸæˆåŒ…å«éŸ³é¢‘æ•°æ®å’Œ `info` ä¸­æŒ‡å®šçš„å…¶ä»–ç‰¹å¾çš„æ•°æ®é›†æ ·æœ¬ã€‚'
- en: 'Start by creating your dataset class as a subclass of [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    and add the three methods. Donâ€™t worry about filling in each of these methods
    yet, youâ€™ll develop those over the next few sections:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆåˆ›å»ºæ‚¨çš„æ•°æ®é›†ç±»ï¼Œä½œä¸º [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    çš„å­ç±»ï¼Œå¹¶æ·»åŠ è¿™ä¸‰ç§æ–¹æ³•ã€‚æš‚æ—¶ä¸ç”¨æ‹…å¿ƒå¡«å†™è¿™äº›æ–¹æ³•ä¸­çš„æ¯ä¸€ä¸ªï¼Œæ‚¨å°†åœ¨æ¥ä¸‹æ¥çš„å‡ ä¸ªéƒ¨åˆ†ä¸­å¼€å‘å®ƒä»¬ï¼š
- en: '[PRE14]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Multiple configurations
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¤šä¸ªé…ç½®
- en: In some cases, a dataset may have more than one configuration. For example,
    [LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia)
    dataset has several configurations corresponding to different languages.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¸€ä¸ªæ•°æ®é›†å¯èƒ½æœ‰å¤šä¸ªé…ç½®ã€‚ä¾‹å¦‚ï¼Œ[LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia)
    æ•°æ®é›†æœ‰å‡ ä¸ªå¯¹åº”ä¸åŒè¯­è¨€çš„é…ç½®ã€‚
- en: To create different configurations, use the [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class to create a subclass of your dataset. The only required parameter is the
    `name` of the configuration, which must be passed to the configurationâ€™s superclass
    `__init__()`. Otherwise, you can specify any custom parameters you want in your
    configuration class.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åˆ›å»ºä¸åŒçš„é…ç½®ï¼Œä½¿ç”¨ [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ç±»æ¥åˆ›å»ºæ•°æ®é›†çš„å­ç±»ã€‚å”¯ä¸€éœ€è¦çš„å‚æ•°æ˜¯é…ç½®çš„ `name`ï¼Œå¿…é¡»ä¼ é€’ç»™é…ç½®çš„è¶…ç±» `__init__()`ã€‚å¦åˆ™ï¼Œæ‚¨å¯ä»¥åœ¨é…ç½®ç±»ä¸­æŒ‡å®šä»»ä½•è‡ªå®šä¹‰å‚æ•°ã€‚
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Define your configurations in the `BUILDER_CONFIGS` class variable inside [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder).
    In this example, the author imports the languages from a separate `release_stats.py`
    [file](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/release_stats.py)
    from their repository, and then loops through each language to create a configuration:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    å†…éƒ¨çš„ `BUILDER_CONFIGS` ç±»å˜é‡ä¸­å®šä¹‰æ‚¨çš„é…ç½®ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œä½œè€…ä»ä¸€ä¸ªå•ç‹¬çš„ `release_stats.py` [æ–‡ä»¶](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/release_stats.py)
    ä¸­å¯¼å…¥è¯­è¨€ï¼Œç„¶åå¾ªç¯éå†æ¯ç§è¯­è¨€ä»¥åˆ›å»ºä¸€ä¸ªé…ç½®ï¼š
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Typically, users need to specify a configuration to load in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    otherwise a `ValueError` is raised. You can avoid this by setting a default dataset
    configuration to load in `DEFAULT_CONFIG_NAME`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç”¨æˆ·éœ€è¦æŒ‡å®šä¸€ä¸ªé…ç½®æ¥åŠ è½½ [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)ï¼Œå¦åˆ™ä¼šå¼•å‘
    `ValueError`ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½®é»˜è®¤æ•°æ®é›†é…ç½®æ¥é¿å…è¿™ç§æƒ…å†µï¼Œä»¥åœ¨ `DEFAULT_CONFIG_NAME` ä¸­åŠ è½½ã€‚
- en: 'Now if users want to load the Balinese (`bal`) configuration, they can use
    the configuration name:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¦‚æœç”¨æˆ·æƒ³è¦åŠ è½½ Balinese (`bal`) é…ç½®ï¼Œä»–ä»¬å¯ä»¥ä½¿ç”¨é…ç½®åç§°ï¼š
- en: '[PRE17]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Add dataset metadata
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ·»åŠ æ•°æ®é›†å…ƒæ•°æ®
- en: 'Adding information about your dataset helps users to learn more about it. This
    information is stored in the [DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo)
    class which is returned by the `info` method. Users can access this information
    by:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ·»åŠ å…³äºæ‚¨çš„æ•°æ®é›†çš„ä¿¡æ¯å¯ä»¥å¸®åŠ©ç”¨æˆ·äº†è§£æ›´å¤šã€‚è¿™äº›ä¿¡æ¯å­˜å‚¨åœ¨ [DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo)
    ç±»ä¸­ï¼Œè¯¥ç±»ç”± `info` æ–¹æ³•è¿”å›ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®è¿™äº›ä¿¡æ¯ï¼š
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'There is a lot of information you can include about your dataset, but some
    important ones are:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åŒ…å«å¾ˆå¤šå…³äºæ•°æ®é›†çš„ä¿¡æ¯ï¼Œä½†ä¸€äº›é‡è¦çš„ä¿¡æ¯åŒ…æ‹¬ï¼š
- en: '`description` provides a concise description of the dataset.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`description` æä¾›æ•°æ®é›†çš„ç®€æ˜æè¿°ã€‚'
- en: '`features` specify the dataset column types. Since youâ€™re creating an audio
    loading script, youâ€™ll need to include the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature and the `sampling_rate` of the dataset.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`features` æŒ‡å®šæ•°æ®é›†åˆ—ç±»å‹ã€‚ç”±äºæ‚¨æ­£åœ¨åˆ›å»ºä¸€ä¸ªéŸ³é¢‘åŠ è½½è„šæœ¬ï¼Œæ‚¨éœ€è¦åŒ…æ‹¬ [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    ç‰¹å¾å’Œæ•°æ®é›†çš„ `sampling_rate`ã€‚'
- en: '`homepage` provides a link to the dataset homepage.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`homepage` æä¾›æ•°æ®é›†ä¸»é¡µçš„é“¾æ¥ã€‚'
- en: '`license` specify the permissions for using a dataset as defined by the license
    type.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`license` æŒ‡å®šä½¿ç”¨æ•°æ®é›†çš„æƒé™ï¼Œç”±è®¸å¯è¯ç±»å‹å®šä¹‰ã€‚'
- en: '`citation` is a BibTeX citation of the dataset.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`citation` æ˜¯æ•°æ®é›†çš„ BibTeX å¼•ç”¨ã€‚'
- en: Youâ€™ll notice a lot of the dataset information is defined earlier in the loading
    script which can make it easier to read. There are also other `~Dataset.Features`
    you can input, so be sure to check out the full list and [features guide](./about_dataset_features)
    for more details.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨ä¼šæ³¨æ„åˆ°å¾ˆå¤šæ•°æ®é›†ä¿¡æ¯åœ¨åŠ è½½è„šæœ¬ä¸­æ—©å·²å®šä¹‰ï¼Œè¿™å¯ä»¥ä½¿é˜…è¯»æ›´åŠ å®¹æ˜“ã€‚è¿˜æœ‰å…¶ä»– `~Dataset.Features` æ‚¨å¯ä»¥è¾“å…¥ï¼Œæ‰€ä»¥ä¸€å®šè¦æŸ¥çœ‹å®Œæ•´åˆ—è¡¨å’Œ
    [features guide](./about_dataset_features) ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Download and define the dataset splits
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å®šä¹‰æ•°æ®é›†æ‹†åˆ†
- en: Now that youâ€™ve added some information about your dataset, the next step is
    to download the dataset and define the splits.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»æ·»åŠ äº†ä¸€äº›å…³äºæ•°æ®é›†çš„ä¿¡æ¯ï¼Œä¸‹ä¸€æ­¥æ˜¯ä¸‹è½½æ•°æ®é›†å¹¶å®šä¹‰æ‹†åˆ†ã€‚
- en: 'Use the [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    method to download metadata file at `_PROMPTS_URLS` and audio TAR archive at `_DATA_URL`.
    This method returns the path to the local file/archive. In streaming mode, it
    doesnâ€™t download the file(s) and just returns a URL to stream the data from. This
    method accepts:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    æ–¹æ³•ä¸‹è½½ `_PROMPTS_URLS` ä¸­çš„å…ƒæ•°æ®æ–‡ä»¶å’Œ `_DATA_URL` ä¸­çš„éŸ³é¢‘ TAR å­˜æ¡£ã€‚æ­¤æ–¹æ³•è¿”å›æœ¬åœ°æ–‡ä»¶/å­˜æ¡£çš„è·¯å¾„ã€‚åœ¨æµå¼æ¨¡å¼ä¸‹ï¼Œå®ƒä¸ä¼šä¸‹è½½æ–‡ä»¶ï¼Œåªä¼šè¿”å›ä¸€ä¸ªä»ä¸­æµå¼ä¼ è¾“æ•°æ®çš„
    URLã€‚æ­¤æ–¹æ³•æ¥å—ï¼š
- en: a relative path to a file inside a Hub dataset repository (for example, in the
    `data/` folder)
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hub æ•°æ®é›†å­˜å‚¨åº“ä¸­æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ï¼ˆä¾‹å¦‚ï¼Œåœ¨ `data/` æ–‡ä»¶å¤¹ä¸­ï¼‰
- en: a URL to a file hosted somewhere else
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‡å‘å…¶ä»–åœ°æ–¹æ‰˜ç®¡çš„æ–‡ä»¶çš„ URL
- en: a (nested) list or dictionary of file names or URLs
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªï¼ˆåµŒå¥—çš„ï¼‰æ–‡ä»¶åæˆ– URL çš„åˆ—è¡¨æˆ–å­—å…¸
- en: 'After youâ€™ve downloaded the dataset, use the [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    to organize the audio files and sentence prompts in each split. Name each split
    with a standard name like: `Split.TRAIN`, `Split.TEST`, and `SPLIT.Validation`.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹è½½æ•°æ®é›†åï¼Œä½¿ç”¨ [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    æ¥ç»„ç»‡æ¯ä¸ªæ‹†åˆ†ä¸­çš„éŸ³é¢‘æ–‡ä»¶å’Œå¥å­æç¤ºã€‚ä¸ºæ¯ä¸ªæ‹†åˆ†å‘½åä¸€ä¸ªæ ‡å‡†åç§°ï¼Œå¦‚ï¼š`Split.TRAIN`ã€`Split.TEST` å’Œ `SPLIT.Validation`ã€‚
- en: In the `gen_kwargs` parameter, specify the file path to the `prompts_path` and
    `path_to_clips`. For `audio_files`, youâ€™ll need to use [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    to iterate over the audio files in the TAR archive. This enables streaming for
    your dataset. All of these file paths are passed onto the next step where youâ€™ll
    actually generate the dataset.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨ `gen_kwargs` å‚æ•°ä¸­ï¼ŒæŒ‡å®š `prompts_path` å’Œ `path_to_clips` çš„æ–‡ä»¶è·¯å¾„ã€‚å¯¹äº `audio_files`ï¼Œæ‚¨éœ€è¦ä½¿ç”¨
    [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    æ¥è¿­ä»£ TAR å­˜æ¡£ä¸­çš„éŸ³é¢‘æ–‡ä»¶ã€‚è¿™ä½¿å¾—æ‚¨çš„æ•°æ®é›†å¯ä»¥è¿›è¡Œæµå¼ä¼ è¾“ã€‚æ‰€æœ‰è¿™äº›æ–‡ä»¶è·¯å¾„éƒ½ä¼ é€’åˆ°ä¸‹ä¸€æ­¥ï¼Œæ‚¨å°†åœ¨é‚£é‡Œå®é™…ç”Ÿæˆæ•°æ®é›†ã€‚
- en: '[PRE20]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This implementation does not extract downloaded archives. If you want to extract
    files after download, you need to additionally use [extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract),
    see the [(Advanced) Extract TAR archives](#advanced-extract-tar-archives-locally)
    section.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å®ç°ä¸ä¼šæå–å·²ä¸‹è½½çš„å­˜æ¡£ã€‚å¦‚æœæ‚¨æƒ³è¦åœ¨ä¸‹è½½åæå–æ–‡ä»¶ï¼Œæ‚¨éœ€è¦é¢å¤–ä½¿ç”¨[extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)ï¼Œè¯·å‚é˜…[(é«˜çº§)
    æœ¬åœ°æå– TAR å­˜æ¡£](#advanced-extract-tar-archives-locally)éƒ¨åˆ†ã€‚
- en: Generate the dataset
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæ•°æ®é›†
- en: The last method in the [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    class actually generates the samples in the dataset. It yields a dataset according
    to the structure specified in `features` from the `info` method. As you can see,
    `generate_examples` accepts the `prompts_path`, `path_to_clips`, and `audio_files`
    from the previous method as arguments.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)
    ç±»ä¸­çš„æœ€åä¸€ä¸ªæ–¹æ³•å®é™…ä¸Šç”Ÿæˆæ•°æ®é›†ä¸­çš„æ ·æœ¬ã€‚å®ƒæ ¹æ®`info`æ–¹æ³•ä¸­æŒ‡å®šçš„`features`ç»“æ„ç”Ÿæˆæ•°æ®é›†ã€‚å¦‚æ‚¨æ‰€è§ï¼Œ`generate_examples`æ¥å—æ¥è‡ªå‰ä¸€æ–¹æ³•çš„`prompts_path`ã€`path_to_clips`å’Œ`audio_files`ä½œä¸ºå‚æ•°ã€‚'
- en: Files inside TAR archives are accessed and yielded sequentially. This means
    you need to have the metadata associated with the audio files in the TAR file
    in hand first so you can yield it with its corresponding audio file.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: TAR å­˜æ¡£ä¸­çš„æ–‡ä»¶æŒ‰é¡ºåºè®¿é—®å’Œç”Ÿæˆã€‚è¿™æ„å‘³ç€æ‚¨éœ€è¦é¦–å…ˆå‡†å¤‡å¥½ä¸ TAR æ–‡ä»¶ä¸­éŸ³é¢‘æ–‡ä»¶ç›¸å…³çš„å…ƒæ•°æ®ï¼Œä»¥ä¾¿èƒ½å¤Ÿå°†å…¶ä¸ç›¸åº”çš„éŸ³é¢‘æ–‡ä»¶ä¸€èµ·ç”Ÿæˆã€‚
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Finally, iterate over files in `audio_files` and yield them along with their
    corresponding metadata. [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    yields a tuple of (`path`, `f`) where `path` is a **relative** path to a file
    inside TAR archive and `f` is a file object itself.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œåœ¨`audio_files`ä¸­è¿­ä»£æ–‡ä»¶å¹¶ä¸å…¶å¯¹åº”çš„å…ƒæ•°æ®ä¸€èµ·ç”Ÿæˆã€‚[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    ç”Ÿæˆä¸€ä¸ªå…ƒç»„(`path`, `f`)ï¼Œå…¶ä¸­`path`æ˜¯ TAR å­˜æ¡£ä¸­æ–‡ä»¶çš„**ç›¸å¯¹**è·¯å¾„ï¼Œ`f`æ˜¯æ–‡ä»¶å¯¹è±¡æœ¬èº«ã€‚
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Put these two steps together, and the whole `_generate_examples` method looks
    like:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™ä¸¤ä¸ªæ­¥éª¤ç»“åˆèµ·æ¥ï¼Œæ•´ä¸ª`_generate_examples`æ–¹æ³•çœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Upload the dataset to the Hub
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†ä¸Šä¼ åˆ°Hub
- en: Once your script is ready, [create a dataset card](./dataset_card) and [upload
    it to the Hub](./share).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨çš„è„šæœ¬å‡†å¤‡å¥½äº†ï¼Œ[åˆ›å»ºä¸€ä¸ªæ•°æ®é›†å¡ç‰‡](./dataset_card)å¹¶[ä¸Šä¼ åˆ°Hub](./share)ã€‚
- en: Congratulations, you can now load your dataset from the Hub! ğŸ¥³
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œï¼Œæ‚¨ç°åœ¨å¯ä»¥ä»HubåŠ è½½æ‚¨çš„æ•°æ®é›†äº†ï¼ğŸ¥³
- en: '[PRE24]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: (Advanced) Extract TAR archives locally
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ï¼ˆé«˜çº§ï¼‰æœ¬åœ°æå– TAR å­˜æ¡£
- en: In the example above downloaded archives are not extracted and therefore examples
    do not contain information about where they are stored locally. To explain how
    to do the extraction in a way that it also supports streaming, we will briefly
    go through the [LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/librivox-indonesia.py)
    loading script.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œä¸‹è½½çš„å­˜æ¡£æ²¡æœ‰è¢«æå–ï¼Œå› æ­¤ç¤ºä¾‹ä¸åŒ…å«æœ‰å…³å®ƒä»¬åœ¨æœ¬åœ°å­˜å‚¨ä½ç½®çš„ä¿¡æ¯ã€‚ä¸ºäº†è§£é‡Šå¦‚ä½•ä»¥æ”¯æŒæµå¼ä¼ è¾“çš„æ–¹å¼è¿›è¡Œæå–ï¼Œæˆ‘ä»¬å°†ç®€è¦ä»‹ç»[LibriVox
    Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/librivox-indonesia.py)åŠ è½½è„šæœ¬ã€‚
- en: Download and define the dataset splits
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶å®šä¹‰æ•°æ®é›†æ‹†åˆ†
- en: Use the [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    method to download the audio data at `_AUDIO_URL`.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)æ–¹æ³•ä¸‹è½½ä½äº`_AUDIO_URL`çš„éŸ³é¢‘æ•°æ®ã€‚
- en: 'To extract audio TAR archive locally, use the [extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract).
    You can use this method only in non-streaming mode (when `dl_manager.is_streaming=False`).
    This returns a local path to the extracted archive directory:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦åœ¨æœ¬åœ°æå–éŸ³é¢‘ TAR å­˜æ¡£ï¼Œè¯·ä½¿ç”¨[extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)ã€‚æ‚¨åªèƒ½åœ¨éæµå¼æ¨¡å¼ä¸‹ä½¿ç”¨æ­¤æ–¹æ³•ï¼ˆå½“`dl_manager.is_streaming=False`æ—¶ï¼‰ã€‚è¿™å°†è¿”å›æå–çš„å­˜æ¡£ç›®å½•çš„æœ¬åœ°è·¯å¾„ï¼š
- en: '[PRE25]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Use the [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    method to iterate over the archive at `audio_path`, just like in the Vivos example
    above. [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    doesnâ€™t provide any information about the full paths of files from the archive,
    even if it has been extracted. As a result, you need to pass the `local_extracted_archive`
    path to the next step in `gen_kwargs`, in order to preserve information about
    where the archive was extracted to. This is required to construct the correct
    paths to the local files when you generate the examples.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)æ–¹æ³•è¿­ä»£ä½äº`audio_path`çš„å­˜æ¡£ï¼Œå°±åƒä¸Šé¢çš„
    Vivos ç¤ºä¾‹ä¸€æ ·ã€‚[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)ä¸æä¾›æœ‰å…³å­˜æ¡£ä¸­æ–‡ä»¶çš„å®Œæ•´è·¯å¾„çš„ä¿¡æ¯ï¼Œå³ä½¿å·²ç»æå–ã€‚å› æ­¤ï¼Œæ‚¨éœ€è¦åœ¨`gen_kwargs`ä¸­å°†`local_extracted_archive`è·¯å¾„ä¼ é€’ç»™ä¸‹ä¸€æ­¥ï¼Œä»¥ä¿ç•™æœ‰å…³å­˜æ¡£æå–ä½ç½®çš„ä¿¡æ¯ã€‚è¿™æ˜¯åœ¨ç”Ÿæˆç¤ºä¾‹æ—¶æ„å»ºæ­£ç¡®çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„æ‰€å¿…éœ€çš„ã€‚
- en: The reason you need to use a combination of [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)
    and [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    is because files in TAR archives canâ€™t be accessed directly by their paths. Instead,
    youâ€™ll need to iterate over the files within the archive! You can use [download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    and [extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)
    with TAR archives only in non-streaming mode, otherwise it would throw an error.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨éœ€è¦åŒæ—¶ä½¿ç”¨[download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)å’Œ[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)çš„ç»„åˆï¼Œå› ä¸ºæ— æ³•ç›´æ¥é€šè¿‡è·¯å¾„è®¿é—®TARå­˜æ¡£ä¸­çš„æ–‡ä»¶ã€‚ç›¸åï¼Œæ‚¨éœ€è¦è¿­ä»£å­˜æ¡£ä¸­çš„æ–‡ä»¶ï¼æ‚¨å¯ä»¥ä½¿ç”¨[download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)å’Œ[extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)æ¥å¤„ç†TARå­˜æ¡£ï¼Œä½†åªèƒ½åœ¨éæµæ¨¡å¼ä¸‹è¿›è¡Œï¼Œå¦åˆ™ä¼šå‡ºé”™ã€‚
- en: Use the [download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    method to download the metadata file specified in `_METADATA_URL`. This method
    returns a path to a local file in non-streaming mode. In streaming mode, it doesnâ€™t
    download file locally and returns the same URL.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)æ–¹æ³•ä¸‹è½½åœ¨`_METADATA_URL`ä¸­æŒ‡å®šçš„å…ƒæ•°æ®æ–‡ä»¶ã€‚è¯¥æ–¹æ³•ä»¥éæµæ¨¡å¼è¿”å›æœ¬åœ°æ–‡ä»¶çš„è·¯å¾„ã€‚åœ¨æµæ¨¡å¼ä¸‹ï¼Œå®ƒä¸ä¼šåœ¨æœ¬åœ°ä¸‹è½½æ–‡ä»¶ï¼Œè€Œæ˜¯è¿”å›ç›¸åŒçš„URLã€‚
- en: 'Now use the [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    to organize the audio files and metadata in each split. Name each split with a
    standard name like: `Split.TRAIN`, `Split.TEST`, and `SPLIT.Validation`.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½¿ç”¨[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)æ¥ç»„ç»‡æ¯ä¸ªæ‹†åˆ†ä¸­çš„éŸ³é¢‘æ–‡ä»¶å’Œå…ƒæ•°æ®ã€‚ä¸ºæ¯ä¸ªæ‹†åˆ†å‘½åä¸€ä¸ªæ ‡å‡†åç§°ï¼Œå¦‚ï¼š`Split.TRAIN`ã€`Split.TEST`å’Œ`SPLIT.Validation`ã€‚
- en: In the `gen_kwargs` parameter, specify the file paths to `local_extracted_archive`,
    `audio_files`, `metadata_path`, and `path_to_clips`. Remember, for `audio_files`,
    you need to use [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)
    to iterate over the audio files in the TAR archives. This enables streaming for
    your dataset! All of these file paths are passed onto the next step where the
    dataset samples are generated.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨`gen_kwargs`å‚æ•°ä¸­ï¼ŒæŒ‡å®š`local_extracted_archive`ã€`audio_files`ã€`metadata_path`å’Œ`path_to_clips`çš„æ–‡ä»¶è·¯å¾„ã€‚è¯·è®°ä½ï¼Œå¯¹äº`audio_files`ï¼Œæ‚¨éœ€è¦ä½¿ç”¨[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)æ¥è¿­ä»£TARå­˜æ¡£ä¸­çš„éŸ³é¢‘æ–‡ä»¶ã€‚è¿™å°†ä¸ºæ‚¨çš„æ•°æ®é›†å¯ç”¨æµå¼å¤„ç†ï¼æ‰€æœ‰è¿™äº›æ–‡ä»¶è·¯å¾„éƒ½ä¼ é€’åˆ°ä¸‹ä¸€æ­¥ï¼Œç”Ÿæˆæ•°æ®é›†æ ·æœ¬ã€‚
- en: '[PRE26]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Generate the dataset
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæ•°æ®é›†
- en: Here `_generate_examples` accepts `local_extracted_archive`, `audio_files`,
    `metadata_path`, and `path_to_clips` from the previous method as arguments.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ`_generate_examples`æ¥å—æ¥è‡ªå…ˆå‰æ–¹æ³•çš„`local_extracted_archive`ã€`audio_files`ã€`metadata_path`å’Œ`path_to_clips`ä½œä¸ºå‚æ•°ã€‚
- en: 'TAR files are accessed and yielded sequentially. This means you need to have
    the metadata in `metadata_path` associated with the audio files in the TAR file
    in hand first so that you can yield it with its corresponding audio file further:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TARæ–‡ä»¶æŒ‰é¡ºåºè®¿é—®å’Œäº§ç”Ÿã€‚è¿™æ„å‘³ç€æ‚¨éœ€è¦é¦–å…ˆå°†`metadata_path`ä¸­çš„å…ƒæ•°æ®ä¸TARæ–‡ä»¶ä¸­çš„éŸ³é¢‘æ–‡ä»¶å…³è”èµ·æ¥ï¼Œä»¥ä¾¿éšåå¯ä»¥å°†å…¶ä¸ç›¸åº”çš„éŸ³é¢‘æ–‡ä»¶ä¸€èµ·äº§ç”Ÿã€‚
- en: '[PRE27]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now you can yield the files in `audio_files` archive. When you use [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive),
    it yielded a tuple of (`path`, `f`) where `path` is a **relative path** to a file
    inside the archive, and `f` is the file object itself. To get the **full path**
    to the locally extracted file, join the path of the directory (`local_extracted_path`)
    where the archive is extracted to and the relative audio file path (`path`):'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å¯ä»¥åœ¨`audio_files`å­˜æ¡£ä¸­è·å–æ–‡ä»¶ã€‚å½“æ‚¨ä½¿ç”¨[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)æ—¶ï¼Œå®ƒä¼šäº§ç”Ÿä¸€ä¸ªå…ƒç»„(`path`,
    `f`)ï¼Œå…¶ä¸­`path`æ˜¯å­˜æ¡£ä¸­æ–‡ä»¶çš„**ç›¸å¯¹è·¯å¾„**ï¼Œ`f`æ˜¯æ–‡ä»¶å¯¹è±¡æœ¬èº«ã€‚è¦è·å–æœ¬åœ°æå–æ–‡ä»¶çš„**å®Œæ•´è·¯å¾„**ï¼Œè¯·å°†å­˜æ¡£æå–åˆ°çš„ç›®å½•(`local_extracted_path`)çš„è·¯å¾„ä¸ç›¸å¯¹éŸ³é¢‘æ–‡ä»¶è·¯å¾„(`path`)è¿æ¥èµ·æ¥ï¼š
- en: '[PRE28]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Put both of these steps together, and the whole `_generate_examples` method
    should look like:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™ä¸¤ä¸ªæ­¥éª¤ç»“åˆèµ·æ¥ï¼Œæ•´ä¸ª`_generate_examples`æ–¹æ³•åº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
