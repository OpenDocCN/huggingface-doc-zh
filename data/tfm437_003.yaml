- en: Quick tour
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¿«é€Ÿå¯¼è§ˆ
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/quicktour](https://huggingface.co/docs/transformers/v4.37.2/en/quicktour)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/quicktour](https://huggingface.co/docs/transformers/v4.37.2/en/quicktour)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Get up and running with ğŸ¤— Transformers! Whether youâ€™re a developer or an everyday
    user, this quick tour will help you get started and show you how to use the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for inference, load a pretrained model and preprocessor with an [AutoClass](./model_doc/auto),
    and quickly train a model with PyTorch or TensorFlow. If youâ€™re a beginner, we
    recommend checking out our tutorials or [course](https://huggingface.co/course/chapter1/1)
    next for more in-depth explanations of the concepts introduced here.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¿«é€Ÿä¸Šæ‰‹ ğŸ¤— Transformersï¼æ— è®ºæ‚¨æ˜¯å¼€å‘äººå‘˜è¿˜æ˜¯æ—¥å¸¸ç”¨æˆ·ï¼Œè¿™ä¸ªå¿«é€Ÿå¯¼è§ˆå°†å¸®åŠ©æ‚¨å…¥é—¨ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)è¿›è¡Œæ¨ç†ï¼ŒåŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹å’Œé¢„å¤„ç†å™¨ä¸[AutoClass](./model_doc/auto)ï¼Œå¹¶å¿«é€Ÿä½¿ç”¨PyTorchæˆ–TensorFlowè®­ç»ƒæ¨¡å‹ã€‚å¦‚æœæ‚¨æ˜¯åˆå­¦è€…ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹æˆ‘ä»¬çš„æ•™ç¨‹æˆ–[è¯¾ç¨‹](https://huggingface.co/course/chapter1/1)ä»¥è·å–æ›´æ·±å…¥çš„è§£é‡Šã€‚
- en: 'Before you begin, make sure you have all the necessary libraries installed:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Youâ€™ll also need to install your preferred machine learning framework:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜éœ€è¦å®‰è£…æ‚¨å–œæ¬¢çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼š
- en: PytorchHide Pytorch content
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè—Pytorchå†…å®¹
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: TensorFlowHide TensorFlow content
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè—TensorFlowå†…å®¹
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Pipeline
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç®¡é“
- en: '[https://www.youtube-nocookie.com/embed/tiZFewofSLM](https://www.youtube-nocookie.com/embed/tiZFewofSLM)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube-nocookie.com/embed/tiZFewofSLM](https://www.youtube-nocookie.com/embed/tiZFewofSLM)'
- en: 'The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    is the easiest and fastest way to use a pretrained model for inference. You can
    use the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    out-of-the-box for many tasks across different modalities, some of which are shown
    in the table below:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)æ˜¯ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•å’Œæœ€å¿«é€Ÿçš„æ–¹æ³•ã€‚æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)æ¥å¤„ç†è®¸å¤šä¸åŒæ¨¡æ€çš„ä»»åŠ¡ï¼Œå…¶ä¸­ä¸€äº›æ˜¾ç¤ºåœ¨ä¸‹è¡¨ä¸­ï¼š'
- en: For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·æŸ¥çœ‹[pipeline APIå‚è€ƒ](./main_classes/pipelines)ã€‚
- en: '| **Task** | **Description** | **Modality** | **Pipeline identifier** |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| **ä»»åŠ¡** | **æè¿°** | **æ¨¡æ€** | **ç®¡é“æ ‡è¯†ç¬¦** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Text classification | assign a label to a given sequence of text | NLP |
    pipeline(task=â€œsentiment-analysisâ€) |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| æ–‡æœ¬åˆ†ç±» | ä¸ºç»™å®šçš„æ–‡æœ¬åºåˆ—åˆ†é…ä¸€ä¸ªæ ‡ç­¾ | NLP | pipeline(task=â€œsentiment-analysisâ€) |'
- en: '| Text generation | generate text given a prompt | NLP | pipeline(task=â€œtext-generationâ€)
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| æ–‡æœ¬ç”Ÿæˆ | æ ¹æ®æç¤ºç”Ÿæˆæ–‡æœ¬ | NLP | pipeline(task=â€œtext-generationâ€) |'
- en: '| Summarization | generate a summary of a sequence of text or document | NLP
    | pipeline(task=â€œsummarizationâ€) |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| æ‘˜è¦ | ç”Ÿæˆæ–‡æœ¬æˆ–æ–‡æ¡£åºåˆ—çš„æ‘˜è¦ | NLP | pipeline(task=â€œsummarizationâ€) |'
- en: '| Image classification | assign a label to an image | Computer vision | pipeline(task=â€œimage-classificationâ€)
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| å›¾åƒåˆ†ç±» | ä¸ºå›¾åƒåˆ†é…ä¸€ä¸ªæ ‡ç­¾ | è®¡ç®—æœºè§†è§‰ | pipeline(task=â€œimage-classificationâ€) |'
- en: '| Image segmentation | assign a label to each individual pixel of an image
    (supports semantic, panoptic, and instance segmentation) | Computer vision | pipeline(task=â€œimage-segmentationâ€)
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| å›¾åƒåˆ†å‰² | ä¸ºå›¾åƒçš„æ¯ä¸ªåƒç´ åˆ†é…ä¸€ä¸ªæ ‡ç­¾ï¼ˆæ”¯æŒè¯­ä¹‰ã€å…¨æ™¯å’Œå®ä¾‹åˆ†å‰²ï¼‰ | è®¡ç®—æœºè§†è§‰ | pipeline(task=â€œimage-segmentationâ€)
    |'
- en: '| Object detection | predict the bounding boxes and classes of objects in an
    image | Computer vision | pipeline(task=â€œobject-detectionâ€) |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| ç‰©ä½“æ£€æµ‹ | é¢„æµ‹å›¾åƒä¸­ç‰©ä½“çš„è¾¹ç•Œæ¡†å’Œç±»åˆ« | è®¡ç®—æœºè§†è§‰ | pipeline(task=â€œobject-detectionâ€) |'
- en: '| Audio classification | assign a label to some audio data | Audio | pipeline(task=â€œaudio-classificationâ€)
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| éŸ³é¢‘åˆ†ç±» | ä¸ºä¸€äº›éŸ³é¢‘æ•°æ®åˆ†é…ä¸€ä¸ªæ ‡ç­¾ | éŸ³é¢‘ | pipeline(task=â€œaudio-classificationâ€) |'
- en: '| Automatic speech recognition | transcribe speech into text | Audio | pipeline(task=â€œautomatic-speech-recognitionâ€)
    |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| è‡ªåŠ¨è¯­éŸ³è¯†åˆ« | å°†è¯­éŸ³è½¬å½•ä¸ºæ–‡æœ¬ | éŸ³é¢‘ | pipeline(task=â€œautomatic-speech-recognitionâ€) |'
- en: '| Visual question answering | answer a question about the image, given an image
    and a question | Multimodal | pipeline(task=â€œvqaâ€) |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| è§†è§‰é—®ç­” | å›ç­”å…³äºå›¾åƒçš„é—®é¢˜ï¼Œç»™å®šä¸€ä¸ªå›¾åƒå’Œä¸€ä¸ªé—®é¢˜ | å¤šæ¨¡æ€ | pipeline(task=â€œvqaâ€) |'
- en: '| Document question answering | answer a question about the document, given
    a document and a question | Multimodal | pipeline(task=â€œdocument-question-answeringâ€)
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| æ–‡æ¡£é—®ç­” | å›ç­”å…³äºæ–‡æ¡£çš„é—®é¢˜ï¼Œç»™å®šä¸€ä¸ªæ–‡æ¡£å’Œä¸€ä¸ªé—®é¢˜ | å¤šæ¨¡æ€ | pipeline(task=â€œdocument-question-answeringâ€)
    |'
- en: '| Image captioning | generate a caption for a given image | Multimodal | pipeline(task=â€œimage-to-textâ€)
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| å›¾åƒå­—å¹• | ä¸ºç»™å®šå›¾åƒç”Ÿæˆå­—å¹• | å¤šæ¨¡æ€ | pipeline(task=â€œimage-to-textâ€) |'
- en: 'Start by creating an instance of [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    and specifying a task you want to use it for. In this guide, youâ€™ll use the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for sentiment analysis as an example:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆåˆ›å»ºä¸€ä¸ª[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)å®ä¾‹ï¼Œå¹¶æŒ‡å®šè¦ç”¨å®ƒè¿›è¡Œçš„ä»»åŠ¡ã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)è¿›è¡Œæƒ…æ„Ÿåˆ†æä½œä¸ºç¤ºä¾‹ï¼š
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    downloads and caches a default [pretrained model](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)
    and tokenizer for sentiment analysis. Now you can use the `classifier` on your
    target text:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)ä¼šä¸‹è½½å¹¶ç¼“å­˜ä¸€ä¸ªé»˜è®¤çš„[é¢„è®­ç»ƒæ¨¡å‹](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)å’Œæƒ…æ„Ÿåˆ†æçš„åˆ†è¯å™¨ã€‚ç°åœ¨æ‚¨å¯ä»¥åœ¨ç›®æ ‡æ–‡æœ¬ä¸Šä½¿ç”¨`classifier`ï¼š'
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you have more than one input, pass your inputs as a list to the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    to return a list of dictionaries:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å¤šä¸ªè¾“å…¥ï¼Œè¯·å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)ä»¥è¿”å›ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼š
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    can also iterate over an entire dataset for any task you like. For this example,
    letâ€™s choose automatic speech recognition as our task:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)è¿˜å¯ä»¥è¿­ä»£å¤„ç†ä»»ä½•æ‚¨å–œæ¬¢çš„ä»»åŠ¡çš„æ•´ä¸ªæ•°æ®é›†ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè®©æˆ‘ä»¬é€‰æ‹©è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä½œä¸ºæˆ‘ä»¬çš„ä»»åŠ¡ï¼š'
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Load an audio dataset (see the ğŸ¤— Datasets [Quick Start](https://huggingface.co/docs/datasets/quickstart#audio)
    for more details) youâ€™d like to iterate over. For example, load the [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)
    dataset:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½éŸ³é¢‘æ•°æ®é›†ï¼ˆæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤—æ•°æ®é›†[å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/datasets/quickstart#audio)ï¼‰ã€‚ä¾‹å¦‚ï¼ŒåŠ è½½[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)æ•°æ®é›†ï¼š
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You need to make sure the sampling rate of the dataset matches the sampling
    rate [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h)
    was trained on:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨éœ€è¦ç¡®ä¿æ•°æ®é›†çš„é‡‡æ ·ç‡ä¸[`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h)è®­ç»ƒæ—¶çš„é‡‡æ ·ç‡åŒ¹é…ï¼š
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The audio files are automatically loaded and resampled when calling the `"audio"`
    column. Extract the raw waveform arrays from the first 4 samples and pass it as
    a list to the pipeline:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è°ƒç”¨â€œaudioâ€åˆ—æ—¶ï¼ŒéŸ³é¢‘æ–‡ä»¶å°†è‡ªåŠ¨åŠ è½½å¹¶é‡æ–°é‡‡æ ·ã€‚ä»å‰ 4 ä¸ªæ ·æœ¬ä¸­æå–åŸå§‹æ³¢å½¢æ•°ç»„ï¼Œå¹¶å°†å…¶ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™ç®¡é“ï¼š
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For larger datasets where the inputs are big (like in speech or vision), youâ€™ll
    want to pass a generator instead of a list to load all the inputs in memory. Take
    a look at the [pipeline API reference](./main_classes/pipelines) for more information.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¾“å…¥æ•°æ®é‡è¾ƒå¤§çš„æƒ…å†µï¼ˆæ¯”å¦‚è¯­éŸ³æˆ–è§†è§‰ï¼‰ï¼Œæ‚¨å°†å¸Œæœ›ä¼ é€’ä¸€ä¸ªç”Ÿæˆå™¨è€Œä¸æ˜¯åˆ—è¡¨ï¼Œä»¥å°†æ‰€æœ‰è¾“å…¥åŠ è½½åˆ°å†…å­˜ä¸­ã€‚æŸ¥çœ‹[pipeline API å‚è€ƒ](./main_classes/pipelines)ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: Use another model and tokenizer in the pipeline
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨ç®¡é“ä¸­ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹å’Œåˆ†è¯å™¨
- en: 'The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    can accommodate any model from the [Hub](https://huggingface.co/models), making
    it easy to adapt the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for other use-cases. For example, if youâ€™d like a model capable of handling French
    text, use the tags on the Hub to filter for an appropriate model. The top filtered
    result returns a multilingual [BERT model](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)
    finetuned for sentiment analysis you can use for French text:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)å¯ä»¥é€‚åº”[Hub](https://huggingface.co/models)ä¸­çš„ä»»ä½•æ¨¡å‹ï¼Œä»è€Œå¯ä»¥è½»æ¾åœ°è°ƒæ•´[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)ä»¥é€‚åº”å…¶ä»–ç”¨ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨éœ€è¦ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†æ³•è¯­æ–‡æœ¬çš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨
    Hub ä¸Šçš„æ ‡ç­¾æ¥è¿‡æ»¤é€‚å½“çš„æ¨¡å‹ã€‚é¡¶éƒ¨è¿‡æ»¤ç»“æœè¿”å›ä¸€ä¸ªé’ˆå¯¹æƒ…æ„Ÿåˆ†æè¿›è¡Œå¾®è°ƒçš„å¤šè¯­è¨€[BERT æ¨¡å‹](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)ï¼Œæ‚¨å¯ä»¥ç”¨äºæ³•è¯­æ–‡æœ¬ï¼š'
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: PytorchHide Pytorch content
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè— Pytorch å†…å®¹
- en: 'Use [AutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification)
    and [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    to load the pretrained model and itâ€™s associated tokenizer (more on an `AutoClass`
    in the next section):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification)å’Œ[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹åŠå…¶å…³è”çš„åˆ†è¯å™¨ï¼ˆå…³äº`AutoClass`çš„æ›´å¤šä¿¡æ¯è¯·å‚è§ä¸‹ä¸€èŠ‚ï¼‰ï¼š
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: TensorFlowHide TensorFlow content
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè— TensorFlow å†…å®¹
- en: 'Use [TFAutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification)
    and [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    to load the pretrained model and itâ€™s associated tokenizer (more on an `TFAutoClass`
    in the next section):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[TFAutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification)å’Œ[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹åŠå…¶å…³è”çš„åˆ†è¯å™¨ï¼ˆå…³äº`TFAutoClass`çš„æ›´å¤šä¿¡æ¯è¯·å‚è§ä¸‹ä¸€èŠ‚ï¼‰ï¼š
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Specify the model and tokenizer in the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline),
    and now you can apply the `classifier` on French text:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)ä¸­æŒ‡å®šæ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œç°åœ¨æ‚¨å¯ä»¥åœ¨æ³•è¯­æ–‡æœ¬ä¸Šåº”ç”¨`classifier`ï¼š
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If you canâ€™t find a model for your use-case, youâ€™ll need to finetune a pretrained
    model on your data. Take a look at our [finetuning tutorial](./training) to learn
    how. Finally, after youâ€™ve finetuned your pretrained model, please consider [sharing](./model_sharing)
    the model with the community on the Hub to democratize machine learning for everyone!
    ğŸ¤—
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‰¾ä¸åˆ°é€‚åˆæ‚¨ç”¨ä¾‹çš„æ¨¡å‹ï¼Œæ‚¨éœ€è¦åœ¨æ‚¨çš„æ•°æ®ä¸Šå¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚æŸ¥çœ‹æˆ‘ä»¬çš„[å¾®è°ƒæ•™ç¨‹](./training)ä»¥äº†è§£å¦‚ä½•æ“ä½œã€‚æœ€åï¼Œåœ¨å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹åï¼Œè¯·è€ƒè™‘åœ¨
    Hub ä¸Š[å…±äº«](./model_sharing)è¯¥æ¨¡å‹ï¼Œä»¥ä½¿æœºå™¨å­¦ä¹ æ°‘ä¸»åŒ–ï¼ğŸ¤—
- en: AutoClass
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoClass
- en: '[https://www.youtube-nocookie.com/embed/AhChOFRegn4](https://www.youtube-nocookie.com/embed/AhChOFRegn4)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube-nocookie.com/embed/AhChOFRegn4](https://www.youtube-nocookie.com/embed/AhChOFRegn4)'
- en: Under the hood, the [AutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification)
    and [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    classes work together to power the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    you used above. An [AutoClass](./model_doc/auto) is a shortcut that automatically
    retrieves the architecture of a pretrained model from its name or path. You only
    need to select the appropriate `AutoClass` for your task and itâ€™s associated preprocessing
    class.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¹•åï¼Œ[AutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification)å’Œ[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)ç±»å…±åŒé©±åŠ¨æ‚¨ä¸Šé¢ä½¿ç”¨çš„[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)ã€‚[AutoClass](./model_doc/auto)æ˜¯ä¸€ä¸ªå¿«æ·æ–¹å¼ï¼Œå¯ä»¥æ ¹æ®é¢„è®­ç»ƒæ¨¡å‹çš„åç§°æˆ–è·¯å¾„è‡ªåŠ¨æ£€ç´¢æ¶æ„ã€‚æ‚¨åªéœ€è¦ä¸ºæ‚¨çš„ä»»åŠ¡é€‰æ‹©é€‚å½“çš„`AutoClass`åŠå…¶å…³è”çš„é¢„å¤„ç†ç±»ã€‚
- en: Letâ€™s return to the example from the previous section and see how you can use
    the `AutoClass` to replicate the results of the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å›åˆ°å‰ä¸€èŠ‚çš„ç¤ºä¾‹ï¼Œçœ‹çœ‹å¦‚ä½•ä½¿ç”¨`AutoClass`æ¥å¤åˆ¶[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)çš„ç»“æœã€‚
- en: AutoTokenizer
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoTokenizer
- en: A tokenizer is responsible for preprocessing text into an array of numbers as
    inputs to a model. There are multiple rules that govern the tokenization process,
    including how to split a word and at what level words should be split (learn more
    about tokenization in the [tokenizer summary](./tokenizer_summary)). The most
    important thing to remember is you need to instantiate a tokenizer with the same
    model name to ensure youâ€™re using the same tokenization rules a model was pretrained
    with.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†è¯å™¨è´Ÿè´£å°†æ–‡æœ¬é¢„å¤„ç†ä¸ºè¾“å…¥æ¨¡å‹çš„æ•°å­—æ•°ç»„ã€‚æœ‰å¤šä¸ªè§„åˆ™ç®¡ç†æ ‡è®°åŒ–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¦‚ä½•æ‹†åˆ†å•è¯ä»¥åŠå•è¯åº”è¯¥åœ¨ä»€ä¹ˆçº§åˆ«æ‹†åˆ†ï¼ˆåœ¨[åˆ†è¯å™¨æ‘˜è¦](./tokenizer_summary)ä¸­äº†è§£æ›´å¤šå…³äºåˆ†è¯çš„ä¿¡æ¯ï¼‰ã€‚æœ€é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ç›¸åŒæ¨¡å‹åç§°å®ä¾‹åŒ–åˆ†è¯å™¨ï¼Œä»¥ç¡®ä¿æ‚¨ä½¿ç”¨ä¸æ¨¡å‹é¢„è®­ç»ƒæ—¶ç›¸åŒçš„æ ‡è®°åŒ–è§„åˆ™ã€‚
- en: 'Load a tokenizer with [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)åŠ è½½åˆ†è¯å™¨ï¼š
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Pass your text to the tokenizer:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ–‡æœ¬ä¼ é€’ç»™åˆ†è¯å™¨ï¼š
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The tokenizer returns a dictionary containing:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†è¯å™¨è¿”å›ä¸€ä¸ªåŒ…å«çš„å­—å…¸ï¼š
- en: '[input_ids](./glossary#input-ids): numerical representations of your tokens.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[input_ids](./glossary#input-ids)ï¼šæ‚¨çš„æ ‡è®°çš„æ•°å€¼è¡¨ç¤ºã€‚'
- en: '[attention_mask](.glossary#attention-mask): indicates which tokens should be
    attended to.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[attention_mask](.glossary#attention-mask)ï¼šæŒ‡ç¤ºåº”è¯¥å…³æ³¨å“ªäº›æ ‡è®°ã€‚'
- en: 'A tokenizer can also accept a list of inputs, and pad and truncate the text
    to return a batch with uniform length:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†è¯å™¨è¿˜å¯ä»¥æ¥å—è¾“å…¥åˆ—è¡¨ï¼Œå¹¶å¡«å……å’Œæˆªæ–­æ–‡æœ¬ä»¥è¿”å›å…·æœ‰ç»Ÿä¸€é•¿åº¦çš„æ‰¹å¤„ç†ï¼š
- en: PytorchHide Pytorch content
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè—Pytorchå†…å®¹
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: TensorFlowHide TensorFlow content
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè—TensorFlowå†…å®¹
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Check out the [preprocess](./preprocessing) tutorial for more details about
    tokenization, and how to use an [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor),
    [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    and [AutoProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor)
    to preprocess image, audio, and multimodal inputs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[é¢„å¤„ç†](./preprocessing)æ•™ç¨‹ï¼Œäº†è§£æœ‰å…³åˆ†è¯ä»¥åŠå¦‚ä½•ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)ã€[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)å’Œ[AutoProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor)é¢„å¤„ç†å›¾åƒã€éŸ³é¢‘å’Œå¤šæ¨¡æ€è¾“å…¥çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
- en: AutoModel
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModel
- en: PytorchHide Pytorch content
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè—Pytorchå†…å®¹
- en: 'ğŸ¤— Transformers provides a simple and unified way to load pretrained instances.
    This means you can load an [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    like you would load an [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    The only difference is selecting the correct [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    for the task. For text (or sequence) classification, you should load [AutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformersæä¾›äº†ä¸€ç§ç®€å•è€Œç»Ÿä¸€çš„æ–¹å¼æ¥åŠ è½½é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥åŠ è½½ä¸€ä¸ª[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)ï¼Œå°±åƒåŠ è½½[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)ä¸€æ ·ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯é€‰æ‹©æ­£ç¡®çš„[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)ç”¨äºä»»åŠ¡ã€‚å¯¹äºæ–‡æœ¬ï¼ˆæˆ–åºåˆ—ï¼‰åˆ†ç±»ï¼Œæ‚¨åº”è¯¥åŠ è½½[AutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification)ï¼š
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: See the [task summary](./task_summary) for tasks supported by an [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    class.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[ä»»åŠ¡æ‘˜è¦](./task_summary)ä»¥äº†è§£[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)ç±»æ”¯æŒçš„ä»»åŠ¡ã€‚
- en: 'Now pass your preprocessed batch of inputs directly to the model. You just
    have to unpack the dictionary by adding `**`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ç›´æ¥å°†é¢„å¤„ç†çš„è¾“å…¥æ‰¹æ¬¡ä¼ é€’ç»™æ¨¡å‹ã€‚æ‚¨åªéœ€é€šè¿‡æ·»åŠ `**`æ¥è§£åŒ…å­—å…¸ï¼š
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The model outputs the final activations in the `logits` attribute. Apply the
    softmax function to the `logits` to retrieve the probabilities:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨`logits`å±æ€§ä¸­è¾“å‡ºæœ€ç»ˆæ¿€æ´»å€¼ã€‚å°†softmaxå‡½æ•°åº”ç”¨äº`logits`ä»¥æ£€ç´¢æ¦‚ç‡ï¼š
- en: '[PRE20]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: TensorFlowHide TensorFlow content
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè—TensorFlowå†…å®¹
- en: 'ğŸ¤— Transformers provides a simple and unified way to load pretrained instances.
    This means you can load an [TFAutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModel)
    like you would load an [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    The only difference is selecting the correct [TFAutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModel)
    for the task. For text (or sequence) classification, you should load [TFAutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformersæä¾›äº†ä¸€ç§ç®€å•è€Œç»Ÿä¸€çš„æ–¹å¼æ¥åŠ è½½é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥åŠ è½½ä¸€ä¸ª[TFAutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModel)ï¼Œå°±åƒåŠ è½½[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)ä¸€æ ·ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯é€‰æ‹©æ­£ç¡®çš„[TFAutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModel)ç”¨äºä»»åŠ¡ã€‚å¯¹äºæ–‡æœ¬ï¼ˆæˆ–åºåˆ—ï¼‰åˆ†ç±»ï¼Œæ‚¨åº”è¯¥åŠ è½½[TFAutoModelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification)ï¼š
- en: '[PRE21]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: See the [task summary](./task_summary) for tasks supported by an [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    class.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[ä»»åŠ¡æ‘˜è¦](./task_summary)ä»¥äº†è§£[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)ç±»æ”¯æŒçš„ä»»åŠ¡ã€‚
- en: 'Now pass your preprocessed batch of inputs directly to the model. You can pass
    the tensors as-is:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ç›´æ¥å°†é¢„å¤„ç†çš„è¾“å…¥æ‰¹æ¬¡ä¼ é€’ç»™æ¨¡å‹ã€‚æ‚¨å¯ä»¥ç›´æ¥ä¼ é€’å¼ é‡ï¼š
- en: '[PRE22]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The model outputs the final activations in the `logits` attribute. Apply the
    softmax function to the `logits` to retrieve the probabilities:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨`logits`å±æ€§ä¸­è¾“å‡ºæœ€ç»ˆæ¿€æ´»å€¼ã€‚å°†softmaxå‡½æ•°åº”ç”¨äº`logits`ä»¥æ£€ç´¢æ¦‚ç‡ï¼š
- en: '[PRE23]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: All ğŸ¤— Transformers models (PyTorch or TensorFlow) output the tensors *before*
    the final activation function (like softmax) because the final activation function
    is often fused with the loss. Model outputs are special dataclasses so their attributes
    are autocompleted in an IDE. The model outputs behave like a tuple or a dictionary
    (you can index with an integer, a slice or a string) in which case, attributes
    that are None are ignored.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ğŸ¤— Transformers æ¨¡å‹ï¼ˆPyTorch æˆ– TensorFlowï¼‰åœ¨æœ€ç»ˆæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ softmaxï¼‰ä¹‹å‰è¾“å‡ºå¼ é‡ï¼Œå› ä¸ºæœ€ç»ˆæ¿€æ´»å‡½æ•°é€šå¸¸ä¸æŸå¤±èåˆåœ¨ä¸€èµ·ã€‚æ¨¡å‹è¾“å‡ºæ˜¯ç‰¹æ®Šçš„æ•°æ®ç±»ï¼Œå› æ­¤åœ¨
    IDE ä¸­å¯ä»¥è‡ªåŠ¨å®Œæˆå…¶å±æ€§ã€‚æ¨¡å‹è¾“å‡ºçš„è¡Œä¸ºç±»ä¼¼äºå…ƒç»„æˆ–å­—å…¸ï¼ˆå¯ä»¥ä½¿ç”¨æ•´æ•°ã€åˆ‡ç‰‡æˆ–å­—ç¬¦ä¸²è¿›è¡Œç´¢å¼•ï¼‰ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç©ºå±æ€§å°†è¢«å¿½ç•¥ã€‚
- en: Save a model
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¿å­˜æ¨¡å‹
- en: PytorchHide Pytorch content
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè— Pytorch å†…å®¹
- en: 'Once your model is fine-tuned, you can save it with its tokenizer using [PreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨çš„æ¨¡å‹å¾®è°ƒå®Œæˆï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[PreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)ä¿å­˜æ¨¡å‹åŠå…¶åˆ†è¯å™¨ï¼š
- en: '[PRE24]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'When you are ready to use the model again, reload it with [PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨å‡†å¤‡å†æ¬¡ä½¿ç”¨æ¨¡å‹æ—¶ï¼Œè¯·ä½¿ç”¨[PreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)é‡æ–°åŠ è½½å®ƒï¼š
- en: '[PRE25]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: TensorFlowHide TensorFlow content
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè— TensorFlow å†…å®¹
- en: 'Once your model is fine-tuned, you can save it with its tokenizer using [TFPreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨çš„æ¨¡å‹å¾®è°ƒå®Œæˆï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[TFPreTrainedModel.save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained)ä¿å­˜æ¨¡å‹åŠå…¶åˆ†è¯å™¨ï¼š
- en: '[PRE26]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When you are ready to use the model again, reload it with [TFPreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨å‡†å¤‡å†æ¬¡ä½¿ç”¨æ¨¡å‹æ—¶ï¼Œè¯·ä½¿ç”¨[TFPreTrainedModel.from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)é‡æ–°åŠ è½½å®ƒï¼š
- en: '[PRE27]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'One particularly cool ğŸ¤— Transformers feature is the ability to save a model
    and reload it as either a PyTorch or TensorFlow model. The `from_pt` or `from_tf`
    parameter can convert the model from one framework to the other:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformers çš„ä¸€ä¸ªç‰¹åˆ«é…·çš„åŠŸèƒ½æ˜¯èƒ½å¤Ÿå°†æ¨¡å‹ä¿å­˜å¹¶é‡æ–°åŠ è½½ä¸º PyTorch æˆ– TensorFlow æ¨¡å‹ã€‚`from_pt` æˆ– `from_tf`
    å‚æ•°å¯ä»¥å°†æ¨¡å‹ä»ä¸€ä¸ªæ¡†æ¶è½¬æ¢ä¸ºå¦ä¸€ä¸ªæ¡†æ¶ï¼š
- en: PytorchHide Pytorch content
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè— Pytorch å†…å®¹
- en: '[PRE28]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: TensorFlowHide TensorFlow content
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè— TensorFlow å†…å®¹
- en: '[PRE29]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Custom model builds
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰æ¨¡å‹æ„å»º
- en: You can modify the modelâ€™s configuration class to change how a model is built.
    The configuration specifies a modelâ€™s attributes, such as the number of hidden
    layers or attention heads. You start from scratch when you initialize a model
    from a custom configuration class. The model attributes are randomly initialized,
    and youâ€™ll need to train the model before you can use it to get meaningful results.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä¿®æ”¹æ¨¡å‹çš„é…ç½®ç±»ä»¥æ›´æ”¹æ¨¡å‹çš„æ„å»ºæ–¹å¼ã€‚é…ç½®æŒ‡å®šæ¨¡å‹çš„å±æ€§ï¼Œä¾‹å¦‚éšè—å±‚æˆ–æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚å½“æ‚¨ä»è‡ªå®šä¹‰é…ç½®ç±»åˆå§‹åŒ–æ¨¡å‹æ—¶ï¼Œæ‚¨å°†ä»å¤´å¼€å§‹ã€‚æ¨¡å‹å±æ€§æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæ‚¨éœ€è¦åœ¨ä½¿ç”¨å®ƒä»¥è·å¾—æœ‰æ„ä¹‰çš„ç»“æœä¹‹å‰å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚
- en: 'Start by importing [AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig),
    and then load the pretrained model you want to modify. Within [AutoConfig.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained),
    you can specify the attribute you want to change, such as the number of attention
    heads:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆå¯¼å…¥[AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig)ï¼Œç„¶ååŠ è½½æ‚¨æƒ³è¦ä¿®æ”¹çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚åœ¨[AutoConfig.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained)ä¸­ï¼Œæ‚¨å¯ä»¥æŒ‡å®šè¦æ›´æ”¹çš„å±æ€§ï¼Œæ¯”å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼š
- en: '[PRE30]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: PytorchHide Pytorch content
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorchéšè— Pytorch å†…å®¹
- en: 'Create a model from your custom configuration with [AutoModel.from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[AutoModel.from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)ä»æ‚¨çš„è‡ªå®šä¹‰é…ç½®åˆ›å»ºæ¨¡å‹ï¼š
- en: '[PRE31]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: TensorFlowHide TensorFlow content
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè— TensorFlow å†…å®¹
- en: 'Create a model from your custom configuration with [TFAutoModel.from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config):'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[TFAutoModel.from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)ä»æ‚¨çš„è‡ªå®šä¹‰é…ç½®åˆ›å»ºæ¨¡å‹ï¼š
- en: '[PRE32]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Take a look at the [Create a custom architecture](./create_a_model) guide for
    more information about building custom configurations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[åˆ›å»ºè‡ªå®šä¹‰æ¶æ„](./create_a_model)æŒ‡å—ï¼Œäº†è§£æœ‰å…³æ„å»ºè‡ªå®šä¹‰é…ç½®çš„æ›´å¤šä¿¡æ¯ã€‚
- en: Trainer - a PyTorch optimized training loop
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Trainer - ä¸€ä¸ª PyTorch ä¼˜åŒ–çš„è®­ç»ƒå¾ªç¯
- en: All models are a standard [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    so you can use them in any typical training loop. While you can write your own
    training loop, ğŸ¤— Transformers provides a [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)
    class for PyTorch, which contains the basic training loop and adds additional
    functionality for features like distributed training, mixed precision, and more.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æ ‡å‡†çš„[`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)ï¼Œå› æ­¤æ‚¨å¯ä»¥åœ¨ä»»ä½•å…¸å‹çš„è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨å®ƒä»¬ã€‚è™½ç„¶æ‚¨å¯ä»¥ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯ï¼ŒğŸ¤—
    Transformers æä¾›äº†ä¸€ä¸ªç”¨äº PyTorch çš„[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ç±»ï¼Œå…¶ä¸­åŒ…å«åŸºæœ¬çš„è®­ç»ƒå¾ªç¯ï¼Œå¹¶æ·»åŠ äº†é¢å¤–çš„åŠŸèƒ½ï¼Œå¦‚åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦ç­‰ã€‚
- en: 'Depending on your task, youâ€™ll typically pass the following parameters to [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ‚¨çš„ä»»åŠ¡ï¼Œé€šå¸¸ä¼šå°†ä»¥ä¸‹å‚æ•°ä¼ é€’ç»™[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼š
- en: 'Youâ€™ll start with a [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)
    or a [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module):'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‚¨å°†ä»[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)æˆ–[`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å¼€å§‹ï¼š
- en: '[PRE33]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)
    contains the model hyperparameters you can change like learning rate, batch size,
    and the number of epochs to train for. The default values are used if you donâ€™t
    specify any training arguments:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)åŒ…å«æ‚¨å¯ä»¥æ›´æ”¹çš„æ¨¡å‹è¶…å‚æ•°ï¼Œå¦‚å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°å’Œè®­ç»ƒçš„æ—¶ä»£æ•°ã€‚å¦‚æœæ‚¨ä¸æŒ‡å®šä»»ä½•è®­ç»ƒå‚æ•°ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ï¼š'
- en: '[PRE34]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Load a preprocessing class like a tokenizer, image processor, feature extractor,
    or processor:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„å¤„ç†ç±»ï¼Œæ¯”å¦‚åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨æˆ–å¤„ç†å™¨ï¼š
- en: '[PRE35]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Load a dataset:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®é›†ï¼š
- en: '[PRE36]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a function to tokenize the dataset:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼š
- en: '[PRE37]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Then apply it over the entire dataset with [map](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.map):'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨å®ƒï¼Œä½¿ç”¨[map](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.map)ï¼š
- en: '[PRE38]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'A [DataCollatorWithPadding](/docs/transformers/v4.37.2/en/main_classes/data_collator#transformers.DataCollatorWithPadding)
    to create a batch of examples from your dataset:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[DataCollatorWithPadding](/docs/transformers/v4.37.2/en/main_classes/data_collator#transformers.DataCollatorWithPadding)æ¥ä»æ‚¨çš„æ•°æ®é›†ä¸­åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ï¼š
- en: '[PRE39]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now gather all these classes in [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å°†æ‰€æœ‰è¿™äº›ç±»èšé›†åœ¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ä¸­ï¼š
- en: '[PRE40]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'When youâ€™re ready, call [train()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.train)
    to start training:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ å‡†å¤‡å¥½æ—¶ï¼Œè°ƒç”¨[train()](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer.train)å¼€å§‹è®­ç»ƒï¼š
- en: '[PRE41]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: For tasks - like translation or summarization - that use a sequence-to-sequence
    model, use the [Seq2SeqTrainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Seq2SeqTrainer)
    and [Seq2SeqTrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments)
    classes instead.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä½¿ç”¨åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„ä»»åŠ¡ï¼Œæ¯”å¦‚ç¿»è¯‘æˆ–æ‘˜è¦ï¼Œä½¿ç”¨[Seq2SeqTrainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Seq2SeqTrainer)å’Œ[Seq2SeqTrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments)ç±»ã€‚
- en: You can customize the training loop behavior by subclassing the methods inside
    [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer).
    This allows you to customize features such as the loss function, optimizer, and
    scheduler. Take a look at the [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)
    reference for which methods can be subclassed.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡å¯¹[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ä¸­çš„æ–¹æ³•è¿›è¡Œå­ç±»åŒ–æ¥è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¡Œä¸ºã€‚è¿™æ ·å¯ä»¥è‡ªå®šä¹‰ç‰¹æ€§ï¼Œå¦‚æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ã€‚æŸ¥çœ‹[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‚è€ƒï¼Œäº†è§£å“ªäº›æ–¹æ³•å¯ä»¥è¢«å­ç±»åŒ–ã€‚
- en: The other way to customize the training loop is by using [Callbacks](./main_classes/callbacks).
    You can use callbacks to integrate with other libraries and inspect the training
    loop to report on progress or stop the training early. Callbacks do not modify
    anything in the training loop itself. To customize something like the loss function,
    you need to subclass the [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)
    instead.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯çš„æ–¹æ³•æ˜¯ä½¿ç”¨[Callbacks](./main_classes/callbacks)ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å›è°ƒå‡½æ•°ä¸å…¶ä»–åº“é›†æˆï¼Œå¹¶æ£€æŸ¥è®­ç»ƒå¾ªç¯ä»¥æŠ¥å‘Šè¿›åº¦æˆ–æå‰åœæ­¢è®­ç»ƒã€‚å›è°ƒå‡½æ•°ä¸ä¼šä¿®æ”¹è®­ç»ƒå¾ªç¯æœ¬èº«ã€‚è¦è‡ªå®šä¹‰åƒæŸå¤±å‡½æ•°è¿™æ ·çš„ä¸œè¥¿ï¼Œæ‚¨éœ€è¦å¯¹[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)è¿›è¡Œå­ç±»åŒ–ã€‚
- en: Train with TensorFlow
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨TensorFlowè¿›è¡Œè®­ç»ƒ
- en: All models are a standard [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    so they can be trained in TensorFlow with the [Keras](https://keras.io/) API.
    ğŸ¤— Transformers provides the [prepare_tf_dataset()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)
    method to easily load your dataset as a `tf.data.Dataset` so you can start training
    right away with Kerasâ€™ [`compile`](https://keras.io/api/models/model_training_apis/#compile-method)
    and [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) methods.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æ ‡å‡†çš„[`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)ï¼Œå› æ­¤å®ƒä»¬å¯ä»¥åœ¨TensorFlowä¸­ä½¿ç”¨[Keras](https://keras.io/)
    APIè¿›è¡Œè®­ç»ƒã€‚ğŸ¤— Transformersæä¾›äº†[prepare_tf_dataset()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)æ–¹æ³•ï¼Œå¯ä»¥è½»æ¾å°†æ•°æ®é›†åŠ è½½ä¸º`tf.data.Dataset`ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥ç«‹å³å¼€å§‹ä½¿ç”¨Kerasçš„[`compile`](https://keras.io/api/models/model_training_apis/#compile-method)å’Œ[`fit`](https://keras.io/api/models/model_training_apis/#fit-method)æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚
- en: 'Youâ€™ll start with a [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)
    or a [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model):'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‚¨å°†ä»[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)æˆ–[`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)å¼€å§‹ï¼š
- en: '[PRE42]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Load a preprocessing class like a tokenizer, image processor, feature extractor,
    or processor:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªé¢„å¤„ç†ç±»ï¼Œæ¯”å¦‚åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨æˆ–å¤„ç†å™¨ï¼š
- en: '[PRE43]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Create a function to tokenize the dataset:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯ï¼š
- en: '[PRE44]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Apply the tokenizer over the entire dataset with [map](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.map)
    and then pass the dataset and tokenizer to [prepare_tf_dataset()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset).
    You can also change the batch size and shuffle the dataset here if youâ€™d like:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[map](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.map)åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨åˆ†è¯å™¨ï¼Œç„¶åå°†æ•°æ®é›†å’Œåˆ†è¯å™¨ä¼ é€’ç»™[prepare_tf_dataset()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)ã€‚å¦‚æœéœ€è¦ï¼Œæ‚¨è¿˜å¯ä»¥åœ¨è¿™é‡Œæ›´æ”¹æ‰¹é‡å¤§å°å’Œå¯¹æ•°æ®é›†è¿›è¡Œæ´—ç‰Œï¼š
- en: '[PRE45]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'When youâ€™re ready, you can call `compile` and `fit` to start training. Note
    that Transformers models all have a default task-relevant loss function, so you
    donâ€™t need to specify one unless you want to:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å½“æ‚¨å‡†å¤‡å¥½æ—¶ï¼Œæ‚¨å¯ä»¥è°ƒç”¨`compile`å’Œ`fit`å¼€å§‹è®­ç»ƒã€‚è¯·æ³¨æ„ï¼ŒTransformersæ¨¡å‹éƒ½æœ‰ä¸€ä¸ªé»˜è®¤çš„ä¸ä»»åŠ¡ç›¸å…³çš„æŸå¤±å‡½æ•°ï¼Œæ‰€ä»¥é™¤éæ‚¨æƒ³è¦ï¼Œå¦åˆ™ä¸éœ€è¦æŒ‡å®šä¸€ä¸ªï¼š
- en: '[PRE46]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Whatâ€™s next?
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥æ˜¯ä»€ä¹ˆï¼Ÿ
- en: Now that youâ€™ve completed the ğŸ¤— Transformers quick tour, check out our guides
    and learn how to do more specific things like writing a custom model, fine-tuning
    a model for a task, and how to train a model with a script. If youâ€™re interested
    in learning more about ğŸ¤— Transformers core concepts, grab a cup of coffee and
    take a look at our Conceptual Guides!
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»å®Œæˆäº†ğŸ¤— Transformersçš„å¿«é€Ÿå¯¼è§ˆï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„æŒ‡å—ï¼Œå­¦ä¹ å¦‚ä½•åšæ›´å…·ä½“çš„äº‹æƒ…ï¼Œæ¯”å¦‚ç¼–å†™è‡ªå®šä¹‰æ¨¡å‹ï¼Œä¸ºä»»åŠ¡å¾®è°ƒæ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨è„šæœ¬è®­ç»ƒæ¨¡å‹ã€‚å¦‚æœæ‚¨å¯¹å­¦ä¹ æ›´å¤šå…³äºğŸ¤—
    Transformersæ ¸å¿ƒæ¦‚å¿µæ„Ÿå…´è¶£ï¼Œè¯·æ‹¿æ¯å’–å•¡ï¼Œçœ‹çœ‹æˆ‘ä»¬çš„æ¦‚å¿µæŒ‡å—ï¼
