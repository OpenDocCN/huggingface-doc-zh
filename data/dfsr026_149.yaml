- en: Latent Consistency Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 潜一致性模型
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/latent_consistency_models](https://huggingface.co/docs/diffusers/api/pipelines/latent_consistency_models)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/latent_consistency_models](https://huggingface.co/docs/diffusers/api/pipelines/latent_consistency_models)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Latent Consistency Models (LCMs) were proposed in [Latent Consistency Models:
    Synthesizing High-Resolution Images with Few-Step Inference](https://huggingface.co/papers/2310.04378)
    by Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 潜一致性模型（LCMs）由Simian Luo、Yiqin Tan、Longbo Huang、Jian Li和Hang Zhao在[潜一致性模型：通过少步推断合成高分辨率图像](https://huggingface.co/papers/2310.04378)中提出。
- en: 'The abstract of the paper is as follows:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要如下：
- en: '*Latent Diffusion models (LDMs) have achieved remarkable results in synthesizing
    high-resolution images. However, the iterative sampling process is computationally
    intensive and leads to slow generation. Inspired by Consistency Models (song et
    al.), we propose Latent Consistency Models (LCMs), enabling swift inference with
    minimal steps on any pre-trained LDMs, including Stable Diffusion (rombach et
    al). Viewing the guided reverse diffusion process as solving an augmented probability
    flow ODE (PF-ODE), LCMs are designed to directly predict the solution of such
    ODE in latent space, mitigating the need for numerous iterations and allowing
    rapid, high-fidelity sampling. Efficiently distilled from pre-trained classifier-free
    guided diffusion models, a high-quality 768 x 768 2~4-step LCM takes only 32 A100
    GPU hours for training. Furthermore, we introduce Latent Consistency Fine-tuning
    (LCF), a novel method that is tailored for fine-tuning LCMs on customized image
    datasets. Evaluation on the LAION-5B-Aesthetics dataset demonstrates that LCMs
    achieve state-of-the-art text-to-image generation performance with few-step inference.
    Project Page: [this https URL](https://latent-consistency-models.github.io/).*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*潜扩散模型（LDMs）在合成高分辨率图像方面取得了显著的成果。然而，迭代采样过程计算密集且导致生成速度缓慢。受一致性模型（song等人）的启发，我们提出了潜一致性模型（LCMs），在任何预训练的LDM上实现快速推断，步骤最少，包括稳定扩散（rombach等人）。将引导的逆扩散过程视为解决潜空间中的增广概率流ODE（PF-ODE），LCMs旨在直接预测此类ODE的解，减轻了对大量迭代的需求，实现了快速、高保真度的采样。从预训练的无分类器引导扩散模型中高效提取，高质量的768
    x 768 2~4步LCM仅需32个A100 GPU小时进行训练。此外，我们引入了潜一致性微调（LCF），这是一种专为在定制图像数据集上微调LCMs的新方法。对LAION-5B-Aesthetics数据集的评估表明，LCMs在少步推断下实现了最先进的文本到图像生成性能。项目页面：[此处的URL](https://latent-consistency-models.github.io/)。*'
- en: A demo for the [SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7)
    checkpoint can be found [here](https://huggingface.co/spaces/SimianLuo/Latent_Consistency_Model).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[此处](https://huggingface.co/spaces/SimianLuo/Latent_Consistency_Model)找到[SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7)检查点的演示。
- en: The pipelines were contributed by [luosiallen](https://luosiallen.github.io/),
    [nagolinc](https://github.com/nagolinc), and [dg845](https://github.com/dg845).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这些管道由[luosiallen](https://luosiallen.github.io/)、[nagolinc](https://github.com/nagolinc)和[dg845](https://github.com/dg845)贡献。
- en: LatentConsistencyModelPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LatentConsistencyModelPipeline
- en: '### `class diffusers.LatentConsistencyModelPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.LatentConsistencyModelPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L109)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L109)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)）-
    变分自动编码器（VAE）模型，用于对图像进行编码和解码以及从潜在表示到图像的解码。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（[CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel)）-
    冻结的文本编码器（clip-vit-large-patch14）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)）-
    用于对文本进行标记化的`CLIPTokenizer`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)）-
    用于去噪编码图像潜变量的`UNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Currently only supports [LCMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lcm#diffusers.LCMScheduler).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)）-
    与`unet`结合使用以去噪编码图像潜变量的调度程序。目前仅支持[LCMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lcm#diffusers.LCMScheduler)。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker`（`StableDiffusionSafetyChecker`）- 估计生成的图像是否可能被视为具有冒犯性或有害性的分类模块。有关模型潜在危害的更多详细信息，请参阅[模型卡片](https://huggingface.co/runwayml/stable-diffusion-v1-5)。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`（[CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)）-
    用于从生成的图像中提取特征的`CLIPImageProcessor`；作为输入用于`safety_checker`。'
- en: '`requires_safety_checker` (`bool`, *optional*, defaults to `True`) — Whether
    the pipeline requires a safety checker component.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requires_safety_checker` (`bool`, *optional*, 默认值为`True`) — 流水线是否需要安全检查器组件。'
- en: Pipeline for text-to-image generation using a latent consistency model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用潜在一致性模型进行文本到图像生成的流水线。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有流水线实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该流水线还继承了以下加载方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    用于加载LoRA权重'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    用于保存LoRA权重'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    用于加载`.ckpt`文件'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    用于加载IP适配器'
- en: '#### `__call__`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L597)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L597)'
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *optional*) — 用于引导图像生成的提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*, 默认值为`self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*, 默认值为`self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认值为50) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`original_inference_steps` (`int`, *optional*) — The original number of inference
    steps use to generate a linearly-spaced timestep schedule, from which we will
    draw `num_inference_steps` evenly spaced timesteps from as our final timestep
    schedule, following the Skipping-Step method in the paper (see Section 4.3). If
    not set this will default to the scheduler’s `original_inference_steps` attribute.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`original_inference_steps` (`int`, *optional*) — 用于生成线性间隔时间步骤计划的原始推理步骤数，我们将从中绘制`num_inference_steps`等间隔时间步骤作为我们的最终时间步骤计划，遵循论文中的跳步方法（参见第4.3节）。如果未设置，将默认为调度器的`original_inference_steps`属性。'
- en: '`timesteps` (`List[int]`, *optional*) — Custom timesteps to use for the denoising
    process. If not defined, equal spaced `num_inference_steps` timesteps on the original
    LCM training/distillation timestep schedule are used. Must be in descending order.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *optional*) — 用于降噪过程的自定义时间步骤。如果未定义，则使用原始LCM训练/蒸馏时间步骤计划上等间隔的`num_inference_steps`时间步骤。必须按降序排列。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`. Note that the original latent consistency models paper uses
    a different CFG formulation where the guidance scales are decreased by 1 (so in
    the paper formulation CFG is enabled when `guidance_scale > 0`).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认值为7.5) — 较高的引导比例值鼓励模型生成与文本`prompt`密切相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。请注意，原始的潜在一致性模型论文使用了不同的CFG公式，其中引导比例减少了1（因此在论文公式中，当`guidance_scale >
    0`时启用CFG）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, 默认值为1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中采样的预生成噪声潜在变量，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，将使用提供的随机`generator`生成潜在变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument. ip_adapter_image —
    (`PipelineImageInput`, *optional*): Optional image input to work with IP Adapters.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，文本嵌入将从`prompt`输入参数生成。ip_adapter_image
    — (`PipelineImageInput`, *optional*): 可选的图像输入，用于与IP适配器一起使用。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为`True`) — 是否返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是普通的`tuple`。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将作为`AttentionProcessor`中的参数传递给[`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 在计算提示嵌入时要跳过的层数。值为1表示将使用预最终层的输出来计算提示嵌入。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) — 在推断过程中每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`将包括由`callback_on_step_end_tensor_inputs`指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — `callback_on_step_end`函数的张量输入列表。列表中指定的张量将作为`callback_kwargs`参数传递。您只能包含在流水线类的`._callback_tensor_inputs`属性中列出的变量。'
- en: Returns
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，将返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则将返回一个`tuple`，其中第一个元素是生成的图像列表，第二个元素是一个包含指示相应生成图像是否包含“不适宜工作”（nsfw）内容的`bool`列表。
- en: The call function to the pipeline for generation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的流水线的调用函数。
- en: 'Examples:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `enable_freeu`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L230)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L230)'
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1` (`float`) — 第1阶段的缩放因子，用于减弱跳跃特征的贡献。这样做是为了在增强去噪过程中减轻“过度平滑效应”。'
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2` (`float`) — 第2阶段的缩放因子，用于减弱跳跃特征的贡献。这样做是为了在增强去噪过程中减轻“过度平滑效应”。'
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1` (`float`) — 第1阶段的缩放因子，用于放大骨干特征的贡献。'
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2` (`float`) — 第2阶段的缩放因子，用于放大骨干特征的贡献。'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 启用FreeU机制，如[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)。
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子后缀表示应用它们的阶段。
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[官方存储库](https://github.com/ChenyangSi/FreeU)，了解已知适用于不同流水线（如Stable Diffusion
    v1、v2和Stable Diffusion XL）的值组合。
- en: '#### `disable_freeu`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L253)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L253)'
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用了启用的FreeU机制。
- en: '#### `enable_vae_slicing`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L197)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L197)'
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。当启用此选项时，VAE将将输入张量分成片段以在多个步骤中计算解码。这对于节省一些内存并允许更大的批量大小很有用。
- en: '#### `disable_vae_slicing`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L205)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L205)'
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片的VAE解码。如果之前启用了`enable_vae_slicing`，则此方法将返回到一步计算解码。
- en: '#### `enable_vae_tiling`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L213)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L213)'
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺的VAE解码。当启用此选项时，VAE将将输入张量分成瓦片以在多个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像很有用。
- en: '#### `disable_vae_tiling`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L222)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L222)'
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺的VAE解码。如果之前启用了`enable_vae_tiling`，则此方法将返回到一步计算解码。
- en: '#### `encode_prompt`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L258)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L258)'
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 要编码的提示设备 — (`torch.device`): torch 设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用分类器自由指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于指导图像生成的提示或提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用指导（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，*例如* 提示加权。如果未提供，文本嵌入将从
    `prompt` 输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，*例如*
    提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *可选*) — 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的LoRA比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *可选*) — 在计算提示嵌入时要跳过的层数。值为1意味着将使用预最终层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_guidance_scale_embedding`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L497)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py#L497)'
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`timesteps` (`torch.Tensor`) — generate embedding vectors at these timesteps'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`torch.Tensor`) — 在这些时间步生成嵌入向量'
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) — dimension of the embeddings
    to generate dtype — data type of the generated embeddings'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dim` (`int`, *可选*, 默认为512) — 要生成的嵌入的维度 dtype — 生成的嵌入的数据类型'
- en: Returns
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为 `(len(timesteps), embedding_dim)` 的嵌入向量
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 参见 [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
- en: LatentConsistencyModelImg2ImgPipeline
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LatentConsistencyModelImg2ImgPipeline
- en: '### `class diffusers.LatentConsistencyModelImg2ImgPipeline`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.LatentConsistencyModelImg2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L131)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L131)'
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — 变分自动编码器（VAE）模型，用于对图像进行编码和解码，并转换为潜在表示。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — 冻结的文本编码器（clip-vit-large-patch14）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 用于对文本进行标记化的 `CLIPTokenizer`。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于降噪编码图像潜在的 `UNet2DConditionModel`。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Currently only supports [LCMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lcm#diffusers.LCMScheduler).'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 与 `unet` 结合使用的调度器，用于降噪编码图像潜在。目前仅支持 [LCMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lcm#diffusers.LCMScheduler)。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) — 用于估计生成的图像是否可能被视为具有冒犯性或有害的分类模块。请参考[模型卡片](https://huggingface.co/runwayml/stable-diffusion-v1-5)以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 用于从生成的图像中提取特征的 `CLIPImageProcessor`；作为 `safety_checker` 的输入。'
- en: '`requires_safety_checker` (`bool`, *optional*, defaults to `True`) — Whether
    the pipeline requires a safety checker component.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requires_safety_checker` (`bool`, *可选*, 默认为 `True`) — 管道是否需要安全检查器组件。'
- en: Pipeline for image-to-image generation using a latent consistency model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用潜在一致性模型进行图像生成的管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有管道实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道还继承了以下加载方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    用于加载 LoRA 权重'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    用于保存 LoRA 权重'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    用于加载 `.ckpt` 文件'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    用于加载 IP 适配器'
- en: '#### `__call__`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L692)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L692)'
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`, *可选*) — 用于指导图像生成的提示或提示。如果未定义，则需要传递 `prompt_embeds`。'
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The height in pixels of the generated image.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    — The width in pixels of the generated image.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 `self.unet.config.sample_size * self.vae_scale_factor`)
    — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 50) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`original_inference_steps` (`int`, *optional*) — The original number of inference
    steps use to generate a linearly-spaced timestep schedule, from which we will
    draw `num_inference_steps` evenly spaced timesteps from as our final timestep
    schedule, following the Skipping-Step method in the paper (see Section 4.3). If
    not set this will default to the scheduler’s `original_inference_steps` attribute.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`original_inference_steps` (`int`, *optional*) — 用于生成线性间隔时间步长计划的原始推断步数，从中我们将从中抽取
    `num_inference_steps` 等间隔时间步长作为我们的最终时间步长计划，遵循论文中的 Skipping-Step 方法（参见第 4.3 节）。如果未设置，这将默认为调度程序的
    `original_inference_steps` 属性。'
- en: '`timesteps` (`List[int]`, *optional*) — Custom timesteps to use for the denoising
    process. If not defined, equal spaced `num_inference_steps` timesteps on the original
    LCM training/distillation timestep schedule are used. Must be in descending order.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *optional*) — 用于去噪过程的自定义时间步长。如果未定义，则使用原始 LCM 训练/蒸馏时间步长计划上等间隔的
    `num_inference_steps` 时间步长。必须按降序排列。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`. Note that the original latent consistency models paper uses
    a different CFG formulation where the guidance scales are decreased by 1 (so in
    the paper formulation CFG is enabled when `guidance_scale > 0`).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — 更高的引导比例值鼓励模型生成与文本
    `prompt` 密切相关的图像，但会降低图像质量。当 `guidance_scale > 1` 时启用引导比例。请注意，原始潜变量一致性模型论文使用不同的
    CFG 公式，其中引导比例减少 1（因此在论文公式中，当 `guidance_scale > 0` 时启用 CFG）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — 用于使生成过程确定性的
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中采样的预生成噪声潜变量，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则通过使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument. ip_adapter_image —
    (`PipelineImageInput`, *optional*): Optional image input to work with IP Adapters.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松微调文本输入（提示加权）。如果未提供，则从
    `prompt` 输入参数生成文本嵌入。ip_adapter_image — (`PipelineImageInput`, *optional*): 与 IP
    适配器一起使用的可选图像输入。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择 `PIL.Image`
    或 `np.array` 之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回 [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    而不是普通元组。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，则将此 kwargs 字典传递给 [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    中定义的 `AttentionProcessor`。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 在计算提示嵌入时要从 CLIP 中跳过的层数。值为 1 表示将使用预终层的输出来计算提示嵌入。'
- en: '`callback_on_step_end` (`Callable`, *optional*) — A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end` (`Callable`, *optional*) — 在推断期间每个去噪步骤结束时调用的函数。该函数将使用以下参数调用：`callback_on_step_end(self:
    DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`。`callback_kwargs`
    将包括由 `callback_on_step_end_tensor_inputs` 指定的所有张量的列表。'
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) — `callback_on_step_end`
    函数的张量输入列表。列表中指定的张量将作为 `callback_kwargs` 参数传递。您只能包含在您的管道类的 `._callback_tensor_inputs`
    属性中列出的变量。'
- en: Returns
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个`tuple`，其中第一个元素是包含生成图像的列表，第二个元素是一个包含“不适宜工作”（nsfw）内容的`bool`列表。
- en: The call function to the pipeline for generation.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#### `enable_freeu`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L246)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L246)'
- en: '[PRE14]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`s1` (`float`) — Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s1` (`float`) — 第1阶段的缩放因子，用于减弱跳跃特征的贡献。这样做是为了减轻增强去噪过程中的“过度平滑效应”。'
- en: '`s2` (`float`) — Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate “oversmoothing effect” in the enhanced
    denoising process.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s2` (`float`) — 第2阶段的缩放因子，用于减弱跳跃特征的贡献。这样做是为了减轻增强去噪过程中的“过度平滑效应”。'
- en: '`b1` (`float`) — Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1` (`float`) — 第1阶段的缩放因子，用于放大骨干特征的贡献。'
- en: '`b2` (`float`) — Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b2` (`float`) — 第2阶段的缩放因子，用于放大骨干特征的贡献。'
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 启用FreeU机制，如[https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497)中所述。
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放因子后缀表示它们被应用的阶段。
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[官方存储库](https://github.com/ChenyangSi/FreeU)以获取已知适用于不同管道（如Stable Diffusion
    v1、v2和Stable Diffusion XL）的值组合。
- en: '#### `disable_freeu`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_freeu`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L269)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L269)'
- en: '[PRE15]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用，则禁用FreeU机制。
- en: '#### `enable_vae_slicing`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L213)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L213)'
- en: '[PRE16]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片VAE解码。当启用此选项时，VAE将在几个步骤中将输入张量分割成片段进行解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `disable_vae_slicing`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L221)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L221)'
- en: '[PRE17]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片VAE解码。如果之前启用了`enable_vae_slicing`，则此方法将回到一步计算解码。
- en: '#### `enable_vae_tiling`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L229)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L229)'
- en: '[PRE18]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺VAE解码。当启用此选项时，VAE将把输入张量分成瓦片，以便在几个步骤中进行解码和编码。这对于节省大量内存和允许处理更大的图像非常有用。
- en: '#### `disable_vae_tiling`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L238)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L238)'
- en: '[PRE19]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺VAE解码。如果之前启用了`enable_vae_tiling`，则此方法将回到一步计算解码。
- en: '#### `encode_prompt`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L274)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L274)'
- en: '[PRE20]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) — 要编码的提示设备 — (`torch.device`):
    torch设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用无分类器指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用来指导图像生成的提示。如果未定义，则必须传递`negative_prompt_embeds`。如果不使用指导（即如果`guidance_scale`小于`1`，则忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *可选*) — 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的LoRA比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *可选*) — 在计算提示嵌入时要跳过的CLIP层数。值为1意味着将使用预终层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_guidance_scale_embedding`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L584)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py#L584)'
- en: '[PRE21]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`timesteps` (`torch.Tensor`) — generate embedding vectors at these timesteps'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`torch.Tensor`) — 在这些时间步生成嵌入向量'
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) — dimension of the embeddings
    to generate dtype — data type of the generated embeddings'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dim` (`int`, *可选*, 默认为512) — 生成嵌入的维度 dtype — 生成的嵌入的数据类型'
- en: Returns
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 形状为`(len(timesteps), embedding_dim)`的嵌入向量
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 参见 [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
- en: StableDiffusionPipelineOutput
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE22]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为`batch_size`的去噪PIL图像列表或形状为`(batch_size,
    height, width, num_channels)`的NumPy数组。'
- en: '`nsfw_content_detected` (`List[bool]`) — List indicating whether the corresponding
    generated image contains “not-safe-for-work” (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) — 列表指示相应生成的图像是否包含“不适宜工作”（nsfw）内容，如果无法执行安全检查，则为`None`。'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散管道的输出类。
