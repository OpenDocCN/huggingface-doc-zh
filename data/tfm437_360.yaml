- en: Nougat
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nougat
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/nougat)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The Nougat model was proposed in [Nougat: Neural Optical Understanding for
    Academic Documents](https://arxiv.org/abs/2308.13418) by Lukas Blecher, Guillem
    Cucurull, Thomas Scialom, Robert Stojnic. Nougat uses the same architecture as
    [Donut](donut), meaning an image Transformer encoder and an autoregressive text
    Transformer decoder to translate scientific PDFs to markdown, enabling easier
    access to them.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'Nougat模型是由Lukas Blecher、Guillem Cucurull、Thomas Scialom、Robert Stojnic提出的[Nougat:
    用于学术文档的神经光学理解](https://arxiv.org/abs/2308.13418)。Nougat使用与[Donut](donut)相同的架构，即图像Transformer编码器和自回归文本Transformer解码器，将科学PDF转换为标记，使其更易于访问。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Scientific knowledge is predominantly stored in books and scientific journals,
    often in the form of PDFs. However, the PDF format leads to a loss of semantic
    information, particularly for mathematical expressions. We propose Nougat (Neural
    Optical Understanding for Academic Documents), a Visual Transformer model that
    performs an Optical Character Recognition (OCR) task for processing scientific
    documents into a markup language, and demonstrate the effectiveness of our model
    on a new dataset of scientific documents. The proposed approach offers a promising
    solution to enhance the accessibility of scientific knowledge in the digital age,
    by bridging the gap between human-readable documents and machine-readable text.
    We release the models and code to accelerate future work on scientific text recognition.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*科学知识主要存储在书籍和科学期刊中，通常以PDF形式存在。然而，PDF格式会导致语义信息的丢失，特别是对于数学表达式。我们提出了Nougat（用于学术文档的神经光学理解），这是一个视觉Transformer模型，用于将科学文档进行光学字符识别（OCR）任务，转换为标记语言，并展示了我们的模型在新的科学文档数据集上的有效性。所提出的方法为增强数字时代科学知识的可访问性提供了一个有希望的解决方案，通过弥合人类可读文档和机器可读文本之间的差距。我们发布了模型和代码，以加速未来关于科学文本识别的工作。*'
- en: '![drawing](../Images/815b74c6366c16cb9cb90a9d9b246b4c.png) Nougat high-level
    overview. Taken from the [original paper](https://arxiv.org/abs/2308.13418).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![图示](../Images/815b74c6366c16cb9cb90a9d9b246b4c.png) Nougat高层概述。摘自[原始论文](https://arxiv.org/abs/2308.13418)。'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/facebookresearch/nougat).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[nielsr](https://huggingface.co/nielsr)贡献。原始代码可在[此处](https://github.com/facebookresearch/nougat)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: The quickest way to get started with Nougat is by checking the [tutorial notebooks](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Nougat),
    which show how to use the model at inference time as well as fine-tuning on custom
    data.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用Nougat的最快方法是查看[教程笔记本](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Nougat)，展示了如何在推理时使用模型以及在自定义数据上进行微调。
- en: Nougat is always used within the [VisionEncoderDecoder](vision-encoder-decoder)
    framework. The model is identical to [Donut](donut) in terms of architecture.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nougat始终在[VisionEncoderDecoder](vision-encoder-decoder)框架内使用。该模型在架构上与[Donut](donut)相同。
- en: Inference
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: Nougat’s `VisionEncoderDecoder` model accepts images as input and makes use
    of [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    to autoregressively generate text given the input image.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Nougat的`VisionEncoderDecoder`模型接受图像作为输入，并利用[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)来自动回归生成给定输入图像的文本。
- en: The [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    class is responsible for preprocessing the input image and [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)
    decodes the generated target tokens to the target string. The [NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)
    wraps [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    and [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)
    classes into a single instance to both extract the input features and decode the
    predicted token ids.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)类负责预处理输入图像，[NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)解码生成的目标标记为目标字符串。[NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)将[NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)和[NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)类封装为单个实例，用于提取输入特征和解码预测的标记ID。'
- en: Step-by-step PDF transcription
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步PDF转录
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: See the [model hub](https://huggingface.co/models?filter=nougat) to look for
    Nougat checkpoints.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看[模型中心](https://huggingface.co/models?filter=nougat)以查找Nougat检查点。
- en: The model is identical to [Donut](donut) in terms of architecture.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在架构上与[Donut](donut)相同。
- en: NougatImageProcessor
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NougatImageProcessor
- en: '### `class transformers.NougatImageProcessor`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.NougatImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L57)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L57)'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_crop_margin` (`bool`, *optional*, defaults to `True`) — Whether to crop
    the image margins.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_crop_margin`（`bool`，*可选*，默认为`True`）— 是否裁剪图像边距。'
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions to the specified `size`. Can be overridden
    by `do_resize` in the `preprocess` method.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`（`bool`，*可选*，默认为`True`）— 是否将图像的（高度，宽度）尺寸调整为指定的`size`。可以在`preprocess`方法中通过`do_resize`进行覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 896, "width":
    672}`): Size of the image after resizing. Can be overridden by `size` in the `preprocess`
    method.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *可选*, 默认为 `{"height" -- 896, "width": 672}`): 调整大小后的图像尺寸。可以被
    `preprocess` 方法中的 `size` 覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`)
    — Resampling filter to use if resizing the image. Can be overridden by `resample`
    in the `preprocess` method.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *可选*, 默认为 `Resampling.BILINEAR`) — 如果调整图像大小，则使用的重采样滤波器。可以被
    `preprocess` 方法中的 `resample` 覆盖。'
- en: '`do_thumbnail` (`bool`, *optional*, defaults to `True`) — Whether to resize
    the image using thumbnail method.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_thumbnail` (`bool`, *可选*, 默认为 `True`) — 是否使用缩略图方法调整图像大小。'
- en: '`do_align_long_axis` (`bool`, *optional*, defaults to `False`) — Whether to
    align the long axis of the image with the long axis of `size` by rotating by 90
    degrees.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_align_long_axis` (`bool`, *可选*, 默认为 `False`) — 是否通过旋转 90 度来使图像的长轴与 `size`
    的长轴对齐。'
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) — Whether to pad the images
    to the largest image size in the batch.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *可选*, 默认为 `True`) — 是否将图像填充到批处理中最大的图像尺寸。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`
    parameter in the `preprocess` method.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *可选*, 默认为 `True`) — 是否按指定比例 `rescale_factor` 重新缩放图像。可以被
    `preprocess` 方法中的 `do_rescale` 参数覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in the `preprocess` method.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` 或 `float`, *可选*, 默认为 `1/255`) — 如果重新缩放图像，则使用的缩放因子。可以被
    `preprocess` 方法中的 `rescale_factor` 参数覆盖。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by `do_normalize` in the `preprocess` method.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *可选*, 默认为 `True`) — 是否对图像进行归一化。可以被 `preprocess` 方法中的
    `do_normalize` 覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `IMAGENET_DEFAULT_MEAN`) —
    如果归一化图像，则使用的均值。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_mean` 参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`)
    — Image standard deviation.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *可选*, 默认为 `IMAGENET_DEFAULT_STD`) — 图像标准差。'
- en: Constructs a Nougat image processor.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 构建 Nougat 图像处理器。
- en: '#### `preprocess`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L358)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/image_processing_nougat.py#L358)'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像。期望单个图像或批处理图像，像素值范围为 0 到 255。'
- en: '`do_crop_margin` (`bool`, *optional*, defaults to `self.do_crop_margin`) —
    Whether to crop the image margins.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_crop_margin` (`bool`, *可选*, 默认为 `self.do_crop_margin`) — 是否裁剪图像边缘。'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *可选*, 默认为 `self.do_resize`) — 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Size of the
    image after resizing. Shortest edge of the image is resized to min(size[“height”],
    size[“width”]) with the longest edge resized to keep the input aspect ratio.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *可选*, 默认为 `self.size`) — 调整大小后的图像尺寸。图像的最短边调整为 min(size[“height”],
    size[“width”])，最长边调整以保持输入的长宽比。'
- en: '`resample` (`int`, *optional*, defaults to `self.resample`) — Resampling filter
    to use if resizing the image. This can be one of the enum `PILImageResampling`.
    Only has an effect if `do_resize` is set to `True`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`int`, *可选*, 默认为 `self.resample`) — 如果调整图像大小，则使用的重采样滤波器。这可以是枚举
    `PILImageResampling` 中的一个。仅当 `do_resize` 设置为 `True` 时才会生效。'
- en: '`do_thumbnail` (`bool`, *optional*, defaults to `self.do_thumbnail`) — Whether
    to resize the image using thumbnail method.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_thumbnail` (`bool`, *可选*, 默认为 `self.do_thumbnail`) — 是否使用缩略图方法调整图像大小。'
- en: '`do_align_long_axis` (`bool`, *optional*, defaults to `self.do_align_long_axis`)
    — Whether to align the long axis of the image with the long axis of `size` by
    rotating by 90 degrees.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_align_long_axis` (`bool`, *可选*, 默认为 `self.do_align_long_axis`) — 是否通过旋转
    90 度来使图像的长轴与 `size` 的长轴对齐。'
- en: '`do_pad` (`bool`, *optional*, defaults to `self.do_pad`) — Whether to pad the
    images to the largest image size in the batch.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *可选*, 默认为 `self.do_pad`) — 是否将图像填充到批处理中最大的图像尺寸。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image by the specified scale `rescale_factor`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *可选*, 默认为 `self.do_rescale`) — 是否按指定比例 `rescale_factor`
    重新缩放图像。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `self.rescale_factor`)
    — Scale factor to use if rescaling the image.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` 或 `float`, *可选*, 默认为 `self.rescale_factor`) — 如果重新缩放图像，则使用的缩放因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *可选*, 默认为 `self.do_normalize`) — 是否对图像进行归一化。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    — Image mean to use for normalization.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `self.image_mean`) — 用于归一化的图像均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    — Image standard deviation to use for normalization.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *可选*, 默认为 `self.image_std`) — 用于归一化的图像标准差。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 `TensorType`, *可选*) — 要返回的张量类型。可以是以下之一:'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '未设置: 返回 `np.ndarray` 的列表。'
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW` 或 `''tf''`: 返回类型为 `tf.Tensor` 的批处理。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` 或 `''pt''`: 返回类型为 `torch.Tensor` 的批处理。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY` 或 `''np''`: 返回类型为 `np.ndarray` 的批处理。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX` 或 `''jax''`: 返回类型为 `jax.numpy.ndarray` 的批处理。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` 或 `str`, *optional*, 默认为 `ChannelDimension.FIRST`)
    — 输出图像的通道维度格式。可以是以下之一：'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`: 图像格式为 (num_channels, height, width)。'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`: 图像格式为 (height, width, num_channels)。'
- en: 'Unset: defaults to the channel dimension format of the input image.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：默认为输入图像的通道维度格式。
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format` (`ChannelDimension` 或 `str`, *optional*) — 输入图像的通道维度格式。如果未设置，将从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` 或 `ChannelDimension.FIRST`: 图像格式为 (num_channels, height,
    width)。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` 或 `ChannelDimension.LAST`: 图像格式为 (height, width, num_channels)。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` 或 `ChannelDimension.NONE`: 图像格式为 (height, width)。'
- en: Preprocess an image or batch of images.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一张图片或一批图片。
- en: NougatTokenizerFast
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NougatTokenizerFast
- en: '### `class transformers.NougatTokenizerFast`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.NougatTokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L376)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L376)'
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`, *optional*) — [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a .model extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`, *optional*) — [SentencePiece](https://github.com/google/sentencepiece)
    文件（通常具有 .model 扩展名），其中包含实例化分词器所需的词汇表。'
- en: '`tokenizer_file` (`str`, *optional*) — [tokenizers](https://github.com/huggingface/tokenizers)
    file (generally has a .json extension) that contains everything needed to load
    the tokenizer.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_file` (`str`, *optional*) — [tokenizers](https://github.com/huggingface/tokenizers)
    文件（通常具有 .json 扩展名），其中包含加载分词器所需的所有内容。'
- en: '`clean_up_tokenization_spaces` (`str`, *optional*, defaults to `False`) — Wether
    to cleanup spaces after decoding, cleanup consists in removing potential artifacts
    like extra spaces.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces` (`str`, *optional*, 默认为 `False`) — 解码后是否清除空格，清除包括删除额外空格等潜在瑕疵。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, 默认为 `"<unk>"`) — 未知标记。词汇表中不存在的标记无法转换为 ID，而是设置为此标记。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — The beginning of sequence
    token that was used during pretraining. Can be used a sequence classifier token.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *optional*, 默认为 `"<s>"`) — 在预训练期间使用的序列开始标记。可用作序列分类器标记。'
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — The end of sequence
    token.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *optional*, 默认为 `"</s>"`) — 序列结束标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, 默认为 `"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`model_max_length` (`int`, *optional*) — The maximum length (in number of tokens)
    for the inputs to the transformer model. When the tokenizer is loaded with [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained),
    this will be set to the value stored for the associated model in `max_model_input_sizes`
    (see above). If no value is provided, will default to VERY_LARGE_INTEGER (`int(1e30)`).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_max_length` (`int`, *optional*) — 转换器模型输入的最大长度（以标记数计）。当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)
    加载分词器时，将设置为存储在 `max_model_input_sizes` 中的相关模型的值（请参见上文）。如果未提供值，将默认为 VERY_LARGE_INTEGER
    (`int(1e30)`）。'
- en: '`padding_side` (`str`, *optional*) — The side on which the model should have
    padding applied. Should be selected between [‘right’, ‘left’]. Default value is
    picked from the class attribute of the same name.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_side` (`str`, *optional*) — 模型应用填充的侧面。应在 [''right'', ''left''] 中选择。默认值从同名的类属性中选择。'
- en: '`truncation_side` (`str`, *optional*) — The side on which the model should
    have truncation applied. Should be selected between [‘right’, ‘left’]. Default
    value is picked from the class attribute of the same name.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_side` (`str`, *optional*) — 模型应用截断的侧面。应在 [''right'', ''left'']
    中选择。默认值从同名的类属性中选择。'
- en: '`chat_template` (`str`, *optional*) — A Jinja template string that will be
    used to format lists of chat messages. See [https://huggingface.co/docs/transformers/chat_templating](https://huggingface.co/docs/transformers/chat_templating)
    for a full description.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chat_template` (`str`, *optional*) — 一个 Jinja 模板字符串，用于格式化聊天消息列表。详细描述请参见 [https://huggingface.co/docs/transformers/chat_templating](https://huggingface.co/docs/transformers/chat_templating)。'
- en: '`model_input_names` (`List[string]`, *optional*) — The list of inputs accepted
    by the forward pass of the model (like `"token_type_ids"` or `"attention_mask"`).
    Default value is picked from the class attribute of the same name.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input_names` (`List[string]`, *optional*) — 模型前向传递接受的输入列表（如 `"token_type_ids"`
    或 `"attention_mask"`）。默认值从同名的类属性中选择。'
- en: '`bos_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the beginning of a sentence. Will be associated to `self.bos_token`
    and `self.bos_token_id`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str` 或 `tokenizers.AddedToken`, *optional*) — 表示句子开头的特殊标记。将与
    `self.bos_token` 和 `self.bos_token_id` 关联。'
- en: '`eos_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the end of a sentence. Will be associated to `self.eos_token` and
    `self.eos_token_id`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表句子结束的特殊标记。将与`self.eos_token`和`self.eos_token_id`相关联。'
- en: '`unk_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing an out-of-vocabulary token. Will be associated to `self.unk_token`
    and `self.unk_token_id`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表词汇外标记的特殊标记。将与`self.unk_token`和`self.unk_token_id`相关联。'
- en: '`sep_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    separating two different sentences in the same input (used by BERT for instance).
    Will be associated to `self.sep_token` and `self.sep_token_id`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token`（`str`或`tokenizers.AddedToken`，*可选*）— 用于在同一输入中分隔两个不同句子的特殊标记（例如BERT使用）。将与`self.sep_token`和`self.sep_token_id`相关联。'
- en: '`pad_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    used to make arrays of tokens the same size for batching purpose. Will then be
    ignored by attention mechanisms or loss computation. Will be associated to `self.pad_token`
    and `self.pad_token_id`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token`（`str`或`tokenizers.AddedToken`，*可选*）— 用于使标记数组大小相同以进行批处理的特殊标记。然后将被注意机制或损失计算忽略。将与`self.pad_token`和`self.pad_token_id`相关联。'
- en: '`cls_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the class of the input (used by BERT for instance). Will be associated
    to `self.cls_token` and `self.cls_token_id`.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表输入类别的特殊标记（例如BERT使用）。将与`self.cls_token`和`self.cls_token_id`相关联。'
- en: '`mask_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing a masked token (used by masked-language modeling pretraining objectives,
    like BERT). Will be associated to `self.mask_token` and `self.mask_token_id`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表掩码标记的特殊标记（用于掩码语言建模预训练目标，如BERT）。将与`self.mask_token`和`self.mask_token_id`相关联。'
- en: '`additional_special_tokens` (tuple or list of `str` or `tokenizers.AddedToken`,
    *optional*) — A tuple or a list of additional special tokens. Add them here to
    ensure they are skipped when decoding with `skip_special_tokens` is set to True.
    If they are not part of the vocabulary, they will be added at the end of the vocabulary.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`additional_special_tokens`（元组或`str`或`tokenizers.AddedToken`，*可选*）— 一组额外的特殊标记。在这里添加它们以确保在将`skip_special_tokens`设置为True时解码时跳过它们。如果它们不是词汇的一部分，它们将被添加到词汇的末尾。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `True`) — Whether
    or not the model should cleanup the spaces that were added when splitting the
    input text during the tokenization process.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*，默认为`True`）— 模型是否应清除在标记化过程中拆分输入文本时添加的空格。'
- en: '`split_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the special tokens should be split during the tokenization process. The
    default behavior is to not split special tokens. This means that if `<s>` is the
    `bos_token`, then `tokenizer.tokenize("<s>") = [''<s>`]. Otherwise, if `split_special_tokens=True`,
    then `tokenizer.tokenize("<s>")` will be give `[''<'', ''s'', ''>'']`. This argument
    is only supported for `slow` tokenizers for the moment.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split_special_tokens`（`bool`，*可选*，默认为`False`）— 是否在标记化过程中拆分特殊标记。默认行为是不拆分特殊标记。这意味着如果`<s>`是`bos_token`，那么`tokenizer.tokenize("<s>")
    = [''<s>`]`。否则，如果`split_special_tokens=True`，那么`tokenizer.tokenize("<s>")`将给出`[''<'',
    ''s'', ''>'']`。此参数目前仅支持`slow`分词器。'
- en: '`tokenizer_object` (`tokenizers.Tokenizer`) — A `tokenizers.Tokenizer` object
    from 🤗 tokenizers to instantiate from. See [Using tokenizers from 🤗 tokenizers](../fast_tokenizers)
    for more information.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_object`（`tokenizers.Tokenizer`）— 来自🤗 tokenizers的`tokenizers.Tokenizer`对象，用于实例化。有关更多信息，请参阅[使用🤗
    tokenizers中的分词器](../fast_tokenizers)。'
- en: '`tokenizer_file` (`str`) — A path to a local JSON file representing a previously
    serialized `tokenizers.Tokenizer` object from 🤗 tokenizers.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_file`（`str`）— 代表以前序列化的`tokenizers.Tokenizer`对象的本地JSON文件的路径。'
- en: Fast tokenizer for Nougat (backed by HuggingFace tokenizers library).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Nougat的快速分词器（由HuggingFace分词器库支持）。
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods. This class mainly adds Nougat-specific
    methods for postprocessing the generated text.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分词器继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)，其中包含大多数主要方法。用户应参考这个超类以获取有关这些方法的更多信息。这个类主要为后处理生成的文本添加了Nougat特定的方法。
- en: Class attributes (overridden by derived classes)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 类属性（由派生类覆盖）
- en: '`vocab_files_names` (`Dict[str, str]`) — A dictionary with, as keys, the `__init__`
    keyword name of each vocabulary file required by the model, and as associated
    values, the filename for saving the associated file (string).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_files_names`（`Dict[str, str]`）— 一个字典，其键是模型所需的每个词汇文件的`__init__`关键字名称，其相关值是用于保存相关文件的文件名（字符串）。'
- en: '`pretrained_vocab_files_map` (`Dict[str, Dict[str, str]]`) — A dictionary of
    dictionaries, with the high-level keys being the `__init__` keyword name of each
    vocabulary file required by the model, the low-level being the `short-cut-names`
    of the pretrained models with, as associated values, the `url` to the associated
    pretrained vocabulary file.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_vocab_files_map`（`Dict[str, Dict[str, str]]`）— 一个字典，其中高级键是模型所需的每个词汇文件的`__init__`关键字名称，低级别是预训练模型的`short-cut-names`，作为相关值，是与相关预训练词汇文件相关联的`url`。'
- en: '`max_model_input_sizes` (`Dict[str, Optional[int]]`) — A dictionary with, as
    keys, the `short-cut-names` of the pretrained models, and as associated values,
    the maximum length of the sequence inputs of this model, or `None` if the model
    has no maximum input size.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_model_input_sizes`（`Dict[str, Optional[int]]`）— 一个字典，其键是预训练模型的`short-cut-names`，其相关值是该模型的序列输入的最大长度，如果模型没有最大输入大小，则为`None`。'
- en: '`pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) — A dictionary
    with, as keys, the `short-cut-names` of the pretrained models, and as associated
    values, a dictionary of specific arguments to pass to the `__init__` method of
    the tokenizer class for this pretrained model when loading the tokenizer with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)
    method.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) — 一个字典，键为预训练模型的`short-cut-names`，值为传递给加载预训练模型时tokenizer类的`__init__`方法的特定参数的字典。'
- en: '`model_input_names` (`List[str]`) — A list of inputs expected in the forward
    pass of the model.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input_names` (`List[str]`) — 模型前向传递中预期的输入列表。'
- en: '`padding_side` (`str`) — The default value for the side on which the model
    should have padding applied. Should be `''right''` or `''left''`.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_side` (`str`) — 模型应该应用填充的默认值。应为`''right''`或`''left''`。'
- en: '`truncation_side` (`str`) — The default value for the side on which the model
    should have truncation applied. Should be `''right''` or `''left''`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_side` (`str`) — 模型应该应用截断的默认值。应为`''right''`或`''left''`。'
- en: '#### `correct_tables`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `correct_tables`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L470)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L470)'
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`generation` (str) — The generated text to be postprocessed.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation` (str) — 要进行后处理的生成文本。'
- en: Returns
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: str
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: The postprocessed text.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理的文本。
- en: Takes a generated string and fixes tables/tabulars to make them match the markdown
    format needed.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接受一个生成的字符串，并修复表格/表格，使其符合所需的Markdown格式。
- en: 'Example:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `post_process_generation`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_generation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L600)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L600)'
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`generation` (Union[str, List[str]]) — The generated text or a list of generated
    texts.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation` (Union[str, List[str]]) — 生成的文本或生成的文本列表。'
- en: '`fix_markdown` (`bool`, *optional*, defaults to `True`) — Whether to perform
    Markdown formatting fixes.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fix_markdown` (`bool`, *可选*, 默认为 `True`) — 是否执行Markdown格式修复。'
- en: '`num_workers` (`int`, *optional*) — Optional number of workers to pass to leverage
    multiprocessing (postprocessing several texts in parallel).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers` (`int`, *可选*) — 传递给利用多进程的工作人员数量（并行后处理多个文本）。'
- en: Returns
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: Union[str, List[str]]
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Union[str, List[str]]
- en: The postprocessed text or list of postprocessed texts.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理的文本或后处理文本列表。
- en: Postprocess a generated text or a list of generated texts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理生成的文本或生成的文本列表。
- en: This function can be used to perform postprocessing on generated text, such
    as fixing Markdown formatting.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数可用于对生成的文本执行后处理，例如修复Markdown格式。
- en: Postprocessing is quite slow so it is recommended to use multiprocessing to
    speed up the process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理速度较慢，建议使用多进程加快处理速度。
- en: '#### `post_process_single`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_single`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L505)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L505)'
- en: '[PRE7]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`generation` (str) — The generated text to be postprocessed.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation` (str) — 要进行后处理的生成文本。'
- en: '`fix_markdown` (bool, optional) — Whether to perform Markdown formatting fixes.
    Default is True.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fix_markdown` (bool, optional) — 是否执行Markdown格式修复。默认为True。'
- en: Returns
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: str
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: The postprocessed text.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理的文本。
- en: Postprocess a single generated text. Regular expressions used here are taken
    directly from the Nougat article authors. These expressions are commented for
    clarity and tested end-to-end in most cases.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理单个生成的文本。此处使用的正则表达式直接来自Nougat文章作者。这些表达式已经过注释以确保清晰，并在大多数情况下进行了端到端测试。
- en: '#### `remove_hallucinated_references`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `remove_hallucinated_references`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L440)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/tokenization_nougat_fast.py#L440)'
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The input text containing references.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 包含引用的输入文本。'
- en: Returns
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The text with hallucinated references removed.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 删除虚构引用的文本。
- en: Remove hallucinated or missing references from the text.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本中删除虚构或缺失的引用。
- en: This function identifies and removes references that are marked as missing or
    hallucinated from the input text.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数识别并删除输入文本中标记为缺失或虚构的引用。
- en: NougatProcessor
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NougatProcessor
- en: '### `class transformers.NougatProcessor`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.NougatProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L27)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L27)'
- en: '[PRE9]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` ([NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor))
    — An instance of [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor).
    The image processor is a required input.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` ([NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor))
    — 一个[NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)的实例。图像处理器是必需的输入。'
- en: '`tokenizer` ([NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast))
    — An instance of [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast).
    The tokenizer is a required input.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast))
    — 一个[NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)的实例。分词器是必需的输入。'
- en: Constructs a Nougat processor which wraps a Nougat image processor and a Nougat
    tokenizer into a single processor.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Nougat处理器，将Nougat图像处理器和Nougat tokenizer包装成一个单一处理器。
- en: '[NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)
    offers all the functionalities of [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    and [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast).
    See the [**call**()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.__call__)
    and [decode()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.decode)
    for more information.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[NougatProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor)
    提供了 [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    和 [NougatTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatTokenizerFast)
    的所有功能。有关更多信息，请参考 [**call**()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.__call__)
    和 [decode()](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatProcessor.decode)。 '
- en: '#### `__call__`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L49)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L49)'
- en: '[PRE10]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `from_pretrained`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE11]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练特征提取器的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    方法保存的特征提取器文件的 *目录* 路径，例如 `./my_model_directory/`。
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs — Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已保存的特征提取器 JSON *文件* 的路径或 URL，例如 `./my_model_directory/preprocessor_config.json`。**kwargs
    — 传递给 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    和 `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` 的额外关键字参数。
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化与预训练模型相关联的处理器。
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用特征提取器 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)、图像处理器
    [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    和分词器 `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` 方法。有关更多信息，请参考上述方法的文档字符串。
- en: '#### `save_pretrained`'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE12]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` or `os.PathLike`) — 将保存特征提取器 JSON 文件和分词器文件的目录（如果目录不存在，则将创建）。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — 是否在保存模型后将其推送到Hugging
    Face模型中心。您可以使用 `repo_id` 指定要推送到的存储库（将默认为您的命名空间中的 `save_directory` 名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *optional*) — 传递给 [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    方法的额外关键字参数。'
- en: Saves the attributes of this processor (feature extractor, tokenizer…) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处理器的属性（特征提取器、分词器等）保存在指定的目录中，以便可以使用 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    方法重新加载。
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    和 [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)。有关更多信息，请参考上述方法的文档字符串。
- en: '#### `batch_decode`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L141)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L141)'
- en: '[PRE13]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This method forwards all its arguments to NougatTokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法将所有参数转发给NougatTokenizer的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。请参考此方法的文档字符串以获取更多信息。
- en: '#### `decode`'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `解码`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L148)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L148)'
- en: '[PRE14]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This method forwards all its arguments to NougatTokenizer’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法将所有参数转发给NougatTokenizer的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。请参考此方法的文档字符串以获取更多信息。
- en: '#### `post_process_generation`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `后处理生成`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L155)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/nougat/processing_nougat.py#L155)'
- en: '[PRE15]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This method forwards all its arguments to NougatTokenizer’s `~PreTrainedTokenizer.post_process_generation`.
    Please refer to the docstring of this method for more information.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法将所有参数转发给NougatTokenizer的`~PreTrainedTokenizer.post_process_generation`。请参考此方法的文档字符串以获取更多信息。
