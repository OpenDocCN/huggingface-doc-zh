- en: DiT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DiT
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/dit](https://huggingface.co/docs/diffusers/api/pipelines/dit)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/dit](https://huggingface.co/docs/diffusers/api/pipelines/dit)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Scalable Diffusion Models with Transformers](https://huggingface.co/papers/2212.09748)
    (DiT) is by William Peebles and Saining Xie.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[具有变压器的可扩展扩散模型](https://huggingface.co/papers/2212.09748)（DiT）由William Peebles和Saining
    Xie撰写。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要为：
- en: '*We explore a new class of diffusion models based on the transformer architecture.
    We train latent diffusion models of images, replacing the commonly-used U-Net
    backbone with a transformer that operates on latent patches. We analyze the scalability
    of our Diffusion Transformers (DiTs) through the lens of forward pass complexity
    as measured by Gflops. We find that DiTs with higher Gflops — through increased
    transformer depth/width or increased number of input tokens — consistently have
    lower FID. In addition to possessing good scalability properties, our largest
    DiT-XL/2 models outperform all prior diffusion models on the class-conditional
    ImageNet 512x512 and 256x256 benchmarks, achieving a state-of-the-art FID of 2.27
    on the latter.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们探索了一类基于变压器架构的扩散模型。我们训练了图像的潜在扩散模型，用一个在潜在补丁上操作的变压器替换了常用的U-Net骨干。我们通过Gflops测量的前向传递复杂性的角度分析了我们的扩散变压器（DiTs）的可扩展性。我们发现具有更高Gflops的DiTs
    - 通过增加变压器深度/宽度或增加输入令牌数量 - 一贯具有较低的FID。除了具有良好的可扩展性属性外，我们最大的DiT-XL/2模型在类条件ImageNet
    512x512和256x256基准上表现优于所有先前的扩散模型，实现了256x256基准的最新FID为2.27。*'
- en: The original codebase can be found at [facebookresearch/dit](https://github.com/facebookresearch/dit).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可以在[facebookresearch/dit](https://github.com/facebookresearch/dit)找到。
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 确保查看调度器[指南](../../using-diffusers/schedulers)以了解如何探索调度器速度和质量之间的权衡，并查看[跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)部分以了解如何有效地将相同组件加载到多个管道中。
- en: DiTPipeline
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DiTPipeline
- en: '### `class diffusers.DiTPipeline`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.DiTPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L31)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L31)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`transformer` ([Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel))
    — A class conditioned `Transformer2DModel` to denoise the encoded image latents.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer`（[Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel)）
    - 一个条件化的`Transformer2DModel`类，用于去噪编码图像潜在。'
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`（[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)）
    - 变分自动编码器（VAE）模型，用于对图像进行编码和解码到和从潜在表示。'
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `transformer` to denoise the encoded
    image latents.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)）
    - 与`transformer`结合使用以去噪编码图像潜在的调度器。'
- en: Pipeline for image generation based on a Transformer backbone instead of a UNet.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基于变压器骨干而不是UNet的图像生成管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解为所有管道实现的通用方法（下载、保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L92)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L92)'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`class_labels` (List[int]) — List of ImageNet class labels for the images to
    be generated.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_labels`（List[int]） - 要生成图像的ImageNet类标签列表。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale`（`float`，*可选*，默认为4.0） - 更高的引导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但以较低的图像质量为代价。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`，*可选*） - 用于使生成具有确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 250) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`（`int`，*可选*，默认为250） - 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type`（`str`，*可选*，默认为`"pil"`） - 生成图像的输出格式。选择`PIL.Image`或`np.array`之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`） - 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)或`tuple`'
- en: If `return_dict` is `True`, [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)，否则返回一个元组，其中第一个元素是包含生成图像的列表
- en: The call function to the pipeline for generation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: 'Examples:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `get_label_ids`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_label_ids`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L67)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L67)'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`label` (`str` or `dict` of `str`) — Label strings to be mapped to class ids.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label` (`str`或`str`的`dict`) — 要映射到类别ID的标签字符串。'
- en: Returns
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`list` of `int`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`的`列表`'
- en: Class ids to be processed by pipeline.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要由管道处理的类别ID。
- en: Map label strings from ImageNet to corresponding class ids.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将ImageNet中的标签字符串映射到相应的类别ID。
- en: ImagePipelineOutput
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ImagePipelineOutput
- en: '### `class diffusers.ImagePipelineOutput`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.ImagePipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L116)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L116)'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]`或`np.ndarray`) — 长度为`batch_size`的去噪PIL图像列表或形状为`(batch_size,
    height, width, num_channels)`的NumPy数组。'
- en: Output class for image pipelines.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于图像管道的输出类。
