- en: ResNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ResNet
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/resnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/resnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/resnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/resnet)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The ResNet model was proposed in [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
    by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun. Our implementation follows
    the small changes made by [Nvidia](https://catalog.ngc.nvidia.com/orgs/nvidia/resources/resnet_50_v1_5_for_pytorch),
    we apply the `stride=2` for downsampling in bottleneck’s `3x3` conv and not in
    the first `1x1`. This is generally known as “ResNet v1.5”.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet模型是由Kaiming He、Xiangyu Zhang、Shaoqing Ren和Jian Sun在[图像识别的深度残差学习](https://arxiv.org/abs/1512.03385)中提出的。我们的实现遵循了[Nvidia](https://catalog.ngc.nvidia.com/orgs/nvidia/resources/resnet_50_v1_5_for_pytorch)所做的小改动，我们在瓶颈的`3x3`卷积中应用`stride=2`进行下采样，而不是在第一个`1x1`中。这通常被称为“ResNet
    v1.5”。
- en: ResNet introduced residual connections, they allow to train networks with an
    unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition,
    one important milestone in deep computer vision.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet引入了残差连接，它们允许训练具有未知层数（高达1000层）的网络。ResNet赢得了2015年ILSVRC和COCO竞赛，这是深度计算机视觉的一个重要里程碑。
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的摘要如下：
- en: '*Deeper neural networks are more difficult to train. We present a residual
    learning framework to ease the training of networks that are substantially deeper
    than those used previously. We explicitly reformulate the layers as learning residual
    functions with reference to the layer inputs, instead of learning unreferenced
    functions. We provide comprehensive empirical evidence showing that these residual
    networks are easier to optimize, and can gain accuracy from considerably increased
    depth. On the ImageNet dataset we evaluate residual nets with a depth of up to
    152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble
    of these residual nets achieves 3.57% error on the ImageNet test set. This result
    won the 1st place on the ILSVRC 2015 classification task. We also present analysis
    on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central
    importance for many visual recognition tasks. Solely due to our extremely deep
    representations, we obtain a 28% relative improvement on the COCO object detection
    dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO
    2015 competitions, where we also won the 1st places on the tasks of ImageNet detection,
    ImageNet localization, COCO detection, and COCO segmentation.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*更深的神经网络更难训练。我们提出了一个残差学习框架，以便训练比以前使用的网络更深的网络变得更容易。我们明确地将层重新构建为学习残差函数，参考层输入，而不是学习无参考的函数。我们提供了全面的实证证据，表明这些残差网络更容易优化，并且可以从明显增加的深度中获得准确性。在ImageNet数据集上，我们评估了深度高达152层的残差网络---比VGG网络深8倍，但仍具有较低的复杂性。这些残差网络的集合在ImageNet测试集上实现了3.57%的错误率。这一结果赢得了ILSVRC
    2015分类任务的第一名。我们还对具有100和1000层的CIFAR-10进行了分析。表示的深度对许多视觉识别任务至关重要。仅仅由于我们极其深的表示，我们在COCO目标检测数据集上获得了28%的相对改进。深度残差网络是我们提交给ILSVRC和COCO
    2015竞赛的基础，我们还在ImageNet检测、ImageNet定位、COCO检测和COCO分割任务上获得了第一名。*'
- en: The figure below illustrates the architecture of ResNet. Taken from the [original
    paper](https://arxiv.org/abs/1512.03385).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示了ResNet的架构。取自[原始论文](https://arxiv.org/abs/1512.03385)。
- en: '![](../Images/9ccad54651391b48289acb1dad8b77f1.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ccad54651391b48289acb1dad8b77f1.png)'
- en: This model was contributed by [Francesco](https://huggingface.co/Francesco).
    The TensorFlow version of this model was added by [amyeroberts](https://huggingface.co/amyeroberts).
    The original code can be found [here](https://github.com/KaimingHe/deep-residual-networks).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型由[Francesco](https://huggingface.co/Francesco)贡献。这个模型的TensorFlow版本是由[amyeroberts](https://huggingface.co/amyeroberts)添加的。原始代码可以在[这里](https://github.com/KaimingHe/deep-residual-networks)找到。
- en: Resources
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with ResNet.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个官方Hugging Face和社区（由🌎表示）资源列表，帮助您开始使用ResNet。
- en: Image Classification
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类
- en: '[ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)由这个[示例脚本](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)和[笔记本](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)支持。'
- en: 'See also: [Image classification task guide](../tasks/image_classification)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参见：[图像分类任务指南](../tasks/image_classification)
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we’ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在这里，请随时打开一个拉取请求，我们将对其进行审查！资源应该理想地展示一些新东西，而不是重复现有资源。
- en: ResNetConfig
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ResNetConfig
- en: '### `class transformers.ResNetConfig`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ResNetConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/configuration_resnet.py#L35)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/configuration_resnet.py#L35)'
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *可选*, 默认为3) — 输入通道数。'
- en: '`embedding_size` (`int`, *optional*, defaults to 64) — Dimensionality (hidden
    size) for the embedding layer.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_size` (`int`, *可选*, 默认为64) — 嵌入层的维度（隐藏大小）。'
- en: '`hidden_sizes` (`List[int]`, *optional*, defaults to `[256, 512, 1024, 2048]`)
    — Dimensionality (hidden size) at each stage.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_sizes` (`List[int]`, *可选*, 默认为`[256, 512, 1024, 2048]`) — 每个阶段的维度（隐藏大小）。'
- en: '`depths` (`List[int]`, *optional*, defaults to `[3, 4, 6, 3]`) — Depth (number
    of layers) for each stage.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depths` (`List[int]`, *可选*, 默认为 `[3, 4, 6, 3]`) — 每个阶段的深度（层数）。'
- en: '`layer_type` (`str`, *optional*, defaults to `"bottleneck"`) — The layer to
    use, it can be either `"basic"` (used for smaller models, like resnet-18 or resnet-34)
    or `"bottleneck"` (used for larger models like resnet-50 and above).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_type` (`str`, *可选*, 默认为 `"bottleneck"`) — 要使用的层，可以是 `"basic"`（用于较小的模型，如
    resnet-18 或 resnet-34）或 `"bottleneck"`（用于较大的模型，如 resnet-50 及以上）。'
- en: '`hidden_act` (`str`, *optional*, defaults to `"relu"`) — The non-linear activation
    function in each block. If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"`
    are supported.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`, *可选*, 默认为 `"relu"`) — 每个块中的非线性激活函数。如果是字符串，支持 `"gelu"`,
    `"relu"`, `"selu"` 和 `"gelu_new"`。'
- en: '`downsample_in_first_stage` (`bool`, *optional*, defaults to `False`) — If
    `True`, the first stage will downsample the inputs using a `stride` of 2.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`downsample_in_first_stage` (`bool`, *可选*, 默认为 `False`) — 如果为 `True`，第一个阶段将使用
    `stride` 为 2 对输入进行下采样。'
- en: '`downsample_in_bottleneck` (`bool`, *optional*, defaults to `False`) — If `True`,
    the first conv 1x1 in ResNetBottleNeckLayer will downsample the inputs using a
    `stride` of 2.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`downsample_in_bottleneck` (`bool`, *可选*, 默认为 `False`) — 如果为 `True`，ResNetBottleNeckLayer
    中的第一个 conv 1x1 将使用 `stride` 为 2 对输入进行下采样。'
- en: '`out_features` (`List[str]`, *optional*) — If used as backbone, list of features
    to output. Can be any of `"stem"`, `"stage1"`, `"stage2"`, etc. (depending on
    how many stages the model has). If unset and `out_indices` is set, will default
    to the corresponding stages. If unset and `out_indices` is unset, will default
    to the last stage. Must be in the same order as defined in the `stage_names` attribute.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_features` (`List[str]`, *可选*) — 如果用作主干，要输出的特征列表。可以是 `"stem"`, `"stage1"`,
    `"stage2"` 等（取决于模型有多少阶段）。如果未设置且设置了 `out_indices`，将默认为相应的阶段。如果未设置且未设置 `out_indices`，将默认为最后一个阶段。必须按照
    `stage_names` 属性中定义的顺序。'
- en: '`out_indices` (`List[int]`, *optional*) — If used as backbone, list of indices
    of features to output. Can be any of 0, 1, 2, etc. (depending on how many stages
    the model has). If unset and `out_features` is set, will default to the corresponding
    stages. If unset and `out_features` is unset, will default to the last stage.
    Must be in the same order as defined in the `stage_names` attribute.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_indices` (`List[int]`, *可选*) — 如果用作主干，要输出的特征的索引列表。可以是 0、1、2 等（取决于模型有多少阶段）。如果未设置且设置了
    `out_features`，将默认为相应的阶段。如果未设置且未设置 `out_features`，将默认为最后一个阶段。必须按照 `stage_names`
    属性中定义的顺序。'
- en: This is the configuration class to store the configuration of a [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel).
    It is used to instantiate an ResNet model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the ResNet [microsoft/resnet-50](https://huggingface.co/microsoft/resnet-50)
    architecture.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是配置类，用于存储 [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    的配置。它用于根据指定的参数实例化 ResNet 模型，定义模型架构。使用默认值实例化配置将产生类似于 ResNet [microsoft/resnet-50](https://huggingface.co/microsoft/resnet-50)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: PytorchHide Pytorch content
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch 内容
- en: ResNetModel
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ResNetModel
- en: '### `class transformers.ResNetModel`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ResNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L311)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L311)'
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: The bare ResNet model outputting raw features without any specific head on top.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的 ResNet 模型输出原始特征，没有特定的头部。这个模型是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    的子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L325)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L325)'
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用 [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    获取。有关详细信息，请参阅 [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    `tuple(torch.FloatTensor)`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention`或`tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含各种元素，取决于配置([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))和输入。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor`，形状为`(batch_size, hidden_size)`) — 在空间维度上进行池化操作后的最后一层隐藏状态。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出的一个
    + 每层的输出的一个）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: The [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ResNetForImageClassification
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ResNetForImageClassification
- en: '### `class transformers.ResNetForImageClassification`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ResNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L361)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L361)'
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — 模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 带有图像分类头部的ResNet模型（在池化特征之上的线性层），例如用于ImageNet。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L381)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_resnet.py#L381)'
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the image classification/regression loss. Indices should be in `[0,
    ..., config.num_labels - 1]`. If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为 `(batch_size,)`，*可选*) — 用于计算图像分类/回归损失的标签。索引应在`[0,
    ..., config.num_labels - 1]`范围内。如果`config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or `tuple(torch.FloatTensor)`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含各种元素，这取决于配置（[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为 `(1,)`，*可选*，当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为 `(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each stage) of shape `(batch_size, num_channels, height,
    width)`. Hidden-states (also called feature maps) of the model at the output of
    each stage.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回)
    — 形状为 `(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每个阶段的输出）。模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: The [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: TensorFlowHide TensorFlow content
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowHide TensorFlow内容
- en: TFResNetModel
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFResNetModel
- en: '### `class transformers.TFResNetModel`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFResNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L472)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L472)'
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare ResNet model outputting raw features without any specific head on top.
    This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的ResNet模型输出原始特征，没有特定的头部。这个模型是TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)子类。将其用作常规的TensorFlow模块，并参考TensorFlow文档以获取与一般用法和行为相关的所有内容。
- en: '#### `call`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L481)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L481)'
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`tf.Tensor`，形状为 `(batch_size, num_channels, height, width)`)
    — 像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or `tuple(tf.Tensor)`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`或`tuple(tf.Tensor)`'
- en: A `transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`或一个`tf.Tensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含各种元素，具体取决于配置（[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)）和输入。
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, num_channels, height,
    width)`) — Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, num_channels, height, width)`的`tf.Tensor`）—
    模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) — Last layer
    hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`（形状为`(batch_size, hidden_size)`的`tf.Tensor`）— 在空间维度上进行池化操作后的最后一层隐藏状态。'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each layer) of shape `(batch_size, num_channels, height, width)`.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, num_channels, height, width)`的`tf.Tensor`元组（如果模型具有嵌入层，则为嵌入输出的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出处的隐藏状态以及可选的初始嵌入输出。
- en: The [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: TFResNetForImageClassification
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFResNetForImageClassification
- en: '### `class transformers.TFResNetForImageClassification`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFResNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L519)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L519)'
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有图像分类头部的ResNet模型（在池化特征的顶部有一个线性层），例如用于ImageNet。
- en: This model is a TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular TensorFlow Module and refer to the TensorFlow documentation
    for all matter related to general usage and behavior.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)子类。将其用作常规的TensorFlow模块，并参考TensorFlow文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `call`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L544)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_tf_resnet.py#L544)'
- en: '[PRE12]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的`tf.Tensor`）—
    像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — Labels for computing
    the image classification/regression loss. Indices should be in `[0, ..., config.num_labels
    - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size,)`的`tf.Tensor`，*可选*）— 用于计算图像分类/回归损失的标签。索引应在`[0, ...,
    config.num_labels - 1]`范围内。如果`config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_tf_outputs.TFImageClassifierOutputWithNoAttention` or
    `tuple(tf.Tensor)`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFImageClassifierOutputWithNoAttention`或`tuple(tf.Tensor)`'
- en: A `transformers.modeling_tf_outputs.TFImageClassifierOutputWithNoAttention`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    and inputs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.modeling_tf_outputs.TFImageClassifierOutputWithNoAttention`或一个`tf.Tensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)）和输入的不同元素。
- en: '`loss` (`tf.Tensor` of shape `(1,)`, *optional*, returned when `labels` is
    provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`tf.Tensor`，*可选*，当提供`labels`时返回） — 分类（如果config.num_labels==1则为回归）损失。'
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) — Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, config.num_labels)`的`tf.Tensor`） — 分类（如果config.num_labels==1则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each stage) of shape `(batch_size, num_channels, height, width)`.
    Hidden-states (also called feature maps) of the model at the output of each stage.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, num_channels, height, width)`的`tf.Tensor`元组（如果模型具有嵌入层，则为嵌入的输出+每个阶段的输出）。模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: The [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Example:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: JAXHide JAX content
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: JAXHide JAX content
- en: FlaxResNetModel
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxResNetModel
- en: '### `class transformers.FlaxResNetModel`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxResNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L576)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L576)'
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）之一。'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定，所有计算将使用给定的`dtype`执行。
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`请注意，这仅指定计算的数据类型，不影响模型参数的数据类型。`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您希望更改模型参数的数据类型，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。
- en: The bare ResNet model outputting raw features without any specific head on top.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的ResNet模型输出原始特征，没有特定的头部。
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。检查超类文档以获取库为其所有模型实现的通用方法（例如从PyTorch模型下载、保存和转换权重）。
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是一个[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)子类。将其用作常规的Flax
    linen模块，并参考Flax文档以获取有关一般用法和行为的所有信息。
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，此模型支持内在的JAX特性，例如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时（JIT）编译](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
- en: '[PRE15]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Returns
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPoolingAndNoAttention`
    or `tuple(torch.FloatTensor)`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPoolingAndNoAttention`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPoolingAndNoAttention`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`)
    and inputs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPoolingAndNoAttention`
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时），包括根据配置 (`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`)
    和输入的不同元素。
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, num_channels, height,
    width)`) — Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, num_channels, height,
    width)`) — 模型最后一层输出的隐藏状态序列。'
- en: '`pooler_output` (`jnp.ndarray` of shape `(batch_size, hidden_size)`) — Last
    layer hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`jnp.ndarray` of shape `(batch_size, hidden_size)`) — 空间维度上进行池化操作后的最后一层隐藏状态。'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`. Hidden-states of the model at the output of each layer plus the optional
    initial embedding outputs.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — 模型在每一层输出的隐藏状态的元组，包括可选的初始嵌入输出。'
- en: The `FlaxResNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxResNetPreTrainedModel` 的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用 `Module` 实例，而不是调用此函数，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: FlaxResNetForImageClassification
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxResNetForImageClassification
- en: '### `class transformers.FlaxResNetForImageClassification`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxResNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L660)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L660)'
- en: '[PRE17]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *optional*, 默认为 `jax.numpy.float32`) — 计算的数据类型。可以是
    `jax.numpy.float32`、`jax.numpy.float16`（在 GPU 上）和 `jax.numpy.bfloat16`（在 TPU 上）之一。'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以用于在 GPU 或 TPU 上启用混合精度训练或半精度推断。如果指定了 `dtype`，则所有计算将使用给定的 `dtype` 执行。
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`请注意，这只指定了计算的数据类型，不影响模型参数的数据类型。`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果希望更改模型参数的数据类型，请参阅 [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    和 [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有图像分类头的 ResNet 模型（在池化特征之上的线性层），例如用于 ImageNet。
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自 [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（例如从
    PyTorch 模型下载、保存和转换权重）。
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是 [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    的子类。将其用作常规的 Flax linen Module，并参考 Flax 文档以获取有关一般用法和行为的所有相关信息。
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个模型支持内在的 JAX 特性，比如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时编译（JIT）](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[向量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/resnet/modeling_flax_resnet.py#L488)'
- en: '[PRE18]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Returns
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or `tuple(torch.FloatTensor)`'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`)
    and inputs.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含根据配置（`<class 'transformers.models.resnet.configuration_resnet.ResNetConfig'>`）和输入的不同元素。
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, config.num_labels)`) — Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为 `(batch_size, config.num_labels)` 的 `jnp.ndarray`） — 分类（如果 `config.num_labels==1`
    则为回归）得分（SoftMax 之前）。'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递了 `output_hidden_states=True`
    或当'
- en: '`config.output_hidden_states=True):` Tuple of `jnp.ndarray` (one for the output
    of the embeddings, if the model has an embedding layer, + one for the output of
    each stage) of shape `(batch_size, num_channels, height, width)`. Hidden-states
    (also called feature maps) of the model at the output of each stage.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_hidden_states=True):` 形状为 `(batch_size, num_channels, height,
    width)` 的 `jnp.ndarray` 元组（如果模型有嵌入层，则为嵌入的输出 + 每个阶段的输出）。模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: The `FlaxResNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxResNetPreTrainedModel` 的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在之后调用 `Module` 实例而不是这个函数，因为前者会处理运行前后的处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE19]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
