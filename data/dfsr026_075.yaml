- en: Overview
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: 'Original text: [https://huggingface.co/docs/diffusers/optimization/opt_overview](https://huggingface.co/docs/diffusers/optimization/opt_overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/optimization/opt_overview](https://huggingface.co/docs/diffusers/optimization/opt_overview)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Generating high-quality outputs is computationally intensive, especially during
    each iterative step where you go from a noisy output to a less noisy output. One
    of ğŸ¤— Diffuserâ€™s goals is to make this technology widely accessible to everyone,
    which includes enabling fast inference on consumer and specialized hardware.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆé«˜è´¨é‡çš„è¾“å‡ºåœ¨è®¡ç®—ä¸Šæ˜¯å¯†é›†çš„ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¯ä¸ªè¿­ä»£æ­¥éª¤ä¸­ï¼Œæ‚¨ä»å˜ˆæ‚çš„è¾“å‡ºè½¬æ¢ä¸ºè¾ƒå°‘å˜ˆæ‚çš„è¾“å‡ºã€‚ğŸ¤— Diffuserçš„ç›®æ ‡ä¹‹ä¸€æ˜¯ä½¿è¿™é¡¹æŠ€æœ¯æ™®éå¯ç”¨ï¼Œè¿™åŒ…æ‹¬åœ¨æ¶ˆè´¹è€…å’Œä¸“ç”¨ç¡¬ä»¶ä¸Šå®ç°å¿«é€Ÿæ¨ç†ã€‚
- en: This section will cover tips and tricks - like half-precision weights and sliced
    attention - for optimizing inference speed and reducing memory-consumption. Youâ€™ll
    also learn how to speed up your PyTorch code with [`torch.compile`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)
    or [ONNX Runtime](https://onnxruntime.ai/docs/), and enable memory-efficient attention
    with [xFormers](https://facebookresearch.github.io/xformers/). There are also
    guides for running inference on specific hardware like Apple Silicon, and Intel
    or Habana processors.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬èŠ‚å°†æ¶µç›–ä¸€äº›æŠ€å·§å’Œçªé—¨ - å¦‚åŠç²¾åº¦æƒé‡å’Œåˆ‡ç‰‡æ³¨æ„åŠ› - ç”¨äºä¼˜åŒ–æ¨ç†é€Ÿåº¦å’Œå‡å°‘å†…å­˜æ¶ˆè€—ã€‚æ‚¨è¿˜å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨[`torch.compile`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)æˆ–[ONNX
    Runtime](https://onnxruntime.ai/docs/)åŠ å¿«PyTorchä»£ç çš„è¿è¡Œé€Ÿåº¦ï¼Œå¹¶ä½¿ç”¨[xFormers](https://facebookresearch.github.io/xformers/)å®ç°å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚è¿˜æœ‰å…³äºåœ¨ç‰¹å®šç¡¬ä»¶ä¸Šè¿è¡Œæ¨ç†çš„æŒ‡å—ï¼Œå¦‚è‹¹æœSiliconï¼Œä»¥åŠè‹±ç‰¹å°”æˆ–Habanaå¤„ç†å™¨ã€‚
