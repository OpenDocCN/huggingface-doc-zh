- en: Stable Diffusion XL Turbo
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳定扩散XL Turbo
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo](https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo](https://huggingface.co/docs/diffusers/using-diffusers/sdxl_turbo)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: SDXL Turbo is an adversarial time-distilled [Stable Diffusion XL](https://huggingface.co/papers/2307.01952)
    (SDXL) model capable of running inference in as little as 1 step.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: SDXL Turbo是一种对抗性时间蒸馏的[稳定扩散XL](https://huggingface.co/papers/2307.01952)（SDXL）模型，能够在至少1步中运行推理。
- en: This guide will show you how to use SDXL-Turbo for text-to-image and image-to-image.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将向您展示如何使用SDXL-Turbo进行文本到图像和图像到图像的操作。
- en: 'Before you begin, make sure you have the following libraries installed:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已安装以下库：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Load model checkpoints
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载模型检查点
- en: 'Model weights may be stored in separate subfolders on the Hub or locally, in
    which case, you should use the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    method:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 模型权重可能存储在Hub或本地的单独子文件夹中，在这种情况下，您应该使用[from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)方法：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can also use the [from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    method to load a model checkpoint stored in a single file format (`.ckpt` or `.safetensors`)
    from the Hub or locally:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)方法来加载存储在单个文件格式（`.ckpt`或`.safetensors`）中的模型检查点，可以从Hub或本地加载：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Text-to-image
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本到图像
- en: For text-to-image, pass a text prompt. By default, SDXL Turbo generates a 512x512
    image, and that resolution gives the best results. You can try setting the `height`
    and `width` parameters to 768x768 or 1024x1024, but you should expect quality
    degradations when doing so.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本到图像，传递一个文本提示。默认情况下，SDXL Turbo 生成一个512x512的图像，这种分辨率可以获得最佳结果。您可以尝试将`height`和`width`参数设置为768x768或1024x1024，但这样做时应该预期质量下降。
- en: Make sure to set `guidance_scale` to 0.0 to disable, as the model was trained
    without it. A single inference step is enough to generate high quality images.
    Increasing the number of steps to 2, 3 or 4 should improve image quality.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保将`guidance_scale`设置为0.0以禁用，因为该模型是在没有它的情况下训练的。进行一次推理步骤足以生成高质量图像。将步数增加到2、3或4应该会提高图像质量。
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![generated image of a racoon in a robe](../Images/792b5784d47e39b90a447d2316d5179c.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![穿着长袍的浣熊的生成图像](../Images/792b5784d47e39b90a447d2316d5179c.png)'
- en: Image-to-image
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像到图像
- en: For image-to-image generation, make sure that `num_inference_steps * strength`
    is larger or equal to 1. The image-to-image pipeline will run for `int(num_inference_steps
    * strength)` steps, e.g. `0.5 * 2.0 = 1` step in our example below.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像到图像的生成，请确保`num_inference_steps * strength`大于或等于1。图像到图像管道将运行`int(num_inference_steps
    * strength)`步，例如，在我们的示例中`0.5 * 2.0 = 1`步。
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Image-to-image generation sample using SDXL Turbo](../Images/5f9d53ee5b337acb14785101d7b6149f.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![使用SDXL Turbo进行图像到图像生成示例](../Images/5f9d53ee5b337acb14785101d7b6149f.png)'
- en: Speed-up SDXL Turbo even more
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加快SDXL Turbo的速度
- en: Compile the UNet if you are using PyTorch version 2 or better. The first inference
    run will be very slow, but subsequent ones will be much faster.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您使用PyTorch版本2或更高版本，请编译UNet。第一次推理运行会非常慢，但后续运行会快得多。
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When using the default VAE, keep it in `float32` to avoid costly `dtype` conversions
    before and after each generation. You only need to do this one before your first
    generation:'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用默认的VAE时，请将其保持在`float32`中，以避免在每次生成之前和之后进行昂贵的`dtype`转换。您只需要在第一次生成之前执行一次：
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As an alternative, you can also use a [16-bit VAE](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)
    created by community member [`@madebyollin`](https://huggingface.co/madebyollin)
    that does not need to be upcasted to `float32`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作为替代方案，您还可以使用社区成员[`@madebyollin`](https://huggingface.co/madebyollin)创建的[16位VAE](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)，无需将其升级为`float32`。
