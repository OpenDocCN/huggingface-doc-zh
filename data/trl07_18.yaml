- en: Iterative Trainer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代训练器
- en: 'Original text: [https://huggingface.co/docs/trl/iterative_sft_trainer](https://huggingface.co/docs/trl/iterative_sft_trainer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/trl/iterative_sft_trainer](https://huggingface.co/docs/trl/iterative_sft_trainer)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Iterative fine-tuning is a training method that enables to perform custom actions
    (generation and filtering for example) between optimization steps. In TRL we provide
    an easy-to-use API to fine-tune your models in an iterative way in just a few
    lines of code.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代微调是一种训练方法，可以在优化步骤之间执行自定义操作（例如生成和过滤）。在 TRL 中，我们提供了一个易于使用的 API，可以仅用几行代码迭代微调您的模型。
- en: Usage
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法
- en: To get started quickly, instantiate an instance a model, and a tokenizer.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 要快速开始，请实例化一个模型和一个分词器。
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You have the choice to either provide a list of strings or a list of tensors
    to the step function.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择向 step 函数提供字符串列表或张量列表。
- en: 'Using a list of tensors as input:'
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '使用张量列表作为输入:'
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Using a list of strings as input:'
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用字符串列表作为输入：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For causal language models, labels will automatically be created from input_ids
    or from texts. When using sequence to sequence models you will have to provide
    your own labels or text_labels.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于因果语言模型，标签将自动从 input_ids 或文本创建。当使用序列到序列模型时，您将需要提供自己的标签或文本标签。
- en: IterativeTrainer
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IterativeTrainer
- en: '### `class trl.IterativeSFTTrainer`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.IterativeSFTTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L39)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L39)'
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '*`*model**` (`PreTrainedModel`) — Model to be optimized, either an ‘AutoModelForCausalLM’
    or an ‘AutoModelForSeq2SeqLM’. — Check the documentation of `PreTrainedModel`
    for more details.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*model**` (`PreTrainedModel`) — 要优化的模型，可以是 ‘AutoModelForCausalLM’ 或 ‘AutoModelForSeq2SeqLM’。
    — 查看 `PreTrainedModel` 的文档以获取更多详细信息。'
- en: '*`*args**` (`transformers.TrainingArguments`) — — The arguments to use for
    training.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*args**` (`transformers.TrainingArguments`) — 用于训练的参数。'
- en: '*`*tokenizer**` (`PreTrainedTokenizerBase`) — Tokenizer to be used for encoding
    the — data. Check the documentation of `transformers.PreTrainedTokenizer` and
    `transformers.PreTrainedTokenizerFast` for more details.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*tokenizer**` (`PreTrainedTokenizerBase`) — 用于编码数据的分词器。查看 `transformers.PreTrainedTokenizer`
    和 `transformers.PreTrainedTokenizerFast` 的文档以获取更多详细信息。'
- en: '*`*optimizers**` (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`)
    — — The optimizer and scheduler to use for training.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*optimizers**` (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`)
    — — 用于训练的优化器和调度器。'
- en: '*`*data_collator**` (Union[DataCollatorForLanguageModeling, DataCollatorForSeq2Seq],
    *optional*) — Data collator to be used for training and — passed along the dataloader.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*data_collator**` (Union[DataCollatorForLanguageModeling, DataCollatorForSeq2Seq],
    *optional*) — 用于训练和传递给数据加载器的数据整合器。'
- en: '*`*eval_dataset**` (`datasets.Dataset`) — The dataset to use for evaluation.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*eval_dataset**` (`datasets.Dataset`) — 用于评估的数据集。'
- en: '*`*max_length**` (`int`, defaults to `None`) — — The maximum length of the
    input.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*max_length**` (`int`, 默认为 `None`) — 输入的最大长度。'
- en: '*`*truncation_mode**` (`str`, defaults to `keep_end`) — — The truncation mode
    to use, either `keep_end` or `keep_start`.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*truncation_mode**` (`str`, 默认为 `keep_end`) — 使用的截断模式，可以是 `keep_end` 或 `keep_start`。'
- en: '*`*preprocess_logits_for_metrics**` (`Callable[[torch.Tensor, torch.Tensor],
    torch.Tensor]`) — — The function to use to preprocess the logits before computing
    the metrics.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*preprocess_logits_for_metrics**` (`Callable[[torch.Tensor, torch.Tensor],
    torch.Tensor]`) — 用于在计算指标之前预处理对数的函数。'
- en: '*`*compute_metrics**` (`Callable[[EvalPrediction], Dict]`, *optional*) — —
    The function to use to compute the metrics. Must take a `EvalPrediction` and return
    a dictionary string to metric values.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*compute_metrics**` (`Callable[[EvalPrediction], Dict]`, *optional*) — 用于计算指标的函数。必须接受
    `EvalPrediction` 并返回一个字符串到指标值的字典。'
- en: '*`*optimize_device_cache` * *(`bool`,* optional*, defaults to `False`) — Optimize
    CUDA cache for slightly more memory-efficient training. —'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*optimize_device_cache` * *(`bool`,* optional*, 默认为 `False`) — 优化 CUDA 缓存以实现略微更高效的内存训练。
    —'
- en: The IterativeSFTTrainer can be used to finetune models with methods that requires
    some steps between optimization.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: IterativeSFTTrainer 可用于微调需要在优化之间执行一些步骤的模型。
- en: '#### `step`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L229)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L229)'
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (List`torch.LongTensor`) — List of tensors containing the input_ids
    (if not provided, text will be used)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (List`torch.LongTensor`) — 包含 input_ids 的张量列表（如果未提供，将使用文本）'
- en: '`attention_mask` (List`torch.LongTensor`, , *optional*) — List of tensors containing
    the attention_mask'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (List`torch.LongTensor`, , *optional*) — 包含 attention_mask
    的张量列表'
- en: '`labels` (List`torch.FloatTensor`, *optional*) — List of tensors containing
    the labels (if set to None, will default to input_ids)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (List`torch.FloatTensor`, *optional*) — 包含标签的张量列表（如果设置为 None，将默认为
    input_ids）'
- en: '`texts` (List`str`, *optional*) — List of strings containing the text input
    (if not provided, input_ids will directly be used)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`texts` (List`str`, *optional*) — 包含文本输入的字符串列表（如果未提供，则将直接使用input_ids）'
- en: '`texts_labels` (List`str`, *optional*) — List of strings containing the text
    labels (if set to None, will default to text)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`texts_labels` (List`str`, *optional*) — 包含文本标签的字符串列表（如果设置为 None，将默认为文本）'
- en: Returns
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`dict[str, Any]`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`dict[str, Any]`'
- en: A summary of the training statistics
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 训练统计摘要
- en: Run an optimisation step given a list of input_ids, attention_mask, and labels
    or a list of text and text_labels.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组 input_ids、attention_mask 和 labels 或一组文本和 text_labels，运行一个优化步骤。
