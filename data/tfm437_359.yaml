- en: MGP-STR
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MGP-STR
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mgp-str](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mgp-str)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mgp-str](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/mgp-str)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The MGP-STR model was proposed in [Multi-Granularity Prediction for Scene Text
    Recognition](https://arxiv.org/abs/2209.03592) by Peng Wang, Cheng Da, and Cong
    Yao. MGP-STR is a conceptually **simple** yet **powerful** vision Scene Text Recognition
    (STR) model, which is built upon the [Vision Transformer (ViT)](vit). To integrate
    linguistic knowledge, Multi-Granularity Prediction (MGP) strategy is proposed
    to inject information from the language modality into the model in an implicit
    way.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: MGP-STR模型由Peng Wang、Cheng Da和Cong Yao在[多粒度预测用于场景文本识别](https://arxiv.org/abs/2209.03592)中提出。MGP-STR是一个概念上简单但强大的视觉场景文本识别（STR）模型，它建立在[视觉Transformer（ViT）](vit)之上。为了整合语言知识，提出了多粒度预测（MGP）策略，以隐式方式将语言模态的信息注入模型中。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Scene text recognition (STR) has been an active research topic in computer
    vision for years. To tackle this challenging problem, numerous innovative methods
    have been successively proposed and incorporating linguistic knowledge into STR
    models has recently become a prominent trend. In this work, we first draw inspiration
    from the recent progress in Vision Transformer (ViT) to construct a conceptually
    simple yet powerful vision STR model, which is built upon ViT and outperforms
    previous state-of-the-art models for scene text recognition, including both pure
    vision models and language-augmented methods. To integrate linguistic knowledge,
    we further propose a Multi-Granularity Prediction strategy to inject information
    from the language modality into the model in an implicit way, i.e. , subword representations
    (BPE and WordPiece) widely-used in NLP are introduced into the output space, in
    addition to the conventional character level representation, while no independent
    language model (LM) is adopted. The resultant algorithm (termed MGP-STR) is able
    to push the performance envelop of STR to an even higher level. Specifically,
    it achieves an average recognition accuracy of 93.35% on standard benchmarks.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*场景文本识别（STR）一直是计算机视觉中的一个活跃研究课题。为了解决这一具有挑战性的问题，已经连续提出了许多创新方法，并且将语言知识整合到STR模型中最近成为一个突出的趋势。在这项工作中，我们首先从视觉Transformer（ViT）的最新进展中汲取灵感，构建了一个概念上简单但强大的视觉STR模型，它建立在ViT之上，并且在场景文本识别方面优于以前的最先进模型，包括纯视觉模型和语言增强方法。为了整合语言知识，我们进一步提出了一种多粒度预测策略，以隐式方式将语言模态的信息注入模型中，即，除了传统的字符级表示外，还引入了在NLP中广泛使用的子词表示（BPE和WordPiece）到输出空间中，而不采用独立的语言模型（LM）。由此产生的算法（称为MGP-STR）能够将STR的性能推向更高的水平。具体而言，在标准基准上实现了93.35%的平均识别准确率。*'
- en: '![drawing](../Images/f0c22cdfb9f67b7ee77ac9d0883362b6.png) MGP-STR architecture.
    Taken from the [original paper](https://arxiv.org/abs/2209.03592).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/f0c22cdfb9f67b7ee77ac9d0883362b6.png) MGP-STR架构。摘自[原始论文](https://arxiv.org/abs/2209.03592)。'
- en: MGP-STR is trained on two synthetic datasets [MJSynth]((http://www.robots.ox.ac.uk/~vgg/data/text/))
    (MJ) and SynthText([http://www.robots.ox.ac.uk/~vgg/data/scenetext/](http://www.robots.ox.ac.uk/~vgg/data/scenetext/))
    (ST) without fine-tuning on other datasets. It achieves state-of-the-art results
    on six standard Latin scene text benchmarks, including 3 regular text datasets
    (IC13, SVT, IIIT) and 3 irregular ones (IC15, SVTP, CUTE). This model was contributed
    by [yuekun](https://huggingface.co/yuekun). The original code can be found [here](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: MGP-STR在两个合成数据集[MJSynth]((http://www.robots.ox.ac.uk/~vgg/data/text/))（MJ）和SynthText([http://www.robots.ox.ac.uk/~vgg/data/scenetext/](http://www.robots.ox.ac.uk/~vgg/data/scenetext/))（ST）上进行训练，而不在其他数据集上进行微调。它在六个标准拉丁场景文本基准上取得了最先进的结果，包括3个常规文本数据集（IC13、SVT、IIIT）和3个不规则数据集（IC15、SVTP、CUTE）。该模型由[yuekun](https://huggingface.co/yuekun)贡献。原始代码可以在[这里](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR)找到。
- en: Inference example
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理示例
- en: '[MgpstrModel](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrModel)
    accepts images as input and generates three types of predictions, which represent
    textual information at different granularities. The three types of predictions
    are fused to give the final prediction result.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[MgpstrModel](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrModel)接受图像作为输入，并生成三种类型的预测，代表不同粒度的文本信息。这三种类型的预测被融合以给出最终的预测结果。'
- en: The [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    class is responsible for preprocessing the input image and [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)
    decodes the generated character tokens to the target string. The [MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)
    wraps [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    and [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)
    into a single instance to both extract the input features and decode the predicted
    token ids.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)类负责预处理输入图像，[MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)解码生成的字符标记为目标字符串。[MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)将[ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)和[MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)封装成单个实例，既提取输入特征又解码预测的标记ID。'
- en: Step-by-step Optical Character Recognition (OCR)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步光学字符识别（OCR）
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: MgpstrConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MgpstrConfig
- en: '### `class transformers.MgpstrConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MgpstrConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/configuration_mgp_str.py#L28)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/configuration_mgp_str.py#L28)'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_size` (`List[int]`, *optional*, defaults to `[32, 128]`) — The size
    (resolution) of each image.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`List[int]`, *optional*, defaults to `[32, 128]`) — 每个图像的大小（分辨率）。'
- en: '`patch_size` (`int`, *optional*, defaults to 4) — The size (resolution) of
    each patch.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *optional*, defaults to 4) — 每个补丁的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, defaults to 3) — 输入通道数。'
- en: '`max_token_length` (`int`, *optional*, defaults to 27) — The max number of
    output tokens.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_token_length` (`int`, *optional*, defaults to 27) — 输出标记的最大数量。'
- en: '`num_character_labels` (`int`, *optional*, defaults to 38) — The number of
    classes for character head .'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_character_labels` (`int`, *optional*, defaults to 38) — 字符头的类数。'
- en: '`num_bpe_labels` (`int`, *optional*, defaults to 50257) — The number of classes
    for bpe head .'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_bpe_labels` (`int`, *optional*, defaults to 50257) — bpe头的类数。'
- en: '`num_wordpiece_labels` (`int`, *optional*, defaults to 30522) — The number
    of classes for wordpiece head .'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_wordpiece_labels` (`int`, *optional*, defaults to 30522) — wordpiece头的类数。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — The embedding dimension.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 嵌入维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Transformer编码器中的隐藏层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Transformer编码器中每个注意力层的注意力头数。'
- en: '`mlp_ratio` (`float`, *optional*, defaults to 4.0) — The ratio of mlp hidden
    dim to embedding dim.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlp_ratio` (`float`, *optional*, defaults to 4.0) — mlp隐藏维度与嵌入维度的比率。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether to add a bias
    to the queries, keys and values.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — 是否为查询、键和值添加偏置。'
- en: '`distilled` (`bool`, *optional*, defaults to `False`) — Model includes a distillation
    token and head as in DeiT models.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilled` (`bool`, *optional*, defaults to `False`) — 模型包括蒸馏令牌和头，如DeiT模型。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — 层归一化层使用的epsilon。'
- en: '`drop_rate` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for all fully connected layers in the embeddings, encoder.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop_rate` (`float`, *optional*, defaults to 0.0) — 嵌入层、编码器中所有全连接层的dropout概率。'
- en: '`attn_drop_rate` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attn_drop_rate` (`float`, *optional*, defaults to 0.0) — 注意力概率的dropout比率。'
- en: '`drop_path_rate` (`float`, *optional*, defaults to 0.0) — The stochastic depth
    rate.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop_path_rate` (`float`, *optional*, defaults to 0.0) — 随机深度率。'
- en: '`output_a3_attentions` (`bool`, *optional*, defaults to `False`) — Whether
    or not the model should returns A^3 module attentions.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_a3_attentions` (`bool`, *optional*, defaults to `False`) — 模型是否返回A^3模块的注意力。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: This is the configuration class to store the configuration of an [MgpstrModel](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrModel).
    It is used to instantiate an MGP-STR model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the MGP-STR [alibaba-damo/mgp-str-base](https://huggingface.co/alibaba-damo/mgp-str-base)
    architecture.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[MgpstrModel](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrModel)的配置。根据指定的参数实例化一个MGP-STR模型，定义模型架构。使用默认值实例化配置将产生类似于MGP-STR
    [alibaba-damo/mgp-str-base](https://huggingface.co/alibaba-damo/mgp-str-base)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: MgpstrTokenizer
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MgpstrTokenizer
- en: '### `class transformers.MgpstrTokenizer`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MgpstrTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/tokenization_mgp_str.py#L38)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/tokenization_mgp_str.py#L38)'
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 词汇表文件路径。'
- en: '`unk_token` (`str`, *optional*, defaults to `"[GO]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, defaults to `"[GO]"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。'
- en: '`bos_token` (`str`, *optional*, defaults to `"[GO]"`) — The beginning of sequence
    token.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *optional*, defaults to `"[GO]"`) — 序列开始标记。'
- en: '`eos_token` (`str`, *optional*, defaults to `"[s]"`) — The end of sequence
    token.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *optional*, defaults to `"[s]"`) — 序列结束标记。'
- en: '`pad_token` (`str` or `tokenizers.AddedToken`, *optional*, defaults to `"[GO]"`)
    — A special token used to make arrays of tokens the same size for batching purpose.
    Will then be ignored by attention mechanisms or loss computation.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str` or `tokenizers.AddedToken`, *optional*, defaults to `"[GO]"`)
    — 用于使标记数组大小相同以进行批处理的特殊标记。然后将被注意力机制或损失计算忽略。'
- en: Construct a MGP-STR char tokenizer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个MGP-STR字符分词器。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此分词器继承自 [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大部分主要方法。用户应参考该超类获取有关这些方法的更多信息。
- en: '#### `save_vocabulary`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/tokenization_mgp_str.py#L100)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/tokenization_mgp_str.py#L100)'
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: MgpstrProcessor
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MgpstrProcessor
- en: '### `class transformers.MgpstrProcessor`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MgpstrProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/processing_mgp_str.py#L39)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/processing_mgp_str.py#L39)'
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` (`ViTImageProcessor`, *optional*) — An instance of `ViTImageProcessor`.
    The image processor is a required input.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor` (`ViTImageProcessor`, *可选*) — 一个 `ViTImageProcessor` 实例。图像处理器是必需的输入。'
- en: '`tokenizer` ([MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer),
    *optional*) — The tokenizer is a required input.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（[MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer),
    *可选*）— Tokenizer 是必需的输入。'
- en: Constructs a MGP-STR processor which wraps an image processor and MGP-STR tokenizers
    into a single
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 MGP-STR 处理器，将图像处理器和 MGP-STR 分词器封装成一个单独的
- en: '[MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)
    offers all the functionalities of `ViTImageProcessor`] and [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer).
    See the [**call**()](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor.__call__)
    and [batch_decode()](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor.batch_decode)
    for more information.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)
    提供了所有 `ViTImageProcessor` 和 [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)
    的功能。查看 [**call**()](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor.__call__)
    和 [batch_decode()](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor.batch_decode)
    获取更多信息。'
- en: '#### `__call__`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/processing_mgp_str.py#L79)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/processing_mgp_str.py#L79)'
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When used in normal mode, this method forwards all its arguments to ViTImageProcessor’s
    [**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    and returns its output. This method also forwards the `text` and `kwargs` arguments
    to MgpstrTokenizer’s [**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    if `text` is not `None` to encode the text. Please refer to the doctsring of the
    above methods for more information.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常模式下使用时，此方法将所有参数转发给 ViTImageProcessor 的 [**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    并返回其输出。如果 `text` 不是 `None`，此方法还将 `text` 和 `kwargs` 参数转发给 MgpstrTokenizer 的 [**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    来编码文本。更多信息请参考上述方法的文档字符串。
- en: '#### `batch_decode`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/processing_mgp_str.py#L102)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/processing_mgp_str.py#L102)'
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequences` (`torch.Tensor`) — List of tokenized input ids.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequences` (`torch.Tensor`) — 分词后输入 id 的列表。'
- en: Returns
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, any]`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, any]`'
- en: 'Dictionary of all the outputs of the decoded results. generated_text (`List[str]`):
    The final results after fusion of char, bpe, and wp. scores (`List[float]`): The
    final scores after fusion of char, bpe, and wp. char_preds (`List[str]`): The
    list of character decoded sentences. bpe_preds (`List[str]`): The list of bpe
    decoded sentences. wp_preds (`List[str]`): The list of wp decoded sentences.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '所有解码结果的字典。 generated_text (`List[str]`): 融合字符、bpe 和 wp 后的最终结果。 scores (`List[float]`):
    融合字符、bpe 和 wp 后的最终分数。 char_preds (`List[str]`): 字符解码句子的列表。 bpe_preds (`List[str]`):
    bpe 解码句子的列表。 wp_preds (`List[str]`): wp 解码句子的列表。'
- en: Convert a list of lists of token ids into a list of strings by calling decode.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用 decode 将 token id 的列表转换为字符串列表。
- en: This method forwards all its arguments to PreTrainedTokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将所有参数转发给 PreTrainedTokenizer 的 [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。更多信息请参考该方法的文档字符串。
- en: MgpstrModel
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MgpstrModel
- en: '### `class transformers.MgpstrModel`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MgpstrModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L364)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L364)'
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法加载模型权重。'
- en: The bare MGP-STR Model transformer outputting raw hidden-states without any
    specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 裸MGP-STR模型变压器输出原始隐藏状态，没有特定的顶部头。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L378)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L378)'
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。有关详细信息，请参阅[ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请查看返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [MgpstrModel](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrModel)
    forward method, overrides the `__call__` special method.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[MgpstrModel](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrModel)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: MgpstrForSceneTextRecognition
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MgpstrForSceneTextRecognition
- en: '### `class transformers.MgpstrForSceneTextRecognition`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.MgpstrForSceneTextRecognition`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L413)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L413)'
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: MGP-STR Model transformer with three classification heads on top (three A^3
    modules and three linear layer on top of the transformer encoder output) for scene
    text recognition (STR) .
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: MGP-STR模型变压器，顶部有三个分类头（三个A^3模块和变压器编码器输出顶部的三个线性层），用于场景文本识别（STR）。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L438)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/mgp_str/modeling_mgp_str.py#L438)'
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。有关详细信息，请参阅[ViTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请查看返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`output_a3_attentions` (`bool`, *optional*) — Whether or not to return the
    attentions tensors of a3 modules. See `a3_attentions` under returned tensors for
    more detail.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_a3_attentions`（`bool`，*可选*）- 是否返回a3模块的注意力张量。有关更多详细信息，请参阅返回张量中的`a3_attentions`。'
- en: Returns
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.mgp_str.modeling_mgp_str.MgpstrModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.mgp_str.modeling_mgp_str.MgpstrModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.mgp_str.modeling_mgp_str.MgpstrModelOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.mgp_str.configuration_mgp_str.MgpstrConfig'>`)
    and inputs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.mgp_str.modeling_mgp_str.MgpstrModelOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包括根据配置（`<class
    'transformers.models.mgp_str.configuration_mgp_str.MgpstrConfig'>`）和输入的不同元素。
- en: '`logits` (`tuple(torch.FloatTensor)` of shape `(batch_size, config.num_character_labels)`)
    — Tuple of `torch.FloatTensor` (one for the output of character of shape `(batch_size,
    config.max_token_length, config.num_character_labels)`, + one for the output of
    bpe of shape `(batch_size, config.max_token_length, config.num_bpe_labels)`, +
    one for the output of wordpiece of shape `(batch_size, config.max_token_length,
    config.num_wordpiece_labels)`) .'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, config.num_character_labels)`的`tuple(torch.FloatTensor)`）-
    `torch.FloatTensor`元组（一个用于字符输出的形状为`(batch_size, config.max_token_length, config.num_character_labels)`，+
    一个用于bpe输出的形状为`(batch_size, config.max_token_length, config.num_bpe_labels)`，+
    一个用于wordpiece输出的形状为`(batch_size, config.max_token_length, config.num_wordpiece_labels)`）。'
- en: Classification scores (before SoftMax) of character, bpe and wordpiece.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 字符、bpe和wordpiece的分类分数（SoftMax之前）。
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有一个嵌入层，+
    一个用于每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, config.max_token_length, sequence_length,
    sequence_length)`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）-
    形状为`(batch_size, config.max_token_length, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`a3_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_a3_attentions=True`
    is passed or when `config.output_a3_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for the attention of character, + one for the attention of bpe`, + one for
    the attention of wordpiece) of shape` (batch_size, config.max_token_length, sequence_length)`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a3_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_a3_attentions=True`或当`config.output_a3_attentions=True`时返回）-
    形状为`(batch_size, config.max_token_length, sequence_length)`的`torch.FloatTensor`元组（一个用于字符的注意力，+
    一个用于bpe的注意力，+ 一个用于wordpiece的注意力）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    forward method, overrides the `__call__` special method.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
