- en: The SnowballTarget Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SnowballTarget环境
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit5/snowball-target](https://huggingface.co/learn/deep-rl-course/unit5/snowball-target)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/learn/deep-rl-course/unit5/snowball-target](https://huggingface.co/learn/deep-rl-course/unit5/snowball-target)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![SnowballTarget](../Images/fb625fa1ee3e280912baaaa56548960f.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![SnowballTarget](../Images/fb625fa1ee3e280912baaaa56548960f.png)'
- en: SnowballTarget is an environment we created at Hugging Face using assets from
    [Kay Lousberg](https://kaylousberg.com/). We have an optional section at the end
    of this Unit **if you want to learn to use Unity and create your environments**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: SnowballTarget是我们在Hugging Face创建的一个环境，使用了[Kay Lousberg](https://kaylousberg.com/)的资源。如果您想学习如何使用Unity创建自己的环境，我们在本单元末尾有一个可选部分。
- en: The agent’s Goal
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理的目标
- en: The first agent you’re going to train is called Julien the bear 🐻. Julien is
    trained **to hit targets with snowballs**.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您将要训练的第一个代理叫做Julien the bear 🐻。Julien被训练**用雪球击中目标**。
- en: The Goal in this environment is that Julien **hits as many targets as possible
    in the limited time** (1000 timesteps). It will need **to place itself correctly
    in relation to the target and shoot**to do that.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个环境中的目标是，Julien **在有限的时间内击中尽可能多的目标**（1000个时间步）。它需要**正确地定位自己与目标的关系并射击**来实现这一目标。
- en: In addition, to avoid “snowball spamming” (aka shooting a snowball every timestep),
    **Julien has a “cool off” system** (it needs to wait 0.5 seconds after a shoot
    to be able to shoot again).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了避免“雪球垃圾邮件”（即每个时间步都射出一个雪球），**Julien有一个“冷却”系统**（需要等待0.5秒后才能再次射击）。
- en: '![Cool Off System](../Images/c50f4eb3112c190598a995d006aece23.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![Cool Off System](../Images/c50f4eb3112c190598a995d006aece23.png)'
- en: The agent needs to wait 0.5s before being able to shoot a snowball again
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 代理需要等待0.5秒才能再次射出雪球
- en: The reward function and the reward engineering problem
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 奖励函数和奖励工程问题
- en: The reward function is simple. **The environment gives a +1 reward every time
    the agent’s snowball hits a target**. Because the agent’s Goal is to maximize
    the expected cumulative reward, **it will try to hit as many targets as possible**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励函数很简单。**每当代理的雪球击中目标时，环境会给予+1的奖励**。因为代理的目标是最大化预期的累积奖励，**它将尽可能击中更多的目标**。
- en: '![Reward system](../Images/97bb6395a1762bfb94d1754c058aa292.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Reward system](../Images/97bb6395a1762bfb94d1754c058aa292.png)'
- en: We could have a more complex reward function (with a penalty to push the agent
    to go faster, for example). But when you design an environment, you need to avoid
    the *reward engineering problem*, which is having a too complex reward function
    to force your agent to behave as you want it to do. Why? Because by doing that,
    **you might miss interesting strategies that the agent will find with a simpler
    reward function**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以有一个更复杂的奖励函数（例如，对代理施加惩罚以促使其更快行动）。但是当设计环境时，您需要避免*奖励工程问题*，即使用过于复杂的奖励函数来强制代理按您希望的方式行事。为什么？因为这样做，**您可能会错过代理将通过更简单的奖励函数找到的有趣策略**。
- en: 'In terms of code, it looks like this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码方面，它看起来像这样：
- en: '![Reward](../Images/7b73d2b4241bd0c68e89efd1fe743505.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![Reward](../Images/7b73d2b4241bd0c68e89efd1fe743505.png)'
- en: The observation space
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观察空间
- en: Regarding observations, we don’t use normal vision (frame), but **we use raycasts**.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 关于观察，我们不使用正常的视觉（帧），而是**使用射线投射**。
- en: Think of raycasts as lasers that will detect if they pass through an object.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 将射线投射想象成激光，它们将检测是否穿过物体。
- en: '![Raycasts](../Images/93b379dd693a76d5472608228f47e6f3.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![Raycasts](../Images/93b379dd693a76d5472608228f47e6f3.png)'
- en: 'Source: [ML-Agents documentation](https://github.com/Unity-Technologies/ml-agents)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[ML-Agents文档](https://github.com/Unity-Technologies/ml-agents)
- en: 'In this environment, our agent has multiple set of raycasts:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个环境中，我们的代理有多组射线投射：
- en: '![Raycasts](../Images/04047cdc3e12f4d8b6fc04d527b49c3e.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Raycasts](../Images/04047cdc3e12f4d8b6fc04d527b49c3e.png)'
- en: In addition to raycasts, the agent gets a “can I shoot” bool as observation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了射线投射外，代理还会得到一个“我能射击吗”的布尔值作为观察。
- en: '![Obs](../Images/781b3f0cb3bdaeaea583e42caa651ef3.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![Obs](../Images/781b3f0cb3bdaeaea583e42caa651ef3.png)'
- en: The action space
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动作空间
- en: 'The action space is discrete:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 动作空间是离散的：
- en: '![Action Space](../Images/1a9d30bdfb0e6cf6ea4e7c6189d64c1f.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Action Space](../Images/1a9d30bdfb0e6cf6ea4e7c6189d64c1f.png)'
