- en: The SnowballTarget Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SnowballTargetç¯å¢ƒ
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit5/snowball-target](https://huggingface.co/learn/deep-rl-course/unit5/snowball-target)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/learn/deep-rl-course/unit5/snowball-target](https://huggingface.co/learn/deep-rl-course/unit5/snowball-target)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![SnowballTarget](../Images/fb625fa1ee3e280912baaaa56548960f.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![SnowballTarget](../Images/fb625fa1ee3e280912baaaa56548960f.png)'
- en: SnowballTarget is an environment we created at Hugging Face using assets from
    [Kay Lousberg](https://kaylousberg.com/). We have an optional section at the end
    of this Unit **if you want to learn to use Unity and create your environments**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: SnowballTargetæ˜¯æˆ‘ä»¬åœ¨Hugging Faceåˆ›å»ºçš„ä¸€ä¸ªç¯å¢ƒï¼Œä½¿ç”¨äº†[Kay Lousberg](https://kaylousberg.com/)çš„èµ„æºã€‚å¦‚æœæ‚¨æƒ³å­¦ä¹ å¦‚ä½•ä½¿ç”¨Unityåˆ›å»ºè‡ªå·±çš„ç¯å¢ƒï¼Œæˆ‘ä»¬åœ¨æœ¬å•å…ƒæœ«å°¾æœ‰ä¸€ä¸ªå¯é€‰éƒ¨åˆ†ã€‚
- en: The agentâ€™s Goal
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»£ç†çš„ç›®æ ‡
- en: The first agent youâ€™re going to train is called Julien the bear ğŸ». Julien is
    trained **to hit targets with snowballs**.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å°†è¦è®­ç»ƒçš„ç¬¬ä¸€ä¸ªä»£ç†å«åšJulien the bear ğŸ»ã€‚Julienè¢«è®­ç»ƒ**ç”¨é›ªçƒå‡»ä¸­ç›®æ ‡**ã€‚
- en: The Goal in this environment is that Julien **hits as many targets as possible
    in the limited time** (1000 timesteps). It will need **to place itself correctly
    in relation to the target and shoot**to do that.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¯å¢ƒä¸­çš„ç›®æ ‡æ˜¯ï¼ŒJulien **åœ¨æœ‰é™çš„æ—¶é—´å†…å‡»ä¸­å°½å¯èƒ½å¤šçš„ç›®æ ‡**ï¼ˆ1000ä¸ªæ—¶é—´æ­¥ï¼‰ã€‚å®ƒéœ€è¦**æ­£ç¡®åœ°å®šä½è‡ªå·±ä¸ç›®æ ‡çš„å…³ç³»å¹¶å°„å‡»**æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚
- en: In addition, to avoid â€œsnowball spammingâ€ (aka shooting a snowball every timestep),
    **Julien has a â€œcool offâ€ system** (it needs to wait 0.5 seconds after a shoot
    to be able to shoot again).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä¸ºäº†é¿å…â€œé›ªçƒåƒåœ¾é‚®ä»¶â€ï¼ˆå³æ¯ä¸ªæ—¶é—´æ­¥éƒ½å°„å‡ºä¸€ä¸ªé›ªçƒï¼‰ï¼Œ**Julienæœ‰ä¸€ä¸ªâ€œå†·å´â€ç³»ç»Ÿ**ï¼ˆéœ€è¦ç­‰å¾…0.5ç§’åæ‰èƒ½å†æ¬¡å°„å‡»ï¼‰ã€‚
- en: '![Cool Off System](../Images/c50f4eb3112c190598a995d006aece23.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![Cool Off System](../Images/c50f4eb3112c190598a995d006aece23.png)'
- en: The agent needs to wait 0.5s before being able to shoot a snowball again
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç†éœ€è¦ç­‰å¾…0.5ç§’æ‰èƒ½å†æ¬¡å°„å‡ºé›ªçƒ
- en: The reward function and the reward engineering problem
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¥–åŠ±å‡½æ•°å’Œå¥–åŠ±å·¥ç¨‹é—®é¢˜
- en: The reward function is simple. **The environment gives a +1 reward every time
    the agentâ€™s snowball hits a target**. Because the agentâ€™s Goal is to maximize
    the expected cumulative reward, **it will try to hit as many targets as possible**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¥–åŠ±å‡½æ•°å¾ˆç®€å•ã€‚**æ¯å½“ä»£ç†çš„é›ªçƒå‡»ä¸­ç›®æ ‡æ—¶ï¼Œç¯å¢ƒä¼šç»™äºˆ+1çš„å¥–åŠ±**ã€‚å› ä¸ºä»£ç†çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–é¢„æœŸçš„ç´¯ç§¯å¥–åŠ±ï¼Œ**å®ƒå°†å°½å¯èƒ½å‡»ä¸­æ›´å¤šçš„ç›®æ ‡**ã€‚
- en: '![Reward system](../Images/97bb6395a1762bfb94d1754c058aa292.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Reward system](../Images/97bb6395a1762bfb94d1754c058aa292.png)'
- en: We could have a more complex reward function (with a penalty to push the agent
    to go faster, for example). But when you design an environment, you need to avoid
    the *reward engineering problem*, which is having a too complex reward function
    to force your agent to behave as you want it to do. Why? Because by doing that,
    **you might miss interesting strategies that the agent will find with a simpler
    reward function**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªæ›´å¤æ‚çš„å¥–åŠ±å‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œå¯¹ä»£ç†æ–½åŠ æƒ©ç½šä»¥ä¿ƒä½¿å…¶æ›´å¿«è¡ŒåŠ¨ï¼‰ã€‚ä½†æ˜¯å½“è®¾è®¡ç¯å¢ƒæ—¶ï¼Œæ‚¨éœ€è¦é¿å…*å¥–åŠ±å·¥ç¨‹é—®é¢˜*ï¼Œå³ä½¿ç”¨è¿‡äºå¤æ‚çš„å¥–åŠ±å‡½æ•°æ¥å¼ºåˆ¶ä»£ç†æŒ‰æ‚¨å¸Œæœ›çš„æ–¹å¼è¡Œäº‹ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºè¿™æ ·åšï¼Œ**æ‚¨å¯èƒ½ä¼šé”™è¿‡ä»£ç†å°†é€šè¿‡æ›´ç®€å•çš„å¥–åŠ±å‡½æ•°æ‰¾åˆ°çš„æœ‰è¶£ç­–ç•¥**ã€‚
- en: 'In terms of code, it looks like this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»£ç æ–¹é¢ï¼Œå®ƒçœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '![Reward](../Images/7b73d2b4241bd0c68e89efd1fe743505.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![Reward](../Images/7b73d2b4241bd0c68e89efd1fe743505.png)'
- en: The observation space
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿç©ºé—´
- en: Regarding observations, we donâ€™t use normal vision (frame), but **we use raycasts**.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºè§‚å¯Ÿï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨æ­£å¸¸çš„è§†è§‰ï¼ˆå¸§ï¼‰ï¼Œè€Œæ˜¯**ä½¿ç”¨å°„çº¿æŠ•å°„**ã€‚
- en: Think of raycasts as lasers that will detect if they pass through an object.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å°„çº¿æŠ•å°„æƒ³è±¡æˆæ¿€å…‰ï¼Œå®ƒä»¬å°†æ£€æµ‹æ˜¯å¦ç©¿è¿‡ç‰©ä½“ã€‚
- en: '![Raycasts](../Images/93b379dd693a76d5472608228f47e6f3.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![Raycasts](../Images/93b379dd693a76d5472608228f47e6f3.png)'
- en: 'Source: [ML-Agents documentation](https://github.com/Unity-Technologies/ml-agents)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[ML-Agentsæ–‡æ¡£](https://github.com/Unity-Technologies/ml-agents)
- en: 'In this environment, our agent has multiple set of raycasts:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬çš„ä»£ç†æœ‰å¤šç»„å°„çº¿æŠ•å°„ï¼š
- en: '![Raycasts](../Images/04047cdc3e12f4d8b6fc04d527b49c3e.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Raycasts](../Images/04047cdc3e12f4d8b6fc04d527b49c3e.png)'
- en: In addition to raycasts, the agent gets a â€œcan I shootâ€ bool as observation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†å°„çº¿æŠ•å°„å¤–ï¼Œä»£ç†è¿˜ä¼šå¾—åˆ°ä¸€ä¸ªâ€œæˆ‘èƒ½å°„å‡»å—â€çš„å¸ƒå°”å€¼ä½œä¸ºè§‚å¯Ÿã€‚
- en: '![Obs](../Images/781b3f0cb3bdaeaea583e42caa651ef3.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![Obs](../Images/781b3f0cb3bdaeaea583e42caa651ef3.png)'
- en: The action space
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ¨ä½œç©ºé—´
- en: 'The action space is discrete:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ¨ä½œç©ºé—´æ˜¯ç¦»æ•£çš„ï¼š
- en: '![Action Space](../Images/1a9d30bdfb0e6cf6ea4e7c6189d64c1f.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Action Space](../Images/1a9d30bdfb0e6cf6ea4e7c6189d64c1f.png)'
