- en: Load a dataset from the Hub
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Hub加载数据集
- en: 'Original text: [https://huggingface.co/docs/datasets/load_hub](https://huggingface.co/docs/datasets/load_hub)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/datasets/load_hub](https://huggingface.co/docs/datasets/load_hub)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Finding high-quality datasets that are reproducible and accessible can be difficult.
    One of 🤗 Datasets main goals is to provide a simple way to load a dataset of any
    format or type. The easiest way to get started is to discover an existing dataset
    on the [Hugging Face Hub](https://huggingface.co/datasets) - a community-driven
    collection of datasets for tasks in NLP, computer vision, and audio - and use
    🤗 Datasets to download and generate the dataset.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 查找可重现且可访问的高质量数据集可能很困难。🤗 数据集的主要目标之一是提供一种简单的方式来加载任何格式或类型的数据集。开始的最简单方法是在[Hugging
    Face Hub](https://huggingface.co/datasets)上发现现有数据集 - 这是一个社区驱动的数据集集合，用于NLP、计算机视觉和音频任务
    - 并使用🤗 数据集下载和生成数据集。
- en: This tutorial uses the [rotten_tomatoes](https://huggingface.co/datasets/rotten_tomatoes)
    and [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) datasets, but feel
    free to load any dataset you want and follow along. Head over to the Hub now and
    find a dataset for your task!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程使用[rotten_tomatoes](https://huggingface.co/datasets/rotten_tomatoes)和[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)数据集，但请随意加载您想要的任何数据集并跟随操作。立即前往Hub并找到适合您任务的数据集！
- en: Load a dataset
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据集
- en: Before you take the time to download a dataset, it’s often helpful to quickly
    get some general information about a dataset. A dataset’s information is stored
    inside [DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo)
    and can include information such as the dataset description, features, and dataset
    size.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在花时间下载数据集之前，快速获取有关数据集的一般信息通常是有帮助的。数据集的信息存储在[DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo)中，可以包括数据集描述、特征和数据集大小等信息。
- en: 'Use the [load_dataset_builder()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset_builder)
    function to load a dataset builder and inspect a dataset’s attributes without
    committing to downloading it:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[load_dataset_builder()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset_builder)函数加载数据集构建器并检查数据集的属性，而不必下载它：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you’re happy with the dataset, then load it with [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对数据集满意，请使用[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)加载它：
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Splits
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分
- en: 'A split is a specific subset of a dataset like `train` and `test`. List a dataset’s
    split names with the [get_dataset_split_names()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.get_dataset_split_names)
    function:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 拆分是数据集的特定子集，如`train`和`test`。使用[get_dataset_split_names()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.get_dataset_split_names)函数列出数据集的拆分名称：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then you can load a specific split with the `split` parameter. Loading a dataset
    `split` returns a [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您可以使用`split`参数加载特定的拆分。加载数据集`split`将返回一个[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you don’t specify a `split`, 🤗 Datasets returns a [DatasetDict](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetDict)
    object instead:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有指定`split`，🤗 数据集将返回一个[DatasetDict](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetDict)对象：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Configurations
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: Some datasets contain several sub-datasets. For example, the [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)
    dataset has several sub-datasets, each one containing audio data in a different
    language. These sub-datasets are known as *configurations*, and you must explicitly
    select one when loading the dataset. If you don’t provide a configuration name,
    🤗 Datasets will raise a `ValueError` and remind you to choose a configuration.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据集包含多个子数据集。例如，[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)数据集有多个子数据集，每个子数据集包含不同语言的音频数据。这些子数据集称为*配置*，在加载数据集时必须明确选择一个。如果您没有提供配置名称，🤗
    数据集将引发`ValueError`并提醒您选择一个配置。
- en: 'Use the [get_dataset_config_names()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.get_dataset_config_names)
    function to retrieve a list of all the possible configurations available to your
    dataset:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[get_dataset_config_names()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.get_dataset_config_names)函数检索数据集可用的所有可能配置的列表：
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then load the configuration you want:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后加载您想要的配置：
- en: '[PRE6]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Remote code
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 远程代码
- en: Certain datasets repositories contain a loading script with the Python code
    used to generate the dataset. Those datasets are generally exported to Parquet
    by Hugging Face, so that 🤗 Datasets can load the dataset fast and without running
    a loading script.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 某些数据集存储库包含用于生成数据集的Python代码的加载脚本。这些数据集通常由Hugging Face导出为Parquet，以便🤗 数据集可以快速加载数据集而无需运行加载脚本。
- en: 'Even if a Parquet export is not available, you can still use any dataset with
    Python code in its repository with `load_dataset`. All files and code uploaded
    to the Hub are scanned for malware (refer to the Hub security documentation for
    more information), but you should still review the dataset loading scripts and
    authors to avoid executing malicious code on your machine. You should set `trust_remote_code=True`
    to use a dataset with a loading script, or you will get a warning:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 即使Parquet导出不可用，您仍然可以使用`load_dataset`中的Python代码在其存储库中使用任何数据集。所有上传到Hub的文件和代码都会被扫描以检测恶意软件（有关更多信息，请参阅Hub安全文档），但您仍应查看数据集加载脚本和作者，以避免在您的计算机上执行恶意代码。您应该设置`trust_remote_code=True`以使用带有加载脚本的数据集，否则您将收到警告：
- en: '[PRE7]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the next major release, the new safety features of 🤗 Datasets will disable
    running dataset loading scripts by default, and you will have to pass `trust_remote_code=True`
    to load datasets that require running a dataset script.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个主要版本中，🤗 数据集的新安全功能将默认禁用运行数据集加载脚本，并且您必须传递`trust_remote_code=True`以加载需要运行数据集脚本的数据集。
