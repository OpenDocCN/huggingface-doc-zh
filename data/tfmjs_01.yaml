- en: Transformers.js
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Transformers.js
- en: 'Original text: [https://huggingface.co/docs/transformers.js/index](https://huggingface.co/docs/transformers.js/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/transformers.js/index](https://huggingface.co/docs/transformers.js/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in
    your browser, with no need for a server!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的最新机器学习。在浏览器中直接运行🤗 Transformers，无需服务器！
- en: 'Transformers.js is designed to be functionally equivalent to Hugging Face’s
    [transformers](https://github.com/huggingface/transformers) python library, meaning
    you can run the same pretrained models using a very similar API. These models
    support common tasks in different modalities, such as:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers.js旨在与Hugging Face的[transformers](https://github.com/huggingface/transformers)
    Python库在功能上等效，这意味着您可以使用非常相似的API运行相同的预训练模型。这些模型支持不同模态中的常见任务，例如：
- en: '📝 **Natural Language Processing**: text classification, named entity recognition,
    question answering, language modeling, summarization, translation, multiple choice,
    and text generation.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📝 **自然语言处理**：文本分类，命名实体识别，问答，语言建模，摘要，翻译，多项选择和文本生成。
- en: '🖼️ **Computer Vision**: image classification, object detection, and segmentation.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🖼️ **计算机视觉**：图像分类，目标检测和分割。
- en: '🗣️ **Audio**: automatic speech recognition and audio classification.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🗣️ **音频**：自动语音识别和音频分类。
- en: '🐙 **Multimodal**: zero-shot image classification.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🐙 **多模态**：零样本图像分类。
- en: Transformers.js uses [ONNX Runtime](https://onnxruntime.ai/) to run models in
    the browser. The best part about it, is that you can easily [convert](#convert-your-models-to-onnx)
    your pretrained PyTorch, TensorFlow, or JAX models to ONNX using [🤗 Optimum](https://github.com/huggingface/optimum#onnx--onnx-runtime).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers.js使用[ONNX Runtime](https://onnxruntime.ai/)在浏览器中运行模型。最好的部分是，您可以使用[🤗
    Optimum](https://github.com/huggingface/optimum#onnx--onnx-runtime)轻松地将您的预训练的PyTorch，TensorFlow或JAX模型转换为ONNX。
- en: For more information, check out the full [documentation](https://huggingface.co/docs/transformers.js).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更多信息，请查看完整的[文档](https://huggingface.co/docs/transformers.js)。
- en: Quick tour
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速介绍
- en: It’s super simple to translate from existing code! Just like the python library,
    we support the `pipeline` API. Pipelines group together a pretrained model with
    preprocessing of inputs and postprocessing of outputs, making it the easiest way
    to run models with the library.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从现有代码进行翻译非常简单！就像Python库一样，我们支持`pipeline` API。管道将预训练模型与输入的预处理和输出的后处理组合在一起，使其成为使用库运行模型的最简单方式。
- en: '| **Python (original)** | **Javascript (ours)** |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **Python（原始）** | **Javascript（我们的）** |'
- en: '|'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '|'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'You can also use a different model by specifying the model id or path as the
    second argument to the `pipeline` function. For example:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过将模型ID或路径指定为`pipeline`函数的第二个参数来使用不同的模型。例如：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Contents
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: 'The documentation is organized into 4 sections:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 文档分为4个部分：
- en: '**GET STARTED** provides a quick tour of the library and installation instructions
    to get up and running.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**入门** 提供了对库的快速介绍和安装说明，以便快速上手。'
- en: '**TUTORIALS** are a great place to start if you’re a beginner! We also include
    sample applications for you to play around with!'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**教程** 是初学者开始的好地方！我们还提供了一些示例应用供您玩耍！'
- en: '**DEVELOPER GUIDES** show you how to use the library to achieve a specific
    goal.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**开发者指南** 展示了如何使用库来实现特定目标。'
- en: '**API REFERENCE** describes all classes and functions, as well as their available
    parameters and types.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**API参考** 描述了所有类和函数，以及它们可用的参数和类型。'
- en: Examples
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: 'Want to jump straight in? Get started with one of our sample applications/templates:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 想要立即开始吗？从我们的示例应用程序/模板开始：
- en: '| Name | Description | Links |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 描述 | 链接 |'
- en: '| --- | --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Whisper Web | Speech recognition w/ Whisper | [code](https://github.com/xenova/whisper-web),
    [demo](https://huggingface.co/spaces/Xenova/whisper-web) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Whisper Web | Whisper的语音识别 | [代码](https://github.com/xenova/whisper-web),
    [演示](https://huggingface.co/spaces/Xenova/whisper-web) |'
- en: '| Doodle Dash | Real-time sketch-recognition game | [blog](https://huggingface.co/blog/ml-web-games),
    [code](https://github.com/xenova/doodle-dash), [demo](https://huggingface.co/spaces/Xenova/doodle-dash)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Doodle Dash | 实时涂鸦识别游戏 | [博客](https://huggingface.co/blog/ml-web-games),
    [代码](https://github.com/xenova/doodle-dash), [演示](https://huggingface.co/spaces/Xenova/doodle-dash)
    |'
- en: '| Code Playground | In-browser code completion website | [code](https://github.com/xenova/transformers.js/tree/main/examples/code-completion/),
    [demo](https://huggingface.co/spaces/Xenova/ai-code-playground) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 代码播放器 | 浏览器代码补全网站 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/code-completion/),
    [演示](https://huggingface.co/spaces/Xenova/ai-code-playground) |'
- en: '| Semantic Image Search (client-side) | Search for images with text | [code](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search-client/),
    [demo](https://huggingface.co/spaces/Xenova/semantic-image-search-client) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 语义图像搜索（客户端） | 使用文本搜索图像 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search-client/),
    [演示](https://huggingface.co/spaces/Xenova/semantic-image-search-client) |'
- en: '| Semantic Image Search (server-side) | Search for images with text (Supabase)
    | [code](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search/),
    [demo](https://huggingface.co/spaces/Xenova/semantic-image-search) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 语义图像搜索（服务器端） | 使用文本搜索图像（Supabase） | [代码](https://github.com/xenova/transformers.js/tree/main/examples/semantic-image-search/),
    [演示](https://huggingface.co/spaces/Xenova/semantic-image-search) |'
- en: '| Vanilla JavaScript | In-browser object detection | [video](https://scrimba.com/scrim/cKm9bDAg),
    [code](https://github.com/xenova/transformers.js/tree/main/examples/vanilla-js/),
    [demo](https://huggingface.co/spaces/Scrimba/vanilla-js-object-detector) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla JavaScript | 浏览器对象检测 | [视频](https://scrimba.com/scrim/cKm9bDAg),
    [代码](https://github.com/xenova/transformers.js/tree/main/examples/vanilla-js/),
    [演示](https://huggingface.co/spaces/Scrimba/vanilla-js-object-detector) |'
- en: '| React | Multilingual translation website | [code](https://github.com/xenova/transformers.js/tree/main/examples/react-translator/),
    [demo](https://huggingface.co/spaces/Xenova/react-translator) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| React | 多语言翻译网站 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/react-translator/),
    [演示](https://huggingface.co/spaces/Xenova/react-translator) |'
- en: '| Text to speech (client-side) | In-browser speech synthesis | [code](https://github.com/xenova/transformers.js/tree/main/examples/text-to-speech-client/),
    [demo](https://huggingface.co/spaces/Xenova/text-to-speech-client) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 文本转语音（客户端） | 浏览器内语音合成 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/text-to-speech-client/)，[演示](https://huggingface.co/spaces/Xenova/text-to-speech-client)
    |'
- en: '| Browser extension | Text classification extension | [code](https://github.com/xenova/transformers.js/tree/main/examples/extension/)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 浏览器扩展 | 文本分类扩展 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/extension/)
    |'
- en: '| Electron | Text classification application | [code](https://github.com/xenova/transformers.js/tree/main/examples/electron/)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 电子 | 文本分类应用 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/electron/)
    |'
- en: '| Next.js (client-side) | Sentiment analysis (in-browser inference) | [code](https://github.com/xenova/transformers.js/tree/main/examples/next-client/),
    [demo](https://huggingface.co/spaces/Xenova/next-example-app) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| Next.js（客户端） | 情感分析（浏览器推断） | [代码](https://github.com/xenova/transformers.js/tree/main/examples/next-client/)，[演示](https://huggingface.co/spaces/Xenova/next-example-app)
    |'
- en: '| Next.js (server-side) | Sentiment analysis (Node.js inference) | [code](https://github.com/xenova/transformers.js/tree/main/examples/next-server/),
    [demo](https://huggingface.co/spaces/Xenova/next-server-example-app) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Next.js（服务器端） | 情感分析（Node.js 推断） | [代码](https://github.com/xenova/transformers.js/tree/main/examples/next-server/)，[演示](https://huggingface.co/spaces/Xenova/next-server-example-app)
    |'
- en: '| Node.js | Sentiment analysis API | [code](https://github.com/xenova/transformers.js/tree/main/examples/node/)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| Node.js | 情感分析API | [代码](https://github.com/xenova/transformers.js/tree/main/examples/node/)
    |'
- en: '| Demo site | A collection of demos | [code](https://github.com/xenova/transformers.js/tree/main/examples/demo-site/),
    [demo](https://xenova.github.io/transformers.js/) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 演示站点 | 一系列演示 | [代码](https://github.com/xenova/transformers.js/tree/main/examples/demo-site/)，[演示](https://xenova.github.io/transformers.js/)
    |'
- en: Check out the Transformers.js [template](https://huggingface.co/new-space?template=static-templates%2Ftransformers.js)
    on Hugging Face to get started in one click!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Transformers.js在Hugging Face上的[模板](https://huggingface.co/new-space?template=static-templates%2Ftransformers.js)，一键开始！
- en: Supported tasks/models
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持的任务/模型
- en: Here is the list of all tasks and architectures currently supported by Transformers.js.
    If you don’t see your task/model listed here or it is not yet supported, feel
    free to open up a feature request [here](https://github.com/xenova/transformers.js/issues/new/choose).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Transformers.js当前支持的所有任务和架构列表。如果您在此处看不到您的任务/模型或尚未支持，请随时在[此处](https://github.com/xenova/transformers.js/issues/new/choose)提出功能请求。
- en: To find compatible models on the Hub, select the “transformers.js” library tag
    in the filter menu (or visit [this link](https://huggingface.co/models?library=transformers.js)).
    You can refine your search by selecting the task you’re interested in (e.g., [text-classification](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Hub上找到兼容的模型，请在过滤菜单中选择“transformers.js”库标签（或访问[此链接](https://huggingface.co/models?library=transformers.js)）。您可以通过选择您感兴趣的任务（例如，[文本分类](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)）来细化搜索。
- en: Tasks
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务
- en: Natural Language Processing
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: '| Task | ID | Description | Supported? |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ID | 描述 | 是否支持？ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Conversational](https://huggingface.co/tasks/conversational) | `conversational`
    | Generating conversational text that is relevant, coherent and knowledgable given
    a prompt. | ❌ |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| [对话](https://huggingface.co/tasks/conversational) | `conversational` | 在给定提示的情况下生成相关、连贯和知识丰富的对话文本。
    | ❌ |'
- en: '| [Fill-Mask](https://huggingface.co/tasks/fill-mask) | `fill-mask` | Masking
    some of the words in a sentence and predicting which words should replace those
    masks. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FillMaskPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=fill-mask&library=transformers.js)
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| [填充掩码](https://huggingface.co/tasks/fill-mask) | `fill-mask` | 掩盖句子中的一些单词并预测应该替换这些掩码的单词。
    | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FillMaskPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=fill-mask&library=transformers.js)
    |'
- en: '| [Question Answering](https://huggingface.co/tasks/question-answering) | `question-answering`
    | Retrieve the answer to a question from a given text. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.QuestionAnsweringPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=question-answering&library=transformers.js)
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| [问答](https://huggingface.co/tasks/question-answering) | `question-answering`
    | 从给定文本中检索问题的答案。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.QuestionAnsweringPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=question-answering&library=transformers.js)
    |'
- en: '| [Sentence Similarity](https://huggingface.co/tasks/sentence-similarity) |
    `sentence-similarity` | Determining how similar two texts are. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| [句子相似度](https://huggingface.co/tasks/sentence-similarity) | `sentence-similarity`
    | 确定两个文本有多相似。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
- en: '| [Summarization](https://huggingface.co/tasks/summarization) | `summarization`
    | Producing a shorter version of a document while preserving its important information.
    | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.SummarizationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=summarization&library=transformers.js)
    |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| [摘要](https://huggingface.co/tasks/summarization) | `summarization` | 生成文档的简短版本，同时保留其重要信息。
    | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.SummarizationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=summarization&library=transformers.js)
    |'
- en: '| [Table Question Answering](https://huggingface.co/tasks/table-question-answering)
    | `table-question-answering` | Answering a question about information from a given
    table. | ❌ |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| [表格问答](https://huggingface.co/tasks/table-question-answering) | `table-question-answering`
    | 回答关于给定表格信息的问题。 | ❌ |'
- en: '| [Text Classification](https://huggingface.co/tasks/text-classification) |
    `text-classification` or `sentiment-analysis` | Assigning a label or class to
    a given text. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| [文本分类](https://huggingface.co/tasks/text-classification) | `text-classification`
    或 `sentiment-analysis` | 为给定文本分配一个标签或类别。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextClassificationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers.js)
    |'
- en: '| [Text Generation](https://huggingface.co/tasks/text-generation#completion-generation-models)
    | `text-generation` | Producing new text by predicting the next word in a sequence.
    | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextGenerationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text-generation&library=transformers.js)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| [文本生成](https://huggingface.co/tasks/text-generation#completion-generation-models)
    | `text-generation` | 通过预测序列中的下一个单词生成新文本。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextGenerationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=text-generation&library=transformers.js)
    |'
- en: '| [Text-to-text Generation](https://huggingface.co/tasks/text-generation#text-to-text-generation-models)
    | `text2text-generation` | Converting one text sequence into another text sequence.
    | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.Text2TextGenerationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text2text-generation&library=transformers.js)
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| [文本到文本生成](https://huggingface.co/tasks/text-generation#text-to-text-generation-models)
    | `text2text-generation` | 将一个文本序列转换为另一个文本序列。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.Text2TextGenerationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=text2text-generation&library=transformers.js)
    |'
- en: '| [Token Classification](https://huggingface.co/tasks/token-classification)
    | `token-classification` or `ner` | Assigning a label to each token in a text.
    | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TokenClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=token-classification&library=transformers.js)
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| [标记分类](https://huggingface.co/tasks/token-classification) | `token-classification`
    或 `ner` | 为文本中的每个标记分配一个标签。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TokenClassificationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=token-classification&library=transformers.js)
    |'
- en: '| [Translation](https://huggingface.co/tasks/translation) | `translation` |
    Converting text from one language to another. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TranslationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=translation&library=transformers.js)
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| [翻译](https://huggingface.co/tasks/translation) | `translation` | 将文本从一种语言转换为另一种语言。
    | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TranslationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=translation&library=transformers.js)
    |'
- en: '| [Zero-Shot Classification](https://huggingface.co/tasks/zero-shot-classification)
    | `zero-shot-classification` | Classifying text into classes that are unseen during
    training. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=zero-shot-classification&library=transformers.js)
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| [零样本分类](https://huggingface.co/tasks/zero-shot-classification) | `zero-shot-classification`
    | 将文本分类为训练期间未见过的类别。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotClassificationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=zero-shot-classification&library=transformers.js)
    |'
- en: Vision
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Vision
- en: '| Task | ID | Description | Supported? |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ID | 描述 | 支持？ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Depth Estimation](https://huggingface.co/tasks/depth-estimation) | `depth-estimation`
    | Predicting the depth of objects present in an image. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DepthEstimationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=depth-estimation&library=transformers.js)
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| [深度估计](https://huggingface.co/tasks/depth-estimation) | `depth-estimation`
    | 预测图像中存在的对象的深度。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DepthEstimationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=depth-estimation&library=transformers.js)
    |'
- en: '| [Image Classification](https://huggingface.co/tasks/image-classification)
    | `image-classification` | Assigning a label or class to an entire image. | ✅
    [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-classification&library=transformers.js)
    |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| [图像分类](https://huggingface.co/tasks/image-classification) | `image-classification`
    | 为整个图像分配一个标签或类别。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageClassificationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=image-classification&library=transformers.js)
    |'
- en: '| [Image Segmentation](https://huggingface.co/tasks/image-segmentation) | `image-segmentation`
    | Divides an image into segments where each pixel is mapped to an object. This
    task has multiple variants such as instance segmentation, panoptic segmentation
    and semantic segmentation. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageSegmentationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-segmentation&library=transformers.js)
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| [图像分割](https://huggingface.co/tasks/image-segmentation) | `image-segmentation`
    | 将图像分割成每个像素映射到一个对象的段。这个任务有多个变体，如实例分割、全景分割和语义分割。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageSegmentationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=image-segmentation&library=transformers.js)
    |'
- en: '| [Image-to-Image](https://huggingface.co/tasks/image-to-image) | `image-to-image`
    | Transforming a source image to match the characteristics of a target image or
    a target image domain. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToImagePipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-to-image&library=transformers.js)
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| [图像到图像](https://huggingface.co/tasks/image-to-image) | `image-to-image` |
    将源图像转换为与目标图像或目标图像域的特征相匹配的图像。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToImagePipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=image-to-image&library=transformers.js)
    |'
- en: '| [Mask Generation](https://huggingface.co/tasks/mask-generation) | `mask-generation`
    | Generate masks for the objects in an image. | ❌ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| [掩模生成](https://huggingface.co/tasks/mask-generation) | `mask-generation`
    | 为图像中的对象生成掩模。 | ❌ |'
- en: '| [Object Detection](https://huggingface.co/tasks/object-detection) | `object-detection`
    | Identify objects of certain defined classes within an image. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ObjectDetectionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=object-detection&library=transformers.js)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| [目标检测](https://huggingface.co/tasks/object-detection) | `object-detection`
    | 在图像中识别特定定义类别的对象。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ObjectDetectionPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=object-detection&library=transformers.js)
    |'
- en: '| [Video Classification](https://huggingface.co/tasks/video-classification)
    | n/a | Assigning a label or class to an entire video. | ❌ |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| [视频分类](https://huggingface.co/tasks/video-classification) | n/a | 为整个视频分配标签或类别。
    | ❌ |'
- en: '| [Unconditional Image Generation](https://huggingface.co/tasks/unconditional-image-generation)
    | n/a | Generating images with no condition in any context (like a prompt text
    or another image). | ❌ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| [无条件图像生成](https://huggingface.co/tasks/unconditional-image-generation) |
    n/a | 在任何情境中（如提示文本或另一图像）生成无条件的图像。 | ❌ |'
- en: Audio
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 音频
- en: '| Task | ID | Description | Supported? |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ID | 描述 | 是否支持？ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Audio Classification](https://huggingface.co/tasks/audio-classification)
    | `audio-classification` | Assigning a label or class to a given audio. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AudioClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=audio-classification&library=transformers.js)
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [音频分类](https://huggingface.co/tasks/audio-classification) | `audio-classification`
    | 为给定音频分配标签或类别。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AudioClassificationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=audio-classification&library=transformers.js)
    |'
- en: '| [Audio-to-Audio](https://huggingface.co/tasks/audio-to-audio) | n/a | Generating
    audio from an input audio source. | ❌ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| [音频到音频](https://huggingface.co/tasks/audio-to-audio) | n/a | 从输入音频源生成音频。
    | ❌ |'
- en: '| [Automatic Speech Recognition](https://huggingface.co/tasks/automatic-speech-recognition)
    | `automatic-speech-recognition` | Transcribing a given audio into text. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AutomaticSpeechRecognitionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&library=transformers.js)
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| [自动语音识别](https://huggingface.co/tasks/automatic-speech-recognition) | `automatic-speech-recognition`
    | 将给定音频转录为文本。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.AutomaticSpeechRecognitionPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&library=transformers.js)
    |'
- en: '| [Text-to-Speech](https://huggingface.co/tasks/text-to-speech) | `text-to-speech`
    or `text-to-audio` | Generating natural-sounding speech given text input. | ✅
    [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextToAudioPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=text-to-audio&library=transformers.js)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [文本到语音](https://huggingface.co/tasks/text-to-speech) | `text-to-speech` 或
    `text-to-audio` | 根据文本输入生成自然音质的语音。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.TextToAudioPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=text-to-audio&library=transformers.js)
    |'
- en: Tabular
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 表格
- en: '| Task | ID | Description | Supported? |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ID | 描述 | 是否支持？ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Tabular Classification](https://huggingface.co/tasks/tabular-classification)
    | n/a | Classifying a target category (a group) based on set of attributes. |
    ❌ |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| [表格分类](https://huggingface.co/tasks/tabular-classification) | n/a | 根据属性集对目标类别（一组）进行分类。
    | ❌ |'
- en: '| [Tabular Regression](https://huggingface.co/tasks/tabular-regression) | n/a
    | Predicting a numerical value given a set of attributes. | ❌ |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [表格回归](https://huggingface.co/tasks/tabular-regression) | n/a | 根据属性集预测数值。
    | ❌ |'
- en: Multimodal
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多模态
- en: '| Task | ID | Description | Supported? |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ID | 描述 | 是否支持？ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Document Question Answering](https://huggingface.co/tasks/document-question-answering)
    | `document-question-answering` | Answering questions on document images. | ✅
    [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DocumentQuestionAnsweringPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=document-question-answering&library=transformers.js)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| [文档问答](https://huggingface.co/tasks/document-question-answering) | `document-question-answering`
    | 回答文档图像上的问题。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.DocumentQuestionAnsweringPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=document-question-answering&library=transformers.js)
    |'
- en: '| [Feature Extraction](https://huggingface.co/tasks/feature-extraction) | `feature-extraction`
    | Transforming raw data into numerical features that can be processed while preserving
    the information in the original dataset. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| [特征提取](https://huggingface.co/tasks/feature-extraction) | `feature-extraction`
    | 将原始数据转换为可以处理的数值特征，同时保留原始数据集中的信息。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.FeatureExtractionPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=feature-extraction&library=transformers.js)
    |'
- en: '| [Image-to-Text](https://huggingface.co/tasks/image-to-text) | `image-to-text`
    | Output text from a given image. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToTextPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=image-to-text&library=transformers.js)
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| [图像到文本](https://huggingface.co/tasks/image-to-text) | `image-to-text` | 从给定图像输出文本。
    | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ImageToTextPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=image-to-text&library=transformers.js)
    |'
- en: '| [Text-to-Image](https://huggingface.co/tasks/text-to-image) | `text-to-image`
    | Generates images from input text. | ❌ |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| [文本到图像](https://huggingface.co/tasks/text-to-image) | `text-to-image` | 从输入文本生成图像。
    | ❌ |'
- en: '| [Visual Question Answering](https://huggingface.co/tasks/visual-question-answering)
    | `visual-question-answering` | Answering open-ended questions based on an image.
    | ❌ |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| [视觉问答](https://huggingface.co/tasks/visual-question-answering) | `visual-question-answering`
    | 根据图像回答开放式问题。 | ❌ |'
- en: '| [Zero-Shot Audio Classification](https://huggingface.co/learn/audio-course/chapter4/classification_models#zero-shot-audio-classification)
    | `zero-shot-audio-classification` | Classifying audios into classes that are
    unseen during training. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotAudioClassificationPipeline)
    [(models)](https://huggingface.co/models?other=zero-shot-audio-classification&library=transformers.js)
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| [零样本音频分类](https://huggingface.co/learn/audio-course/chapter4/classification_models#zero-shot-audio-classification)
    | `zero-shot-audio-classification` | 将音频分类为在训练过程中未见过的类别。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotAudioClassificationPipeline)
    [(模型)](https://huggingface.co/models?other=zero-shot-audio-classification&library=transformers.js)
    |'
- en: '| [Zero-Shot Image Classification](https://huggingface.co/tasks/zero-shot-image-classification)
    | `zero-shot-image-classification` | Classifying images into classes that are
    unseen during training. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotImageClassificationPipeline)
    [(models)](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&library=transformers.js)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| [零样本图像分类](https://huggingface.co/tasks/zero-shot-image-classification) |
    `zero-shot-image-classification` | 将图像分类为在训练过程中未见过的类别。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotImageClassificationPipeline)
    [(模型)](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&library=transformers.js)
    |'
- en: '| [Zero-Shot Object Detection](https://huggingface.co/tasks/zero-shot-object-detection)
    | `zero-shot-object-detection` | Identify objects of classes that are unseen during
    training. | ✅ [(docs)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotObjectDetectionPipeline)
    [(models)](https://huggingface.co/models?other=zero-shot-object-detection&library=transformers.js)
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| [零样本目标检测](https://huggingface.co/tasks/zero-shot-object-detection) | `zero-shot-object-detection`
    | 识别在训练过程中未见过的类别的对象。 | ✅ [(文档)](https://huggingface.co/docs/transformers.js/api/pipelines#module_pipelines.ZeroShotObjectDetectionPipeline)
    [(模型)](https://huggingface.co/models?other=zero-shot-object-detection&library=transformers.js)
    |'
- en: Reinforcement Learning
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强化学习
- en: '| Task | ID | Description | Supported? |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ID | 描述 | 是否支持？ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [Reinforcement Learning](https://huggingface.co/tasks/reinforcement-learning)
    | n/a | Learning from actions by interacting with an environment through trial
    and error and receiving rewards (negative or positive) as feedback. | ❌ |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| [强化学习](https://huggingface.co/tasks/reinforcement-learning) | n/a | 通过与环境互动，通过试错学习行为，并根据奖励（负面或正面）作为反馈。
    | ❌ |'
- en: Models
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型
- en: '**[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from
    Google Research and the Toyota Technological Institute at Chicago) released with
    the paper [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942),
    by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma,
    Radu Soricut.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)**（来自Google
    Research和芝加哥丰田技术研究所）发布了论文[ALBERT:自监督学习语言表示的轻量BERT](https://arxiv.org/abs/1909.11942)，作者是Zhenzhong
    Lan，Mingda Chen，Sebastian Goodman，Kevin Gimpel，Piyush Sharma，Radu Soricut。'
- en: '**[Audio Spectrogram Transformer](https://huggingface.co/docs/transformers/model_doc/audio-spectrogram-transformer)**
    (from MIT) released with the paper [AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778)
    by Yuan Gong, Yu-An Chung, James Glass.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[音频频谱变换器](https://huggingface.co/docs/transformers/model_doc/audio-spectrogram-transformer)**（来自MIT）发布了论文[AST:音频频谱变换器](https://arxiv.org/abs/2104.01778)，作者是Yuan
    Gong，Yu-An Chung，James Glass。'
- en: '**[BART](https://huggingface.co/docs/transformers/model_doc/bart)** (from Facebook)
    released with the paper [BART: Denoising Sequence-to-Sequence Pre-training for
    Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)
    by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
    Omer Levy, Ves Stoyanov and Luke Zettlemoyer.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BART](https://huggingface.co/docs/transformers/model_doc/bart)**（来自Facebook）发布了论文[BART:去噪序列到序列预训练用于自然语言生成、翻译和理解](https://arxiv.org/abs/1910.13461)，作者是Mike
    Lewis，Yinhan Liu，Naman Goyal，Marjan Ghazvininejad，Abdelrahman Mohamed，Omer Levy，Ves
    Stoyanov和Luke Zettlemoyer。'
- en: '**[BEiT](https://huggingface.co/docs/transformers/model_doc/beit)** (from Microsoft)
    released with the paper [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254)
    by Hangbo Bao, Li Dong, Furu Wei.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BEiT](https://huggingface.co/docs/transformers/model_doc/beit)**（来自微软）发布了论文[BEiT:
    图像Transformer的BERT预训练](https://arxiv.org/abs/2106.08254)，作者是Hangbo Bao，Li Dong，Furu
    Wei。'
- en: '**[BERT](https://huggingface.co/docs/transformers/model_doc/bert)** (from Google)
    released with the paper [BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding](https://arxiv.org/abs/1810.04805) by Jacob Devlin,
    Ming-Wei Chang, Kenton Lee and Kristina Toutanova.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BERT](https://huggingface.co/docs/transformers/model_doc/bert)**（来自Google）发布了论文[BERT:深度双向Transformer的预训练用于语言理解](https://arxiv.org/abs/1810.04805)，作者是Jacob
    Devlin，Ming-Wei Chang，Kenton Lee和Kristina Toutanova。'
- en: '**[Blenderbot](https://huggingface.co/docs/transformers/model_doc/blenderbot)**
    (from Facebook) released with the paper [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637)
    by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu,
    Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Blenderbot](https://huggingface.co/docs/transformers/model_doc/blenderbot)**（来自Facebook）发布了论文[构建开放域聊天机器人的配方](https://arxiv.org/abs/2004.13637)，作者是Stephen
    Roller，Emily Dinan，Naman Goyal，Da Ju，Mary Williamson，Yinhan Liu，Jing Xu，Myle Ott，Kurt
    Shuster，Eric M. Smith，Y-Lan Boureau，Jason Weston。'
- en: '**[BlenderbotSmall](https://huggingface.co/docs/transformers/model_doc/blenderbot-small)**
    (from Facebook) released with the paper [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637)
    by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu,
    Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BlenderbotSmall](https://huggingface.co/docs/transformers/model_doc/blenderbot-small)**（来自Facebook）由Stephen
    Roller、Emily Dinan、Naman Goyal、Da Ju、Mary Williamson、Yinhan Liu、Jing Xu、Myle Ott、Kurt
    Shuster、Eric M. Smith、Y-Lan Boureau、Jason Weston发布的论文[Recipes for building an
    open-domain chatbot](https://arxiv.org/abs/2004.13637)。'
- en: '**[BLOOM](https://huggingface.co/docs/transformers/model_doc/bloom)** (from
    BigScience workshop) released by the [BigScience Workshop](https://bigscience.huggingface.co/).'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[BLOOM](https://huggingface.co/docs/transformers/model_doc/bloom)**（来自BigScience
    workshop）由[BigScience Workshop](https://bigscience.huggingface.co/)发布。'
- en: '**[CamemBERT](https://huggingface.co/docs/transformers/model_doc/camembert)**
    (from Inria/Facebook/Sorbonne) released with the paper [CamemBERT: a Tasty French
    Language Model](https://arxiv.org/abs/1911.03894) by Louis Martin*, Benjamin Muller*,
    Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la
    Clergerie, Djamé Seddah and Benoît Sagot.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CamemBERT](https://huggingface.co/docs/transformers/model_doc/camembert)**（来自Inria/Facebook/Sorbonne）由Louis
    Martin*、Benjamin Muller*、Pedro Javier Ortiz Suárez*、Yoann Dupont、Laurent Romary、Éric
    Villemonte de la Clergerie、Djamé Seddah和Benoît Sagot发布的论文[CamemBERT: a Tasty French
    Language Model](https://arxiv.org/abs/1911.03894)。'
- en: '**[Chinese-CLIP](https://huggingface.co/docs/transformers/model_doc/chinese_clip)**
    (from OFA-Sys) released with the paper [Chinese CLIP: Contrastive Vision-Language
    Pretraining in Chinese](https://arxiv.org/abs/2211.01335) by An Yang, Junshu Pan,
    Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Chinese-CLIP](https://huggingface.co/docs/transformers/model_doc/chinese_clip)**（来自OFA-Sys）由An
    Yang、Junshu Pan、Junyang Lin、Rui Men、Yichang Zhang、Jingren Zhou、Chang Zhou发布的论文[Chinese
    CLIP: Contrastive Vision-Language Pretraining in Chinese](https://arxiv.org/abs/2211.01335)。'
- en: '**[CLAP](https://huggingface.co/docs/transformers/model_doc/clap)** (from LAION-AI)
    released with the paper [Large-scale Contrastive Language-Audio Pretraining with
    Feature Fusion and Keyword-to-Caption Augmentation](https://arxiv.org/abs/2211.06687)
    by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo
    Dubnov.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CLAP](https://huggingface.co/docs/transformers/model_doc/clap)**（来自LAION-AI）由Yusong
    Wu、Ke Chen、Tianyu Zhang、Yuchen Hui、Taylor Berg-Kirkpatrick、Shlomo Dubnov发布的论文[Large-scale
    Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption
    Augmentation](https://arxiv.org/abs/2211.06687)。'
- en: '**[CLIP](https://huggingface.co/docs/transformers/model_doc/clip)** (from OpenAI)
    released with the paper [Learning Transferable Visual Models From Natural Language
    Supervision](https://arxiv.org/abs/2103.00020) by Alec Radford, Jong Wook Kim,
    Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda
    Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CLIP](https://huggingface.co/docs/transformers/model_doc/clip)**（来自OpenAI）由Alec
    Radford、Jong Wook Kim、Chris Hallacy、Aditya Ramesh、Gabriel Goh、Sandhini Agarwal、Girish
    Sastry、Amanda Askell、Pamela Mishkin、Jack Clark、Gretchen Krueger、Ilya Sutskever发布的论文[Learning
    Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)。'
- en: '**[CLIPSeg](https://huggingface.co/docs/transformers/model_doc/clipseg)** (from
    University of Göttingen) released with the paper [Image Segmentation Using Text
    and Image Prompts](https://arxiv.org/abs/2112.10003) by Timo Lüddecke and Alexander
    Ecker.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CLIPSeg](https://huggingface.co/docs/transformers/model_doc/clipseg)**（来自Göttingen大学）由Timo
    Lüddecke和Alexander Ecker发布的论文[Image Segmentation Using Text and Image Prompts](https://arxiv.org/abs/2112.10003)。'
- en: '**[CodeGen](https://huggingface.co/docs/transformers/model_doc/codegen)** (from
    Salesforce) released with the paper [A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474)
    by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio
    Savarese, Caiming Xiong.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CodeGen](https://huggingface.co/docs/transformers/model_doc/codegen)**（来自Salesforce）由Erik
    Nijkamp、Bo Pang、Hiroaki Hayashi、Lifu Tu、Huan Wang、Yingbo Zhou、Silvio Savarese、Caiming
    Xiong发布的论文[A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474)。'
- en: '**[CodeLlama](https://huggingface.co/docs/transformers/model_doc/llama_code)**
    (from MetaAI) released with the paper [Code Llama: Open Foundation Models for
    Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)
    by Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing
    Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov,
    Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori,
    Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis
    Martin, Nicolas Usunier, Thomas Scialom, Gabriel Synnaeve.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[CodeLlama](https://huggingface.co/docs/transformers/model_doc/llama_code)**（来自MetaAI）由Baptiste
    Rozière、Jonas Gehring、Fabian Gloeckle、Sten Sootla、Itai Gat、Xiaoqing Ellen Tan、Yossi
    Adi、Jingyu Liu、Tal Remez、Jérémy Rapin、Artyom Kozhevnikov、Ivan Evtimov、Joanna Bitton、Manish
    Bhatt、Cristian Canton Ferrer、Aaron Grattafiori、Wenhan Xiong、Alexandre Défossez、Jade
    Copet、Faisal Azhar、Hugo Touvron、Louis Martin、Nicolas Usunier、Thomas Scialom、Gabriel
    Synnaeve发布的论文[Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code)。'
- en: '**[ConvBERT](https://huggingface.co/docs/transformers/model_doc/convbert)**
    (from YituTech) released with the paper [ConvBERT: Improving BERT with Span-based
    Dynamic Convolution](https://arxiv.org/abs/2008.02496) by Zihang Jiang, Weihao
    Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ConvBERT](https://huggingface.co/docs/transformers/model_doc/convbert)**（来自YituTech）由Zihang
    Jiang、Weihao Yu、Daquan Zhou、Yunpeng Chen、Jiashi Feng、Shuicheng Yan发布的论文[ConvBERT:
    Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496)。'
- en: '**[ConvNeXT](https://huggingface.co/docs/transformers/model_doc/convnext)**
    (from Facebook AI) released with the paper [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
    by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
    Saining Xie.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ConvNeXT](https://huggingface.co/docs/transformers/model_doc/convnext)**（来自Facebook
    AI）由Zhuang Liu、Hanzi Mao、Chao-Yuan Wu、Christoph Feichtenhofer、Trevor Darrell、Saining
    Xie发布的论文[A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)。'
- en: '**[ConvNeXTV2](https://huggingface.co/docs/transformers/model_doc/convnextv2)**
    (from Facebook AI) released with the paper [ConvNeXt V2: Co-designing and Scaling
    ConvNets with Masked Autoencoders](https://arxiv.org/abs/2301.00808) by Sanghyun
    Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining
    Xie.'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ConvNeXTV2](https://huggingface.co/docs/transformers/model_doc/convnextv2)**（来自Facebook
    AI）与Sanghyun Woo、Shoubhik Debnath、Ronghang Hu、Xinlei Chen、Zhuang Liu、In So Kweon、Saining
    Xie 的论文[ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders](https://arxiv.org/abs/2301.00808)一同发布。'
- en: '**[DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta)** (from
    Microsoft) released with the paper [DeBERTa: Decoding-enhanced BERT with Disentangled
    Attention](https://arxiv.org/abs/2006.03654) by Pengcheng He, Xiaodong Liu, Jianfeng
    Gao, Weizhu Chen.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta)**（来自微软）与Pengcheng
    He、Xiaodong Liu、Jianfeng Gao、Weizhu Chen 的论文[DeBERTa: Decoding-enhanced BERT with
    Disentangled Attention](https://arxiv.org/abs/2006.03654)一同发布。'
- en: '**[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)**
    (from Microsoft) released with the paper [DeBERTa: Decoding-enhanced BERT with
    Disentangled Attention](https://arxiv.org/abs/2006.03654) by Pengcheng He, Xiaodong
    Liu, Jianfeng Gao, Weizhu Chen.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)**（来自微软）与Pengcheng
    He、Xiaodong Liu、Jianfeng Gao、Weizhu Chen 的论文[DeBERTa: Decoding-enhanced BERT with
    Disentangled Attention](https://arxiv.org/abs/2006.03654)一同发布。'
- en: '**[DeiT](https://huggingface.co/docs/transformers/model_doc/deit)** (from Facebook)
    released with the paper [Training data-efficient image transformers & distillation
    through attention](https://arxiv.org/abs/2012.12877) by Hugo Touvron, Matthieu
    Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DeiT](https://huggingface.co/docs/transformers/model_doc/deit)**（来自Facebook）与Hugo
    Touvron、Matthieu Cord、Matthijs Douze、Francisco Massa、Alexandre Sablayrolles、Hervé
    Jégou 的论文[Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)一同发布。'
- en: '**[Depth Anything](https://huggingface.co/docs/transformers/main/model_doc/depth_anything)**
    (from University of Hong Kong and TikTok) released with the paper [Depth Anything:
    Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891)
    by Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, Hengshuang
    Zhao.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Depth Anything](https://huggingface.co/docs/transformers/main/model_doc/depth_anything)**（来自香港大学和TikTok）与Lihe
    Yang、Bingyi Kang、Zilong Huang、Xiaogang Xu、Jiashi Feng、Hengshuang Zhao 的论文[Depth
    Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891)一同发布。'
- en: '**[DETR](https://huggingface.co/docs/transformers/model_doc/detr)** (from Facebook)
    released with the paper [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)
    by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
    Kirillov, Sergey Zagoruyko.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DETR](https://huggingface.co/docs/transformers/model_doc/detr)**（来自Facebook）与Nicolas
    Carion、Francisco Massa、Gabriel Synnaeve、Nicolas Usunier、Alexander Kirillov、Sergey
    Zagoruyko 的论文[End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)一同发布。'
- en: '**[DINOv2](https://huggingface.co/docs/transformers/model_doc/dinov2)** (from
    Meta AI) released with the paper [DINOv2: Learning Robust Visual Features without
    Supervision](https://arxiv.org/abs/2304.07193) by Maxime Oquab, Timothée Darcet,
    Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel
    Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech
    Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat,
    Vasu Sharma, Gabriel Synnaeve, Hu Xu, Hervé Jegou, Julien Mairal, Patrick Labatut,
    Armand Joulin, Piotr Bojanowski.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DINOv2](https://huggingface.co/docs/transformers/model_doc/dinov2)**（来自Meta
    AI）与Maxime Oquab、Timothée Darcet、Théo Moutakanni、Huy Vo、Marc Szafraniec、Vasil
    Khalidov、Pierre Fernandez、Daniel Haziza、Francisco Massa、Alaaeldin El-Nouby、Mahmoud
    Assran、Nicolas Ballas、Wojciech Galuba、Russell Howes、Po-Yao Huang、Shang-Wen Li、Ishan
    Misra、Michael Rabbat、Vasu Sharma、Gabriel Synnaeve、Hu Xu、Hervé Jegou、Julien Mairal、Patrick
    Labatut、Armand Joulin、Piotr Bojanowski 的论文[DINOv2: Learning Robust Visual Features
    without Supervision](https://arxiv.org/abs/2304.07193)一同发布。'
- en: '**[DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)**
    (from HuggingFace), released together with the paper [DistilBERT, a distilled
    version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)
    by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied
    to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation),
    RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation),
    Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)
    and a German version of DistilBERT.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)**（来自HuggingFace）与Victor
    Sanh、Lysandre Debut 和 Thomas Wolf 的论文[DistilBERT, a distilled version of BERT:
    smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)一同发布。相同的方法已被应用于将GPT2压缩为[DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)、RoBERTa压缩为[DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)、Multilingual
    BERT压缩为[DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation)以及德语版本的DistilBERT。'
- en: '**[DiT](https://huggingface.co/docs/transformers/model_doc/dit)** (from Microsoft
    Research) released with the paper [DiT: Self-supervised Pre-training for Document
    Image Transformer](https://arxiv.org/abs/2203.02378) by Junlong Li, Yiheng Xu,
    Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DiT](https://huggingface.co/docs/transformers/model_doc/dit)**（来自微软研究）与Junlong
    Li、Yiheng Xu、Tengchao Lv、Lei Cui、Cha Zhang、Furu Wei 的论文[DiT: Self-supervised Pre-training
    for Document Image Transformer](https://arxiv.org/abs/2203.02378)一同发布。'
- en: '**[Donut](https://huggingface.co/docs/transformers/model_doc/donut)** (from
    NAVER), released together with the paper [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664)
    by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong
    Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Donut](https://huggingface.co/docs/transformers/model_doc/donut)**（来自NAVER）与Geewook
    Kim、Teakgyu Hong、Moonbin Yim、Jeongyeon Nam、Jinyoung Park、Jinyeong Yim、Wonseok
    Hwang、Sangdoo Yun、Dongyoon Han、Seunghyun Park 的论文[OCR-free Document Understanding
    Transformer](https://arxiv.org/abs/2111.15664)一同发布。'
- en: '**[DPT](https://huggingface.co/docs/transformers/master/model_doc/dpt)** (from
    Intel Labs) released with the paper [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)
    by René Ranftl, Alexey Bochkovskiy, Vladlen Koltun.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[DPT](https://huggingface.co/docs/transformers/master/model_doc/dpt)**（来自英特尔实验室）与René
    Ranftl、Alexey Bochkovskiy、Vladlen Koltun合著的论文[用于密集预测的视觉Transformer](https://arxiv.org/abs/2103.13413)一起发布。'
- en: '**[ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)** (from
    Google Research/Stanford University) released with the paper [ELECTRA: Pre-training
    text encoders as discriminators rather than generators](https://arxiv.org/abs/2003.10555)
    by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)**（来自Google
    Research/斯坦福大学）与Kevin Clark、Minh-Thang Luong、Quoc V. Le、Christopher D. Manning合著的论文[将文本编码器预训练为判别器而不是生成器](https://arxiv.org/abs/2003.10555)一起发布。'
- en: '**[ESM](https://huggingface.co/docs/transformers/model_doc/esm)** (from Meta
    AI) are transformer protein language models. **ESM-1b** was released with the
    paper [Biological structure and function emerge from scaling unsupervised learning
    to 250 million protein sequences](https://www.pnas.org/content/118/15/e2016239118)
    by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason
    Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. **ESM-1v**
    was released with the paper [Language models enable zero-shot prediction of the
    effects of mutations on protein function](https://doi.org/10.1101/2021.07.09.450648)
    by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander
    Rives. **ESM-2 and ESMFold** were released with the paper [Language models of
    protein sequences at the scale of evolution enable accurate structure prediction](https://doi.org/10.1101/2022.07.20.500902)
    by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan
    dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ESM](https://huggingface.co/docs/transformers/model_doc/esm)**（来自Meta AI）是变压器蛋白质语言模型。**ESM-1b**与Alexander
    Rives、Joshua Meier、Tom Sercu、Siddharth Goyal、Zeming Lin、Jason Liu、Demi Guo、Myle
    Ott、C. Lawrence Zitnick、Jerry Ma和Rob Fergus合著的论文[从扩展无监督学习到2.5亿蛋白质序列的生物结构和功能](https://www.pnas.org/content/118/15/e2016239118)一起发布。**ESM-1v**与Joshua
    Meier、Roshan Rao、Robert Verkuil、Jason Liu、Tom Sercu和Alexander Rives合著的论文[语言模型实现对蛋白质功能突变的零样本预测](https://doi.org/10.1101/2021.07.09.450648)一起发布。**ESM-2和ESMFold**与Zeming
    Lin、Halil Akin、Roshan Rao、Brian Hie、Zhongkai Zhu、Wenting Lu、Allan dos Santos Costa、Maryam
    Fazel-Zarandi、Tom Sercu、Sal Candido、Alexander Rives合著的论文[蛋白质序列的语言模型在演化尺度上实现准确的结构预测](https://doi.org/10.1101/2022.07.20.500902)一起发布。'
- en: '**[Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)** (from
    Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and
    Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah,
    Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic,
    Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)**（来自技术创新研究所）由Almazrouei、Ebtesam、Alobeidli、Hamza、Alshamsi、Abdulaziz、Cappelli、Alessandro、Cojocaru、Ruxandra、Debbah、Merouane、Goffinet、Etienne、Heslow、Daniel、Launay、Julien、Malartic、Quentin、Noune、Badreddine、Pannier、Baptiste、Penedo、Guilherme等人合作。'
- en: '**[FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)** (from
    Google AI) released in the repository [google-research/t5x](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints)
    by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
    Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang
    Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang,
    Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu,
    Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc
    V. Le, and Jason Wei'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)**（来自Google
    AI）由Hyung Won Chung、Le Hou、Shayne Longpre、Barret Zoph、Yi Tay、William Fedus、Eric
    Li、Xuezhi Wang、Mostafa Dehghani、Siddhartha Brahma、Albert Webson、Shixiang Shane
    Gu、Zhuyun Dai、Mirac Suzgun、Xinyun Chen、Aakanksha Chowdhery、Sharan Narang、Gaurav
    Mishra、Adams Yu、Vincent Zhao、Yanping Huang、Andrew Dai、Hongkun Yu、Slav Petrov、Ed
    H. Chi、Jeff Dean、Jacob Devlin、Adam Roberts、Denny Zhou、Quoc V. Le和Jason Wei合作发布。'
- en: '**[GLPN](https://huggingface.co/docs/transformers/model_doc/glpn)** (from KAIST)
    released with the paper [Global-Local Path Networks for Monocular Depth Estimation
    with Vertical CutDepth](https://arxiv.org/abs/2201.07436) by Doyeon Kim, Woonghyun
    Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GLPN](https://huggingface.co/docs/transformers/model_doc/glpn)**（来自KAIST）与Doyeon
    Kim、Woonghyun Ga、Pyungwhan Ahn、Donggyu Joo、Sehwan Chun、Junmo Kim合著的论文[全局-局部路径网络用于单目深度估计与垂直切割深度](https://arxiv.org/abs/2201.07436)一起发布。'
- en: '**[GPT Neo](https://huggingface.co/docs/transformers/model_doc/gpt_neo)** (from
    EleutherAI) released in the repository [EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo)
    by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT Neo](https://huggingface.co/docs/transformers/model_doc/gpt_neo)**（来自EleutherAI）由Sid
    Black、Stella Biderman、Leo Gao、Phil Wang和Connor Leahy合作发布。'
- en: '**[GPT NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)**
    (from EleutherAI) released with the paper [GPT-NeoX-20B: An Open-Source Autoregressive
    Language Model](https://arxiv.org/abs/2204.06745) by Sid Black, Stella Biderman,
    Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy,
    Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit,
    Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)**（来自EleutherAI）与Sid
    Black、Stella Biderman、Eric Hallahan、Quentin Anthony、Leo Gao、Laurence Golding、Horace
    He、Connor Leahy、Kyle McDonell、Jason Phang、Michael Pieler、USVSN Sai Prashanth、Shivanshu
    Purohit、Laria Reynolds、Jonathan Tow、Ben Wang、Samuel Weinbach合著的论文[GPT-NeoX-20B：一个开源的自回归语言模型](https://arxiv.org/abs/2204.06745)一起发布。'
- en: '**[GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2)** (from
    OpenAI) released with the paper [Language Models are Unsupervised Multitask Learners](https://blog.openai.com/better-language-models/)
    by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei**and Ilya
    Sutskever**.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2)**（来自OpenAI）与Alec
    Radford*、Jeffrey Wu*、Rewon Child、David Luan、Dario Amodei**和Ilya Sutskever**合著的论文[《Language
    Models are Unsupervised Multitask Learners》](https://blog.openai.com/better-language-models/)一同发布。'
- en: '**[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)** (from
    EleutherAI) released in the repository [kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/)
    by Ben Wang and Aran Komatsuzaki.'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)**（来自EleutherAI）由Ben
    Wang和Aran Komatsuzaki在[repository kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/)中发布。'
- en: '**[GPTBigCode](https://huggingface.co/docs/transformers/model_doc/gpt_bigcode)**
    (from BigCode) released with the paper [SantaCoder: don’t reach for the stars!](https://arxiv.org/abs/2301.03988)
    by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki,
    Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey,
    Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier,
    Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert,
    Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya,
    Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David
    Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine
    Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[GPTBigCode](https://huggingface.co/docs/transformers/model_doc/gpt_bigcode)**（来自BigCode）与Loubna
    Ben Allal、Raymond Li、Denis Kocetkov、Chenghao Mou、Christopher Akiki、Carlos Munoz
    Ferrandis、Niklas Muennighoff、Mayank Mishra、Alex Gu、Manan Dey、Logesh Kumar Umapathi、Carolyn
    Jane Anderson、Yangtian Zi、Joel Lamy Poirier、Hailey Schoelkopf、Sergey Troshin、Dmitry
    Abulkhanov、Manuel Romero、Michael Lappert、Francesco De Toni、Bernardo García del
    Río、Qian Liu、Shamik Bose、Urvashi Bhattacharyya、Terry Yue Zhuo、Ian Yu、Paulo Villegas、Marco
    Zocca、Sourab Mangrulkar、David Lansky、Huu Nguyen、Danish Contractor、Luis Villa、Jia
    Li、Dzmitry Bahdanau、Yacine Jernite、Sean Hughes、Daniel Fried、Arjun Guha、Harm de
    Vries、Leandro von Werra合著的论文[《SantaCoder: don’t reach for the stars!》](https://arxiv.org/abs/2301.03988)一同发布。'
- en: '**[HerBERT](https://huggingface.co/docs/transformers/model_doc/herbert)** (from
    Allegro.pl, AGH University of Science and Technology) released with the paper
    [KLEJ: Comprehensive Benchmark for Polish Language Understanding](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)
    by Piotr Rybak, Robert Mroczkowski, Janusz Tracz, Ireneusz Gawlik.'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[HerBERT](https://huggingface.co/docs/transformers/model_doc/herbert)**（来自Allegro.pl,
    AGH科技大学）与Piotr Rybak、Robert Mroczkowski、Janusz Tracz、Ireneusz Gawlik合著的论文[《KLEJ:
    Comprehensive Benchmark for Polish Language Understanding》](https://www.aclweb.org/anthology/2020.acl-main.111.pdf)一同发布。'
- en: '**[Hubert](https://huggingface.co/docs/transformers/model_doc/hubert)** (from
    Facebook) released with the paper [HuBERT: Self-Supervised Speech Representation
    Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447)
    by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan
    Salakhutdinov, Abdelrahman Mohamed.'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Hubert](https://huggingface.co/docs/transformers/model_doc/hubert)**（来自Facebook）与Wei-Ning
    Hsu、Benjamin Bolte、Yao-Hung Hubert Tsai、Kushal Lakhotia、Ruslan Salakhutdinov、Abdelrahman
    Mohamed合著的论文[《HuBERT: Self-Supervised Speech Representation Learning by Masked
    Prediction of Hidden Units》](https://arxiv.org/abs/2106.07447)一同发布。'
- en: '**[LongT5](https://huggingface.co/docs/transformers/model_doc/longt5)** (from
    Google AI) released with the paper [LongT5: Efficient Text-To-Text Transformer
    for Long Sequences](https://arxiv.org/abs/2112.07916) by Mandy Guo, Joshua Ainslie,
    David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[LongT5](https://huggingface.co/docs/transformers/model_doc/longt5)**（来自Google
    AI）与Mandy Guo、Joshua Ainslie、David Uthus、Santiago Ontanon、Jianmo Ni、Yun-Hsuan
    Sung、Yinfei Yang合著的论文[《LongT5: Efficient Text-To-Text Transformer for Long Sequences》](https://arxiv.org/abs/2112.07916)一同发布。'
- en: '**[LLaMA](https://huggingface.co/docs/transformers/model_doc/llama)** (from
    The FAIR team of Meta AI) released with the paper [LLaMA: Open and Efficient Foundation
    Language Models](https://arxiv.org/abs/2302.13971) by Hugo Touvron, Thibaut Lavril,
    Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste
    Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin,
    Edouard Grave, Guillaume Lample.'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[LLaMA](https://huggingface.co/docs/transformers/model_doc/llama)**（来自Meta
    AI的FAIR团队）与Hugo Touvron、Thibaut Lavril、Gautier Izacard、Xavier Martinet、Marie-Anne
    Lachaux、Timothée Lacroix、Baptiste Rozière、Naman Goyal、Eric Hambro、Faisal Azhar、Aurelien
    Rodriguez、Armand Joulin、Edouard Grave、Guillaume Lample合著的论文[《LLaMA: Open and Efficient
    Foundation Language Models》](https://arxiv.org/abs/2302.13971)一同发布。'
- en: '**[Llama2](https://huggingface.co/docs/transformers/model_doc/llama2)** (from
    The FAIR team of Meta AI) released with the paper [Llama2: Open Foundation and
    Fine-Tuned Chat Models](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/XXX)
    by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
    Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan
    Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David
    Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj
    Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan,
    Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit
    Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai
    Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog,
    Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan
    Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan,
    Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan,
    Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien
    Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Llama2](https://huggingface.co/docs/transformers/model_doc/llama2)**（来自Meta
    AI的FAIR团队）与论文[Llama2：开放基础和精细调整的聊天模型](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/XXX)一起发布，作者是Hugo
    Touvron，Louis Martin，Kevin Stone，Peter Albert，Amjad Almahairi，Yasmine Babaei，Nikolay
    Bashlykov，Soumya Batra，Prajjwal Bhargava，Shruti Bhosale，Dan Bikel，Lukas Blecher，Cristian
    Canton Ferrer，Moya Chen，Guillem Cucurull，David Esiobu，Jude Fernandes，Jeremy Fu，Wenyin
    Fu，Brian Fuller，Cynthia Gao，Vedanuj Goswami，Naman Goyal，Anthony Hartshorn，Saghar
    Hosseini，Rui Hou，Hakan Inan，Marcin Kardas，Viktor Kerkez Madian Khabsa，Isabel Kloumann，Artem
    Korenev，Punit Singh Koura，Marie-Anne Lachaux，Thibaut Lavril，Jenya Lee，Diana Liskovich，Yinghai
    Lu，Yuning Mao，Xavier Martinet，Todor Mihaylov，Pushka rMishra，Igor Molybog，Yixin
    Nie，Andrew Poulton，Jeremy Reizenstein，Rashi Rungta，Kalyan Saladi，Alan Schelten，Ruan
    Silva，Eric Michael Smith，Ranjan Subramanian，Xiaoqing EllenTan，Binh Tang，Ross Taylor，Adina
    Williams，Jian Xiang Kuan，Puxin Xu，Zheng Yan，Iliyan Zarov，Yuchen Zhang，Angela Fan，Melanie
    Kambadur，Sharan Narang，Aurelien Rodriguez，Robert Stojnic，Sergey Edunov，Thomas
    Scialom。'
- en: '**[M2M100](https://huggingface.co/docs/transformers/model_doc/m2m_100)** (from
    Facebook) released with the paper [Beyond English-Centric Multilingual Machine
    Translation](https://arxiv.org/abs/2010.11125) by Angela Fan, Shruti Bhosale,
    Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur
    Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky,
    Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[M2M100](https://huggingface.co/docs/transformers/model_doc/m2m_100)**（来自Facebook）与论文[超越以英语为中心的多语言机器翻译](https://arxiv.org/abs/2010.11125)一起发布，作者是Angela
    Fan，Shruti Bhosale，Holger Schwenk，Zhiyi Ma，Ahmed El-Kishky，Siddharth Goyal，Mandeep
    Baines，Onur Celebi，Guillaume Wenzek，Vishrav Chaudhary，Naman Goyal，Tom Birch，Vitaliy
    Liptchinsky，Sergey Edunov，Edouard Grave，Michael Auli，Armand Joulin。'
- en: '**[MarianMT](https://huggingface.co/docs/transformers/model_doc/marian)** Machine
    translation models trained using [OPUS](http://opus.nlpl.eu/) data by Jörg Tiedemann.
    The [Marian Framework](https://marian-nmt.github.io/) is being developed by the
    Microsoft Translator Team.'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MarianMT](https://huggingface.co/docs/transformers/model_doc/marian)**使用Jörg
    Tiedemann的[OPUS](http://opus.nlpl.eu/)数据训练的机器翻译模型。[Marian Framework](https://marian-nmt.github.io/)由Microsoft
    Translator团队开发。'
- en: '**[mBART](https://huggingface.co/docs/transformers/model_doc/mbart)** (from
    Facebook) released with the paper [Multilingual Denoising Pre-training for Neural
    Machine Translation](https://arxiv.org/abs/2001.08210) by Yinhan Liu, Jiatao Gu,
    Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[mBART](https://huggingface.co/docs/transformers/model_doc/mbart)**（来自Facebook）与论文[神经机器翻译的多语言去噪预训练](https://arxiv.org/abs/2001.08210)一起发布，作者是Yinhan
    Liu，Jiatao Gu，Naman Goyal，Xian Li，Sergey Edunov，Marjan Ghazvininejad，Mike Lewis，Luke
    Zettlemoyer。'
- en: '**[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)** (from
    Facebook) released with the paper [Multilingual Translation with Extensible Multilingual
    Pretraining and Finetuning](https://arxiv.org/abs/2008.00401) by Yuqing Tang,
    Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu,
    Angela Fan.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)**（来自Facebook）与论文[具有可扩展多语言预训练和微调的多语言翻译](https://arxiv.org/abs/2008.00401)一起发布，作者是Yuqing
    Tang，Chau Tran，Xian Li，Peng-Jen Chen，Naman Goyal，Vishrav Chaudhary，Jiatao Gu，Angela
    Fan。'
- en: '**[Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)** (from
    Mistral AI) by The [Mistral AI](https://mistral.ai) team: Albert Jiang, Alexandre
    Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las
    Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lélio Renard Lavaud,
    Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril,
    Thomas Wang, Timothée Lacroix, William El Sayed.'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)**（来自Mistral
    AI）由[Mistral AI](https://mistral.ai)团队发布：Albert Jiang，Alexandre Sablayrolles，Arthur
    Mensch，Chris Bamford，Devendra Singh Chaplot，Diego de las Casas，Florian Bressand，Gianna
    Lengyel，Guillaume Lample，Lélio Renard Lavaud，Lucile Saulnier，Marie-Anne Lachaux，Pierre
    Stock，Teven Le Scao，Thibaut Lavril，Thomas Wang，Timothée Lacroix，William El Sayed。'
- en: '**[MMS](https://huggingface.co/docs/transformers/model_doc/mms)** (from Facebook)
    released with the paper [Scaling Speech Technology to 1,000+ Languages](https://arxiv.org/abs/2305.13516)
    by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani
    Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski,
    Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MMS](https://huggingface.co/docs/transformers/model_doc/mms)**（来自Facebook）与论文[将语音技术扩展到1000多种语言](https://arxiv.org/abs/2305.13516)一起发布，作者是Vineel
    Pratap，Andros Tjandra，Bowen Shi，Paden Tomasello，Arun Babu，Sayani Kundu，Ali Elkahky，Zhaoheng
    Ni，Apoorv Vyas，Maryam Fazel-Zarandi，Alexei Baevski，Yossi Adi，Xiaohui Zhang，Wei-Ning
    Hsu，Alexis Conneau，Michael Auli。'
- en: '**[MobileBERT](https://huggingface.co/docs/transformers/model_doc/mobilebert)**
    (from CMU/Google Brain) released with the paper [MobileBERT: a Compact Task-Agnostic
    BERT for Resource-Limited Devices](https://arxiv.org/abs/2004.02984) by Zhiqing
    Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MobileBERT](https://huggingface.co/docs/transformers/model_doc/mobilebert)**（来自CMU/Google
    Brain）与论文[MobileBERT：适用于资源受限设备的紧凑通用BERT](https://arxiv.org/abs/2004.02984)一起发布，作者是Zhiqing
    Sun，Hongkun Yu，Xiaodan Song，Renjie Liu，Yiming Yang和Denny Zhou。'
- en: '**[MobileViT](https://huggingface.co/docs/transformers/model_doc/mobilevit)**
    (from Apple) released with the paper [MobileViT: Light-weight, General-purpose,
    and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) by Sachin
    Mehta and Mohammad Rastegari.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MobileViT](https://huggingface.co/docs/transformers/model_doc/mobilevit)**（来自苹果）由Sachin
    Mehta和Mohammad Rastegari在论文[MobileViT: Light-weight, General-purpose, and Mobile-friendly
    Vision Transformer](https://arxiv.org/abs/2110.02178)中发布。'
- en: '**[MPNet](https://huggingface.co/docs/transformers/model_doc/mpnet)** (from
    Microsoft Research) released with the paper [MPNet: Masked and Permuted Pre-training
    for Language Understanding](https://arxiv.org/abs/2004.09297) by Kaitao Song,
    Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MPNet](https://huggingface.co/docs/transformers/model_doc/mpnet)**（来自微软研究）由Kaitao
    Song、Xu Tan、Tao Qin、Jianfeng Lu、刘铁彦在论文[MPNet: Masked and Permuted Pre-training
    for Language Understanding](https://arxiv.org/abs/2004.09297)中发布。'
- en: '**[MPT](https://huggingface.co/docs/transformers/model_doc/mpt)** (from MosaiML)
    released with the repository [llm-foundry](https://github.com/mosaicml/llm-foundry/)
    by the MosaicML NLP Team.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MPT](https://huggingface.co/docs/transformers/model_doc/mpt)**（来自MosaiML）由MosaicML
    NLP团队在[llm-foundry](https://github.com/mosaicml/llm-foundry/)存储库中发布。'
- en: '**[MT5](https://huggingface.co/docs/transformers/model_doc/mt5)** (from Google
    AI) released with the paper [mT5: A massively multilingual pre-trained text-to-text
    transformer](https://arxiv.org/abs/2010.11934) by Linting Xue, Noah Constant,
    Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[MT5](https://huggingface.co/docs/transformers/model_doc/mt5)**（来自Google
    AI）由Linting Xue、Noah Constant、Adam Roberts、Mihir Kale、Rami Al-Rfou、Aditya Siddhant、Aditya
    Barua、Colin Raffel在论文[mT5: A massively multilingual pre-trained text-to-text transformer](https://arxiv.org/abs/2010.11934)中发布。'
- en: '**[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)** (from Meta)
    released with the paper [No Language Left Behind: Scaling Human-Centered Machine
    Translation](https://arxiv.org/abs/2207.04672) by the NLLB team.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)**（来自Meta）由NLLB团队在论文[No
    Language Left Behind: Scaling Human-Centered Machine Translation](https://arxiv.org/abs/2207.04672)中发布。'
- en: '**[Nougat](https://huggingface.co/docs/transformers/model_doc/nougat)** (from
    Meta AI) released with the paper [Nougat: Neural Optical Understanding for Academic
    Documents](https://arxiv.org/abs/2308.13418) by Lukas Blecher, Guillem Cucurull,
    Thomas Scialom, Robert Stojnic.'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Nougat](https://huggingface.co/docs/transformers/model_doc/nougat)**（来自Meta
    AI）由Lukas Blecher、Guillem Cucurull、Thomas Scialom、Robert Stojnic在论文[Nougat: Neural
    Optical Understanding for Academic Documents](https://arxiv.org/abs/2308.13418)中发布。'
- en: '**[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)** (from
    Meta AI) released with the paper [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068)
    by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
    Chen et al.'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)**（来自Meta
    AI）由Susan Zhang、Stephen Roller、Naman Goyal、Mikel Artetxe、Moya Chen、Shuohui Chen等人在论文[OPT:
    Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068)中发布。'
- en: '**[OWL-ViT](https://huggingface.co/docs/transformers/model_doc/owlvit)** (from
    Google AI) released with the paper [Simple Open-Vocabulary Object Detection with
    Vision Transformers](https://arxiv.org/abs/2205.06230) by Matthias Minderer, Alexey
    Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy,
    Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua
    Zhai, Thomas Kipf, and Neil Houlsby.'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[OWL-ViT](https://huggingface.co/docs/transformers/model_doc/owlvit)**（来自Google
    AI）由Matthias Minderer、Alexey Gritsenko、Austin Stone、Maxim Neumann、Dirk Weissenborn、Alexey
    Dosovitskiy、Aravindh Mahendran、Anurag Arnab、Mostafa Dehghani、Zhuoran Shen、Xiao
    Wang、Xiaohua Zhai、Thomas Kipf和Neil Houlsby在论文[Simple Open-Vocabulary Object Detection
    with Vision Transformers](https://arxiv.org/abs/2205.06230)中发布。'
- en: '**[Phi](https://huggingface.co/docs/transformers/main/model_doc/phi)** (from
    Microsoft) released with the papers - [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)
    by Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del
    Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli
    Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck,
    Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee and Yuanzhi Li, [Textbooks Are All
    You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463) by Yuanzhi
    Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar and Yin
    Tat Lee.'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Phi](https://huggingface.co/docs/transformers/main/model_doc/phi)**（来自微软）由Suriya
    Gunasekar、Yi Zhang、Jyoti Aneja、Caio César Teodoro Mendes、Allie Del Giorno、Sivakanth
    Gopi、Mojan Javaheripi、Piero Kauffmann、Gustavo de Rosa、Olli Saarikivi、Adil Salim、Shital
    Shah、Harkirat Singh Behl、Xin Wang、Sébastien Bubeck、Ronen Eldan、Adam Tauman Kalai、Yin
    Tat Lee和Yuanzhi Li在论文[Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)和[Yuanzhi
    Li、Sébastien Bubeck、Ronen Eldan、Allie Del Giorno、Suriya Gunasekar和Yin Tat Lee在论文Textbooks
    Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463)中发布。'
- en: '**[Qwen2](https://huggingface.co/docs/transformers/model_doc/qwen2)** (from
    the Qwen team, Alibaba Group) released with the paper [Qwen Technical Report](https://arxiv.org/abs/2309.16609)
    by Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan,
    Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji
    Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang
    Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang,
    Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng
    Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang,
    Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou and Tianhang
    Zhu.'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Qwen2](https://huggingface.co/docs/transformers/model_doc/qwen2)**（来自阿里巴巴集团的Qwen团队）由Jinze
    Bai、Shuai Bai、Yunfei Chu、Zeyu Cui、Kai Dang、Xiaodong Deng、Yang Fan、Wenbin Ge、Yu
    Han、Fei Huang、Binyuan Hui、Luo Ji、Mei Li、Junyang Lin、Runji Lin、Dayiheng Liu、Gao
    Liu、Chengqiang Lu、Keming Lu、Jianxin Ma、Rui Men、Xingzhang Ren、Xuancheng Ren、Chuanqi
    Tan、Sinan Tan、Jianhong Tu、Peng Wang、Shijie Wang、Wei Wang、Shengguang Wu、Benfeng
    Xu、Jin Xu、An Yang、Hao Yang、Jian Yang、Shusheng Yang、Yang Yao、Bowen Yu、Hongyi Yuan、Zheng
    Yuan、Jianwei Zhang、Xingxuan Zhang、Yichang Zhang、Zhenru Zhang、Chang Zhou、Jingren
    Zhou、Xiaohuan Zhou和Tianhang Zhu在论文[Qwen Technical Report](https://arxiv.org/abs/2309.16609)中发布。'
- en: '**[ResNet](https://huggingface.co/docs/transformers/model_doc/resnet)** (from
    Microsoft Research) released with the paper [Deep Residual Learning for Image
    Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He, Xiangyu Zhang, Shaoqing
    Ren, Jian Sun.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ResNet](https://huggingface.co/docs/transformers/model_doc/resnet)**（来自微软研究）与论文[Deep
    Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)一起发布，作者为Kaiming
    He、Xiangyu Zhang、Shaoqing Ren、Jian Sun。'
- en: '**[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)** (from
    Facebook), released together with the paper [RoBERTa: A Robustly Optimized BERT
    Pretraining Approach](https://arxiv.org/abs/1907.11692) by Yinhan Liu, Myle Ott,
    Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke
    Zettlemoyer, Veselin Stoyanov.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)**（来自Facebook），与论文[RoBERTa:
    A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)一起发布，作者为刘银涵、Myle
    Ott、Naman Goyal、Jingfei Du、Mandar Joshi、Danqi Chen、Omer Levy、Mike Lewis、Luke Zettlemoyer、Veselin
    Stoyanov。'
- en: '**[RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer)**
    (from ZhuiyiTechnology), released together with the paper [RoFormer: Enhanced
    Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864)
    by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer)**（来自追一科技），与论文[RoFormer:
    Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864)一起发布，作者为苏建林、陆宇、潘胜锋、文波、刘云峰。'
- en: '**[SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer)**
    (from NVIDIA) released with the paper [SegFormer: Simple and Efficient Design
    for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)
    by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping
    Luo.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer)**（来自NVIDIA）与论文[SegFormer:
    Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)一起发布，作者为Enze
    Xie、Wenhai Wang、Zhiding Yu、Anima Anandkumar、Jose M. Alvarez、Ping Luo。'
- en: '**[Segment Anything](https://huggingface.co/docs/transformers/model_doc/sam)**
    (from Meta AI) released with the paper [Segment Anything](https://arxiv.org/pdf/2304.02643v1.pdf)
    by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
    Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar,
    Ross Girshick.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Segment Anything](https://huggingface.co/docs/transformers/model_doc/sam)**（来自Meta
    AI）与论文[Segment Anything](https://arxiv.org/pdf/2304.02643v1.pdf)一起发布，作者为Alexander
    Kirillov、Eric Mintun、Nikhila Ravi、Hanzi Mao、Chloe Rolland、Laura Gustafson、Tete
    Xiao、Spencer Whitehead、Alex Berg、Wan-Yen Lo、Piotr Dollar、Ross Girshick。'
- en: '**[SigLIP](https://huggingface.co/docs/transformers/main/model_doc/siglip)**
    (from Google AI) released with the paper [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)
    by Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, Lucas Beyer.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SigLIP](https://huggingface.co/docs/transformers/main/model_doc/siglip)**（来自Google
    AI）与论文[Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)一起发布，作者为Xiaohua
    Zhai、Basil Mustafa、Alexander Kolesnikov、Lucas Beyer。'
- en: '**[SpeechT5](https://huggingface.co/docs/transformers/model_doc/speecht5)**
    (from Microsoft Research) released with the paper [SpeechT5: Unified-Modal Encoder-Decoder
    Pre-Training for Spoken Language Processing](https://arxiv.org/abs/2110.07205)
    by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom
    Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SpeechT5](https://huggingface.co/docs/transformers/model_doc/speecht5)**（来自微软研究）与论文[SpeechT5:
    Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing](https://arxiv.org/abs/2110.07205)一起发布，作者为Junyi
    Ao、Rui Wang、Long Zhou、Chengyi Wang、Shuo Ren、Yu Wu、Shujie Liu、Tom Ko、Qing Li、Yu
    Zhang、Zhihua Wei、Yao Qian、Jinyu Li、Furu Wei。'
- en: '**[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)**
    (from Berkeley) released with the paper [SqueezeBERT: What can computer vision
    teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316)
    by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)**（来自伯克利）与论文[SqueezeBERT:
    What can computer vision teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316)一起发布，作者为Forrest
    N. Iandola、Albert E. Shaw、Ravi Krishna、Kurt W. Keutzer。'
- en: '**[Swin Transformer](https://huggingface.co/docs/transformers/model_doc/swin)**
    (from Microsoft) released with the paper [Swin Transformer: Hierarchical Vision
    Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) by Ze Liu,
    Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Swin Transformer](https://huggingface.co/docs/transformers/model_doc/swin)**（来自微软）与论文[Swin
    Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)一起发布，作者为Ze
    Liu、Yutong Lin、Yue Cao、Han Hu、Yixuan Wei、Zheng Zhang、Stephen Lin、Baining Guo。'
- en: '**[Swin2SR](https://huggingface.co/docs/transformers/model_doc/swin2sr)** (from
    University of Würzburg) released with the paper [Swin2SR: SwinV2 Transformer for
    Compressed Image Super-Resolution and Restoration](https://arxiv.org/abs/2209.11345)
    by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Swin2SR](https://huggingface.co/docs/transformers/model_doc/swin2sr)**（来自Würzburg大学）与论文[Swin2SR:
    SwinV2 Transformer for Compressed Image Super-Resolution and Restoration](https://arxiv.org/abs/2209.11345)一起发布，作者为Marcos
    V. Conde、Ui-Jin Choi、Maxime Burchi、Radu Timofte。'
- en: '**[T5](https://huggingface.co/docs/transformers/model_doc/t5)** (from Google
    AI) released with the paper [Exploring the Limits of Transfer Learning with a
    Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin Raffel
    and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael
    Matena and Yanqi Zhou and Wei Li and Peter J. Liu.'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[T5](https://huggingface.co/docs/transformers/model_doc/t5)**（来自Google AI）与论文[Exploring
    the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)一起发布，作者为Colin
    Raffel、Noam Shazeer、Adam Roberts、Katherine Lee、Sharan Narang、Michael Matena、Yanqi
    Zhou、Wei Li、Peter J. Liu。'
- en: '**[T5v1.1](https://huggingface.co/docs/transformers/model_doc/t5v1.1)** (from
    Google AI) released in the repository [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511)
    by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan
    Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[T5v1.1](https://huggingface.co/docs/transformers/model_doc/t5v1.1)**（来自Google
    AI）在[google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511)仓库中发布，作者为Colin
    Raffel、Noam Shazeer、Adam Roberts、Katherine Lee、Sharan Narang、Michael Matena、Yanqi
    Zhou、Wei Li、Peter J. Liu。'
- en: '**[Table Transformer](https://huggingface.co/docs/transformers/model_doc/table-transformer)**
    (from Microsoft Research) released with the paper [PubTables-1M: Towards Comprehensive
    Table Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061)
    by Brandon Smock, Rohith Pesala, Robin Abraham.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Table Transformer](https://huggingface.co/docs/transformers/model_doc/table-transformer)**（来自微软研究院），与Brandon
    Smock、Rohith Pesala、Robin Abraham合作发布了论文[PubTables-1M: Towards Comprehensive Table
    Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061)。'
- en: '**[TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)** (from
    Microsoft), released together with the paper [TrOCR: Transformer-based Optical
    Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282)
    by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun
    Li, Furu Wei.'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)**（来自微软），与Minghao
    Li、Tengchao Lv、Lei Cui、Yijuan Lu、Dinei Florencio、Cha Zhang、Zhoujun Li、Furu Wei合作发布了论文[TrOCR:
    Transformer-based Optical Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282)。'
- en: '**[Vision Transformer (ViT)](https://huggingface.co/docs/transformers/model_doc/vit)**
    (from Google AI) released with the paper [An Image is Worth 16x16 Words: Transformers
    for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) by Alexey Dosovitskiy,
    Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
    Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,
    Neil Houlsby.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Vision Transformer (ViT)](https://huggingface.co/docs/transformers/model_doc/vit)**（来自Google
    AI），与Alexey Dosovitskiy、Lucas Beyer、Alexander Kolesnikov、Dirk Weissenborn、Xiaohua
    Zhai、Thomas Unterthiner、Mostafa Dehghani、Matthias Minderer、Georg Heigold、Sylvain
    Gelly、Jakob Uszkoreit、Neil Houlsby合作发布了论文[An Image is Worth 16x16 Words: Transformers
    for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)。'
- en: '**[ViTMatte](https://huggingface.co/docs/transformers/model_doc/vitmatte)**
    (from HUST-VL) released with the paper [ViTMatte: Boosting Image Matting with
    Pretrained Plain Vision Transformers](https://arxiv.org/abs/2305.15272) by Jingfeng
    Yao, Xinggang Wang, Shusheng Yang, Baoyuan Wang.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[ViTMatte](https://huggingface.co/docs/transformers/model_doc/vitmatte)**（来自HUST-VL），与Jingfeng
    Yao、Xinggang Wang、Shusheng Yang、Baoyuan Wang合作发布了论文[ViTMatte: Boosting Image Matting
    with Pretrained Plain Vision Transformers](https://arxiv.org/abs/2305.15272)。'
- en: '**[VITS](https://huggingface.co/docs/transformers/model_doc/vits)** (from Kakao
    Enterprise) released with the paper [Conditional Variational Autoencoder with
    Adversarial Learning for End-to-End Text-to-Speech](https://arxiv.org/abs/2106.06103)
    by Jaehyeon Kim, Jungil Kong, Juhee Son.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[VITS](https://huggingface.co/docs/transformers/model_doc/vits)**（来自Kakao
    Enterprise），与Jaehyeon Kim、Jungil Kong、Juhee Son合作发布了论文[Conditional Variational
    Autoencoder with Adversarial Learning for End-to-End Text-to-Speech](https://arxiv.org/abs/2106.06103)。'
- en: '**[Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)**
    (from Facebook AI) released with the paper [wav2vec 2.0: A Framework for Self-Supervised
    Learning of Speech Representations](https://arxiv.org/abs/2006.11477) by Alexei
    Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)**（来自Facebook
    AI），与Alexei Baevski、Henry Zhou、Abdelrahman Mohamed、Michael Auli合作发布了论文[wav2vec
    2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477)。'
- en: '**[Wav2Vec2-BERT](https://huggingface.co/docs/transformers/main/model_doc/wav2vec2-bert)**
    (from Meta AI) released with the paper [Seamless: Multilingual Expressive and
    Streaming Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)
    by the Seamless Communication team.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Wav2Vec2-BERT](https://huggingface.co/docs/transformers/main/model_doc/wav2vec2-bert)**（来自Meta
    AI），与Seamless Communication团队合作发布了论文[Seamless: Multilingual Expressive and Streaming
    Speech Translation](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/)。'
- en: '**[WavLM](https://huggingface.co/docs/transformers/model_doc/wavlm)** (from
    Microsoft Research) released with the paper [WavLM: Large-Scale Self-Supervised
    Pre-Training for Full Stack Speech Processing](https://arxiv.org/abs/2110.13900)
    by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu
    Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren,
    Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[WavLM](https://huggingface.co/docs/transformers/model_doc/wavlm)**（来自微软研究院），与Sanyuan
    Chen、Chengyi Wang、Zhengyang Chen、Yu Wu、Shujie Liu、Zhuo Chen、Jinyu Li、Naoyuki Kanda、Takuya
    Yoshioka、Xiong Xiao、Jian Wu、Long Zhou、Shuo Ren、Yanmin Qian、Yao Qian、Jian Wu、Michael
    Zeng、Furu Wei合作发布了论文[WavLM: Large-Scale Self-Supervised Pre-Training for Full
    Stack Speech Processing](https://arxiv.org/abs/2110.13900)。'
- en: '**[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)** (from
    OpenAI) released with the paper [Robust Speech Recognition via Large-Scale Weak
    Supervision](https://cdn.openai.com/papers/whisper.pdf) by Alec Radford, Jong
    Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)**（来自OpenAI），与Alec
    Radford、Jong Wook Kim、Tao Xu、Greg Brockman、Christine McLeavey、Ilya Sutskever合作发布了论文[Robust
    Speech Recognition via Large-Scale Weak Supervision](https://cdn.openai.com/papers/whisper.pdf)。'
- en: '**[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (from Facebook)
    released together with the paper [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291)
    by Guillaume Lample and Alexis Conneau.'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)**（来自Facebook），与Guillaume
    Lample和Alexis Conneau合作发布了论文[Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291)。'
- en: '**[XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta)**
    (from Facebook AI), released together with the paper [Unsupervised Cross-lingual
    Representation Learning at Scale](https://arxiv.org/abs/1911.02116) by Alexis
    Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek,
    Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta)**（来自Facebook
    AI），与Alexis Conneau、Kartikay Khandelwal、Naman Goyal、Vishrav Chaudhary、Guillaume
    Wenzek、Francisco Guzmán、Edouard Grave、Myle Ott、Luke Zettlemoyer和Veselin Stoyanov合作发布了论文[Unsupervised
    Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116)。'
- en: '**[YOLOS](https://huggingface.co/docs/transformers/model_doc/yolos)** (from
    Huazhong University of Science & Technology) released with the paper [You Only
    Look at One Sequence: Rethinking Transformer in Vision through Object Detection](https://arxiv.org/abs/2106.00666)
    by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei
    Niu, Wenyu Liu.'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**[YOLOS](https://huggingface.co/docs/transformers/model_doc/yolos)**（来自华中科技大学）是由Yuxin
    Fang、Bencheng Liao、Xinggang Wang、Jiemin Fang、Jiyang Qi、Rui Wu、Jianwei Niu、Wenyu
    Liu等人发表的论文[You Only Look at One Sequence: Rethinking Transformer in Vision through
    Object Detection](https://arxiv.org/abs/2106.00666)发布的。'
