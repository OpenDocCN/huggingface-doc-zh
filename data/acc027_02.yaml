- en: Accelerate
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ é€Ÿ
- en: 'Original text: [https://huggingface.co/docs/accelerate/index](https://huggingface.co/docs/accelerate/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://huggingface.co/docs/accelerate/index](https://huggingface.co/docs/accelerate/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ¤— Accelerate is a library that enables the same PyTorch code to be run across
    any distributed configuration by adding just four lines of code! In short, training
    and inference at scale made simple, efficient and adaptable.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤—åŠ é€Ÿæ˜¯ä¸€ä¸ªåº“ï¼Œé€šè¿‡æ·»åŠ åªæœ‰å››è¡Œä»£ç ï¼Œä½¿ç›¸åŒçš„PyTorchä»£ç å¯ä»¥åœ¨ä»»ä½•åˆ†å¸ƒå¼é…ç½®ä¸Šè¿è¡Œï¼ç®€è€Œè¨€ä¹‹ï¼Œç®€å•ã€é«˜æ•ˆå’Œé€‚åº”æ€§çš„è§„æ¨¡è®­ç»ƒå’Œæ¨ç†ã€‚
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Built on `torch_xla` and `torch.distributed`, ğŸ¤— Accelerate takes care of the
    heavy lifting, so you donâ€™t have to write any custom code to adapt to these platforms.
    Convert existing codebases to utilize [DeepSpeed](usage_guides/deepspeed), perform
    [fully sharded data parallelism](usage_guides/fsdp), and have automatic support
    for mixed-precision training!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäº`torch_xla`å’Œ`torch.distributed`æ„å»ºï¼ŒğŸ¤—åŠ é€Ÿä¼šå¤„ç†ç¹é‡çš„å·¥ä½œï¼Œå› æ­¤æ‚¨æ— éœ€ç¼–å†™ä»»ä½•è‡ªå®šä¹‰ä»£ç æ¥é€‚åº”è¿™äº›å¹³å°ã€‚å°†ç°æœ‰ä»£ç åº“è½¬æ¢ä¸ºåˆ©ç”¨[DeepSpeed](usage_guides/deepspeed)ï¼Œæ‰§è¡Œ[å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ](usage_guides/fsdp)ï¼Œå¹¶è‡ªåŠ¨æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼
- en: To get a better idea of this process, make sure to check out the [Tutorials](basic_tutorials/overview)!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ›´å¥½åœ°äº†è§£è¿™ä¸ªè¿‡ç¨‹ï¼Œè¯·ç¡®ä¿æŸ¥çœ‹[æ•™ç¨‹](basic_tutorials/overview)ï¼
- en: 'This code can then be launched on any system through Accelerateâ€™s CLI interface:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¯ä»¥é€šè¿‡åŠ é€Ÿçš„CLIç•Œé¢åœ¨ä»»ä½•ç³»ç»Ÿä¸Šå¯åŠ¨æ­¤ä»£ç ï¼š
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[Tutorials'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ•™ç¨‹'
- en: Learn the basics and become familiar with using ğŸ¤— Accelerate. Start here if
    you are using ğŸ¤— Accelerate for the first time!](./basic_tutorials/overview) [How-to
    guides
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ åŸºç¡€çŸ¥è¯†ï¼Œå¹¶ç†Ÿæ‚‰ä½¿ç”¨ğŸ¤—åŠ é€Ÿã€‚å¦‚æœæ‚¨æ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨ğŸ¤—åŠ é€Ÿï¼Œè¯·ä»è¿™é‡Œå¼€å§‹ï¼](./basic_tutorials/overview) [æ“ä½œæŒ‡å—
- en: Practical guides to help you achieve a specific goal. Take a look at these guides
    to learn how to use ğŸ¤— Accelerate to solve real-world problems.](./usage_guides/explore)
    [Conceptual guides
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç”¨æŒ‡å—ï¼Œå¸®åŠ©æ‚¨å®ç°ç‰¹å®šç›®æ ‡ã€‚æŸ¥çœ‹è¿™äº›æŒ‡å—ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨ğŸ¤—åŠ é€Ÿè§£å†³ç°å®ä¸–ç•Œçš„é—®é¢˜ã€‚](./usage_guides/explore) [æ¦‚å¿µæŒ‡å—
- en: High-level explanations for building a better understanding of important topics
    such as avoiding subtle nuances and pitfalls in distributed training and DeepSpeed.](./concept_guides/gradient_synchronization)
    [Reference
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: é«˜å±‚æ¬¡çš„è§£é‡Šï¼Œä»¥å»ºç«‹å¯¹é‡è¦ä¸»é¢˜çš„æ›´å¥½ç†è§£ï¼Œä¾‹å¦‚é¿å…åœ¨åˆ†å¸ƒå¼è®­ç»ƒå’ŒDeepSpeedä¸­çš„å¾®å¦™ç»†å¾®å·®åˆ«å’Œé™·é˜±ã€‚](./concept_guides/gradient_synchronization)
    [å‚è€ƒ
- en: Technical descriptions of how ğŸ¤— Accelerate classes and methods work.](./package_reference/accelerator)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºğŸ¤—åŠ é€Ÿç±»å’Œæ–¹æ³•å¦‚ä½•å·¥ä½œçš„æŠ€æœ¯æè¿°ã€‚](./package_reference/accelerator)
