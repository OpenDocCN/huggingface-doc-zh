- en: Processors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤„ç†å™¨
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Processors can mean two different things in the Transformers library:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Transformers åº“ä¸­ï¼Œå¤„ç†å™¨å¯ä»¥æœ‰ä¸¤ç§ä¸åŒçš„å«ä¹‰ï¼š
- en: the objects that pre-process inputs for multi-modal models such as [Wav2Vec2](../model_doc/wav2vec2)
    (speech and text) or [CLIP](../model_doc/clip) (text and vision)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºå¤šæ¨¡æ€æ¨¡å‹é¢„å¤„ç†è¾“å…¥çš„å¯¹è±¡ï¼Œå¦‚[Wav2Vec2](../model_doc/wav2vec2)ï¼ˆè¯­éŸ³å’Œæ–‡æœ¬ï¼‰æˆ–[CLIP](../model_doc/clip)ï¼ˆæ–‡æœ¬å’Œè§†è§‰ï¼‰
- en: deprecated objects that were used in older versions of the library to preprocess
    data for GLUE or SQUAD.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨åº“çš„æ—§ç‰ˆæœ¬ä¸­ç”¨äºé¢„å¤„ç† GLUE æˆ– SQUAD æ•°æ®çš„å·²å¼ƒç”¨å¯¹è±¡ã€‚
- en: Multi-modal processors
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤šæ¨¡æ€å¤„ç†å™¨
- en: Any multi-modal model will require an object to encode or decode the data that
    groups several modalities (among text, vision and audio). This is handled by objects
    called processors, which group together two or more processing objects such as
    tokenizers (for the text modality), image processors (for vision) and feature
    extractors (for audio).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•å¤šæ¨¡æ€æ¨¡å‹éƒ½éœ€è¦ä¸€ä¸ªå¯¹è±¡æ¥ç¼–ç æˆ–è§£ç å°†å¤šä¸ªæ¨¡æ€ï¼ˆæ–‡æœ¬ã€è§†è§‰å’ŒéŸ³é¢‘ï¼‰ç»„åˆåœ¨ä¸€èµ·çš„æ•°æ®ã€‚è¿™ç”±ç§°ä¸ºå¤„ç†å™¨çš„å¯¹è±¡å¤„ç†ï¼Œè¿™äº›å¯¹è±¡å°†å¤šä¸ªå¤„ç†å¯¹è±¡ï¼ˆå¦‚æ–‡æœ¬æ¨¡æ€çš„åˆ†è¯å™¨ã€è§†è§‰çš„å›¾åƒå¤„ç†å™¨å’ŒéŸ³é¢‘çš„ç‰¹å¾æå–å™¨ï¼‰ç»„åˆåœ¨ä¸€èµ·ã€‚
- en: 'Those processors inherit from the following base class that implements the
    saving and loading functionality:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤„ç†å™¨ç»§æ‰¿è‡ªå®ç°ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½çš„ä»¥ä¸‹åŸºç±»ï¼š
- en: '### `class transformers.ProcessorMixin`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.ProcessorMixin`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L56)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L56)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is a mixin used to provide saving/loading functionality for all processor
    classes.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæ··åˆç±»ï¼Œç”¨äºä¸ºæ‰€æœ‰å¤„ç†å™¨ç±»æä¾›ä¿å­˜/åŠ è½½åŠŸèƒ½ã€‚
- en: '#### `from_args_and_dict`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_args_and_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L365)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L365)'
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`processor_dict` (`Dict[str, Any]`) â€” Dictionary that will be used to instantiate
    the processor object. Such a dictionary can be retrieved from a pretrained checkpoint
    by leveraging the `~processing_utils.ProcessingMixin.to_dict` method.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processor_dict` (`Dict[str, Any]`) â€” å°†ç”¨äºå®ä¾‹åŒ–å¤„ç†å™¨å¯¹è±¡çš„å­—å…¸ã€‚å¯ä»¥é€šè¿‡åˆ©ç”¨`~processing_utils.ProcessingMixin.to_dict`æ–¹æ³•ä»é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ä¸­æ£€ç´¢è¿™æ ·çš„å­—å…¸ã€‚'
- en: '`kwargs` (`Dict[str, Any]`) â€” Additional parameters from which to initialize
    the processor object.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`) â€” ç”¨äºåˆå§‹åŒ–å¤„ç†å™¨å¯¹è±¡çš„å…¶ä»–å‚æ•°ã€‚'
- en: Returns
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`~processing_utils.ProcessingMixin`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`~processing_utils.ProcessingMixin`'
- en: The processor object instantiated from those parameters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™äº›å‚æ•°å®ä¾‹åŒ–çš„å¤„ç†å™¨å¯¹è±¡ã€‚
- en: Instantiates a type of `~processing_utils.ProcessingMixin` from a Python dictionary
    of parameters.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä» Python å‚æ•°å­—å…¸ä¸­å®ä¾‹åŒ–`~processing_utils.ProcessingMixin`ç±»å‹ã€‚
- en: '#### `from_pretrained`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) â€” This can be either:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`) â€” è¿™å¯ä»¥æ˜¯ï¼š'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„*æ¨¡å‹æ ‡è¯†*ï¼Œæ‰˜ç®¡åœ¨ huggingface.co ä¸Šçš„æ¨¡å‹ä»“åº“å†…ã€‚æœ‰æ•ˆçš„æ¨¡å‹æ ‡è¯†å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*ç›®å½•*çš„è·¯å¾„ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)æ–¹æ³•ä¿å­˜çš„ç‰¹å¾æå–å™¨æ–‡ä»¶ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs â€” Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜çš„ç‰¹å¾æå–å™¨ JSON *æ–‡ä»¶*çš„è·¯å¾„æˆ– URLï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/preprocessor_config.json`ã€‚**kwargs
    â€” ä¼ é€’ç»™[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)å’Œ`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`çš„å…¶ä»–å…³é”®å­—å‚æ•°ã€‚
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å®ä¾‹åŒ–ä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸å…³è”çš„å¤„ç†å™¨ã€‚
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ç‰¹å¾æå–å™¨[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)ã€å›¾åƒå¤„ç†å™¨[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)å’Œåˆ†è¯å™¨`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`æ–¹æ³•ã€‚è¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `get_processor_dict`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_processor_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L256)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L256)'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) â€” The identifier of
    the pre-trained checkpoint from which we want the dictionary of parameters.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`) â€” æˆ‘ä»¬æƒ³è¦å‚æ•°å­—å…¸çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹çš„æ ‡è¯†ç¬¦ã€‚'
- en: '`subfolder` (`str`, *optional*, defaults to `""`) â€” In case the relevant files
    are located inside a subfolder of the model repo on huggingface.co, you can specify
    the folder name here.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `""`) â€” å¦‚æœç›¸å…³æ–‡ä»¶ä½äº huggingface.co ä¸Šæ¨¡å‹å­˜å‚¨åº“çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œå¯ä»¥åœ¨æ­¤å¤„æŒ‡å®šæ–‡ä»¶å¤¹åç§°ã€‚'
- en: Returns
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`Tuple[Dict, Dict]`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tuple[Dict, Dict]`'
- en: The dictionary(ies) that will be used to instantiate the processor object.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç”¨äºå®ä¾‹åŒ–å¤„ç†å™¨å¯¹è±¡çš„å­—å…¸ã€‚
- en: From a `pretrained_model_name_or_path`, resolve to a dictionary of parameters,
    to be used for instantiating a processor of type `~processing_utils.ProcessingMixin`
    using `from_args_and_dict`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä» `pretrained_model_name_or_path`ï¼Œè§£æä¸ºå‚æ•°å­—å…¸ï¼Œç”¨äºä½¿ç”¨ `from_args_and_dict` å®ä¾‹åŒ–ç±»å‹ä¸º `~processing_utils.ProcessingMixin`
    çš„å¤„ç†å™¨ã€‚
- en: '#### `push_to_hub`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `push_to_hub`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`repo_id` (`str`) â€” The name of the repository you want to push your processor
    to. It should contain your organization name when pushing to a given organization.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) â€” è¦å°†å¤„ç†å™¨æ¨é€åˆ°çš„å­˜å‚¨åº“çš„åç§°ã€‚åœ¨æ¨é€åˆ°ç»™å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚'
- en: '`use_temp_dir` (`bool`, *optional*) â€” Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_temp_dir` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•æ¥å­˜å‚¨åœ¨æ¨é€åˆ° Hub ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶ã€‚å¦‚æœæ²¡æœ‰åä¸º `repo_id`
    çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`ã€‚'
- en: '`commit_message` (`str`, *optional*) â€” Message to commit while pushing. Will
    default to `"Upload processor"`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message` (`str`ï¼Œ*å¯é€‰*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º `"Upload processor"`ã€‚'
- en: '`private` (`bool`, *optional*) â€” Whether or not the repository created should
    be private.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦åº”è¯¥åˆ›å»ºçš„å­˜å‚¨åº“æ˜¯ç§æœ‰çš„ã€‚'
- en: '`token` (`bool` or `str`, *optional*) â€” The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`bool` æˆ– `str`ï¼Œ*å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ
    `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š `repo_url`ï¼Œåˆ™é»˜è®¤ä¸º `True`ã€‚'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"5GB"`) â€” Only applicable
    for models. The maximum size for a checkpoint before being sharded. Checkpoints
    shard will then be each of size lower than this size. If expressed as a string,
    needs to be digits followed by a unit (like `"5MB"`). We default it to `"5GB"`
    so that users can easily load models on free-tier Google Colab instances without
    any CPU OOM issues.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size` (`int` æˆ– `str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"5GB"`) â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡çš„å¤§å°å°†å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚
    `"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤ä¸º `"5GB"`ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè½»æ¾åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½• CPU OOM é—®é¢˜ã€‚'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) â€” Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªåŒ…å«ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) â€” Whether or
    not to convert the model weights in safetensors format for safer serialization.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º safetensors æ ¼å¼ä»¥è¿›è¡Œæ›´å®‰å…¨çš„åºåˆ—åŒ–ã€‚'
- en: '`revision` (`str`, *optional*) â€” Branch to push the uploaded files to.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`ï¼Œ*å¯é€‰*) â€” è¦å°†ä¸Šä¼ çš„æ–‡ä»¶æ¨é€åˆ°çš„åˆ†æ”¯ã€‚'
- en: '`commit_description` (`str`, *optional*) â€” The description of the commit that
    will be created'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_description` (`str`ï¼Œ*å¯é€‰*) â€” å°†åˆ›å»ºçš„æäº¤çš„æè¿°'
- en: '`tags` (`List[str]`, *optional*) â€” List of tags to push on the Hub.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags` (`List[str]`ï¼Œ*å¯é€‰*) â€” è¦æ¨é€åˆ° Hub ä¸Šçš„æ ‡ç­¾åˆ—è¡¨ã€‚'
- en: Upload the processor files to the ğŸ¤— Model Hub.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å¤„ç†å™¨æ–‡ä»¶ä¸Šä¼ åˆ° ğŸ¤— æ¨¡å‹ä¸­å¿ƒã€‚
- en: 'Examples:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `register_for_auto_class`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register_for_auto_class`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L471)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L471)'
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`auto_class` (`str` or `type`, *optional*, defaults to `"AutoProcessor"`) â€”
    The auto class to register this new feature extractor with.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_class` (`str` æˆ– `type`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"AutoProcessor"`) â€” è¦å°†æ­¤æ–°ç‰¹å¾æå–å™¨æ³¨å†Œåˆ°çš„è‡ªåŠ¨ç±»ã€‚'
- en: Register this class with a given auto class. This should only be used for custom
    feature extractors as the ones in the library are already mapped with `AutoProcessor`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤ç±»æ³¨å†Œåˆ°ç»™å®šçš„è‡ªåŠ¨ç±»ä¸­ã€‚è¿™åº”è¯¥ä»…ç”¨äºè‡ªå®šä¹‰ç‰¹å¾æå–å™¨ï¼Œå› ä¸ºåº“ä¸­çš„ç‰¹å¾æå–å™¨å·²ç»ä¸ `AutoProcessor` æ˜ å°„ã€‚
- en: This API is experimental and may have some slight breaking changes in the next
    releases.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤ API æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½åœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­æœ‰ä¸€äº›è½»å¾®çš„ç ´åæ€§æ›´æ”¹ã€‚
- en: '#### `save_pretrained`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`save_directory` (`str` or `os.PathLike`) â€” Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` æˆ– `os.PathLike`) â€” å°†ä¿å­˜ç‰¹å¾æå–å™¨ JSON æ–‡ä»¶å’Œåˆ†è¯å™¨æ–‡ä»¶çš„ç›®å½•ï¼ˆå¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™å°†åˆ›å»ºè¯¥ç›®å½•ï¼‰ã€‚'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) â€” Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” ä¿å­˜æ¨¡å‹åæ˜¯å¦å°†æ¨¡å‹æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨
    `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` çš„åç§°ï¼‰ã€‚'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) â€” Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`ï¼Œ*å¯é€‰*) â€” ä¼ é€’ç»™ [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    æ–¹æ³•çš„å…¶ä»–å…³é”®å­—å‚æ•°ã€‚'
- en: Saves the attributes of this processor (feature extractor, tokenizerâ€¦) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿å­˜æ­¤å¤„ç†å™¨çš„å±æ€§ï¼ˆç‰¹å¾æå–å™¨ã€åˆ†è¯å™¨ç­‰ï¼‰åˆ°æŒ‡å®šç›®å½•ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    æ–¹æ³•é‡æ–°åŠ è½½ã€‚
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    å’Œ [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)ã€‚è¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `to_dict`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L102)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L102)'
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Returns
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›å€¼
- en: '`Dict[str, Any]`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, Any]`'
- en: Dictionary of all the attributes that make up this processor instance.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…å«æ„æˆæ­¤å¤„ç†å™¨å®ä¾‹çš„æ‰€æœ‰å±æ€§çš„å­—å…¸ã€‚
- en: Serializes this instance to a Python dictionary.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º Python å­—å…¸ã€‚
- en: '#### `to_json_file`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_json_file`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L151)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L151)'
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`json_file_path` (`str` or `os.PathLike`) â€” Path to the JSON file in which
    this processor instanceâ€™s parameters will be saved.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`json_file_path` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜æ­¤å¤„ç†å™¨å®ä¾‹å‚æ•°çš„ JSON æ–‡ä»¶è·¯å¾„ã€‚'
- en: Save this instance to a JSON file.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å®ä¾‹ä¿å­˜åˆ° JSON æ–‡ä»¶ä¸­ã€‚
- en: '#### `to_json_string`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_json_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L140)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L140)'
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Returns
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›å€¼
- en: '`str`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: String containing all the attributes that make up this feature_extractor instance
    in JSON format.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ JSON æ ¼å¼åŒ…å«æ„æˆæ­¤ feature_extractor å®ä¾‹çš„æ‰€æœ‰å±æ€§çš„å­—ç¬¦ä¸²ã€‚
- en: Serializes this instance to a JSON string.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ã€‚
- en: Deprecated processors
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å·²å¼ƒç”¨çš„å¤„ç†å™¨
- en: All processors follow the same architecture which is that of the [DataProcessor](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.DataProcessor).
    The processor returns a list of [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample).
    These [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)
    can be converted to [InputFeatures](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputFeatures)
    in order to be fed to the model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å¤„ç†å™¨éƒ½éµå¾ªç›¸åŒçš„æ¶æ„ï¼Œå³ [DataProcessor](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.DataProcessor)
    çš„æ¶æ„ã€‚å¤„ç†å™¨è¿”å›ä¸€ä¸ª [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)
    åˆ—è¡¨ã€‚è¿™äº› [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)
    å¯ä»¥è½¬æ¢ä¸º [InputFeatures](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputFeatures)ï¼Œä»¥ä¾¿é¦ˆé€åˆ°æ¨¡å‹ä¸­ã€‚
- en: '### `class transformers.DataProcessor`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DataProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L80)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L80)'
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Base class for data converters for sequence classification data sets.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåºåˆ—åˆ†ç±»æ•°æ®é›†çš„æ•°æ®è½¬æ¢å™¨çš„åŸºç±»ã€‚
- en: '#### `get_dev_examples`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_dev_examples`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L97)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L97)'
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Gets a collection of [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)
    for the dev set.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºå¼€å‘é›†è·å–ä¸€ç»„ [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)ã€‚
- en: '#### `get_example_from_tensor_dict`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_example_from_tensor_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L83)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L83)'
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Gets an example from a dict with tensorflow tensors.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å¸¦æœ‰ tensorflow å¼ é‡çš„å­—å…¸ä¸­è·å–ä¸€ä¸ªç¤ºä¾‹ã€‚
- en: '#### `get_labels`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_labels`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L105)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L105)'
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Gets the list of labels for this data set.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: è·å–æ­¤æ•°æ®é›†çš„æ ‡ç­¾åˆ—è¡¨ã€‚
- en: '#### `get_test_examples`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_test_examples`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L101)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L101)'
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Gets a collection of [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)
    for the test set.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæµ‹è¯•é›†è·å–ä¸€ç»„ [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)ã€‚
- en: '#### `get_train_examples`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_train_examples`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L93)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L93)'
- en: '[PRE16]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Gets a collection of [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)
    for the train set.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºè®­ç»ƒé›†è·å–ä¸€ç»„ [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)ã€‚
- en: '#### `tfds_map`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tfds_map`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L109)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L109)'
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets
    are. This method converts examples to the correct format.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æŸäº› tensorflow_datasets æ•°æ®é›†çš„æ ¼å¼ä¸ GLUE æ•°æ®é›†ä¸åŒã€‚æ­¤æ–¹æ³•å°†ç¤ºä¾‹è½¬æ¢ä¸ºæ­£ç¡®çš„æ ¼å¼ã€‚
- en: '### `class transformers.InputExample`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.InputExample`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L29)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L29)'
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: A single training/test example for simple sequence classification.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç®€å•åºåˆ—åˆ†ç±»çš„å•ä¸ªè®­ç»ƒ/æµ‹è¯•ç¤ºä¾‹ã€‚
- en: '#### `to_json_string`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_json_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L49)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L49)'
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Serializes this instance to a JSON string.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ã€‚
- en: '### `class transformers.InputFeatures`'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.InputFeatures`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L54)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L54)'
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: A single set of features of data. Property names are the same names as the corresponding
    inputs to a model.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®çš„ä¸€ç»„ç‰¹å¾ã€‚å±æ€§åç§°ä¸æ¨¡å‹çš„ç›¸åº”è¾“å…¥åç§°ç›¸åŒã€‚
- en: '#### `to_json_string`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_json_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L75)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L75)'
- en: '[PRE21]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Serializes this instance to a JSON string.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ã€‚
- en: GLUE
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GLUE
- en: '[General Language Understanding Evaluation (GLUE)](https://gluebenchmark.com/)
    is a benchmark that evaluates the performance of models across a diverse set of
    existing NLU tasks. It was released together with the paper [GLUE: A multi-task
    benchmark and analysis platform for natural language understanding](https://openreview.net/pdf?id=rJ4km2R5t7)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[é€šç”¨è¯­è¨€ç†è§£è¯„ä¼°ï¼ˆGLUEï¼‰](https://gluebenchmark.com/)æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨å„ç§ç°æœ‰NLUä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®ƒä¸è®ºæ–‡[GLUEï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„å¤šä»»åŠ¡åŸºå‡†å’Œåˆ†æå¹³å°](https://openreview.net/pdf?id=rJ4km2R5t7)ä¸€èµ·å‘å¸ƒ'
- en: 'This library hosts a total of 10 processors for the following tasks: MRPC,
    MNLI, MNLI (mismatched), CoLA, SST2, STSB, QQP, QNLI, RTE and WNLI.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåº“ä¸ºä»¥ä¸‹ä»»åŠ¡æä¾›äº†æ€»å…±10ä¸ªå¤„ç†å™¨ï¼šMRPCï¼ŒMNLIï¼ŒMNLIï¼ˆä¸åŒ¹é…ï¼‰ï¼ŒCoLAï¼ŒSST2ï¼ŒSTSBï¼ŒQQPï¼ŒQNLIï¼ŒRTEå’ŒWNLIã€‚
- en: 'Those processors are:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤„ç†å™¨æ˜¯ï¼š
- en: '`~data.processors.utils.MrpcProcessor`'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.MrpcProcessor`'
- en: '`~data.processors.utils.MnliProcessor`'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.MnliProcessor`'
- en: '`~data.processors.utils.MnliMismatchedProcessor`'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.MnliMismatchedProcessor`'
- en: '`~data.processors.utils.Sst2Processor`'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.Sst2Processor`'
- en: '`~data.processors.utils.StsbProcessor`'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.StsbProcessor`'
- en: '`~data.processors.utils.QqpProcessor`'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.QqpProcessor`'
- en: '`~data.processors.utils.QnliProcessor`'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.QnliProcessor`'
- en: '`~data.processors.utils.RteProcessor`'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.RteProcessor`'
- en: '`~data.processors.utils.WnliProcessor`'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.WnliProcessor`'
- en: Additionally, the following method can be used to load values from a data file
    and convert them to a list of [InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä»¥ä¸‹æ–¹æ³•å¯ç”¨äºä»æ•°æ®æ–‡ä»¶åŠ è½½å€¼å¹¶å°†å…¶è½¬æ¢ä¸º[InputExample](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.InputExample)åˆ—è¡¨ã€‚
- en: '#### `transformers.glue_convert_examples_to_features`'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `transformers.glue_convert_examples_to_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/glue.py#L41)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/glue.py#L41)'
- en: '[PRE22]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Loads a data file into a list of `InputFeatures`
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ•°æ®æ–‡ä»¶åŠ è½½åˆ°`InputFeatures`åˆ—è¡¨ä¸­
- en: XNLI
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XNLI
- en: '[The Cross-Lingual NLI Corpus (XNLI)](https://www.nyu.edu/projects/bowman/xnli/)
    is a benchmark that evaluates the quality of cross-lingual text representations.
    XNLI is crowd-sourced dataset based on [*MultiNLI*](http://www.nyu.edu/projects/bowman/multinli/):
    pairs of text are labeled with textual entailment annotations for 15 different
    languages (including both high-resource language such as English and low-resource
    languages such as Swahili).'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[è·¨è¯­è¨€NLIè¯­æ–™åº“ï¼ˆXNLIï¼‰](https://www.nyu.edu/projects/bowman/xnli/)æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œè¯„ä¼°è·¨è¯­è¨€æ–‡æœ¬è¡¨ç¤ºçš„è´¨é‡ã€‚XNLIæ˜¯åŸºäº[*MultiNLI*](http://www.nyu.edu/projects/bowman/multinli/)çš„ä¼—åŒ…æ•°æ®é›†ï¼šæ–‡æœ¬å¯¹ä½¿ç”¨15ç§ä¸åŒè¯­è¨€ï¼ˆåŒ…æ‹¬é«˜èµ„æºè¯­è¨€å¦‚è‹±è¯­å’Œä½èµ„æºè¯­è¨€å¦‚æ–¯ç“¦å¸Œé‡Œè¯­ï¼‰è¿›è¡Œæ–‡æœ¬è•´æ¶µæ³¨é‡Šã€‚'
- en: 'It was released together with the paper [XNLI: Evaluating Cross-lingual Sentence
    Representations](https://arxiv.org/abs/1809.05053)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¸è®ºæ–‡[XNLIï¼šè¯„ä¼°è·¨è¯­è¨€å¥å­è¡¨ç¤º](https://arxiv.org/abs/1809.05053)ä¸€èµ·å‘å¸ƒ
- en: 'This library hosts the processor to load the XNLI data:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåº“æä¾›äº†åŠ è½½XNLIæ•°æ®çš„å¤„ç†å™¨ï¼š
- en: '`~data.processors.utils.XnliProcessor`'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.XnliProcessor`'
- en: Please note that since the gold labels are available on the test set, evaluation
    is performed on the test set.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œç”±äºæµ‹è¯•é›†ä¸Šæœ‰é‡‘æ ‡ç­¾ï¼Œè¯„ä¼°æ˜¯åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œçš„ã€‚
- en: An example using these processors is given in the [run_xnli.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification/run_xnli.py)
    script.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[run_xnli.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification/run_xnli.py)è„šæœ¬ä¸­æä¾›äº†ä½¿ç”¨è¿™äº›å¤„ç†å™¨çš„ç¤ºä¾‹ã€‚
- en: SQuAD
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SQuAD
- en: '[The Stanford Question Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer//)
    is a benchmark that evaluates the performance of models on question answering.
    Two versions are available, v1.1 and v2.0\. The first version (v1.1) was released
    together with the paper [SQuAD: 100,000+ Questions for Machine Comprehension of
    Text](https://arxiv.org/abs/1606.05250). The second version (v2.0) was released
    alongside the paper [Know What You Donâ€™t Know: Unanswerable Questions for SQuAD](https://arxiv.org/abs/1806.03822).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ–¯å¦ç¦é—®ç­”æ•°æ®é›†ï¼ˆSQuADï¼‰](https://rajpurkar.github.io/SQuAD-explorer//)æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨é—®ç­”ä¸Šçš„è¡¨ç°ã€‚æœ‰ä¸¤ä¸ªç‰ˆæœ¬å¯ç”¨ï¼Œv1.1å’Œv2.0ã€‚ç¬¬ä¸€ä¸ªç‰ˆæœ¬ï¼ˆv1.1ï¼‰ä¸è®ºæ–‡[SQuADï¼šæ–‡æœ¬æœºå™¨ç†è§£çš„10ä¸‡+é—®é¢˜](https://arxiv.org/abs/1606.05250)ä¸€èµ·å‘å¸ƒã€‚ç¬¬äºŒä¸ªç‰ˆæœ¬ï¼ˆv2.0ï¼‰ä¸è®ºæ–‡[çŸ¥é“ä½ ä¸çŸ¥é“çš„ï¼šSQuADçš„æ— æ³•å›ç­”é—®é¢˜](https://arxiv.org/abs/1806.03822)ä¸€èµ·å‘å¸ƒã€‚'
- en: 'This library hosts a processor for each of the two versions:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåº“ä¸ºä¸¤ä¸ªç‰ˆæœ¬ä¸­çš„æ¯ä¸ªç‰ˆæœ¬æä¾›äº†å¤„ç†å™¨ï¼š
- en: Processors
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤„ç†å™¨
- en: 'Those processors are:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤„ç†å™¨æ˜¯ï¼š
- en: '`~data.processors.utils.SquadV1Processor`'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.SquadV1Processor`'
- en: '`~data.processors.utils.SquadV2Processor`'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~data.processors.utils.SquadV2Processor`'
- en: They both inherit from the abstract class `~data.processors.utils.SquadProcessor`
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬éƒ½ç»§æ‰¿è‡ªæŠ½è±¡ç±»`~data.processors.utils.SquadProcessor`
- en: '### `class transformers.data.processors.squad.SquadProcessor`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.data.processors.squad.SquadProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L541)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L541)'
- en: '[PRE23]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor,
    used by the version 1.1 and version 2.0 of SQuAD, respectively.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: SQuADæ•°æ®é›†çš„å¤„ç†å™¨ã€‚è¢«SquadV1Processorå’ŒSquadV2Processorè¦†ç›–ï¼Œåˆ†åˆ«ç”±SQuADçš„ç‰ˆæœ¬1.1å’Œç‰ˆæœ¬2.0ä½¿ç”¨ã€‚
- en: '#### `get_dev_examples`'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_dev_examples`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L629)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L629)'
- en: '[PRE24]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Returns the evaluation example from the data directory.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ•°æ®ç›®å½•è¿”å›è¯„ä¼°ç¤ºä¾‹ã€‚
- en: '#### `get_examples_from_dataset`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_examples_from_dataset`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L574)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L574)'
- en: '[PRE25]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Creates a list of `SquadExample` using a TFDS dataset.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨TFDSæ•°æ®é›†åˆ›å»º`SquadExample`åˆ—è¡¨ã€‚
- en: 'Examples:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE26]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#### `get_train_examples`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_train_examples`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L607)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L607)'
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Returns the training examples from the data directory.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ•°æ®ç›®å½•è¿”å›è®­ç»ƒç¤ºä¾‹ã€‚
- en: Additionally, the following method can be used to convert SQuAD examples into
    `~data.processors.utils.SquadFeatures` that can be used as model inputs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä»¥ä¸‹æ–¹æ³•å¯ç”¨äºå°†SQuADç¤ºä¾‹è½¬æ¢ä¸ºå¯ç”¨ä½œæ¨¡å‹è¾“å…¥çš„`~data.processors.utils.SquadFeatures`ã€‚
- en: '#### `transformers.squad_convert_examples_to_features`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `transformers.squad_convert_examples_to_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L316)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L316)'
- en: '[PRE28]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Converts a list of examples into a list of features that can be directly given
    as input to a model. It is model-dependant and takes advantage of many of the
    tokenizerâ€™s features to create the modelâ€™s inputs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç¤ºä¾‹åˆ—è¡¨è½¬æ¢ä¸ºå¯ä»¥ç›´æ¥ä½œä¸ºæ¨¡å‹è¾“å…¥çš„ç‰¹å¾åˆ—è¡¨ã€‚å®ƒå–å†³äºæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨è®¸å¤šåˆ†è¯å™¨çš„ç‰¹æ€§æ¥åˆ›å»ºæ¨¡å‹çš„è¾“å…¥ã€‚
- en: 'Example:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å­ï¼š
- en: '[PRE29]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: These processors as well as the aforementioned method can be used with files
    containing the data as well as with the *tensorflow_datasets* package. Examples
    are given below.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤„ç†å™¨ä»¥åŠå‰è¿°æ–¹æ³•å¯ä»¥ä¸åŒ…å«æ•°æ®çš„æ–‡ä»¶ä»¥åŠ*tensorflow_datasets*åŒ…ä¸€èµ·ä½¿ç”¨ã€‚ä¸‹é¢ç»™å‡ºäº†ç¤ºä¾‹ã€‚
- en: Example usage
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ç”¨æ³•
- en: 'Here is an example using the processors as well as the conversion method using
    data files:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œä½¿ç”¨å¤„ç†å™¨ä»¥åŠä½¿ç”¨æ•°æ®æ–‡ä»¶çš„è½¬æ¢æ–¹æ³•ï¼š
- en: '[PRE30]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Using *tensorflow_datasets* is as easy as using a data file:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨*tensorflow_datasets*å°±åƒä½¿ç”¨æ•°æ®æ–‡ä»¶ä¸€æ ·ç®€å•ï¼š
- en: '[PRE31]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Another example using these processors is given in the [run_squad.py](https://github.com/huggingface/transformers/tree/main/examples/legacy/question-answering/run_squad.py)
    script.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªä½¿ç”¨è¿™äº›å¤„ç†å™¨çš„ç¤ºä¾‹åœ¨[run_squad.py](https://github.com/huggingface/transformers/tree/main/examples/legacy/question-answering/run_squad.py)è„šæœ¬ä¸­ç»™å‡ºã€‚
