- en: Activation functions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¿€æ´»å‡½æ•°
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/activations](https://huggingface.co/docs/diffusers/api/activations)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'åŸæ–‡é“¾æ¥: [https://huggingface.co/docs/diffusers/api/activations](https://huggingface.co/docs/diffusers/api/activations)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Customized activation functions for supporting various models in ğŸ¤— Diffusers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºğŸ¤— Diffusersä¸­æ”¯æŒå„ç§æ¨¡å‹çš„è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°ã€‚
- en: GELU
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GELU
- en: '### `class diffusers.models.activations.GELU`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.activations.GELU`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/activations.py#L50)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/activations.py#L50)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`dim_in` (`int`) â€” The number of channels in the input.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_in` (`int`) â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚'
- en: '`dim_out` (`int`) â€” The number of channels in the output.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_out` (`int`) â€” è¾“å‡ºé€šé“çš„æ•°é‡ã€‚'
- en: '`approximate` (`str`, *optional*, defaults to `"none"`) â€” If `"tanh"`, use
    tanh approximation.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`approximate` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"none"`) â€” å¦‚æœä¸º`"tanh"`ï¼Œåˆ™ä½¿ç”¨tanhè¿‘ä¼¼ã€‚'
- en: '`bias` (`bool`, defaults to True) â€” Whether to use a bias in the linear layer.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias` (`bool`, é»˜è®¤ä¸ºTrue) â€” æ˜¯å¦åœ¨çº¿æ€§å±‚ä¸­ä½¿ç”¨åç½®ã€‚'
- en: GELU activation function with tanh approximation support with `approximate="tanh"`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰tanhè¿‘ä¼¼æ”¯æŒçš„GELUæ¿€æ´»å‡½æ•°ï¼Œä½¿ç”¨`approximate="tanh"`ã€‚
- en: GEGLU
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GEGLU
- en: '### `class diffusers.models.activations.GEGLU`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.activations.GEGLU`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/activations.py#L78)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/activations.py#L78)'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`dim_in` (`int`) â€” The number of channels in the input.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_in` (`int`) â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚'
- en: '`dim_out` (`int`) â€” The number of channels in the output.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_out` (`int`) â€” è¾“å‡ºé€šé“çš„æ•°é‡ã€‚'
- en: '`bias` (`bool`, defaults to True) â€” Whether to use a bias in the linear layer.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias` (`bool`, é»˜è®¤ä¸ºTrue) â€” æ˜¯å¦åœ¨çº¿æ€§å±‚ä¸­ä½¿ç”¨åç½®ã€‚'
- en: A [variant](https://arxiv.org/abs/2002.05202) of the gated linear unit activation
    function.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: é—¨æ§çº¿æ€§å•å…ƒæ¿€æ´»å‡½æ•°çš„ä¸€ç§å˜ä½“ã€‚
- en: ApproximateGELU
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ApproximateGELU
- en: '### `class diffusers.models.activations.ApproximateGELU`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.models.activations.ApproximateGELU`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/activations.py#L106)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/activations.py#L106)'
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`dim_in` (`int`) â€” The number of channels in the input.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_in` (`int`) â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚'
- en: '`dim_out` (`int`) â€” The number of channels in the output.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim_out` (`int`) â€” è¾“å‡ºé€šé“çš„æ•°é‡ã€‚'
- en: '`bias` (`bool`, defaults to True) â€” Whether to use a bias in the linear layer.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias` (`bool`, é»˜è®¤ä¸ºTrue) â€” æ˜¯å¦åœ¨çº¿æ€§å±‚ä¸­ä½¿ç”¨åç½®ã€‚'
- en: The approximate form of the Gaussian Error Linear Unit (GELU). For more details,
    see section 2 of this [paper](https://arxiv.org/abs/1606.08415).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: é«˜æ–¯è¯¯å·®çº¿æ€§å•å…ƒï¼ˆGELUï¼‰çš„è¿‘ä¼¼å½¢å¼ã€‚æ›´å¤šç»†èŠ‚è¯·å‚è§è¿™ç¯‡[è®ºæ–‡](https://arxiv.org/abs/1606.08415)çš„ç¬¬2èŠ‚ã€‚
