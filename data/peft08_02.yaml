- en: PEFT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PEFT
- en: 'Original text: [https://huggingface.co/docs/peft/index](https://huggingface.co/docs/peft/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://huggingface.co/docs/peft/index](https://huggingface.co/docs/peft/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ¤— PEFT (Parameter-Efficient Fine-Tuning) is a library for efficiently adapting
    large pretrained models to various downstream applications without fine-tuning
    all of a modelâ€™s parameters because it is prohibitively costly. PEFT methods only
    fine-tune a small number of (extra) model parameters - significantly decreasing
    computational and storage costs - while yielding performance comparable to a fully
    fine-tuned model. This makes it more accessible to train and store large language
    models (LLMs) on consumer hardware.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— PEFTï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰æ˜¯ä¸€ä¸ªåº“ï¼Œç”¨äºæœ‰æ•ˆåœ°è°ƒæ•´å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ä»¥é€‚åº”å„ç§ä¸‹æ¸¸åº”ç”¨ï¼Œè€Œæ— éœ€å¾®è°ƒæ‰€æœ‰æ¨¡å‹å‚æ•°ï¼Œå› ä¸ºè¿™æ˜¯ä»£ä»·é«˜æ˜‚çš„ã€‚PEFTæ–¹æ³•ä»…å¾®è°ƒå°‘é‡ï¼ˆé¢å¤–çš„ï¼‰æ¨¡å‹å‚æ•°
    - æ˜¾è‘—é™ä½è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ - åŒæ—¶äº§ç”Ÿä¸å®Œå…¨å¾®è°ƒæ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚è¿™ä½¿å¾—åœ¨æ¶ˆè´¹è€…ç¡¬ä»¶ä¸Šè®­ç»ƒå’Œå­˜å‚¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ›´åŠ å®¹æ˜“ã€‚
- en: PEFT is integrated with the Transformers, Diffusers, and Accelerate libraries
    to provide a faster and easier way to load, train, and use large models for inference.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: PEFTä¸Transformersã€Diffuserså’ŒAccelerateåº“é›†æˆï¼Œæä¾›äº†ä¸€ç§æ›´å¿«æ›´ç®€å•çš„æ–¹å¼æ¥åŠ è½½ã€è®­ç»ƒå’Œä½¿ç”¨å¤§å‹æ¨¡å‹è¿›è¡Œæ¨æ–­ã€‚
- en: '[Get started'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¼€å§‹'
- en: Start here if you're new to ğŸ¤— PEFT to get an overview of the library's main
    features, and how to train a model with a PEFT method.](quicktour) [How-to guides
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ˜¯ğŸ¤— PEFTçš„æ–°æ‰‹ï¼Œè¯·ä»è¿™é‡Œå¼€å§‹ï¼Œäº†è§£åº“çš„ä¸»è¦ç‰¹ç‚¹ä»¥åŠå¦‚ä½•ä½¿ç”¨PEFTæ–¹æ³•è®­ç»ƒæ¨¡å‹ã€‚](quicktour) [æ“ä½œæŒ‡å—
- en: Practical guides demonstrating how to apply various PEFT methods across different
    types of tasks like image classification, causal language modeling, automatic
    speech recognition, and more. Learn how to use ğŸ¤— PEFT with the DeepSpeed and Fully
    Sharded Data Parallel scripts.](./task_guides/image_classification_lora) [Conceptual
    guides
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç”¨æŒ‡å—æ¼”ç¤ºå¦‚ä½•åœ¨ä¸åŒç±»å‹çš„ä»»åŠ¡ï¼ˆå¦‚å›¾åƒåˆ†ç±»ã€å› æœè¯­è¨€å»ºæ¨¡ã€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç­‰ï¼‰ä¸­åº”ç”¨å„ç§PEFTæ–¹æ³•ã€‚å­¦ä¹ å¦‚ä½•ä½¿ç”¨ğŸ¤— PEFTä¸DeepSpeedå’ŒFully
    Sharded Data Parallelè„šæœ¬ã€‚](./task_guides/image_classification_lora) [æ¦‚å¿µæŒ‡å—
- en: Get a better theoretical understanding of how LoRA and various soft prompting
    methods help reduce the number of trainable parameters to make training more efficient.](./conceptual_guides/lora)
    [Reference
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ›´å¥½åœ°ç†è§£LoRAå’Œå„ç§è½¯æç¤ºæ–¹æ³•å¦‚ä½•å¸®åŠ©å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼Œä»è€Œä½¿è®­ç»ƒæ›´åŠ é«˜æ•ˆã€‚](./conceptual_guides/lora) [å‚è€ƒ
- en: Technical descriptions of how ğŸ¤— PEFT classes and methods work.](./package_reference/config)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ€æœ¯æè¿°äº†ğŸ¤— PEFTç±»å’Œæ–¹æ³•çš„å·¥ä½œåŸç†ã€‚](./package_reference/config)
- en: '[https://stevhliu-peft-methods.hf.space](https://stevhliu-peft-methods.hf.space)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://stevhliu-peft-methods.hf.space](https://stevhliu-peft-methods.hf.space)'
