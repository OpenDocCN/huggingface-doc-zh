- en: BridgeTower
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BridgeTower
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bridgetower](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bridgetower)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bridgetower](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bridgetower)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The BridgeTower model was proposed in [BridgeTower: Building Bridges Between
    Encoders in Vision-Language Representative Learning](https://arxiv.org/abs/2206.08657)
    by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.
    The goal of this model is to build a bridge between each uni-modal encoder and
    the cross-modal encoder to enable comprehensive and detailed interaction at each
    layer of the cross-modal encoder thus achieving remarkable performance on various
    downstream tasks with almost negligible additional performance and computational
    costs.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'BridgeTower模型是由Xiao Xu、Chenfei Wu、Shachar Rosenman、Vasudev Lal、Wanxiang Che、Nan
    Duan在[《BridgeTower: Building Bridges Between Encoders in Vision-Language Representative
    Learning》](https://arxiv.org/abs/2206.08657)中提出的。该模型的目标是在每个交叉模态编码器的每一层之间建立桥梁，以实现全面和详细的交互，从而在各种下游任务中取得显著的性能，几乎没有额外的性能和计算成本。'
- en: This paper has been accepted to the [AAAI’23](https://aaai.org/Conferences/AAAI-23/)
    conference.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文已被[AAAI’23](https://aaai.org/Conferences/AAAI-23/)会议接受。
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Vision-Language (VL) models with the TWO-TOWER architecture have dominated
    visual-language representation learning in recent years. Current VL models either
    use lightweight uni-modal encoders and learn to extract, align and fuse both modalities
    simultaneously in a deep cross-modal encoder, or feed the last-layer uni-modal
    representations from the deep pre-trained uni-modal encoders into the top cross-modal
    encoder. Both approaches potentially restrict vision-language representation learning
    and limit model performance. In this paper, we propose BRIDGETOWER, which introduces
    multiple bridge layers that build a connection between the top layers of uni-modal
    encoders and each layer of the crossmodal encoder. This enables effective bottom-up
    cross-modal alignment and fusion between visual and textual representations of
    different semantic levels of pre-trained uni-modal encoders in the cross-modal
    encoder. Pre-trained with only 4M images, BRIDGETOWER achieves state-of-the-art
    performance on various downstream vision-language tasks. In particular, on the
    VQAv2 test-std set, BRIDGETOWER achieves an accuracy of 78.73%, outperforming
    the previous state-of-the-art model METER by 1.09% with the same pre-training
    data and almost negligible additional parameters and computational costs. Notably,
    when further scaling the model, BRIDGETOWER achieves an accuracy of 81.15%, surpassing
    models that are pre-trained on orders-of-magnitude larger datasets.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*近年来，具有双塔架构的视觉语言（VL）模型在视觉语言表示学习中占据主导地位。当前的VL模型要么使用轻量级的单模编码器并学习同时提取、对齐和融合两种模态，要么将深度预训练的单模编码器的最后一层单模表示馈送到顶部交叉模态编码器中。这两种方法都可能限制视觉语言表示学习并限制模型性能。在本文中，我们提出了BRIDGETOWER，它引入了多个桥接层，建立了单模编码器的顶层与交叉模态编码器的每一层之间的连接。这使得在交叉模态编码器中能够有效地进行自底向上的跨模态对齐和融合，从而实现不同语义级别的预训练单模编码器的视觉和文本表示之间的交叉模态对齐和融合。仅使用4M张图像进行预训练，BRIDGETOWER在各种下游视觉语言任务上实现了最先进的性能。特别是在VQAv2测试集上，BRIDGETOWER实现了78.73%的准确率，比之前的最先进模型METER高出1.09%，使用相同的预训练数据几乎没有额外的参数和计算成本。值得注意的是，当进一步扩展模型时，BRIDGETOWER实现了81.15%的准确率，超过了在数量级更大的数据集上进行预训练的模型。*'
- en: '![drawing](../Images/2cf6cac1e694d76fda85d82f66c9a1aa.png) BridgeTower architecture.
    Taken from the [original paper.](https://arxiv.org/abs/2206.08657)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![drawing](../Images/2cf6cac1e694d76fda85d82f66c9a1aa.png) BridgeTower架构。摘自[原始论文。](https://arxiv.org/abs/2206.08657)'
- en: This model was contributed by [Anahita Bhiwandiwalla](https://huggingface.co/anahita-b),
    [Tiep Le](https://huggingface.co/Tile) and [Shaoyen Tseng](https://huggingface.co/shaoyent).
    The original code can be found [here](https://github.com/microsoft/BridgeTower).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[Anahita Bhiwandiwalla](https://huggingface.co/anahita-b)、[Tiep Le](https://huggingface.co/Tile)和[Shaoyen
    Tseng](https://huggingface.co/shaoyent)贡献。原始代码可以在[这里](https://github.com/microsoft/BridgeTower)找到。
- en: Usage tips and examples
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示和示例
- en: BridgeTower consists of a visual encoder, a textual encoder and cross-modal
    encoder with multiple lightweight bridge layers. The goal of this approach was
    to build a bridge between each uni-modal encoder and the cross-modal encoder to
    enable comprehensive and detailed interaction at each layer of the cross-modal
    encoder. In principle, one can apply any visual, textual or cross-modal encoder
    in the proposed architecture.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: BridgeTower包括一个视觉编码器、一个文本编码器和一个带有多个轻量级桥接层的交叉模态编码器。该方法的目标是在每个交叉模态编码器的每一层之间建立桥梁，以实现全面和详细的交互。原则上，可以在提出的架构中应用任何视觉、文本或交叉模态编码器。
- en: The [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    wraps [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    and [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    into a single instance to both encode the text and prepare the images respectively.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)将[RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)和[BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)封装成一个单一实例，用于同时对文本进行编码和准备图像。'
- en: The following example shows how to run contrastive learning using [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    and [BridgeTowerForContrastiveLearning](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForContrastiveLearning).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何使用[BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)和[BridgeTowerForContrastiveLearning](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForContrastiveLearning)来运行对比学习。
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The following example shows how to run image-text retrieval using [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    and [BridgeTowerForImageAndTextRetrieval](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForImageAndTextRetrieval).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例显示如何使用[BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)和[BridgeTowerForImageAndTextRetrieval](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForImageAndTextRetrieval)运行图像文本检索。
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The following example shows how to run masked language modeling using [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    and [BridgeTowerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForMaskedLM).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例显示如何使用[BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)和[BridgeTowerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForMaskedLM)运行掩码语言建模。
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Tips:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: This implementation of BridgeTower uses [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    to generate text embeddings and OpenAI’s CLIP/ViT model to compute visual embeddings.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此BridgeTower的实现使用[RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)生成文本嵌入，并使用OpenAI的CLIP/ViT模型计算视觉嵌入。
- en: Checkpoints for pre-trained [bridgeTower-base](https://huggingface.co/BridgeTower/bridgetower-base)
    and [bridgetower masked language modeling and image text matching](https://huggingface.co/BridgeTower/bridgetower-base-itm-mlm)
    are released.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布了预训练的[bridgeTower-base](https://huggingface.co/BridgeTower/bridgetower-base)和[bridgetower
    masked language modeling and image text matching](https://huggingface.co/BridgeTower/bridgetower-base-itm-mlm)的检查点。
- en: Please refer to [Table 5](https://arxiv.org/pdf/2206.08657.pdf) for BridgeTower’s
    performance on Image Retrieval and other down stream tasks.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考[Table 5](https://arxiv.org/pdf/2206.08657.pdf)了解BridgeTower在图像检索和其他下游任务上的性能。
- en: The PyTorch version of this model is only available in torch 1.10 and higher.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此模型的PyTorch版本仅在torch 1.10及更高版本中可用。
- en: BridgeTowerConfig
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerConfig
- en: '### `class transformers.BridgeTowerConfig`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L243)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L243)'
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`share_cross_modal_transformer_layers` (`bool`, *optional*, defaults to `True`)
    — Whether cross modal transformer layers are shared.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`share_cross_modal_transformer_layers` (`bool`, *optional*, defaults to `True`)
    — 是否共享跨模态transformer层。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 编码器层和池化层的维度。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1) — A factor for initializing
    all weight matrices (should be kept to 1, used internally for initialization testing).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor` (`float`, *optional*, defaults to 1) — 用于初始化所有权重矩阵的因子（应保持为1，用于内部初始化测试）。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — 层归一化层使用的epsilon。'
- en: '`share_link_tower_layers` (`bool`, *optional*, defaults to `False`) — Whether
    the bride/link tower layers are shared.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`share_link_tower_layers` (`bool`, *optional*, defaults to `False`) — 是否共享桥/链接塔层。'
- en: '`link_tower_type` (`str`, *optional*, defaults to `"add"`) — Type of the bridge/link
    layer.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`link_tower_type` (`str`, *optional*, defaults to `"add"`) — 桥/链接层的类型。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Transformer编码器中每个注意力层的注意力头数。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 6) — Number of hidden layers
    in the Transformer encoder.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 6) — Transformer编码器中的隐藏层数量。'
- en: '`tie_word_embeddings` (`bool`, *optional*, defaults to `False`) — Whether to
    tie input and output embeddings.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tie_word_embeddings` (`bool`, *optional*, defaults to `False`) — 是否绑定输入和输出嵌入。'
- en: '`init_layernorm_from_vision_encoder` (`bool`, *optional*, defaults to `False`)
    — Whether to init LayerNorm from the vision encoder.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_layernorm_from_vision_encoder` (`bool`, *optional*, defaults to `False`)
    — 是否从视觉编码器初始化LayerNorm。'
- en: '`text_config` (`dict`, *optional*) — Dictionary of configuration options used
    to initialize [BridgeTowerTextConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerTextConfig).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_config` (`dict`, *optional*) — 用于初始化[BridgeTowerTextConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerTextConfig)的配置选项字典。'
- en: '`vision_config` (`dict`, *optional*) — Dictionary of configuration options
    used to initialize [BridgeTowerVisionConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerVisionConfig).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_config` (`dict`, *optional*) — 用于初始化[BridgeTowerVisionConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerVisionConfig)的配置选项字典。'
- en: This is the configuration class to store the configuration of a [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel).
    It is used to instantiate a BridgeTower model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the bridgetower-base [BridgeTower/bridgetower-base](https://huggingface.co/BridgeTower/bridgetower-base/)
    architecture.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)配置的配置类。根据指定的参数实例化一个BridgeTower模型，定义模型架构。使用默认值实例化配置将产生与bridgetower-base
    [BridgeTower/bridgetower-base](https://huggingface.co/BridgeTower/bridgetower-base/)架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    并可用于控制模型输出。阅读来自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `from_text_vision_configs`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_text_vision_configs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L344)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L344)'
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Instantiate a [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    (or a derived class) from BridgeTower text model configuration. Returns: [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig):
    An instance of a configuration object'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '从 BridgeTower 文本模型配置中实例化一个 [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)（或派生类）。返回:
    [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig):
    配置对象的实例'
- en: BridgeTowerTextConfig
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerTextConfig
- en: '### `class transformers.BridgeTowerTextConfig`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerTextConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L121)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L121)'
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 50265) — Vocabulary size of the
    text part of the model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *可选*, 默认为50265) — 模型文本部分的词汇表大小。定义了在调用 [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    时可以表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *可选*, 默认为768) — 编码器层和池化器层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *可选*, 默认为12) — Transformer 编码器中的隐藏层数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *可选*, 默认为12) — Transformer 编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (often named feed-forward) layer in the Transformer encoder.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *可选*, 默认为3072) — Transformer 编码器中“中间”（通常称为前馈）层的维度。'
- en: '`hidden_act` (`str` or `Callable`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` 或 `Callable`, *可选*, 默认为`"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probability for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *可选*, 默认为0.1) — 嵌入层、编码器和池化器中所有全连接层的丢弃概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *可选*, 默认为0.1) — 注意力概率的丢弃比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 514) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *可选*, 默认为514) — 此模型可能使用的最大序列长度。通常将其设置为一个较大的值以防万一（例如512、1024或2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids`.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *可选*, 默认为2) — `token_type_ids` 的词汇表大小。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1) — A factor for initializing
    all weight matrices (should be kept to 1, used internally for initialization testing).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor` (`float`, *可选*, 默认为1) — 用于初始化所有权重矩阵的因子（应保持为1，用于内部初始化测试）。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *可选*, 默认为1e-05) — 层归一化层使用的 epsilon。'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"absolute"`) — Type
    of position embedding. Choose one of `"absolute"`, `"relative_key"`, `"relative_key_query"`.
    For positional embeddings use `"absolute"`. For more information on `"relative_key"`,
    please refer to [Self-Attention with Relative Position Representations (Shaw et
    al.)](https://arxiv.org/abs/1803.02155). For more information on `"relative_key_query"`,
    please refer to *Method 4* in [Improve Transformer Models with Better Relative
    Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *可选*, 默认为`"absolute"`) — 位置嵌入的类型。选择`"absolute"`、`"relative_key"`、`"relative_key_query"`中的一个。对于位置嵌入，请使用`"absolute"`。有关`"relative_key"`的更多信息，请参考[Self-Attention
    with Relative Position Representations (Shaw et al.)](https://arxiv.org/abs/1803.02155)。有关`"relative_key_query"`的更多信息，请参考[Improve
    Transformer Models with Better Relative Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658)
    中的 *Method 4*。'
- en: '`is_decoder` (`bool`, *optional*, defaults to `False`) — Whether the model
    is used as a decoder or not. If `False`, the model is used as an encoder.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_decoder` (`bool`, *可选*, 默认为`False`) — 模型是否用作解码器。如果为`False`，则模型用作编码器。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models). Only relevant
    if `config.is_decoder=True`.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *可选*, 默认为`True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。仅在`config.is_decoder=True`时相关。'
- en: This is the configuration class to store the text configuration of a [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel).
    The default values here are copied from RoBERTa. Instantiating a configuration
    with the defaults will yield a similar configuration to that of the bridgetower-base
    [BridegTower/bridgetower-base](https://huggingface.co/BridgeTower/bridgetower-base/)
    architecture.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)的文本配置的配置类。这里的默认值是从RoBERTa复制的。使用默认值实例化配置将产生与bridgetower-base
    [BridegTower/bridgetower-base](https://huggingface.co/BridgeTower/bridgetower-base/)架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: BridgeTowerVisionConfig
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerVisionConfig
- en: '### `class transformers.BridgeTowerVisionConfig`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerVisionConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L34)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/configuration_bridgetower.py#L34)'
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`，*可选*，默认为768) — 编码器层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in visual encoder model.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`，*可选*，默认为12) — 视觉编码器模型中的隐藏层数量。'
- en: '`patch_size` (`int`, *optional*, defaults to 16) — The size (resolution) of
    each patch.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`，*可选*，默认为16) — 每个补丁的大小（分辨率）。'
- en: '`image_size` (`int`, *optional*, defaults to 288) — The size (resolution) of
    each image.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`，*可选*，默认为288) — 每个图像的大小（分辨率）。'
- en: '`initializer_factor` (`float`, *optional*, defaults to 1) — A factor for initializing
    all weight matrices (should be kept to 1, used internally for initialization testing).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_factor` (`float`，*可选*，默认为1) — 用于初始化所有权重矩阵的因子（应保持为1，用于内部初始化测试）。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-05) — The epsilon used
    by the layer normalization layers.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`，*可选*，默认为1e-05) — 层归一化层使用的epsilon。'
- en: '`stop_gradient` (`bool`, *optional*, defaults to `False`) — Whether to stop
    gradient for training.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stop_gradient` (`bool`，*可选*，默认为`False`) — 是否停止训练的梯度。'
- en: '`share_layernorm` (`bool`, *optional*, defaults to `True`) — Whether LayerNorm
    layers are shared.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`share_layernorm` (`bool`，*可选*，默认为`True`) — 是否共享LayerNorm层。'
- en: '`remove_last_layer` (`bool`, *optional*, defaults to `False`) — Whether to
    remove the last layer from the vision encoder.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remove_last_layer` (`bool`，*可选*，默认为`False`) — 是否从视觉编码器中移除最后一层。'
- en: This is the configuration class to store the vision configuration of a [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel).
    Instantiating a configuration with the defaults will yield a similar configuration
    to that of the bridgetower-base [BridgeTower/bridgetower-base](https://huggingface.co/BridgeTower/bridgetower-base/)
    architecture.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)的视觉配置的配置类。使用默认值实例化配置将产生与bridgetower-base
    [BridgeTower/bridgetower-base](https://huggingface.co/BridgeTower/bridgetower-base/)架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: BridgeTowerImageProcessor
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerImageProcessor
- en: '### `class transformers.BridgeTowerImageProcessor`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/image_processing_bridgetower.py#L123)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/image_processing_bridgetower.py#L123)'
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions to the specified `size`. Can be overridden
    by the `do_resize` parameter in the `preprocess` method.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`，*可选*，默认为`True`) — 是否将图像的（高度，宽度）尺寸调整为指定的`size`。可以被`preprocess`方法中的`do_resize`参数覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to 288) — Resize the shorter
    side of the input to `size["shortest_edge"]`. The longer side will be limited
    to under `int((1333 / 800) * size["shortest_edge"])` while preserving the aspect
    ratio. Only has an effect if `do_resize` is set to `True`. Can be overridden by
    the `size` parameter in the `preprocess` method.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *可选*，默认为288) — 将输入的较短边调整为`size["shortest_edge"]`。较长边将受限于`int((1333
    / 800) * size["shortest_edge"])`，同时保持纵横比。仅在`do_resize`设置为`True`时有效。可以被`preprocess`方法中的`size`参数覆盖。'
- en: '`size_divisor` (`int`, *optional*, defaults to 32) — The size by which to make
    sure both the height and width can be divided. Only has an effect if `do_resize`
    is set to `True`. Can be overridden by the `size_divisor` parameter in the `preprocess`
    method.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisor` (`int`，*可选*，默认为32) — 确保高度和宽度都可以被划分的大小。仅在`do_resize`设置为`True`时有效。可以被`preprocess`方法中的`size_divisor`参数覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BICUBIC`)
    — Resampling filter to use if resizing the image. Only has an effect if `do_resize`
    is set to `True`. Can be overridden by the `resample` parameter in the `preprocess`
    method.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *可选*, 默认为 `Resampling.BICUBIC`) — 如果调整图像大小，则使用的重采样滤波器。仅在
    `do_resize` 设置为 `True` 时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`
    parameter in the `preprocess` method.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *可选*, 默认为 `True`) — 是否按照指定的比例 `rescale_factor` 对图像进行重新缩放。可以被
    `preprocess` 方法中的 `do_rescale` 参数覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Only has an effect if `do_rescale` is set
    to `True`. Can be overridden by the `rescale_factor` parameter in the `preprocess`
    method.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` 或 `float`, *可选*, 默认为 `1/255`) — 如果重新缩放图像，则使用的缩放因子。仅在
    `do_rescale` 设置为 `True` 时有效。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *可选*, 默认为 `True`) — 是否对图像进行归一化。可以被 `preprocess` 方法中的
    `do_normalize` 参数覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method. Can be overridden by the `image_mean` parameter
    in the `preprocess` method.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `IMAGENET_STANDARD_MEAN`)
    — 如果归一化图像，则使用的均值。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_mean` 参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method. Can be overridden by
    the `image_std` parameter in the `preprocess` method.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` 或 `List[float]`, *可选*, 默认为 `IMAGENET_STANDARD_STD`) —
    如果归一化图像，则使用的标准差。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_std` 参数覆盖。'
- en: '`do_center_crop` (`bool`, *optional*, defaults to `True`) — Whether to center
    crop the image. Can be overridden by the `do_center_crop` parameter in the `preprocess`
    method.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_center_crop` (`bool`, *可选*, 默认为 `True`) — 是否对图像进行中心裁剪。可以被 `preprocess`
    方法中的 `do_center_crop` 参数覆盖。'
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) — Whether to pad the image
    to the `(max_height, max_width)` of the images in the batch. Can be overridden
    by the `do_pad` parameter in the `preprocess` method.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *可选*, 默认为 `True`) — 是否将图像填充到批次中图像的 `(max_height, max_width)`。可以被
    `preprocess` 方法中的 `do_pad` 参数覆盖。'
- en: Constructs a BridgeTower image processor.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 BridgeTower 图像处理器。
- en: '#### `preprocess`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/image_processing_bridgetower.py#L367)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/image_processing_bridgetower.py#L367)'
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像。期望传入单个图像或图像批次，像素值范围为 0 到 255。如果传入像素值在 0 到
    1 之间的图像，请设置 `do_rescale=False`。'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *可选*, 默认为 `self.do_resize`) — 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Controls the
    size of the image after `resize`. The shortest edge of the image is resized to
    `size["shortest_edge"]` whilst preserving the aspect ratio. If the longest edge
    of this resized image is > `int(size["shortest_edge"] * (1333 / 800))`, then the
    image is resized again to make the longest edge equal to `int(size["shortest_edge"]
    * (1333 / 800))`.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *可选*, 默认为 `self.size`) — 控制 `resize` 后图像的大小。图像的最短边被调整为
    `size["shortest_edge"]`，同时保持纵横比。如果调整后图像的最长边 > `int(size["shortest_edge"] * (1333
    / 800))`，则再次调整图像大小，使最长边等于 `int(size["shortest_edge"] * (1333 / 800))`。'
- en: '`size_divisor` (`int`, *optional*, defaults to `self.size_divisor`) — The image
    is resized to a size that is a multiple of this value.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisor` (`int`, *可选*, 默认为 `self.size_divisor`) — 将图像调整为此值的倍数。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `self.resample`)
    — Resampling filter to use if resizing the image. Only has an effect if `do_resize`
    is set to `True`.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *可选*, 默认为 `self.resample`) — 如果调整图像大小，则使用的重采样滤波器。仅在
    `do_resize` 设置为 `True` 时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image values between [0 - 1].'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *可选*, 默认为 `self.do_rescale`) — 是否将图像值重新缩放到 [0 - 1] 之间。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    Rescale factor to rescale the image by if `do_rescale` is set to `True`.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *可选*, 默认为 `self.rescale_factor`) — 如果 `do_rescale`
    设置为 `True`，则用于重新缩放图像的缩放因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *可选*, 默认为 `self.do_normalize`) — 是否对图像进行归一化。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    — Image mean to normalize the image by if `do_normalize` is set to `True`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` 或 `List[float]`, *可选*, 默认为 `self.image_mean`) — 如果 `do_normalize`
    设置为 `True`，则用于归一化图像的图像均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    — Image standard deviation to normalize the image by if `do_normalize` is set
    to `True`.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std`（`float`或`List[float]`，*可选*，默认为`self.image_std`）— 如果`do_normalize`设置为`True`，用于归一化图像的图像标准差。'
- en: '`do_pad` (`bool`, *optional*, defaults to `self.do_pad`) — Whether to pad the
    image to the (max_height, max_width) in the batch. If `True`, a pixel mask is
    also created and returned.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad`（`bool`，*可选*，默认为`self.do_pad`）— 是否将图像填充到批处理中的(max_height, max_width)。如果为`True`，还会创建并返回像素掩码。'
- en: '`do_center_crop` (`bool`, *optional*, defaults to `self.do_center_crop`) —
    Whether to center crop the image. If the input size is smaller than `crop_size`
    along any edge, the image is padded with 0’s and then center cropped.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_center_crop`（`bool`，*可选*，默认为`self.do_center_crop`）— 是否对图像进行中心裁剪。如果输入尺寸小于任何边缘的`crop_size`，则图像将填充为0，然后进行中心裁剪。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或`TensorType`，*可选*）— 要返回的张量类型。可以是以下之一：'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：返回一个`np.ndarray`列表。
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW`或`''tf''`：返回一个`tf.Tensor`类型的批处理。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH`或`''pt''`：返回一个`torch.Tensor`类型的批处理。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY`或`''np''`：返回一个`np.ndarray`类型的批处理。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX`或`''jax''`：返回一个`jax.numpy.ndarray`类型的批处理。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`（`ChannelDimension`或`str`，*可选*，默认为`ChannelDimension.FIRST`）— 输出图像的通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图像以(num_channels, height, width)格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图像以(height, width, num_channels)格式。'
- en: 'Unset: Use the channel dimension format of the input image.'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：使用输入图像的通道维度格式。
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format`（`ChannelDimension`或`str`，*可选*）— 输入图像的通道维度格式。如果未设置，将从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图像以(num_channels, height, width)格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图像以(height, width, num_channels)格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"`或`ChannelDimension.NONE`：图像以(height, width)格式。'
- en: Preprocess an image or batch of images.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一张图片或一批图片。
- en: BridgeTowerProcessor
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerProcessor
- en: '### `class transformers.BridgeTowerProcessor`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/processing_bridgetower.py#L26)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/processing_bridgetower.py#L26)'
- en: '[PRE12]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` (`BridgeTowerImageProcessor`) — An instance of [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor).
    The image processor is a required input.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor`（`BridgeTowerImageProcessor`）— 一个[BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)的实例。图像处理器是必需的输入。'
- en: '`tokenizer` (`RobertaTokenizerFast`) — An instance of [‘RobertaTokenizerFast`].
    The tokenizer is a required input.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`RobertaTokenizerFast`）— 一个[‘RobertaTokenizerFast`]的实例。分词器是必需的输入。'
- en: Constructs a BridgeTower processor which wraps a Roberta tokenizer and BridgeTower
    image processor into a single processor.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个BridgeTower处理器，将一个Roberta分词器和一个BridgeTower图像处理器包装成一个处理器。
- en: '[BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    offers all the functionalities of [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    and [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast).
    See the docstring of [**call**()](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor.__call__)
    and `decode()` for more information.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)提供了[BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)和[RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)的所有功能。查看[**call**()](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor.__call__)和`decode()`的文档字符串以获取更多信息。'
- en: '#### `__call__`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/processing_bridgetower.py#L49)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/processing_bridgetower.py#L49)'
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This method uses [BridgeTowerImageProcessor.**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    method to prepare image(s) for the model, and [RobertaTokenizerFast.**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    to prepare text for the model.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用[BridgeTowerImageProcessor.**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)方法准备模型的图像，并使用[RobertaTokenizerFast.**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)准备模型的文本。
- en: Please refer to the docstring of the above two methods for more information.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请参考上述两种方法的文档字符串。
- en: BridgeTowerModel
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerModel
- en: '### `class transformers.BridgeTowerModel`'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1197)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1197)'
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: The bare BridgeTower Model transformer outputting BridgeTowerModelOutput object
    without any specific head on top. This model is a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的 BridgeTower 模型，输出 BridgeTowerModelOutput 对象，没有特定的头部在顶部。这个模型是 PyTorch `torch.nn.Module
    <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_ 的子类。将其用作常规的 PyTorch
    模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1265)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1265)'
- en: '[PRE15]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `({0})`) — Indices of input sequence
    tokens in the vocabulary. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为 `({0})`) — 词汇表中输入序列标记的索引。可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `({0})`, *optional*) — Mask
    to avoid performing attention on padding token indices. Mask values selected in
    `[0, 1]`:'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`，形状为 `({0})`，*可选*) — 避免在填充标记索引上执行注意力的掩码。掩码值在
    `[0, 1]` 中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被 `掩码` 的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被 `掩码` 的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`token_type_ids` (`torch.LongTensor` of shape `({0})`, *optional*) — Segment
    token indices to indicate first and second portions of the inputs. Indices are
    selected in `[0, 1]`:'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor`，形状为 `({0})`，*可选*) — 段标记索引，用于指示输入的第一部分和第二部分。索引在
    `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于一个 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于一个 *句子 B* 标记。[什么是标记类型 ID？](../glossary#token-type-ids)
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor).
    See [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height,
    width)`) — 像素值。可以使用 [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    获取像素值。有关详细信息，请参阅 [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor`，形状为 `(batch_size, height, width)`，*可选*) —
    避免在填充像素值上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示真实的像素（即未被 `掩码`），
- en: 0 for pixels that are padding (i.e. `masked`). `What are attention masks? <../glossary.html#attention-mask>`__
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示填充的像素（即被 `掩码`）。`什么是注意力掩码？ <../glossary.html#attention-mask>`__
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块中选择的头部失效的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `掩码`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*)
    — Optionally, instead of passing `input_ids` you can choose to directly pass an
    embedded representation. This is useful if you want more control over how to convert
    `input_ids` indices into associated vectors than the model’s internal embedding
    lookup matrix.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为 `({0}, hidden_size)`，*可选*) — 可选地，可以直接传递嵌入表示，而不是传递
    `input_ids`。如果您想要更多控制如何将 `input_ids` 索引转换为相关向量，而不是模型的内部嵌入查找矩阵。'
- en: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`,
    *optional*) — Optionally, instead of passing `pixel_values`, you can choose to
    directly pass an embedded representation. This is useful if you want more control
    over how to convert `pixel_values` into patch embeddings.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor`，形状为 `(batch_size, num_patches, hidden_size)`，*可选*)
    — 可选地，可以直接传递嵌入表示，而不是传递 `pixel_values`。如果您想要更多控制如何将 `pixel_values` 转换为补丁嵌入，这将非常有用。'
- en: '`image_token_type_idx` (`int`, *optional*) —'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_token_type_idx` (`int`，*可选*) —'
- en: The token type ids for images.
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的标记类型 ID。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`output_hidden_states` (`bool`, *optional*) — If set to `True`, hidden states
    are returned as a list containing the hidden states of text, image, and cross-modal
    components respectively. i.e. `(hidden_states_text, hidden_states_image, hidden_states_cross_modal)`
    where each element is a list of the hidden states of the corresponding modality.
    `hidden_states_txt/img` are a list of tensors corresponding to unimodal hidden
    states and `hidden_states_cross_modal` is a list of tuples containing `cross_modal_text_hidden_states`
    and `cross_modal_image_hidden_states` of each brdige layer.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 如果设置为`True`，则返回隐藏状态作为一个列表，分别包含文本、图像和跨模态组件的隐藏状态。即`(hidden_states_text,
    hidden_states_image, hidden_states_cross_modal)`，其中每个元素都是对应模态的隐藏状态列表。`hidden_states_txt/img`是对应单模态隐藏状态的张量列表，`hidden_states_cross_modal`是一个包含每个桥接层的`cross_modal_text_hidden_states`和`cross_modal_image_hidden_states`的元组列表。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    are currently not supported.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size,)`，*可选*) — 目前不支持标签。'
- en: Returns
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.bridgetower.modeling_bridgetower.BridgeTowerModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.bridgetower.modeling_bridgetower.BridgeTowerModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.bridgetower.modeling_bridgetower.BridgeTowerModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    and inputs.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.bridgetower.modeling_bridgetower.BridgeTowerModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)）和输入的不同元素。
- en: '`text_features` (`torch.FloatTensor` of shape `(batch_size, text_sequence_length,
    hidden_size)`) — Sequence of hidden-states at the text output of the last layer
    of the model.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_features` (`torch.FloatTensor`，形状为`(batch_size, text_sequence_length,
    hidden_size)`) — 模型最后一层文本输出的隐藏状态序列。'
- en: '`image_features` (`torch.FloatTensor` of shape `(batch_size, image_sequence_length,
    hidden_size)`) — Sequence of hidden-states at the image output of the last layer
    of the model.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_features` (`torch.FloatTensor`，形状为`(batch_size, image_sequence_length,
    hidden_size)`) — 模型最后一层图像输出的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size x 2)`)
    — Concatenation of last layer hidden-state of the first token of the text and
    image sequence (classification token), respectively, after further processing
    through layers used for auxiliary pretraining tasks.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor`，形状为`(batch_size, hidden_size x 2)`) —
    文本和图像序列的第一个标记（分类标记）的最后一层隐藏状态的连接，分别经过用于辅助预训练任务的层进一步处理。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出加上每层的输出）。模型在每一层输出的隐藏状态以及可选的初始嵌入输出。'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    forward method, overrides the `__call__` special method.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Examples:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: BridgeTowerForContrastiveLearning
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerForContrastiveLearning
- en: '### `class transformers.BridgeTowerForContrastiveLearning`'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerForContrastiveLearning`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1761)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1761)'
- en: '[PRE17]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: BridgeTower Model with a image-text contrastive head on top computing image-text
    contrastive loss.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部具有图像文本对比头部的BridgeTower模型，计算图像文本对比损失。
- en: This model is a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch的`torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1781)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1781)'
- en: '[PRE18]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `({0})`) — Indices of input sequence
    tokens in the vocabulary. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`({0})`) — 词汇表中输入序列标记的索引。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)获取详细信息。[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `({0})`, *optional*) — Mask
    to avoid performing attention on padding token indices. Mask values selected in
    `[0, 1]`:'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`，形状为`({0})`，*optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0,
    1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示`未被遮罩`的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示`被遮罩`的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`token_type_ids` (`torch.LongTensor` of shape `({0})`, *optional*) — Segment
    token indices to indicate first and second portions of the inputs. Indices are
    selected in `[0, 1]`:'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor`，形状为`({0})`，*optional*) — 段标记索引，指示输入的第一部分和第二部分。索引选择在`[0,
    1]`之间：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于*句子B*标记。[什么是标记类型ID？](../glossary#token-type-ids)
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor).
    See [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。可以使用[BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)获取像素值。查看[BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)获取详细信息。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor`，形状为`(batch_size, height, width)`，*optional*)
    — 用于避免在填充像素值上执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示真实像素（即`未被遮罩`），
- en: 0 for pixels that are padding (i.e. `masked`). `What are attention masks? <../glossary.html#attention-mask>`__
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示填充像素（即`被遮罩`）。`什么是注意力掩码？<../glossary.html#attention-mask>`__
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*optional*)
    — 用于使自注意力模块中选择的头部失效的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部`未被遮罩`，
- en: 0 indicates the head is `masked`.
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部`被遮罩`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*)
    — Optionally, instead of passing `input_ids` you can choose to directly pass an
    embedded representation. This is useful if you want more control over how to convert
    `input_ids` indices into associated vectors than the model’s internal embedding
    lookup matrix.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为`({0}, hidden_size)`，*optional*) —
    可选地，可以直接传递嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将`input_ids`索引转换为与模型内部嵌入查找矩阵相关联的向量，则这很有用。'
- en: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`,
    *optional*) — Optionally, instead of passing `pixel_values`, you can choose to
    directly pass an embedded representation. This is useful if you want more control
    over how to convert `pixel_values` into patch embeddings.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor`，形状为`(batch_size, num_patches, hidden_size)`，*optional*)
    — 可选地，可以直接传递嵌入表示，而不是传递`pixel_values`。如果您想要更多控制如何将`pixel_values`转换为补丁嵌入，则这很有用。'
- en: '`image_token_type_idx` (`int`, *optional*) —'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_token_type_idx` (`int`, *optional*) —'
- en: The token type ids for images.
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的标记类型ID。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`return_loss` (`bool`, *optional*) — Whether or not to return the contrastive
    loss.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_loss` (`bool`, *可选*) — 是否返回对比损失。'
- en: Returns
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.bridgetower.modeling_bridgetower.BridgeTowerContrastiveOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.bridgetower.modeling_bridgetower.BridgeTowerContrastiveOutput`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.bridgetower.modeling_bridgetower.BridgeTowerContrastiveOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    and inputs.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `transformers.models.bridgetower.modeling_bridgetower.BridgeTowerContrastiveOutput`
    或一个 `torch.FloatTensor` 元组（如果传递 `return_dict=False` 或 `config.return_dict=False`
    或 `config.return_dict=False`）包含根据配置（[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `return_loss`
    is `True` — Image-text contrastive loss.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为 `(1,)`，*可选*，当 `return_loss` 为 `True` 时返回） —
    图像-文本对比损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax 前每个词汇标记的分数）。'
- en: '`text_embeds` (`torch.FloatTensor)`, *optional*, returned when model is initialized
    with `with_projection=True`) — The text embeddings obtained by applying the projection
    layer to the pooler_output.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_embeds` (`torch.FloatTensor)`，*可选*，当使用 `with_projection=True` 初始化模型时返回）
    — 通过将投影层应用于 pooler_output 获得的文本嵌入。'
- en: '`image_embeds` (`torch.FloatTensor)`, *optional*, returned when model is initialized
    with `with_projection=True`) — The image embeddings obtained by applying the projection
    layer to the pooler_output.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor)`，*可选*，当使用 `with_projection=True` 初始化模型时返回）
    — 通过将投影层应用于 pooler_output 获得的图像嵌入。'
- en: '`cross_embeds` (`torch.FloatTensor)`, *optional*, returned when model is initialized
    with `with_projection=True`) — The text-image cross-modal embeddings obtained
    by applying the projection layer to the pooler_output.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_embeds` (`torch.FloatTensor)`，*可选*，当使用 `with_projection=True` 初始化模型时返回）
    — 通过将投影层应用于 pooler_output 获得的文本-图像跨模态嵌入。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递 `output_hidden_states=True`
    或 `config.output_hidden_states=True` 时返回） — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组。模型在每个层的输出的隐藏状态加上可选的初始嵌入输出。'
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递 `output_attentions=True`
    或 `config.output_attentions=True` 时返回） — 形状为 `(batch_size, num_heads, sequence_length,
    sequence_length)` 的 `torch.FloatTensor` 元组。'
- en: The [BridgeTowerForContrastiveLearning](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForContrastiveLearning)
    forward method, overrides the `__call__` special method.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '[BridgeTowerForContrastiveLearning](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForContrastiveLearning)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在之后调用 `Module` 实例而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE19]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: BridgeTowerForMaskedLM
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerForMaskedLM
- en: '### `class transformers.BridgeTowerForMaskedLM`'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerForMaskedLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1541)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1541)'
- en: '[PRE20]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: BridgeTower Model with a language modeling head on top as done during pretraining.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: BridgeTower 模型在预训练期间在顶部具有语言建模头。
- en: This model is a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是 PyTorch 的 `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_
    子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1565)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1565)'
- en: '[PRE21]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Indices can be obtained using
    [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入
    ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被遮蔽的标记，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被遮蔽的标记。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 段落标记索引，用于指示输入的第一部分和第二部分。索引在 `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 的标记，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 的标记。[什么是标记类型 ID？](../glossary#token-type-ids)
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor).
    See [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。可以使用 [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    获取像素值。有关详细信息，请参阅 [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — 用于避免在填充像素值上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示真实的像素（即未被遮蔽），
- en: 0 for pixels that are padding (i.e. `masked`). `What are attention masks? <../glossary.html#attention-mask>`__
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示填充的像素（即 `masked`）。`什么是注意力掩码？<../glossary.html#attention-mask>`__
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块的选定头部失效的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被遮蔽。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将
    `input_ids` 索引转换为相关向量，而不是模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`,
    *optional*) — Optionally, instead of passing `pixel_values`, you can choose to
    directly pass an embedded representation. This is useful if you want more control
    over how to convert `pixel_values` into patch embeddings.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`,
    *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递 `pixel_values`。如果您想要更多控制如何将 `pixel_values`
    转换为补丁嵌入，这将非常有用。'
- en: '`image_token_type_idx` (`int`, *optional*) —'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_token_type_idx` (`int`, *optional*) —'
- en: The token type ids for images.
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的标记类型 ID。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回的张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是一个普通的元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 用于计算掩码语言建模损失的标签。索引应在`[-100,
    0, ..., config.vocab_size]`内（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`中的标记。'
- en: Returns
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    and inputs.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包括各种元素，取决于配置（[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Masked language modeling (MLM) loss.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 掩码语言建模（MLM）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）—
    语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有一个嵌入层，+
    一个用于每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [BridgeTowerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForMaskedLM)
    forward method, overrides the `__call__` special method.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[BridgeTowerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForMaskedLM)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE22]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: BridgeTowerForImageAndTextRetrieval
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BridgeTowerForImageAndTextRetrieval
- en: '### `class transformers.BridgeTowerForImageAndTextRetrieval`'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BridgeTowerForImageAndTextRetrieval`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1649)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1649)'
- en: '[PRE23]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: BridgeTower Model transformer with a classifier head on top (a linear layer
    on top of the final hidden state of the [CLS] token) for image-to-text matching.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: BridgeTower模型变压器，顶部带有分类器头（在[CLS]标记的最终隐藏状态之上的线性层），用于图像到文本匹配。
- en: This model is a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1667)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bridgetower/modeling_bridgetower.py#L1667)'
- en: '[PRE24]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `({0})`) — Indices of input sequence
    tokens in the vocabulary. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `({0})`) — 词汇表中输入序列标记的索引。 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。 有关详细信息，请参见 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
    [什么是输入 ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `({0})`, *optional*) — Mask
    to avoid performing attention on padding token indices. Mask values selected in
    `[0, 1]`:'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `({0})`, *optional*) — 用于避免在填充标记索引上执行注意力的掩码。
    选择的掩码值在 `[0, 1]` 之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 1 的标记是 `not masked`，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 0 的标记是 `masked`。 [什么是注意力掩码？](../glossary#attention-mask)
- en: '`token_type_ids` (`torch.LongTensor` of shape `({0})`, *optional*) — Segment
    token indices to indicate first and second portions of the inputs. Indices are
    selected in `[0, 1]`:'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `({0})`, *optional*) — 段标记索引，指示输入的第一部分和第二部分。
    索引在 `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token. [What are token type IDs?](../glossary#token-type-ids)
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。 [什么是标记类型 ID？](../glossary#token-type-ids)
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor).
    See [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。 可以使用 [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    获取像素值。 有关详细信息，请参见 [BridgeTowerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — 用于避免在填充像素值上执行注意力的掩码。 选择的掩码值在 `[0, 1]` 之间：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 1 的像素是真实的（即 `not masked`），
- en: 0 for pixels that are padding (i.e. `masked`). `What are attention masks? <../glossary.html#attention-mask>`__
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充像素的值为 0（即 `masked`）。 `什么是注意力掩码？ <../glossary.html#attention-mask>`__
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — 用于使自注意力模块的选定头部失效的掩码。 选择的掩码值在 `[0, 1]` 之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 0 表示头部被 `masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*)
    — Optionally, instead of passing `input_ids` you can choose to directly pass an
    embedded representation. This is useful if you want more control over how to convert
    `input_ids` indices into associated vectors than the model’s internal embedding
    lookup matrix.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*)
    — 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。 如果您想要更多控制如何将 `input_ids` 索引转换为相关向量，而不是模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`,
    *optional*) — Optionally, instead of passing `pixel_values`, you can choose to
    directly pass an embedded representation. This is useful if you want more control
    over how to convert `pixel_values` into patch embeddings.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`,
    *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递 `pixel_values`。 如果您想要更多控制如何将 `pixel_values`
    转换为补丁嵌入，这将非常有用。'
- en: '`image_token_type_idx` (`int`, *optional*) —'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_token_type_idx` (`int`, *optional*) —'
- en: The token type ids for images.
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的标记类型 ID。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。 有关更多详细信息，请参见返回张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。 有关更多详细信息，请参见返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, 1)`, *optional*) — Labels
    for computing the image-text matching loss. 0 means the pairs don’t match and
    1 means they match. The pairs with 0 will be skipped for calculation.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, 1)`, *optional*) — 用于计算图像文本匹配损失的标签。
    0 表示配对不匹配，1 表示匹配。 标签为 0 的配对将被跳过计算。'
- en: Returns
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig))
    and inputs.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含各种元素，取决于配置（[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回） - 分类（如果config.num_labels==1则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, config.num_labels)`的`torch.FloatTensor`） - 分类（如果config.num_labels==1则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    - 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    - 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [BridgeTowerForImageAndTextRetrieval](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForImageAndTextRetrieval)
    forward method, overrides the `__call__` special method.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '[BridgeTowerForImageAndTextRetrieval](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerForImageAndTextRetrieval)的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE25]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
