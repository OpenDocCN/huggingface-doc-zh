- en: DDPMScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DDPMScheduler
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/ddpm](https://huggingface.co/docs/diffusers/api/schedulers/ddpm)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/diffusers/api/schedulers/ddpm](https://huggingface.co/docs/diffusers/api/schedulers/ddpm)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Denoising Diffusion Probabilistic Models](https://huggingface.co/papers/2006.11239)
    (DDPM) by Jonathan Ho, Ajay Jain and Pieter Abbeel proposes a diffusion based
    model of the same name. In the context of the ğŸ¤— Diffusers library, DDPM refers
    to the discrete denoising scheduler from the paper as well as the pipeline.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹](https://huggingface.co/papers/2006.11239)ï¼ˆDDPMï¼‰ç”± Jonathan Hoã€Ajay
    Jain å’Œ Pieter Abbeel æå‡ºäº†åŒåçš„åŸºäºæ‰©æ•£çš„æ¨¡å‹ã€‚åœ¨ ğŸ¤— Diffusers åº“çš„ä¸Šä¸‹æ–‡ä¸­ï¼ŒDDPM æŒ‡çš„æ˜¯è®ºæ–‡ä¸­çš„ç¦»æ•£å»å™ªè°ƒåº¦ç¨‹åºä»¥åŠæµæ°´çº¿ã€‚'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*We present high quality image synthesis results using diffusion probabilistic
    models, a class of latent variable models inspired by considerations from nonequilibrium
    thermodynamics. Our best results are obtained by training on a weighted variational
    bound designed according to a novel connection between diffusion probabilistic
    models and denoising score matching with Langevin dynamics, and our models naturally
    admit a progressive lossy decompression scheme that can be interpreted as a generalization
    of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an
    Inception score of 9.46 and a state-of-the-art FID score of 3.17\. On 256x256
    LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is
    available at [this https URL](https://github.com/hojonathanho/diffusion).*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘ä»¬ä½¿ç”¨æ‰©æ•£æ¦‚ç‡æ¨¡å‹è¿›è¡Œé«˜è´¨é‡å›¾åƒåˆæˆï¼Œè¿™æ˜¯ä¸€ç±»å—éå¹³è¡¡çƒ­åŠ›å­¦è€ƒè™‘å¯å‘çš„æ½œå˜é‡æ¨¡å‹ã€‚æˆ‘ä»¬é€šè¿‡æ ¹æ®æ‰©æ•£æ¦‚ç‡æ¨¡å‹å’Œä½¿ç”¨ Langevin åŠ¨åŠ›å­¦è¿›è¡Œå»å™ªå¾—åˆ†åŒ¹é…ä¹‹é—´çš„æ–°é¢–è¿æ¥è®¾è®¡çš„åŠ æƒå˜åˆ†ç•Œæ¥è®­ç»ƒï¼Œè·å¾—äº†æœ€ä½³ç»“æœï¼Œæˆ‘ä»¬çš„æ¨¡å‹è‡ªç„¶åœ°é‡‡ç”¨äº†ä¸€ç§æ¸è¿›çš„æœ‰æŸè§£å‹ç¼©æ–¹æ¡ˆï¼Œå¯ä»¥è§£é‡Šä¸ºè‡ªå›å½’è§£ç çš„ä¸€èˆ¬åŒ–ã€‚åœ¨æ— æ¡ä»¶çš„
    CIFAR10 æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬è·å¾—äº† 9.46 çš„ Inception åˆ†æ•°å’Œ 3.17 çš„æœ€æ–° FID åˆ†æ•°ã€‚åœ¨ 256x256 LSUN ä¸Šï¼Œæˆ‘ä»¬è·å¾—äº†ç±»ä¼¼äº
    ProgressiveGAN çš„æ ·æœ¬è´¨é‡ã€‚æˆ‘ä»¬çš„å®ç°å¯åœ¨ [æ­¤ https URL](https://github.com/hojonathanho/diffusion)
    ä¸Šæ‰¾åˆ°ã€‚*'
- en: DDPMScheduler
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DDPMScheduler
- en: '### `class diffusers.DDPMScheduler`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.DDPMScheduler`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L129)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L129)'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`num_train_timesteps` (`int`, defaults to 1000) â€” The number of diffusion steps
    to train the model.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_timesteps` (`int`, é»˜è®¤ä¸º 1000) â€” è®­ç»ƒæ¨¡å‹çš„æ‰©æ•£æ­¥æ•°ã€‚'
- en: '`beta_start` (`float`, defaults to 0.0001) â€” The starting `beta` value of inference.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_start` (`float`, é»˜è®¤ä¸º 0.0001) â€” æ¨æ–­çš„èµ·å§‹ `beta` å€¼ã€‚'
- en: '`beta_end` (`float`, defaults to 0.02) â€” The final `beta` value.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_end` (`float`, é»˜è®¤ä¸º 0.02) â€” æœ€ç»ˆçš„ `beta` å€¼ã€‚'
- en: '`beta_schedule` (`str`, defaults to `"linear"`) â€” The beta schedule, a mapping
    from a beta range to a sequence of betas for stepping the model. Choose from `linear`,
    `scaled_linear`, or `squaredcos_cap_v2`.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_schedule` (`str`, é»˜è®¤ä¸º `"linear"`) â€” beta è®¡åˆ’ï¼Œä» beta èŒƒå›´åˆ°ç”¨äºæ­¥è¿›æ¨¡å‹çš„ä¸€ç³»åˆ— beta
    çš„æ˜ å°„ã€‚å¯é€‰æ‹© `linear`ã€`scaled_linear` æˆ– `squaredcos_cap_v2`ã€‚'
- en: '`trained_betas` (`np.ndarray`, *optional*) â€” An array of betas to pass directly
    to the constructor without using `beta_start` and `beta_end`.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trained_betas` (`np.ndarray`, *å¯é€‰*) â€” ä¸€ç»„ beta æ•°ç»„ï¼Œç›´æ¥ä¼ é€’ç»™æ„é€ å‡½æ•°ï¼Œè€Œä¸ä½¿ç”¨ `beta_start`
    å’Œ `beta_end`ã€‚'
- en: '`variance_type` (`str`, defaults to `"fixed_small"`) â€” Clip the variance when
    adding noise to the denoised sample. Choose from `fixed_small`, `fixed_small_log`,
    `fixed_large`, `fixed_large_log`, `learned` or `learned_range`.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variance_type` (`str`, é»˜è®¤ä¸º `"fixed_small"`) â€” åœ¨å‘å»å™ªæ ·æœ¬æ·»åŠ å™ªå£°æ—¶å‰ªåˆ‡æ–¹å·®ã€‚å¯é€‰æ‹© `fixed_small`ã€`fixed_small_log`ã€`fixed_large`ã€`fixed_large_log`ã€`learned`
    æˆ– `learned_range`ã€‚'
- en: '`clip_sample` (`bool`, defaults to `True`) â€” Clip the predicted sample for
    numerical stability.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_sample` (`bool`, é»˜è®¤ä¸º `True`) â€” ä¸ºäº†æ•°å€¼ç¨³å®šæ€§è€Œå‰ªåˆ‡é¢„æµ‹æ ·æœ¬ã€‚'
- en: '`clip_sample_range` (`float`, defaults to 1.0) â€” The maximum magnitude for
    sample clipping. Valid only when `clip_sample=True`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_sample_range` (`float`, é»˜è®¤ä¸º 1.0) â€” æ ·æœ¬å‰ªåˆ‡çš„æœ€å¤§å¹…åº¦ã€‚ä»…åœ¨ `clip_sample=True` æ—¶æœ‰æ•ˆã€‚'
- en: '`prediction_type` (`str`, defaults to `epsilon`, *optional*) â€” Prediction type
    of the scheduler function; can be `epsilon` (predicts the noise of the diffusion
    process), `sample` (directly predicts the noisy sample`) or` v_prediction` (see
    section 2.4 of [Imagen Video](https://imagen.research.google/video/paper.pdf)
    paper).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_type` (`str`, é»˜è®¤ä¸º `epsilon`, *å¯é€‰*) â€” è°ƒåº¦å™¨å‡½æ•°çš„é¢„æµ‹ç±»å‹ï¼›å¯ä»¥æ˜¯ `epsilon`ï¼ˆé¢„æµ‹æ‰©æ•£è¿‡ç¨‹çš„å™ªå£°ï¼‰ã€`sample`ï¼ˆç›´æ¥é¢„æµ‹æœ‰å™ªå£°çš„æ ·æœ¬ï¼‰æˆ–
    `v_prediction`ï¼ˆå‚è§[Imagen Video](https://imagen.research.google/video/paper.pdf)è®ºæ–‡çš„ç¬¬2.4èŠ‚ï¼‰ã€‚'
- en: '`thresholding` (`bool`, defaults to `False`) â€” Whether to use the â€œdynamic
    thresholdingâ€ method. This is unsuitable for latent-space diffusion models such
    as Stable Diffusion.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresholding` (`bool`, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä½¿ç”¨â€œåŠ¨æ€é˜ˆå€¼â€æ–¹æ³•ã€‚è¿™ä¸é€‚ç”¨äºç¨³å®šæ‰©æ•£ç­‰æ½œç©ºé—´æ‰©æ•£æ¨¡å‹ã€‚'
- en: '`dynamic_thresholding_ratio` (`float`, defaults to 0.995) â€” The ratio for the
    dynamic thresholding method. Valid only when `thresholding=True`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dynamic_thresholding_ratio` (`float`, é»˜è®¤ä¸º 0.995) â€” åŠ¨æ€é˜ˆå€¼æ–¹æ³•çš„æ¯”ç‡ã€‚ä»…åœ¨ `thresholding=True`
    æ—¶æœ‰æ•ˆã€‚'
- en: '`sample_max_value` (`float`, defaults to 1.0) â€” The threshold value for dynamic
    thresholding. Valid only when `thresholding=True`.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_max_value` (`float`, é»˜è®¤ä¸º 1.0) â€” åŠ¨æ€é˜ˆå€¼çš„é˜ˆå€¼å€¼ã€‚ä»…åœ¨ `thresholding=True` æ—¶æœ‰æ•ˆã€‚'
- en: '`timestep_spacing` (`str`, defaults to `"leading"`) â€” The way the timesteps
    should be scaled. Refer to Table 2 of the [Common Diffusion Noise Schedules and
    Sample Steps are Flawed](https://huggingface.co/papers/2305.08891) for more information.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep_spacing` (`str`, é»˜è®¤ä¸º `"leading"`) â€” æ—¶é—´æ­¥é•¿åº”è¯¥å¦‚ä½•ç¼©æ”¾ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ[Common
    Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)çš„è¡¨2ã€‚'
- en: '`steps_offset` (`int`, defaults to 0) â€” An offset added to the inference steps.
    You can use a combination of `offset=1` and `set_alpha_to_one=False` to make the
    last step use step 0 for the previous alpha product like in Stable Diffusion.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`steps_offset` (`int`, é»˜è®¤ä¸º 0) â€” æ·»åŠ åˆ°æ¨æ–­æ­¥éª¤çš„åç§»é‡ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `offset=1` å’Œ `set_alpha_to_one=False`
    çš„ç»„åˆï¼Œä½¿æœ€åä¸€æ­¥ä½¿ç”¨æ­¥éª¤ 0 ç”¨äºå…ˆå‰ alpha äº§å“ï¼Œå°±åƒåœ¨ Stable Diffusion ä¸­ä¸€æ ·ã€‚'
- en: '`rescale_betas_zero_snr` (`bool`, defaults to `False`) â€” Whether to rescale
    the betas to have zero terminal SNR. This enables the model to generate very bright
    and dark samples instead of limiting it to samples with medium brightness. Loosely
    related to [`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_betas_zero_snr`ï¼ˆé»˜è®¤ä¸º`False`çš„`bool`ï¼‰- æ˜¯å¦é‡æ–°ç¼©æ”¾betaä»¥ä½¿ç»ˆç«¯SNRä¸ºé›¶ã€‚è¿™ä½¿æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆéå¸¸æ˜äº®å’Œé»‘æš—çš„æ ·æœ¬ï¼Œè€Œä¸ä»…é™äºå…·æœ‰ä¸­ç­‰äº®åº¦çš„æ ·æœ¬ã€‚ä¸[`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506)
    looselyç›¸å…³ã€‚'
- en: '`DDPMScheduler` explores the connections between denoising score matching and
    Langevin dynamics sampling.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`DDPMScheduler`æ¢ç´¢å»å™ªå¾—åˆ†åŒ¹é…å’Œæœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦é‡‡æ ·ä¹‹é—´çš„è”ç³»ã€‚'
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)å’Œ[ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰è°ƒåº¦å™¨å®ç°çš„é€šç”¨æ–¹æ³•ï¼Œä¾‹å¦‚åŠ è½½å’Œä¿å­˜ã€‚
- en: '#### `scale_model_input`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `scale_model_input`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L236)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L236)'
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`sample` (`torch.FloatTensor`) â€” The input sample.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`ï¼ˆ`torch.FloatTensor`ï¼‰- è¾“å…¥æ ·æœ¬ã€‚'
- en: '`timestep` (`int`, *optional*) â€” The current timestep in the diffusion chain.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼‰- æ‰©æ•£é“¾ä¸­çš„å½“å‰æ—¶é—´æ­¥ã€‚'
- en: Returns
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`torch.FloatTensor`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: A scaled input sample.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç»è¿‡ç¼©æ”¾çš„è¾“å…¥æ ·æœ¬ã€‚
- en: Ensures interchangeability with schedulers that need to scale the denoising
    model input depending on the current timestep.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿ä¸éœ€è¦æ ¹æ®å½“å‰æ—¶é—´æ­¥ç¼©æ”¾å»å™ªæ¨¡å‹è¾“å…¥çš„è°ƒåº¦å™¨å¯äº’æ¢ã€‚
- en: '#### `set_timesteps`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_timesteps`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L253)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L253)'
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`num_inference_steps` (`int`) â€” The number of diffusion steps used when generating
    samples with a pre-trained model. If used, `timesteps` must be `None`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`ï¼ˆ`int`ï¼‰- ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆæ ·æœ¬æ—¶ä½¿ç”¨çš„æ‰©æ•£æ­¥æ•°ã€‚å¦‚æœä½¿ç”¨ï¼Œåˆ™`timesteps`å¿…é¡»ä¸º`None`ã€‚'
- en: '`device` (`str` or `torch.device`, *optional*) â€” The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`ï¼ˆ`str`æˆ–`torch.device`ï¼Œ*å¯é€‰*ï¼‰- æ—¶é—´æ­¥åº”ç§»åŠ¨åˆ°çš„è®¾å¤‡ã€‚å¦‚æœä¸º`None`ï¼Œåˆ™ä¸ç§»åŠ¨æ—¶é—´æ­¥ã€‚'
- en: '`timesteps` (`List[int]`, *optional*) â€” Custom timesteps used to support arbitrary
    spacing between timesteps. If `None`, then the default timestep spacing strategy
    of equal spacing between timesteps is used. If `timesteps` is passed, `num_inference_steps`
    must be `None`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps`ï¼ˆ`List[int]`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºæ”¯æŒæ—¶é—´æ­¥ä¹‹é—´ä»»æ„é—´è·çš„è‡ªå®šä¹‰æ—¶é—´æ­¥ã€‚å¦‚æœä¸º`None`ï¼Œåˆ™ä½¿ç”¨æ—¶é—´æ­¥ä¹‹é—´ç­‰è·ç¦»çš„é»˜è®¤æ—¶é—´æ­¥é—´è·ç­–ç•¥ã€‚å¦‚æœä¼ é€’äº†`timesteps`ï¼Œåˆ™`num_inference_steps`å¿…é¡»ä¸º`None`ã€‚'
- en: Sets the discrete timesteps used for the diffusion chain (to be run before inference).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®ç”¨äºæ‰©æ•£é“¾çš„ç¦»æ•£æ—¶é—´æ­¥ï¼ˆåœ¨æ¨ç†ä¹‹å‰è¿è¡Œï¼‰ã€‚
- en: '#### `step`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L401)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L401)'
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model_output` (`torch.FloatTensor`) â€” The direct output from learned diffusion
    model.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_output`ï¼ˆ`torch.FloatTensor`ï¼‰- ä»å­¦ä¹ æ‰©æ•£æ¨¡å‹çš„ç›´æ¥è¾“å‡ºã€‚'
- en: '`timestep` (`float`) â€” The current discrete timestep in the diffusion chain.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep`ï¼ˆ`float`ï¼‰- æ‰©æ•£é“¾ä¸­çš„å½“å‰ç¦»æ•£æ—¶é—´æ­¥ã€‚'
- en: '`sample` (`torch.FloatTensor`) â€” A current instance of a sample created by
    the diffusion process.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`ï¼ˆ`torch.FloatTensor`ï¼‰- ç”±æ‰©æ•£è¿‡ç¨‹åˆ›å»ºçš„æ ·æœ¬çš„å½“å‰å®ä¾‹ã€‚'
- en: '`generator` (`torch.Generator`, *optional*) â€” A random number generator.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`ï¼ˆ`torch.Generator`ï¼Œ*å¯é€‰*ï¼‰- éšæœºæ•°ç”Ÿæˆå™¨ã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    or `tuple`.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰- æ˜¯å¦è¿”å›[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)æˆ–`tuple`ã€‚'
- en: Returns
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    or `tuple`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)æˆ–`tuple`'
- en: If return_dict is `True`, [DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ`return_dict`ä¸º`True`ï¼Œåˆ™è¿”å›[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ªå…ƒç»„ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ ·æœ¬å¼ é‡ã€‚
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åè½¬SDEé¢„æµ‹å‰ä¸€ä¸ªæ—¶é—´æ­¥çš„æ ·æœ¬ã€‚æ­¤å‡½æ•°ä»å­¦ä¹ æ¨¡å‹è¾“å‡ºï¼ˆé€šå¸¸æ˜¯é¢„æµ‹çš„å™ªå£°ï¼‰ä¼ æ’­æ‰©æ•£è¿‡ç¨‹ã€‚
- en: DDPMSchedulerOutput
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DDPMSchedulerOutput
- en: '### `class diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L30)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L30)'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prev_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` for images) â€” Computed sample `(x_{t-1})` of previous timestep. `prev_sample`
    should be used as next model input in the denoising loop.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prev_sample`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`ï¼ˆbatch_sizeï¼Œnum_channelsï¼Œheightï¼Œwidthï¼‰`ï¼Œç”¨äºå›¾åƒï¼‰-
    ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„è®¡ç®—æ ·æœ¬`ï¼ˆx_{t-1}ï¼‰`ã€‚`prev_sample`åº”è¯¥åœ¨å»å™ªå¾ªç¯ä¸­ä½œä¸ºä¸‹ä¸€ä¸ªæ¨¡å‹è¾“å…¥ä½¿ç”¨ã€‚'
- en: '`pred_original_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)` for images) â€” The predicted denoised sample `(x_{0})` based on
    the model output from the current timestep. `pred_original_sample` can be used
    to preview progress or for guidance.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pred_original_sample`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height,
    width)`ï¼Œç”¨äºå›¾åƒï¼‰- åŸºäºå½“å‰æ—¶é—´æ­¥çš„æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹å»å™ªæ ·æœ¬`(x_{0})`ã€‚`pred_original_sample`å¯ç”¨äºé¢„è§ˆè¿›å±•æˆ–æŒ‡å¯¼ã€‚'
- en: Output class for the schedulerâ€™s `step` function output.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒåº¦ç¨‹åºçš„`step`å‡½æ•°è¾“å‡ºçš„è¾“å‡ºç±»ã€‚
