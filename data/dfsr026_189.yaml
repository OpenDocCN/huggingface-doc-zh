- en: DDPMScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DDPMScheduler
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/ddpm](https://huggingface.co/docs/diffusers/api/schedulers/ddpm)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/api/schedulers/ddpm](https://huggingface.co/docs/diffusers/api/schedulers/ddpm)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Denoising Diffusion Probabilistic Models](https://huggingface.co/papers/2006.11239)
    (DDPM) by Jonathan Ho, Ajay Jain and Pieter Abbeel proposes a diffusion based
    model of the same name. In the context of the 🤗 Diffusers library, DDPM refers
    to the discrete denoising scheduler from the paper as well as the pipeline.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[去噪扩散概率模型](https://huggingface.co/papers/2006.11239)（DDPM）由 Jonathan Ho、Ajay
    Jain 和 Pieter Abbeel 提出了同名的基于扩散的模型。在 🤗 Diffusers 库的上下文中，DDPM 指的是论文中的离散去噪调度程序以及流水线。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We present high quality image synthesis results using diffusion probabilistic
    models, a class of latent variable models inspired by considerations from nonequilibrium
    thermodynamics. Our best results are obtained by training on a weighted variational
    bound designed according to a novel connection between diffusion probabilistic
    models and denoising score matching with Langevin dynamics, and our models naturally
    admit a progressive lossy decompression scheme that can be interpreted as a generalization
    of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an
    Inception score of 9.46 and a state-of-the-art FID score of 3.17\. On 256x256
    LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is
    available at [this https URL](https://github.com/hojonathanho/diffusion).*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们使用扩散概率模型进行高质量图像合成，这是一类受非平衡热力学考虑启发的潜变量模型。我们通过根据扩散概率模型和使用 Langevin 动力学进行去噪得分匹配之间的新颖连接设计的加权变分界来训练，获得了最佳结果，我们的模型自然地采用了一种渐进的有损解压缩方案，可以解释为自回归解码的一般化。在无条件的
    CIFAR10 数据集上，我们获得了 9.46 的 Inception 分数和 3.17 的最新 FID 分数。在 256x256 LSUN 上，我们获得了类似于
    ProgressiveGAN 的样本质量。我们的实现可在 [此 https URL](https://github.com/hojonathanho/diffusion)
    上找到。*'
- en: DDPMScheduler
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DDPMScheduler
- en: '### `class diffusers.DDPMScheduler`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.DDPMScheduler`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L129)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L129)'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_train_timesteps` (`int`, defaults to 1000) — The number of diffusion steps
    to train the model.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_timesteps` (`int`, 默认为 1000) — 训练模型的扩散步数。'
- en: '`beta_start` (`float`, defaults to 0.0001) — The starting `beta` value of inference.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_start` (`float`, 默认为 0.0001) — 推断的起始 `beta` 值。'
- en: '`beta_end` (`float`, defaults to 0.02) — The final `beta` value.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_end` (`float`, 默认为 0.02) — 最终的 `beta` 值。'
- en: '`beta_schedule` (`str`, defaults to `"linear"`) — The beta schedule, a mapping
    from a beta range to a sequence of betas for stepping the model. Choose from `linear`,
    `scaled_linear`, or `squaredcos_cap_v2`.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_schedule` (`str`, 默认为 `"linear"`) — beta 计划，从 beta 范围到用于步进模型的一系列 beta
    的映射。可选择 `linear`、`scaled_linear` 或 `squaredcos_cap_v2`。'
- en: '`trained_betas` (`np.ndarray`, *optional*) — An array of betas to pass directly
    to the constructor without using `beta_start` and `beta_end`.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trained_betas` (`np.ndarray`, *可选*) — 一组 beta 数组，直接传递给构造函数，而不使用 `beta_start`
    和 `beta_end`。'
- en: '`variance_type` (`str`, defaults to `"fixed_small"`) — Clip the variance when
    adding noise to the denoised sample. Choose from `fixed_small`, `fixed_small_log`,
    `fixed_large`, `fixed_large_log`, `learned` or `learned_range`.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variance_type` (`str`, 默认为 `"fixed_small"`) — 在向去噪样本添加噪声时剪切方差。可选择 `fixed_small`、`fixed_small_log`、`fixed_large`、`fixed_large_log`、`learned`
    或 `learned_range`。'
- en: '`clip_sample` (`bool`, defaults to `True`) — Clip the predicted sample for
    numerical stability.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_sample` (`bool`, 默认为 `True`) — 为了数值稳定性而剪切预测样本。'
- en: '`clip_sample_range` (`float`, defaults to 1.0) — The maximum magnitude for
    sample clipping. Valid only when `clip_sample=True`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_sample_range` (`float`, 默认为 1.0) — 样本剪切的最大幅度。仅在 `clip_sample=True` 时有效。'
- en: '`prediction_type` (`str`, defaults to `epsilon`, *optional*) — Prediction type
    of the scheduler function; can be `epsilon` (predicts the noise of the diffusion
    process), `sample` (directly predicts the noisy sample`) or` v_prediction` (see
    section 2.4 of [Imagen Video](https://imagen.research.google/video/paper.pdf)
    paper).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_type` (`str`, 默认为 `epsilon`, *可选*) — 调度器函数的预测类型；可以是 `epsilon`（预测扩散过程的噪声）、`sample`（直接预测有噪声的样本）或
    `v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文的第2.4节）。'
- en: '`thresholding` (`bool`, defaults to `False`) — Whether to use the “dynamic
    thresholding” method. This is unsuitable for latent-space diffusion models such
    as Stable Diffusion.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresholding` (`bool`, 默认为 `False`) — 是否使用“动态阈值”方法。这不适用于稳定扩散等潜空间扩散模型。'
- en: '`dynamic_thresholding_ratio` (`float`, defaults to 0.995) — The ratio for the
    dynamic thresholding method. Valid only when `thresholding=True`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dynamic_thresholding_ratio` (`float`, 默认为 0.995) — 动态阈值方法的比率。仅在 `thresholding=True`
    时有效。'
- en: '`sample_max_value` (`float`, defaults to 1.0) — The threshold value for dynamic
    thresholding. Valid only when `thresholding=True`.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_max_value` (`float`, 默认为 1.0) — 动态阈值的阈值值。仅在 `thresholding=True` 时有效。'
- en: '`timestep_spacing` (`str`, defaults to `"leading"`) — The way the timesteps
    should be scaled. Refer to Table 2 of the [Common Diffusion Noise Schedules and
    Sample Steps are Flawed](https://huggingface.co/papers/2305.08891) for more information.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep_spacing` (`str`, 默认为 `"leading"`) — 时间步长应该如何缩放。有关更多信息，请参考[Common
    Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表2。'
- en: '`steps_offset` (`int`, defaults to 0) — An offset added to the inference steps.
    You can use a combination of `offset=1` and `set_alpha_to_one=False` to make the
    last step use step 0 for the previous alpha product like in Stable Diffusion.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`steps_offset` (`int`, 默认为 0) — 添加到推断步骤的偏移量。您可以使用 `offset=1` 和 `set_alpha_to_one=False`
    的组合，使最后一步使用步骤 0 用于先前 alpha 产品，就像在 Stable Diffusion 中一样。'
- en: '`rescale_betas_zero_snr` (`bool`, defaults to `False`) — Whether to rescale
    the betas to have zero terminal SNR. This enables the model to generate very bright
    and dark samples instead of limiting it to samples with medium brightness. Loosely
    related to [`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_betas_zero_snr`（默认为`False`的`bool`）- 是否重新缩放beta以使终端SNR为零。这使模型能够生成非常明亮和黑暗的样本，而不仅限于具有中等亮度的样本。与[`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506)
    loosely相关。'
- en: '`DDPMScheduler` explores the connections between denoising score matching and
    Langevin dynamics sampling.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`DDPMScheduler`探索去噪得分匹配和朗之万动力学采样之间的联系。'
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)和[ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。检查超类文档以了解库为所有调度器实现的通用方法，例如加载和保存。
- en: '#### `scale_model_input`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `scale_model_input`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L236)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L236)'
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor`) — The input sample.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（`torch.FloatTensor`）- 输入样本。'
- en: '`timestep` (`int`, *optional*) — The current timestep in the diffusion chain.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep`（`int`，*可选*）- 扩散链中的当前时间步。'
- en: Returns
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: A scaled input sample.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经过缩放的输入样本。
- en: Ensures interchangeability with schedulers that need to scale the denoising
    model input depending on the current timestep.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 确保与需要根据当前时间步缩放去噪模型输入的调度器可互换。
- en: '#### `set_timesteps`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_timesteps`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L253)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L253)'
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_inference_steps` (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model. If used, `timesteps` must be `None`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`（`int`）- 使用预训练模型生成样本时使用的扩散步数。如果使用，则`timesteps`必须为`None`。'
- en: '`device` (`str` or `torch.device`, *optional*) — The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`（`str`或`torch.device`，*可选*）- 时间步应移动到的设备。如果为`None`，则不移动时间步。'
- en: '`timesteps` (`List[int]`, *optional*) — Custom timesteps used to support arbitrary
    spacing between timesteps. If `None`, then the default timestep spacing strategy
    of equal spacing between timesteps is used. If `timesteps` is passed, `num_inference_steps`
    must be `None`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps`（`List[int]`，*可选*）- 用于支持时间步之间任意间距的自定义时间步。如果为`None`，则使用时间步之间等距离的默认时间步间距策略。如果传递了`timesteps`，则`num_inference_steps`必须为`None`。'
- en: Sets the discrete timesteps used for the diffusion chain (to be run before inference).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于扩散链的离散时间步（在推理之前运行）。
- en: '#### `step`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L401)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L401)'
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model_output` (`torch.FloatTensor`) — The direct output from learned diffusion
    model.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_output`（`torch.FloatTensor`）- 从学习扩散模型的直接输出。'
- en: '`timestep` (`float`) — The current discrete timestep in the diffusion chain.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep`（`float`）- 扩散链中的当前离散时间步。'
- en: '`sample` (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample`（`torch.FloatTensor`）- 由扩散过程创建的样本的当前实例。'
- en: '`generator` (`torch.Generator`, *optional*) — A random number generator.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`，*可选*）- 随机数生成器。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    or `tuple`.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）- 是否返回[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)或`tuple`。'
- en: Returns
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    or `tuple`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)或`tuple`'
- en: If return_dict is `True`, [DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[DDPMSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput)，否则返回一个元组，其中第一个元素是样本张量。
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反转SDE预测前一个时间步的样本。此函数从学习模型输出（通常是预测的噪声）传播扩散过程。
- en: DDPMSchedulerOutput
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DDPMSchedulerOutput
- en: '### `class diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L30)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L30)'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prev_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` for images) — Computed sample `(x_{t-1})` of previous timestep. `prev_sample`
    should be used as next model input in the denoising loop.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prev_sample`（`torch.FloatTensor`，形状为`（batch_size，num_channels，height，width）`，用于图像）-
    上一个时间步的计算样本`（x_{t-1}）`。`prev_sample`应该在去噪循环中作为下一个模型输入使用。'
- en: '`pred_original_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)` for images) — The predicted denoised sample `(x_{0})` based on
    the model output from the current timestep. `pred_original_sample` can be used
    to preview progress or for guidance.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pred_original_sample`（`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`，用于图像）- 基于当前时间步的模型输出的预测去噪样本`(x_{0})`。`pred_original_sample`可用于预览进展或指导。'
- en: Output class for the scheduler’s `step` function output.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 调度程序的`step`函数输出的输出类。
