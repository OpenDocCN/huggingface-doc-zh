- en: Batch mapping
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‰¹å¤„ç†æ˜ å°„
- en: 'Original text: [https://huggingface.co/docs/datasets/about_map_batch](https://huggingface.co/docs/datasets/about_map_batch)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/datasets/about_map_batch](https://huggingface.co/docs/datasets/about_map_batch)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Combining the utility of [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    with batch mode is very powerful. It allows you to speed up processing, and freely
    control the size of the generated dataset.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å°†[Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)çš„å®ç”¨æ€§ä¸æ‰¹å¤„ç†æ¨¡å¼ç»“åˆèµ·æ¥éå¸¸å¼ºå¤§ã€‚å®ƒå…è®¸æ‚¨åŠ å¿«å¤„ç†é€Ÿåº¦ï¼Œå¹¶è‡ªç”±æ§åˆ¶ç”Ÿæˆçš„æ•°æ®é›†çš„å¤§å°ã€‚
- en: Need for speed
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éœ€è¦é€Ÿåº¦
- en: The primary objective of batch mapping is to speed up processing. Often times,
    it is faster to work with batches of data instead of single examples. Naturally,
    batch mapping lends itself to tokenization. For example, the ğŸ¤— [Tokenizers](https://huggingface.co/docs/tokenizers/python/latest/)
    library works faster with batches because it parallelizes the tokenization of
    all the examples in a batch.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¹å¤„ç†æ˜ å°„çš„ä¸»è¦ç›®æ ‡æ˜¯åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œä½¿ç”¨æ•°æ®æ‰¹æ¬¡è€Œä¸æ˜¯å•ä¸ªç¤ºä¾‹æ›´å¿«ã€‚è‡ªç„¶åœ°ï¼Œæ‰¹å¤„ç†æ˜ å°„é€‚ç”¨äºæ ‡è®°åŒ–ã€‚ä¾‹å¦‚ï¼ŒğŸ¤— [Tokenizers](https://huggingface.co/docs/tokenizers/python/latest/)åº“åœ¨æ‰¹å¤„ç†ä¸­çš„å·¥ä½œé€Ÿåº¦æ›´å¿«ï¼Œå› ä¸ºå®ƒå¹¶è¡Œå¤„ç†æ‰¹æ¬¡ä¸­æ‰€æœ‰ç¤ºä¾‹çš„æ ‡è®°åŒ–ã€‚
- en: Input size != output size
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¾“å…¥å¤§å° != è¾“å‡ºå¤§å°
- en: 'The ability to control the size of the generated dataset can be leveraged for
    many interesting use-cases. In the How-to [map](#map) section, there are examples
    of using batch mapping to:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ§åˆ¶ç”Ÿæˆæ•°æ®é›†å¤§å°çš„èƒ½åŠ›å¯ä»¥ç”¨äºè®¸å¤šæœ‰è¶£çš„ç”¨ä¾‹ã€‚åœ¨[map](#map)éƒ¨åˆ†ä¸­ï¼Œæœ‰ä½¿ç”¨æ‰¹å¤„ç†æ˜ å°„çš„ç¤ºä¾‹ï¼š
- en: Split long sentences into shorter chunks.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†é•¿å¥å­æ‹†åˆ†ä¸ºè¾ƒçŸ­çš„å—ã€‚
- en: Augment a dataset with additional tokens.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨é¢å¤–çš„æ ‡è®°å¢å¼ºæ•°æ®é›†ã€‚
- en: 'It is helpful to understand how this works, so you can come up with your own
    ways to use batch mapping. At this point, you may be wondering how you can control
    the size of the generated dataset. The answer is: **the mapped function does not
    have to return an output batch of the same size**.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: äº†è§£è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„å¾ˆæœ‰å¸®åŠ©ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥æƒ³å‡ºè‡ªå·±ä½¿ç”¨æ‰¹å¤„ç†æ˜ å°„çš„æ–¹æ³•ã€‚æ­¤æ—¶ï¼Œæ‚¨å¯èƒ½æƒ³çŸ¥é“å¦‚ä½•æ§åˆ¶ç”Ÿæˆæ•°æ®é›†çš„å¤§å°ã€‚ç­”æ¡ˆæ˜¯ï¼š**æ˜ å°„å‡½æ•°ä¸å¿…è¿”å›ç›¸åŒå¤§å°çš„è¾“å‡ºæ‰¹æ¬¡**ã€‚
- en: In other words, your mapped function input can be a batch of size `N` and return
    a batch of size `M`. The output `M` can be greater than or less than `N`. This
    means you can concatenate your examples, divide it up, and even add more examples!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæ‚¨çš„æ˜ å°„å‡½æ•°è¾“å…¥å¯ä»¥æ˜¯å¤§å°ä¸º`N`çš„æ‰¹æ¬¡ï¼Œå¹¶è¿”å›å¤§å°ä¸º`M`çš„æ‰¹æ¬¡ã€‚è¾“å‡º`M`å¯ä»¥å¤§äºæˆ–å°äº`N`ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥è¿æ¥ç¤ºä¾‹ï¼Œå°†å…¶åˆ†å‰²ï¼Œå¹¶ç”šè‡³æ·»åŠ æ›´å¤šç¤ºä¾‹ï¼
- en: However, remember that all values in the output dictionary must contain the
    **same number of elements** as the other fields in the output dictionary. Otherwise,
    it is not possible to define the number of examples in the output returned by
    the mapped function. The number can vary between successive batches processed
    by the mapped function. For a single batch though, all values of the output dictionary
    should have the same length (i.e., the number of elements).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œè¯·è®°ä½ï¼Œè¾“å‡ºå­—å…¸ä¸­çš„æ‰€æœ‰å€¼å¿…é¡»åŒ…å«ä¸è¾“å‡ºå­—å…¸ä¸­çš„å…¶ä»–å­—æ®µ**ç›¸åŒæ•°é‡çš„å…ƒç´ **ã€‚å¦åˆ™ï¼Œæ— æ³•å®šä¹‰æ˜ å°„å‡½æ•°è¿”å›çš„è¾“å‡ºä¸­çš„ç¤ºä¾‹æ•°é‡ã€‚æ˜ å°„å‡½æ•°å¤„ç†çš„è¿ç»­æ‰¹æ¬¡ä¹‹é—´çš„æ•°é‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ä½†æ˜¯å¯¹äºå•ä¸ªæ‰¹æ¬¡ï¼Œè¾“å‡ºå­—å…¸çš„æ‰€æœ‰å€¼åº”å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼ˆå³å…ƒç´ æ•°é‡ï¼‰ã€‚
- en: 'For example, from a dataset of 1 column and 3 rows, if you use `map` to return
    a new column with twice as many rows, then you will have an error. In this case,
    you end up with one column with 3 rows, and one column with 6 rows. As you can
    see, the table will not be valid:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä»å…·æœ‰1åˆ—å’Œ3è¡Œçš„æ•°æ®é›†ä¸­ï¼Œå¦‚æœæ‚¨ä½¿ç”¨`map`è¿”å›å…·æœ‰ä¸¤å€è¡Œæ•°çš„æ–°åˆ—ï¼Œåˆ™ä¼šå‡ºç°é”™è¯¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å°†å¾—åˆ°ä¸€åˆ—æœ‰3è¡Œï¼Œå¦ä¸€åˆ—æœ‰6è¡Œã€‚å¦‚æ‚¨æ‰€è§ï¼Œè¡¨å°†æ— æ•ˆï¼š
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To make it valid, you have to drop one of the columns:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä½¿å…¶æœ‰æ•ˆï¼Œæ‚¨å¿…é¡»åˆ é™¤å…¶ä¸­ä¸€ä¸ªåˆ—ï¼š
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
