- en: Bark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bark
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bark](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bark)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bark](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bark)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: Bark is a transformer-based text-to-speech model proposed by Suno AI in [suno-ai/bark](https://github.com/suno-ai/bark).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Bark是由Suno AI提出的基于Transformer的文本到语音模型，位于[suno-ai/bark](https://github.com/suno-ai/bark)。
- en: 'Bark is made of 4 main models:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Bark由4个主要模型组成：
- en: '[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)
    (also referred to as the ‘text’ model): a causal auto-regressive transformer model
    that takes as input tokenized text, and predicts semantic text tokens that capture
    the meaning of the text.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)（也称为“文本”模型）：一个因果自回归Transformer模型，其输入为标记化文本，并预测捕捉文本含义的语义文本标记。'
- en: '[BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)
    (also referred to as the ‘coarse acoustics’ model): a causal autoregressive transformer,
    that takes as input the results of the [BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)
    model. It aims at predicting the first two audio codebooks necessary for EnCodec.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)（也称为“粗声学”模型）：一个因果自回归Transformer，其输入为[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)模型的结果。它旨在预测EnCodec所需的前两个音频码本。'
- en: '[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)
    (the ‘fine acoustics’ model), this time a non-causal autoencoder transformer,
    which iteratively predicts the last codebooks based on the sum of the previous
    codebooks embeddings.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)（“精细声学”模型），这次是一个非因果自编码器Transformer，它根据先前码本嵌入的总和迭代预测最后的码本。'
- en: having predicted all the codebook channels from the [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel),
    Bark uses it to decode the output audio array.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)中预测了所有码本通道后，Bark使用它来解码输出音频数组。
- en: It should be noted that each of the first three modules can support conditional
    speaker embeddings to condition the output sound according to specific predefined
    voice.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，前三个模块中的每一个都可以支持条件说话者嵌入，以根据特定预定义的声音来调整输出声音。
- en: This model was contributed by [Yoach Lacombe (ylacombe)](https://huggingface.co/ylacombe)
    and [Sanchit Gandhi (sanchit-gandhi)](https://github.com/sanchit-gandhi). The
    original code can be found [here](https://github.com/suno-ai/bark).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[Yoach Lacombe (ylacombe)](https://huggingface.co/ylacombe)和[Sanchit Gandhi
    (sanchit-gandhi)](https://github.com/sanchit-gandhi)贡献。原始代码可以在[这里](https://github.com/suno-ai/bark)找到。
- en: Optimizing Bark
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化Bark
- en: Bark can be optimized with just a few extra lines of code, which **significantly
    reduces its memory footprint** and **accelerates inference**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Bark可以通过添加几行额外的代码进行优化，**显著减少其内存占用**并**加速推理**。
- en: Using half-precision
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用半精度
- en: You can speed up inference and reduce memory footprint by 50% simply by loading
    the model in half-precision.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将模型加载为半精度，可以将推理加速并减少内存占用量50%。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using CPU offload
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用CPU卸载
- en: As mentioned above, Bark is made up of 4 sub-models, which are called up sequentially
    during audio generation. In other words, while one sub-model is in use, the other
    sub-models are idle.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，Bark由4个子模型组成，在音频生成过程中按顺序调用。换句话说，当一个子模型在使用时，其他子模型处于空闲状态。
- en: 'If you’re using a CUDA device, a simple solution to benefit from an 80% reduction
    in memory footprint is to offload the submodels from GPU to CPU when they’re idle.
    This operation is called *CPU offloading*. You can use it with one line of code
    as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用CUDA设备，要获得80%的内存占用减少，一个简单的解决方案是在子模型空闲时将其从GPU卸载到CPU。这个操作称为*CPU卸载*。您可以使用以下一行代码来实现：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that 🤗 Accelerate must be installed before using this feature. [Here’s
    how to install it.](https://huggingface.co/docs/accelerate/basic_tutorials/install)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在使用此功能之前，必须安装🤗 Accelerate。[这里是如何安装它的方法。](https://huggingface.co/docs/accelerate/basic_tutorials/install)
- en: Using Better Transformer
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Better Transformer
- en: 'Better Transformer is an 🤗 Optimum feature that performs kernel fusion under
    the hood. You can gain 20% to 30% in speed with zero performance degradation.
    It only requires one line of code to export the model to 🤗 Better Transformer:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Better Transformer是一个🤗 Optimum功能，可以在后台执行内核融合。您可以获得20%至30%的速度提升，而性能不会降低。只需一行代码即可将模型导出到🤗
    Better Transformer：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that 🤗 Optimum must be installed before using this feature. [Here’s how
    to install it.](https://huggingface.co/docs/optimum/installation)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在使用此功能之前，必须安装🤗 Optimum。[这里是如何安装它的方法。](https://huggingface.co/docs/optimum/installation)
- en: Using Flash Attention 2
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Flash Attention 2
- en: Flash Attention 2 is an even faster, optimized version of the previous optimization.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Flash Attention 2是前一个优化的更快、优化版本。
- en: Installation
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 安装
- en: First, check whether your hardware is compatible with Flash Attention 2\. The
    latest list of compatible hardware can be found in the [official documentation](https://github.com/Dao-AILab/flash-attention#installation-and-features).
    If your hardware is not compatible with Flash Attention 2, you can still benefit
    from attention kernel optimisations through Better Transformer support covered
    [above](https://huggingface.co/docs/transformers/main/en/model_doc/bark#using-better-transformer).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，检查您的硬件是否与Flash Attention 2兼容。最新的兼容硬件列表可以在[官方文档](https://github.com/Dao-AILab/flash-attention#installation-and-features)中找到。如果您的硬件与Flash
    Attention 2不兼容，您仍然可以通过上面提到的Better Transformer支持从注意力内核优化中受益。
- en: 'Next, [install](https://github.com/Dao-AILab/flash-attention#installation-and-features)
    the latest version of Flash Attention 2:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，[安装](https://github.com/Dao-AILab/flash-attention#installation-and-features)最新版本的Flash
    Attention 2：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Usage
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 用法
- en: 'To load a model using Flash Attention 2, we can pass the `attn_implementation="flash_attention_2"`
    flag to [`.from_pretrained`](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained).
    We’ll also load the model in half-precision (e.g. `torch.float16`), since it results
    in almost no degradation to audio quality but significantly lower memory usage
    and faster inference:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Flash Attention 2加载模型，我们可以通过在[`.from_pretrained`](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)中传递`attn_implementation="flash_attention_2"`标志来实现。我们还将以半精度（例如`torch.float16`）加载模型，因为这几乎不会对音频质量造成降级，但内存使用量明显降低，推理速度更快：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Performance comparison
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 性能比较
- en: 'The following diagram shows the latency for the native attention implementation
    (no optimisation) against Better Transformer and Flash Attention 2\. In all cases,
    we generate 400 semantic tokens on a 40GB A100 GPU with PyTorch 2.1\. Flash Attention
    2 is also consistently faster than Better Transformer, and its performance improves
    even more as batch sizes increase:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了原生注意力实现（无优化）与Better Transformer和Flash Attention 2之间的延迟。在所有情况下，我们在40GB
    A100 GPU上使用PyTorch 2.1生成400个语义标记。Flash Attention 2也比Better Transformer更快，并且随着批量大小的增加，其性能甚至更好：
- en: '![](../Images/62ff1093eff6a3b02e14aad370aaa0c2.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62ff1093eff6a3b02e14aad370aaa0c2.png)'
- en: To put this into perspective, on an NVIDIA A100 and when generating 400 semantic
    tokens with a batch size of 16, you can get 17 times the [throughput](https://huggingface.co/blog/optimizing-bark#throughput)
    and still be 2 seconds faster than generating sentences one by one with the native
    model implementation. In other words, all the samples will be generated 17 times
    faster.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，在NVIDIA A100上，当使用批量大小为16生成400个语义标记时，您可以获得17倍的[吞吐量](https://huggingface.co/blog/optimizing-bark#throughput)，并且仍然比使用原生模型实现逐句生成句子快2秒。换句话说，所有样本将生成速度提高17倍。
- en: At batch size 8, on an NVIDIA A100, Flash Attention 2 is also 10% faster than
    Better Transformer, and at batch size 16, 25%.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在批量大小为8时，在NVIDIA A100上，Flash Attention 2也比Better Transformer快10%，在批量大小为16时，快25%。
- en: Combining optimization techniques
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结合优化技术
- en: You can combine optimization techniques, and use CPU offload, half-precision
    and Flash Attention 2 (or 🤗 Better Transformer) all at once.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以结合优化技术，同时使用CPU卸载、半精度和Flash Attention 2（或🤗 Better Transformer）。
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Find out more on inference optimization techniques [here](https://huggingface.co/docs/transformers/perf_infer_gpu_one).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理优化技术上了解更多信息[这里](https://huggingface.co/docs/transformers/perf_infer_gpu_one)。
- en: Usage tips
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用提示
- en: Suno offers a library of voice presets in a number of languages [here](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c).
    These presets are also uploaded in the hub [here](https://huggingface.co/suno/bark-small/tree/main/speaker_embeddings)
    or [here](https://huggingface.co/suno/bark/tree/main/speaker_embeddings).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Suno提供了多种语言的声音预设库[这里](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)。这些预设也上传到了hub
    [这里](https://huggingface.co/suno/bark-small/tree/main/speaker_embeddings) 或 [这里](https://huggingface.co/suno/bark/tree/main/speaker_embeddings)。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Bark can generate highly realistic, **multilingual** speech as well as other
    audio - including music, background noise and simple sound effects.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Bark可以生成高度逼真的**多语言**语音以及其他音频 - 包括音乐、背景噪音和简单的音效。
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The model can also produce **nonverbal communications** like laughing, sighing
    and crying.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还可以产生像笑、叹息和哭泣等**非语言交流**。
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To save the audio, simply take the sample rate from the model config and some
    scipy utility:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要保存音频，只需从模型配置中获取采样率和一些scipy实用程序：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: BarkConfig
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkConfig
- en: '### `class transformers.BarkConfig`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L219)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L219)'
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`semantic_config` ([BarkSemanticConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticConfig),
    *optional*) — Configuration of the underlying semantic sub-model.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`semantic_config` ([BarkSemanticConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticConfig),
    *optional*) — 底层语义子模型的配置。'
- en: '`coarse_acoustics_config` ([BarkCoarseConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseConfig),
    *optional*) — Configuration of the underlying coarse acoustics sub-model.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`coarse_acoustics_config` ([BarkCoarseConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseConfig),
    *optional*) — 底层粗糙声学子模型的配置。'
- en: '`fine_acoustics_config` ([BarkFineConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineConfig),
    *optional*) — Configuration of the underlying fine acoustics sub-model.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fine_acoustics_config` ([BarkFineConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineConfig),
    *optional*) — 底层精细声学子模型的配置。'
- en: '`codec_config` ([AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig),
    *optional*) — Configuration of the underlying codec sub-model.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codec_config` ([AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig),
    *optional*) — 底层编解码器子模型的配置。'
- en: Example —
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例 —
- en: This is the configuration class to store the configuration of a [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel).
    It is used to instantiate a Bark model according to the specified sub-models configurations,
    defining the model architecture.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)的配置。它用于根据指定的子模型配置实例化Bark模型，定义模型架构。
- en: Instantiating a configuration with the defaults will yield a similar configuration
    to that of the Bark [suno/bark](https://huggingface.co/suno/bark) architecture.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认值实例化配置将产生与Bark [suno/bark](https://huggingface.co/suno/bark)架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: '#### `from_sub_model_configs`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_sub_model_configs`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L309)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L309)'
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Returns
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)'
- en: An instance of a configuration object
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象的实例
- en: Instantiate a [BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)
    (or a derived class) from bark sub-models configuration.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从bark子模型配置实例化一个[BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)（或派生类）。
- en: BarkProcessor
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkProcessor
- en: '### `class transformers.BarkProcessor`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L34)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L34)'
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — An instance of [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)的实例。'
- en: '`speaker_embeddings` (`Dict[Dict[str]]`, *optional*) — Optional nested speaker
    embeddings dictionary. The first level contains voice preset names (e.g `"en_speaker_4"`).
    The second level contains `"semantic_prompt"`, `"coarse_prompt"` and `"fine_prompt"`
    embeddings. The values correspond to the path of the corresponding `np.ndarray`.
    See [here](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)
    for a list of `voice_preset_names`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings` (`Dict[Dict[str]]`, *可选*) — 可选的嵌套说话者嵌入字典。第一级包含声音预设名称（例如`"en_speaker_4"`）。第二级包含`"semantic_prompt"`、`"coarse_prompt"`和`"fine_prompt"`嵌入。值对应于相应`np.ndarray`的路径。请参阅[此处](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)获取`voice_preset_names`列表。'
- en: Constructs a Bark processor which wraps a text tokenizer and optional Bark voice
    presets into a single processor.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Bark处理器，将文本标记器和可选的Bark声音预设包装成一个处理器。
- en: '#### `__call__`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L219)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L219)'
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence can be a string or a list of strings (pretokenized
    string). If the sequences are provided as list of strings (pretokenized), you
    must set `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]`, `List[List[str]]`) — 要编码的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果提供的序列是字符串列表（预分词），必须设置`is_split_into_words=True`（以消除与序列批次的歧义）。'
- en: '`voice_preset` (`str`, `Dict[np.ndarray]`) — The voice preset, i.e the speaker
    embeddings. It can either be a valid voice_preset name, e.g `"en_speaker_1"`,
    or directly a dictionnary of `np.ndarray` embeddings for each submodel of `Bark`.
    Or it can be a valid file name of a local `.npz` single voice preset.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`voice_preset` (`str`, `Dict[np.ndarray]`) — 声音预设，即说话者嵌入。它可以是有效的voice_preset名称，例如`"en_speaker_1"`，或直接是`Bark`的每个子模型的`np.ndarray`嵌入的字典。或者它可以是本地`.npz`单个声音预设的有效文件名。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors of a particular framework. Acceptable
    values are:'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *可选*) — 如果设置，将返回特定框架的张量。可接受的值为：'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return NumPy `np.ndarray` objects.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回NumPy `np.ndarray`对象。'
- en: Returns
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: Tuple([BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding),
    [BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature))
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 元组([BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding),
    [BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature))
- en: A tuple composed of a [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding),
    i.e the output of the `tokenizer` and a [BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature),
    i.e the voice preset with the right tensors type.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个元组，由一个[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)组成，即`tokenizer`的输出，以及一个[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)，即具有正确张量类型的声音预设。
- en: Main method to prepare for the model one or several sequences(s). This method
    forwards the `text` and `kwargs` arguments to the AutoTokenizer’s `__call__()`
    to encode the text. The method also proposes a voice preset which is a dictionary
    of arrays that conditions `Bark`’s output. `kwargs` arguments are forwarded to
    the tokenizer and to `cached_file` method if `voice_preset` is a valid filename.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 准备模型一个或多个序列的主要方法。此方法将`text`和`kwargs`参数转发给AutoTokenizer的`__call__()`以对文本进行编码。该方法还提供了一个声音预设，它是一个数组字典，用于条件化`Bark`的输出。如果`voice_preset`是有效的文件名，则`kwargs`参数将被转发给tokenizer和`cached_file`方法。
- en: '#### `from_pretrained`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L64)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L64)'
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 这可以是：'
- en: a string, the *model id* of a pretrained [BarkProcessor](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor)
    hosted inside a model repo on huggingface.co. Valid model ids can be located at
    the root-level, like `bert-base-uncased`, or namespaced under a user or organization
    name, like `dbmdz/bert-base-german-cased`.
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练的 [BarkProcessor](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor)
    的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a processor saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor.save_pretrained)
    方法保存的处理器的*目录*路径，例如，`./my_model_directory/`。
- en: '`speaker_embeddings_dict_path` (`str`, *optional*, defaults to `"speaker_embeddings_path.json"`)
    — The name of the `.json` file containing the speaker_embeddings dictionnary located
    in `pretrained_model_name_or_path`. If `None`, no speaker_embeddings is loaded.
    **kwargs — Additional keyword arguments passed along to both `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings_dict_path` (`str`, *可选*, 默认为 `"speaker_embeddings_path.json"`)
    — 包含位于 `pretrained_model_name_or_path` 中的说话者嵌入字典的 `.json` 文件的名称。如果为 `None`，则不加载说话者嵌入。**kwargs
    — 传递给 `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained` 的额外关键字参数。'
- en: Instantiate a Bark processor associated with a pretrained model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化一个与预训练模型相关联的Bark处理器。
- en: '#### `save_pretrained`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L118)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/processing_bark.py#L118)'
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the tokenizer files
    and the speaker embeddings will be saved (directory will be created if it does
    not exist).'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str` 或 `os.PathLike`) — 将分词器文件和说话者嵌入保存在其中的目录（如果不存在，将创建目录）。'
- en: '`speaker_embeddings_dict_path` (`str`, *optional*, defaults to `"speaker_embeddings_path.json"`)
    — The name of the `.json` file that will contains the speaker_embeddings nested
    path dictionnary, if it exists, and that will be located in `pretrained_model_name_or_path/speaker_embeddings_directory`.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings_dict_path` (`str`, *可选*, 默认为 `"speaker_embeddings_path.json"`)
    — 包含说话者嵌入嵌套路径字典的 `.json` 文件的名称，如果存在，将位于 `pretrained_model_name_or_path/speaker_embeddings_directory`
    中。'
- en: '`speaker_embeddings_directory` (`str`, *optional*, defaults to `"speaker_embeddings/"`)
    — The name of the folder in which the speaker_embeddings arrays will be saved.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings_directory` (`str`, *可选*, 默认为 `"speaker_embeddings/"`) —
    说话者嵌入数组将保存在其中的文件夹的名称。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace). kwargs — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为 `False`) — 是否在保存后将模型推送到Hugging Face模型中心。您可以使用
    `repo_id` 指定要推送到的存储库（将默认为您的命名空间中的 `save_directory` 名称）。kwargs — 传递给 [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    方法的额外关键字参数。'
- en: Saves the attributes of this processor (tokenizer…) in the specified directory
    so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor.from_pretrained)
    method.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处理器的属性（分词器等）保存在指定目录中，以便可以使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor.from_pretrained)
    方法重新加载。
- en: BarkModel
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkModel
- en: '### `class transformers.BarkModel`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1629)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1629)'
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig))
    — 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: 'The full Bark model, a text-to-speech model composed of 4 sub-models:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的Bark模型，一个由4个子模型组成的文本到语音模型：
- en: '[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)
    (also referred to as the ‘text’ model): a causal auto-regressive transformer model
    that takes as input tokenized text, and predicts semantic text tokens that capture
    the meaning of the text.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)（也称为‘文本’模型）：一个因果自回归变换器模型，以标记化文本作为输入，并预测捕捉文本含义的语义文本标记。'
- en: '[BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)
    (also refered to as the ‘coarse acoustics’ model), also a causal autoregressive
    transformer, that takes into input the results of the last model. It aims at regressing
    the first two audio codebooks necessary to `encodec`.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)（也称为‘粗声学’模型），也是一个因果自回归变换器，它接受上一个模型的结果作为输入。它旨在回归出编码所需的前两个音频码书。'
- en: '[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)
    (the ‘fine acoustics’ model), this time a non-causal autoencoder transformer,
    which iteratively predicts the last codebooks based on the sum of the previous
    codebooks embeddings.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)（''fine
    acoustics''模型），这次是一个非因果自动编码器变压器，它基于前一个码本嵌入的总和来迭代预测最后的码本。'
- en: having predicted all the codebook channels from the [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel),
    Bark uses it to decode the output audio array.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从[EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)中预测出所有码本通道后，Bark使用它来解码输出音频数组。
- en: It should be noted that each of the first three modules can support conditional
    speaker embeddings to condition the output sound according to specific predefined
    voice.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，前三个模块中的每一个都可以支持条件说话者嵌入，根据特定预定义的声音来调整输出声音。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以了解所有与一般用法和行为相关的事项。
- en: '#### `generate`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1737)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1737)'
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`Optional[torch.Tensor]` of shape (batch_size, seq_len), *optional*)
    — Input ids. Will be truncated up to 256 tokens. Note that the output audios will
    be as long as the longest generation among the batch.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为（batch_size，seq_len）的`Optional[torch.Tensor]`，*可选*）— 输入id。将被截断至256个标记。请注意，输出音频的长度将与批次中最长的生成长度一样。'
- en: '`history_prompt` (`Optional[Dict[str,torch.Tensor]]`, *optional*) — Optional
    `Bark` speaker prompt. Note that for now, this model takes only one speaker prompt
    per batch.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`history_prompt`（`Optional[Dict[str,torch.Tensor]]`，*可选*）— 可选的`Bark`说话者提示。请注意，目前，该模型每批次只接受一个说话者提示。'
- en: '`kwargs` (*optional*) — Remaining dictionary of keyword arguments. Keyword
    arguments are of two types:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（*可选*）— 剩余的关键字参数字典。关键字参数有两种类型：'
- en: Without a prefix, they will be entered as `**kwargs` for the `generate` method
    of each sub-model.
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有前缀，它们将作为每个子模型的`generate`方法的`**kwargs`输入。
- en: With a *semantic_*, *coarse_*, *fine_* prefix, they will be input for the `generate`
    method of the semantic, coarse and fine respectively. It has the priority over
    the keywords without a prefix.
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*semantic_*、*coarse_*、*fine_*前缀，它们将作为语义、粗糙和细致的`generate`方法的输入。它优先于没有前缀的关键字。
- en: This means you can, for example, specify a generation strategy for all sub-models
    except one.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着您可以为所有子模型指定一个生成策略，除了一个。
- en: '`return_output_lengths` (`bool`, *optional*) — Whether or not to return the
    waveform lengths. Useful when batching.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_output_lengths`（`bool`，*可选*）— 是否返回波形长度。在批处理时很有用。'
- en: Returns
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: By default
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下
- en: '`audio_waveform` (`torch.Tensor` of shape (batch_size, seq_len)): Generated
    audio waveform. When `return_output_lengths=True`: Returns a tuple made of:'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_waveform`（形状为（batch_size，seq_len）的`torch.Tensor`）：生成的音频波形。当`return_output_lengths=True`时：返回一个由以下元组组成：'
- en: '`audio_waveform` (`torch.Tensor` of shape (batch_size, seq_len)): Generated
    audio waveform.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_waveform`（形状为（batch_size，seq_len）的`torch.Tensor`）：生成的音频波形。'
- en: '`output_lengths` (`torch.Tensor` of shape (batch_size)): The length of each
    waveform in the batch'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_lengths`（形状为（batch_size）的`torch.Tensor`）：批次中每个波形的长度'
- en: Generates audio from an input prompt and an additional optional `Bark` speaker
    prompt.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从输入提示和一个额外的可选`Bark`说话者提示生成音频。
- en: 'Example:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE18]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#### `enable_cpu_offload`'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1680)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1680)'
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`gpu_id` (`int`, *optional*, defaults to 0) — GPU id on which the sub-models
    will be loaded and offloaded.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpu_id`（`int`，*可选*，默认为0）— 子模型将加载和卸载的GPU id。'
- en: Offloads all sub-models to CPU using accelerate, reducing memory usage with
    a low impact on performance. This method moves one whole sub-model at a time to
    the GPU when it is used, and the sub-model remains in GPU until the next sub-model
    runs.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有子模型卸载到CPU，减少内存使用量，对性能影响较小。该方法在使用时一次将一个完整的子模型移动到GPU，并且子模型在GPU中保持，直到下一个子模型运行。
- en: BarkSemanticModel
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkSemanticModel
- en: '### `class transformers.BarkSemanticModel`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkSemanticModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L913)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L913)'
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BarkSemanticConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[BarkSemanticConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Bark semantic (or text) model. It shares the same architecture as the coarse
    model. It is a GPT-2 like autoregressive model with a language modeling head on
    top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Bark语义（或文本）模型。它与粗模型共享相同的架构。这是一个类似于GPT-2的自回归模型，顶部带有语言建模头。此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为其所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)'
- en: '[PRE21]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。默认情况下，如果提供填充，则将被忽略。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递了`use_cache`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块中的键和值），可用于加速顺序解码。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（那些没有将其过去的键值状态提供给此模型的标记），形状为`(batch_size,
    1)`，而不是形状为`(batch_size, sequence_length)`的所有`input_ids`。
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.Tensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。掩码值在`[0,
    1]`中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“未屏蔽”的标记，为1，
- en: 0 for tokens that are `masked`.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“屏蔽”的标记，为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）-
    每个输入序列标记在位置嵌入中的位置索引。在范围`[0, config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于将编码器中注意力模块的选定头部置零的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未“屏蔽”。
- en: 0 indicates the head is `masked`.
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“屏蔽”。
- en: '`input_embeds` (`torch.FloatTensor` of shape `(batch_size, input_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. Here, due to `Bark` particularities,
    if `past_key_values` is used, `input_embeds` will be ignored and you have to use
    `input_ids`. If `past_key_values` is not used and `use_cache` is set to `True`,
    `input_embeds` is used in priority instead of `input_ids`.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_embeds`（形状为`(batch_size, input_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）-
    可选地，可以直接传递嵌入表示，而不是传递`input_ids`。在这里，由于`Bark`的特殊性，如果使用了`past_key_values`，将忽略`input_embeds`，您必须使用`input_ids`。如果未使用`past_key_values`且`use_cache`设置为`True`，则优先使用`input_embeds`而不是`input_ids`。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）- 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: The [BarkCausalModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCausalModel)
    forward method, overrides the `__call__` special method.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '[BarkCausalModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCausalModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: BarkCoarseModel
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkCoarseModel
- en: '### `class transformers.BarkCoarseModel`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkCoarseModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1022)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1022)'
- en: '[PRE22]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BarkCoarseConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([BarkCoarseConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Bark coarse acoustics model. It shares the same architecture as the semantic
    (or text) model. It is a GPT-2 like autoregressive model with a language modeling
    head on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Bark粗糙声学模型。它与语义（或文本）模型共享相同的架构。这是一个类似于GPT-2的自回归模型，顶部带有语言建模头。此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)'
- en: '[PRE23]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。默认情况下将忽略填充。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache`参数或者`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块中的键和值），可用于加速顺序解码（查看`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后一个形状为`(batch_size, 1)`的`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的）而不是所有形状为`(batch_size,
    sequence_length)`的`input_ids`。
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`，形状为`(batch_size, sequence_length)`，*optional*)
    — 用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记为1，
- en: 0 for tokens that are `masked`.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 每个输入序列标记在位置嵌入中的位置索引。在范围`[0, config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`，形状为`(encoder_layers, encoder_attention_heads)`，*可选*)
    — 用于使编码器中注意力模块的选定头部失效的掩码。掩码值选择在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部是`未屏蔽`。
- en: 0 indicates the head is `masked`.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部是`masked`。
- en: '`input_embeds` (`torch.FloatTensor` of shape `(batch_size, input_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. Here, due to `Bark` particularities,
    if `past_key_values` is used, `input_embeds` will be ignored and you have to use
    `input_ids`. If `past_key_values` is not used and `use_cache` is set to `True`,
    `input_embeds` is used in priority instead of `input_ids`.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_embeds` (`torch.FloatTensor`，形状为`(batch_size, input_sequence_length,
    hidden_size)`，*可选*) — 可选择直接传递嵌入表示而不是传递`input_ids`。在这里，由于`Bark`的特殊性，如果使用了`past_key_values`，则将忽略`input_embeds`，必须使用`input_ids`。如果未使用`past_key_values`并且`use_cache`设置为`True`，则优先使用`input_embeds`而不是`input_ids`。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`，*可选*) — 如果设置为`True`，则返回`past_key_values`键值状态，可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: The [BarkCausalModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCausalModel)
    forward method, overrides the `__call__` special method.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[BarkCausalModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCausalModel)的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义配方，但应该在此之后调用`Module`实例，而不是调用此函数，因为前者负责运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: BarkFineModel
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkFineModel
- en: '### `class transformers.BarkFineModel`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkFineModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1243)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1243)'
- en: '[PRE24]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([BarkFineConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([BarkFineConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Bark fine acoustics model. It is a non-causal GPT-like model with `config.n_codes_total`
    embedding layers and language modeling heads, one for each codebook. This model
    inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Bark fine acoustics model. It is a non-causal GPT-like model with `config.n_codes_total`
    embedding layers and language modeling heads, one for each codebook. This model
    inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1381)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L1381)'
- en: '[PRE25]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`codebook_idx` (`int`) — Index of the codebook that will be predicted.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codebook_idx` (`int`) — 将被预测的码书的索引。'
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length, number_of_codebooks)`)
    — Indices of input sequence tokens in the vocabulary. Padding will be ignored
    by default should you provide it. Initially, indices of the first two codebooks
    are obtained from the `coarse` sub-model. The rest is predicted recursively by
    attending the previously predicted channels. The model predicts on windows of
    length 1024.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length, number_of_codebooks)`）
    — 输入序列标记在词汇表中的索引。默认情况下将忽略填充。最初，前两个码书的索引是从`coarse`子模型中获取的。其余的通过递归预测前面预测的通道来预测。模型对长度为1024的窗口进行预测。'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*) —
    避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`范围内：'
- en: 1 for tokens that are `not masked`,
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示`未被mask`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`masked`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。 '
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`，形状为`(encoder_layers, encoder_attention_heads)`，*可选*)
    — 在编码器中将注意力模块的选定头部置零的掩码。掩码值选择在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被mask`，
- en: 0 indicates the head is `masked`.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — NOT IMPLEMENTED YET.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*) — 尚未实现。'
- en: '`input_embeds` (`torch.FloatTensor` of shape `(batch_size, input_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. If `past_key_values` is used,
    optionally only the last `input_embeds` have to be input (see `past_key_values`).
    This is useful if you want more control over how to convert `input_ids` indices
    into associated vectors than the model’s internal embedding lookup matrix.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_embeds` (`torch.FloatTensor`，形状为`(batch_size, input_sequence_length,
    hidden_size)`，*可选*) — 可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果使用`past_key_values`，则只需输入最后的`input_embeds`（请参见`past_key_values`）。如果您想要更多控制如何将`input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: The [BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)
    forward method, overrides the `__call__` special method.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数中定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: BarkCausalModel
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkCausalModel
- en: '### `class transformers.BarkCausalModel`'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkCausalModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L658)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L658)'
- en: '[PRE26]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#### `forward`'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/modeling_bark.py#L749)'
- en: '[PRE27]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`) — 输入序列标记在词汇表中的索引。默认情况下将忽略填充。可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参见[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入ID？](../glossary#input-ids)'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递了`use_cache`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有两个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后一个形状为`(batch_size, 1)`的`decoder_input_ids`（那些没有将其过去的键值状态传递给该模型的）而不是形状为`(batch_size,
    sequence_length)`的所有`input_ids`。
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`，形状为`(batch_size, sequence_length)`，*可选*) —
    用于避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示标记未被“masked”。
- en: 0 for tokens that are `masked`.
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被“masked”的标记为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[注意力掩码是什么？](../glossary#attention-mask)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 每个输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[位置ID是什么？](../glossary#position-ids)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`，形状为`(encoder_layers, encoder_attention_heads)`，*可选*)
    — 用于使编码器中注意力模块的选定头部失效的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被“masked”。
- en: 0 indicates the head is `masked`.
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“masked”。
- en: '`input_embeds` (`torch.FloatTensor` of shape `(batch_size, input_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. Here, due to `Bark` particularities,
    if `past_key_values` is used, `input_embeds` will be ignored and you have to use
    `input_ids`. If `past_key_values` is not used and `use_cache` is set to `True`,
    `input_embeds` is used in priority instead of `input_ids`.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_embeds` (`torch.FloatTensor`，形状为`(batch_size, input_sequence_length,
    hidden_size)`，*可选*) — 可选地，可以直接传递嵌入表示而不是传递`input_ids`。在这里，由于`Bark`的特殊性，如果使用了`past_key_values`，将忽略`input_embeds`，必须使用`input_ids`。如果未使用`past_key_values`且`use_cache`设置为`True`，则优先使用`input_embeds`而不是`input_ids`。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *可选*) — 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: The [BarkCausalModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCausalModel)
    forward method, overrides the `__call__` special method.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '[BarkCausalModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCausalModel)
    的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: BarkCoarseConfig
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkCoarseConfig
- en: '### `class transformers.BarkCoarseConfig`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkCoarseConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L164)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L164)'
- en: '[PRE28]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`block_size` (`int`, *optional*, defaults to 1024) — The maximum sequence length
    that this model might ever be used with. Typically set this to something large
    just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_size` (`int`, *可选*, 默认为 1024) — 该模型可能会使用的最大序列长度。通常将其设置为较大的值以防万一（例如，512、1024或2048）。'
- en: '`input_vocab_size` (`int`, *optional*, defaults to 10_048) — Vocabulary size
    of a Bark sub-model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel).
    Defaults to 10_048 but should be carefully thought with regards to the chosen
    sub-model.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_vocab_size` (`int`, *可选*, 默认为 10_048) — Bark 子模型的词汇量。定义了在调用 [BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)
    时可以表示的不同标记数量。默认为 10_048，但应谨慎考虑所选子模型。'
- en: '`output_vocab_size` (`int`, *optional*, defaults to 10_048) — Output vocabulary
    size of a Bark sub-model. Defines the number of different tokens that can be represented
    by the: `output_ids` when passing forward a [BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel).
    Defaults to 10_048 but should be carefully thought with regards to the chosen
    sub-model.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_vocab_size` (`int`, *optional*, 默认为10_048) — Bark子模型的输出词汇量。定义了在向前传递[BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)时可以表示的不同标记数量：`output_ids`。默认为10_048，但应根据所选子模型慎重考虑。'
- en: '`num_layers` (`int`, *optional*, defaults to 12) — Number of hidden layers
    in the given sub-model.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers` (`int`, *optional*, 默认为12) — 给定子模型中隐藏层的数量。'
- en: '`num_heads` (`int`, *optional*, defaults to 12) — Number of attention heads
    for each attention layer in the Transformer architecture.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`int`, *optional*, 默认为12) — Transformer架构中每个注意力层的注意力头数。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    “intermediate” (often named feed-forward) layer in the architecture.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为768) — 架构中“中间”（通常称为前馈）层的维度。'
- en: '`dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, 默认为0.0) — 嵌入层、编码器和池化器中所有全连接层的丢弃概率。'
- en: '`bias` (`bool`, *optional*, defaults to `True`) — Whether or not to use bias
    in the linear layers and layer norm layers.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias` (`bool`, *optional*, 默认为`True`) — 是否在线性层和层归一化层中使用偏置。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, 默认为0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, 默认为`True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: This is the configuration class to store the configuration of a [BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel).
    It is used to instantiate the model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the Bark [suno/bark](https://huggingface.co/suno/bark)
    architecture.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[BarkCoarseModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkCoarseModel)的配置。根据指定的参数实例化模型，定义模型架构。使用默认值实例化配置将产生与Bark
    [suno/bark](https://huggingface.co/suno/bark)架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: BarkFineConfig
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkFineConfig
- en: '### `class transformers.BarkFineConfig`'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkFineConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L186)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L186)'
- en: '[PRE30]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`block_size` (`int`, *optional*, defaults to 1024) — The maximum sequence length
    that this model might ever be used with. Typically set this to something large
    just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_size` (`int`, *optional*, 默认为1024) — 此模型可能会使用的最大序列长度。通常将其设置为较大的值以防万一（例如，512或1024或2048）。'
- en: '`input_vocab_size` (`int`, *optional*, defaults to 10_048) — Vocabulary size
    of a Bark sub-model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel).
    Defaults to 10_048 but should be carefully thought with regards to the chosen
    sub-model.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_vocab_size` (`int`, *optional*, 默认为10_048) — Bark子模型的词汇量。定义了在调用[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)时可以表示的不同标记数量：`inputs_ids`。默认为10_048，但应根据所选子模型慎重考虑。'
- en: '`output_vocab_size` (`int`, *optional*, defaults to 10_048) — Output vocabulary
    size of a Bark sub-model. Defines the number of different tokens that can be represented
    by the: `output_ids` when passing forward a [BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel).
    Defaults to 10_048 but should be carefully thought with regards to the chosen
    sub-model.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_vocab_size` (`int`, *optional*, 默认为10_048) — Bark子模型的输出词汇量。定义了在向前传递[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)时可以表示的不同标记数量：`output_ids`。默认为10_048，但应根据所选子模型慎重考虑。'
- en: '`num_layers` (`int`, *optional*, defaults to 12) — Number of hidden layers
    in the given sub-model.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers` (`int`, *optional*, 默认为12) — 给定子模型中隐藏层的数量。'
- en: '`num_heads` (`int`, *optional*, defaults to 12) — Number of attention heads
    for each attention layer in the Transformer architecture.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`int`, *optional*, 默认为12) — Transformer架构中每个注意力层的注意力头数。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    “intermediate” (often named feed-forward) layer in the architecture.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为768) — 架构中“中间”（通常称为前馈）层的维度。'
- en: '`dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, 默认为0.0) — 嵌入层、编码器和池化器中所有全连接层的丢弃概率。'
- en: '`bias` (`bool`, *optional*, defaults to `True`) — Whether or not to use bias
    in the linear layers and layer norm layers.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias` (`bool`, *optional*, 默认为`True`) — 是否在线性层和层归一化层中使用偏置。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: '`n_codes_total` (`int`, *optional*, defaults to 8) — The total number of audio
    codebooks predicted. Used in the fine acoustics sub-model.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_codes_total` (`int`, *optional*, defaults to 8) — 预测的音频码书总数。用于细声学子模型。'
- en: '`n_codes_given` (`int`, *optional*, defaults to 1) — The number of audio codebooks
    predicted in the coarse acoustics sub-model. Used in the acoustics sub-models.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_codes_given` (`int`, *optional*, defaults to 1) — 粗声学子模型中预测的音频码书数量。用于声学子模型。'
- en: This is the configuration class to store the configuration of a [BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel).
    It is used to instantiate the model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the Bark [suno/bark](https://huggingface.co/suno/bark)
    architecture.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[BarkFineModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkFineModel)的配置。根据指定的参数实例化模型，定义模型架构。使用默认值实例化配置将产生类似于Bark
    [suno/bark](https://huggingface.co/suno/bark)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE31]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: BarkSemanticConfig
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BarkSemanticConfig
- en: '### `class transformers.BarkSemanticConfig`'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.BarkSemanticConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L142)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bark/configuration_bark.py#L142)'
- en: '[PRE32]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`block_size` (`int`, *optional*, defaults to 1024) — The maximum sequence length
    that this model might ever be used with. Typically set this to something large
    just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_size` (`int`, *optional*, defaults to 1024) — 该模型可能使用的最大序列长度。通常设置为较大的值以防万一（例如，512或1024或2048）。'
- en: '`input_vocab_size` (`int`, *optional*, defaults to 10_048) — Vocabulary size
    of a Bark sub-model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel).
    Defaults to 10_048 but should be carefully thought with regards to the chosen
    sub-model.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_vocab_size` (`int`, *optional*, defaults to 10_048) — Bark子模型的词汇量。定义了在调用[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)时传递的`inputs_ids`可以表示的不同标记数量。默认为10_048，但应根据所选子模型慎重考虑。'
- en: '`output_vocab_size` (`int`, *optional*, defaults to 10_048) — Output vocabulary
    size of a Bark sub-model. Defines the number of different tokens that can be represented
    by the: `output_ids` when passing forward a [BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel).
    Defaults to 10_048 but should be carefully thought with regards to the chosen
    sub-model.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_vocab_size` (`int`, *optional*, defaults to 10_048) — Bark子模型的输出词汇量。定义了在传递[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)时`output_ids`可以表示的不同标记数量。默认为10_048，但应根据所选子模型慎重考虑。'
- en: '`num_layers` (`int`, *optional*, defaults to 12) — Number of hidden layers
    in the given sub-model.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers` (`int`, *optional*, defaults to 12) — 给定子模型中的隐藏层数量。'
- en: '`num_heads` (`int`, *optional*, defaults to 12) — Number of attention heads
    for each attention layer in the Transformer architecture.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_heads` (`int`, *optional*, defaults to 12) — Transformer架构中每个注意力层的注意力头数。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    “intermediate” (often named feed-forward) layer in the architecture.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 架构中“中间”（通常称为前馈）层的维度。'
- en: '`dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.0) — 嵌入层、编码器和池化器中所有全连接层的丢失概率。'
- en: '`bias` (`bool`, *optional*, defaults to `True`) — Whether or not to use bias
    in the linear layers and layer norm layers.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias` (`bool`, *optional*, defaults to `True`) — 是否在线性层和层归一化层中使用偏置。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: This is the configuration class to store the configuration of a [BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel).
    It is used to instantiate the model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the Bark [suno/bark](https://huggingface.co/suno/bark)
    architecture.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[BarkSemanticModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkSemanticModel)的配置。根据指定的参数实例化模型，定义模型架构。使用默认值实例化配置将产生类似于Bark
    [suno/bark](https://huggingface.co/suno/bark)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE33]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
