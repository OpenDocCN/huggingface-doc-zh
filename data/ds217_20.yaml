- en: Use with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与PyTorch一起使用
- en: 'Original text: [https://huggingface.co/docs/datasets/use_with_pytorch](https://huggingface.co/docs/datasets/use_with_pytorch)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/use_with_pytorch](https://huggingface.co/docs/datasets/use_with_pytorch)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This document is a quick introduction to using `datasets` with PyTorch, with
    a particular focus on how to get `torch.Tensor` objects out of our datasets, and
    how to use a PyTorch `DataLoader` and a Hugging Face `Dataset` with the best performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是关于如何在PyTorch中使用`datasets`的快速介绍，特别关注如何从我们的数据集中获取`torch.Tensor`对象，以及如何使用PyTorch的`DataLoader`和Hugging
    Face的`Dataset`以获得最佳性能。
- en: Dataset format
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集格式
- en: 'By default, datasets return regular python objects: integers, floats, strings,
    lists, etc.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，数据集返回常规的Python对象：整数、浮点数、字符串、列表等。
- en: 'To get PyTorch tensors instead, you can set the format of the dataset to `pytorch`
    using [Dataset.with_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_format):'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取PyTorch张量，可以使用[Dataset.with_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_format)将数据集的格式设置为`pytorch`：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object is a wrapper of an Arrow table, which allows fast zero-copy reads from
    arrays in the dataset to PyTorch tensors.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象是Arrow表的包装器，允许从数据集中的数组快速零拷贝读取到PyTorch张量中。'
- en: 'To load the data as tensors on a GPU, specify the `device` argument:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据加载为GPU上的张量，请指定`device`参数：
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: N-dimensional arrays
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: N维数组
- en: 'If your dataset consists of N-dimensional arrays, you will see that by default
    they are considered as nested lists. In particular, a PyTorch formatted dataset
    outputs nested lists instead of a single tensor:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集由N维数组组成，则默认情况下它们被视为嵌套列表。特别是，PyTorch格式化的数据集输出嵌套列表而不是单个张量：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To get a single tensor, you must explicitly use the `Array` feature type and
    specify the shape of your tensors:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取单个张量，必须显式使用`Array`特征类型并指定张量的形状：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Other feature types
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他特征类型
- en: '[ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel)
    data are properly converted to tensors:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel)数据会被正确转换为张量：'
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: String and binary objects are unchanged, since PyTorch only supports numbers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串和二进制对象保持不变，因为PyTorch仅支持数字。
- en: The [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    and [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature types are also supported.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)和[Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)特征类型也受支持。'
- en: To use the [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    feature type, you’ll need to install the `vision` extra as `pip install datasets[vision]`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用[Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)特征类型，您需要安装`vision`额外功能，如`pip
    install datasets[vision]`。
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: To use the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature type, you’ll need to install the `audio` extra as `pip install datasets[audio]`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用[Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)特征类型，您需要安装`audio`额外功能，如`pip
    install datasets[audio]`。
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Data loading
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据加载
- en: 'Like `torch.utils.data.Dataset` objects, a [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    can be passed directly to a PyTorch `DataLoader`:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与`torch.utils.data.Dataset`对象一样，[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)可以直接传递给PyTorch的`DataLoader`：
- en: '[PRE7]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Optimize data loading
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化数据加载
- en: There are several ways you can increase the speed your data is loaded which
    can save you time, especially if you are working with large datasets. PyTorch
    offers parallelized data loading, retrieving batches of indices instead of individually,
    and streaming to iterate over the dataset without downloading it on disk.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以提高数据加载速度，这可以节省您的时间，特别是如果您正在处理大型数据集。PyTorch提供了并行化数据加载、检索批次索引而不是单独检索以及流式迭代数据集而无需将其下载到磁盘上的功能。
- en: Use multiple Workers
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用多个工作进程
- en: You can parallelize data loading with the `num_workers` argument of a PyTorch
    `DataLoader` and get a higher throughput.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用PyTorch的`DataLoader`的`num_workers`参数并行加载数据，并获得更高的吞吐量。
- en: Under the hood, the `DataLoader` starts `num_workers` processes. Each process
    reloads the dataset passed to the `DataLoader` and is used to query examples.
    Reloading the dataset inside a worker doesn’t fill up your RAM, since it simply
    memory-maps the dataset again from your disk.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，`DataLoader`启动`num_workers`个进程。每个进程重新加载传递给`DataLoader`的数据集，并用于查询示例。在工作进程内重新加载数据集不会填满您的RAM，因为它只是从磁盘再次内存映射数据集。
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Stream data
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流式数据
- en: Stream a dataset by loading it as an [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset).
    This allows you to progressively iterate over a remote dataset without downloading
    it on disk and or over local data files. Learn more about which type of dataset
    is best for your use case in the [choosing between a regular dataset or an iterable
    dataset](./about_mapstyle_vs_iterable) guide.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将其加载为[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)来流式传输数据集。这允许您逐步迭代远程数据集，而无需将其下载到磁盘上或本地数据文件上。在[选择常规数据集或可迭代数据集](./about_mapstyle_vs_iterable)指南中了解更多关于哪种类型的数据集最适合您的用例。
- en: 'An iterable dataset from `datasets` inherits from `torch.utils.data.IterableDataset`
    so you can pass it to a `torch.utils.data.DataLoader`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从`datasets`中的可迭代数据集继承自`torch.utils.data.IterableDataset`，因此您可以将其传递给`torch.utils.data.DataLoader`：
- en: '[PRE9]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If the dataset is split in several shards (i.e. if the dataset consists of
    multiple data files), then you can stream in parallel using `num_workers`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集分为多个分片（即如果数据集由多个数据文件组成），则可以使用`num_workers`并行流式传输：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this case each worker is given a subset of the list of shards to stream from.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，每个工作进程都会获得要从中流式传输的分片列表的子集。
- en: Distributed
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式
- en: 'To split your dataset across your training nodes, you can use [datasets.distributed.split_dataset_by_node()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.distributed.split_dataset_by_node):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要在训练节点之间分割数据集，您可以使用[datasets.distributed.split_dataset_by_node()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.distributed.split_dataset_by_node)：
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This works for both map-style datasets and iterable datasets. The dataset is
    split for the node at rank `rank` in a pool of nodes of size `world_size`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这适用于映射样式数据集和可迭代数据集。数据集在大小为`world_size`的节点池中为排名为`rank`的节点分割。
- en: 'For map-style datasets:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于映射样式数据集：
- en: Each node is assigned a chunk of data, e.g. rank 0 is given the first chunk
    of the dataset.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点被分配一块数据，例如，排名为0的节点被给予数据集的第一块。
- en: 'For iterable datasets:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可迭代数据集：
- en: If the dataset has a number of shards that is a factor of `world_size` (i.e.
    if `dataset.n_shards % world_size == 0`), then the shards are evenly assigned
    across the nodes, which is the most optimized. Otherwise, each node keeps 1 example
    out of `world_size`, skipping the other examples.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集的分片数是`world_size`的因子（即如果`dataset.n_shards % world_size == 0`），那么分片将均匀分配给节点，这是最优化的。否则，每个节点保留`world_size`中的一个示例，跳过其他示例。
- en: This can also be combined with a `torch.utils.data.DataLoader` if you want each
    node to use multiple workers to load the data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以与`torch.utils.data.DataLoader`结合使用，如果您希望每个节点使用多个工作进程来加载数据。
